{
  "id": "de4731f6-5740-45e8-8c01-4594514ce7a3",
  "title": "Journey to 1000 models: Scaling Instagram’s recommendation system",
  "link": "https://engineering.fb.com/2025/05/21/production-engineering/journey-to-1000-models-scaling-instagrams-recommendation-system/",
  "description": "In this post, we explore how Instagram has successfully scaled its algorithm to include over 1000 ML models without sacrificing recommendation quality or reliability.  We delve into the intricacies of managing such a vast array of models, each with its own performance characteristics and product goals.  We share insights and lessons learned along the way—from [...] Read More... The post Journey to 1000 models: Scaling Instagram’s recommendation system appeared first on Engineering at Meta.",
  "author": "",
  "published": "Wed, 21 May 2025 16:00:38 +0000",
  "source": "https://engineering.fb.com/feed/",
  "categories": [
    "Production Engineering",
    "Instagram"
  ],
  "byline": "By Luke Levis, Sing Sing Ma, Eduardo Nava",
  "length": 23154,
  "excerpt": "In this post, we explore how Instagram has successfully scaled its algorithm to include over 1000 ML models without sacrificing recommendation quality or reliability. We delve into the intricacies…",
  "siteName": "Engineering at Meta",
  "favicon": "",
  "text": "In this post, we explore how Instagram has successfully scaled its algorithm to include over 1000 ML models without sacrificing recommendation quality or reliability.  We delve into the intricacies of managing such a vast array of models, each with its own performance characteristics and product goals.  We share insights and lessons learned along the way—from the initial realization that our infrastructure maturity was lagging behind our ambitious scaling goals, to the innovative solutions we implemented to bridge these gaps. In the ever-evolving landscape of social media, Instagram serves as a hub for creative expression and connection, continually adapting to meet the dynamic needs of its global community. At the heart of this adaptability lies a web of machine learning (ML) models, each playing a crucial role in personalizing experiences. As Instagram’s reach and influence has grown, so too has the complexity of its algorithmic infrastructure. This growth, while exciting, presents a unique set of challenges, particularly in terms of reliability and scalability. Join us as we uncover the strategies and tools that have enabled Instagram to maintain its position at the forefront of social media innovation, ensuring a seamless and engaging experience for billions of users worldwide. Are there really that many ML models in Instagram? Though what shows up in Feed, Stories, and Reels is personally ranked, the number of ranked surfaces goes much deeper—to which comments surface in Feed, which notifications are “important,” or whom you might tag in a post. These are all driven by ML recommendations.  Within a given surface, we’ll have different layers of the ranking funnel: sourcing (retrieval), early-stage ranking (ESR), and late-stage ranking (LSR). We operate on fewer candidates as we progress through the funnel, as the underlying operations grow more expensive (see Figure 1 below): Figure 1: The ranking funnel. Within each surface and layer, there is constant experimentation, and these permutations create a severe infrastructure challenge. We need to allow room for our ML engineers to experiment with changes such as adjusting weights for a given prediction. The net result, depicted below in Figure 2, is a large number of models serving user traffic in production: Figure 2: An expression of the factors behind the fleet’s numerical growth. How did we realize infra maturity wasn’t going to catch up? Identified risks We identified several risks associated with scaling our algorithm, rooted in complaints about ML productivity and repeating patterns of issues: Discovery: Even as a team focused on one app — Instagram — we couldn’t stay on top of the growth, and product ML teams were maintaining separate sources of truth, if any, for their models in production. Release: We didn’t have a consistent way to launch new models safely, and the process was slow, impacting ML velocity and, therefore, product innovation. Health: We lacked a consistent definition of model prediction quality, and with the diversity of surfaces and subtlety of degraded ranking, quality issues went unnoticed. Solution overview To address these risks, we implemented several solutions: Model registry: We built a registry that serves as a ledger for production model importance and business function foremost, among other metadata. This registry serves as our foundational source of truth, upon which we can leverage automation to uplevel system-wide observability, change management, and model health. Model launch tooling: We developed a more ideal flow for launching new models that includes estimation, approval, prep, scale-up, and finalization. This process is now automated, and we’ve reduced the time it takes to launch a new model from days to hours. Model stability: We defined and operationalized model stability, a pioneering metric that measures the accuracy of our model predictions. We’ve leveraged model stability to produce SLOs for all models in the model registry, which enables simple understanding of the entire product surface’s ML health. Model registry What did model investigations look like prior to the registry? Before we created the model registry, the investigation process was a time-consuming and error-prone experience for on-call engineers and model owners. An on-call engineer had to ask multiple questions to model owners to gather information, as depicted Figure 3 below, about the context of what this model does in the stack and to clarify how important it is to the business. Figure 3: A fictional but typical non-productive investigation. Understanding this context is extremely important to the operational response: Depending on the importance of the model and the criticality of the surface it’s supporting, the response is going to differ in kind. When a model is an experiment serving a small percentage of the traffic, an appropriate response can be to end the experiment and reroute the traffic back to the main model (the baseline). But if there’s a problem with the baseline model that needs to be handled with urgency, it’s not possible to “just turn it off.” The engineer on call has to loop in the model owner, defeating the purpose of having a dedicated on-call. To avoid holding up an operational response on a single POC, we needed a central source of truth for model importance and business function. What if the model is not available? What if 10 of these issues happen concurrently?  With the development of the model registry, we standardized the collection of model importance and business function information, ensuring most of our operational resources were going towards the most important models. What problems did the model registry solve? The model registry is a system of record built on top of Configerator, Meta’s distributed configuration suite . This schematized ledger (see an example in Figure 4 and detailed further below) provides read-and-write access to operational data based on the inventory of production models. It’s a flexible and extensible foundation upon which one can build automation and tools to solve problems that are specific to individual organizations within Meta that are not served by the general tooling.  Figure 4: An abridged example of what a model registry entry looks like. As Instagram scaled its investment in AI through rapid innovation in content recommendations, the number of models and AI assets grew; as a result, it has been increasingly important — but also increasingly difficult — to maintain a minimum standard for all of our models, as we lacked an authoritative source for the business context as well as for a model’s importance.  In creating the model registry, we set out to provide a structured interface for collecting business context via model types, importance via criticality, and additional metadata that would enable model understanding. Below, we’ll get into the model types, criticality, and automation we’ve built for this purpose. Model types At a high level, model type describes the purpose for the ML workload where it represents a category or class of models that share a common purpose or are used in similar contexts. For example, we have “ig_stories_tray_mtml” which is a string attached to training flows, model checkpoints, inference services, and more. Put simply, a model type identifies for the reader this model’s purpose in the ranking funnel. Let’s break it down:  “ig_stories_tray_mtml” → “ig” “stories” “tray” “mtml” “ig”: This model is an “ig” model as opposed to “fb” or “whatsapp”. “stories”: This model serves IG Stories. “tray”: This model serves in the main IG Stories tray (as opposed to stories in some other surface).  “mtml”: This model is a multi-task-multi-label model, commonly used in late-stage ranking. We can then use these model type strings to tag AI assets, and since they serve as proxies for business context, we can use them also for asset management, policy enforcement, analytics, and more. The metadata entries in the model registry are anchored on two main types that describe model instances (ModelMetadata) as well as model types (ModelTypeMetadata). These types are made up of “core” attributes that are universally applicable, as well as “extended” attributes that allow different teams to encode their opinions about how these entries will inform operations. For example, in Instagram our extended attributes encode “baseline” and “holdout” model IDs, which are used in our ranking infrastructure to orchestrate ranking funnel execution.  Criticality In addition to defining business function, we had to establish clear guidelines for model importance. Within Meta, SEVs and services have a unified-importance tier system where the Global Service Index (GSI) records a criticality from TIER0 to TIER4 based on the maximum incident severity level the service can cause, from SEV0 as the most critical to SEV4 as simply a “heads up.” Since GSI criticality had social proof at the company, and infra engineers were familiar with this system, we adopted these criticalities for models and now annotate them at the model type and model level. No longer would each team decide to raise their own model services to TIER1 for themselves, increasing the burden on all teams that support these models. Teams needed to provide an immediate response (available 24/7) on call and be able to prove that their models contributed meaningfully to critical business metrics to qualify for elevated monitoring. Configuration structure as a foundation for automation  Once we had onboarded a critical mass of Instagram models to the model registry, we could begin to fully integrate with our monitoring and observability suite using our Meta-wide configuration solution, Configerator. With this, we could now have model performance monitoring and alerts that are fully automated and integrated with our tooling for SLIs called SLICK, dashboards that allow us to monitor models across many time series dimensions, and a suite of alerting specific to the model that is driven from the entries in the model registry. This provided all our teams confidence that our monitoring coverage was complete and automated. Launching While a point-in-time snapshot of models in production is great for static systems, Instagram’s ML landscape is constantly shifting. With the rapid increase of iteration on the recommendation system driving an increased number of launches, it became clear our infrastructure support to make this happen was not adequate. Time-to-launch was a bottleneck in ML velocity, and we needed to drive it down. What did the process look like? Conventionally, services were longstanding systems that had engineers supporting them to tune. Even when new changes would introduce new capacity regression risks, we could gate this behind change safety mechanisms.  However, our modeling and experimentation structure was unique in that we were planning for more rapid iteration, and our options were insufficient. To safely test the extent of load a new service could support, we would clone the entire service, send shadow traffic (i.e., cloned traffic that isn’t processed by our clients), and run multiple overload tests until we found a consistent peak throughput. But this wasn’t a perfect science. Sometimes we didn’t send enough traffic, and sometimes we’d send too much, and the amount could change throughout the day due to variations in global user behavior.  This could easily take two days to get right, including actually debugging the performance itself when the results weren’t expected. Once we got the result, we’d then have to estimate the final cost. Below (in Figure 5) is the formula we landed on. Figure 5: A formula calculating capacity estimations for a new launch. The actual traffic shifting portion was tedious as well. For example, when we managed to fully estimate that we needed 500 replicas to host the new service, we might not actually have 500 spares lying around to do a full replacement, so launching was a delicate process of partially sizing up by approximately 20%, sending 20% of traffic over, and then scaling down the old service by 20% to reclaim and recycle the capacity. Rinse, repeat. Inefficient! And by the time we got to the end of this arduous process, the ordeal still wasn’t over. Each team was responsible for correctly setting up new alerts for their baseline in a timely fashion, or else their old models could and did trigger false alarms.  How does forcing virtual pools aid product growth? One of the prerequisites for fixing competition for resources and unblocking productivity was to put up guardrails. Prior to this, it was “first come first served,” with no clear way to even “reserve” future freed capacity. It was also hard to reason about fairness from an infra perspective: Would it make sense to give each team equal pools, or give each individual person a maximum limit?  As it turned out, not all MLEs are experimenting at the same time, due to staggered progress on their work, so individual (per-engineer) limits were not ideal. One member might be in the experimentation stage and another might be training. So our solution was to provide bandwidth to each team.  Once each team — and therefore product — had quotas distributed, their launch policy became more clear cut. Some teams established free launching as long as the team was within quota. Others required no regressions in capacity usage. But mostly this unlocked our ability to run launches in parallel, since each one required much less red tape, and prioritization was no longer done at the org level. What other tooling improved launching? As mentioned earlier, preplanning with capacity estimations was critical to understanding cost and ensuring reliability. We were often asked, Why not let autoscaling take care of everything? The problem was that each service could be configured slightly differently than a previously optimized service, or some architectural change could have affected the performance of the model. We didn’t have an infinite amount of supply to work with, so by the time we fully traffic-shifted everything over, we might find that we didn’t have enough supply. Reverting is costly, taking hours to get through each stage. By doing capacity estimations in advance, this also allowed us and each team to accurately evaluate metric improvement versus cost. It might be worthwhile to double our costs if something would increase time spent on the app by 1%, but likely not for a 0.05% improvement where we could better spend that capacity funding another initiative.   With partners in AI Infra, we developed two major solutions to this process: offline performance evaluation and an automated launching platform. We simplified determining performance of a new service using recorded traffic. Pre-recorded traffic was continuously collected into a data warehouse that the benchmarker could read from, and we’d spin up temporary jobs with this automation. One job would replay different levels of traffic continuously and send it to another job that was a clone of the existing experiment. By putting stoppers on desired latency and error rates, the tooling would eventually output a converged stable number that we could understand as the max load (see Figure 6). Figure 6: Load tests converging on an accurate measure of load. The launch platform itself would input the numbers we captured from these tests, automatically collect demand data as defined, and run that same formula to calculate a cost. The platform would then perform the upscaling/downscaling cycle for teams as we shifted traffic. And finally, by leveraging the model registry, we were able to land this model change in code (see example in Figure 6), to help us better maintain and understand the 1000+ models within our fleet. Likewise, this bolstered our trust in the model registry, which was now directly tied to the model launch lifecycle. Figure 7: A theoretical model registry change during launch. This suite of launch automation has dramatically reduced the class of SEVs related to model launches, improved our pace of innovation from a few to more than 10 launches per week, and reduced the amount of time engineers spend conducting a launch by more than two days. Model stability As the number of models in production increased, our organization started to feel the effects of an inconsistent measure of model health. While ranking models are run like any other distributed backend system (receive a request, produce a response), one may think a universal SLO that measures request success rate can suffice to capture holistic health. This is not the case for ranking models, as the accuracy of recommendations received carries significant importance to the end-user experience. If we consider a user who is a huge fan of golf but does not enjoy cooking content (see the “available \u0026 irrelevant” case in Figure 8 below), we see an example of this inaccuracy in practice. This is precisely what the model stability metric sought to capture. Figure 8: Different types of responses that can be provided to an end user. Why is measuring ranking model reliability unique? Ranking models, unlike traditional idempotent request/response backends, produce scores predicting user action given a set of candidates (PLIKE, PCOMMENT, PFOLLOW, etc.). These scores then combine and are used to determine which candidates are most relevant to an end user. It’s important that these scores accurately reflect user interest, as their accuracy is directly correlated to user engagement. If we recommend irrelevant content, user engagement suffers. The model stability metric was designed to make it easy to measure this accuracy and detect inaccuracy at our scale.  Let’s discuss how this works. Defining model stability Models are complex, and they produce multiple output predictions. Let’s take a simplified example (shown in Figure 9 below) of a multi-task-multi-label (MTML) model predicting three actions: Figure 9: A simplified MTML model predicting three actions. For us to claim this model is stable, we must also claim that each underlying prediction is stable. When evaluating the accuracy of a ranking model’s predictions, we typically look at two metrics: Model calibration, which is based on observed real-world outcomes and answers the question, “Are we over- or under-predicting user action?” It is calculated as a ratio of predicted click-through-rate (CTR) and empirical CTR. A perfect predictor will have calibration centered at 1. Model normalized entropy (NE), which measures the discriminative power of a predictor, and answers the question, “How well can this predictor separate action from inaction?” It is calculated as a ratio of the average log-loss per impression to what the average log-loss per impression would be if we always predicted the empirical CTR. With NE, lower values are better, and an NE of 1 is equivalent to random predictions. (For more information regarding our choice of prediction evaluation metrics, please refer to the paper, “Practical Lessons from Predicting Clicks on Ads at Facebook.”) A model’s predictions are unstable when either calibration or NE are out of their expected healthy ranges. To determine what a healthy range is, we must look at each metric in real time, and Figure 10 below shows what these time series can look like: Figure 10: Example predictions of calibration and NE over a period of time. By observing the trend of a healthy prediction, we can apply thresholds for our evaluation metrics. When these thresholds are breached, the underlying prediction is considered unstable. From here, we can define model stability as a binary indicator across a model’s predictions. It is 1 if all underlying predictions are stable, and 0 if any prediction is unstable. This is an extremely powerful method of reacting to real-time prediction instability as well as a tool for understanding trends in predictive health per model or across distinct products ranking funnels. Operationalizing model stability With a real-time view on model predictive health, we can leverage this unified definition of model stability and apply it to all of our models in production, once again leveraging the model registry as a ledger to hold this important data. In Figure 11 below, we can see the addition of model stability metric metadata after we determined the expected thresholds. Figure 11: Model stability definitions stored in the model registry. Given the large number of models in production, each producing many predictions, building a portable definition of model health applicable to all of our ranking models represented an important milestone toward upleveling Instagram’s ML infrastructure maturity. This has unlocked our ability to build generic alerting to guarantee detection of our most important models becoming unstable, thereby moving us closer to mitigation when our recommendation system is at risk.  Since the addition of these metrics and alerting, ML teams have discovered previously hidden issues within their models and addressed them faster than before, leading to higher-quality recommendations. Key takeaways In our journey to scale Instagram’s algorithm to manage over 1000 models, we have learned several critical lessons that have shaped our approach and infrastructure. These takeaways not only highlight the challenges we faced but also underscore the strategies that led to our success. Infra understanding is the foundation to building the right tools A unified understanding of our infrastructure footprint was essential in developing the right tools to support our scaling efforts. By identifying the gaps and potential risks in our existing systems, we were able to implement solutions such as the model registry that significantly improved our operational efficiency and reliability posture. Helping colleagues move fast means we all move faster By addressing the model iteration bottleneck, we enabled our teams to innovate more rapidly. Our focus on creating a seamless, self-service process for model iteration empowered client teams to take ownership of their workflows. This not only accelerated their progress but also reduced the operational burden on our infrastructure team. As a result, the entire organization benefited from increased agility and productivity. Reliability must consider quality Ensuring the reliability of our models required us to redefine how we measure and maintain model quality. By operationalizing model stability and establishing clear metrics for model health, we were able to proactively manage the performance of our models. This approach enables us to maintain high standards of quality across our recommendation systems, ultimately enhancing user engagement and satisfaction. Our experience in scaling Instagram’s recommendation system has reinforced the importance of infrastructure understanding, collaboration, and a focus on quality. By building robust tools and processes, we have not only improved our own operations but also empowered our colleagues to drive innovation and growth across the platform.",
  "image": "https://engineering.fb.com/wp-content/uploads/2025/05/Eng-Blog-Self-Serve-Hero-Images-DEBUGGING-203-TealeLight-x2.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n\t\t\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eIn this post, we explore how Instagram has successfully scaled its algorithm to include over 1000 ML models without sacrificing recommendation quality or reliability. \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eWe delve into the intricacies of managing such a vast array of models, each with its own performance characteristics and product goals. \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eWe share insights and lessons learned along the way—from the initial realization that our infrastructure maturity was lagging behind our ambitious scaling goals, to the innovative solutions we implemented to bridge these gaps.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003eIn the ever-evolving landscape of social media, Instagram serves as a hub for creative expression and connection, continually adapting to meet the dynamic needs of its global community. At the heart of this adaptability lies a web of machine learning (ML) models, each playing a crucial role in personalizing experiences. As Instagram’s reach and influence has grown, so too has the complexity of its algorithmic infrastructure. This growth, while exciting, presents a unique set of challenges, particularly in terms of reliability and scalability.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eJoin us as we uncover the strategies and tools that have enabled Instagram to maintain its position at the forefront of social media innovation, ensuring a seamless and engaging experience for billions of users worldwide.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003ciframe title=\"Journey to 1000 Models: Scaling Instagram\u0026#39;s algorithm without the Reliability Nightmare\" width=\"1778\" height=\"1000\" src=\"https://www.youtube.com/embed/Aojmc0R1Nmo?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eAre there really that many ML models in Instagram?\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eThough what shows up in Feed, Stories, and Reels is personally ranked, the number of ranked surfaces goes much deeper—to which comments surface in Feed, which notifications are “important,” or whom you might tag in a post. These are all driven by ML recommendations. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWithin a given surface, we’ll have different layers of the ranking funnel: sourcing (retrieval), early-stage ranking (ESR), and late-stage ranking (LSR). We operate on fewer candidates as we progress through the funnel, as the underlying operations grow more expensive (see Figure 1 below):\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22526\" aria-describedby=\"caption-attachment-22526\"\u003e\u003cimg decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?w=933\" alt=\"\" width=\"547\" height=\"600\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png 1566w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?resize=835,916 835w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?resize=768,843 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?resize=933,1024 933w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?resize=1400,1536 1400w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?resize=96,105 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-1.png?resize=192,211 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22526\"\u003eFigure 1: The ranking funnel.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eWithin each surface and layer, there is constant experimentation, and these permutations create a severe infrastructure challenge. We need to allow room for our ML engineers to experiment with changes such as adjusting weights for a given prediction. The net result, depicted below in Figure 2, is a large number of models serving user traffic in production:\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22527\" aria-describedby=\"caption-attachment-22527\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?w=1024\" alt=\"\" width=\"1024\" height=\"187\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?resize=916,168 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?resize=768,141 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?resize=1024,187 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?resize=1536,281 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?resize=96,18 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-2.png?resize=192,35 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22527\"\u003eFigure 2: An expression of the factors behind the fleet’s numerical growth.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003ch2\u003e\u003cspan\u003eHow did we realize infra maturity wasn’t going to catch up?\u003c/span\u003e\u003c/h2\u003e\n\u003ch3\u003e\u003cspan\u003eIdentified risks\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eWe identified several risks associated with scaling our algorithm, rooted in complaints about ML productivity and repeating patterns of issues:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eDiscovery:\u003c/b\u003e\u003cspan\u003e Even as a team focused on one app — Instagram — we couldn’t stay on top of the growth, and product ML teams were maintaining separate sources of truth, if any, for their models in production.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eRelease:\u003c/b\u003e\u003cspan\u003e We didn’t have a consistent way to launch new models safely, and the process was slow, impacting ML velocity and, therefore, product innovation.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eHealth:\u003c/b\u003e\u003cspan\u003e We lacked a consistent definition of model prediction quality, and with the diversity of surfaces and subtlety of degraded ranking, quality issues went unnoticed.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003cspan\u003eSolution overview\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eTo address these risks, we implemented several solutions:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eModel registry:\u003c/b\u003e\u003cspan\u003e We built a registry that serves as a ledger for production model importance and business function foremost, among other metadata. This registry serves as our foundational source of truth, upon which we can leverage automation to uplevel system-wide observability, change management, and model health.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eModel launch tooling:\u003c/b\u003e\u003cspan\u003e We developed a more ideal flow for launching new models that includes estimation, approval, prep, scale-up, and finalization. This process is now automated, and we’ve reduced the time it takes to launch a new model from days to hours.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eModel stability:\u003c/b\u003e\u003cspan\u003e We defined and operationalized model stability, a pioneering metric that measures the accuracy of our model predictions. We’ve leveraged model stability to produce SLOs for all models in the model registry, which enables simple understanding of the entire product surface’s ML health.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003cspan\u003eModel registry\u003c/span\u003e\u003c/h2\u003e\n\u003ch3\u003e\u003cspan\u003eWhat did model investigations look like prior to the registry?\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eBefore we created the model registry, the investigation process was a time-consuming and error-prone experience for on-call engineers and model owners. An on-call engineer had to ask multiple questions to model owners to gather information, as depicted Figure 3 below, about the context of what this model does in the stack and to clarify how important it is to the business.\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22528\" aria-describedby=\"caption-attachment-22528\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?w=1024\" alt=\"\" width=\"1024\" height=\"536\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png 1782w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?resize=916,479 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?resize=768,402 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?resize=1024,536 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?resize=1536,803 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?resize=96,50 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-3.png?resize=192,100 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22528\"\u003eFigure 3: A fictional but typical non-productive investigation.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eUnderstanding this context is extremely important to the operational response: Depending on the importance of the model and the criticality of the surface it’s supporting, the response is going to differ in kind. When a model is an experiment serving a small percentage of the traffic, an appropriate response can be to end the experiment and reroute the traffic back to the main model (the baseline). But if there’s a problem with the baseline model that needs to be handled with urgency, it’s not possible to “just turn it off.” The engineer on call has to loop in the model owner, defeating the purpose of having a dedicated on-call.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eTo avoid holding up an operational response on a single POC, we needed a central source of truth for model importance and business function. \u003c/span\u003e\u003ci\u003e\u003cspan\u003eWhat if the model is not available? What if 10 of these issues happen concurrently?\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWith the development of the model registry, we standardized the collection of model importance and business function information, ensuring most of our operational resources were going towards the most important models.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eWhat problems did the model registry solve?\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eThe model registry is a system of record built on top of \u003c/span\u003e\u003ca href=\"https://research.facebook.com/publications/holistic-configuration-management-at-facebook/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003eConfigerator\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, Meta’s distributed configuration suite . This schematized ledger (see an example in Figure 4 and detailed further below) provides read-and-write access to operational data based on the inventory of production models. It’s a flexible and extensible foundation upon which one can build automation and tools to solve problems that are specific to individual organizations within Meta that are not served by the general tooling. \u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22529\" aria-describedby=\"caption-attachment-22529\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?w=1024\" alt=\"\" width=\"1024\" height=\"375\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?resize=916,335 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?resize=768,281 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?resize=1024,375 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?resize=1536,562 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?resize=96,35 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-4.png?resize=192,70 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22529\"\u003eFigure 4: An abridged example of what a model registry entry looks like.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eAs Instagram scaled its investment in AI through \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2023/08/09/ml-applications/scaling-instagram-explore-recommendations-system/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003erapid innovation in content recommendations\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, the number of models and AI assets grew; as a result, it has been increasingly important — but also increasingly difficult — to maintain a minimum standard for all of our models, as we lacked an authoritative source for the business context as well as for a model’s importance. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eIn creating the model registry, we set out to provide a structured interface for collecting business context via model types, importance via criticality, and additional metadata that would enable model understanding. Below, we’ll get into the model types, criticality, and automation we’ve built for this purpose.\u003c/span\u003e\u003c/p\u003e\n\u003ch4\u003e\u003cspan\u003eModel types\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003cspan\u003eAt a high level, model type describes the purpose for the ML workload where it represents a category or class of models that share a common purpose or are used in similar contexts. For example, we have “\u003c/span\u003e\u003cspan\u003eig_stories_tray_mtml\u003c/span\u003e\u003cb\u003e”\u003c/b\u003e\u003cspan\u003e which is a string attached to training flows, model checkpoints, inference services, and more. Put simply, a model type identifies for the reader this model’s purpose in the ranking funnel.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eLet’s break it down: \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e“\u003c/span\u003e\u003cspan\u003eig_stories_tray_mtml\u003c/span\u003e\u003cspan\u003e” → “\u003c/span\u003e\u003cspan\u003eig\u003c/span\u003e\u003cb\u003e” “\u003c/b\u003e\u003cspan\u003estories\u003c/span\u003e\u003cb\u003e” “\u003c/b\u003e\u003cspan\u003etray\u003c/span\u003e\u003cb\u003e” “\u003c/b\u003e\u003cspan\u003emtml\u003c/span\u003e\u003cspan\u003e”\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003e“\u003c/b\u003e\u003cb\u003eig\u003c/b\u003e\u003cb\u003e”:\u003c/b\u003e\u003cspan\u003e This model is an “ig” model as opposed to “fb” or “whatsapp”.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003e“\u003c/b\u003e\u003cb\u003estories\u003c/b\u003e\u003cb\u003e”:\u003c/b\u003e\u003cspan\u003e This model serves IG Stories.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003e“\u003c/b\u003e\u003cb\u003etray\u003c/b\u003e\u003cb\u003e”:\u003c/b\u003e\u003cspan\u003e This model serves in the main IG Stories tray (as opposed to stories in some other surface).\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003e “\u003c/b\u003e\u003cb\u003emtml\u003c/b\u003e\u003cb\u003e”:\u003c/b\u003e\u003cspan\u003e This model is a multi-task-multi-label model, commonly used in late-stage ranking.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003eWe can then use these model type strings to tag AI assets, and since they serve as proxies for business context, we can use them also for asset management, policy enforcement, analytics, and more.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThe metadata entries in the model registry are anchored on two main types that describe model instances (\u003c/span\u003e\u003cspan\u003eModelMetadata\u003c/span\u003e\u003cspan\u003e) as well as model types (\u003c/span\u003e\u003cspan\u003eModelTypeMetadata\u003c/span\u003e\u003cspan\u003e). These types are made up of “core” attributes that are universally applicable, as well as “extended” attributes that allow different teams to encode their opinions about how these entries will inform operations. For example, in Instagram our extended attributes encode “baseline” and “holdout” model IDs, which are used in our ranking infrastructure to orchestrate ranking funnel execution. \u003c/span\u003e\u003c/p\u003e\n\u003ch4\u003e\u003cspan\u003eCriticality\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003cspan\u003eIn addition to defining business function, we had to establish clear guidelines for model importance. Within Meta, SEVs and services have a unified-importance tier system where the Global Service Index (GSI) records a criticality from TIER0 to TIER4 based on the maximum incident severity level the service can cause, from SEV0 as the most critical to SEV4 as simply a “heads up.” Since GSI criticality had social proof at the company, and infra engineers were familiar with this system, we adopted these criticalities for models and now annotate them at the model type and model level.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eNo longer would each team decide to raise their own model services to TIER1 for themselves, increasing the burden on all teams that support these models. Teams needed to provide an immediate response (available 24/7) on call and be able to prove that their models contributed meaningfully to critical business metrics to qualify for elevated monitoring.\u003c/span\u003e\u003c/p\u003e\n\u003ch4\u003e\u003cspan\u003eConfiguration structure as a foundation for automation \u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003cspan\u003eOnce we had onboarded a critical mass of Instagram models to the model registry, we could begin to fully integrate with our monitoring and observability suite using our Meta-wide configuration solution, Configerator. With this, we could now have model performance monitoring and alerts that are fully automated and integrated with our tooling for \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2021/12/13/production-engineering/slick/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003eSLIs called SLICK\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, dashboards that allow us to monitor models across many time series dimensions, and a suite of alerting specific to the model that is driven from the entries in the model registry.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThis provided all our teams confidence that our monitoring coverage was complete and automated.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eLaunching\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eWhile a point-in-time snapshot of models in production is great for static systems, Instagram’s ML landscape is constantly shifting. With the rapid increase of iteration on the recommendation system driving an increased number of launches, it became clear our infrastructure support to make this happen was not adequate. Time-to-launch was a bottleneck in ML velocity, and we needed to drive it down.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eWhat did the process look like?\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eConventionally, services were longstanding systems that had engineers supporting them to tune. Even when new changes would introduce new capacity regression risks, we could gate this behind change safety mechanisms. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eHowever, our modeling and experimentation structure was unique in that we were planning for more rapid iteration, and our options were insufficient. To safely test the extent of load a new service could support, we would clone the entire service, send shadow traffic (i.e., cloned traffic that isn’t processed by our clients), and run multiple overload tests until we found a consistent peak throughput. But this wasn’t a perfect science. Sometimes we didn’t send enough traffic, and sometimes we’d send too much, and the amount could change throughout the day due to variations in global user behavior. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThis could easily take two days to get right, including actually debugging the performance itself when the results weren’t expected. Once we got the result, we’d then have to estimate the final cost. Below (in Figure 5) is the formula we landed on.\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22530\" aria-describedby=\"caption-attachment-22530\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?w=1024\" alt=\"\" width=\"1024\" height=\"131\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png 1828w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?resize=916,117 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?resize=768,98 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?resize=1024,131 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?resize=1536,197 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?resize=96,12 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-5.png?resize=192,25 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22530\"\u003eFigure 5: A formula calculating capacity estimations for a new launch.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eThe actual traffic shifting portion was tedious as well. For example, when we managed to fully estimate that we needed 500 replicas to host the new service, we might not actually have 500 spares lying around to do a full replacement, so launching was a delicate process of partially sizing up by approximately 20%, sending 20% of traffic over, and then scaling down the old service by 20% to reclaim and recycle the capacity. Rinse, repeat. Inefficient!\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eAnd by the time we got to the end of this arduous process, the ordeal still wasn’t over. Each team was responsible for correctly setting up new alerts for their baseline in a timely fashion, or else their old models could and did trigger false alarms. \u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eHow does forcing virtual pools aid product growth?\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eOne of the prerequisites for fixing competition for resources and unblocking productivity was to put up guardrails. Prior to this, it was “first come first served,” with no clear way to even “reserve” future freed capacity. It was also hard to reason about fairness from an infra perspective: Would it make sense to give each team equal pools, or give each individual person a maximum limit? \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eAs it turned out, not all MLEs are experimenting at the same time, due to staggered progress on their work, so individual (per-engineer) limits were not ideal. One member might be in the experimentation stage and another might be training. So our solution was to provide bandwidth to each team. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eOnce each team — and therefore product — had quotas distributed, their launch policy became more clear cut. Some teams established free launching as long as the team was within quota. Others required no regressions in capacity usage. But mostly this unlocked our ability to run launches in parallel, since each one required much less red tape, and prioritization was no longer done at the org level.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eWhat other tooling improved launching?\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eAs mentioned earlier, preplanning with capacity estimations was critical to understanding cost and ensuring reliability. We were often asked, \u003c/span\u003e\u003ci\u003e\u003cspan\u003eWhy not let autoscaling take care of everything?\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e The problem was that each service could be configured slightly differently than a previously optimized service, or some architectural change could have affected the performance of the model. We didn’t have an infinite amount of supply to work with, so by the time we fully traffic-shifted everything over, we might find that we didn’t have enough supply. Reverting is costly, taking hours to get through each stage.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eBy doing capacity estimations in advance, this also allowed us and each team to accurately evaluate metric improvement versus cost. It might be worthwhile to double our costs if something would increase time spent on the app by 1%, but likely not for a 0.05% improvement where we could better spend that capacity funding another initiative.  \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWith partners in AI Infra, we developed two major solutions to this process: offline performance evaluation and an automated launching platform.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWe simplified determining performance of a new service using recorded traffic. Pre-recorded traffic was continuously collected into a data warehouse that the benchmarker could read from, and we’d spin up temporary jobs with this automation. One job would replay different levels of traffic continuously and send it to another job that was a clone of the existing experiment. By putting stoppers on desired latency and error rates, the tooling would eventually output a converged stable number that we could understand as the max load (see Figure 6).\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22531\" aria-describedby=\"caption-attachment-22531\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png?w=1024\" alt=\"\" width=\"575\" height=\"500\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png 1174w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png?resize=916,796 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png?resize=768,667 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png?resize=1024,890 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png?resize=96,83 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-6.png?resize=192,167 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22531\"\u003eFigure 6: Load tests converging on an accurate measure of load.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eThe launch platform itself would input the numbers we captured from these tests, automatically collect demand data as defined, and run that same formula to calculate a cost. The platform would then perform the upscaling/downscaling cycle for teams as we shifted traffic.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eAnd finally, by leveraging the model registry, we were able to land this model change in code (see example in Figure 6), to help us better maintain and understand the 1000+ models within our fleet. Likewise, this bolstered our trust in the model registry, which was now directly tied to the model launch lifecycle.\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22532\" aria-describedby=\"caption-attachment-22532\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?w=1024\" alt=\"\" width=\"1024\" height=\"446\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?resize=916,399 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?resize=768,334 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?resize=1024,446 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?resize=1536,668 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?resize=96,42 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-7.png?resize=192,84 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22532\"\u003eFigure 7: A theoretical model registry change during launch.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eThis suite of launch automation has dramatically reduced the class of SEVs related to model launches, improved our pace of innovation from a few to more than 10 launches per week, and reduced the amount of time engineers spend conducting a launch by more than two days.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eModel stability\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eAs the number of models in production increased, our organization started to feel the effects of an inconsistent measure of model health. While ranking models are run like any other distributed backend system (receive a request, produce a response), one may think a universal SLO that measures request success rate can suffice to capture holistic health. This is not the case for ranking models, as the \u003c/span\u003e\u003ci\u003e\u003cspan\u003eaccuracy\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e of recommendations received carries significant importance to the end-user experience. If we consider a user who is a huge fan of golf but does not enjoy cooking content (see the “available \u0026amp; irrelevant” case in Figure 8 below), we see an example of this \u003c/span\u003e\u003ci\u003e\u003cspan\u003einaccuracy\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e in practice. This is precisely what the model stability metric sought to capture.\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22533\" aria-describedby=\"caption-attachment-22533\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?w=1024\" alt=\"\" width=\"1024\" height=\"586\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?resize=916,524 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?resize=768,439 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?resize=1024,586 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?resize=1536,878 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?resize=96,55 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-8.png?resize=192,110 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22533\"\u003eFigure 8: Different types of responses that can be provided to an end user.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003ch3\u003e\u003cspan\u003eWhy is measuring ranking model reliability unique?\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eRanking models, unlike traditional idempotent request/response backends, produce scores predicting user action given a set of candidates (PLIKE, PCOMMENT, PFOLLOW, etc.). These scores then combine and are used to determine which candidates are most relevant to an end user. It’s important that these scores accurately reflect user interest, as their accuracy is directly correlated to user engagement. If we recommend irrelevant content, user engagement suffers. The model stability metric was designed to make it easy to measure this \u003c/span\u003e\u003ci\u003e\u003cspan\u003eaccuracy\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e and detect \u003c/span\u003e\u003ci\u003e\u003cspan\u003einaccuracy\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e at our scale. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eLet’s discuss how this works.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eDefining model stability\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eModels are complex, and they produce multiple output predictions. Let’s take a simplified example (shown in Figure 9 below) of a multi-task-multi-label (MTML) model predicting three actions:\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22534\" aria-describedby=\"caption-attachment-22534\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?w=1024\" alt=\"\" width=\"1024\" height=\"625\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png 1926w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?resize=916,559 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?resize=768,469 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?resize=1024,625 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?resize=1536,938 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?resize=96,59 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-9.png?resize=192,117 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22534\"\u003eFigure 9: A simplified MTML model predicting three actions.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eFor us to claim this model is stable, we must also claim that each underlying \u003c/span\u003e\u003ci\u003e\u003cspan\u003eprediction\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e is stable.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWhen evaluating the accuracy of a ranking model’s predictions, we typically look at two metrics:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eModel \u003c/span\u003e\u003cb\u003ecalibration\u003c/b\u003e\u003cspan\u003e, which is based on observed real-world outcomes and answers the question, \u003c/span\u003e\u003ci\u003e\u003cspan\u003e“Are we over- or under-predicting user action?”\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e It is calculated as a ratio of predicted click-through-rate (CTR) and empirical CTR. A perfect predictor will have calibration centered at 1.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eModel \u003c/span\u003e\u003cb\u003enormalized entropy\u003c/b\u003e\u003cspan\u003e (NE), which measures the discriminative power of a predictor, and answers the question, \u003c/span\u003e\u003ci\u003e\u003cspan\u003e“How well can this predictor separate action from inaction?”\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e It is calculated as a ratio of the average log-loss per impression to what the average log-loss per impression would be if we always predicted the empirical CTR. With NE, lower values are better, and an NE of 1 is equivalent to random predictions.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003e(For more information regarding our choice of prediction evaluation metrics, please refer to the paper, “\u003c/span\u003e\u003ca href=\"https://research.facebook.com/publications/practical-lessons-from-predicting-clicks-on-ads-at-facebook/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003ePractical Lessons from Predicting Clicks on Ads at Facebook.\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e”)\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eA model’s predictions are unstable when either \u003c/span\u003e\u003cb\u003ecalibration\u003c/b\u003e\u003cspan\u003e or \u003c/span\u003e\u003cb\u003eNE\u003c/b\u003e\u003cspan\u003e are out of their expected healthy ranges. To determine what a healthy range is, we must look at each metric in real time, and Figure 10 below shows what these time series can look like:\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22535\" aria-describedby=\"caption-attachment-22535\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?w=1024\" alt=\"\" width=\"1024\" height=\"511\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?resize=916,457 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?resize=768,383 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?resize=1024,511 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?resize=1536,766 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?resize=96,48 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-10.png?resize=192,96 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22535\"\u003eFigure 10: Example predictions of calibration and NE over a period of time.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eBy observing the trend of a healthy prediction, we can apply thresholds for our evaluation metrics. When these thresholds are breached, the underlying prediction is considered unstable.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eFrom here, we can define \u003c/span\u003e\u003ci\u003e\u003cspan\u003emodel stability\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e as a binary indicator across a model’s predictions. It is 1 if all underlying predictions are stable, and 0 if any prediction is unstable. This is an extremely powerful method of reacting to real-time prediction instability as well as a tool for understanding trends in predictive health per model or across distinct products ranking funnels.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eOperationalizing model stability\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eWith a real-time view on model predictive health, we can leverage this unified definition of model stability and apply it to all of our models in production, once again leveraging the model registry as a ledger to hold this important data. In Figure 11 below, we can see the addition of model stability metric metadata after we determined the expected thresholds.\u003c/span\u003e\u003c/p\u003e\n\u003cfigure id=\"attachment_22536\" aria-describedby=\"caption-attachment-22536\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?w=1024\" alt=\"\" width=\"1024\" height=\"446\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?resize=916,399 916w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?resize=768,334 768w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?resize=1024,446 1024w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?resize=1536,668 1536w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?resize=96,42 96w, https://engineering.fb.com/wp-content/uploads/2025/05/Instagram-1000-models-image-11.png?resize=192,84 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cfigcaption id=\"caption-attachment-22536\"\u003eFigure 11: Model stability definitions stored in the model registry.\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003e\u003cspan\u003eGiven the large number of models in production, each producing many predictions, building a portable definition of model health applicable to all of our ranking models represented an important milestone toward upleveling Instagram’s ML infrastructure maturity. This has unlocked our ability to build generic alerting to guarantee detection of our most important models becoming unstable, thereby moving us closer to mitigation when our recommendation system is at risk. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eSince the addition of these metrics and alerting, ML teams have discovered previously hidden issues within their models and addressed them faster than before, leading to higher-quality recommendations.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eKey takeaways\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eIn our journey to scale Instagram’s algorithm to manage over 1000 models, we have learned several critical lessons that have shaped our approach and infrastructure. These takeaways not only highlight the challenges we faced but also underscore the strategies that led to our success.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eInfra understanding is the foundation to building the right tools\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eA unified understanding of our infrastructure footprint was essential in developing the right tools to support our scaling efforts. By identifying the gaps and potential risks in our existing systems, we were able to implement solutions such as the model registry that significantly improved our operational efficiency and reliability posture.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eHelping colleagues move fast means we all move faster\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eBy addressing the model iteration bottleneck, we enabled our teams to innovate more rapidly. Our focus on creating a seamless, self-service process for model iteration empowered client teams to take ownership of their workflows. This not only accelerated their progress but also reduced the operational burden on our infrastructure team. As a result, the entire organization benefited from increased agility and productivity.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eReliability must consider quality\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eEnsuring the reliability of our models required us to redefine how we measure and maintain model quality. By operationalizing model stability and establishing clear metrics for model health, we were able to proactively manage the performance of our models. This approach enables us to maintain high standards of quality across our recommendation systems, ultimately enhancing user engagement and satisfaction.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eOur experience in scaling Instagram’s recommendation system has reinforced the importance of infrastructure understanding, collaboration, and a focus on quality. By building robust tools and processes, we have not only improved our own operations but also empowered our colleagues to drive innovation and growth across the platform.\u003c/span\u003e\u003c/p\u003e\n\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "24 min read",
  "publishedTime": "2025-05-21T16:00:38Z",
  "modifiedTime": "2025-05-21T16:08:25Z"
}
