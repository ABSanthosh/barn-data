{
  "id": "33512aad-90ce-4e33-8f25-be2c915f4541",
  "title": "Build and train a recommender system in 10 minutes using Keras and JAX",
  "link": "https://developers.googleblog.com/en/build-train-recommender-system-keras-jax/",
  "description": "Keras Recommenders (KerasRS) is a new library announced to help developers build recommendation systems using APIs with building blocks for ranking and retrieval, and it can be installed via pip with support for JAX, TensorFlow, or PyTorch backends.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Yufeng Guo, Monica Song",
  "length": 4405,
  "excerpt": "Keras Recommenders (KerasRS) is a new library announced to help developers build recommendation systems using APIs with building blocks for ranking and retrieval, and it can be installed via pip with support for JAX, TensorFlow, or PyTorch backends.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Today, we are excited to announce the launch of Keras Recommenders, a new library that puts state-of-the-art recommendation techniques at your fingertips.Power digital experiences with recommendation systemsRecommendation systems power many of the interactions you have with technology today. Open up any app on your phone and you’ll likely find yourself interacting with a recommendation model right away, from the homefeed on your go-to social media platform to video suggestions on YouTube to even the ads that pop up in your favorite game. As the world of AI continues to evolve, delivering personalized experiences is more important than ever. Large language models can't do everything, and recommender systems are responsible for creating many top-tier digital experiences today.To help developers create performant and accurate recommender systems, Keras Recommenders (KerasRS) contains a set of APIs with building blocks designed for tasks such as ranking and retrieval. For example, at Google, we use KerasRS to help power the feed in Google Play.Install KerasRS with JAX, TensorFlow, or PyTorchTo get started, pip install the keras-rs package. Then set the backend to JAX (or TensorFlow or PyTorch). Now you are on your way to crafting your own state-of-the-art recommender system. import os os.environ[\"KERAS_BACKEND\"] = \"jax\" import keras import keras_rs class SequentialRetrievalModel(keras.Model): def __init__(self): self.query_model = keras.Sequential([ keras.layers.Embedding(query_count, embed_dim), keras.layers.GRU(embed_dim), ]) self.candidate_model = keras.layers.Embedding(candidate_count, embed_dim) self.retrieval = keras_rs.layers.BruteForceRetrieval(k=10) self.loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True) def call(self, inputs): query_embeddings = self.query_model(inputs) predictions = self.retrieval(query_embeddings) return {\"query_embeddings\": query_embeddings, \"predictions\": predictions} Copied In this example, we show a popular retrieval architecture in which we identify a set of candidate recommendations. KerasRS provides everything you need to implement this architecture, with specialized layers, losses, and metrics designed specifically for recommender tasks. You can also follow along in this colab notebook.And of course, all these building blocks work with the standard Keras APIs of model.compile to build your model and model.fit to easily configure your training loop. model.compile( loss=keras_rs.losses.PairwiseHingeLoss(), metrics=[keras_rs.metrics.NDCG(k=8, name=\"ndcg\")], optimizer=keras.optimizers.Adagrad(learning_rate=3e-4), ) model.fit(train_ds, validation_data=val_ds, epochs=5) Copied In the coming months, we plan to release the keras_rs.layers.DistributedEmbedding class for leveraging SparseCore chips on TPU for doing large embedding lookups distributed across machines. Additionally, we will add popular model implementations to our library continuously, making it even easier to build state-of-the-art recommender systems.Explore the KerasRS documentation and examplesWe also want to highlight all the documentation we have for Keras Recommenders on our recently redesigned keras.io website. On keras.io/keras_rs, you can find starter examples involving the classic Deep and Cross Network (DCN) and two-tower embedding model that show the step-by-step processes for writing and training your first recommender. There are also more advanced tutorials, such as SASRec, showing an end-to-end example of training a transformer model. Sorry, your browser doesn't support playback for this video Get startedVisit our website today for more examples, documentation, and guides to build your very own recommendation system. You can also browse the code and contribute at https://github.com/keras-team/keras-rs (feel free to give it a star ⭐ too while you’re there!).We look forward to seeing all the excellent recommendation systems that get built with Keras Recommenders.AcknowledgementsShout-out to Fabien Hertschuh and Abheesht Sharma for building Keras Recommenders. We also want to thank the Keras and ML Frameworks teams as well as all our collaborators and leadership for helping us pull this off.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/KerasRecommendersBlog-Evergreen-M.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"clhnt\"\u003eToday, we are excited to announce the launch of \u003ca href=\"https://keras.io/keras_rs/\"\u003eKeras Recommenders\u003c/a\u003e, a new library that puts state-of-the-art recommendation techniques at your fingertips.\u003c/p\u003e\u003ch2 data-block-key=\"6m4xa\" id=\"power-digital-experiences-with-recommendation-systems\"\u003e\u003cbr/\u003ePower digital experiences with recommendation systems\u003c/h2\u003e\u003cp data-block-key=\"65d6c\"\u003eRecommendation systems power many of the interactions you have with technology today. Open up any app on your phone and you’ll likely find yourself interacting with a recommendation model right away, from the homefeed on your go-to social media platform to video suggestions on YouTube to even the ads that pop up in your favorite game. As the world of AI continues to evolve, delivering personalized experiences is more important than ever. Large language models can\u0026#39;t do everything, and recommender systems are responsible for creating many top-tier digital experiences today.\u003c/p\u003e\u003cp data-block-key=\"3l09p\"\u003eTo help developers create performant and accurate recommender systems, \u003ca href=\"https://keras.io/keras_rs/\"\u003eKeras Recommenders (KerasRS)\u003c/a\u003e contains a set of \u003ca href=\"https://keras.io/keras_rs/api/\"\u003eAPIs\u003c/a\u003e with building blocks designed for tasks such as ranking and retrieval. For example, at Google, we use KerasRS to help power the feed in Google Play.\u003c/p\u003e\u003ch2 data-block-key=\"xltdv\" id=\"install-kerasrs-with-jax-tensorflow-or-pytorch\"\u003e\u003cbr/\u003eInstall KerasRS with JAX, TensorFlow, or PyTorch\u003c/h2\u003e\u003cp data-block-key=\"35m36\"\u003eTo get started, pip install the \u003ca href=\"https://pypi.org/project/keras-rs/\"\u003ekeras-rs package\u003c/a\u003e. Then set the backend to JAX (or TensorFlow or PyTorch). Now you are on your way to crafting your own state-of-the-art recommender system.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cdiv\u003e\u003cpre\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003eos\u003c/span\u003e\n\u003cspan\u003eos\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eenviron\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e\u0026#34;KERAS_BACKEND\u0026#34;\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003e\u0026#34;jax\u0026#34;\u003c/span\u003e\n\n\u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003ekeras\u003c/span\u003e\n\u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003ekeras_rs\u003c/span\u003e\n\n\u003cspan\u003eclass\u003c/span\u003e \u003cspan\u003eSequentialRetrievalModel\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eModel\u003c/span\u003e\u003cspan\u003e):\u003c/span\u003e\n    \u003cspan\u003edef\u003c/span\u003e \u003cspan\u003e__init__\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e):\u003c/span\u003e\n        \u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003equery_model\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eSequential\u003c/span\u003e\u003cspan\u003e([\u003c/span\u003e\n            \u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003elayers\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eEmbedding\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003equery_count\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003eembed_dim\u003c/span\u003e\u003cspan\u003e),\u003c/span\u003e\n            \u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003elayers\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eGRU\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eembed_dim\u003c/span\u003e\u003cspan\u003e),\u003c/span\u003e\n        \u003cspan\u003e])\u003c/span\u003e\n        \u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ecandidate_model\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003elayers\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eEmbedding\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ecandidate_count\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003eembed_dim\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n        \u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eretrieval\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003ekeras_rs\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003elayers\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eBruteForceRetrieval\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ek\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e10\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n        \u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eloss_fn\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003elosses\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eCategoricalCrossentropy\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003efrom_logits\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003eTrue\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\n    \u003cspan\u003edef\u003c/span\u003e \u003cspan\u003ecall\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003einputs\u003c/span\u003e\u003cspan\u003e):\u003c/span\u003e\n        \u003cspan\u003equery_embeddings\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003equery_model\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003einputs\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n        \u003cspan\u003epredictions\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003eself\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eretrieval\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003equery_embeddings\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n        \u003cspan\u003ereturn\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\u003cspan\u003e\u0026#34;query_embeddings\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003equery_embeddings\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003e\u0026#34;predictions\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003epredictions\u003c/span\u003e\u003cspan\u003e}\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"clhnt\"\u003eIn this example, we show a popular retrieval architecture in which we identify a set of candidate recommendations. KerasRS provides everything you need to implement this architecture, with specialized layers, losses, and metrics designed specifically for recommender tasks. You can also follow along in\u003ca href=\"https://colab.sandbox.google.com/github/keras-team/keras-io/blob/master/examples/keras_rs/ipynb/sequential_retrieval.ipynb\"\u003e this colab notebook.\u003c/a\u003e\u003c/p\u003e\u003cp data-block-key=\"d8dm7\"\u003eAnd of course, all these building blocks work with the standard Keras APIs of \u003ccode\u003emodel.compile\u003c/code\u003e to build your model and \u003ccode\u003emodel.fit\u003c/code\u003e to easily configure your training loop.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cdiv\u003e\u003cpre\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003emodel\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ecompile\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\n    \u003cspan\u003eloss\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003ekeras_rs\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003elosses\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ePairwiseHingeLoss\u003c/span\u003e\u003cspan\u003e(),\u003c/span\u003e\n    \u003cspan\u003emetrics\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003ekeras_rs\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003emetrics\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eNDCG\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ek\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e8\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003ename\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;ndcg\u0026#34;\u003c/span\u003e\u003cspan\u003e)],\u003c/span\u003e\n    \u003cspan\u003eoptimizer\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003ekeras\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eoptimizers\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eAdagrad\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003elearning_rate\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e3e-4\u003c/span\u003e\u003cspan\u003e),\u003c/span\u003e\n\u003cspan\u003e)\u003c/span\u003e\n\u003cspan\u003emodel\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efit\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003etrain_ds\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003evalidation_data\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003eval_ds\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003eepochs\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e5\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"clhnt\"\u003eIn the coming months, we plan to release the \u003ccode\u003ekeras_rs.layers.DistributedEmbedding\u003c/code\u003e class for leveraging SparseCore chips on TPU for doing large embedding lookups distributed across machines. Additionally, we will add popular model implementations to our library continuously, making it even easier to build state-of-the-art recommender systems.\u003c/p\u003e\u003ch2 data-block-key=\"ons2l\" id=\"explore-the-kerasrs-documentation-and-examples\"\u003e\u003cbr/\u003eExplore the KerasRS documentation and examples\u003c/h2\u003e\u003cp data-block-key=\"b20g9\"\u003eWe also want to highlight all the documentation we have for Keras Recommenders on our recently redesigned \u003ca href=\"http://keras.io/\"\u003ekeras.io\u003c/a\u003e website. On \u003ca href=\"http://keras.io/keras_rs\"\u003ekeras.io/keras_rs\u003c/a\u003e, you can find starter examples involving the classic \u003ca href=\"https://keras.io/keras_rs/examples/dcn/\"\u003eDeep and Cross Network (DCN)\u003c/a\u003e and \u003ca href=\"https://keras.io/keras_rs/examples/basic_retrieval/\"\u003etwo-tower embedding model\u003c/a\u003e that show the step-by-step processes for writing and training your first recommender. There are also more advanced tutorials, such as \u003ca href=\"https://keras.io/keras_rs/examples/sas_rec/\"\u003eSASRec\u003c/a\u003e, showing an end-to-end example of training a transformer model.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-taquqkgi_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/kerasRS.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"x7zbz\" id=\"get-started\"\u003eGet started\u003c/h2\u003e\u003cp data-block-key=\"ah0tr\"\u003eVisit \u003ca href=\"http://keras.io/keras-rs\"\u003eour website\u003c/a\u003e today for more examples, documentation, and guides to build your very own recommendation system. You can also browse the code and contribute at \u003ca href=\"https://github.com/keras-team/keras-rs\"\u003ehttps://github.com/keras-team/keras-rs\u003c/a\u003e (feel free to give it a star ⭐ too while you’re there!).\u003c/p\u003e\u003cp data-block-key=\"6ib17\"\u003eWe look forward to seeing all the excellent recommendation systems that get built with \u003ca href=\"https://pypi.org/project/keras-rs/\"\u003eKeras Recommenders\u003c/a\u003e.\u003c/p\u003e\u003chr/\u003e\u003ch3 data-block-key=\"tsbuy\" id=\"\"\u003e\u003cbr/\u003e\u003cb\u003eAcknowledgements\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"345a9\"\u003e\u003csup\u003eShout-out to Fabien Hertschuh and Abheesht Sharma for building Keras Recommenders. We also want to thank the Keras and ML Frameworks teams as well as all our collaborators and leadership for helping us pull this off.\u003c/sup\u003e\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-05-13T00:00:00Z",
  "modifiedTime": null
}
