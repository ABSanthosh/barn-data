{
  "id": "821681a5-e990-4805-b61e-7bf9f1fcb6f4",
  "title": "Use GitLab Duo to build and deploy a simple Quarkus-native project",
  "link": "https://about.gitlab.com/blog/2024/10/17/use-gitlab-duo-to-build-and-deploy-a-simple-quarkus-native-project",
  "description": "",
  "author": "Cesar Saavedra",
  "published": "2024-10-17T00:00:00.000Z",
  "source": "https://about.gitlab.com/atom.xml",
  "categories": null,
  "byline": "Cesar Saavedra",
  "length": 25882,
  "excerpt": "This tutorial shows how a Java application is compiled to machine code and deployed to a Kubernetes cluster using a CI/CD pipeline. See how AI makes the process faster and more efficient.",
  "siteName": "GitLab",
  "favicon": "https://about.gitlab.com/blog/nuxt-images/ico/favicon-192x192.png?cache=2022041",
  "text": "In “How to automate software delivery using Quarkus and GitLab,” you learned how to develop and deploy a simple Quarkus-JVM application to a Kubernetes cluster using GitLab Auto DevOps. Now, you'll learn how to use Quarkus-native to compile a Java application to machine code and deploy it to a Kubernetes cluster using a CI/CD pipeline. Follow our journey from development to deployment leveraging GitLab Duo as our AI companion, including the specific prompts we used. What is Quarkus? Quarkus, also known as the Supersonic Subatomic Java, is an open source, Kubernetes-native Java stack tailored to OpenJDK HotSpot and GraalVM. The Quarkus project recently moved to the Commonhaus Foundation, a nonprofit organization dedicated to the sustainability of open source libraries and frameworks that provides a balanced approach to governance and support. Prerequisites This tutorial assumes: You have a running Kubernetes cluster, e.g. GKE. You have access to the Kubernetes cluster from your local laptop via the kubectl command. The cluster is connected to your GitLab project. You have Maven (Version 3.9.6 or later) installed on your local laptop. You have Visual Studio Code installed on your local laptop. If you’d like to set up a Kubernetes cluster connected to your GitLab project, you can follow the instructions in this tutorial, up to but not including the “Creating an instance of MySQL database in your cluster via Flux” section (you do not need a database for this tutorial). You will also need to install an nginx ingress in your Kubernetes cluster. Here are two ways to do this: You can follow the instructions in “Creating and importing projects”, up to the creation of the variable KUBE_INGRESS_BASE_DOMAIN. Or, just create an ingress in your Kubernetes cluster by following the instructions in our Auto DevOps with GKE documentation. NOTE: For this article, we used the first method above to install an ingress and cert-manager in the Kubernetes cluster. Creating necessary project files using GitLab Duo Chat We started our endeavor from VS Code and an empty project called quarkus-native, which we had previously created in GitLab and had already cloned to our local laptop. We opened GitLab Duo Chat, within VS Code, and entered the following prompt: Create a “Hello World” Quarkus application that can be natively compiled Chat replied with the prerequisites and process of what to do to create a simple “Hello World” Quarkus application. At this point, we were after the generated body of the class HelloResource.java: package org.acme; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; @Path(\"/hello\") public class HelloResource { @GET @Produces(MediaType.TEXT_PLAIN) public String hello() { return \"Hello World\"; } } We knew that for Quarkus we needed a special Dockerfile, named Dockerfile.native, as part of the creation of the image for the application executable. We then entered the following prompt in Chat: Create the Dockerfile.native file for the sample application above Chat replied with a very thorough answer about this file, its contents, and the containerization process. At this point, we were just after the generated body of the file Dockerfile.native: #### # This Dockerfile is used in order to build a container that runs the Quarkus application in native (no JVM) mode #### FROM registry.access.redhat.com/ubi8/ubi-minimal:8.6 WORKDIR /work/ RUN chown 1001 /work \\ \u0026\u0026 chmod \"g+rwX\" /work \\ \u0026\u0026 chown 1001:root /work COPY --chown=1001:root target/*-runner /work/application EXPOSE 8080 USER 1001 CMD [\"./application\", \"-Dquarkus.http.host=0.0.0.0\"] Next, we asked Chat to generate the pom.xml for this application by entering the following prompt: Create the pom.xml file for the sample application above Chat provided the content of the pom.xml file, an explanation of its contents, and how to use it. At this point, we were after the generated body of the file pom.xml: \u003c?xml version=\"1.0\"?\u003e \u003cproject xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003eorg.acme\u003c/groupId\u003e \u003cartifactId\u003ehello-world-quarkus\u003c/artifactId\u003e \u003cversion\u003e1.0.0-SNAPSHOT\u003c/version\u003e \u003cproperties\u003e \u003ccompiler-plugin.version\u003e3.10.1\u003c/compiler-plugin.version\u003e \u003cmaven.compiler.release\u003e11\u003c/maven.compiler.release\u003e \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e \u003cproject.reporting.outputEncoding\u003eUTF-8\u003c/project.reporting.outputEncoding\u003e \u003cquarkus.platform.artifact-id\u003equarkus-bom\u003c/quarkus.platform.artifact-id\u003e \u003cquarkus.platform.group-id\u003eio.quarkus.platform\u003c/quarkus.platform.group-id\u003e \u003cquarkus.platform.version\u003e2.16.5.Final\u003c/quarkus.platform.version\u003e \u003cskipITs\u003etrue\u003c/skipITs\u003e \u003csurefire-plugin.version\u003e3.0.0-M7\u003c/surefire-plugin.version\u003e \u003c/properties\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003e${quarkus.platform.group-id}\u003c/groupId\u003e \u003cartifactId\u003e${quarkus.platform.artifact-id}\u003c/artifactId\u003e \u003cversion\u003e${quarkus.platform.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eio.quarkus\u003c/groupId\u003e \u003cartifactId\u003equarkus-arc\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eio.quarkus\u003c/groupId\u003e \u003cartifactId\u003equarkus-resteasy\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eio.quarkus\u003c/groupId\u003e \u003cartifactId\u003equarkus-junit5\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eio.rest-assured\u003c/groupId\u003e \u003cartifactId\u003erest-assured\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003e${quarkus.platform.group-id}\u003c/groupId\u003e \u003cartifactId\u003equarkus-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e${quarkus.platform.version}\u003c/version\u003e \u003cextensions\u003etrue\u003c/extensions\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cgoals\u003e \u003cgoal\u003ebuild\u003c/goal\u003e \u003cgoal\u003egenerate-code\u003c/goal\u003e \u003cgoal\u003egenerate-code-tests\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cversion\u003e${compiler-plugin.version}\u003c/version\u003e \u003cconfiguration\u003e \u003ccompilerArgs\u003e \u003carg\u003e-parameters\u003c/arg\u003e \u003c/compilerArgs\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cartifactId\u003emaven-surefire-plugin\u003c/artifactId\u003e \u003cversion\u003e${surefire-plugin.version}\u003c/version\u003e \u003cconfiguration\u003e \u003csystemPropertyVariables\u003e \u003cjava.util.logging.manager\u003eorg.jboss.logmanager.LogManager\u003c/java.util.logging.manager\u003e \u003cmaven.home\u003e${maven.home}\u003c/maven.home\u003e \u003c/systemPropertyVariables\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003cplugin\u003e \u003cartifactId\u003emaven-failsafe-plugin\u003c/artifactId\u003e \u003cversion\u003e${surefire-plugin.version}\u003c/version\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cgoals\u003e \u003cgoal\u003eintegration-test\u003c/goal\u003e \u003cgoal\u003everify\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003csystemPropertyVariables\u003e \u003cnative.image.path\u003e${project.build.directory}/${project.build.finalName}-runner\u003c/native.image.path\u003e \u003cjava.util.logging.manager\u003eorg.jboss.logmanager.LogManager\u003c/java.util.logging.manager\u003e \u003cmaven.home\u003e${maven.home}\u003c/maven.home\u003e \u003c/systemPropertyVariables\u003e \u003c/configuration\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003cprofiles\u003e \u003cprofile\u003e \u003cid\u003enative\u003c/id\u003e \u003cactivation\u003e \u003cproperty\u003e \u003cname\u003enative\u003c/name\u003e \u003c/property\u003e \u003c/activation\u003e \u003cproperties\u003e \u003cskipITs\u003efalse\u003c/skipITs\u003e \u003cquarkus.package.type\u003enative\u003c/quarkus.package.type\u003e \u003c/properties\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003c/project\u003e We then asked Chat to generate the Quarkus test file for this application by entering the following prompt: Create the content for the Quarkus test for the application above Chat returned the body for the Quarkus test, how to use it, and the body of the Java class for the test needed for its native compilation. At this point, we were after the generated bodies of the file HelloResourceTest.java and HelloResourceIT.java. Here is the generated body for HelloResourceTest.java: package org.acme; import io.quarkus.test.junit.QuarkusTest; import org.junit.jupiter.api.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.CoreMatchers.is; @QuarkusTest public class HelloResourceTest { @Test public void testHelloEndpoint() { given() .when().get(\"/hello\") .then() .statusCode(200) .body(is(\"Hello World\")); } } Here is the generated body for HelloResourceIT.java: package org.acme; import io.quarkus.test.junit.QuarkusIntegrationTest; @QuarkusIntegrationTest public class HelloResourceIT extends HelloResourceTest { // Execute the same tests but in native mode. } We needed to know how to organize these files in the GitLab project, so we asked about the directory structure for all these files by entering the following prompt in Chat: Give me the entire directory structure for this project including the location of each file, e.g. pom.xml, Dockerfile.native, application.properties, HelloResource.java, HelloResourceTest.java, and the location of the target directory Chat replied with a detailed diagram about the entire directory structure for the project and where all these files should be located as well as a description of the purpose of each of them. It even mentioned that the directory target/ and its contents should not be version controlled since it was generated by the build process. Another interesting aspect of the reply was the existence of a file called resources/application.properties in the directory structure. With all this information in our hands, we were ready to start creating these files in our GitLab project. Populating our project with the generated content for each file We created each of the following files in their corresponding location and their generated content as provided by Chat: src/main/java/org/acme/HelloResource.java resources/application.properties src/test/java/org/acme/HelloResourceTest.java src/test/java/org/acme/HelloResourceIT.java pom.xml Dockerfile.native NOTE: We considered using GitLab Auto Deploy for this endeavor but later realized that it would not be a supported option. We are mentioning this because in the video at the end of this tutorial, you will see that we asked Chat: How to set the service internalPort to 8080 for auto deploy. Then we created a file named .gitlab/auto-deploy-values.yaml with the generated content from Chat. The creation of this file is not necessary for this tutorial. Before we started tackling the pipeline to build, containerize, and deploy the application to our Kubernetes cluster, we decided to generate the executable locally on our Mac and test the application locally. Testing the application locally Here is the process we went through to test the application on our local machine. To build the application on the local Mac laptop, from a Terminal window, we entered the following command: mvn clean package -Pnative The native compilation failed with the error message: Cannot find the ‘native-image’ in the GRAALVM_HOME, JAVA_HOME and System PATH. Install it using ‘gu install native-image’ So, we used our trusty GitLab Duo Chat again and asked it the following: The command “mvn clean package -Pnative” is failing with error “java.lang.RuntimeException: Cannot find the ‘native-image’ in the GRAALVM_HOME, JAVA_HOME and System PATH. Install it using gu install native-image”. I’m using a MacOS Sonoma. How do I fix this error on my Mac? Chat replied with a detailed set of steps on how to install the necessary software and set the appropriate environment variables. We copied and pasted the following commands from the Chat window to a Terminal window: brew install –cask graalvm/tap/graalvm-ce-java17 export JAVA_HOME=/Library/Java/JavaVIrtualMachines/graalvm-ce-java17-22.3.1 export GRAALVM_HOME=${JAVA_HOME} export PATH=${GRAALVM_HOME}/bin:$PATH xattr -r -d com.apple.quarantine ${GRAALVM_HOME}/../.. gu install native-image The commands above installed the community edition of GraalVM Version 22.3.1 that supported Java 17. We noticed, during the brew install, that the version of the GraalVM being installed was java17-22.3.1, so we had to update the pasted value for JAVA_HOME from graalvm-ce-java17-22.3.0 to graalvm-ce-java17-22.3.1. We also had to run the xattr command to get the GraalVM, which we had downloaded and installed on our Mac, out of quarantine so that it could run locally. Lastly, we installed the GraalVM native-image. At this point, we again, from a Terminal window, entered the following command to build the application on the local Mac laptop: mvn clean package -Pnative This time the compilation was successful and an executable was generated in the target directory. We ran the executable by entering the following commands from a Terminal window: cd target ./quarkus-native-1.0.0-SNAPSHOT-runner “-Dquarkus.http.host=0.0.0.0” With the application running, we opened a browser window, and in the URL field, we entered: http://localhost:8080/hello The application returned the string Hello World, which was displayed in the browser window. At this point, we committed and pushed all the changes to our GitLab project and started working on creating a CI/CD pipeline that would build and deploy the application to a Kubernetes cluster running on the cloud. But before continuing, we remembered to add, commit, and push a .gitignore file to our project that included the path target/, since this was the directory where the executable would be created and we didn’t need to keep it - or its contents - under version control. Creating the pipeline with GitLab Duo Chat Now that we had already successfully tested the application locally on our Mac, we needed to create the CI/CD pipeline that would compile the application, containerize it, and deploy it to our Kubernetes cluster. We wanted to keep the pipeline simple, brief, and have a single environment in which to deploy it. To this end, the pipeline would not tackle multiple environments or feature branches, for example. To avoid manually creating a pipeline from scratch, we decided to once again leverage Chat. We entered the following prompt Create a .gitlab-ci.yml file with 3 stages: build, containerize, and deploy. Each of these stages should have a single job with the same name. The build job should compile the application natively using the -Pnative maven option and the builder image for mandrel jdk-22 for java17 and store the application executable and its Dockerfile as artifacts. The containerize job should use docker to build and push the image to the built-in container registry. The deploy job should rollout the containerized application, named quarkus-app, to the production environment in the Kubernetes cluster by creating a deployment resource, a service resource and an ingress rule with host ${KUBE_INGRESS_BASE_DOMAIN} and /hello prefix. The deploy job should also include the url for the production environment. When setting the Kubernetes context, use ${KUBE_CONTEXT}, and for application namespace, use ${KUBE_NAMESPACE} The prompt above provided some points that we thought would be useful and necessary for a good outcome. The requirements listed by the prompt were: It specified that the pipeline needed to have three stages: build, containerize, and deploy. Each stage would have a single job. The build job should natively compile (not build) the application using the -Pnative option. The build job should use the open source software mandrel and use the version that would support jdk-22 for Java 17. Remember that these were the versions that we tested on our local machine. The build job would also need to pass the resulting executable and the project Dockerfile to the next job, i.e. containerize, in the pipeline. The containerize job should build a docker image with the executable using the Dockerfile, both of which were passed as artifacts. The containerize job should push the image to the GitLab container registry. The deploy job should use the image from the GitLab container registry, name it quarkus-app, and deploy it to the Kubernetes cluster using deployment, service and ingress rule resources. The deploy job should use the environment variables ${KUBE_INGRESS_BASE_DOMAIN}, ${KUBE_CONTEXT}, and ${KUBE_NAMESPACE}, which had been defined as group/project variables, accordingly. Chat responded with the following .gitlab-ci.yml example: # Define the stages for the pipeline stages: - build - containerize - deploy # Variables section to use GitLab CI/CD variables variables: MAVEN_OPTS: \"-Dmaven.repo.local=.m2/repository\" MAVEN_CLI_OPTS: \"--batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true\" CONTAINER_IMAGE: ${CI_REGISTRY_IMAGE}:${CI_COMMIT_SHA} # Cache configuration for Maven dependencies cache: paths: - .m2/repository # Build stage: Compile the application natively build: stage: build image: name: quay.io/quarkus/ubi-quarkus-mandrel-builder-image:22.3-java17 entrypoint: - \"\" script: - ./mvnw ${MAVEN_CLI_OPTS} clean package -Pnative artifacts: paths: - target/*-runner - src/main/docker/Dockerfile.native-micro # This job runs only on the main branch only: - main # Containerize stage: Build and push Docker image containerize: stage: containerize image: docker:20.10.16 services: - docker:20.10.16-dind variables: DOCKER_TLS_CERTDIR: \"/certs\" before_script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY script: - docker build -f src/main/docker/Dockerfile.native-micro -t ${CONTAINER_IMAGE} . - docker push ${CONTAINER_IMAGE} # This job runs only on the main branch only: - main # Deploy stage: Deploy to Kubernetes deploy: stage: deploy image: name: bitnami/kubectl:latest entrypoint: [''] script: - kubectl config use-context ${KUBE_CONTEXT} - kubectl config set-context --current --namespace=${KUBE_NAMESPACE} - | cat \u003c\u003cEOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: quarkus-app spec: replicas: 1 selector: matchLabels: app: quarkus-app template: metadata: labels: app: quarkus-app spec: containers: - name: quarkus-app image: ${CONTAINER_IMAGE} ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: quarkus-app spec: selector: app: quarkus-app ports: - port: 80 targetPort: 8080 --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: quarkus-app spec: rules: - host: ${KUBE_INGRESS_BASE_DOMAIN} http: paths: - path: /hello pathType: Prefix backend: service: name: quarkus-app port: number: 80 EOF - echo \"Application deployed to https://${KUBE_INGRESS_BASE_DOMAIN}/hello\" # This job runs only on the main branch only: - main There were some things we needed to adjust in the sample .gitlab-ci.yml file above before we could commit it to our main branch. These are the updates we made to the file: We deleted all occurrences of only: -main because we wanted to keep of pipeline definition file simple and with no branch-related rules. We fixed the name of the file Dockerfile.native-micro to Dockerfile.native. At this point, we wanted to ensure that the deployment would be to the production environment so we asked Chat the following prompt: What is the syntax to specify an environment with its url in a pipeline? The response from Chat included an example of how to do this so we used this information to add the following environment block to our pipeline: environment: name: production url: http://${KUBE_INGRESS_BASE_DOMAIN}/hello The example provided by Chat includes a URL that started with https and we modified that to http since we didn’t really need a secure connection for this simple application. Lastly, we noticed that in the build job, there was a script mvnw that we didn’t have in our project. So, we asked Chat the following: How can I get the mvnw script for Quarkus? Chat responded with the command to execute to bootstrap and create this script. We executed this command from a Terminal window: mvn wrapper:wrapper We were now ready to commit all of our changes to the main branch and have the pipeline executed. However, on our first attempt, our first pipeline failed at the build job. Troubleshooting using GitLab Duo Root Cause Analysis Our first attempt at running our brand-new pipeline failed. So, we took advantage of GitLab Duo Root Cause Analysis, which looks at the job logs and provides a thorough natural language explanation (with examples) of the root cause of the problem and, most importantly, how to fix it. Root Cause Analysis recommended we look at the compatibility of the command that was trying to be executed with the image of mandrel used in the build job. We were not using any command with the image so we concluded that it must have been the predefined entrypoint for the image itself. We needed to override this so we asked Chat the following: How do I override the entrypoint of an image using gitlab keywords? Chat replied with some use case examples of overriding an image entry point. We used that information to update the build job image definition: build: stage: build image: quay.io/quarkus/ubi-quarkus-mandrel-builder-image:22.3-java17 entrypoint: - “” We committed our changes to the main branch, which launched a new instance of the pipeline. This time the build job executed successfully but the pipeline failed at the containerize job. Running a successful pipeline Before drilling down into the log of the failed containerize job, we decided to drill into the log of the successfully completed build job first. Everything looked good in the log of the build job with the exception of this warning message at the very end of it: WARNING: src/main/docker/Dockerfile.native: no matching files. Ensure that the artifact path is relative to the working directory … We took notice of this warning and then headed to the log of the failed containerize job. In it, we saw that the docker build command had failed due to a non-existent Dockerfile. We ran Root Cause Analysis on the job and among its suggested fixes was for us to verify that the project structure matched the path of the specified Dockerfile.native file. This information confirmed our suspicion of the misplaced Dockerfile.native file. Instead of being at the directory src/main/docker as specified in the pipeline, it was located at the root directory of the project. So, we went back to our project and updated every occurrence of the location of this file in our .gitlab-ci.yml file. We modified the two locations where this happened, one in the build job and one in the containerize job, as follows: src/main/docker/Dockerfile.native to Dockerfile.native We committed our updates to the main branch and this time our entire pipeline executed successfully! Our last step was to check the running application in the production environment in our Kubernetes cluster. Accessing the deployed application running in cluster Once the pipeline ran successfully to completion, we drilled in the log file for the deploy job. Remember, this job printed the URL of the application at the end of its execution. We scrolled down to the bottom of the log and clicked on the https application link, which opened a browser window warning us that the connection was not private (we disabled https for the environment URL but forgot it for this string). We proceeded past the browser warning and then the string \"Hello World\" was displaced in the browser window indicating that the application was up and running in the Kubernetes cluster. Finally, to double-check our production deployment URL, we headed to the project Operate \u003e Environments window, and clicked on the \"Open\" button for it, which immediately opened a browser window with the \"Hello World\" message. Try it We created, compiled, built, and deployed a simple Quarkus application to a Kubernetes cluster using GitLab Duo. This approach allowed us to be more efficient and productive in all the tasks that we performed and it helped us streamline our DevSecOps processes. We have shown only a small portion of how GitLab Duo's AI-powered capabilities can help you, namely Chat and Root Cause Analysis. There’s so much more you can leverage in GitLab Duo to help you create better software faster and more securely. Watch this whole use case in action: All the project assets we used are available here. Try GitLab Duo for free for 60 days and get started on exciting projects like this.",
  "image": "https://images.ctfassets.net/r9o86ar0p03f/3oqldo5Yt5wPonEJYZOLTM/69da748b67497f782070edd85333f151/AdobeStock_639935439.jpeg?fm=webp\u0026w=820\u0026h=500",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-v-b794d8fe=\"\" data-v-7488832a=\"\" data-v-74bd29c6=\"\"\u003e\u003cp\u003eIn \u003ca href=\"https://about.gitlab.com/blog/2022/06/09/how-to-automate-software-delivery-using-quarkus-and-gitlab/\"\u003e“How to automate software delivery using Quarkus and GitLab,”\u003c/a\u003e you learned how to develop and deploy a simple Quarkus-JVM application to a Kubernetes cluster using \u003ca href=\"https://docs.gitlab.com/ee/topics/autodevops/\"\u003eGitLab Auto DevOps\u003c/a\u003e. Now, you\u0026#39;ll learn how to use Quarkus-native to compile a Java application to machine code and deploy it to a Kubernetes cluster using a CI/CD pipeline. Follow our journey from development to deployment leveraging \u003ca href=\"https://about.gitlab.com/gitlab-duo/\"\u003eGitLab Duo\u003c/a\u003e as our AI companion, including the specific prompts we used.\u003c/p\u003e\n\u003ch2 id=\"what-is-quarkus%3F\" tabindex=\"-1\"\u003eWhat is Quarkus? \u003ca href=\"#what-is-quarkus%3F\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://quarkus.io/\"\u003eQuarkus\u003c/a\u003e, also known as the Supersonic Subatomic Java, is an open source, Kubernetes-native Java stack tailored to OpenJDK HotSpot and GraalVM. The Quarkus project recently moved to the \u003ca href=\"https://www.commonhaus.org/\"\u003eCommonhaus Foundation\u003c/a\u003e, a nonprofit organization dedicated to the sustainability of open source libraries and frameworks that provides a balanced approach to governance and support.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\" tabindex=\"-1\"\u003ePrerequisites \u003ca href=\"#prerequisites\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThis tutorial assumes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou have a running Kubernetes cluster, e.g. GKE.\u003c/li\u003e\n\u003cli\u003eYou have access to the Kubernetes cluster from your local laptop via the \u003ccode\u003ekubectl\u003c/code\u003e command.\u003c/li\u003e\n\u003cli\u003eThe cluster is connected to your GitLab project.\u003c/li\u003e\n\u003cli\u003eYou have \u003ca href=\"https://maven.apache.org/\"\u003eMaven (Version 3.9.6 or later)\u003c/a\u003e installed on your local laptop.\u003c/li\u003e\n\u003cli\u003eYou have Visual Studio Code installed on your local laptop.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you’d like to set up a Kubernetes cluster connected to your GitLab project, you can follow the instructions in this \u003ca href=\"https://about.gitlab.com/blog/2023/09/20/eliminate-risk-with-feature-flags-tutorial/\"\u003etutorial\u003c/a\u003e, up to but not including the “Creating an instance of MySQL database in your cluster via Flux” section (you do not need a database for this tutorial).\u003c/p\u003e\n\u003cp\u003eYou will also need to install an nginx ingress in your Kubernetes cluster. Here are two ways to do this:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eYou can follow the instructions in \u003ca href=\"https://about.gitlab.com/blog/2023/09/20/eliminate-risk-with-feature-flags-tutorial/#creating-and-importing-projects\"\u003e“Creating and importing projects”\u003c/a\u003e, up to the creation of the variable \u003ccode\u003eKUBE_INGRESS_BASE_DOMAIN\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eOr, just create an ingress in your Kubernetes cluster by following the instructions in our \u003ca href=\"https://docs.gitlab.com/ee/topics/autodevops/cloud_deployments/auto_devops_with_gke.html#install-ingress\"\u003eAuto DevOps with GKE documentation\u003c/a\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE:\u003c/strong\u003e For this article, we used the first method above to install an ingress and cert-manager in the Kubernetes cluster.\u003c/p\u003e\n\u003ch2 id=\"creating-necessary-project-files-using-gitlab-duo-chat\" tabindex=\"-1\"\u003eCreating necessary project files using GitLab Duo Chat \u003ca href=\"#creating-necessary-project-files-using-gitlab-duo-chat\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWe started our endeavor from VS Code and an empty project called \u003ccode\u003equarkus-native\u003c/code\u003e, which we had previously created in GitLab and had already cloned to our local laptop.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWe opened GitLab Duo Chat, within VS Code, and entered the following prompt:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate a “Hello World” Quarkus application that can be natively compiled\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/ZXoct8HRPMV3dxLZV52oa/a23ca21cf9bfead7510ce48943434647/hello-world-prompt.png\" alt=\"hello-world-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat replied with the prerequisites and process of what to do to create a simple “Hello World” Quarkus application. At this point, we were after the generated body of the class \u003ccode\u003eHelloResource.java\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epackage org.acme;\n\nimport javax.ws.rs.GET;\nimport javax.ws.rs.Path;\nimport javax.ws.rs.Produces;\nimport javax.ws.rs.core.MediaType;\n\n@Path(\u0026#34;/hello\u0026#34;)\npublic class HelloResource {\n\n    @GET\n    @Produces(MediaType.TEXT_PLAIN)\n    public String hello() {\n        return \u0026#34;Hello World\u0026#34;;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eWe knew that for Quarkus we needed a special Dockerfile, named \u003ccode\u003eDockerfile.native\u003c/code\u003e, as part of the creation of the image for the application executable. We then entered the following prompt in Chat:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate the Dockerfile.native file for the sample application above\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/1b1BwVS4hNMoG9dAFfui60/187b6c1aed364ffd169e39683fe68304/create-dockerfile-prompt.png\" alt=\"create-dockerfile-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat replied with a very thorough answer about this file, its contents, and the containerization process. At this point, we were just after the generated body of the file \u003ccode\u003eDockerfile.native\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e####\n# This Dockerfile is used in order to build a container that runs the Quarkus application in native (no JVM) mode\n####\nFROM registry.access.redhat.com/ubi8/ubi-minimal:8.6\nWORKDIR /work/\nRUN chown 1001 /work \\\n    \u0026amp;\u0026amp; chmod \u0026#34;g+rwX\u0026#34; /work \\\n    \u0026amp;\u0026amp; chown 1001:root /work\nCOPY --chown=1001:root target/*-runner /work/application\n\nEXPOSE 8080\nUSER 1001\n\nCMD [\u0026#34;./application\u0026#34;, \u0026#34;-Dquarkus.http.host=0.0.0.0\u0026#34;]\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eNext, we asked Chat to generate the \u003ccode\u003epom.xml\u003c/code\u003e for this application by entering the following prompt:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate the pom.xml file for the sample application above\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/0UCy4Tln8Q5tNHycPEae8/daa136fcea4d898c21020fe324a73b8e/create-pom-prompt.png\" alt=\"create-pom-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat provided the content of the \u003ccode\u003epom.xml\u003c/code\u003e file, an explanation of its contents, and how to use it. At this point, we were after the generated body of the file \u003ccode\u003epom.xml\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt;\n\u0026lt;project xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34;\n    xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;\n  \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\n  \u0026lt;groupId\u0026gt;org.acme\u0026lt;/groupId\u0026gt;\n  \u0026lt;artifactId\u0026gt;hello-world-quarkus\u0026lt;/artifactId\u0026gt;\n  \u0026lt;version\u0026gt;1.0.0-SNAPSHOT\u0026lt;/version\u0026gt;\n  \u0026lt;properties\u0026gt;\n    \u0026lt;compiler-plugin.version\u0026gt;3.10.1\u0026lt;/compiler-plugin.version\u0026gt;\n    \u0026lt;maven.compiler.release\u0026gt;11\u0026lt;/maven.compiler.release\u0026gt;\n    \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\n    \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt;\n    \u0026lt;quarkus.platform.artifact-id\u0026gt;quarkus-bom\u0026lt;/quarkus.platform.artifact-id\u0026gt;\n    \u0026lt;quarkus.platform.group-id\u0026gt;io.quarkus.platform\u0026lt;/quarkus.platform.group-id\u0026gt;\n    \u0026lt;quarkus.platform.version\u0026gt;2.16.5.Final\u0026lt;/quarkus.platform.version\u0026gt;\n    \u0026lt;skipITs\u0026gt;true\u0026lt;/skipITs\u0026gt;\n    \u0026lt;surefire-plugin.version\u0026gt;3.0.0-M7\u0026lt;/surefire-plugin.version\u0026gt;\n  \u0026lt;/properties\u0026gt;\n  \u0026lt;dependencyManagement\u0026gt;\n    \u0026lt;dependencies\u0026gt;\n      \u0026lt;dependency\u0026gt;\n        \u0026lt;groupId\u0026gt;${quarkus.platform.group-id}\u0026lt;/groupId\u0026gt;\n        \u0026lt;artifactId\u0026gt;${quarkus.platform.artifact-id}\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;${quarkus.platform.version}\u0026lt;/version\u0026gt;\n        \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt;\n        \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt;\n      \u0026lt;/dependency\u0026gt;\n    \u0026lt;/dependencies\u0026gt;\n  \u0026lt;/dependencyManagement\u0026gt;\n  \u0026lt;dependencies\u0026gt;\n    \u0026lt;dependency\u0026gt;\n      \u0026lt;groupId\u0026gt;io.quarkus\u0026lt;/groupId\u0026gt;\n      \u0026lt;artifactId\u0026gt;quarkus-arc\u0026lt;/artifactId\u0026gt;\n    \u0026lt;/dependency\u0026gt;\n    \u0026lt;dependency\u0026gt;\n      \u0026lt;groupId\u0026gt;io.quarkus\u0026lt;/groupId\u0026gt;\n      \u0026lt;artifactId\u0026gt;quarkus-resteasy\u0026lt;/artifactId\u0026gt;\n    \u0026lt;/dependency\u0026gt;\n    \u0026lt;dependency\u0026gt;\n      \u0026lt;groupId\u0026gt;io.quarkus\u0026lt;/groupId\u0026gt;\n      \u0026lt;artifactId\u0026gt;quarkus-junit5\u0026lt;/artifactId\u0026gt;\n      \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\n    \u0026lt;/dependency\u0026gt;\n    \u0026lt;dependency\u0026gt;\n      \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt;\n      \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt;\n      \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\n    \u0026lt;/dependency\u0026gt;\n  \u0026lt;/dependencies\u0026gt;\n  \u0026lt;build\u0026gt;\n    \u0026lt;plugins\u0026gt;\n      \u0026lt;plugin\u0026gt;\n        \u0026lt;groupId\u0026gt;${quarkus.platform.group-id}\u0026lt;/groupId\u0026gt;\n        \u0026lt;artifactId\u0026gt;quarkus-maven-plugin\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;${quarkus.platform.version}\u0026lt;/version\u0026gt;\n        \u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt;\n        \u0026lt;executions\u0026gt;\n          \u0026lt;execution\u0026gt;\n            \u0026lt;goals\u0026gt;\n              \u0026lt;goal\u0026gt;build\u0026lt;/goal\u0026gt;\n              \u0026lt;goal\u0026gt;generate-code\u0026lt;/goal\u0026gt;\n              \u0026lt;goal\u0026gt;generate-code-tests\u0026lt;/goal\u0026gt;\n            \u0026lt;/goals\u0026gt;\n          \u0026lt;/execution\u0026gt;\n        \u0026lt;/executions\u0026gt;\n      \u0026lt;/plugin\u0026gt;\n      \u0026lt;plugin\u0026gt;\n        \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;${compiler-plugin.version}\u0026lt;/version\u0026gt;\n        \u0026lt;configuration\u0026gt;\n          \u0026lt;compilerArgs\u0026gt;\n            \u0026lt;arg\u0026gt;-parameters\u0026lt;/arg\u0026gt;\n          \u0026lt;/compilerArgs\u0026gt;\n        \u0026lt;/configuration\u0026gt;\n      \u0026lt;/plugin\u0026gt;\n      \u0026lt;plugin\u0026gt;\n        \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;${surefire-plugin.version}\u0026lt;/version\u0026gt;\n        \u0026lt;configuration\u0026gt;\n          \u0026lt;systemPropertyVariables\u0026gt;\n            \u0026lt;java.util.logging.manager\u0026gt;org.jboss.logmanager.LogManager\u0026lt;/java.util.logging.manager\u0026gt;\n            \u0026lt;maven.home\u0026gt;${maven.home}\u0026lt;/maven.home\u0026gt;\n          \u0026lt;/systemPropertyVariables\u0026gt;\n        \u0026lt;/configuration\u0026gt;\n      \u0026lt;/plugin\u0026gt;\n      \u0026lt;plugin\u0026gt;\n        \u0026lt;artifactId\u0026gt;maven-failsafe-plugin\u0026lt;/artifactId\u0026gt;\n        \u0026lt;version\u0026gt;${surefire-plugin.version}\u0026lt;/version\u0026gt;\n        \u0026lt;executions\u0026gt;\n          \u0026lt;execution\u0026gt;\n            \u0026lt;goals\u0026gt;\n              \u0026lt;goal\u0026gt;integration-test\u0026lt;/goal\u0026gt;\n              \u0026lt;goal\u0026gt;verify\u0026lt;/goal\u0026gt;\n            \u0026lt;/goals\u0026gt;\n            \u0026lt;configuration\u0026gt;\n              \u0026lt;systemPropertyVariables\u0026gt;\n                \u0026lt;native.image.path\u0026gt;${project.build.directory}/${project.build.finalName}-runner\u0026lt;/native.image.path\u0026gt;\n                \u0026lt;java.util.logging.manager\u0026gt;org.jboss.logmanager.LogManager\u0026lt;/java.util.logging.manager\u0026gt;\n                \u0026lt;maven.home\u0026gt;${maven.home}\u0026lt;/maven.home\u0026gt;\n              \u0026lt;/systemPropertyVariables\u0026gt;\n            \u0026lt;/configuration\u0026gt;\n          \u0026lt;/execution\u0026gt;\n        \u0026lt;/executions\u0026gt;\n      \u0026lt;/plugin\u0026gt;\n    \u0026lt;/plugins\u0026gt;\n  \u0026lt;/build\u0026gt;\n  \u0026lt;profiles\u0026gt;\n    \u0026lt;profile\u0026gt;\n      \u0026lt;id\u0026gt;native\u0026lt;/id\u0026gt;\n      \u0026lt;activation\u0026gt;\n        \u0026lt;property\u0026gt;\n          \u0026lt;name\u0026gt;native\u0026lt;/name\u0026gt;\n        \u0026lt;/property\u0026gt;\n      \u0026lt;/activation\u0026gt;\n      \u0026lt;properties\u0026gt;\n        \u0026lt;skipITs\u0026gt;false\u0026lt;/skipITs\u0026gt;\n        \u0026lt;quarkus.package.type\u0026gt;native\u0026lt;/quarkus.package.type\u0026gt;\n      \u0026lt;/properties\u0026gt;\n    \u0026lt;/profile\u0026gt;\n  \u0026lt;/profiles\u0026gt;\n\u0026lt;/project\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eWe then asked Chat to generate the Quarkus test file for this application by entering the following prompt:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate the content for the Quarkus test for the application above\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/4gFxmFPg1ILKf40JqrAXZi/146d59de707b7696d05acf01d3b2d3a2/create-quarkus-test-prompt.png\" alt=\"create-quarkus-test-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat returned the body for the Quarkus test, how to use it, and the body of the Java class for the test needed for its native compilation. At this point, we were after the generated bodies of the file \u003ccode\u003eHelloResourceTest.java\u003c/code\u003e and \u003ccode\u003eHelloResourceIT.java\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eHere is the generated body for \u003ccode\u003eHelloResourceTest.java\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epackage org.acme;\n\nimport io.quarkus.test.junit.QuarkusTest;\nimport org.junit.jupiter.api.Test;\n\nimport static io.restassured.RestAssured.given;\nimport static org.hamcrest.CoreMatchers.is;\n\n@QuarkusTest\npublic class HelloResourceTest {\n\n    @Test\n    public void testHelloEndpoint() {\n        given()\n          .when().get(\u0026#34;/hello\u0026#34;)\n          .then()\n             .statusCode(200)\n             .body(is(\u0026#34;Hello World\u0026#34;));\n    }\n\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere is the generated body for \u003ccode\u003eHelloResourceIT.java\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epackage org.acme;\n\nimport io.quarkus.test.junit.QuarkusIntegrationTest;\n\n@QuarkusIntegrationTest\npublic class HelloResourceIT extends HelloResourceTest {\n    // Execute the same tests but in native mode.\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eWe needed to know how to organize these files in the GitLab project, so we asked about the directory structure for all these files by entering the following prompt in Chat:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eGive me the entire directory structure for this project including the location of each file, e.g. pom.xml, Dockerfile.native, application.properties, HelloResource.java, HelloResourceTest.java, and the location of the target directory\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/66cOpKjJUFQUHdkOuFFEbD/9509c81b0562ac722ee4439925481e76/create-dir-struct-prompt.png\" alt=\"create-dir-struct-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat replied with a detailed diagram about the entire directory structure for the project and where all these files should be located as well as a description of the purpose of each of them. It even mentioned that the directory \u003ccode\u003etarget/\u003c/code\u003e and its contents should not be version controlled since it was generated by the build process. Another interesting aspect of the reply was the existence of a file called \u003ccode\u003eresources/application.properties\u003c/code\u003e in the directory structure.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/1my72NOMEAZmYTUEzklHhl/ba3c5c7029153eb4917c87cfd4a0c69a/dir-struct-chat-response.png\" alt=\"dir-struct-chat-response\"/\u003e\u003c/p\u003e\n\u003cp\u003eWith all this information in our hands, we were ready to start creating these files in our GitLab project.\u003c/p\u003e\n\u003ch2 id=\"populating-our-project-with-the-generated-content-for-each-file\" tabindex=\"-1\"\u003ePopulating our project with the generated content for each file \u003ca href=\"#populating-our-project-with-the-generated-content-for-each-file\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWe created each of the following files in their corresponding location and their generated content as provided by Chat:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esrc/main/java/org/acme/HelloResource.java\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eresources/application.properties\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esrc/test/java/org/acme/HelloResourceTest.java\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esrc/test/java/org/acme/HelloResourceIT.java\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epom.xml\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDockerfile.native\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE:\u003c/strong\u003e We considered using GitLab Auto Deploy for this endeavor but later realized that it would not be a supported option. We are mentioning this because in the video at the end of this tutorial, you will see that we asked Chat: \u003ccode\u003eHow to set the service internalPort to 8080 for auto deploy\u003c/code\u003e. Then we created a file named \u003ccode\u003e.gitlab/auto-deploy-values.yaml\u003c/code\u003e with the generated content from Chat. The creation of this file is not necessary for this tutorial.\u003c/p\u003e\n\u003cp\u003eBefore we started tackling the pipeline to build, containerize, and deploy the application to our Kubernetes cluster, we decided to generate the executable locally on our Mac and test the application locally.\u003c/p\u003e\n\u003ch2 id=\"testing-the-application-locally\" tabindex=\"-1\"\u003eTesting the application locally \u003ca href=\"#testing-the-application-locally\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHere is the process we went through to test the application on our local machine.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eTo build the application on the local Mac laptop, from a Terminal window, we entered the following command:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003emvn clean package -Pnative\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/3cSsMPZoMusniHKOBqFj7H/6330474ed4645b449d7831982091d727/first-build.png\" alt=\"first-build\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe native compilation failed with the error message:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eCannot find the ‘native-image’ in the GRAALVM_HOME, JAVA_HOME and System PATH. Install it using ‘gu install native-image’\u003c/code\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eSo, we used our trusty GitLab Duo Chat again and asked it the following:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eThe command “mvn clean package -Pnative” is failing with error “java.lang.RuntimeException: Cannot find the ‘native-image’ in the GRAALVM_HOME, JAVA_HOME and System PATH. Install it using gu install native-image”. I’m using a MacOS Sonoma. How do I fix this error on my Mac?\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/7JobooCFJgmIrjpH0wvhm4/bbe1e9d0936acd796b3835c54ab71318/how-to-fix-build-failure-prompt.png\" alt=\"how-to-fix-build-failure-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat replied with a detailed set of steps on how to install the necessary software and set the appropriate environment variables.\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eWe copied and pasted the following commands from the Chat window to a Terminal window:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003ebrew install –cask graalvm/tap/graalvm-ce-java17\nexport JAVA_HOME=/Library/Java/JavaVIrtualMachines/graalvm-ce-java17-22.3.1\nexport GRAALVM_HOME=${JAVA_HOME}\nexport PATH=${GRAALVM_HOME}/bin:$PATH\nxattr -r -d com.apple.quarantine ${GRAALVM_HOME}/../..\ngu install native-image\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe commands above installed the community edition of GraalVM Version 22.3.1 that supported Java 17. We noticed, during the brew install, that the version of the GraalVM being installed was \u003ccode\u003ejava17-22.3.1\u003c/code\u003e, so we had to update the pasted value for \u003ccode\u003eJAVA_HOME\u003c/code\u003e from \u003ccode\u003egraalvm-ce-java17-22.3.0\u003c/code\u003e to \u003ccode\u003egraalvm-ce-java17-22.3.1\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eWe also had to run the \u003ccode\u003exattr\u003c/code\u003e command to get the GraalVM, which we had downloaded and installed on our Mac, out of quarantine so that it could run locally. Lastly, we installed the GraalVM native-image.\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eAt this point, we again, from a Terminal window, entered the following command to build the application on the local Mac laptop:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003emvn clean package -Pnative\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis time the compilation was successful and an executable was generated in the \u003ccode\u003etarget\u003c/code\u003e directory.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/IcZm7UoWkuNum1jH8lslO/b53d79525300dd679148c316d852a0e4/successful-local-compilation.png\" alt=\"successful-local-compilation\"/\u003e\u003c/p\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eWe ran the executable by entering the following commands from a Terminal window:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003ecd target\n./quarkus-native-1.0.0-SNAPSHOT-runner “-Dquarkus.http.host=0.0.0.0”\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/44seuJjJyVVVf9nyk8nyJX/3d373c65cb49169b2a6d31687355be29/executable-local-run.png\" alt=\"executable-local-run\"/\u003e\u003c/p\u003e\n\u003col start=\"6\"\u003e\n\u003cli\u003eWith the application running, we opened a browser window, and in the URL field, we entered:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003ehttp://localhost:8080/hello\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/1HniotBXPTvbo5BFcUsMCF/8a90ce6265b24e46cee48f7b3342225f/app-running-locally.png\" alt=\"app-running-locally\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe application returned the string \u003ccode\u003eHello World\u003c/code\u003e, which was displayed in the browser window.\u003c/p\u003e\n\u003cp\u003eAt this point, we committed and pushed all the changes to our GitLab project and started working on creating a CI/CD pipeline that would build and deploy the application to a Kubernetes cluster running on the cloud.\u003c/p\u003e\n\u003cp\u003eBut before continuing, we remembered to add, commit, and push a \u003ccode\u003e.gitignore\u003c/code\u003e file to our project that included the path \u003ccode\u003etarget/\u003c/code\u003e, since this was the directory where the executable would be created and we didn’t need to keep it - or its contents - under version control.\u003c/p\u003e\n\u003ch2 id=\"creating-the-pipeline-with-gitlab-duo-chat\" tabindex=\"-1\"\u003eCreating the pipeline with GitLab Duo Chat \u003ca href=\"#creating-the-pipeline-with-gitlab-duo-chat\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eNow that we had already successfully tested the application locally on our Mac, we needed to create the CI/CD pipeline that would compile the application, containerize it, and deploy it to our Kubernetes cluster. We wanted to keep the pipeline simple, brief, and have a single environment in which to deploy it. To this end, the pipeline would not tackle multiple environments or feature branches, for example.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eTo avoid manually creating a pipeline from scratch, we decided to once again leverage Chat. We entered the following prompt\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCreate a .gitlab-ci.yml file with 3 stages: build, containerize, and deploy. Each of these stages should have a single job with the same name. The build job should compile the application natively using the -Pnative maven option and the builder image for mandrel jdk-22 for java17 and store the application executable and its Dockerfile as artifacts. The containerize job should use docker to build and push the image to the built-in container registry. The deploy job should rollout the containerized application, named quarkus-app, to the production environment in the Kubernetes cluster by creating a deployment resource, a service resource and an ingress rule with host ${KUBE_INGRESS_BASE_DOMAIN} and /hello prefix. The deploy job should also include the url for the production environment. When setting the Kubernetes context, use ${KUBE_CONTEXT}, and for application namespace, use ${KUBE_NAMESPACE}\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/W2fmunLY1XXWCwKrKPL9I/575056cb91bd8187dc69cb765177eab2/create-pipeline-prompt.png\" alt=\"create-pipeline-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe prompt above provided some points that we thought would be useful and necessary for a good outcome. The requirements listed by the prompt were:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt specified that the pipeline needed to have three stages: build, containerize, and deploy.\u003c/li\u003e\n\u003cli\u003eEach stage would have a single job.\u003c/li\u003e\n\u003cli\u003eThe build job should natively compile (not build) the application using the -Pnative option.\u003c/li\u003e\n\u003cli\u003eThe build job should use the open source software \u003ccode\u003emandrel\u003c/code\u003e and use the version that would support jdk-22 for Java 17. Remember that these were the versions that we tested on our local machine.\u003c/li\u003e\n\u003cli\u003eThe build job would also need to pass the resulting executable and the project Dockerfile to the next job, i.e. containerize, in the pipeline.\u003c/li\u003e\n\u003cli\u003eThe containerize job should build a docker image with the executable using the Dockerfile, both of which were passed as artifacts.\u003c/li\u003e\n\u003cli\u003eThe containerize job should push the image to the GitLab container registry.\u003c/li\u003e\n\u003cli\u003eThe deploy job should use the image from the GitLab container registry, name it \u003ccode\u003equarkus-app\u003c/code\u003e, and deploy it to the Kubernetes cluster using deployment, service and ingress rule resources.\u003c/li\u003e\n\u003cli\u003eThe deploy job should use the environment variables \u003ccode\u003e${KUBE_INGRESS_BASE_DOMAIN}\u003c/code\u003e, \u003ccode\u003e${KUBE_CONTEXT}\u003c/code\u003e, and \u003ccode\u003e${KUBE_NAMESPACE}\u003c/code\u003e, which had been defined as group/project variables, accordingly.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eChat responded with the following \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Define the stages for the pipeline\nstages:\n  - build\n  - containerize\n  - deploy\n\n# Variables section to use GitLab CI/CD variables\nvariables:\n  MAVEN_OPTS: \u0026#34;-Dmaven.repo.local=.m2/repository\u0026#34;\n  MAVEN_CLI_OPTS: \u0026#34;--batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true\u0026#34;\n  CONTAINER_IMAGE: ${CI_REGISTRY_IMAGE}:${CI_COMMIT_SHA}\n\n# Cache configuration for Maven dependencies\ncache:\n  paths:\n    - .m2/repository\n\n# Build stage: Compile the application natively\nbuild:\n  stage: build\n  image:\n    name: quay.io/quarkus/ubi-quarkus-mandrel-builder-image:22.3-java17\n    entrypoint:\n      - \u0026#34;\u0026#34;\n  script:\n    - ./mvnw ${MAVEN_CLI_OPTS} clean package -Pnative\n  artifacts:\n    paths:\n      - target/*-runner\n      - src/main/docker/Dockerfile.native-micro\n  # This job runs only on the main branch\n  only:\n      - main\n\n# Containerize stage: Build and push Docker image\ncontainerize:\n  stage: containerize\n  image: docker:20.10.16\n  services:\n    - docker:20.10.16-dind\n  variables:\n    DOCKER_TLS_CERTDIR: \u0026#34;/certs\u0026#34;\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -f src/main/docker/Dockerfile.native-micro -t ${CONTAINER_IMAGE} .\n    - docker push ${CONTAINER_IMAGE}\n  # This job runs only on the main branch\n  only:\n      - main\n\n# Deploy stage: Deploy to Kubernetes\ndeploy:\n  stage: deploy\n  image: \n    name: bitnami/kubectl:latest\n    entrypoint: [\u0026#39;\u0026#39;]\n  script:\n    - kubectl config use-context ${KUBE_CONTEXT}\n    - kubectl config set-context --current --namespace=${KUBE_NAMESPACE}\n    - |\n      cat \u0026lt;\u0026lt;EOF | kubectl apply -f -\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        name: quarkus-app\n      spec:\n        replicas: 1\n        selector:\n          matchLabels:\n            app: quarkus-app\n        template:\n          metadata:\n            labels:\n              app: quarkus-app\n          spec:\n            containers:\n            - name: quarkus-app\n              image: ${CONTAINER_IMAGE}\n              ports:\n              - containerPort: 8080\n      ---\n      apiVersion: v1\n      kind: Service\n      metadata:\n        name: quarkus-app\n      spec:\n        selector:\n          app: quarkus-app\n        ports:\n        - port: 80\n          targetPort: 8080\n      ---\n      apiVersion: networking.k8s.io/v1\n      kind: Ingress\n      metadata:\n        name: quarkus-app\n      spec:\n        rules:\n        - host: ${KUBE_INGRESS_BASE_DOMAIN}\n          http:\n            paths:\n            - path: /hello\n              pathType: Prefix\n              backend:\n                service:\n                  name: quarkus-app\n                  port: \n                    number: 80\n      EOF\n    - echo \u0026#34;Application deployed to https://${KUBE_INGRESS_BASE_DOMAIN}/hello\u0026#34;\n  # This job runs only on the main branch\n  only:\n      - main\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eThere were some things we needed to adjust in the sample \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e file above before we could commit it to our \u003ccode\u003emain\u003c/code\u003e branch. These are the updates we made to the file:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eWe deleted all occurrences of \u003ccode\u003eonly: -main\u003c/code\u003e because we wanted to keep of pipeline definition file simple and with no branch-related rules.\u003c/li\u003e\n\u003cli\u003eWe fixed the name of the file \u003ccode\u003eDockerfile.native-micro\u003c/code\u003e to \u003ccode\u003eDockerfile.native\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eAt this point, we wanted to ensure that the deployment would be to the \u003ccode\u003eproduction\u003c/code\u003e environment so we asked Chat the following prompt:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eWhat is the syntax to specify an environment with its url in a pipeline?\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/23NAa7IgcoSBtYCy4EpvYq/ab18fe617b112137be52d878ffaeecaf/how-to-add-env-prompt.png\" alt=\"how-to-add-env-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe response from Chat included an example of how to do this so we used this information to add the following environment block to our pipeline:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e  environment:\n       name: production\n       url: http://${KUBE_INGRESS_BASE_DOMAIN}/hello\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e\n\u003cp\u003eThe example provided by Chat includes a URL that started with \u003ccode\u003ehttps\u003c/code\u003e and we modified that to \u003ccode\u003ehttp\u003c/code\u003e since we didn’t really need a secure connection for this simple application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLastly, we noticed that in the \u003ccode\u003ebuild\u003c/code\u003e job, there was a script \u003ccode\u003emvnw\u003c/code\u003e that we didn’t have in our project. So, we asked Chat the following:\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eHow can I get the mvnw script for Quarkus?\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/2zchShhqe8XuBfUwhnnciZ/9757f2962ca7546f6d6ea8b63e3487c5/how-to-add-mvnw-prompt.png\" alt=\"how-to-add-mvnw-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat responded with the command to execute to bootstrap and create this script. We executed this command from a Terminal window:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emvn wrapper:wrapper\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe were now ready to commit all of our changes to the \u003ccode\u003emain\u003c/code\u003e branch and have the pipeline executed. However, on our first attempt, our first pipeline failed at the build job.\u003c/p\u003e\n\u003ch2 id=\"troubleshooting-using-gitlab-duo-root-cause-analysis\" tabindex=\"-1\"\u003eTroubleshooting using GitLab Duo Root Cause Analysis \u003ca href=\"#troubleshooting-using-gitlab-duo-root-cause-analysis\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOur first attempt at running our brand-new pipeline failed. So, we took advantage of \u003ca href=\"https://about.gitlab.com/blog/2024/06/06/developing-gitlab-duo-blending-ai-and-root-cause-analysis-to-fix-ci-cd/\"\u003eGitLab Duo Root Cause Analysis\u003c/a\u003e, which looks at the job logs and provides a thorough natural language explanation (with examples) of the root cause of the problem and, most importantly, how to fix it.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/50aoe9JUV0urUQg0iTDiD5/877b665c401961bb62403636b64cc75d/build-job-troubleshooting.png\" alt=\"build-job-troubleshooting\"/\u003e\u003c/p\u003e\n\u003cp\u003eRoot Cause Analysis recommended we look at the compatibility of the command that was trying to be executed with the image of mandrel used in the build job. We were not using any command with the image so we concluded that it must have been the predefined \u003ccode\u003eentrypoint\u003c/code\u003e for the image itself. We needed to override this so we asked Chat the following:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eHow do I override the entrypoint of an image using gitlab keywords?\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/3ZKkSHmSjaDs0NH52G3nJE/eec7e5093eaec1475d20d4d25afc869b/how-to-override-entrypoint-prompt.png\" alt=\"how-to-override-entrypoint-prompt\"/\u003e\u003c/p\u003e\n\u003cp\u003eChat replied with some use case examples of overriding an image entry point. We used that information to update the build job image definition:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuild:\n    stage: build\n    image: quay.io/quarkus/ubi-quarkus-mandrel-builder-image:22.3-java17\n    entrypoint:\n        - “”\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe committed our changes to the \u003ccode\u003emain\u003c/code\u003e branch, which launched a new instance of the pipeline. This time the build job executed successfully but the pipeline failed at the \u003ccode\u003econtainerize\u003c/code\u003e job.\u003c/p\u003e\n\u003ch2 id=\"running-a-successful-pipeline\" tabindex=\"-1\"\u003eRunning a successful pipeline \u003ca href=\"#running-a-successful-pipeline\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBefore drilling down into the log of the failed \u003ccode\u003econtainerize\u003c/code\u003e job, we decided to drill into the log of the successfully completed build job first. Everything looked good in the log of the build job with the exception of this warning message at the very end of it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eWARNING: src/main/docker/Dockerfile.native: no matching files. Ensure that the artifact path is relative to the working directory …\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe took notice of this warning and then headed to the log of the failed \u003ccode\u003econtainerize\u003c/code\u003e job. In it, we saw that the \u003ccode\u003edocker build\u003c/code\u003e command had failed due to a non-existent Dockerfile. We ran Root Cause Analysis on the job and among its suggested fixes was for us to verify that the project structure matched the path of the specified \u003ccode\u003eDockerfile.native\u003c/code\u003e file.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/T1cnmaU1dJEp9yodUo4pH/fb4e88cadcad13bbb99dd1a121221c33/containerize-job-troubleshooting.png\" alt=\"containerize-job-troubleshooting\"/\u003e\u003c/p\u003e\n\u003cp\u003eThis information confirmed our suspicion of the misplaced \u003ccode\u003eDockerfile.native\u003c/code\u003e file. Instead of being at the directory \u003ccode\u003esrc/main/docker\u003c/code\u003e as specified in the pipeline, it was located at the root directory of the project.\u003c/p\u003e\n\u003cp\u003eSo, we went back to our project and updated every occurrence of the location of this file in our \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e file. We modified the two locations where this happened, one in the \u003ccode\u003ebuild\u003c/code\u003e job and one in the \u003ccode\u003econtainerize\u003c/code\u003e job, as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esrc/main/docker/Dockerfile.native\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eto\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eDockerfile.native\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe committed our updates to the \u003ccode\u003emain\u003c/code\u003e branch and this time our entire pipeline executed successfully!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/1hWmlNp25abbtY0OhPgX2m/030b898d0ae51d35f8333364bb827c5a/pipeline-successful-run.png\" alt=\"pipeline-successful-run\"/\u003e\u003c/p\u003e\n\u003cp\u003eOur last step was to check the running application in the \u003ccode\u003eproduction\u003c/code\u003e environment in our Kubernetes cluster.\u003c/p\u003e\n\u003ch2 id=\"accessing-the-deployed-application-running-in-cluster\" tabindex=\"-1\"\u003eAccessing the deployed application running in cluster \u003ca href=\"#accessing-the-deployed-application-running-in-cluster\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOnce the pipeline ran successfully to completion, we drilled in the log file for the \u003ccode\u003edeploy\u003c/code\u003e job. Remember, this job printed the URL of the application at the end of its execution. We scrolled down to the bottom of the log and clicked on the \u003ccode\u003ehttps\u003c/code\u003e application link, which opened a browser window warning us that the connection was not private (we disabled \u003ccode\u003ehttps\u003c/code\u003e for the environment URL but forgot it for this string). We proceeded past the browser warning and then the string \u0026#34;Hello World\u0026#34; was displaced in the browser window indicating that the application was up and running in the Kubernetes cluster.\u003c/p\u003e\n\u003cp\u003eFinally, to double-check our production deployment URL, we headed to the project \u003cstrong\u003eOperate \u0026gt; Environments\u003c/strong\u003e window, and clicked on the \u0026#34;Open\u0026#34; button for it, which immediately opened a browser window with the \u0026#34;Hello World\u0026#34; message.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/YKwc1bFgjXy8BdRvS3CCn/736834a9a70aa6a19b2e19dc0d0a1fbc/app-running-on-k8s.png\" alt=\"app-running-on-k8s\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"try-it\" tabindex=\"-1\"\u003eTry it \u003ca href=\"#try-it\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWe created, compiled, built, and deployed a simple Quarkus application to a Kubernetes cluster using \u003ca href=\"https://about.gitlab.com/gitlab-duo/\"\u003eGitLab Duo\u003c/a\u003e. This approach allowed us to be more efficient and productive in all the tasks that we performed and it helped us streamline our DevSecOps processes. We have shown only a small portion of how GitLab Duo\u0026#39;s AI-powered capabilities can help you, namely Chat and Root Cause Analysis. There’s so much more you can leverage in GitLab Duo to help you create better software faster and more securely.\u003c/p\u003e\n\u003cp\u003eWatch this whole use case in action:\u003c/p\u003e\n\n\u003cfigure\u003e\n  \u003ciframe src=\"https://www.youtube.com/embed/xDpycxz3RPY?si=HHZrFt1O_8XoLATf\" frameborder=\"0\" allowfullscreen=\"\"\u003e \u003c/iframe\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eAll the project assets we used are available \u003ca href=\"https://gitlab.com/gitlab-da/use-cases/ai/ai-applications/quarkusn/quarkus-native\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://about.gitlab.com/solutions/gitlab-duo-pro/sales/?type=free-trial\u0026amp;toggle=gitlab-duo-pro\"\u003eTry GitLab Duo for free for 60 days\u003c/a\u003e and get started on exciting projects like this.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "27 min read",
  "publishedTime": "2024-10-17T00:00:00Z",
  "modifiedTime": null
}
