{
  "id": "0f115c27-9579-428b-ae48-e4cc5c2e3eeb",
  "title": "DevSummit Boston: Humans in the Loop: Engineering Leadership in a Chaotic Industry",
  "link": "https://www.infoq.com/news/2025/06/infoq-dev-summit-aihype/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "At the InfoQ Dev Summit, Google’s Engineering Director Michelle Brush addressed software leaders, emphasizing the evolving landscape of software engineering amidst rising automation. She championed a shift toward higher-level cognitive skills, systems thinking, and foundational knowledge, urging engineers to embrace complexity for enhanced resilience and decision-making in their work. By Andrew Hoblitzell",
  "author": "Andrew Hoblitzell",
  "published": "Mon, 16 Jun 2025 12:22:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "InfoQ Dev Summit Boston 2025",
    "Leadership",
    "Artificial Intelligence",
    "Culture",
    "Development",
    "Architecture \u0026 Design",
    "Culture \u0026 Methods",
    "news"
  ],
  "byline": "Andrew Hoblitzell",
  "length": 4009,
  "excerpt": "At the InfoQ Dev Summit, Google’s Engineering Director Michelle Brush addressed software leaders, emphasizing the evolving landscape of software engineering amidst rising automation. She championed a",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250605075544/apple-touch-icon.png",
  "text": "At the InfoQ Dev Summit in Boston, Michelle Brush, Engineering Director of Site Reliability Engineering (SRE) at Google, delivered a keynote that spoke directly to software leaders on the broader changes underway in software engineering, systems thinking, and leadership through complexity. She opened by acknowledging the uncertainty that many practitioners feel, affirming that this was a shared experience and an expected part of navigating today’s technological landscape. Brush argued that the nature of software engineering work is shifting, not disappearing. As AI systems automate pieces of software development, engineers will face harder and more complex challenges. Citing Bainbridge’s “ironies of automation”, she explained, “when you automate some piece of work, the job that you leave behind for humans to do is actually harder.” The result is a landscape where engineers must monitor, debug, and validate automated systems, even as their direct responsibilities evolve. She illustrated this point with a simple analogy: “Dishwashers are great… but we didn’t get rid of all the work.” While machines may handle routine tasks, humans are left with responsibility for exception handling, quality assurance, and system maintenance. In software, this translates into higher-level abstraction work, deeper troubleshooting, and a reliance on engineering judgment. “Our brains are going to start working on higher and higher abstractions,” she said, emphasizing the cognitive shift required in modern development. Brush explained that large language models (LLMs) today operate with a kind of “unconscious competence.” They can produce impressive results, but lack explainability and awareness of their limitations. “They don’t know what they don’t know,” she said, framing hallucinations as a natural byproduct of this architecture. By contrast, humans sit in the space of “conscious competence”—we understand what we know and can explain it, which is essential for teaching, mentoring, and validating machine outputs. A central concept in her talk was the importance of “chunking,” or cognitive encapsulation, as engineers deal with increasing complexity. She argued that the ability to move between abstraction layers—while still being able to drill into the underlying systems—is crucial. “All abstractions leak,” she reminded the audience, “especially our hardware abstractions.” Brush also stressed the enduring importance of foundational technical knowledge. “I have used calculus in my day job. Definitely discrete math. I’ve had the misfortune of using assembly twice,” she joked, highlighting how education in the fundamentals continues to pay off—even as tools and platforms evolve. She called this kind of knowledge essential for engineering resilience, not just in code, but in understanding systems holistically. To this end, she advocated for systems thinking, citing Donella Meadows’ work on flows, feedback loops, and change. She recommended supporting disciplines such as control theory, cybernetics, and behavioral economics to better model and design socio-technical systems. For engineering leaders, this was a call to develop broader lenses for decision-making and risk assessment. Sharing a case study from Google, Brush detailed a 2019 outage that brought down two data centers due to runaway automation. The assumption that geographic distribution was sufficient proved wrong when a third data center also failed under the load of recovery traffic. The takeaway? “We realized we needed to be in more than just three data centers,” she said. The response involved not just more capacity, but smarter design—using latency injection testing and intent-based rollout systems to surface risks before deployment. Developers looking to learn more can watch infoq.com in the coming weeks for videos from the event. About the Author Andrew Hoblitzell",
  "image": "https://cdn.infoq.com/statics_s2_20250605075544/styles/static/images/logo/logo-big.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eAt the InfoQ \u003ca href=\"https://devsummit.infoq.com/conference/boston2025\"\u003eDev Summit\u003c/a\u003e in Boston, \u003ca href=\"https://devsummit.infoq.com/speakers/michellebrush\"\u003eMichelle Brush\u003c/a\u003e, Engineering Director of Site Reliability Engineering (SRE) at \u003ca href=\"http://google.com\"\u003eGoogle\u003c/a\u003e, delivered a \u003ca href=\"https://devsummit.infoq.com/keynote/boston2025/humans-loop-engineering-leadership-chaotic-industry\"\u003ekeynote\u003c/a\u003e that spoke directly to software leaders on the broader changes underway in software engineering, systems thinking, and leadership through complexity.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2025/06/infoq-dev-summit-aihype/en/resources/3img1-1749991822731.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2025/06/infoq-dev-summit-aihype/en/resources/3img1-1749991822731.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eShe opened by acknowledging the uncertainty that many practitioners feel, affirming that this was a shared experience and an expected part of navigating today’s technological landscape. Brush argued that the nature of software engineering work is shifting, not disappearing. As AI systems automate pieces of software development, engineers will face harder and more complex challenges.\u003c/p\u003e\n\n\u003cp\u003eCiting Bainbridge’s \u003ca href=\"https://ckrybus.com/static/papers/Bainbridge_1983_Automatica.pdf\" target=\"_blank\"\u003e“ironies of automation”\u003c/a\u003e, she explained, “when you automate some piece of work, the job that you leave behind for humans to do is actually harder.” The result is a landscape where engineers must monitor, debug, and validate automated systems, even as their direct responsibilities evolve.\u003c/p\u003e\n\n\u003cp\u003eShe illustrated this point with a simple analogy: “Dishwashers are great… but we didn’t get rid of all the work.” While machines may handle routine tasks, humans are left with responsibility for exception handling, quality assurance, and system maintenance. In software, this translates into higher-level abstraction work, deeper troubleshooting, and a reliance on engineering judgment. “Our brains are going to start working on higher and higher abstractions,” she said, emphasizing the cognitive shift required in modern development.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2025/06/infoq-dev-summit-aihype/en/resources/2img2-1749991822731.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2025/06/infoq-dev-summit-aihype/en/resources/2img2-1749991822731.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eBrush explained that large language models (LLMs) today operate with a kind of “unconscious competence.” They can produce impressive results, but lack explainability and awareness of their limitations. “They don’t know what they don’t know,” she said, framing hallucinations as a natural byproduct of this architecture. By contrast, humans sit in the space of “conscious competence”—we understand what we know and can explain it, which is essential for teaching, mentoring, and validating machine outputs.\u003c/p\u003e\n\n\u003cp\u003eA central concept in her talk was the importance of “chunking,” or cognitive encapsulation, as engineers deal with increasing complexity. She argued that the ability to move between abstraction layers—while still being able to drill into the underlying systems—is crucial. “All abstractions leak,” she reminded the audience, “especially our hardware abstractions.”\u003c/p\u003e\n\n\u003cp\u003eBrush also stressed the enduring importance of foundational technical knowledge. “I have used calculus in my day job. Definitely discrete math. I’ve had the misfortune of using assembly twice,” she joked, highlighting how education in the fundamentals continues to pay off—even as tools and platforms evolve. She called this kind of knowledge essential for engineering resilience, not just in code, but in understanding systems holistically.\u003c/p\u003e\n\n\u003cp\u003eTo this end, she advocated for systems thinking, citing Donella Meadows’ work on \u003ca href=\"https://donellameadows.org/systems-thinking-resources/\" target=\"_blank\"\u003eflows, feedback loops, and change\u003c/a\u003e. She recommended supporting disciplines such as control theory, cybernetics, and behavioral economics to better model and design socio-technical systems. For engineering leaders, this was a call to develop broader lenses for decision-making and risk assessment.\u003c/p\u003e\n\n\u003cp\u003eSharing a case study from Google, Brush detailed a 2019 outage that brought down two data centers due to runaway automation. The assumption that geographic distribution was sufficient proved wrong when a third data center also failed under the load of recovery traffic. The takeaway? “We realized we needed to be in more than just three data centers,” she said. The response involved not just more capacity, but smarter design—using latency injection testing and intent-based rollout systems to surface risks before deployment.\u003c/p\u003e\n\n\u003cp\u003eDevelopers looking to learn more can watch \u003ca href=\"https://www.infoq.com\" target=\"_blank\"\u003einfoq.com\u003c/a\u003e in the coming weeks for videos from the event.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Andrew-Hoblitzell\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eAndrew Hoblitzell\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-06-16T00:00:00Z",
  "modifiedTime": null
}
