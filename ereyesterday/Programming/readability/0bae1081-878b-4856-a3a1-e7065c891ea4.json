{
  "id": "0bae1081-878b-4856-a3a1-e7065c891ea4",
  "title": "Bringing AI Agents to production with Gemini API",
  "link": "https://developers.googleblog.com/en/bringing-ai-agents-to-production-with-gemini-api/",
  "description": "AgentOps uses the Gemini API to provide cost-effective and powerful LLM-powered agent observability for enterprises.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Vishal Dharmadhikari, Paige Bailey, Adam Silverman",
  "length": 2443,
  "excerpt": "AgentOps uses the Gemini API to provide cost-effective and powerful LLM-powered agent observability for enterprises.",
  "siteName": "",
  "favicon": "",
  "text": "Building and deploying AI agents is an exciting frontier, but managing these complex systems in a production environment requires robust observability. AgentOps, a Python SDK for agent monitoring, LLM cost tracking, benchmarking, and more, empowers developers to take their agents from prototype to production, especially when paired with the power and cost-effectiveness of the Gemini API. The Gemini advantageAdam Silverman, COO of Agency AI, the team behind AgentOps, explains that cost is a critical factor for enterprises deploying AI agents at scale. \"We've seen enterprises spend $80,000 per month on LLM calls. With Gemini 1.5, this would have been a few thousand dollars for the same output.\"This cost-effectiveness, combined with Gemini's powerful language understanding and generation capabilities, makes it an ideal choice for developers building sophisticated AI agents. \"Gemini 1.5 Flash is giving us comparable quality to larger models, at a fraction of the cost while being incredibly fast,\" says Silverman. This allows developers to focus on building complex, multi-step agent workflows without worrying about runaway costs.\"We have seen individual agent runs with other LLM providers cost $500+ per run. These same runs with Gemini (1.5 Fash 8B) cost under $50.\" – Adam Silverman, COO, Agency AI Powering AI AgentsAgentOps captures data on every agent interaction, not just LLM calls, providing a comprehensive view of how multi-agent systems operate. This granular level of detail is essential for engineering and compliance teams, offering crucial insights for debugging, optimization, and audit trails.Integrating Gemini models with AgentOps is remarkably simple, often taking just minutes using LiteLLM. Developers can quickly gain visibility into their Gemini APIcalls, track costs in real-time, and ensure the reliability of their agents in production.Looking aheadAgentOps is committed to supporting agent developers as they scale their projects. Agency AI is helping enterprises navigate the complexities of building affordable, scalable agents, further solidifying the value proposition of combining AgentOps with the Gemini API. As Silverman emphasizes, \"It is ushering more price-conscious developers to build agents.\"For developers considering using Gemini, Silverman's advice is clear: \"Give it a try, and you will be impressed.\"",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-X-AgentOps.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cp data-block-key=\"2ww3x\"\u003eBuilding and deploying AI agents is an exciting frontier, but managing these complex systems in a production environment requires robust observability. \u003ca href=\"https://www.agentops.ai/\"\u003eAgentOps\u003c/a\u003e, a Python SDK for agent monitoring, LLM cost tracking, benchmarking, and more, empowers developers to take their agents from prototype to production, especially when paired with the power and cost-effectiveness of the \u003ca href=\"https://ai.google.dev/gemini-api/docs\"\u003eGemini API\u003c/a\u003e.\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_zNfzuEc.original.png\" alt=\"A screenshot of the AgentOps AI platform displaying session data, including the session duration, cost, and prompts used, highlighting the LLM (Large Language Model) calls and events, the specific agent involved, and their role in the session.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"2ww3x\"\u003eThe Gemini advantage\u003c/h2\u003e\u003cp data-block-key=\"ci2b6\"\u003eAdam Silverman, COO of \u003ca href=\"http://www.agen.cy/\"\u003eAgency AI\u003c/a\u003e, the team behind AgentOps, explains that cost is a critical factor for enterprises deploying AI agents at scale. \u0026#34;We\u0026#39;ve seen enterprises spend $80,000 per month on LLM calls. With Gemini 1.5, this would have been a few thousand dollars for the same output.\u0026#34;\u003c/p\u003e\u003cp data-block-key=\"4ibbe\"\u003eThis cost-effectiveness, combined with Gemini\u0026#39;s powerful language understanding and generation capabilities, makes it an ideal choice for developers building sophisticated AI agents. \u0026#34;Gemini 1.5 Flash is giving us comparable quality to larger models, at a fraction of the cost while being incredibly fast,\u0026#34; says Silverman. This allows developers to focus on building complex, multi-step agent workflows without worrying about runaway costs.\u003c/p\u003e\u003cblockquote data-block-key=\"e0pk3\"\u003e\u003ci\u003e\u0026#34;We have seen individual agent runs with other LLM providers cost $500+ per run. These same runs with Gemini (1.5 Fash 8B) cost under $50.\u0026#34;\u003c/i\u003e\u003cbr/\u003e \u003cb\u003e\u003csub\u003e– Adam Silverman\u003c/sub\u003e\u003c/b\u003e\u003csub\u003e, COO, Agency AI\u003c/sub\u003e\u003c/blockquote\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_nAE7BoO.original.png\" alt=\"A screen share of an AgentOps AI dashboard showing graphs and charts of analytics for session end states, failed sessions, session cost distribution, and events per session.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"2ww3x\"\u003ePowering AI Agents\u003c/h2\u003e\u003cp data-block-key=\"5pjht\"\u003eAgentOps captures data on every agent interaction, not just LLM calls, providing a comprehensive view of how multi-agent systems operate. This granular level of detail is essential for engineering and compliance teams, offering crucial insights for debugging, optimization, and audit trails.\u003c/p\u003e\u003cp data-block-key=\"djcnd\"\u003eIntegrating Gemini models with AgentOps is remarkably simple, often taking just minutes using LiteLLM. Developers can quickly gain visibility into their Gemini \u003ccode\u003eAPIcalls\u003c/code\u003e, track costs in real-time, and ensure the reliability of their agents in production.\u003c/p\u003e\u003ch2 data-block-key=\"3lt6f\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eLooking ahead\u003c/h2\u003e\u003cp data-block-key=\"6l5v0\"\u003eAgentOps is committed to supporting agent developers as they scale their projects. Agency AI is helping enterprises navigate the complexities of building affordable, scalable agents, further solidifying the value proposition of combining AgentOps with the Gemini API. As Silverman emphasizes, \u0026#34;It is ushering more price-conscious developers to build agents.\u0026#34;\u003c/p\u003e\u003cp data-block-key=\"d5a26\"\u003eFor developers considering using Gemini, Silverman\u0026#39;s advice is clear: \u0026#34;Give it a try, and you will be impressed.\u0026#34;\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2024-10-30T00:00:00Z",
  "modifiedTime": null
}
