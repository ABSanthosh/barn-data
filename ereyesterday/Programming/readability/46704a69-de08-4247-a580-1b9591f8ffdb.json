{
  "id": "46704a69-de08-4247-a580-1b9591f8ffdb",
  "title": "Part 3: A Survey of Analytics Engineering Work at Netflix",
  "link": "https://netflixtechblog.com/part-3-a-survey-of-analytics-engineering-work-at-netflix-e67f0aa82183?source=rss----2615bd06b42e---4",
  "description": "",
  "author": "Netflix Technology Blog",
  "published": "Mon, 06 Jan 2025 19:27:38 GMT",
  "source": "https://netflixtechblog.com/feed",
  "categories": [
    "analytics-engineering",
    "analytics"
  ],
  "byline": "Netflix Technology Blog",
  "length": 11963,
  "excerpt": "This article is the last in a multi-part series sharing a breadth of Analytics Engineering work at Netflix, recently presented as part of our annual internal Analytics Engineering conference. Need to…",
  "siteName": "Netflix TechBlog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "This article is the last in a multi-part series sharing a breadth of Analytics Engineering work at Netflix, recently presented as part of our annual internal Analytics Engineering conference. Need to catch up? Check out Part 1, which detailed how we’re empowering Netflix to efficiently produce and effectively deliver high quality, actionable analytic insights across the company and Part 2, which stepped through a few exciting business applications for Analytics Engineering. This post will go into aspects of technical craft.Dashboard Design TipsRina Chang, Susie LuWhat is design, and why does it matter? Often people think design is about how things look, but design is actually about how things work. Everything is designed, because we’re all making choices about how things work, but not everything is designed well. Good design doesn’t waste time or mental energy; instead, it helps the user achieve their goals.When applying this to a dashboard application, the easiest way to use design effectively is to leverage existing patterns. (For example, people have learned that blue underlined text on a website means it’s a clickable link.) So knowing the arsenal of available patterns and what they imply is useful when making the choice of when to use which pattern.First, to design a dashboard well, you need to understand your user.Talk to your users throughout the entire product lifecycle. Talk to them early and often, through whatever means you can.Understand their needs, ask why, then ask why again. Separate symptoms from problems from solutions.Prioritize and clarify — less is more! Distill what you can build that’s differentiated and provides the most value to your user.Here is a framework for thinking about what your users are trying to achieve. Where do your users fall on these axes? Don’t solve for multiple positions across these axes in a given view; if that exists, then create different views or potentially different dashboards.Second, understanding your users’ mental models will allow you to choose how to structure your app to match. A few questions to ask yourself when considering the information architecture of your app include:Do you have different user groups trying to accomplish different things? Split them into different apps or different views.What should go together on a single page? All the information needed for a single user type to accomplish their “job.” If there are multiple jobs to be done, split each out onto its own page.What should go together within a single section on a page? All the information needed to answer a single question.Does your dashboard feel too difficult to use? You probably have too much information! When in doubt, keep it simple. If needed, hide complexity under an “Advanced” section.Here are some general guidelines for page layouts:Choose infinite scrolling vs. clicking through multiple pages depending on which option suits your users’ expectations betterLead with the most-used information first, above the foldCreate signposts that cue the user to where they are by labeling pages, sections, and linksUse cards or borders to visually group related items togetherLeverage nesting to create well-understood “scopes of control.” Specifically, users expect a controller object to affect children either: Below it (if horizontal) or To the right of it (if vertical)Third, some tips and tricks can help you more easily tackle the unique design challenges that come with making interactive charts.Titles: Make sure filters are represented in the title or subtitle of the chart for easy scannability and screenshot-ability.Tooltips: Core details should be on the page, while the context in the tooltip is for deeper information. Annotate multiple points when there are only a handful of lines.Annotations: Provide annotations on charts to explain shifts in values so all users can access that context.Color: Limit the number of colors you use. Be consistent in how you use colors. Otherwise, colors lose meaning.Onboarding: Separate out onboarding to your dashboard from routine usage.Finally, it is important to note that these are general guidelines, but there is always room for interpretation and/or the use of good judgment to adapt them to suit your own product and use cases. At the end of the day, the most important thing is that a user can leverage the data insights provided by your dashboard to perform their work, and good design is a means to that end.Learnings from Deploying an Analytics API at NetflixDevin CarulloAt Netflix Studio, we operate at the intersection of art and science. Data is a tool that enhances decision-making, complementing the deep expertise and industry knowledge of our creative professionals.One example is in production budgeting — namely, determining how much we should spend to produce a given show or movie. Although there was already a process for creating and comparing budgets for new productions against similar past projects, it was highly manual. We developed a tool that automatically selects and compares similar Netflix productions, flagging any anomalies for Production Finance to review.To ensure success, it was essential that results be delivered in real-time and integrated seamlessly into existing tools. This required close collaboration among product teams, DSE, and front-end and back-end developers. We developed a GraphQL endpoint using Metaflow, integrating it into the existing budgeting product. This solution enabled data to be used more effectively for real-time decision-making.We recently launched our MVP and continue to iterate on the product. Reflecting on our journey, the path to launch was complex and filled with unexpected challenges. As an analytics engineer accustomed to crafting quick solutions, I underestimated the effort required to deploy a production-grade analytics API.Fig 1. My vague idea of how my API would workFig 2: Our actual solutionWith hindsight, below are my key learnings.Measure Impact and Necessity of Real-Time ResultsBefore implementing real-time analytics, assess whether real-time results are truly necessary for your use case. This can significantly impact the complexity and cost of your solution. Batch processing data may provide a similar impact and take significantly less time. It’s easier to develop and maintain, and tends to be more familiar for analytics engineers, data scientists, and data engineers.Additionally, if you are developing a proof of concept, the upfront investment may not be worth it. Scrappy solutions can often be the best choice for analytics work.Explore All Available SolutionsAt Netflix, there were multiple established methods for creating an API, but none perfectly suited our specific use case. Metaflow, a tool developed at Netflix for data science projects, already supported REST APIs. However, this approach did not align with the preferred workflow of our engineering partners. Although they could integrate with REST endpoints, this solution presented inherent limitations. Large response sizes rendered the API/front-end integration unreliable, necessitating the addition of filter parameters to reduce the response size.Additionally, the product we were integrating into was using GraphQL, and deviating from this established engineering approach was not ideal. Lastly, given our goal to overlay results throughout the product, GraphQL features, such as federation, proved to be particularly advantageous.After realizing there wasn’t an existing solution at Netflix for deploying python endpoints with GraphQL, we worked with the Metaflow team to build this feature. This allowed us to continue developing via Metaflow and allowed our engineering partners to stay on their paved path.Align on Performance ExpectationsA major challenge during development was managing API latency. Much of this could have been mitigated by aligning on performance expectations from the outset. Initially, we operated under our assumptions of what constituted an acceptable response time, which differed greatly from the actual needs of our users and our engineering partners.Understanding user expectations is key to designing an effective solution. Our methodology resulted in a full budget analysis taking, on average, 7 seconds. Users were willing to wait for an analysis when they modified a budget, but not every time they accessed one. To address this, we implemented caching using Metaflow, reducing the API response time to approximately 1 second for cached results. Additionally, we set up a nightly batch job to pre-cache results.While users were generally okay with waiting for analysis during changes, we had to be mindful of GraphQL’s 30-second limit. This highlighted the importance of continuously monitoring the impact of changes on response times, leading us to our next key learning: rigorous testing.Real-Time Analysis Requires Rigorous TestingLoad Testing: We leveraged Locust to measure the response time of our endpoint and assess how the endpoint responded to reasonable and elevated loads. We were able to use FullStory, which was already being used in the product, to estimate expected calls per minute.Fig 3. Locust allows us to simulate concurrent calls and measure response timeUnit Tests \u0026 Integration Tests: Code testing is always a good idea, but it can often be overlooked in analytics. It is especially important when you are delivering live analysis to circumvent end users from being the first to see an error or incorrect information. We implemented unit testing and full integration tests, ensuring that our analysis would return correct results.The Importance of Aligning Workflows and CollaborationThis project marked the first time our team collaborated directly with our engineering partners to integrate a DSE API into their product. Throughout the process, we discovered significant gaps in our understanding of each other’s workflows. Assumptions about each other’s knowledge and processes led to misunderstandings and delays.Deployment Paths: Our engineering partners followed a strict deployment path, whereas our approach on the DSE side was more flexible. We typically tested our work on feature branches using Metaflow projects and then pushed results to production. However, this lack of control led to issues, such as inadvertently deploying changes to production before the corresponding product updates were ready and difficulties in managing a test endpoint. Ultimately, we deferred to our engineering partners to establish a deployment path and collaborated with the Metaflow team and data engineers to implement it effectively.Fig 4. Our current deployment pathWork Planning: While the engineering team operated on sprints, our DSE team planned by quarters. This misalignment in planning cycles is an ongoing challenge that we are actively working to resolve.Looking ahead, our team is committed to continuing this partnership with our engineering colleagues. Both teams have invested significant time in building this relationship, and we are optimistic that it will yield substantial benefits in future projects.External Speaker: Benn StancilIn addition to the above presentations, we kicked off our Analytics Summit with a keynote talk from Benn Stancil, Founder of Mode Analytics. Benn stepped through a history of the modern data stack, and the group discussed ideas on the future of analytics.Analytics Engineering is a key contributor to building our deep data culture at Netflix, and we are proud to have a large group of stunning colleagues that are not only applying but advancing our analytical capabilities at Netflix. The 2024 Analytics Summit continued to be a wonderful way to give visibility to one another on work across business verticals, celebrate our collective impact, and highlight what’s to come in analytics practice at Netflix.To learn more, follow the Netflix Research Site, and if you are also interested in entertaining the world, have a look at our open roles!",
  "image": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*ar0t2-zF5YVuXnUe",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://netflixtechblog.medium.com/?source=post_page---byline--e67f0aa82183--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Netflix Technology Blog\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*BJWRqfSMf9Da9vsXG9EBRQ.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://netflixtechblog.com/?source=post_page---byline--e67f0aa82183--------------------------------\" rel=\"noopener  ugc nofollow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Netflix TechBlog\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*ty4NvNrGg4ReETxqU2N3Og.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"ca1c\"\u003e\u003cem\u003eThis article is the last in a multi-part series sharing a breadth of Analytics Engineering work at Netflix, recently presented as part of our annual internal Analytics Engineering conference. Need to catch up? Check out \u003c/em\u003e\u003ca href=\"https://research.netflix.com/publication/part-1-a-survey-of-analytics-engineering-work-at-netflix\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003ePart 1\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, which detailed how we’re empowering Netflix to efficiently produce and effectively deliver high quality, actionable analytic insights across the company and \u003c/em\u003e\u003ca href=\"https://research.netflix.com/publication/part-2-a-survey-of-analytics-engineering-work-at-netflix\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003ePart 2\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, which stepped through a few exciting business applications for Analytics Engineering. This post will go into aspects of technical craft.\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"a095\"\u003eDashboard Design Tips\u003c/h2\u003e\u003cp id=\"1817\"\u003e\u003ca href=\"https://www.linkedin.com/in/rinachang\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRina Chang\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/shansusielu/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSusie Lu\u003c/a\u003e\u003c/p\u003e\u003cp id=\"4102\"\u003eWhat is design, and why does it matter? Often people think design is about how things look, but design is actually about how things work. Everything is designed, because we’re all making choices about how things work, but not everything is designed well. Good design doesn’t waste time or mental energy; instead, it helps the user achieve their goals.\u003c/p\u003e\u003cp id=\"59f0\"\u003eWhen applying this to a dashboard application, the easiest way to use design effectively is to leverage existing patterns. (For example, people have learned that blue underlined text on a website means it’s a clickable link.) So knowing the arsenal of available patterns and what they imply is useful when making the choice of when to use which pattern.\u003c/p\u003e\u003cp id=\"692c\"\u003eFirst, to design a dashboard well, you need to understand your user.\u003c/p\u003e\u003cul\u003e\u003cli id=\"e325\"\u003eTalk to your users throughout the entire product lifecycle. Talk to them early and often, through whatever means you can.\u003c/li\u003e\u003cli id=\"12e2\"\u003eUnderstand their needs, ask why, then ask why again. Separate symptoms from problems from solutions.\u003c/li\u003e\u003cli id=\"4374\"\u003ePrioritize and clarify — less is more! Distill what you can build that’s differentiated and provides the most value to your user.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"dd4d\"\u003eHere is a framework for thinking about what your users are trying to achieve. Where do your users fall on these axes? Don’t solve for multiple positions across these axes in a given view; if that exists, then create different views or potentially different dashboards.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"106c\"\u003eSecond, understanding your users’ mental models will allow you to choose how to structure your app to match. A few questions to ask yourself when considering the information architecture of your app include:\u003c/p\u003e\u003cul\u003e\u003cli id=\"30c3\"\u003eDo you have different user groups trying to accomplish different things? Split them into different apps or different views.\u003c/li\u003e\u003cli id=\"feea\"\u003eWhat should go together on a single page? All the information needed for a single user type to accomplish their “job.” If there are multiple \u003ca href=\"https://www.christenseninstitute.org/theory/jobs-to-be-done/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ejobs to be done\u003c/a\u003e, split each out onto its own page.\u003c/li\u003e\u003cli id=\"c406\"\u003eWhat should go together within a single section on a page? All the information needed to answer a single question.\u003c/li\u003e\u003cli id=\"3bd1\"\u003eDoes your dashboard feel too difficult to use? You probably have too much information! When in doubt, keep it simple. If needed, hide complexity under an “Advanced” section.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"0289\"\u003eHere are some general guidelines for page layouts:\u003c/p\u003e\u003cul\u003e\u003cli id=\"935c\"\u003eChoose infinite scrolling vs. clicking through multiple pages depending on which option suits your users’ expectations better\u003c/li\u003e\u003cli id=\"d91d\"\u003eLead with the most-used information first, above the fold\u003c/li\u003e\u003cli id=\"a5c0\"\u003eCreate signposts that cue the user to where they are by labeling pages, sections, and links\u003c/li\u003e\u003cli id=\"7543\"\u003eUse cards or borders to visually group related items together\u003c/li\u003e\u003cli id=\"94e9\"\u003eLeverage nesting to create well-understood “scopes of control.” Specifically, users expect a controller object to affect children either: Below it (if horizontal) or To the right of it (if vertical)\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"8d9f\"\u003eThird, some tips and tricks can help you more easily tackle the unique design challenges that come with making interactive charts.\u003c/p\u003e\u003cul\u003e\u003cli id=\"9697\"\u003eTitles: Make sure filters are represented in the title or subtitle of the chart for easy scannability and screenshot-ability.\u003c/li\u003e\u003cli id=\"c959\"\u003eTooltips: Core details should be on the page, while the context in the tooltip is for deeper information. Annotate multiple points when there are only a handful of lines.\u003c/li\u003e\u003cli id=\"c00c\"\u003eAnnotations: Provide annotations on charts to explain shifts in values so all users can access that context.\u003c/li\u003e\u003cli id=\"4445\"\u003eColor: Limit the number of colors you use. Be consistent in how you use colors. Otherwise, colors lose meaning.\u003c/li\u003e\u003cli id=\"fe99\"\u003eOnboarding: Separate out onboarding to your dashboard from routine usage.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"a37f\"\u003eFinally, it is important to note that these are general guidelines, but there is always room for interpretation and/or the use of good judgment to adapt them to suit your own product and use cases. At the end of the day, the most important thing is that a user can leverage the data insights provided by your dashboard to perform their work, and good design is a means to that end.\u003c/p\u003e\u003ch2 id=\"f4f7\"\u003e\u003cstrong\u003eLearnings from Deploying an Analytics API at Netflix\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"31ad\"\u003e\u003ca href=\"https://www.linkedin.com/in/devincarullo/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDevin Carullo\u003c/a\u003e\u003c/p\u003e\u003cp id=\"430b\"\u003eAt Netflix Studio, we operate at the intersection of art and science. Data is a tool that enhances decision-making, complementing the deep expertise and industry knowledge of our creative professionals.\u003c/p\u003e\u003cp id=\"970d\"\u003eOne example is in production budgeting — namely, determining how much we should spend to produce a given show or movie. Although there was already a process for creating and comparing budgets for new productions against similar past projects, it was highly manual. We developed a tool that automatically selects and compares similar Netflix productions, flagging any anomalies for Production Finance to review.\u003c/p\u003e\u003cp id=\"b3ea\"\u003eTo ensure success, it was essential that results be delivered in real-time and integrated seamlessly into existing tools. This required close collaboration among product teams, DSE, and front-end and back-end developers. We developed a GraphQL endpoint using Metaflow, integrating it into the existing budgeting product. This solution enabled data to be used more effectively for real-time decision-making.\u003c/p\u003e\u003cp id=\"d3db\"\u003eWe recently launched our MVP and continue to iterate on the product. Reflecting on our journey, the path to launch was complex and filled with unexpected challenges. As an analytics engineer accustomed to crafting quick solutions, I underestimated the effort required to deploy a production-grade analytics API.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eFig 1. My vague idea of how my API would work\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption\u003eFig 2: Our actual solution\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"3a82\"\u003eWith hindsight, below are my key learnings.\u003c/p\u003e\u003cp id=\"3ed3\"\u003e\u003cstrong\u003eMeasure Impact and Necessity of Real-Time Results\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"8dac\"\u003eBefore implementing real-time analytics, assess whether real-time results are truly necessary for your use case. This can significantly impact the complexity and cost of your solution. Batch processing data may provide a similar impact and take significantly less time. It’s easier to develop and maintain, and tends to be more familiar for analytics engineers, data scientists, and data engineers.\u003c/p\u003e\u003cp id=\"70ae\"\u003eAdditionally, if you are developing a proof of concept, the upfront investment may not be worth it. Scrappy solutions can often be the best choice for analytics work.\u003c/p\u003e\u003cp id=\"1905\"\u003e\u003cstrong\u003eExplore All Available Solutions\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"fc32\"\u003eAt Netflix, there were multiple established methods for creating an API, but none perfectly suited our specific use case. Metaflow, a tool developed at Netflix for data science projects, already supported REST APIs. However, this approach did not align with the preferred workflow of our engineering partners. Although they could integrate with REST endpoints, this solution presented inherent limitations. Large response sizes rendered the API/front-end integration unreliable, necessitating the addition of filter parameters to reduce the response size.\u003c/p\u003e\u003cp id=\"ccc2\"\u003eAdditionally, the product we were integrating into was using GraphQL, and deviating from this established engineering approach was not ideal. Lastly, given our goal to overlay results throughout the product, GraphQL features, such as federation, proved to be particularly advantageous.\u003c/p\u003e\u003cp id=\"7ffd\"\u003eAfter realizing there wasn’t an existing solution at Netflix for deploying python endpoints with GraphQL, we worked with the Metaflow team to build this feature. This allowed us to continue developing via Metaflow and allowed our engineering partners to stay on their paved path.\u003c/p\u003e\u003cp id=\"c621\"\u003e\u003cstrong\u003eAlign on Performance Expectations\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"d3b5\"\u003eA major challenge during development was managing API latency. Much of this could have been mitigated by aligning on performance expectations from the outset. Initially, we operated under our assumptions of what constituted an acceptable response time, which differed greatly from the actual needs of our users and our engineering partners.\u003c/p\u003e\u003cp id=\"2ae7\"\u003eUnderstanding user expectations is key to designing an effective solution. Our methodology resulted in a full budget analysis taking, on average, 7 seconds. Users were willing to wait for an analysis when they modified a budget, but not every time they accessed one. To address this, we implemented caching using Metaflow, reducing the API response time to approximately 1 second for cached results. Additionally, we set up a nightly batch job to pre-cache results.\u003c/p\u003e\u003cp id=\"7495\"\u003eWhile users were generally okay with waiting for analysis during changes, we had to be mindful of GraphQL’s 30-second limit. This highlighted the importance of continuously monitoring the impact of changes on response times, leading us to our next key learning: rigorous testing.\u003c/p\u003e\u003cp id=\"1924\"\u003e\u003cstrong\u003eReal-Time Analysis Requires Rigorous Testing\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"ca7a\"\u003eLoad Testing: We leveraged Locust to measure the response time of our endpoint and assess how the endpoint responded to reasonable and elevated loads. We were able to use FullStory, which was already being used in the product, to estimate expected calls per minute.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eFig 3. Locust allows us to simulate concurrent calls and measure response time\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"4782\"\u003eUnit Tests \u0026amp; Integration Tests: Code testing is always a good idea, but it can often be overlooked in analytics. It is especially important when you are delivering live analysis to circumvent end users from being the first to see an error or incorrect information. We implemented unit testing and full integration tests, ensuring that our analysis would return correct results.\u003c/p\u003e\u003cp id=\"91e6\"\u003e\u003cstrong\u003eThe Importance of Aligning Workflows and Collaboration\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"3443\"\u003eThis project marked the first time our team collaborated directly with our engineering partners to integrate a DSE API into their product. Throughout the process, we discovered significant gaps in our understanding of each other’s workflows. Assumptions about each other’s knowledge and processes led to misunderstandings and delays.\u003c/p\u003e\u003cp id=\"3d94\"\u003eDeployment Paths: Our engineering partners followed a strict deployment path, whereas our approach on the DSE side was more flexible. We typically tested our work on feature branches using Metaflow projects and then pushed results to production. However, this lack of control led to issues, such as inadvertently deploying changes to production before the corresponding product updates were ready and difficulties in managing a test endpoint. Ultimately, we deferred to our engineering partners to establish a deployment path and collaborated with the Metaflow team and data engineers to implement it effectively.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eFig 4. Our current deployment path\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"6fa7\"\u003eWork Planning: While the engineering team operated on sprints, our DSE team planned by quarters. This misalignment in planning cycles is an ongoing challenge that we are actively working to resolve.\u003c/p\u003e\u003cp id=\"e86e\"\u003eLooking ahead, our team is committed to continuing this partnership with our engineering colleagues. Both teams have invested significant time in building this relationship, and we are optimistic that it will yield substantial benefits in future projects.\u003c/p\u003e\u003ch2 id=\"f327\"\u003eExternal Speaker: Benn Stancil\u003c/h2\u003e\u003cp id=\"fa9b\"\u003eIn addition to the above presentations, we kicked off our Analytics Summit with a keynote talk from \u003ca href=\"https://www.linkedin.com/in/benn-stancil/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBenn Stancil\u003c/a\u003e, Founder of Mode Analytics. Benn stepped through a history of the modern data stack, and the group discussed ideas on the future of analytics.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"5e52\"\u003eAnalytics Engineering is a key contributor to building our deep data culture at Netflix, and we are proud to have a large group of stunning colleagues that are not only applying but advancing our analytical capabilities at Netflix. The 2024 Analytics Summit continued to be a wonderful way to give visibility to one another on work across business verticals, celebrate our collective impact, and highlight what’s to come in analytics practice at Netflix.\u003c/p\u003e\u003cp id=\"1920\"\u003eTo learn more, follow the \u003ca href=\"https://research.netflix.com/research-area/analytics\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNetflix Research Site\u003c/a\u003e, and if you are also interested in entertaining the world, have a look at \u003ca href=\"https://explore.jobs.netflix.net/careers\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eour open roles\u003c/a\u003e!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2025-01-06T19:27:20.316Z",
  "modifiedTime": null
}
