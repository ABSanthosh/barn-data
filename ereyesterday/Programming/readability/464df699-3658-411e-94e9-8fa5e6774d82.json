{
  "id": "464df699-3658-411e-94e9-8fa5e6774d82",
  "title": "Meta Announces API and Protection Tools at First LlamaCon Event",
  "link": "https://www.infoq.com/news/2025/05/meta-llamacon-announcements/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "At Meta's first-ever LlamaCon event, the company announced several new tools for building with their Llama AI models: a limited preview of the Llama API that allows developers to experiment with different models, and new Llama Protection Tools for securing AI applications. By Anthony Alford",
  "author": "Anthony Alford",
  "published": "Tue, 13 May 2025 13:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Generative AI",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Anthony Alford",
  "length": 3408,
  "excerpt": "At Meta's first-ever LlamaCon event, the company announced several new tools for building with their Llama AI models: a limited preview of the Llama API that allows developers to experiment with diffe",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250513062617/apple-touch-icon.png",
  "text": "At Meta's first-ever LlamaCon event, the company announced several new tools for building with their Llama AI models: a limited preview of the Llama API that allows developers to experiment with different models, and new Llama Protection Tools for securing AI applications. LlamaCon was a one-day virtual event that featured a keynote by chief product officer Chris Cox and two one-on-one chats between Meta CEO Mark Zuckerberg and other CEOs: Satya Nadella of Microsoft and Ali Ghodsi of Databricks. Besides announcing the API, Meta also announced a collaboration with Cerebras and Groq to bring fast inference capability to the API. They also announced an integration of LlamaStack with NVIDIA NeMo microservices. Meta also announced new open-source AI safeguard tools: Llama Guard 4, LlamaFirewall, and Llama Prompt Guard 2. According to Meta: We’re committed to being a long-term partner for enterprises and developers and providing a seamless transition path from closed models. Llama is affordable, easy-to-use, and enabling more people to access the benefits of AI regardless of their technical expertise or hardware resources. We believe in the potential of AI to transform industries and improve lives, which is why we’re excited to continue supporting the growth and development of the Llama ecosystem for the benefit of all. We can’t wait to see what you’ll build next. The Llama protection tools are a suite of safeguards that developers can use to make their AI applications more secure. The LlamaCon release includes Llama Guard 4, a content moderation model; Prompt Guard 2, a tool for preventing jailbreaks and prompt injection; and LlamaFirewall, an orchestration component for integrating multiple protection tools into an AI application.  The Llama API has been released as a free preview. Meta touts its \"easy one-click API key creation and interactive playgrounds.\" Available models include the recently released Llama 4 Scout and Maverick MoE models. The release also includes Python and Typescript SDKs, and the API is compatible with OpenAI's SDK, \"making it easy to convert existing applications.\" The API includes resources for fine-tuning and evaluating custom models. Meta claims they will not use any uploaded prompts or model outputs in their own training. They also say that developers can download and run their custom models anywhere. Some users in Hacker News discussion about LlamaCon lamented the restrictions on the Llama license, making it in their opinion not fully open-source. In reference to the API announcement, another user remarked: Feels like Meta is going to Cloud services business but in AI domain. They resisted entering cloud business for so long, with the success of AWS/Azure/GCP I think they are realizing they can't keep at the top only with social networks without owning a platform (hardware, cloud). In a Reddit thread about the announcements, users reacted positively to the fast inference news: I think the future lies with speed for sure. You can do some wild things when you are able to pump out hundreds if not thousands of tokens a second. Developers interested in gaining access to the Llama API Preview can join the waitlist. The Llama Stack code is available on GitHub. About the Author Anthony Alford",
  "image": "https://res.infoq.com/news/2025/05/meta-llamacon-announcements/en/headerimage/generatedHeaderImage-1746357175866.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eAt \u003ca href=\"https://ai.meta.com/\"\u003eMeta\u0026#39;s\u003c/a\u003e first-ever \u003ca href=\"https://ai.meta.com/blog/llamacon-llama-news/\"\u003eLlamaCon event\u003c/a\u003e, the company announced several new tools for building with their \u003ca href=\"https://www.llama.com/\"\u003eLlama\u003c/a\u003e AI models: a limited preview of the Llama API that allows developers to experiment with different models, and new Llama Protection Tools for securing AI applications.\u003c/p\u003e\n\n\u003cp\u003eLlamaCon was a \u003ca href=\"https://www.llama.com/events/llamacon/2025/?linkId=100000362755559\"\u003eone-day virtual event\u003c/a\u003e that featured a keynote by chief product officer Chris Cox and two one-on-one chats between Meta CEO Mark Zuckerberg and other CEOs: Satya Nadella of Microsoft and Ali Ghodsi of Databricks. Besides announcing the API, Meta also announced a collaboration with \u003ca href=\"https://www.cerebras.ai/\"\u003eCerebras\u003c/a\u003e and \u003ca href=\"https://groq.com/\"\u003eGroq\u003c/a\u003e to bring fast inference capability to the API. They also announced an integration of LlamaStack with NVIDIA NeMo microservices. Meta also announced new \u003ca href=\"https://ai.meta.com/blog/ai-defenders-program-llama-protection-tools/\"\u003eopen-source AI safeguard tools\u003c/a\u003e: Llama Guard 4, LlamaFirewall, and Llama Prompt Guard 2. According to Meta:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eWe’re committed to being a long-term partner for enterprises and developers and providing a seamless transition path from closed models. Llama is affordable, easy-to-use, and enabling more people to access the benefits of AI regardless of their technical expertise or hardware resources. We believe in the potential of AI to transform industries and improve lives, which is why we’re excited to continue supporting the growth and development of the Llama ecosystem for the benefit of all. We can’t wait to see what you’ll build next.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://www.llama.com/llama-protections/\"\u003eLlama protection tools\u003c/a\u003e are a suite of safeguards that developers can use to make their AI applications more secure. The LlamaCon release includes Llama Guard 4, a content moderation model; Prompt Guard 2, a tool for preventing jailbreaks and prompt injection; and LlamaFirewall, an orchestration component for integrating multiple protection tools into an AI application. \u003c/p\u003e\n\n\u003cp\u003eThe Llama API has been released as a free preview. Meta touts its \u0026#34;easy one-click API key creation and interactive playgrounds.\u0026#34; Available models include the recently released Llama 4 Scout and Maverick MoE models. The release also includes Python and Typescript SDKs, and the API is compatible with OpenAI\u0026#39;s SDK, \u0026#34;making it easy to convert existing applications.\u0026#34;\u003c/p\u003e\n\n\u003cp\u003eThe API includes resources for fine-tuning and evaluating custom models. Meta claims they will not use any uploaded prompts or model outputs in their own training. They also say that developers can download and run their custom models anywhere.\u003c/p\u003e\n\n\u003cp\u003eSome users in Hacker News \u003ca href=\"https://news.ycombinator.com/item?id=43835424\"\u003ediscussion about LlamaCon\u003c/a\u003e lamented the restrictions on the Llama license, making it in their opinion \u003ca href=\"https://github.com/meta-llama/llama3/issues/156\"\u003enot fully open-source\u003c/a\u003e. In reference to the API announcement, another user remarked:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eFeels like Meta is going to Cloud services business but in AI domain. They resisted entering cloud business for so long, with the success of AWS/Azure/GCP I think they are realizing they can\u0026#39;t keep at the top only with social networks without owning a platform (hardware, cloud).\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn a Reddit thread about the announcements, users \u003ca href=\"https://www.reddit.com/r/LocalLLaMA/comments/1katz6u/no_new_models_in_llamacon_announced/\"\u003ereacted positively to the fast inference\u003c/a\u003e news:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eI think the future lies with speed for sure. You can do some wild things when you are able to pump out hundreds if not thousands of tokens a second.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eDevelopers interested in gaining access to the Llama API Preview can \u003ca href=\"https://llama.developer.meta.com/join_waitlist\"\u003ejoin the waitlist\u003c/a\u003e. The \u003ca href=\"https://github.com/meta-llama/llama-stack\"\u003eLlama Stack\u003c/a\u003e code is available on GitHub.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Anthony-Alford\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eAnthony Alford\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-05-13T00:00:00Z",
  "modifiedTime": null
}
