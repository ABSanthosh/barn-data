{
  "id": "9924e70b-0a6a-44b7-b036-0a89ee276f6b",
  "title": "AWS Introduces S3 Tables Bucket: Is S3 Becoming a Data Lakehouse?",
  "link": "https://www.infoq.com/news/2025/01/s3-tables-bucket/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "AWS has recently announced S3 Tables Bucket, managed Apache Iceberg tables optimized for analytics workloads. According to the cloud provider, the new option delivers up to 3x faster query performance and up to 10x higher transaction rates for Apache Iceberg tables compared to standard S3 storage. By Renato Losio",
  "author": "Renato Losio",
  "published": "Sat, 04 Jan 2025 05:25:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "AWS",
    "S3",
    "Apache Iceberg",
    "Cloud",
    "Data Lake",
    "AI, ML \u0026 Data Engineering",
    "Development",
    "news"
  ],
  "byline": "Renato Losio",
  "length": 4463,
  "excerpt": "AWS has recently announced S3 Tables Bucket, managed Apache Iceberg tables optimized for analytics workloads. According to the cloud provider, the new option delivers up to 3x faster query performance",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20241210082243/apple-touch-icon.png",
  "text": "AWS has recently announced S3 Tables Bucket, managed Apache Iceberg tables optimized for analytics workloads. According to the cloud provider, the new option delivers up to 3x faster query performance and up to 10x higher transaction rates for Apache Iceberg tables compared to standard S3 storage. In one of his final posts on the AWS Blog, Jeff Barr, vice president and chief evangelist at AWS, writes: Table buckets are the third type of S3 bucket, taking their place alongside the existing general purpose and directory buckets. You can think of a table bucket as an analytics warehouse that can store Iceberg tables with various schemas. Originally developed at Netflix, Apache Iceberg is a high-performance, open-source format for large analytic tables. It allows the use of SQL tables for big data, enabling engines like Spark, Trino, Flink, Presto, and Hive to access and work with the same tables simultaneously. Competing with services like Databricks Delta Lake and Snowflake’s external Iceberg tables, S3 Tables are designed to perform continuous table maintenance, automatically optimizing query efficiency and storage costs. Additionally, they integrate with AWS Glue Data Catalog, enabling data engineers to leverage analytics services such as Amazon Kinesis Data Firehose, Athena, Redshift, EMR, and QuickSight. In a separate article, the cloud provider details how Amazon S3 Tables use compaction to improve query performance. Aliaa Abbas, Anupriti Warade, and Jacob Tardieu explain: Customers often choose Apache Parquet for improved storage and query performance. Additionally, customers use Apache Iceberg to organize Parquet datasets to take advantage of its database-like features such as schema evolution, time travel, and ACID transactions. To illustrate the benefits of automatic compaction, the team compares the query performance of an uncompacted Iceberg table in a general-purpose bucket with that of a newer, optimized table. They write: Our results revealed significant performance improvements when using datasets compacted by S3 Tables. With compaction enabled on the table bucket, we observed query acceleration up to 3.2x, (...) overall, we saw a 2.26x improvement in the total execution time for all eight queries. \"Is S3 becoming a data lakehouse?\" was a common sentiment in the community when the new storage option was announced, with many developers expressing excitement. Andrew Warfield, VP and distinguished engineer at Amazon, summarizes the three main benefits: First, tables are an important primitive for analytics on S3, and second they are quickly changing how we integrate other services with data in S3. The third one is a little more subtle and speculative but in some ways it's the one that I think is the most interesting. It's the idea that S3 Tables, if we get them right, may turn into a much more general primitive outside of analytics engines like Spark. John Kutay, director of product \u0026 engineering at Striim, offers a different perspective, writing: As a data platform vendor, I demand AWS stop building high-level S3 table APIs/catalogs, and instead build low-level convenience features for me to sell a managed data lake service. Javi Santana, co-founder at Tinybird.co, questions the pricing: Storage and operation costs are almost the same as regular S3. But, the main point (...) is the cost of compaction \"$0.05 per GB processed\". Seems like not much but I'm checking some of our customers they process around 1PB (...) That means it's a no-go for real-time workloads when you also want to have fast reads. While some developers highlight missing functionalities. Francesco Mucio, owner and BI/data architect at Untitled Data Company, concludes: To be fair, this is not the first time that AWS released a half-baked feature/tool... and some of them stayed like that. But it's also true that, despite the marketing announcements, not all tools are for everybody. Further extending S3 capabilities, AWS announced at re:Invent the preview of S3 Metadata, a new feature that automatically updates object metadata on S3. Read more on InfoQ. S3 Tables Bucket is currently available in only three U.S. regions. While S3 Tables are generally available, the integration with AWS Glue Data Catalog is still in preview. About the Author Renato Losio",
  "image": "https://res.infoq.com/news/2025/01/s3-tables-bucket/en/headerimage/generatedHeaderImage-1734985636246.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eAWS has recently \u003ca href=\"https://aws.amazon.com/blogs/aws/new-amazon-s3-tables-storage-optimized-for-analytics-workloads/\"\u003eannounced S3 Tables Bucket\u003c/a\u003e, managed Apache Iceberg tables optimized for analytics workloads. According to the cloud provider, the new option delivers up to 3x faster query performance and up to 10x higher transaction rates for Apache Iceberg tables compared to standard S3 storage.\u003c/p\u003e\n\n\u003cp\u003eIn one of his \u003ca href=\"https://aws.amazon.com/blogs/aws/and-thats-a-wrap/\"\u003efinal posts\u003c/a\u003e on the AWS Blog, Jeff Barr, vice president and chief evangelist at AWS, writes:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eTable buckets are the third type of S3 bucket, taking their place alongside the existing general purpose and directory buckets. You can think of a table bucket as an analytics warehouse that can store Iceberg tables with various schemas.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eOriginally developed at Netflix, \u003ca href=\"https://iceberg.apache.org/\"\u003eApache Iceberg\u003c/a\u003e is a high-performance, open-source format for large analytic tables. It allows the use of SQL tables for big data, enabling engines like Spark, Trino, Flink, Presto, and Hive to access and work with the same tables simultaneously.\u003c/p\u003e\n\n\u003cp\u003eCompeting with services like Databricks Delta Lake and Snowflake’s external Iceberg tables, S3 Tables are designed to perform continuous table maintenance, automatically optimizing query efficiency and storage costs. Additionally, they integrate with AWS Glue Data Catalog, enabling data engineers to leverage analytics services such as Amazon Kinesis Data Firehose, Athena, Redshift, EMR, and QuickSight.\u003c/p\u003e\n\n\u003cp\u003eIn a \u003ca href=\"https://aws.amazon.com/blogs/storage/how-amazon-s3-tables-use-compaction-to-improve-query-performance-by-up-to-3-times/\"\u003eseparate article\u003c/a\u003e, the cloud provider details how Amazon S3 Tables use compaction to improve query performance. \u003ca href=\"https://www.linkedin.com/in/aliaa-abbas/\"\u003eAliaa Abbas\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/anupritiwarade/\"\u003eAnupriti Warade\u003c/a\u003e, and \u003ca href=\"https://www.linkedin.com/in/jacobtardieu/\"\u003eJacob Tardieu \u003c/a\u003eexplain:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eCustomers often choose Apache Parquet for improved storage and query performance. Additionally, customers use Apache Iceberg to organize Parquet datasets to take advantage of its database-like features such as schema evolution, time travel, and ACID transactions.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eTo illustrate the benefits of automatic compaction, the team compares the query performance of an uncompacted Iceberg table in a general-purpose bucket with that of a newer, optimized table. They write:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eOur results revealed significant performance improvements when using datasets compacted by S3 Tables. With compaction enabled on the table bucket, we observed query acceleration up to 3.2x, (...) overall, we saw a 2.26x improvement in the total execution time for all eight queries.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u0026#34;\u003ca href=\"https://www.reddit.com/r/aws/comments/1h7dtsh/is_s3_becoming_a_data_lakehouse/\"\u003eIs S3 becoming a data lakehouse?\u003c/a\u003e\u0026#34; was a common sentiment in the community when the new storage option was announced, with many developers expressing excitement. Andrew Warfield, VP and distinguished engineer at Amazon, summarizes the three main \u003ca href=\"https://www.linkedin.com/posts/andywarfield_last-week-at-reinvent-i-posted-about-the-activity-7272657802836238336-FcnT?utm_source=share\u0026amp;utm_medium=member_desktop\"\u003ebenefits\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eFirst, tables are an important primitive for analytics on S3, and second they are quickly changing how we integrate other services with data in S3. The third one is a little more subtle and speculative but in some ways it\u0026#39;s the one that I think is the most interesting. It\u0026#39;s the idea that S3 Tables, if we get them right, may turn into a much more general primitive outside of analytics engines like Spark.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eJohn Kutay, director of product \u0026amp; engineering at Striim, offers a different perspective, \u003ca href=\"https://bsky.app/profile/jkxosound.com/post/3lco7bodbws25\"\u003ewriting\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eAs a data platform vendor, I demand AWS stop building high-level S3 table APIs/catalogs, and instead build low-level convenience features for me to sell a managed data lake service.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eJavi Santana, co-founder at Tinybird.co, \u003ca href=\"https://www.linkedin.com/posts/javisantana_a-quick-analysis-on-the-s3-tables-pricing-activity-7270077869572202496-b3dv?utm_source=share\u0026amp;utm_medium=member_desktop\"\u003equestions\u003c/a\u003e the pricing:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eStorage and operation costs are almost the same as regular S3. But, the main point (...) is the cost of compaction \u0026#34;$0.05 per GB processed\u0026#34;. Seems like not much but I\u0026#39;m checking some of our customers they process around 1PB (...) That means it\u0026#39;s a no-go for real-time workloads when you also want to have fast reads.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhile some developers \u003ca href=\"https://www.linkedin.com/posts/dacort_querying-s3-tables-with-spark-on-kubernetes-activity-7275887749549735936-XSh9\"\u003ehighlight missing functionalities\u003c/a\u003e. Francesco Mucio, owner and BI/data architect at Untitled Data Company, \u003ca href=\"https://www.linkedin.com/feed/update/urn:li:activity:7275887749549735936?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7275887749549735936%2C7275951143099260928%29\u0026amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287275951143099260928%2Curn%3Ali%3Aactivity%3A7275887749549735936%29\"\u003econcludes\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eTo be fair, this is not the first time that AWS released a half-baked feature/tool... and some of them stayed like that. But it\u0026#39;s also true that, despite the marketing announcements, not all tools are for everybody.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eFurther extending S3 capabilities, AWS announced at re:Invent the preview of S3 Metadata, a new feature that \u003ca href=\"https://aws.amazon.com/blogs/aws/introducing-queryable-object-metadata-for-amazon-s3-buckets-preview/\"\u003eautomatically updates object metadata\u003c/a\u003e on S3. Read \u003ca href=\"https://www.infoq.com/news/2024/12/metadata-amazon-s3-buckets-previ\"\u003emore on InfoQ\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eS3 Tables Bucket is currently available in only three U.S. regions. While S3 Tables are generally available, the integration with AWS Glue Data Catalog is still in preview.\u003c/p\u003e\n\n\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Renato-Losio\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRenato Losio\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-01-04T00:00:00Z",
  "modifiedTime": null
}
