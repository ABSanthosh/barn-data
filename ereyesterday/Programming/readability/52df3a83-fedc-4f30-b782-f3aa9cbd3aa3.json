{
  "id": "52df3a83-fedc-4f30-b782-f3aa9cbd3aa3",
  "title": "AI Assistant expands with cutting-edge models",
  "link": "https://blog.jetbrains.com/ai/2025/02/ai-assistant-expands-with-cutting-edge-models/",
  "description": "JetBrains AI Assistant offers you the flexibility to choose from a range of advanced cloud-based LLMs from leading providers or use locally hosted models for increased data privacy. We’re continuously updating the platform with the latest high-performance models. Starting from JetBrains IDEs 2024.3.2, you’ll have access to Anthropic’s Claude Sonnet 3.5 and Haiku 3.5, OpenAI’s […]",
  "author": "Daniela Bentrup",
  "published": "Tue, 11 Feb 2025 13:06:12 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": [
    "news",
    "ai-assistant"
  ],
  "byline": "Daniela Bentrup",
  "length": 2447,
  "excerpt": "JetBrains AI Assistant offers you the flexibility to choose from a range of advanced cloud-based LLMs from leading providers or use locally hosted models for increased data privacy. We’re continuously",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "NewsAI Assistant expands with cutting-edge models JetBrains AI Assistant offers you the flexibility to choose from a range of advanced cloud-based LLMs from leading providers or use locally hosted models for increased data privacy. We’re continuously updating the platform with the latest high-performance models. Starting from JetBrains IDEs 2024.3.2, you’ll have access to Anthropic’s Claude Sonnet 3.5 and Haiku 3.5, OpenAI’s o1, o1-mini, and o3-mini model, and local LLM support via LM Studio. Try AI Assistant Claude models are now available Our newest update includes support for the most recent Claude models – Claude 3.5 Sonnet and Claude 3.5 Haiku – to enhance your AI Assistant development experience. You can now customize your workflows by manually selecting Claude models for chat-based interactions, enabling tailored responses for your specific needs. Latest OpenAI models We’ve added access to OpenAI o1, o1-mini, and o3-mini to offer an even more adaptable and personalized experience with JetBrains AI Assistant. OpenAI’s o1 model introduces a new series of reasoning models for solving complex problems. The o1 model is designed to take more time to think before responding. OpenAI’s o3-mini and o1-mini models are ideal if you need faster and more cost-efficient reasoning capabilities. These compact OpenAI models offer faster processing than o1 and are tailored for coding, scientific, and mathematical tasks. LM Studio meets JetBrains AI Assistant This update introduces the option to connect AI chat to locally hosted models using LM Studio. The LM Studio platform offers a user-friendly interface for managing and running AI models on your local machine. Using local LLMs increases data privacy and allows you to customize your environment to meet specific requirements. To use this feature, you will need to configure the connection to your LM Studio in AI Assistant’s settings. Explore these new models and stay tuned for more exciting news in the future! Subscribe to JetBrains AI Blog updates",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2025/02/as-social_share_blog_1280x720_en-2.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                    \t\t\t\t\u003cp\u003e\u003ca href=\"https://blog.jetbrains.com/ai/category/news/\"\u003eNews\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"major-updates\"\u003eAI Assistant expands with cutting-edge models\u003c/h2\u003e                    \n                    \n\u003cp\u003eJetBrains AI Assistant offers you the flexibility to choose from a range of advanced cloud-based LLMs from leading providers or use locally hosted models for increased data privacy. We’re continuously updating the platform with the latest high-performance models. Starting from JetBrains IDEs 2024.3.2, you’ll have access to Anthropic’s Claude Sonnet 3.5 and Haiku 3.5, OpenAI’s o1, o1-mini, and o3-mini model, and local LLM support via LM Studio.\u003c/p\u003e\n\n\n\u003cp\u003e\u003ca href=\"https://www.jetbrains.com/ai/#plans-and-pricing\" target=\"_blank\" rel=\"noopener\"\u003e\u003ci\u003e\u003c/i\u003eTry AI Assistant\u003c/a\u003e\u003c/p\u003e\n\n\n\u003ch2\u003eClaude models are now available\n\u003c/h2\u003e\n\n\n\n\u003cp\u003eOur newest update includes support for the \u003ca href=\"https://blog.jetbrains.com/ai/2025/02/jetbrains-ai-assistant-now-supports-claude-models-via-amazon-bedrock/\"\u003emost recent Claude models\u003c/a\u003e – Claude 3.5 Sonnet and Claude 3.5 Haiku – to enhance your AI Assistant development experience.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can now customize your workflows by manually selecting Claude models for chat-based interactions, enabling tailored responses for your specific needs. \u003c/p\u003e\n\n\n\n\u003ch2\u003eLatest OpenAI models\u003c/h2\u003e\n\n\n\n\u003cp\u003eWe’ve added access to \u003ca href=\"https://blog.jetbrains.com/ai/2025/02/openai-o1-o1-mini-and-o3-mini-models-now-available-in-jetbrains-ai-assistant/\"\u003eOpenAI o1, o1-mini, and o3-mini\u003c/a\u003e to offer an even more adaptable and personalized experience with JetBrains AI Assistant. OpenAI’s o1 model introduces a new series of reasoning models for solving complex problems. The o1 model is designed to take more time to think before responding.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI’s o3-mini and o1-mini models are ideal if you need faster and more cost-efficient reasoning capabilities. These compact OpenAI models offer faster processing than o1 and are tailored for coding, scientific, and mathematical tasks.\u003c/p\u003e\n\n\n\n\u003ch2\u003eLM Studio meets JetBrains AI Assistant\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis update introduces the option to connect AI chat to locally hosted models using \u003ca href=\"https://lmstudio.ai/\" target=\"_blank\" rel=\"noopener\"\u003eLM Studio\u003c/a\u003e. The LM Studio platform offers a user-friendly interface for managing and running AI models on your local machine. Using local LLMs increases data privacy and allows you to customize your environment to meet specific requirements. To use this feature, you will need to configure the connection to your LM Studio in AI Assistant’s settings.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cimg decoding=\"async\" fetchpriority=\"high\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeBGGLinCOh5GvUJVlv4FBLGt4FIGfg1IRSirMPN70C-Kf4lNg3gsNXtcLVDIRNion5RjC500ksVc4Us2zLxfzgoK7dlvEopuIb_D8cWx96Hr8J23Q-EXkzm12sFZZz46iddaWU0w?key=5rTLeDcSJWTt_HdoQicXfu7p\" width=\"624\" height=\"197\"/\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eExplore these new models and stay tuned for more exciting news in the future!\u003c/p\u003e\n                    \n                                                                                                                                                                                                                            \u003cdiv\u003e\n                                \u003cdiv\u003e\n                                                                            \u003ch4\u003eSubscribe to JetBrains AI Blog updates\u003c/h4\u003e\n                                                                                                            \n                                \u003c/div\u003e\n                                \n                                \u003cp\u003e\u003cimg src=\"https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg\" alt=\"image description\"/\u003e\n                                                                    \u003c/p\u003e\n                            \u003c/div\u003e\n                                                            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
