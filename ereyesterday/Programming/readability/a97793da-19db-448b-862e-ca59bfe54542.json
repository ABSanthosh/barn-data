{
  "id": "a97793da-19db-448b-862e-ca59bfe54542",
  "title": "JetBrains AI Assistant Integrates Google Gemini and Local LLMs",
  "link": "https://blog.jetbrains.com/ai/2024/11/jetbrains-ai-assistant-integrates-google-gemini-and-local-llms/",
  "description": "Weâ€™ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. Whatâ€™s special about Google models? Gemini 1.5 Pro and 1.5 Flash on Google Cloudâ€™s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several [â€¦]",
  "author": "Irina Mariasova",
  "published": "Fri, 22 Nov 2024 14:55:23 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": [
    "news",
    "gemini",
    "google",
    "jetbrains-ai",
    "mellum"
  ],
  "byline": "Irina Mariasova",
  "length": 1792,
  "excerpt": "Weâ€™ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. Whatâ€™s special about Google mo",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "NewsJetBrains AI Assistant Integrates Google Gemini and Local LLMs Weâ€™ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. Whatâ€™s special about Google models? Gemini 1.5 Pro and 1.5 Flash on Google Cloudâ€™s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several new use cases. Gemini Flash 1.5 will specifically help when cost efficiency at high volume and low latency is paramount.Â Â  How to try Google models Starting from the 2024.3 version of JetBrains AI Assistant, you can pick your preferred LLM right in the AI chat. This expanded selection allows you to customize the AI chatâ€™s responses to your specific workflow, offering a more adaptable and personalized experience.Â  Local model support via Ollama In addition to cloud-based models, you can now connect the AI chat to local models available through Ollama. This is particularly useful if you need more control over your AI models, and it offers enhanced privacy, flexibility, and the ability to run models on local hardware. To add an Ollama model to the chat, enable Ollama support in AI Assistantâ€™s settings and configure the connection to your Ollama instance.Â  Explore these new models, and let us know what you think! ðŸŒŸ Subscribe to JetBrains AI Blog updates",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2024/11/jbai-social_share_blog_1280x720_en-2.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                    \t\t\t\t\u003cp\u003e\u003ca href=\"https://blog.jetbrains.com/ai/category/news/\"\u003eNews\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"major-updates\"\u003eJetBrains AI Assistant Integrates Google Gemini and Local LLMs\u003c/h2\u003e                    \n                    \n\u003cp\u003eWeâ€™ve now added Gemini 1.5 Pro and Gemini 1.5 Flash to the lineup of LLMs used by JetBrains AI Assistant. These LLMs join forces with OpenAI models and local models. \u003c/p\u003e\n\n\n\n\u003ch2\u003eWhatâ€™s special about Google models?\u003c/h2\u003e\n\n\n\n\u003cp\u003eGemini 1.5 Pro and 1.5 Flash on Google Cloudâ€™s Vertex AI will deliver advanced reasoning and impressive performance, unlocking several new use cases. Gemini Flash 1.5 will specifically help when cost efficiency at high volume and low latency is paramount.Â Â \u003c/p\u003e\n\n\n\n\u003ch2\u003eHow to try Google models\u003c/h2\u003e\n\n\n\n\u003cp\u003eStarting from the \u003ca href=\"https://blog.jetbrains.com/ai/2024/11/jetbrains-ai-assistant-2024-3/\"\u003e2024.3 version of JetBrains AI Assistant\u003c/a\u003e, you can pick your preferred LLM right in the AI chat. This expanded selection allows you to customize the AI chatâ€™s responses to your specific workflow, offering a more adaptable and personalized experience.Â \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeEjL15eYljlJlQQCzWvFNcjlatWbEqVMkp6mcEE-amMnF8vDR04JYcSKqNGPAqb9n60pxaZZx-XZwF5tE3Vny4FHvN7l6AB7YOhavKxsqGIX6OrEYrqaMVXlVX-P8gVKGlVbdPtA?key=l9CleK8rUDp4xnOhCF3QZqG8\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003ch2\u003eLocal model support via Ollama\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn addition to cloud-based models, you can now connect the AI chat to local models available through \u003ca href=\"https://ollama.com/\" target=\"_blank\" rel=\"noopener\"\u003eOllama\u003c/a\u003e. This is particularly useful if you need more control over your AI models, and it offers enhanced privacy, flexibility, and the ability to run models on local hardware.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo add an Ollama model to the chat, enable Ollama support in AI Assistantâ€™s settings and configure the connection to your Ollama instance.Â \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfxECpyxl41SzCCjh_uFUtPgxIC0ggx2c0KTKpviyVaMhJuTmweBmDQJKTfLdaqbMIuqLm1kfzuekhcR-ZYPgwDeXWsdt8r6ixs9MD0TFddecEPaF--k6wXIW1aIGxGKK_0-dajxQ?key=l9CleK8rUDp4xnOhCF3QZqG8\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eExplore these new models, and let us know what you think! ðŸŒŸ\u003c/p\u003e\n                    \n                                                                                                                                                                                                                            \u003cdiv\u003e\n                                \u003cdiv\u003e\n                                                                            \u003ch4\u003eSubscribe to JetBrains AI Blog updates\u003c/h4\u003e\n                                                                                                            \n                                \u003c/div\u003e\n                                \n                                \u003cp\u003e\u003cimg src=\"https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg\" alt=\"image description\"/\u003e\n                                                                    \u003c/p\u003e\n                            \u003c/div\u003e\n                                                            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
