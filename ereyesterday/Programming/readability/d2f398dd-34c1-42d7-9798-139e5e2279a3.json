{
  "id": "d2f398dd-34c1-42d7-9798-139e5e2279a3",
  "title": "Meta Releases NotebookLlama: Open-Source PDF to Podcast Toolkit",
  "link": "https://www.infoq.com/news/2024/11/meta-notebook-llama/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Meta has released NotebookLlama, an open-source toolkit designed to convert PDF documents into podcasts, providing developers with a structured, accessible PDF-to-audio workflow. As an open-source alternative to Google’s NotebookLM, NotebookLlama guides users through a four-step process that converts PDF text into audio content. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Sun, 17 Nov 2024 15:55:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Artificial Intelligence",
    "podcast",
    "Google",
    "Transcripts",
    "Machine Learning",
    "Open Source",
    "PDF",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 2935,
  "excerpt": "Meta has released NotebookLlama, an open-source toolkit designed to convert PDF documents into podcasts, providing developers with a structured, accessible PDF-to-audio workflow. As an open-source alt",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20241112123203/apple-touch-icon.png",
  "text": "Meta has released NotebookLlama, an open-source toolkit designed to convert PDF documents into podcasts, providing developers with a structured, accessible PDF-to-audio workflow. As an open-source alternative to Google’s NotebookLM, NotebookLlama guides users through a four-step process that converts PDF text into audio content, without needing prior experience with large language models (LLMs) or audio processing. The toolkit offers a practical way for users to experiment with LLMs and TTS models to create conversational, audio-ready content. NotebookLlama's workflow includes: PDF Pre-processing: Using the Llama-3.2-1B-Instruct model, the toolkit cleans and formats PDF content into plain text, maintaining structural integrity. Transcript Generation: The Llama-3.1-70B-Instruct model crafts the plain text into a script suitable for podcast format, selected for its capabilities in creating engaging, conversational text. Dramatize Podcast: The Llama-3.1-8B-Instruct model further adjusts the transcript, enhancing its conversational appeal for audio audiences. Text-to-Speech (TTS) Conversion: The final audio is produced using Parler-tts and bark TTS models, with prompts tailored to simulate distinct speakers. (Source: NotebookLlama GitHub Repository) Running NotebookLlama requires a GPU server or an API provider for the larger models. The 70B model, for instance, needs around 140GB of aggregated memory. The toolkit is available through GitHub, and users have to log in to Hugging Face for model access. NotebookLlama has received significant community feedback since its launch. While users appreciate the flexibility of the open-source model, several pointed out limitations when comparing it to Google’s proprietary system, particularly in voice quality. In response to AI-generated text quality, John K. Moran added:  While NotebookLlama offers exciting features, the ongoing issue of hallucinations in AI-generated content is a real concern. Accuracy is paramount, especially when it comes to generating documentation or analysis for code. Both NotebookLlama and NotebookLM will need to prioritize this to gain trust among developers and users alike. Future improvements for NotebookLlama include refining the Text-to-Speech model to achieve more natural-sounding audio and exploring the potential of using two LLMs to create interactive podcast scripts, enhancing the conversational feel. The developers are also experimenting with larger models, like the 405B, to improve transcript quality. Other planned updates include broader input options, such as website or YouTube links, and better prompt design. Meta encourages experimentation with model selection and prompt tuning. The community is invited to contribute and create PRs.  About the Author Robert Krzaczyński",
  "image": "https://res.infoq.com/news/2024/11/meta-notebook-llama/en/headerimage/generatedHeaderImage-1731858581718.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/NotebookLlama\"\u003eMeta has released NotebookLlama\u003c/a\u003e, an open-source toolkit designed to convert PDF documents into podcasts, providing developers with a structured, accessible PDF-to-audio workflow. As an open-source alternative to Google’s NotebookLM, NotebookLlama guides users through a four-step process that converts PDF text into audio content, without needing prior experience with large language models (LLMs) or audio processing. The toolkit offers a practical way for users to experiment with LLMs and TTS models to create conversational, audio-ready content.\u003c/p\u003e\n\n\u003cp\u003eNotebookLlama\u0026#39;s workflow includes:\u003c/p\u003e\n\n\u003col\u003e\n\t\u003cli\u003e\u003cstrong\u003ePDF Pre-processing\u003c/strong\u003e: Using the Llama-3.2-1B-Instruct model, the toolkit cleans and formats PDF content into plain text, maintaining structural integrity.\u003c/li\u003e\n\t\u003cli\u003e\u003cstrong\u003eTranscript Generation\u003c/strong\u003e: The Llama-3.1-70B-Instruct model crafts the plain text into a script suitable for podcast format, selected for its capabilities in creating engaging, conversational text.\u003c/li\u003e\n\t\u003cli\u003e\u003cstrong\u003eDramatize Podcast\u003c/strong\u003e: The Llama-3.1-8B-Instruct model further adjusts the transcript, enhancing its conversational appeal for audio audiences.\u003c/li\u003e\n\t\u003cli\u003e\u003cstrong\u003eText-to-Speech (TTS) Conversion\u003c/strong\u003e: The final audio is produced using Parler-tts and bark TTS models, with prompts tailored to simulate distinct speakers.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003cimg alt=\"NotebookLlama \" data-src=\"news/2024/11/meta-notebook-llama/en/resources/1notebookllama-1731858580641.png\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2024/11/meta-notebook-llama/en/resources/1notebookllama-1731858580641.png\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003e(Source: NotebookLlama GitHub Repository)\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eRunning NotebookLlama requires a GPU server or an API provider for the larger models. The 70B model, for instance, needs around 140GB of aggregated memory. The toolkit is available through \u003ca href=\"https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/NotebookLlama\"\u003eGitHub\u003c/a\u003e, and users have to log in to \u003ca href=\"https://huggingface.co/login?next=%2Fsettings%2Ftokens\"\u003eHugging Face\u003c/a\u003e for model access.\u003c/p\u003e\n\n\u003cp\u003eNotebookLlama has received significant community feedback since its launch. While users appreciate the flexibility of the open-source model, several \u003ca href=\"https://www.reddit.com/r/LocalLLaMA/comments/1gdk92b/comment/lu2fqhf/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003epointed out\u003c/a\u003e limitations when comparing it to Google’s proprietary system, particularly in voice quality.\u003c/p\u003e\n\n\u003cp\u003eIn response to AI-generated text quality, John K. Moran \u003ca href=\"https://www.linkedin.com/feed/update/urn:li:activity:7256503701136146432?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7256503701136146432%2C7256545329087434752%29\u0026amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287256545329087434752%2Curn%3Ali%3Aactivity%3A7256503701136146432%29\"\u003eadded\u003c/a\u003e: \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eWhile NotebookLlama offers exciting features, the ongoing issue of hallucinations in AI-generated content is a real concern. Accuracy is paramount, especially when it comes to generating documentation or analysis for code. Both NotebookLlama and NotebookLM will need to prioritize this to gain trust among developers and users alike.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eFuture improvements for NotebookLlama include refining the Text-to-Speech model to achieve more natural-sounding audio and exploring the potential of using two LLMs to create interactive podcast scripts, enhancing the conversational feel. The developers are also experimenting with larger models, like the 405B, to improve transcript quality. Other planned updates include broader input options, such as website or YouTube links, and better prompt design.\u003c/p\u003e\n\n\u003cp\u003eMeta encourages experimentation with model selection and prompt tuning. The community is invited to contribute and create PRs. \u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2024-11-17T00:00:00Z",
  "modifiedTime": null
}
