{
  "id": "bf5c658a-75af-4ace-851d-80c8536b151d",
  "title": "FM-Intent: Predicting User Session Intent with Hierarchical Multi-Task Learning",
  "link": "https://netflixtechblog.com/fm-intent-predicting-user-session-intent-with-hierarchical-multi-task-learning-94c75e18f4b8?source=rss----2615bd06b42e---4",
  "description": "",
  "author": "Netflix Technology Blog",
  "published": "Wed, 21 May 2025 16:28:07 GMT",
  "source": "https://netflixtechblog.com/feed",
  "categories": [
    "deep-learning",
    "foundation-models",
    "ai",
    "machine-learning",
    "personalization"
  ],
  "byline": "Netflix Technology Blog",
  "length": 11328,
  "excerpt": "Authors: Sejoon Oh, Moumita Bhattacharya, Yesu Feng, Sudarshan Lamkhede, Ko-Jen Hsiao, and Justin Basilico Recommender systems have become essential components of digital services across e-commerce…",
  "siteName": "Netflix TechBlog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "Authors: Sejoon Oh, Moumita Bhattacharya, Yesu Feng, Sudarshan Lamkhede, Ko-Jen Hsiao, and Justin BasilicoMotivationRecommender systems have become essential components of digital services across e-commerce, streaming media, and social networks [1, 2]. At Netflix, these systems drive significant product and business impact by connecting members with relevant content at the right time [3, 4]. While our recommendation foundation model (FM) has made substantial progress in understanding user preferences through large-scale learning from interaction histories (please refer to this article about FM @ Netflix), there is an opportunity to further enhance its capabilities. By extending FM to incorporate the prediction of underlying user intents, we aim to enrich its understanding of user sessions beyond next-item prediction, thereby offering a more comprehensive and nuanced recommendation experience.Recent research has highlighted the importance of understanding user intent in online platforms [5, 6, 7, 8]. As Xia et al. [8] demonstrated at Pinterest, predicting a user’s future intent can lead to more accurate and personalized recommendations. However, existing intent prediction approaches typically employ simple multi-task learning that adds intent prediction heads to next-item prediction models without establishing a hierarchical relationship between these tasks.To address these limitations, we introduce FM-Intent, a novel recommendation model that enhances our foundation model through hierarchical multi-task learning. FM-Intent captures a user’s latent session intent using both short-term and long-term implicit signals as proxies, then leverages this intent prediction to improve next-item recommendations. Unlike conventional approaches, FM-Intent establishes a clear hierarchy where intent predictions directly inform item recommendations, creating a more coherent and effective recommendation pipeline.FM-Intent makes three key contributions:A novel recommendation model that captures user intent on the Netflix platform and enhances next-item prediction using this intent information.A hierarchical multi-task learning approach that effectively models both short-term and long-term user interests.Comprehensive experimental validation showing significant performance improvements over state-of-the-art models, including our foundation model.Understanding User Intent in NetflixIn the Netflix ecosystem, user intent manifests through various interaction metadata, as illustrated in Figure 1. FM-Intent leverages these implicit signals to predict both user intent and next-item recommendations.Figure 1: Overview of user engagement data in Netflix. User intent can be associated with several interaction metadata. We leverage various implicit signals to predict user intent and next-item.In Netflix, there can be multiple types of user intents. For instance,Action Type: Categories reflecting what users intend to do on Netflix, such as discovering new content versus continuing previously started content. For example, when a member plays a follow-up episode of something they were already watching, this can be categorized as “continue watching” intent.Genre Preference: The pre-defined genre labels (e.g., Action, Thriller, Comedy) that indicate a user’s content preferences during a session. These preferences can shift significantly between sessions, even for the same user.Movie/Show Type: Whether a user is looking for a movie (typically a single, longer viewing experience) or a TV show (potentially multiple episodes of shorter duration).Time-since-release: Whether the user prefers newly released content, recent content (e.g., between a week and a month), or evergreen catalog titles.These dimensions serve as proxies for the latent user intent, which is often not directly observable but crucial for providing relevant recommendations.FM-Intent Model ArchitectureFM-Intent employs a hierarchical multi-task learning approach with three major components, as illustrated in Figure 2.Figure 2: An architectural illustration of our hierarchical multi-task learning model FM-Intent for user intent and item predictions. We use ground-truth intent and item-ID labels to optimize predictions.1. Input Feature Sequence FormationThe first component constructs rich input features by combining interaction metadata. The input feature for each interaction combines categorical embeddings and numerical features, creating a comprehensive representation of user behavior.2. User Intent PredictionThe intent prediction component processes the input feature sequence through a Transformer encoder and generates predictions for multiple intent signals.The Transformer encoder effectively models the long-term interest of users through multi-head attention mechanisms. For each prediction task, the intent encoding is transformed into prediction scores via fully-connected layers.A key innovation in FM-Intent is the attention-based aggregation of individual intent predictions. This approach generates a comprehensive intent embedding that captures the relative importance of different intent signals for each user, providing valuable insights for personalization and explanation.3. Next-Item Prediction with Hierarchical Multi-Task LearningThe final component combines the input features with the user intent embedding to make more accurate next-item recommendations.FM-Intent employs hierarchical multi-task learning where intent predictions are conducted first, and their results are used as input features for the next-item prediction task. This hierarchical relationship ensures that the next-item recommendations are informed by the predicted user intent, creating a more coherent and effective recommendation model.Offline ResultsWe conducted comprehensive offline experiments on sampled Netflix user engagement data to evaluate FM-Intent’s performance. Note that FM-Intent uses a much smaller dataset for training compared to the FM production model due to its complex hierarchical prediction architecture.Next-Item and Next-Intent Prediction AccuracyTable 1 compares FM-Intent with several state-of-the-art sequential recommendation models, including our production model (FM-Intent-V0).Table 1: Next-item and next-intent prediction results of baselines and our proposed method FM-Intent on the Netflix user engagement dataset.All metrics are represented as relative % improvements compared to the SOTA baseline: TransAct. N/A indicates that a model is not capable of predicting a certain intent. Note that we added additional fully-connected layers to LSTM, GRU, and Transformer baselines in order to predict user intent, while we used original implementations for other baselines. FM-Intent demonstrates statistically significant improvement of 7.4% in next-item prediction accuracy compared to the best baseline (TransAct).Most baseline models show limited performance as they either cannot predict user intent or cannot incorporate intent predictions into next-item recommendations. Our production model (FM-Intent-V0) performs well but lacks the ability to predict and leverage user intent. Note that FM-Intent-V0 is trained with a smaller dataset for a fair comparison with other models; the actual production model is trained with a much larger dataset.Qualitative Analysis: User ClusteringFigure 3: K-means++ (K=10) clustering of user intent embeddings found by FM-Intent; FM-Intent finds unique clusters of users that share the similar intent.FM-Intent generates meaningful user intent embeddings that can be used for clustering users with similar intents. Figure 3 visualizes 10 distinct clusters identified through K-means++ clustering. These clusters reveal meaningful user segments with distinct viewing patterns:Users who primarily discover new content versus those who continue watching recent/favorite content.Genre enthusiasts (e.g., anime/kids content viewers).Users with specific viewing patterns (e.g., Rewatchers versus casual viewers).Potential Applications of FM-IntentFM-Intent has been successfully integrated into Netflix’s recommendation ecosystem, can be leveraged for several downstream applications:Personalized UI Optimization: The predicted user intent could inform the layout and content selection on the Netflix homepage, emphasizing different rows based on whether users are in discovery mode, continue-watching mode, or exploring specific genres.Analytics and User Understanding: Intent embeddings and clusters provide valuable insights into viewing patterns and preferences, informing content acquisition and production decisions.Enhanced Recommendation Signals: Intent predictions serve as features for other recommendation models, improving their accuracy and relevance.Search Optimization: Real-time intent predictions help prioritize search results based on the user’s current session intent.ConclusionFM-Intent represents an advancement in Netflix’s recommendation capabilities by enhancing them with hierarchical multi-task learning for user intent prediction. Our comprehensive experiments demonstrate that FM-Intent significantly outperforms state-of-the-art models, including our prior foundation model that focused solely on next-item prediction. By understanding not just what users might watch next but what underlying intents users have, we can provide more personalized, relevant, and satisfying recommendations.AcknowledgementsWe thank our stunning colleagues in the Foundation Model team \u0026 AIMS org. for their valuable feedback and discussions. We also thank our partner teams for getting this up and running in production.References[1] Amatriain, X., \u0026 Basilico, J. (2015). Recommender systems in industry: A netflix case study. In Recommender systems handbook (pp. 385–419). Springer.[2] Gomez-Uribe, C. A., \u0026 Hunt, N. (2015). The netflix recommender system: Algorithms, business value, and innovation. ACM Transactions on Management Information Systems (TMIS), 6(4), 1–19.[3] Jannach, D., \u0026 Jugovac, M. (2019). Measuring the business value of recommender systems. ACM Transactions on Management Information Systems (TMIS), 10(4), 1–23.[4] Bhattacharya, M., \u0026 Lamkhede, S. (2022). Augmenting Netflix Search with In-Session Adapted Recommendations. In Proceedings of the 16th ACM Conference on Recommender Systems (pp. 542–545).[5] Chen, Y., Liu, Z., Li, J., McAuley, J., \u0026 Xiong, C. (2022). Intent contrastive learning for sequential recommendation. In Proceedings of the ACM Web Conference 2022 (pp. 2172–2182).[6] Ding, Y., Ma, Y., Wong, W. K., \u0026 Chua, T. S. (2021). Modeling instant user intent and content-level transition for sequential fashion recommendation. IEEE Transactions on Multimedia, 24, 2687–2700.[7] Liu, Z., Chen, H., Sun, F., Xie, X., Gao, J., Ding, B., \u0026 Shen, Y. (2021). Intent preference decoupling for user representation on online recommender system. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence (pp. 2575–2582).[8] Xia, X., Eksombatchai, P., Pancha, N., Badani, D. D., Wang, P. W., Gu, N., Joshi, S. V., Farahpour, N., Zhang, Z., \u0026 Zhai, A. (2023). TransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 5249–5259).",
  "image": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*3pMgS5u3TepefPLB",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://netflixtechblog.medium.com/?source=post_page---byline--94c75e18f4b8---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Netflix Technology Blog\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*BJWRqfSMf9Da9vsXG9EBRQ.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp id=\"e0a5\"\u003eAuthors: \u003ca href=\"https://www.linkedin.com/in/sejoon-oh/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSejoon Oh\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/moumitab/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMoumita Bhattacharya\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/yesufeng/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eYesu Feng\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/sudarshanlamkhede/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSudarshan Lamkhede\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/markhsiao/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKo-Jen Hsiao\u003c/a\u003e, and \u003ca href=\"https://www.linkedin.com/in/jbasilico/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJustin Basilico\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"115a\"\u003eMotivation\u003c/h2\u003e\u003cp id=\"cb4a\"\u003eRecommender systems have become essential components of digital services across e-commerce, streaming media, and social networks [1, 2]. At Netflix, these systems drive significant product and business impact by connecting members with relevant content at the right time [3, 4]. While our recommendation \u003cstrong\u003efoundation model (FM)\u003c/strong\u003e has made substantial progress in understanding user preferences through large-scale learning from interaction histories (please refer to this \u003ca href=\"https://netflixtechblog.medium.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39\" rel=\"noopener\"\u003e\u003cstrong\u003e\u003cem\u003earticle\u003c/em\u003e\u003c/strong\u003e\u003c/a\u003e about FM @ Netflix), there is an opportunity to further enhance its capabilities. By extending FM to incorporate the prediction of underlying user intents, we aim to enrich its understanding of user sessions beyond next-item prediction, thereby offering a more comprehensive and nuanced recommendation experience.\u003c/p\u003e\u003cp id=\"1371\"\u003eRecent research has highlighted the importance of understanding user intent in online platforms [5, 6, 7, 8]. As Xia et al. [8] demonstrated at Pinterest, predicting a user’s future intent can lead to more accurate and personalized recommendations. However, existing intent prediction approaches typically employ simple multi-task learning that adds intent prediction heads to next-item prediction models without establishing a hierarchical relationship between these tasks.\u003c/p\u003e\u003cp id=\"62f1\"\u003eTo address these limitations, we introduce \u003cstrong\u003e\u003cem\u003eFM-Intent\u003c/em\u003e\u003c/strong\u003e, a novel recommendation model that enhances our foundation model through hierarchical multi-task learning. FM-Intent captures a user’s latent session intent using both short-term and long-term implicit signals as proxies, then leverages this intent prediction to improve next-item recommendations. Unlike conventional approaches, FM-Intent establishes a clear hierarchy where intent predictions directly inform item recommendations, creating a more coherent and effective recommendation pipeline.\u003c/p\u003e\u003cp id=\"16e8\"\u003eFM-Intent makes three key contributions:\u003c/p\u003e\u003col\u003e\u003cli id=\"9b16\"\u003eA novel recommendation model that captures user intent on the Netflix platform and enhances next-item prediction using this intent information.\u003c/li\u003e\u003cli id=\"538d\"\u003eA hierarchical multi-task learning approach that effectively models both short-term and long-term user interests.\u003c/li\u003e\u003cli id=\"c154\"\u003eComprehensive experimental validation showing significant performance improvements over state-of-the-art models, including our foundation model.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"04a3\"\u003eUnderstanding User Intent in Netflix\u003c/h2\u003e\u003cp id=\"d624\"\u003eIn the Netflix ecosystem, user intent manifests through various interaction metadata, as illustrated in Figure 1. FM-Intent leverages these implicit signals to predict both user intent and next-item recommendations.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"cd73\"\u003e\u003cem\u003eFigure 1: Overview of user engagement data in Netflix. User intent can be associated with several interaction metadata. We leverage various implicit signals to predict user intent and next-item.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"798c\"\u003eIn Netflix, there can be multiple types of user intents. For instance,\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"78cd\"\u003e\u003cstrong\u003e\u003cem\u003eAction Type\u003c/em\u003e\u003c/strong\u003e: Categories reflecting what users intend to do on Netflix, such as discovering new content versus continuing previously started content. For example, when a member plays a follow-up episode of something they were already watching, this can be categorized as “continue watching” intent.\u003c/p\u003e\u003cp id=\"5e27\"\u003e\u003cstrong\u003e\u003cem\u003eGenre Preference\u003c/em\u003e\u003c/strong\u003e: The pre-defined genre labels (e.g., Action, Thriller, Comedy) that indicate a user’s content preferences during a session. These preferences can shift significantly between sessions, even for the same user.\u003c/p\u003e\u003cp id=\"39f6\"\u003e\u003cstrong\u003e\u003cem\u003eMovie/Show Type\u003c/em\u003e\u003c/strong\u003e: Whether a user is looking for a movie (typically a single, longer viewing experience) or a TV show (potentially multiple episodes of shorter duration).\u003c/p\u003e\u003cp id=\"ebf9\"\u003e\u003cstrong\u003e\u003cem\u003eTime-since-release\u003c/em\u003e\u003c/strong\u003e: Whether the user prefers newly released content, recent content (e.g., between a week and a month), or evergreen catalog titles.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"cff1\"\u003eThese dimensions serve as proxies for the latent user intent, which is often not directly observable but crucial for providing relevant recommendations.\u003c/p\u003e\u003ch2 id=\"9ea0\"\u003eFM-Intent Model Architecture\u003c/h2\u003e\u003cp id=\"30e5\"\u003eFM-Intent employs a hierarchical multi-task learning approach with three major components, as illustrated in Figure 2.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"0f7c\"\u003e\u003cem\u003eFigure 2: An architectural illustration of our hierarchical multi-task learning model FM-Intent for user intent and item predictions. We use ground-truth intent and item-ID labels to optimize predictions.\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"2f73\"\u003e1. Input Feature Sequence Formation\u003c/h2\u003e\u003cp id=\"852b\"\u003eThe first component constructs rich input features by combining interaction metadata. The input feature for each interaction combines categorical embeddings and numerical features, creating a comprehensive representation of user behavior.\u003c/p\u003e\u003ch2 id=\"be50\"\u003e2. User Intent Prediction\u003c/h2\u003e\u003cp id=\"754b\"\u003eThe intent prediction component processes the input feature sequence through a Transformer encoder and generates predictions for multiple intent signals.\u003c/p\u003e\u003cp id=\"7364\"\u003eThe Transformer encoder effectively models the long-term interest of users through multi-head attention mechanisms. For each prediction task, the intent encoding is transformed into prediction scores via fully-connected layers.\u003c/p\u003e\u003cp id=\"eefb\"\u003eA key innovation in FM-Intent is the attention-based aggregation of individual intent predictions. This approach generates a comprehensive intent embedding that captures the relative importance of different intent signals for each user, providing valuable insights for personalization and explanation.\u003c/p\u003e\u003ch2 id=\"19c9\"\u003e3. Next-Item Prediction with Hierarchical Multi-Task Learning\u003c/h2\u003e\u003cp id=\"6faa\"\u003eThe final component combines the input features with the user intent embedding to make more accurate next-item recommendations.\u003c/p\u003e\u003cp id=\"32a2\"\u003eFM-Intent employs hierarchical multi-task learning where intent predictions are conducted first, and their results are used as input features for the next-item prediction task. This hierarchical relationship ensures that the next-item recommendations are informed by the predicted user intent, creating a more coherent and effective recommendation model.\u003c/p\u003e\u003ch2 id=\"6df1\"\u003eOffline Results\u003c/h2\u003e\u003cp id=\"f9d0\"\u003eWe conducted comprehensive offline experiments on sampled Netflix user engagement data to evaluate FM-Intent’s performance. Note that FM-Intent uses a much smaller dataset for training compared to the FM production model due to its complex hierarchical prediction architecture.\u003c/p\u003e\u003ch2 id=\"eb63\"\u003eNext-Item and Next-Intent Prediction Accuracy\u003c/h2\u003e\u003cp id=\"47fb\"\u003eTable 1 compares FM-Intent with several state-of-the-art sequential recommendation models, including our production model (FM-Intent-V0).\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"e95c\"\u003e\u003cem\u003eTable 1: Next-item and next-intent prediction results of baselines and our proposed method FM-Intent on the Netflix user engagement dataset.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"c67b\"\u003eAll metrics are represented as relative % improvements compared to the SOTA baseline: TransAct. N/A indicates that a model is not capable of predicting a certain intent. Note that we added additional fully-connected layers to LSTM, GRU, and Transformer baselines in order to predict user intent, while we used original implementations for other baselines. FM-Intent demonstrates statistically significant improvement of 7.4% in next-item prediction accuracy compared to the best baseline (TransAct).\u003c/p\u003e\u003cp id=\"01c4\"\u003eMost baseline models show limited performance as they either cannot predict user intent or cannot incorporate intent predictions into next-item recommendations. Our production model (FM-Intent-V0) performs well but lacks the ability to predict and leverage user intent. Note that FM-Intent-V0 is trained with a smaller dataset for a fair comparison with other models; the actual production model is trained with a much larger dataset.\u003c/p\u003e\u003ch2 id=\"c46f\"\u003eQualitative Analysis: User Clustering\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"c3dc\"\u003e\u003cem\u003eFigure 3: K-means++ (K=10) clustering of user intent embeddings found by FM-Intent; FM-Intent finds unique clusters of users that share the similar intent.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"b54d\"\u003eFM-Intent generates meaningful user intent embeddings that can be used for clustering users with similar intents. Figure 3 visualizes 10 distinct clusters identified through K-means++ clustering.\u003cem\u003e \u003c/em\u003eThese clusters reveal meaningful user segments with distinct viewing patterns:\u003c/p\u003e\u003cul\u003e\u003cli id=\"de73\"\u003eUsers who primarily discover new content versus those who continue watching recent/favorite content.\u003c/li\u003e\u003cli id=\"67ed\"\u003eGenre enthusiasts (e.g., \u003cem\u003eanime/kids content viewers\u003c/em\u003e).\u003c/li\u003e\u003cli id=\"d511\"\u003eUsers with specific viewing patterns (e.g., \u003cem\u003eRewatchers\u003c/em\u003e versus \u003cem\u003ecasual viewers\u003c/em\u003e).\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"2e06\"\u003ePotential Applications of FM-Intent\u003c/h2\u003e\u003cp id=\"5515\"\u003eFM-Intent has been successfully integrated into Netflix’s recommendation ecosystem, can be leveraged for several downstream applications:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"39d4\"\u003e\u003cstrong\u003ePersonalized UI Optimization\u003c/strong\u003e: The predicted user intent could inform the layout and content selection on the Netflix homepage, emphasizing different rows based on whether users are in discovery mode, continue-watching mode, or exploring specific genres.\u003c/p\u003e\u003cp id=\"710a\"\u003e\u003cstrong\u003eAnalytics and User Understanding\u003c/strong\u003e: Intent embeddings and clusters provide valuable insights into viewing patterns and preferences, informing content acquisition and production decisions.\u003c/p\u003e\u003cp id=\"c3c1\"\u003e\u003cstrong\u003eEnhanced Recommendation Signals\u003c/strong\u003e: Intent predictions serve as features for other recommendation models, improving their accuracy and relevance.\u003c/p\u003e\u003cp id=\"3b9a\"\u003e\u003cstrong\u003eSearch Optimization\u003c/strong\u003e: Real-time intent predictions help prioritize search results based on the user’s current session intent.\u003c/p\u003e\u003c/blockquote\u003e\u003ch2 id=\"cc1a\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"6e9a\"\u003eFM-Intent represents an advancement in Netflix’s recommendation capabilities by enhancing them with hierarchical multi-task learning for user intent prediction. Our comprehensive experiments demonstrate that FM-Intent significantly outperforms state-of-the-art models, including our prior foundation model that focused solely on next-item prediction. By understanding not just what users might watch next but what underlying intents users have, we can provide more personalized, relevant, and satisfying recommendations.\u003c/p\u003e\u003ch2 id=\"c957\"\u003eAcknowledgements\u003c/h2\u003e\u003cp id=\"e32c\"\u003eWe thank our stunning colleagues in the Foundation Model team \u0026amp; AIMS org. for their valuable feedback and discussions. We also thank our partner teams for getting this up and running in production.\u003c/p\u003e\u003ch2 id=\"2e36\"\u003eReferences\u003c/h2\u003e\u003cp id=\"8218\"\u003e[1] Amatriain, X., \u0026amp; Basilico, J. (2015). Recommender systems in industry: A netflix case study. In Recommender systems handbook (pp. 385–419). Springer.\u003c/p\u003e\u003cp id=\"c60d\"\u003e[2] Gomez-Uribe, C. A., \u0026amp; Hunt, N. (2015). The netflix recommender system: Algorithms, business value, and innovation. ACM Transactions on Management Information Systems (TMIS), 6(4), 1–19.\u003c/p\u003e\u003cp id=\"84d0\"\u003e[3] Jannach, D., \u0026amp; Jugovac, M. (2019). Measuring the business value of recommender systems. ACM Transactions on Management Information Systems (TMIS), 10(4), 1–23.\u003c/p\u003e\u003cp id=\"b1fc\"\u003e[4] Bhattacharya, M., \u0026amp; Lamkhede, S. (2022). Augmenting Netflix Search with In-Session Adapted Recommendations. In Proceedings of the 16th ACM Conference on Recommender Systems (pp. 542–545).\u003c/p\u003e\u003cp id=\"3d01\"\u003e[5] Chen, Y., Liu, Z., Li, J., McAuley, J., \u0026amp; Xiong, C. (2022). Intent contrastive learning for sequential recommendation. In Proceedings of the ACM Web Conference 2022 (pp. 2172–2182).\u003c/p\u003e\u003cp id=\"cabd\"\u003e[6] Ding, Y., Ma, Y., Wong, W. K., \u0026amp; Chua, T. S. (2021). Modeling instant user intent and content-level transition for sequential fashion recommendation. IEEE Transactions on Multimedia, 24, 2687–2700.\u003c/p\u003e\u003cp id=\"f88f\"\u003e[7] Liu, Z., Chen, H., Sun, F., Xie, X., Gao, J., Ding, B., \u0026amp; Shen, Y. (2021). Intent preference decoupling for user representation on online recommender system. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence (pp. 2575–2582).\u003c/p\u003e\u003cp id=\"1c91\"\u003e[8] Xia, X., Eksombatchai, P., Pancha, N., Badani, D. D., Wang, P. W., Gu, N., Joshi, S. V., Farahpour, N., Zhang, Z., \u0026amp; Zhai, A. (2023). TransAct: Transformer-based Realtime User Action Model for Recommendation at Pinterest. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 5249–5259).\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2025-05-21T16:26:18.519Z",
  "modifiedTime": null
}
