{
  "id": "49f89cf4-54c9-4897-a958-c48a9cfe2f2d",
  "title": "State-of-the-art text embedding via the Gemini API",
  "link": "https://developers.googleblog.com/en/gemini-embedding-text-model-now-available-gemini-api/",
  "description": "A new experimental Gemini Embedding text model, now available in the Gemini API, achieves top rankings on the Massive Text Embedding Benchmark (MTEB) leaderboard and offers expanded language support and high-dimensional embeddings.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Logan Kilpatrick, Zach Gleicher, Parashar Shah",
  "length": 4762,
  "excerpt": "A new experimental Gemini Embedding text model, now available in the Gemini API, achieves top rankings on the Massive Text Embedding Benchmark (MTEB) leaderboard and offers expanded language support and high-dimensional embeddings.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Logan Kilpatrick Senior Product Manager Gemini API and Google AI Studio [Image created by Google with Gemini 2.0 Flash native image generation]Today, we’re making a new experimental Gemini Embedding text model (gemini-embedding-exp-03-07)1 available in the Gemini API.Trained on the Gemini model itself, this embedding model has inherited Gemini’s understanding of language and nuanced context making it applicable for a wide range of uses. This new embedding model surpasses our previous state-of-the-art model (text-embedding-004), achieves the top rank on the Massive Text Embedding Benchmark (MTEB) Multilingual leaderboard, and comes with new features like longer input token length!Our most capable text embedding model yetWe've trained our model to be remarkably general, delivering exceptional performance across diverse domains, including finance, science, legal, search, and more. It works effectively out-of-the-box, eliminating the need for extensive fine-tuning for specific tasks.The MTEB (Multilingual) leaderboard ranks text embedding models across diverse tasks such as retrieval and classification to provide a comprehensive benchmark for model comparison. Our Gemini Embedding model achieves a mean (task) score of 68.32–a margin of +5.81 over the next competing model. Our new Gemini text embedding model (gemini-embedding-exp-03-07) achieves high scores on the MTEB (Multilingual) leaderboard (right click to open image in new tab). Why embeddings?From building intelligent retrieval augmented generation (RAG) and recommendation systems to text classification, the ability for LLMs to understand the meaning behind text is crucial. Embeddings are often critical for building more efficient systems, reducing cost and latency while also generally providing better results than keyword matching systems. Embeddings capture semantic meaning and context through numerical representations of data. Data with similar semantic meaning have embeddings that are closer together. Embeddings enable a wide range of applications, including:Efficient Retrieval: Find relevant documents within large databases, like legal document retrieval or enterprise search, by comparing the embeddings of queries and documents.Retrieval-Augmented Generation (RAG): Enhance the quality and relevance of generated text by retrieving and incorporating contextually relevant information into the context of a model.Clustering and Categorization: Group similar texts together, identifying trends and topics within your data.Classification: Automatically categorize text based on its content, such as sentiment analysis or spam detection.Text Similarity: Identify duplicate content, enabling tasks like web page deduplication or plagiarism detection.You can learn more about embeddings and common AI use cases in the Gemini API docs.Get started with Gemini EmbeddingDevelopers can now access our new, experimental Gemini Embeddings model through the Gemini API. It’s compatible with the existing embed_content endpoint. from google import genai client = genai.Client(api_key=\"GEMINI_API_KEY\") result = client.models.embed_content( model=\"gemini-embedding-exp-03-07\", contents=\"How does alphafold work?\", ) print(result.embeddings) In addition to improved quality across all dimensions, Gemini Embedding also features:Input token limit of 8K tokens. We’ve improved our context length from previous models allowing you to embed large chunks of text, code, or other data.Output dimensions of 3K dimensions. High-dimensional embeddings with almost 4x more tokens over previous embedding models.Matryoshka Representation Learning (MRL): MRL allows you to truncate the original 3K dimensions to scale down to meet your desired storage cost.Expanded language support. We’ve doubled the number of languages supported to over 100.Unified model. This model surpasses the quality of our previous task-specific multilingual, english-only, and code specific models.While currently in an experimental phase with limited capacity, this release gives you an early opportunity to explore Gemini Embedding capabilities. As with all experimental models, it's subject to change, and we're working towards a stable, generally available release in the months to come. We’d love to hear your feedback on the embeddings feedback form.1 On Vertex AI, the same model is served through the endpoint “text-embedding-large-exp-03-07.” For general availability, naming will be consistent.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-metadata.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \u003csection\u003e\n      \n        \n          \u003cp\u003e\u003ca href=\"https://developers.googleblog.com/en/search/?author=Logan+Kilpatrick\"\u003eLogan Kilpatrick\u003c/a\u003e\n            \n              \u003cspan\u003eSenior Product Manager\u003c/span\u003e\n            \n            \n              \u003cspan\u003eGemini API and Google AI Studio\u003c/span\u003e\n            \n          \u003c/p\u003e\n        \n          \n        \n          \n        \n\n      \n      \u003c/section\u003e\n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"ad5x6\"\u003e\u003csub\u003e[Image created by Google with Gemini 2.0 Flash native image generation]\u003c/sub\u003e\u003c/p\u003e\u003cp data-block-key=\"laee\"\u003e\u003cbr/\u003eToday, we’re making a new experimental Gemini Embedding text model (gemini-embedding-exp-03-07)\u003csup\u003e1\u003c/sup\u003e available in the Gemini API.\u003c/p\u003e\u003cp data-block-key=\"135cg\"\u003eTrained on the Gemini model itself, this embedding model has inherited Gemini’s understanding of language and nuanced context making it applicable for a wide range of uses. This new embedding model surpasses our previous state-of-the-art model (\u003ca href=\"https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding\"\u003e\u003ci\u003etext-embedding-004\u003c/i\u003e\u003c/a\u003e), achieves the top rank on the Massive Text Embedding Benchmark (MTEB) Multilingual leaderboard, and comes with new features like longer input token length!\u003c/p\u003e\u003ch2 data-block-key=\"3mnb2\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eOur most capable text embedding model yet\u003c/h2\u003e\u003cp data-block-key=\"861cp\"\u003eWe\u0026#39;ve trained our model to be remarkably general, delivering exceptional performance across diverse domains, including finance, science, legal, search, and more. It works effectively out-of-the-box, eliminating the need for extensive fine-tuning for specific tasks.\u003c/p\u003e\u003cp data-block-key=\"dbfoh\"\u003eThe MTEB (Multilingual) leaderboard ranks text embedding models across diverse tasks such as retrieval and classification to provide a comprehensive benchmark for model comparison. Our Gemini Embedding model achieves a mean (task) score of 68.32–a margin of +5.81 over the next competing model.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n        \n            \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_embedding_blog_post_-_benchmark_table.original.png\" alt=\"MTEB Leaderboard text model performance ranking\"/\u003e\u003c/p\u003e\u003cp\u003e\n                    Our new Gemini text embedding model (gemini-embedding-exp-03-07) achieves high scores on the MTEB (Multilingual) leaderboard (right click to open image in new tab).\n                \u003c/p\u003e\n            \n        \n    \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"ad5x6\"\u003eWhy embeddings?\u003c/h2\u003e\u003cp data-block-key=\"8g1em\"\u003eFrom building intelligent retrieval augmented generation (RAG) and recommendation systems to text classification, the ability for LLMs to understand the meaning behind text is crucial. Embeddings are often critical for building more efficient systems, reducing cost and latency while also generally providing better results than keyword matching systems. Embeddings capture semantic meaning and context through numerical representations of data. Data with similar semantic meaning have embeddings that are closer together. Embeddings enable a wide range of applications, including:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"b97o1\"\u003e\u003cb\u003eEfficient Retrieval:\u003c/b\u003e Find relevant documents within large databases, like legal document retrieval or enterprise search, by comparing the embeddings of queries and documents.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"5idl4\"\u003e\u003cb\u003eRetrieval-Augmented Generation (RAG):\u003c/b\u003e Enhance the quality and relevance of generated text by retrieving and incorporating contextually relevant information into the context of a model.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"fovjm\"\u003e\u003cb\u003eClustering and Categorization:\u003c/b\u003e Group similar texts together, identifying trends and topics within your data.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"c2leq\"\u003e\u003cb\u003eClassification:\u003c/b\u003e Automatically categorize text based on its content, such as sentiment analysis or spam detection.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"e1035\"\u003e\u003cb\u003eText Similarity:\u003c/b\u003e Identify duplicate content, enabling tasks like web page deduplication or plagiarism detection.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"4cve2\"\u003eYou can learn more about embeddings and common AI use cases in the \u003ca href=\"https://ai.google.dev/gemini-api/docs/embeddings\"\u003eGemini API docs\u003c/a\u003e.\u003c/p\u003e\u003ch2 data-block-key=\"aa0k7\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eGet started with Gemini Embedding\u003c/h2\u003e\u003cp data-block-key=\"aklj1\"\u003eDevelopers can now access our new, experimental Gemini Embeddings model through the Gemini API. It’s compatible with the existing \u003ccode\u003eembed_content\u003c/code\u003e endpoint.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003efrom\u003c/span\u003e \u003cspan\u003egoogle\u003c/span\u003e \u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003egenai\u003c/span\u003e\n\n\u003cspan\u003eclient\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003egenai\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eClient\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eapi_key\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;GEMINI_API_KEY\u0026#34;\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\n\u003cspan\u003eresult\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003eclient\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003emodels\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eembed_content\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\n        \u003cspan\u003emodel\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;gemini-embedding-exp-03-07\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n        \u003cspan\u003econtents\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;How does alphafold work?\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n\u003cspan\u003e)\u003c/span\u003e\n\n\u003cspan\u003eprint\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eresult\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eembeddings\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"ad5x6\"\u003eIn addition to improved quality across all dimensions, Gemini Embedding also features:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"24q2p\"\u003e\u003cb\u003eInput token limit of 8K tokens.\u003c/b\u003e We’ve improved our context length from previous models allowing you to embed large chunks of text, code, or other data.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"f6nlr\"\u003e\u003cb\u003eOutput dimensions of 3K dimensions.\u003c/b\u003e High-dimensional embeddings with almost 4x more tokens over previous embedding models.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"jlbf\"\u003e\u003cb\u003eMatryoshka Representation Learning (MRL):\u003c/b\u003e MRL allows you to truncate the original 3K dimensions to scale down to meet your desired storage cost.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"cnduc\"\u003e\u003cb\u003eExpanded language support.\u003c/b\u003e We’ve doubled the number of languages supported to over 100.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"7ovef\"\u003e\u003cb\u003eUnified model.\u003c/b\u003e This model surpasses the quality of our previous task-specific multilingual, english-only, and code specific models.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"4h0ro\"\u003e\u003cbr/\u003eWhile currently in an experimental phase with limited capacity, this release gives you an early opportunity to explore Gemini Embedding capabilities. As with all experimental models, it\u0026#39;s subject to change, and we\u0026#39;re working towards a stable, generally available release in the months to come. We’d love to hear your feedback on the \u003ca href=\"https://docs.google.com/forms/d/e/1FAIpQLSeuFskna8EhdtxG3sQxkGhHAHXt2piRAZUtmSebpqxNV4tmwQ/viewform\"\u003eembeddings feedback form\u003c/a\u003e.\u003c/p\u003e\u003chr/\u003e\u003cp data-block-key=\"dt81v\"\u003e\u003csup\u003e1\u003c/sup\u003e\u003csub\u003e On Vertex AI, the same model is served through the endpoint “\u003c/sub\u003e\u003ca href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#supported-models\"\u003e\u003csub\u003etext-embedding-large-exp-03-07\u003c/sub\u003e\u003c/a\u003e\u003csub\u003e.” For general availability, naming will be consistent.\u003c/sub\u003e\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-03-07T00:00:00Z",
  "modifiedTime": null
}
