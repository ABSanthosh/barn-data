{
  "id": "4ade6990-c5f5-4fdf-a6ee-4a0adfcbbca5",
  "title": "Synthetic Data Generator Simplifies Dataset Creation with Large Language Models",
  "link": "https://www.infoq.com/news/2025/01/synthetic-data-generator/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Hugging Face has introduced the Synthetic Data Generator, a new tool leveraging Large Language Models (LLMs), that offers a streamlined, no-code approach to creating custom datasets. The tool facilitates the creation of text classification and chat datasets through a clear and accessible process, making it usable for both non-technical users and experienced AI practitioners. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Mon, 27 Jan 2025 20:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Hugging Face",
    "Machine Learning",
    "Data",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 3322,
  "excerpt": "Hugging Face has introduced the Synthetic Data Generator, a new tool leveraging Large Language Models (LLMs), that offers a streamlined, no-code approach to creating custom datasets. The tool facilita",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250124075613_4/apple-touch-icon.png",
  "text": "Hugging Face has introduced the Synthetic Data Generator, a new tool leveraging Large Language Models (LLMs), that offers a streamlined, no-code approach to creating custom datasets. The tool facilitates the creation of text classification and chat datasets through a clear and accessible process, making it usable for both non-technical users and experienced AI practitioners. The Synthetic Data Generator uses a simple three-step process to create datasets: Describe Your Dataset: Users start by defining the dataset's purpose and providing examples to guide the tool. This step ensures the generator aligns with the user's specific requirements. Configure and Refine: After generating an initial sample dataset, users can refine it by adjusting task-specific settings, such as the system prompt or dataset parameters, iterating until they achieve the desired output. Generate and Push: Finally, users can name the dataset, specify the number of samples to generate, and set parameters like the temperature for the output. The completed dataset is saved directly to Argilla and the Hugging Face Hub for further use. After generation, the tool integrates with Argilla, enabling users to review, explore, and curate the dataset with features like semantic search and composable filters. This step is critical for maintaining data quality, even in synthetic datasets. Once the dataset is reviewed, it can be exported to the Hugging Face Hub to fine-tune models. The tool currently supports two tasks: Text Classification: For categorizing text into predefined classes. Chat Datasets: Designed for conversational AI tasks, such as training customer support chatbots. For instance, users can train a text classification model using the argilla/synthetic-text-classification-news dataset, which classifies news articles into eight categories. The Synthetic Data Generator simplifies the process by enabling model training through AutoTrain, a no-code platform for creating AI models. Shashi Bhushan, a data scientist, highlighted the broader impact of the tool: This is a fantastic development! The ability to generate high-quality datasets rapidly without requiring coding skills will democratize AI and empower a broader range of professionals to leverage machine learning. This tool could significantly reduce the time and resources typically needed for data preparation, allowing teams to focus more on model development and innovation. Additionally, the integration with AutoTrain suggests a seamless workflow from data generation to model training, which is a huge plus for efficiency. Looking forward to seeing the impact this will have on the AI community! The Synthetic Data Generator can produce 50 text classification samples or 20 chat samples per minute with the free Hugging Face API. Users can scale this further by using custom APIs or advanced models. Planned improvements include support for Retrieval Augmented Generation (RAG) and customized evaluations using LLMs as judges.  The tool is also available as an open-source Python package via GitHub, enabling local deployment and further customization under an Apache 2 license. About the Author Robert Krzaczyński",
  "image": "https://res.infoq.com/news/2025/01/synthetic-data-generator/en/headerimage/generatedHeaderImage-1738006994831.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://huggingface.co/blog/synthetic-data-generator\"\u003eHugging Face has introduced the Synthetic Data Generator\u003c/a\u003e, a new tool leveraging Large Language Models (LLMs), that offers a streamlined, no-code approach to creating custom datasets. The tool facilitates the creation of text classification and chat datasets through a clear and accessible process, making it usable for both non-technical users and experienced AI practitioners.\u003cbr/\u003e\nThe Synthetic Data Generator uses a simple three-step process to create datasets:\u003c/p\u003e\n\n\u003col\u003e\n\t\u003cli\u003e\u003cstrong\u003eDescribe Your Dataset\u003c/strong\u003e: Users start by defining the dataset\u0026#39;s purpose and providing examples to guide the tool. This step ensures the generator aligns with the user\u0026#39;s specific requirements.\u003c/li\u003e\n\t\u003cli\u003e\u003cstrong\u003eConfigure and Refine\u003c/strong\u003e: After generating an initial sample dataset, users can refine it by adjusting task-specific settings, such as the system prompt or dataset parameters, iterating until they achieve the desired output.\u003c/li\u003e\n\t\u003cli\u003e\u003cstrong\u003eGenerate and Push\u003c/strong\u003e: Finally, users can name the dataset, specify the number of samples to generate, and set parameters like the temperature for the output. The completed dataset is saved directly to \u003ca href=\"https://argilla.io/\"\u003eArgilla\u003c/a\u003e and the Hugging Face Hub for further use.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cdiv\u003e\u003cp\u003eAfter generation, the tool integrates with Argilla, enabling users to review, explore, and curate the dataset with features like semantic search and composable filters. This step is critical for maintaining data quality, even in synthetic datasets. Once the dataset is reviewed, it can be exported to the Hugging Face Hub to fine-tune models.\u003c/p\u003e\u003cp\u003e\n\nThe tool currently supports two tasks:\u003c/p\u003e\u003c/div\u003e\n\n\u003cul\u003e\n\t\u003cli\u003eText Classification: For categorizing text into predefined classes.\u003c/li\u003e\n\t\u003cli\u003eChat Datasets: Designed for conversational AI tasks, such as training customer support chatbots.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFor instance, users can train a text classification model using the \u003ca href=\"https://huggingface.co/datasets/argilla/synthetic-text-classification-news\"\u003e\u003cem\u003eargilla/synthetic-text-classification-news\u003c/em\u003e\u003c/a\u003e dataset, which classifies news articles into eight categories. The Synthetic Data Generator simplifies the process by enabling model training through AutoTrain, a no-code platform for creating AI models.\u003c/p\u003e\n\n\u003cp\u003eShashi Bhushan, a data scientist, \u003ca href=\"https://www.linkedin.com/feed/update/urn:li:activity:7274443947563769857?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7274443947563769857%2C7280847894218235904%29\u0026amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287280847894218235904%2Curn%3Ali%3Aactivity%3A7274443947563769857%29\"\u003ehighlighted\u003c/a\u003e the broader impact of the tool:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThis is a fantastic development! The ability to generate high-quality datasets rapidly without requiring coding skills will democratize AI and empower a broader range of professionals to leverage machine learning. This tool could significantly reduce the time and resources typically needed for data preparation, allowing teams to focus more on model development and innovation. Additionally, the integration with AutoTrain suggests a seamless workflow from data generation to model training, which is a huge plus for efficiency. Looking forward to seeing the impact this will have on the AI community!\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cdiv\u003e\u003cp\u003eThe Synthetic Data Generator can produce 50 text classification samples or 20 chat samples per minute with the free Hugging Face API. Users can scale this further by using custom APIs or advanced models. Planned improvements include support for Retrieval Augmented Generation (RAG) and customized evaluations using LLMs as judges. \u003c/p\u003e\u003cp\u003e\n\nThe tool is also available as an open-source Python package via \u003ca href=\"https://github.com/argilla-io/synthetic-data-generator?tab=readme-ov-file#installation\"\u003eGitHub\u003c/a\u003e, enabling local deployment and further customization under an Apache 2 license.\u003c/p\u003e\u003c/div\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-01-27T00:00:00Z",
  "modifiedTime": null
}
