{
  "id": "14598526-538a-4a1e-b622-f15ddf04253e",
  "title": "Advancing the frontier of video understanding with Gemini 2.5",
  "link": "https://developers.googleblog.com/en/gemini-2-5-video-understanding/",
  "description": "Gemini 2.5 marks a major leap in video understanding, achieving state-of-the-art performance on key video understanding benchmarks and being able to seamlessly use audio-visual information with code and other data formats.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Anirudh Baddepudi, Antoine Yang, Mario Lučić",
  "length": 5092,
  "excerpt": "Gemini 2.5 marks a major leap in video understanding, achieving state-of-the-art performance on key video understanding benchmarks and being able to seamlessly use audio-visual information with code and other data formats.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "We recently launched two new models in our Gemini family: Gemini 2.5 Pro Preview (05/06) and Gemini 2.5 Flash (04/17). These models mark a major leap in video understanding. Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks, surpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video frames).Furthermore, it rivals specialized fine-tuned models on several challenging benchmarks (e.g. YouCook2 dense captioning and QVHighlights moment retrieval). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative. Evaluation of Gemini 2.5 vs. prior models on video understanding benchmarks. Performance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy for EgoTempo, R1@0.5 for QVHighlights and CIDEr for YouCook2. *Videos were processed at 1fps and linearly subsampled to a maximum of 256 frames, except for 1H-VideoQA (7200 frames). Combining video and code with Gemini 2.5Gemini 2.5 is the first time a natively multimodal model can use audio-visual information seamlessly with code and other data formats. To illustrate the power of Gemini 2.5's video understanding capabilities, we showcase some of the use cases that we’ve been most excited about below.Transforming videos into interactive applicationsGemini 2.5 Pro unlocks new possibilities for transforming videos into interactive applications. Video To Learning App, a Google AI Studio starter app, uses Gemini 2.5 to make learning from video content more effective and engaging.First, the model sees a YouTube URL along with a text prompt that explains how it should analyze the video. Gemini 2.5 Pro analyzes the video and crafts a detailed spec for a learning application which reinforces key ideas in the video.The generated spec is then sent directly back to Gemini 2.5 Pro to generate the code for the application, as illustrated in the vision correction simulator application below. Gemini 2.5 Flash can achieve similar results, offering a glimpse into novel video use cases in domains such as education and interactive content creation. Sorry, your browser doesn't support playback for this video Video to interactive application in Google AI Studio Creating animations from video with p5.jsGemini 2.5 Pro unlocks exciting creative possibilities, such as the ability to generate dynamic animations from videos with a single prompt. This capability opens up new avenues for use cases such as automated content generation and creating accessible video summaries.For example, when given our video on Project Astra along with the prompt 'Create an animation in p5.js covering the different landmarks seen in this video.', Gemini 2.5 Pro analyzes the footage and produces a corresponding p5.js animation. The animation visualizes the landmarks identified by Gemini 2.5 Pro in the same temporal order as in the video. Retrieving and describing moments from videoGemini 2.5 Pro excels at identifying specific moments within videos using audio-visual cues with significantly higher accuracy than previous video processing systems. For example, in this 10-minute video of the Google Cloud Next '25 opening keynote, it accurately identifies 16 distinct segments related to product presentations, using both audio and visual cues from the video to do so. Temporal reasoningWith its advanced moment retrieval capabilities, Gemini 2.5 Pro is also able to solve nuanced temporal reasoning problems such as counting. In this example, Gemini successfully counts 17 distinct occurrences where the main character uses their phone in the project Astra video. Building with Gemini 2.5 video understandingVideo understanding in Gemini 2.5 Flash and Pro are available in Google AI Studio, the Gemini API, and Vertex AI. Support for YouTube videos is available via the Gemini API and Google AI Studio, enabling anyone to build applications with access to billions of videos.The Gemini API now offers a 'low' media resolution parameter enabling Gemini 2.5 Pro to process ~6 hours of video with 2 million token context. This provides for a more cost-effective setting with competitive video understanding performance (e.g., 84.7% vs 85.2% accuracy on VideoMME) for many long video understanding use cases.We are inspired by the innovative video applications already emerging from the community and can’t wait to see what you build!AcknowledgementsA big shoutout to Aaron Wade for creating Video To Learning App and for the Vision Correction simulator example showcased in the blogpost.We thank Sergi Caelles, Boyu Wang and Saarthak Khanna for their contributions on the eval side, Angeliki Lazaridou for inspiring some examples, Paul Natsev and Jean-Baptiste Alayrac on advising, as well the entire Gemini video understanding team.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/2.5Pro_Metadatal_RD2-V01.2e16d0ba.fill-1200x600.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"l0gcr\"\u003eWe recently launched two new models in our Gemini family: \u003ca href=\"https://developers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance/\"\u003eGemini 2.5 Pro Preview (05/06)\u003c/a\u003e and \u003ca href=\"https://blog.google/products/gemini/gemini-2-5-flash-preview/\"\u003eGemini 2.5 Flash (04/17)\u003c/a\u003e. These models mark a major leap in video understanding. Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks, surpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video frames).\u003c/p\u003e\u003cp data-block-key=\"31ugm\"\u003eFurthermore, it rivals specialized fine-tuned models on several challenging benchmarks (e.g. YouCook2 dense captioning and QVHighlights moment retrieval). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n        \n            \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_2-5_Video_Blogpost_V04.original.jpg\" alt=\"Advancing the frontier of video understanding with Gemini 2.5\"/\u003e\u003c/p\u003e\u003cp\u003e\n                    Evaluation of Gemini 2.5 vs. prior models on video understanding benchmarks.\nPerformance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy for EgoTempo, R1@0.5 for QVHighlights and CIDEr for YouCook2.\n*Videos were processed at 1fps and linearly subsampled to a maximum of 256 frames, except for 1H-VideoQA (7200 frames).\n                \u003c/p\u003e\n            \n        \n    \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"2loq3\" id=\"combining-video-and-code-with-gemini-2.5\"\u003eCombining video and code with Gemini 2.5\u003c/h2\u003e\u003cp data-block-key=\"5uqiq\"\u003eGemini 2.5 is the first time a natively multimodal model can use audio-visual information seamlessly with code and other data formats. To illustrate the power of Gemini 2.5\u0026#39;s video understanding capabilities, we showcase some of the use cases that we’ve been most excited about below.\u003c/p\u003e\u003ch3 data-block-key=\"u2b9r\" id=\"transforming-videos-into-interactive-applications\"\u003e\u003cbr/\u003e\u003cb\u003eTransforming videos into interactive applications\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"f92oc\"\u003eGemini 2.5 Pro unlocks new possibilities for transforming videos into interactive applications. \u003ca href=\"https://aistudio.google.com/u/1/apps/bundled/video-to-learning-app?showPreview=true\"\u003eVideo To Learning App\u003c/a\u003e, a Google AI Studio starter app, uses Gemini 2.5 to make learning from video content more effective and engaging.\u003c/p\u003e\u003cp data-block-key=\"k05k\"\u003eFirst, the model sees a YouTube URL along with a text prompt that explains how it should analyze the video. Gemini 2.5 Pro analyzes the video and crafts a detailed spec for a learning application which reinforces key ideas in the video.\u003c/p\u003e\u003cp data-block-key=\"dkotd\"\u003eThe generated spec is then sent directly back to Gemini 2.5 Pro to generate the code for the application, as illustrated in the vision correction simulator application below. Gemini 2.5 Flash can achieve similar results, offering a glimpse into novel video use cases in domains such as education and interactive content creation.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-6ec7ozs0_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/image5.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n        \n            \u003ca href=\"https://aistudio.google.com/u/1/apps/bundled/video-to-learning-app?showPreview=true\" target=\"_blank\" rel=\"noopener\"\u003e\n                \u003cp\u003e\n                    Video to interactive application in Google AI Studio\n                \u003c/p\u003e\n            \u003c/a\u003e\n        \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"2ieq7\" id=\"creating-animations-from-video-with-p5.js\"\u003e\u003cb\u003eCreating animations from video with p5.js\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"atoui\"\u003eGemini 2.5 Pro unlocks exciting creative possibilities, such as the ability to generate dynamic animations from videos with a single prompt. This capability opens up new avenues for use cases such as automated content generation and creating accessible video summaries.\u003c/p\u003e\u003cp data-block-key=\"ee9mb\"\u003eFor example, when given our \u003ca href=\"https://www.youtube.com/watch?v=hIIlJt8JERI\"\u003evideo\u003c/a\u003e on \u003ca href=\"https://deepmind.google/technologies/project-astra/\"\u003eProject Astra\u003c/a\u003e along with the prompt \u0026#39;\u003ci\u003eCreate an animation in p5.js covering the different landmarks seen in this video.\u003c/i\u003e\u0026#39;, Gemini 2.5 Pro analyzes the footage and produces a corresponding \u003ca href=\"https://p5js.org/\"\u003ep5.js\u003c/a\u003e animation. The animation visualizes the landmarks identified by Gemini 2.5 Pro \u003ci\u003ein the same temporal order as in the video\u003c/i\u003e.\u003c/p\u003e\n\u003c/div\u003e   \n\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"b454u\" id=\"retrieving-and-describing-moments-from-video\"\u003e\u003cb\u003eRetrieving and describing moments from video\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"6q5pn\"\u003eGemini 2.5 Pro excels at identifying specific moments within videos using audio-visual cues with significantly higher accuracy than previous video processing systems. For example, in this 10-minute \u003ca href=\"https://www.youtube.com/watch?v=dwgmfSOZNoQ\"\u003evideo\u003c/a\u003e of the Google Cloud Next \u0026#39;25 opening keynote, it accurately identifies 16 distinct segments related to product presentations, using both audio and visual cues from the video to do so.\u003c/p\u003e\n\u003c/div\u003e   \n\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"t5zt1\" id=\"temporal-reasoning\"\u003e\u003cb\u003eTemporal reasoning\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"11das\"\u003eWith its advanced moment retrieval capabilities, Gemini 2.5 Pro is also able to solve nuanced temporal reasoning problems such as counting. In this example, Gemini successfully counts 17 distinct occurrences where the main character uses their phone in the project Astra \u003ca href=\"https://www.youtube.com/watch?v=hIIlJt8JERI\"\u003evideo\u003c/a\u003e.\u003c/p\u003e\n\u003c/div\u003e   \n\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"ea1qi\" id=\"building-with-gemini-2.5-video-understanding\"\u003eBuilding with Gemini 2.5 video understanding\u003c/h2\u003e\u003cp data-block-key=\"drfhm\"\u003eVideo understanding in Gemini 2.5 Flash and Pro are available in \u003ca href=\"http://aistudio.google.com/\"\u003eGoogle AI Studio\u003c/a\u003e, the \u003ca href=\"https://ai.google.dev/gemini-api/docs/video-understanding\"\u003eGemini API\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding\"\u003eVertex AI\u003c/a\u003e. Support for YouTube videos is available via the \u003ca href=\"https://ai.google.dev/gemini-api/docs/video-understanding\"\u003eGemini API\u003c/a\u003e and \u003ca href=\"http://aistudio.google.com/\"\u003eGoogle AI Studio\u003c/a\u003e, enabling anyone to build applications with access to billions of videos.\u003c/p\u003e\u003cp data-block-key=\"6piah\"\u003eThe \u003ca href=\"https://ai.google.dev/gemini-api/docs/video-understanding\"\u003eGemini API\u003c/a\u003e now offers a \u0026#39;low\u0026#39; \u003ca href=\"https://ai.google.dev/api/generate-content#MediaResolution\"\u003emedia resolution parameter\u003c/a\u003e enabling Gemini 2.5 Pro to process ~6 hours of video with 2 million token context. This provides for a more cost-effective setting with competitive video understanding performance (e.g., 84.7% vs 85.2% accuracy on VideoMME) for many long video understanding use cases.\u003c/p\u003e\u003cp data-block-key=\"4trnk\"\u003eWe are inspired by the innovative video applications already emerging from the community and can’t wait to see what you build!\u003c/p\u003e\u003chr/\u003e\u003ch3 data-block-key=\"dlx0w\" id=\"acknowledgements\"\u003e\u003cb\u003eAcknowledgements\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"7ifka\"\u003e\u003csup\u003eA big shoutout to\u003c/sup\u003e \u003cb\u003e\u003csup\u003eAaron Wade\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e for creating\u003c/sup\u003e \u003ca href=\"https://aistudio.google.com/u/1/apps/bundled/video-to-learning-app?showPreview=true\"\u003e\u003csup\u003eVideo To Learning App\u003c/sup\u003e\u003c/a\u003e\u003csup\u003e and for the Vision Correction simulator example showcased in the blogpost.\u003c/sup\u003e\u003c/p\u003e\u003cp data-block-key=\"kgu9\"\u003e\u003csup\u003eWe thank\u003c/sup\u003e \u003cb\u003e\u003csup\u003eSergi Caelles\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e,\u003c/sup\u003e \u003cb\u003e\u003csup\u003eBoyu Wang\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e and\u003c/sup\u003e \u003cb\u003e\u003csup\u003eSaarthak Khanna\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e for their contributions on the eval side,\u003c/sup\u003e \u003cb\u003e\u003csup\u003eAngeliki Lazaridou\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e for inspiring some examples,\u003c/sup\u003e \u003cb\u003e\u003csup\u003ePaul Natsev\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e and\u003c/sup\u003e \u003cb\u003e\u003csup\u003eJean-Baptiste Alayrac\u003c/sup\u003e\u003c/b\u003e\u003csup\u003e on advising, as well the entire Gemini video understanding team.\u003c/sup\u003e\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-05-09T00:00:00Z",
  "modifiedTime": null
}
