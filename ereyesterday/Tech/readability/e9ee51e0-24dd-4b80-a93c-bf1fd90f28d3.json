{
  "id": "e9ee51e0-24dd-4b80-a93c-bf1fd90f28d3",
  "title": "I helped fix sleep-wake hangs on Linux with AMD GPUs",
  "link": "https://nyanpasu64.gitlab.io/blog/amdgpu-sleep-wake-hang/",
  "description": "Comments",
  "author": "",
  "published": "Sun, 16 Feb 2025 21:42:03 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "nyanpasu64",
  "length": 22869,
  "excerpt": "Adventures in programming, hardware, DSP, and chiptune",
  "siteName": "nyanpasu64's blog",
  "favicon": "https://nyanpasu64.gitlab.io/apple-touch-icon.png",
  "text": "Written by nyanpasu64 onÂ December 29, 2024 I dual-boot my desktop between Windows and Linux. Over the past few years, Linux would often crash when I tried to sleep my computer with high RAM usage. Upon waking it would show a black screen with moving cursor, or enter a \"vegetative\" state with no image on-screen, only responding to magic SysRq or a hard reset. I traced this behavior to an amdgpu driver power/memory management bug, which took over a year to brainstorm and implement solutions for. TL;DR: The bug is fixed in agd5f/linux, and the change should be out in stable kernel 6.14. Diagnosing the problem I started debugging this issue in 2023-09. My setup was a Gigabyte B550M DS3H motherboard with AMD RX 570 GPU and 1TB Kingston A2000 NVMe SSD, running Arch Linux with systemd-boot and Linux 6.4. The first thing I do after a system crash is to check the journals. For example, journalctl --system -b -1 will print system logs from the previous boot (dmesg and system services, excluding logs from my user account's apps). The output showed that some sleep attempts had out-of-memory (OOM) errors in kernel code under amdgpu_device_suspend, and it took one or more failed attempts before the system crashed. Though oftentimes journalctl would print no logs whatsoever of the broken system waking up, terminating at: Aug 30 12:47:01 ryzen systemd-sleep[41722]: Entering sleep state 'suspend'... Aug 30 12:47:01 ryzen kernel: PM: suspend entry (deep) At one point after my computer attempted to sleep, it entered a \"undead\" state where the computer woke up enough to show KDE's lock screen clock updating in real time, but locked up if I tried to log in or interact beyond a REISUB reboot. Terrifyingly, after rebooting the PC and checking the journals, they stopped at Entering sleep state 'suspend'... and contained no record of waking up and loading KDE's lock screen. I concluded that the NVMe storage driver failed to reinitialize during system wakeup, causing the system to freeze and logs to stop being written. I suspected that Linux was telling my NVMe drive to enter a power-saving APST mode, but my drive would instead stop responding to requests permanently. The Arch wiki suggested that I disable APST by adding kernel parameter nvme_core.default_ps_max_latency_us=0 and enable software IOMMU using iommu=soft, but this did not solve my problem. Later I installed a SSD firmware upgrade that fixed APST handling (bricking not covered by warranty ðŸ˜‰), and upgraded to a 2TB boot SSD, but neither step helped. One contributing factor was that systemd would try multiple sleep modes back to back (bug report). If the first sleep attempt failed due to OOM, subsequent attempts would generate noise in system logs and corrupt the kernel further. I turned this off on my system by editing /etc/systemd/sleep.conf and adding SuspendState=mem; this simplified debugging but did not solve the underlying problem. I also tried echo 1 \u003e /sys/power/pm_trace to check where suspend failed, which had the side effect of disabling asynchronous suspend (which suspended multiple devices in parallel). I noticed that Linux would recover from amdgpu suspend failures rather than entering a full system hang. pm_trace stores sleep-wake progress into a computer's system time (docs), so after a failed sleep you can find which operation hung. At one point I rebooted or woke up my computer, only to find that the time was decades off! Next I enabled the systemd debug shell, which allowed me to run commands on a broken system even when I was unable to unlock KDE or log into a TTY. I added a systemd.debug_shell kernel parameter to my systemd-boot config, though the Fedora wiki says you can also run systemctl enable debug-shell to enable it through systemd itself. Afterwards pressing Ctrl-Alt-F9 would spawn a root shell. Because the kernel crash sometimes broke the motherboard's USB controller and keyboards, preventing me from typing into the debug shell, I dug a PS/2 keyboard out of a dusty closet and plugged it into my system (only safe when the PC is off!). This helped me navigate the debug shell, but was largely obsoleted by the serial console I set up later, which doesn't require a working display output. After looking through my crash logs, I noticed that the crashes generally happened in amdgpu's TTM buffer eviction (amdgpu_device_evict_resources() â†’ amdgpu_ttm_evict_resources()). To learn what this meant and report my findings, I looked on amdgpu's Gitlab bug tracker for issues related to sleep-wake crashing. I found a bug report about crashing under high memory usage, which reported that \"evict\" means copying VRAM to system ram (or system RAM to swap). Through some digging, I found that when a desktop enters S3 sleep, the system cuts power to PCIe GPUs, causing their VRAM chips to lose data. To preserve this data, GPU drivers copy VRAM in use to system RAM before the system sleeps, then restore it after the system wakes. However the Linux amdgpu driver has a bug where, if there is not enough free RAM to store all VRAM in use, the system will run out of memory and crash, instead of moving RAM to disk-based swap. If Linux OOMs during suspend, it will cancel sleeping and attempt to restart devices. However some drivers may break due to the aborted sleep, or themselves OOM during suspend or resume. This is more likely with asynchronous suspend enabled. Alternatively Linux may successfully suspend, but OOM during resume while starting up devices. Upstream debugging I thought that in order to allow swapping to disk, you'd have to evict VRAM to system RAM (while swapping out system RAM if it fills up) before suspending disk-based storage. After we discussed on the bug report, Mario Limonciello suggested that I enable /sys/power/pm_print_times and /sys/power/pm_debug_messages (docs) and check the logs from sleeping. The resulting logs showed that during sleep, the NVMe and amdgpu drivers entered pci_pm_suspend in parallel. I started looking for ways to move GPU suspend before SSD suspend, and found a mechanism for ordering device suspend. However it appeared built more for synchronizing tightly-coupled peripherals than suspending every GPU before any system disk. Mario instead suggested evicting VRAM during Linux suspend's prepare phase (before disks are suspended), and wrote some kernel patches to move VRAM eviction there. As an overview of how the suspend process fits together, I've written a flowchart of Linux's suspend control flow (source code, drivers): enter_state(state) { // kernel/power/suspend.c suspend_prepare(state); // notify drivers ... pm_restrict_gfp_mask(); // disable swap suspend_devices_and_enter(state) â†’ dpm_suspend_start() { // drivers/base/power/main.c dpm_prepare() { // Call device_prepare() â†’ callback on each device in series. ...amdgpu_pmops_prepare(); } dpm_suspend() { // Call async_suspend() â†’ device_suspend() in parallel, // and/or device_suspend() â†’ callback in series. ...amdgpu_pmops_suspend(); } } } The patch moved VRAM eviction (and some other large allocations) from dpm_suspend() (when the SSD is being turned off) to dpm_prepare() earlier. This way, if amdgpu runs out of memory while backing up VRAM, it will abort the suspend before entering dpm_suspend() and attempting to suspend other devices. Previously, backing up VRAM during/after suspending other devices could cause them to crash from OOM themselves, or fail to resume from a failed suspend. Unfortunately suspending on high RAM usage would still fail to complete, even though the disks were still powered on! The amdgpu developers initially did not think that swap was disabled, but I discovered that the call to pm_restrict_gfp_mask() disabled swap before either dpm_prepare() or dpm_suspend() was called. When backing up VRAM during dpm_prepare(), amdgpu_ttm_evict_resources() often ran out of contiguous memory, causing dpm_prepare() to fail and abandoning the sleep attempt. Worse yet, if amdgpu_ttm_evict_resources() managed to fit all VRAM into system RAM, but there was not enough free memory to handle later allocations, then drivers would hit OOM and crash during sleep or wake. This meant that if you used up just enough RAM, you could still crash your system even with this patch. Nonetheless, the amdgpu developers considered Mario's kernel patch to be an improvement over backing up VRAM during dpm_suspend(), and submitted the patch to kernel review. When testing the patch, \"daqiu li\" reported extremely slow suspend (100 seconds) and suggested the use of __GFP_NORETRY for allocation. I did not experience the issue or how to evaluate the suggestion, and the amdgpu developers did not respond either. Along the way, Mario suggested I could hook up a serial console to my computer to pull logs off the system, even when the display and SSD were down. I found an internal serial header on my motherboard, bought a motherboard-to-DB9-bracket adapter (warning, there's two layouts of motherboard connector, and the header pin numbering differs from the port pins), and hooked my motherboard up to a serial-to-USB cable I plugged into my always-on server laptop. This allowed my laptop to continually capture data sent over the serial port, acting as a persistent serial console I could check when my PC crashed. On my desktop, I set up systemd-boot to pass additional parameters no_console_suspend console=tty0 console=ttyS0,115200 loglevel=8 (docs) to the kernel.1 On my laptop, I opened a terminal and ran sudo minicom --device /dev/ttyUSB0 --baudrate 115200 to monitor the computer over serial. In addition to saving logs, I could use the serial console to run commands on the system. Text transfer was slower than a direct getty TTY or SSH (a long wall of text could block the terminal for seconds), and it ran into issues with colors and screen size (breaking htop and fish shell completion), but it could often survive a system crash that broke display and networking. Intermission: Debugging crashes with Ghidra While testing swapping during prepare(), I got my usual OOM errors during or after backing up VRAM, but one crash stood out to me. At one point, amdgpu crashed with error BUG: unable to handle page fault for address: fffffffffffffffc, attempting to dereference a near-null pointer. To me this looked like a state-handling bug caused by failing to test a pointer for null. The crash log mentioned that the null pointer dereference occurred at dm_resume+0x200, but did not provide a line number corresponding to the source code I had. So I did the natural thing: I saved and extracted the amdgpu.ko kernel module, decompiled it in Ghidra, and mapped the location of the crash in dm_resume to the corresponding lines in the kernel source. While looking at the code, I found that the macro for_each_new_crtc_in_state(dm-\u003ecached_state, crtc, new_crtc_state, i) was crashing when it loaded pointer dm-\u003ecached_state into register RSI, then loaded field -\u003edev = [RSI + 0x8]. The crash dump said that RSI was fffffffffffffff4 rather than a valid pointer, then the code tried loading a field at offset 8 and page-faulted at address fffffffffffffffc (= RSI + 8). Why was dm-\u003ecached_state storing -12 instead of a pointer? Most likely this happened because earlier during suspend, dm_suspend() assigned dm.cached_state = drm_atomic_helper_suspend(adev_to_drm(adev)). The callee drm_atomic_helper_suspend() could return either a valid pointer, or ERR_PTR(err) which encoded errors as negative pointers. But the caller function assigned the return value directly to a pointer which gets dereferenced upon resume, instead of testing the return value for an error. In this case, I think that drm_atomic_helper_suspend() ran out of memory, printed and/or returned -ENOMEM (-12), and the amdgpu suspend code interpreted it as a pointer and unsafely dereferenced it upon waking. Mario fixed this issue by adding code to check for a failed return value and abort the suspend instead. Abandoned: Allow swapping during prepare()? At this time, high RAM usage still caused sleeping to fail. This happens because amdgpu backs up VRAM during dpm_prepare(), which runs after pm_restrict_gfp_mask() disables swapping to disk. I wanted to fix sleeping under high RAM usage by disabling swap after dpm_prepare() backs up VRAM, but before dpm_suspend() turns off the disk. Both dpm_â€¦() functions were called within dpm_suspend_start(), so this required moving pm_restrict_gfp_mask() deeper into the call hierarchy. enter_state() // kernel/power/suspend.c // removed pm_restrict_gfp_mask() call â†’ suspend_devices_and_enter() â†’ dpm_suspend_start(PMSG_SUSPEND) { // drivers/base/power/main.c dpm_prepare() { // backup VRAM, swap RAM to SSD } pm_restrict_gfp_mask(); // disable swap dpm_suspend() { // turn off SSD } } Unfortunately this posed some practical challenges: pm_restrict_gfp_mask() is declared in kernel/power/power.h (in the kernel/ core folder), and called in kernel/power/suspend.c. I wanted to call it in dpm_suspend_start() in file drivers/base/power/main.c, in the drivers/ subsystem. This file does not include headers from kernel/power/, but only includes \u003clinux/...h\u003e from include/, and \"../base.h\" etc. from drivers/base/power/. As a hack to allow drivers/base/power/main.c to access likely-private kernel core APIs, I edited it and added #include \u003c../kernel/power/power.h\u003e (from include/). If I wanted to upstream my change, I'd have to convince the power management and driver maintainer (both files were maintained by Rafael J. Wysocki) that this memory management API should be accessed by the driver subsystem. On top of this, there were more correctness challenges to disabling swap during dpm_suspend_start(). For example, hybrid sleep calls pm_restrict_gfp_mask() while saving a system image, then leaves swap disabled and calls suspend_devices_and_enter() â†’ dpm_suspend_start() while expecting the function will not call pm_restrict_gfp_mask() again (which would throw a warning and prevent pm_restore_gfp_mask() from reenabling swap). Hybrid sleep initiated through the less-used userspace ioctl API also leaves swap disabled after saving a system image. To \"handle\" this case, I added a function bool pm_gfp_mask_restricted(void), and modified dpm_suspend_start() to not call pm_restrict_gfp_mask() if it was already active. Oddly hybrid sleep calls dpm_prepare() â€¦ dpm_suspend() twice. It calls these functions to power down devices, saves a system image to disk, wakes the devices back up, then enters regular sleep mode through suspend_devices_and_enter(). (It only calls pm_restrict_gfp_mask() and pm_restore_gfp_mask() once.) I did not look into how drivers handle hibernation (dpm_prepare(PMSG_FREEZE)) and sleep (dpm_suspend_start(PMSG_SUSPEND) â†’ dpm_prepare(PMSG_SUSPEND)) differently. In my testing, this reduced the rate of failed or crashed suspends, but did not fix crashing entirely. After a system lockup I checked my serial console, but found to my dismay I hadn't restarted my serial logger after I rebooted my laptop, leaving me with no clue about what caused the crash. I decided against trying to upstream an \"improvement\" to power management, that required fragile changes to core power management infrastructure (outside of the amdgpu driver), and didn't even fully solve the problem. Sidenote: Corrupted consoles on shutdown While shutting down my machine, I've been intermittently getting corrupted screens filled with 8x16 blocks of colors. This pattern would fill the space around the shutdown console (which is the resolution of the smallest connected screen), though the console itself was missing since I had redirected it to serial.1 When this happened, I usually found a kernel error from dc_set_power_state during a previous (successful) sleep attempt, pointing to line ASSERT(dc-\u003ecurrent_state-\u003estream_count == 0); in the amdgpu driver. Close-up photo of 8x16 glitched pattern. I've reported the bug a few times in the thread, but have not made a separate bug report for this issue (because the symptoms are minor enough to be ignored). Neither I nor the amdgpu maintainers have determined why this happens. Workaround: Evicting VRAM in userspace A year later in 2024-10, I finished a session of SuperTuxKart, closed the game, and put my computer to sleep. When I woke my computer I was greeted by a black screen. I logged into the serial console and ran sudo rmmod -f amdgpu trying to reset the driver, but triggered a kernel panic instead. (I've sometimes managed to recover from an amdgpu crash by instead using systemctl suspend to power-cycle the GPU and driver.) Reviewing the logs revealed that one failed sleep attempt OOM'd in amdgpu during dpm_prepare(), and the next attempt used up enough memory that during resume, amdgpu's bw_calcs() crashed when allocating memory. This sent the amdgpu driver into an inconsistent state, resulting in a black screen and a stream of errors in the journal. At this point I had the idea to copy NVIDIA's userspace VRAM backup system. NVIDIA faced the same issue of being unable to save large amounts of VRAM to RAM when swap was disabled2, and wrote scripts that systemd runs before/after it tells the Linux kernel to sleep. Prior to sleeping, nvidia-suspend.service writes to /proc/driver/nvidia/suspend, telling the driver to switch to a blank TTY and backup VRAM to a tmpfile. After resuming, nvidia-resume.service tells the driver to restore VRAM from the file and return to the previous session. I forked NVIDIA's system services and built an amdgpu-sleep package for Arch Linux. Prior to system sleep, my script reads the contents of file /sys/kernel/debug/dri/1/amdgpu_evict_vram, a debugging endpoint that tells amdgpu to save all VRAM into system RAM. This way every time the system tried to sleep, systemd would wait for the GPU's VRAM to be evicted (moving system RAM into swap if needed) before initiating a kernel suspend. This workaround was partly successful. When I slept my computer from the desktop, the script could quickly copy all VRAM to memory (swapping out RAM to make room for VRAM) before entering the kernel to sleep the system. But when I slept my computer with multiple 3D apps running, the apps would continue rendering frames and pulling VRAM back onto the GPU, while the amdgpu_evict_vram callback was trying to move VRAM to system RAM! This tug-of-war livelock continued for over 70 seconds before amdgpu_evict_vram gave up on trying to move all VRAM to system memory, and systemd began the kernel suspend process (which froze userspace processes and successfully evicted VRAM). In any case, I left the scripts enabled on my computer, since they caused livelock less often than disabling the scripts caused kernel-level crashes. Solution: Power management notifiers In 2024-11, Mario asked users to test a patch that promised to allow evicting while swap was still active. I looked into the patch sources and found that it called a function register_pm_notifier() on a callback struct; this function belongs to Linux's power management notifier API. The callback in the patch listens to PM_HIBERNATION_PREPARE and PM_SUSPEND_PREPARE messages, and calls amdgpu_device_evict_resources() to evict VRAM. When is PM_SUSPEND_PREPARE issued during the suspend process? Reading the code, enter_state() â†’ suspend_prepare() calls pm_notifier_call_chain_robust(PM_SUSPEND_PREPARE, PM_POST_SUSPEND). This issues PM_SUSPEND_PREPARE to every driver with a notifier callback (including amdgpu), and if any failed it would abort sleep by issuing PM_POST_SUSPEND to any driver that had already prepared for sleep. We can revise the flowchart from before: enter_state(state) { // kernel/power/suspend.c suspend_prepare(state) { pm_notifier_call_chain_robust(PM_SUSPEND_PREPARE, PM_POST_SUSPEND) { // notify drivers ...amdgpu_device_pm_notifier() â†’ amdgpu_device_evict_resources(); } } ... pm_restrict_gfp_mask(); // disable swap suspend_devices_and_enter(state) â†’ dpm_suspend_start() { // drivers/base/power/main.c dpm_prepare()... dpm_suspend()... } } Evicting VRAM during PM_SUSPEND_PREPARE allows amdgpu to evict VRAM to system RAM before swapping is disabled or disks are frozen. It's interesting that neither Mario nor the other amdgpu maintainers thought to use this alternative hook until a year after I initially investigated the issue; I was not aware that this notifier API existed until then. To test the change, I built a custom kernel with the modified amdgpu driver, as rebuilding only the driver failed unlike last year. After rebooting, I was able to suspend multiple times under high RAM and VRAM usage with no errors. The only issue I noticed was a few seconds of audio looping, as amdgpu tried to back up VRAM before PipeWire or the kernel silenced the speakers (and PipeWire does not configure the ALSA output to stop playing when it runs out of data to be played). I do not know that this patch will always fix suspend, since my previous \"allow swapping during prepare()\" patch still hung the system during a sleep attempt. But since this patch was much cleaner and worked in all cases I had tested so far, I thought it was the current best step to fixing the bug. After a few rounds of code review, this change was merged into the amdgpu tree, finally resolving the bug after over a year of attempts. Sidenote: Alternative userspace sleep-wake workarounds, memreserver Reading the patch message out of curiosity, I found a separate bug report filed against AMD's ROCm compute drivers in 2024-10 (my bug report was against 3D graphics). This issue described the same issue (OOM evicting VRAM on suspend), but the replies linked to yet another amdgpu workaround known as memreserver, developed from 2020 to 2023. Like my userspace eviction attempt, this program is also a systemd service which runs a userspace program prior to system sleep. To make room for VRAM, memreserver allocates system RAM based on used VRAM plus 1 gigabyte, then fills the RAM with 0xFF bytes and mlocks the memory (so none of it is swapped out). Afterwards it quits to free up enough physical RAM to fit allocated VRAM. I have not tested this program's functionality or performance, but suspect that filling gigabytes of RAM with dummy bytes may be unnecessary or slow (though it's obviously better than a system crash). Conclusion This took over a year of debugging and multiple attempts by many people to fix. It should be hitting stable Linux kernel 6.14 in 2025 (unless it gets pushed or backported to 6.13), and will be fanning out to distributions as they pick up new kernels in their update cycles.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n  \t\n  \t\u003cp\u003e\u003cspan\u003eWritten by\u003c/span\u003e nyanpasu64\u003cbr/\u003e\n  \t\t\u003cspan\u003eonÂ \u003c/span\u003e\u003ctime datetime=\"2024-12-29T19:35:00-08:00\"\u003eDecember 29, 2024\u003c/time\u003e\n  \t\u003c/p\u003e\n  \t\n  \t\u003cp\u003eI dual-boot my desktop between Windows and Linux. Over the past few years, Linux would often crash when I tried to sleep my computer with high RAM usage. Upon waking it would show a black screen with moving cursor, or enter a \u0026#34;vegetative\u0026#34; state with no image on-screen, only responding to magic SysRq or a hard reset. I traced this behavior to an amdgpu driver power/memory management bug, which took over a year to brainstorm and implement solutions for.\u003c/p\u003e\n\u003cp\u003eTL;DR: The bug is \u003ca href=\"https://gitlab.freedesktop.org/agd5f/linux/-/commit/2965e6355dcdf157b5fafa25a2715f00064da8bf\"\u003efixed in agd5f/linux\u003c/a\u003e, and the change should be out in stable kernel 6.14.\u003c/p\u003e\n\u003ch2 id=\"diagnosing-the-problem\"\u003e\nDiagnosing the problem\u003c/h2\u003e\n\u003cp\u003eI started debugging this issue in 2023-09. My setup was a Gigabyte B550M DS3H motherboard with AMD RX 570 GPU and 1TB Kingston A2000 NVMe SSD, running Arch Linux with systemd-boot and Linux 6.4.\u003c/p\u003e\n\u003cp\u003eThe first thing I do after a system crash is to check the journals. For example, \u003ccode\u003ejournalctl --system -b -1\u003c/code\u003e will print system logs from the previous boot (dmesg and system services, excluding logs from my user account\u0026#39;s apps).\u003c/p\u003e\n\u003cp\u003eThe output showed that some sleep attempts had out-of-memory (OOM) errors in kernel code under \u003ccode\u003eamdgpu_device_suspend\u003c/code\u003e, and it took one or more failed attempts before the system crashed. Though oftentimes \u003ccode\u003ejournalctl\u003c/code\u003e would print \u003cem\u003eno logs\u003c/em\u003e whatsoever of the broken system waking up, terminating at:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cspan\u003eAug 30 12:47:01 ryzen systemd-sleep[41722]: Entering sleep state \u0026#39;suspend\u0026#39;...\n\u003c/span\u003e\u003cspan\u003eAug 30 12:47:01 ryzen kernel: PM: suspend entry (deep)\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAt one point after my computer attempted to sleep, it entered a \u0026#34;undead\u0026#34; state where the computer woke up enough to show KDE\u0026#39;s lock screen clock updating in real time, but locked up if I tried to log in or interact beyond a REISUB reboot. Terrifyingly, after rebooting the PC and checking the journals, they stopped at \u003ccode\u003eEntering sleep state \u0026#39;suspend\u0026#39;...\u003c/code\u003e and contained \u003cem\u003eno record\u003c/em\u003e of waking up and loading KDE\u0026#39;s lock screen. I concluded that the NVMe storage driver failed to reinitialize during system wakeup, causing the system to freeze and logs to stop being written.\u003c/p\u003e\n\u003cp\u003eI suspected that Linux was telling my NVMe drive to enter a power-saving APST mode, but my drive would instead stop responding to requests permanently. The \u003ca href=\"https://wiki.archlinux.org/title/Solid_state_drive/NVMe#Power_Saving_(APST)\"\u003eArch wiki\u003c/a\u003e suggested that I disable APST by adding kernel parameter \u003ccode\u003envme_core.default_ps_max_latency_us=0\u003c/code\u003e and enable software IOMMU using \u003ccode\u003eiommu=soft\u003c/code\u003e, but this did not solve my problem. Later I installed a SSD firmware upgrade that fixed APST handling (bricking not covered by warranty ðŸ˜‰), and upgraded to a 2TB boot SSD, but neither step helped.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOne contributing factor was that systemd would try multiple sleep modes back to back (\u003ca href=\"https://github.com/systemd/systemd/issues/25151\"\u003ebug report\u003c/a\u003e). If the first sleep attempt failed due to OOM, subsequent attempts would generate noise in system logs and corrupt the kernel further. I turned this off on my system by editing \u003ccode\u003e/etc/systemd/sleep.conf\u003c/code\u003e and adding \u003ccode\u003eSuspendState=mem\u003c/code\u003e; this simplified debugging but did not solve the underlying problem.\u003c/li\u003e\n\u003cli\u003eI also tried \u003ccode\u003eecho 1 \u0026gt; /sys/power/pm_trace\u003c/code\u003e to check where suspend failed, which had the side effect of disabling asynchronous suspend (which suspended multiple devices in parallel). I noticed that Linux would recover from amdgpu suspend failures rather than entering a full system hang.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epm_trace\u003c/code\u003e stores sleep-wake progress into a computer\u0026#39;s system time (\u003ca href=\"https://www.kernel.org/doc/Documentation/power/s2ram.rst\"\u003edocs\u003c/a\u003e), so after a failed sleep you can find which operation hung. At one point I rebooted or woke up my computer, only to find that the time was decades off!\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNext I enabled the systemd debug shell, which allowed me to run commands on a broken system even when I was unable to unlock KDE or log into a TTY. I added a \u003ccode\u003esystemd.debug_shell\u003c/code\u003e kernel parameter to my systemd-boot config, though the \u003ca href=\"https://fedoraproject.org/wiki/Systemd_early_debug-shell\"\u003eFedora wiki\u003c/a\u003e says you can also run \u003ccode\u003esystemctl enable debug-shell\u003c/code\u003e to enable it through systemd itself. Afterwards pressing Ctrl-Alt-F9 would spawn a root shell.\u003c/p\u003e\n\u003cp\u003eBecause the kernel crash sometimes broke the motherboard\u0026#39;s USB controller and keyboards, preventing me from typing into the debug shell, I dug a PS/2 keyboard out of a dusty closet and plugged it into my system (only safe when the PC is off!). This helped me navigate the debug shell, but was largely obsoleted by the serial console I set up later, which doesn\u0026#39;t require a working display output.\u003c/p\u003e\n\u003cp\u003eAfter looking through my crash logs, I noticed that the crashes generally happened in amdgpu\u0026#39;s TTM buffer eviction (\u003ccode\u003eamdgpu_device_evict_resources() â†’ amdgpu_ttm_evict_resources()\u003c/code\u003e). To learn what this meant and report my findings, I looked on amdgpu\u0026#39;s Gitlab bug tracker for issues related to sleep-wake crashing. I found a \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362\"\u003ebug report\u003c/a\u003e about crashing under high memory usage, which reported that \u0026#34;evict\u0026#34; means copying VRAM to system ram (or system RAM to swap).\u003c/p\u003e\n\u003cp\u003eThrough some digging, I found that when a desktop enters S3 sleep, the system cuts power to PCIe GPUs, causing their VRAM chips to lose data. To preserve this data, GPU drivers copy VRAM in use to system RAM before the system sleeps, then restore it after the system wakes. However the Linux amdgpu driver has a bug where, if there is not enough free RAM to store all VRAM in use, the system will run out of memory and crash, instead of moving RAM to disk-based swap.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf Linux OOMs during suspend, it will cancel sleeping and attempt to restart devices. However some drivers may break due to the aborted sleep, or themselves OOM during suspend or resume. This is more likely with asynchronous suspend enabled.\u003c/li\u003e\n\u003cli\u003eAlternatively Linux may successfully suspend, but OOM during resume while starting up devices.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"upstream-debugging\"\u003e\nUpstream debugging\u003c/h2\u003e\n\u003cp\u003eI thought that in order to allow swapping to disk, you\u0026#39;d have to evict VRAM to system RAM (while swapping out system RAM if it fills up) \u003cem\u003ebefore\u003c/em\u003e suspending disk-based storage. After we discussed on the bug report, Mario Limonciello \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2096149\"\u003esuggested\u003c/a\u003e that I enable \u003ccode\u003e/sys/power/pm_print_times\u003c/code\u003e and \u003ccode\u003e/sys/power/pm_debug_messages\u003c/code\u003e (\u003ca href=\"https://www.kernel.org/doc/Documentation/ABI/testing/sysfs-power\"\u003edocs\u003c/a\u003e) and check the logs from sleeping. The resulting logs showed that during sleep, the NVMe and amdgpu drivers entered \u003ccode\u003epci_pm_suspend\u003c/code\u003e in parallel.\u003c/p\u003e\n\u003cp\u003eI started looking for ways to move GPU suspend before SSD suspend, and found a \u003ca href=\"https://www.kernel.org/doc/html/v6.5/driver-api/device_link.html\"\u003emechanism for ordering device suspend\u003c/a\u003e. However it appeared built more for synchronizing tightly-coupled peripherals than suspending every GPU before any system disk. Mario \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2097101\"\u003einstead suggested\u003c/a\u003e evicting VRAM during \u003ca href=\"https://www.kernel.org/doc/html/latest/driver-api/pm/devices.html#entering-system-suspend\"\u003eLinux suspend\u0026#39;s prepare phase\u003c/a\u003e (before disks are suspended), and wrote some kernel patches to move VRAM eviction there.\u003c/p\u003e\n\u003cp\u003eAs an overview of how the suspend process fits together, I\u0026#39;ve written a flowchart of Linux\u0026#39;s suspend control flow (\u003ca href=\"https://github.com/torvalds/linux/blob/master/kernel/power/suspend.c\"\u003esource code\u003c/a\u003e, \u003ca href=\"https://github.com/torvalds/linux/blob/master/drivers/base/power/main.c\"\u003edrivers\u003c/a\u003e):\u003c/p\u003e\n\u003cpre data-lang=\"c\"\u003e\u003ccode data-lang=\"c\"\u003e\u003cspan\u003eenter_state\u003c/span\u003e\u003cspan\u003e(state) {  \u003c/span\u003e\u003cspan\u003e// kernel/power/suspend.c\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003esuspend_prepare\u003c/span\u003e\u003cspan\u003e(state);  \u003c/span\u003e\u003cspan\u003e// notify drivers\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003e...\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003epm_restrict_gfp_mask\u003c/span\u003e\u003cspan\u003e();  \u003c/span\u003e\u003cspan\u003e// disable swap\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003esuspend_devices_and_enter\u003c/span\u003e\u003cspan\u003e(state) â†’ \u003c/span\u003e\u003cspan\u003edpm_suspend_start\u003c/span\u003e\u003cspan\u003e() {  \u003c/span\u003e\u003cspan\u003e// drivers/base/power/main.c\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003edpm_prepare\u003c/span\u003e\u003cspan\u003e() {\n\u003c/span\u003e\u003cspan\u003e            \u003c/span\u003e\u003cspan\u003e// Call device_prepare() â†’ callback on each device in series.\n\u003c/span\u003e\u003cspan\u003e            \u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003eamdgpu_pmops_prepare\u003c/span\u003e\u003cspan\u003e();\n\u003c/span\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003edpm_suspend\u003c/span\u003e\u003cspan\u003e() {\n\u003c/span\u003e\u003cspan\u003e            \u003c/span\u003e\u003cspan\u003e// Call async_suspend() â†’ device_suspend() in parallel,\n\u003c/span\u003e\u003cspan\u003e            \u003c/span\u003e\u003cspan\u003e// and/or device_suspend() â†’ callback in series.\n\u003c/span\u003e\u003cspan\u003e            \u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003eamdgpu_pmops_suspend\u003c/span\u003e\u003cspan\u003e();\n\u003c/span\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe patch moved VRAM eviction (and some other large allocations) from \u003ccode\u003edpm_suspend()\u003c/code\u003e (when the SSD is being turned off) to \u003ccode\u003edpm_prepare()\u003c/code\u003e earlier. This way, if amdgpu runs out of memory while backing up VRAM, it will abort the suspend \u003cem\u003ebefore\u003c/em\u003e entering \u003ccode\u003edpm_suspend()\u003c/code\u003e and attempting to suspend other devices. Previously, backing up VRAM during/after suspending other devices could cause them to crash from OOM themselves, or fail to resume from a failed suspend.\u003c/p\u003e\n\u003cp\u003eUnfortunately suspending on high RAM usage would \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2111721\"\u003estill fail to complete\u003c/a\u003e, even though the disks were still powered on! The amdgpu developers initially did not think that swap was disabled, but I discovered that the call to \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e disabled swap before either \u003ccode\u003edpm_prepare()\u003c/code\u003e or \u003ccode\u003edpm_suspend()\u003c/code\u003e was called. When backing up VRAM during \u003ccode\u003edpm_prepare()\u003c/code\u003e, \u003ccode\u003eamdgpu_ttm_evict_resources()\u003c/code\u003e often ran out of \u003ca href=\"https://lore.kernel.org/amd-gfx/20241118200323.16541-1-mario.limonciello@amd.com/T/#u\"\u003econtiguous\u003c/a\u003e memory, causing \u003ccode\u003edpm_prepare()\u003c/code\u003e to fail and abandoning the sleep attempt.\u003c/p\u003e\n\u003cp\u003eWorse yet, if \u003ccode\u003eamdgpu_ttm_evict_resources()\u003c/code\u003e managed to fit all VRAM into system RAM, but there was not enough free memory to handle later allocations, then drivers would hit OOM and crash during sleep or wake. This meant that if you used up just enough RAM, you could \u003cem\u003estill\u003c/em\u003e crash your system even with this patch. Nonetheless, the amdgpu developers considered Mario\u0026#39;s kernel patch to be an improvement over backing up VRAM during \u003ccode\u003edpm_suspend()\u003c/code\u003e, and submitted the patch to kernel review.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhen testing the patch, \u0026#34;daqiu li\u0026#34; \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2220099\"\u003ereported extremely slow suspend\u003c/a\u003e (100 seconds) and suggested the use of \u003ccode\u003e__GFP_NORETRY\u003c/code\u003e for allocation. I did not experience the issue or how to evaluate the suggestion, and the amdgpu developers did not respond either.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr/\u003e\n\u003cp\u003eAlong the way, Mario suggested I could hook up a serial console to my computer to pull logs off the system, even when the display and SSD were down. I found an internal serial header on my motherboard, bought a motherboard-to-DB9-bracket adapter (warning, there\u0026#39;s two layouts of motherboard connector, and the header pin numbering differs from the port pins), and hooked my motherboard up to a serial-to-USB cable I plugged into my always-on server laptop. This allowed my laptop to continually capture data sent over the serial port, acting as a persistent serial console I could check when my PC crashed.\u003c/p\u003e\n\u003cp\u003eOn my desktop, I set up systemd-boot to pass additional parameters \u003ccode\u003eno_console_suspend console=tty0 console=ttyS0,115200 loglevel=8\u003c/code\u003e (\u003ca href=\"https://tldp.org/HOWTO/Remote-Serial-Console-HOWTO/configure-kernel.html\"\u003edocs\u003c/a\u003e) to the kernel.\u003csup\u003e\u003ca href=\"#tty-console\"\u003e1\u003c/a\u003e\u003c/sup\u003e On my laptop, I opened a terminal and ran \u003ccode\u003esudo minicom --device /dev/ttyUSB0 --baudrate 115200\u003c/code\u003e to monitor the computer over serial. In addition to saving logs, I could use the serial console to run commands on the system. Text transfer was slower than a direct getty TTY or SSH (a long wall of text could block the terminal for seconds), and it ran into issues with colors and screen size (breaking htop and fish shell completion), but it could often survive a system crash that broke display and networking.\u003c/p\u003e\n\u003ch3 id=\"intermission-debugging-crashes-with-ghidra\"\u003e\nIntermission: Debugging crashes with Ghidra\u003c/h3\u003e\n\u003cp\u003eWhile testing swapping during \u003ccode\u003eprepare()\u003c/code\u003e, I got my usual OOM errors during or after backing up VRAM, but one crash stood out to me. At one point, amdgpu crashed with error \u003ccode\u003eBUG: unable to handle page fault for address: fffffffffffffffc\u003c/code\u003e, attempting to dereference a near-null pointer. To me this looked like a state-handling bug caused by failing to test a pointer for null.\u003c/p\u003e\n\u003cp\u003eThe \u003ca href=\"https://gist.github.com/nyanpasu64/3dcf924d34983f0cd6bb532cc6e9e7b0\"\u003ecrash log\u003c/a\u003e mentioned that the null pointer dereference occurred at \u003ccode\u003edm_resume+0x200\u003c/code\u003e, but did not provide a line number corresponding to the source code I had. So I did the natural thing: I saved and extracted the \u003ccode\u003eamdgpu.ko\u003c/code\u003e kernel module, decompiled it in Ghidra, and mapped the location of the crash in \u003ccode\u003edm_resume\u003c/code\u003e to the corresponding lines in the kernel source.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2115049\"\u003eWhile looking at the code\u003c/a\u003e, I found that the macro \u003ccode\u003efor_each_new_crtc_in_state(dm-\u0026gt;cached_state, crtc, new_crtc_state, i)\u003c/code\u003e was crashing when it loaded pointer \u003ccode\u003edm-\u0026gt;cached_state\u003c/code\u003e into register \u003ccode\u003eRSI\u003c/code\u003e, then loaded field \u003ccode\u003e-\u0026gt;dev = [RSI + 0x8]\u003c/code\u003e. The crash dump said that \u003ccode\u003eRSI\u003c/code\u003e was \u003ccode\u003efffffffffffffff4\u003c/code\u003e rather than a valid pointer, then the code tried loading a field at offset 8 and page-faulted at address \u003ccode\u003efffffffffffffffc\u003c/code\u003e (= RSI + 8).\u003c/p\u003e\n\u003cp\u003eWhy was \u003ccode\u003edm-\u0026gt;cached_state\u003c/code\u003e storing -12 instead of a pointer? Most likely this happened because earlier during suspend, \u003ccode\u003edm_suspend()\u003c/code\u003e assigned \u003ccode\u003edm.cached_state = drm_atomic_helper_suspend(adev_to_drm(adev))\u003c/code\u003e. The callee \u003ccode\u003edrm_atomic_helper_suspend()\u003c/code\u003e could return either a valid pointer, or \u003ccode\u003eERR_PTR(err)\u003c/code\u003e which encoded errors as negative pointers. But the caller function assigned the return value directly to a pointer which gets dereferenced upon resume, instead of testing the return value for an error.\u003c/p\u003e\n\u003cp\u003eIn this case, I think that \u003ccode\u003edrm_atomic_helper_suspend()\u003c/code\u003e ran out of memory, printed and/or returned \u003ccode\u003e-ENOMEM\u003c/code\u003e (-12), and the amdgpu suspend code interpreted it as a pointer and unsafely dereferenced it upon waking. Mario \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2116000\"\u003efixed this issue\u003c/a\u003e by adding code to \u003ca href=\"https://lore.kernel.org/amd-gfx/20231006185026.5536-6-mario.limonciello@amd.com/\"\u003echeck for a failed return value\u003c/a\u003e and abort the suspend instead.\u003c/p\u003e\n\u003ch2 id=\"abandoned-allow-swapping-during-prepare\"\u003e\nAbandoned: Allow swapping during prepare()?\u003c/h2\u003e\n\u003cp\u003eAt this time, high RAM usage still caused sleeping to fail. This happens because amdgpu backs up VRAM during \u003ccode\u003edpm_prepare()\u003c/code\u003e, which runs \u003cem\u003eafter\u003c/em\u003e \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e disables swapping to disk. I wanted to fix sleeping under high RAM usage by disabling swap after \u003ccode\u003edpm_prepare()\u003c/code\u003e backs up VRAM, but before \u003ccode\u003edpm_suspend()\u003c/code\u003e turns off the disk. Both \u003ccode\u003edpm_â€¦()\u003c/code\u003e functions were called within \u003ccode\u003edpm_suspend_start()\u003c/code\u003e, so this required moving \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e deeper into the call hierarchy.\u003c/p\u003e\n\u003cpre data-lang=\"c\"\u003e\u003ccode data-lang=\"c\"\u003e\u003cspan\u003eenter_state\u003c/span\u003e\u003cspan\u003e()  \u003c/span\u003e\u003cspan\u003e// kernel/power/suspend.c\n\u003c/span\u003e\u003cspan\u003e// removed pm_restrict_gfp_mask() call\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eâ†’ \u003c/span\u003e\u003cspan\u003esuspend_devices_and_enter\u003c/span\u003e\u003cspan\u003e() â†’ \u003c/span\u003e\u003cspan\u003edpm_suspend_start\u003c/span\u003e\u003cspan\u003e(PMSG_SUSPEND) {  \u003c/span\u003e\u003cspan\u003e// drivers/base/power/main.c\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003edpm_prepare\u003c/span\u003e\u003cspan\u003e() {\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003e// backup VRAM, swap RAM to SSD\n\u003c/span\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003epm_restrict_gfp_mask\u003c/span\u003e\u003cspan\u003e();  \u003c/span\u003e\u003cspan\u003e// disable swap\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003edpm_suspend\u003c/span\u003e\u003cspan\u003e() {\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003e// turn off SSD\n\u003c/span\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUnfortunately this posed some practical challenges:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e is declared in \u003ccode\u003ekernel/power/power.h\u003c/code\u003e (in the \u003ccode\u003ekernel/\u003c/code\u003e core folder), and called in \u003ccode\u003ekernel/power/suspend.c\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eI wanted to call it in \u003ccode\u003edpm_suspend_start()\u003c/code\u003e in file \u003ccode\u003edrivers/base/power/main.c\u003c/code\u003e, in the \u003ccode\u003edrivers/\u003c/code\u003e subsystem. \u003ca href=\"https://github.com/torvalds/linux/blob/master/drivers/base/power/main.c\"\u003eThis file\u003c/a\u003e does not include headers from \u003ccode\u003ekernel/power/\u003c/code\u003e, but only includes \u003ccode\u003e\u0026lt;linux/...h\u0026gt;\u003c/code\u003e from \u003ccode\u003einclude/\u003c/code\u003e, and \u003ccode\u003e\u0026#34;../base.h\u0026#34;\u003c/code\u003e etc. from \u003ccode\u003edrivers/base/power/\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAs a hack to allow \u003ccode\u003edrivers/base/power/main.c\u003c/code\u003e to access likely-private kernel core APIs, I edited it and added \u003ccode\u003e#include \u0026lt;../kernel/power/power.h\u0026gt;\u003c/code\u003e (from \u003ccode\u003einclude/\u003c/code\u003e). If I wanted to upstream my change, I\u0026#39;d have to convince the power management and driver maintainer (\u003ca href=\"https://github.com/torvalds/linux/blob/master/MAINTAINERS\"\u003eboth files were maintained\u003c/a\u003e by Rafael J. Wysocki) that this memory management API should be accessed by the driver subsystem.\u003c/p\u003e\n\u003cp\u003eOn top of this, there were more correctness challenges to disabling swap \u003cem\u003eduring\u003c/em\u003e \u003ccode\u003edpm_suspend_start()\u003c/code\u003e. For example, \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2115049\"\u003ehybrid sleep calls\u003c/a\u003e \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e while saving a system image, then \u003cem\u003eleaves\u003c/em\u003e swap disabled and calls \u003ccode\u003esuspend_devices_and_enter() â†’ dpm_suspend_start()\u003c/code\u003e while expecting the function will not call \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e again (which would \u003ca href=\"https://github.com/torvalds/linux/blob/v6.12/kernel/power/main.c#L35-L50\"\u003ethrow a warning\u003c/a\u003e and prevent \u003ccode\u003epm_restore_gfp_mask()\u003c/code\u003e from reenabling swap). Hybrid sleep initiated through the less-used \u003ca href=\"https://docs.kernel.org/power/userland-swsusp.html\"\u003euserspace ioctl\u003c/a\u003e API \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2114607\"\u003ealso leaves swap disabled\u003c/a\u003e after saving a system image.\u003c/p\u003e\n\u003cp\u003eTo \u0026#34;handle\u0026#34; this case, I added a function \u003ccode\u003ebool pm_gfp_mask_restricted(void)\u003c/code\u003e, and modified \u003ccode\u003edpm_suspend_start()\u003c/code\u003e to not call \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e if it was already active.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOddly \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2115049\"\u003ehybrid sleep calls\u003c/a\u003e \u003ccode\u003edpm_prepare() â€¦ dpm_suspend()\u003c/code\u003e \u003cem\u003etwice\u003c/em\u003e. It calls these functions to power down devices, saves a system image to disk, wakes the devices back up, then enters regular sleep mode through \u003ccode\u003esuspend_devices_and_enter()\u003c/code\u003e. (It only calls \u003ccode\u003epm_restrict_gfp_mask()\u003c/code\u003e and \u003ccode\u003epm_restore_gfp_mask()\u003c/code\u003e once.)\u003c/li\u003e\n\u003cli\u003eI did not look into how drivers handle hibernation (\u003ccode\u003edpm_prepare(PMSG_FREEZE)\u003c/code\u003e) and sleep (\u003ccode\u003edpm_suspend_start(PMSG_SUSPEND) â†’ dpm_prepare(PMSG_SUSPEND)\u003c/code\u003e) differently.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn my testing, this reduced the rate of failed or crashed suspends, but did not fix crashing entirely. After a system lockup I checked my serial console, but found to my dismay I \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2127372\"\u003ehadn\u0026#39;t restarted my serial logger\u003c/a\u003e after I rebooted my laptop, leaving me with no clue about what caused the crash. I decided against trying to upstream an \u0026#34;improvement\u0026#34; to power management, that required fragile changes to core power management infrastructure (outside of the amdgpu driver), and didn\u0026#39;t even fully solve the problem.\u003c/p\u003e\n\u003ch3 id=\"sidenote-corrupted-consoles-on-shutdown\"\u003e\nSidenote: Corrupted consoles on shutdown\u003c/h3\u003e\n\u003cp\u003eWhile shutting down my machine, I\u0026#39;ve been \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2129196\"\u003eintermittently getting corrupted screens\u003c/a\u003e filled with 8x16 blocks of colors. This pattern would fill the space around the shutdown console (which is the resolution of the smallest connected screen), though the console itself was missing since I had redirected it to serial.\u003csup\u003e\u003ca href=\"#tty-console\"\u003e1\u003c/a\u003e\u003c/sup\u003e When this happened, I usually found a kernel error from \u003ccode\u003edc_set_power_state\u003c/code\u003e during a previous (successful) sleep attempt, pointing to line \u003ccode\u003eASSERT(dc-\u0026gt;current_state-\u0026gt;stream_count == 0);\u003c/code\u003e in the amdgpu driver.\u003c/p\u003e\n\n\u003cfigure\u003e\n  \u003ca href=\"https://nyanpasu64.gitlab.io/blog/amdgpu-sleep-wake-hang/PXL_20231010_071642558.jpg\"\u003e\u003cimg src=\"https://nyanpasu64.gitlab.io/processed_images/PXL_20231010_071642558.ddddf3bec420509f.jpg\" alt=\"Macro photo of colorful glitched patterns on a LCD screen in 8x16 blocks, each made up of horizontal lines.\"/\u003e\u003c/a\u003e\n  \u003cfigcaption\u003eClose-up photo of 8x16 glitched pattern.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eI\u0026#39;ve reported the bug a few times in the thread, but have not made a separate bug report for this issue (because the symptoms are minor enough to be ignored). Neither I nor the amdgpu maintainers have determined why this happens.\u003c/p\u003e\n\u003ch2 id=\"workaround-evicting-vram-in-userspace\"\u003e\nWorkaround: Evicting VRAM in userspace\u003c/h2\u003e\n\u003cp\u003eA year later in 2024-10, I finished a session of SuperTuxKart, closed the game, and put my computer to sleep. When I woke my computer I was greeted by a black screen. I logged into the serial console and ran \u003ccode\u003esudo rmmod -f amdgpu\u003c/code\u003e trying to reset the driver, but triggered a kernel panic instead. (I\u0026#39;ve sometimes managed to recover from an amdgpu crash by instead using \u003ccode\u003esystemctl suspend\u003c/code\u003e to power-cycle the GPU and driver.)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2606387\"\u003eReviewing the logs revealed\u003c/a\u003e that one failed sleep attempt OOM\u0026#39;d in amdgpu during \u003ccode\u003edpm_prepare()\u003c/code\u003e, and the next attempt used up enough memory that during resume, amdgpu\u0026#39;s \u003ccode\u003ebw_calcs()\u003c/code\u003e crashed when allocating memory. This sent the amdgpu driver into an inconsistent state, resulting in a black screen and a stream of errors in the journal.\u003c/p\u003e\n\u003cp\u003eAt this point I had the idea to copy NVIDIA\u0026#39;s \u003ca href=\"https://download.nvidia.com/XFree86/Linux-x86_64/560.35.03/README/powermanagement.html\"\u003euserspace VRAM backup system\u003c/a\u003e. NVIDIA faced the same issue of being unable to save large amounts of VRAM to RAM when swap was disabled\u003csup\u003e\u003ca href=\"#nvidia\"\u003e2\u003c/a\u003e\u003c/sup\u003e, and wrote scripts that systemd runs before/after it tells the Linux kernel to sleep. Prior to sleeping, \u003ccode\u003envidia-suspend.service\u003c/code\u003e writes to \u003ccode\u003e/proc/driver/nvidia/suspend\u003c/code\u003e, telling the driver to switch to a blank TTY and backup VRAM to a tmpfile. After resuming, \u003ccode\u003envidia-resume.service\u003c/code\u003e tells the driver to restore VRAM from the file and return to the previous session.\u003c/p\u003e\n\u003cp\u003eI forked NVIDIA\u0026#39;s system services and built an \u003ca href=\"https://gitlab.freedesktop.org/nyanpasu64/amdgpu-sleep\"\u003eamdgpu-sleep\u003c/a\u003e package for Arch Linux. Prior to system sleep, my script reads the contents of file \u003ccode\u003e/sys/kernel/debug/dri/1/amdgpu_evict_vram\u003c/code\u003e, a debugging endpoint that tells amdgpu to save all VRAM into system RAM. This way every time the system tried to sleep, systemd would wait for the GPU\u0026#39;s VRAM to be evicted (moving system RAM into swap if needed) before initiating a kernel suspend.\u003c/p\u003e\n\u003cp\u003eThis workaround was partly successful. When I slept my computer from the desktop, the script could quickly copy all VRAM to memory (swapping out RAM to make room for VRAM) before entering the kernel to sleep the system. But when I slept my computer with multiple 3D apps running, \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2606387\"\u003ethe apps would continue rendering frames\u003c/a\u003e and pulling VRAM back onto the GPU, while the \u003ccode\u003eamdgpu_evict_vram\u003c/code\u003e callback was trying to move VRAM to system RAM! This tug-of-war livelock continued for over 70 seconds before \u003ccode\u003eamdgpu_evict_vram\u003c/code\u003e gave up on trying to move all VRAM to system memory, and systemd began the kernel suspend process (which froze userspace processes and \u003cem\u003esuccessfully\u003c/em\u003e evicted VRAM).\u003c/p\u003e\n\u003cp\u003eIn any case, I left the scripts enabled on my computer, since they caused livelock less often than disabling the scripts caused kernel-level crashes.\u003c/p\u003e\n\u003ch2 id=\"solution-power-management-notifiers\"\u003e\nSolution: Power management notifiers\u003c/h2\u003e\n\u003cp\u003eIn 2024-11, Mario \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2667918\"\u003easked users to test a patch\u003c/a\u003e that promised to allow evicting while swap was still active. I looked into the \u003ca href=\"https://lore.kernel.org/amd-gfx/20241118200323.16541-1-mario.limonciello@amd.com/T/#u\"\u003epatch sources\u003c/a\u003e and found that it called a function \u003ccode\u003eregister_pm_notifier()\u003c/code\u003e on a callback struct; this function belongs to Linux\u0026#39;s \u003ca href=\"https://docs.kernel.org/driver-api/pm/notifiers.html\"\u003epower management notifier API\u003c/a\u003e. The callback in the patch listens to \u003ccode\u003ePM_HIBERNATION_PREPARE\u003c/code\u003e and \u003ccode\u003ePM_SUSPEND_PREPARE\u003c/code\u003e messages, and calls \u003ccode\u003eamdgpu_device_evict_resources()\u003c/code\u003e to evict VRAM.\u003c/p\u003e\n\u003cp\u003eWhen is \u003ccode\u003ePM_SUSPEND_PREPARE\u003c/code\u003e issued during the suspend process? Reading the code, \u003ccode\u003eenter_state() â†’ suspend_prepare()\u003c/code\u003e calls \u003ccode\u003epm_notifier_call_chain_robust(PM_SUSPEND_PREPARE, PM_POST_SUSPEND)\u003c/code\u003e. This issues \u003ccode\u003ePM_SUSPEND_PREPARE\u003c/code\u003e to every driver with a notifier callback (including amdgpu), and if any failed it would abort sleep by issuing \u003ccode\u003ePM_POST_SUSPEND\u003c/code\u003e to any driver that had already prepared for sleep.\u003c/p\u003e\n\u003cp\u003eWe can revise the flowchart from before:\u003c/p\u003e\n\u003cpre data-lang=\"c\"\u003e\u003ccode data-lang=\"c\"\u003e\u003cspan\u003eenter_state\u003c/span\u003e\u003cspan\u003e(state) {  \u003c/span\u003e\u003cspan\u003e// kernel/power/suspend.c\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003esuspend_prepare\u003c/span\u003e\u003cspan\u003e(state) {\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003epm_notifier_call_chain_robust\u003c/span\u003e\u003cspan\u003e(PM_SUSPEND_PREPARE, PM_POST_SUSPEND) {  \u003c/span\u003e\u003cspan\u003e// notify drivers\n\u003c/span\u003e\u003cspan\u003e            \u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003eamdgpu_device_pm_notifier\u003c/span\u003e\u003cspan\u003e() â†’ \u003c/span\u003e\u003cspan\u003eamdgpu_device_evict_resources\u003c/span\u003e\u003cspan\u003e();\n\u003c/span\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003e...\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003epm_restrict_gfp_mask\u003c/span\u003e\u003cspan\u003e();  \u003c/span\u003e\u003cspan\u003e// disable swap\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003esuspend_devices_and_enter\u003c/span\u003e\u003cspan\u003e(state) â†’ \u003c/span\u003e\u003cspan\u003edpm_suspend_start\u003c/span\u003e\u003cspan\u003e() {  \u003c/span\u003e\u003cspan\u003e// drivers/base/power/main.c\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003edpm_prepare\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\u003cspan\u003e...\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003edpm_suspend\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\u003cspan\u003e...\n\u003c/span\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEvicting VRAM during \u003ccode\u003ePM_SUSPEND_PREPARE\u003c/code\u003e allows amdgpu to evict VRAM to system RAM \u003cem\u003ebefore\u003c/em\u003e swapping is disabled or disks are frozen. It\u0026#39;s interesting that neither Mario nor the other amdgpu maintainers thought to use this alternative hook until a year after I initially investigated the issue; I was not aware that this notifier API existed until then.\u003c/p\u003e\n\u003cp\u003eTo test the change, I built a custom kernel with the modified amdgpu driver, as \u003ca href=\"https://gitlab.freedesktop.org/drm/amd/-/issues/2362#note_2669637\"\u003erebuilding only the driver failed\u003c/a\u003e unlike last year. After rebooting, I was able to suspend multiple times under high RAM and VRAM usage with no errors. The only issue I noticed was a few seconds of audio looping, as amdgpu tried to back up VRAM \u003cem\u003ebefore\u003c/em\u003e PipeWire or the kernel silenced the speakers (and PipeWire does not configure the ALSA output to stop playing when it runs out of data to be played).\u003c/p\u003e\n\u003cp\u003eI do not know that this patch will \u003cem\u003ealways\u003c/em\u003e fix suspend, since my previous \u003ca href=\"https://nyanpasu64.gitlab.io/blog/amdgpu-sleep-wake-hang/#abandoned-allow-swapping-during-prepare\"\u003e\u0026#34;allow swapping during prepare()\u0026#34;\u003c/a\u003e patch still hung the system during a sleep attempt. But since this patch was much cleaner and worked in all cases I had tested so far, I thought it was the current best step to fixing the bug. After a few rounds of code review, this change was merged into the amdgpu tree, \u003cem\u003efinally\u003c/em\u003e resolving the bug after over a year of attempts.\u003c/p\u003e\n\u003ch3 id=\"sidenote-alternative-userspace-sleep-wake-workarounds-memreserver\"\u003e\nSidenote: Alternative userspace sleep-wake workarounds, \u003ccode\u003ememreserver\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eReading the \u003ca href=\"https://lore.kernel.org/amd-gfx/20241118200323.16541-1-mario.limonciello@amd.com/T/#u\"\u003epatch message\u003c/a\u003e out of curiosity, I found a \u003ca href=\"https://github.com/ROCm/ROCK-Kernel-Driver/issues/174\"\u003eseparate bug report\u003c/a\u003e filed against AMD\u0026#39;s ROCm compute drivers in 2024-10 (my bug report was against 3D graphics). This issue described the same issue (OOM evicting VRAM on suspend), but the replies linked to \u003cem\u003eyet another\u003c/em\u003e amdgpu workaround known as \u003ca href=\"https://git.dolansoft.org/lorenz/memreserver\"\u003ememreserver\u003c/a\u003e, developed from 2020 to 2023. Like my userspace eviction attempt, this program is also a systemd service which runs a userspace program prior to system sleep.\u003c/p\u003e\n\u003cp\u003eTo make room for VRAM, memreserver allocates \u003cem\u003esystem RAM\u003c/em\u003e based on used VRAM plus 1 gigabyte, then fills the RAM with 0xFF bytes and \u003ccode\u003emlock\u003c/code\u003es the memory (so none of it is swapped out). Afterwards it quits to free up enough physical RAM to fit allocated VRAM. I have not tested this program\u0026#39;s functionality or performance, but suspect that filling gigabytes of RAM with dummy bytes may be unnecessary or slow (though it\u0026#39;s obviously better than a system crash).\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003e\nConclusion\u003c/h2\u003e\n\u003cp\u003eThis took over a year of debugging and multiple attempts by many people to fix. It should be hitting stable Linux kernel 6.14 in 2025 (unless it gets pushed or backported to 6.13), and will be fanning out to distributions as they pick up new kernels in their update cycles.\u003c/p\u003e\n\n\n\n\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "24 min read",
  "publishedTime": "2024-12-29T19:35:00-08:00",
  "modifiedTime": null
}
