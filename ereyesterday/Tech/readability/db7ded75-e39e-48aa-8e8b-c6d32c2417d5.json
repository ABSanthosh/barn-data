{
  "id": "db7ded75-e39e-48aa-8e8b-c6d32c2417d5",
  "title": "The latest AI news we announced in March",
  "link": "https://blog.google/technology/ai/google-ai-updates-march-2025/",
  "description": "Here are Google’s latest AI updates from March 2025.",
  "author": "Keyword Team\u003cdepartment/\u003e\u003ccompany/\u003e",
  "published": "Fri, 04 Apr 2025 14:30:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Search",
    "Google DeepMind",
    "Developers",
    "Entrepreneurs",
    "Shopping",
    "Gemini",
    "Sustainability",
    "AI",
    "Pixel",
    "Gemini App",
    "Gemini Models",
    "Research"
  ],
  "byline": "Keyword Team",
  "length": 8391,
  "excerpt": "Here are Google’s latest AI updates from March 2025.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20250401-1731",
  "text": "Apr 04, 2025 [[read-time]] min read Here’s a recap of some of our biggest AI updates from March, including Gemini 2.5 Pro, expanded access to AI Overviews, the release of AI Mode and more. General summary Google made significant progress in AI during March. They expanded access to AI Overviews and introduced AI Mode in Search, making it easier to find answers and explore topics. They also released Gemini 2.5 Pro, their most intelligent AI model, and Gemini Robotics, which aims to bring AI into the physical world. Google is also using AI to help developers create applications, detect wildfires, and protect nature. Summaries were generated by Google AI. Generative AI is experimental. Shakespeare-ish In March, Google's AI did advance, With Gemini's upgrades, a grand expanse. New features, like personalization, And AI Overviews, a great realization. For shoppers, robots, and developers too, AI's reach expands, a helpful view. From wildfire detection to nature's aid, Google's AI, a path we've made. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! For more than 20 years, we’ve invested in machine learning and AI research, tools and infrastructure to build products that make everyday life better for more people. Teams across Google are working on ways to unlock AI’s benefits in fields as wide-ranging as healthcare, crisis response and education. To keep you posted on our progress, we're doing a regular roundup of Google's most recent AI news across products, research and more.Here’s a look back at just some of our AI announcements from March. March was all about expanding AI across our products to make them even more helpful. The Gemini app was upgraded to include new features like personalization, Canvas and Audio Overviews, and we made our Deep Research and Gems features available at no cost. We also added our speedy Gemini 2.0 Flash Thinking experimental model under the hood — and one-upped ourselves just a few days later by making our most intelligent AI model, Gemini 2.5 Pro (experimental), available to all Gemini users.Gemini 2.5 Pro is state-of-the-art on a wide range of benchmarks — try it out now in Gemini, or in Google AI Studio. Read on for more ways we've been making our leading AI even more helpful for Pixel users, online shoppers, roboticists, developers, wildfire authorities and beyond. We expanded access to AI Overviews and introduced AI Mode. AI Overviews are one of our most popular Search features and are now used by more than a billion people. Starting in the U.S., we launched Gemini 2.0 for AI Overviews to help with harder questions, beginning with coding, advanced math and multimodal queries to provide faster and higher quality responses. We also announced the new AI Mode experiment in Google Search to help people get AI-powered responses and dig deeper with follow-up questions and links to helpful web content.We launched personalization in Gemini to make its responses more relevant to you. Gemini with personalization gives you the option to use your Search history to deliver contextually relevant responses that are adapted to your individual interests. With your permission, Gemini can now tailor its responses based on your past searches, saving you time and delivering more precise answers. In the coming months, Gemini will expand its ability to understand you better by connecting with other Google apps and services, including Photos and YouTube.We added updates for Gemini Live, Scam Detection and more in our March Pixel Drop. Our first Pixel Drop of the year included more helpful features and updates to your devices. Gemini Live, a conversational experience that helps you brainstorm ideas, simplify complex topics and rehearse for important moments was upgraded for better performance during multilingual conversation. You can now seamlessly switch between more than 45 languages when speaking to Gemini Live. Plus, features like stronger Scam Detection, better step accuracy and Auto-bedtime Mode bring even more AI to Pixel.We released new AI tools for Google Shopping to help you find the perfect products. Our new immersive shopping features — like our vision match feature — can help you find clothes and beauty products to fit your style. With vision match, you can describe any garment you have in mind, and get back an AI-generated image that shows you what it could look like, along with similar shoppable products. It’s another way we’re making it even easier to find items that resonate with you. We released Gemini Robotics to help bring AI into the physical world. We introduced two new AI models, based on Gemini 2.0, which are designed to lay the foundation for a new generation of helpful robots. The first is Gemini Robotics, an advanced vision-language-action (VLA) model that was built on Gemini 2.0 for the purpose of directly controlling robots. The second, Gemini Robotics-ER, is a Gemini model with advanced spatial understanding, enabling roboticists to run their own programs using Gemini’s embodied reasoning (ER) abilities. We released Gemma 3 to help developers create even more helpful applications. Gemma 3, the latest version of our lightweight, state-of-the-art open models that can run on a single TPU or GPU, are designed to be our most advanced and portable open models for developers. They’re meant to run fast, directly on devices — from phones and laptops to workstations — helping developers create AI applications, wherever people need them. The first FireSat satellite for early detection of wildfires made contact with Earth. The FireSat satellite launched from Vandenberg Space Force Base in California aboard SpaceX's Transporter-13 mission. This satellite — a collaboration between Google, Muon Space, Earth Fire Alliance, Moore Foundation, wildfire authorities and others — is the first of more than 50 in a first-of-its-kind constellation designed to ultimately use AI to detect and track wildfires as small as roughly 5x5 meters.We launched three new initiatives to protect and restore nature using AI. A startup accelerator, kicking off in May 2025, includes programming, mentoring and technical support from Google. Google.org is also providing $3 million to support AI-enabled solutions for biodiversity, bioeconomy and agriculture from Brazilian nonprofits. And we released SpeciesNet, a Cloud-based, open-source AI model for identifying animal species from camera trap photos, enabling people to protect nature and biodiversity. POSTED IN: AI Gemini Gemini App Gemini Models Google DeepMind Sustainability Research Pixel Shopping Entrepreneurs Developers Search",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/march_ai.width-1300.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n  }\"\u003e\n  \n  \u003cdiv\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eApr 04, 2025\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          Here’s a recap of some of our biggest AI updates from March, including Gemini 2.5 Pro, expanded access to AI Overviews, the release of AI Mode and more.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n  \n  \u003cdiv data-component=\"uni-ai-generated-summary\" data-analytics-module=\"{\n    \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n    \u0026#34;module_name\u0026#34;: \u0026#34;ai_summary\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;CTA\u0026#34;\n  }\"\u003e\n      \n        \u003cdiv data-summary-id=\"ai_summary_1\"\u003e\n          \u003ch2\u003eGeneral summary\u003c/h2\u003e\n          \u003cp\u003eGoogle made significant progress in AI during March. They expanded access to AI Overviews and introduced AI Mode in Search, making it easier to find answers and explore topics. They also released Gemini 2.5 Pro, their most intelligent AI model, and Gemini Robotics, which aims to bring AI into the physical world. Google is also using AI to help developers create applications, detect wildfires, and protect nature.\u003c/p\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n      \n        \u003cdiv data-summary-id=\"ai_summary_4\"\u003e\n          \u003ch2\u003eShakespeare-ish\u003c/h2\u003e\n          \u003cp\u003eIn March, Google\u0026#39;s AI did advance,\u003cbr/\u003e\nWith Gemini\u0026#39;s upgrades, a grand expanse.\u003cbr/\u003e\nNew features, like personalization,\u003cbr/\u003e\nAnd AI Overviews, a great realization.\u003c/p\u003e\n\u003cp\u003eFor shoppers, robots, and developers too,\u003cbr/\u003e\nAI\u0026#39;s reach expands, a helpful view.\u003cbr/\u003e\nFrom wildfire detection to nature\u0026#39;s aid,\u003cbr/\u003e\nGoogle\u0026#39;s AI, a path we\u0026#39;ve made.\u003c/p\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n      \n\n      \n      \u003cdiv\u003e\n        \u003ch4\u003e\n          Explore other styles:\n        \u003c/h4\u003e\n        \n      \u003c/div\u003e\n      \n\n      \u003c/div\u003e\n\u003c/div\u003e\n\n    \n\n    \n      \u003cdiv\u003e\n      \u003cp\u003e\n        \u003cvideo autoplay=\"\" muted=\"\" loop=\"\" playsinline=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/March_AI.mp4\" title=\"an MP4 video featuring alternative images like a robot, a series of blue squares and a software interface\" poster=\"\n            \n              https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/march_ai.png\n            \"\u003e\n          Sorry, your browser doesn\u0026#39;t support embedded videos, but don\u0026#39;t worry, you can\n            \u003ca href=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/March_AI.mp4\"\u003edownload it\u003c/a\u003e\n            and watch it with your favorite video player!\n        \u003c/video\u003e\n      \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\n\n\n\u003cuni-article-speakable page-title=\"The latest AI news we announced in March\" listen-to-article=\"Listen to article\" data-date-modified=\"2025-04-04T18:35:37.186438+00:00\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-script-src=\"https://www.gstatic.com/readaloud/player/web/api/js/api.js\"\u003e\u003c/uni-article-speakable\u003e\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"eakgv\"\u003eFor more than 20 years, we’ve invested in machine learning and AI research, tools and infrastructure to build products that make everyday life better for more people. Teams across Google are working on ways to unlock AI’s benefits in fields as wide-ranging as healthcare, crisis response and education. To keep you posted on our progress, we\u0026#39;re doing a regular roundup of Google\u0026#39;s most recent AI news across products, research and more.\u003c/p\u003e\u003cp data-block-key=\"8v9pe\"\u003eHere’s a look back at just some of our AI announcements from March.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"a text card reading \u0026#34;The big picture\u0026#34;\" external-image=\"\" or-mp4-video-title=\"\" or-mp4-video-url=\"\" section-header=\"The latest AI news we announced in March\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n  \n    \u003cp\u003e\u003cimg alt=\"a text card reading \u0026#34;The big picture\u0026#34;\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-03.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n            \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-03.width-500.format-webp.webp\u0026#34;,\n            \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-03.width-1000.format-webp.webp\u0026#34;\n          }\"/\u003e\n    \u003c/p\u003e\n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"eakgv\"\u003eMarch was all about expanding AI across our products to make them even more helpful. The Gemini app was upgraded to include new features like \u003ca href=\"https://blog.google/products/gemini/gemini-personalization/\"\u003epersonalization\u003c/a\u003e, \u003ca href=\"https://blog.google/products/gemini/gemini-collaboration-features/\"\u003eCanvas\u003c/a\u003e and Audio Overviews, and we made our Deep Research and Gems features \u003ca href=\"https://blog.google/products/gemini/new-gemini-app-features-march-2025/\"\u003eavailable at no cost\u003c/a\u003e. We also added our speedy Gemini 2.0 Flash Thinking experimental model under the hood — and one-upped ourselves \u003ca href=\"https://x.com/sundarpichai/status/1906141478029799873\"\u003ejust a few days\u003c/a\u003e later by making our most intelligent AI model, \u003ca href=\"https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro\"\u003eGemini 2.5 Pro (experimental)\u003c/a\u003e, available to all Gemini users.\u003c/p\u003e\u003cp data-block-key=\"6ru8n\"\u003eGemini 2.5 Pro is state-of-the-art on a wide range of benchmarks — try it out now in Gemini, or in Google AI Studio. Read on for more ways we\u0026#39;ve been making our leading AI even more helpful for Pixel users, online shoppers, roboticists, developers, wildfire authorities and beyond.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"a text card reading \u0026#34;AI to help you day to day\u0026#34;\" external-image=\"\" or-mp4-video-title=\"\" or-mp4-video-url=\"\" section-header=\"The latest AI news we announced in March\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n  \n    \u003cp\u003e\u003cimg alt=\"a text card reading \u0026#34;AI to help you day to day\u0026#34;\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-02.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n            \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-02.width-500.format-webp.webp\u0026#34;,\n            \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-02.width-1000.format-webp.webp\u0026#34;\n          }\"/\u003e\n    \u003c/p\u003e\n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"eakgv\"\u003e\u003ca href=\"https://blog.google/products/search/ai-mode-search/\"\u003e\u003cb\u003eWe expanded access to AI Overviews and introduced AI Mode\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e AI Overviews are one of our most popular Search features and are now used by more than a billion people. Starting in the U.S., we launched Gemini 2.0 for AI Overviews to help with harder questions, beginning with coding, advanced math and multimodal queries to provide faster and higher quality responses. We also announced the new AI Mode experiment in Google Search to help people get AI-powered responses and dig deeper with follow-up questions and links to helpful web content.\u003c/p\u003e\u003cp data-block-key=\"3aq7v\"\u003e\u003ca href=\"https://blog.google/products/gemini/gemini-personalization/\"\u003e\u003cb\u003eWe launched personalization in Gemini to make its responses more relevant to you\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e Gemini with personalization gives you the option to use your Search history to deliver contextually relevant responses that are adapted to your individual interests. With your permission, Gemini can now tailor its responses based on your past searches, saving you time and delivering more precise answers. In the coming months, Gemini will expand its ability to understand you better by connecting with other Google apps and services, including Photos and YouTube.\u003c/p\u003e\u003cp data-block-key=\"4hb2o\"\u003e\u003ca href=\"https://blog.google/products/pixel/pixel-drop-march-2025/\"\u003e\u003cb\u003eWe added updates for Gemini Live, Scam Detection and more in our March Pixel Drop\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e Our first Pixel Drop of the year included more helpful features and updates to your devices. Gemini Live, a conversational experience that helps you brainstorm ideas, simplify complex topics and rehearse for important moments was upgraded for better performance during multilingual conversation. You can now seamlessly switch between more than 45 languages when speaking to Gemini Live. Plus, features like stronger Scam Detection, better step accuracy and Auto-bedtime Mode bring even more AI to Pixel.\u003c/p\u003e\u003cp data-block-key=\"73bdc\"\u003e\u003ca href=\"https://blog.google/products/shopping/ai-vision-match-ar-beauty-virtual-try-on/\"\u003e\u003cb\u003eWe released new AI tools for Google Shopping to help you find the perfect products\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e Our new immersive shopping features — like our vision match feature — can help you find clothes and beauty products to fit your style. With vision match, you can describe any garment you have in mind, and get back an AI-generated image that shows you what it could look like, along with similar shoppable products. It’s another way we’re making it even easier to find items that resonate with you.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"a text card reading \u0026#34;AI to build a new generation of helpful robots\u0026#34;\" external-image=\"\" or-mp4-video-title=\"\" or-mp4-video-url=\"\" section-header=\"The latest AI news we announced in March\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n  \n    \u003cp\u003e\u003cimg alt=\"a text card reading \u0026#34;AI to build a new generation of helpful robots\u0026#34;\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-05.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n            \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-05.width-500.format-webp.webp\u0026#34;,\n            \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-05.width-1000.format-webp.webp\u0026#34;\n          }\"/\u003e\n    \u003c/p\u003e\n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"eakgv\"\u003e\u003ca href=\"https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/\"\u003e\u003cb\u003eWe released Gemini Robotics to help bring AI into the physical world\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e We introduced two new AI models, based on Gemini 2.0, which are designed to lay the foundation for a new generation of helpful robots. The first is Gemini Robotics, an advanced vision-language-action (VLA) model that was built on Gemini 2.0 for the purpose of directly controlling robots. The second, Gemini Robotics-ER, is a Gemini model with advanced spatial understanding, enabling roboticists to run their own programs using Gemini’s embodied reasoning (ER) abilities.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"a text card reading \u0026#34;AI to help developers get more done\u0026#34;\" external-image=\"\" or-mp4-video-title=\"\" or-mp4-video-url=\"\" section-header=\"The latest AI news we announced in March\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n  \n    \u003cp\u003e\u003cimg alt=\"a text card reading \u0026#34;AI to help developers get more done\u0026#34;\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-04.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n            \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-04.width-500.format-webp.webp\u0026#34;,\n            \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-04.width-1000.format-webp.webp\u0026#34;\n          }\"/\u003e\n    \u003c/p\u003e\n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"eakgv\"\u003e\u003ca href=\"https://blog.google/technology/developers/gemma-3/\"\u003e\u003cb\u003eWe released Gemma 3 to help developers create even more helpful applications\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e Gemma 3, the latest version of our lightweight, state-of-the-art open models that can run on a single TPU or GPU, are designed to be our most advanced and portable open models for developers. They’re meant to run fast, directly on devices — from phones and laptops to workstations — helping developers create AI applications, wherever people need them.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"a text card reading \u0026#34;AI to help the natural world and the people in it\u0026#34;\" external-image=\"\" or-mp4-video-title=\"\" or-mp4-video-url=\"\" section-header=\"The latest AI news we announced in March\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n  \n    \u003cp\u003e\u003cimg alt=\"a text card reading \u0026#34;AI to help the natural world and the people in it\u0026#34;\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-01.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n            \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-01.width-500.format-webp.webp\u0026#34;,\n            \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI_subheads-01.width-1000.format-webp.webp\u0026#34;\n          }\"/\u003e\n    \u003c/p\u003e\n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"eakgv\"\u003e\u003ca href=\"https://blog.google/feed/firesat-first-satellite-launch/\"\u003e\u003cb\u003eThe first FireSat satellite for early detection of wildfires made contact with Earth\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e The FireSat satellite launched from Vandenberg Space Force Base in California aboard SpaceX\u0026#39;s Transporter-13 mission. This satellite — a collaboration between Google, Muon Space, Earth Fire Alliance, Moore Foundation, wildfire authorities and others — is the first of more than 50 in a first-of-its-kind constellation designed to ultimately use AI to detect and track wildfires as small as roughly 5x5 meters.\u003c/p\u003e\u003cp data-block-key=\"8j7ae\"\u003e\u003ca href=\"https://blog.google/outreach-initiatives/entrepreneurs/ai-nature-climate-accelerator-nonprofits-speciesnet/\"\u003e\u003cb\u003eWe launched three new initiatives to protect and restore nature using AI\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e A startup accelerator, kicking off in May 2025, includes programming, mentoring and technical support from Google. Google.org is also providing $3 million to support AI-enabled solutions for biodiversity, bioeconomy and agriculture from Brazilian nonprofits. And we released SpeciesNet, a Cloud-based, open-source AI model for identifying animal species from camera trap photos, enabling people to protect nature and biodiversity.\u003c/p\u003e\u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\u003cdiv data-analytics-module=\"{\n       \u0026#34;module_name\u0026#34;: \u0026#34;Article Tags\u0026#34;,\n       \u0026#34;section_header\u0026#34;: \u0026#34;The latest AI news we announced in March\u0026#34;\n     }\"\u003e\n  \u003cp\u003e\u003cspan\u003ePOSTED IN:\u003c/span\u003e\n  \u003c/p\u003e\n  \u003cnav data-analytics=\"{\n                \u0026#34;category\u0026#34;: \u0026#34;landing page lead\u0026#34;,\n                \u0026#34;action\u0026#34;: \u0026#34;article tag\u0026#34;\n              }\"\u003e\n    \u003cul\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/ai/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: AI\u0026#34;}\"\u003e\n\n\nAI\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini\u0026#34;}\"\u003e\n\n\nGemini\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini App\u0026#34;}\"\u003e\n\n\nGemini App\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini Models\u0026#34;}\"\u003e\n\n\nGemini Models\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/google-deepmind/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Google DeepMind\u0026#34;}\"\u003e\n\n\nGoogle DeepMind\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/outreach-initiatives/sustainability/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Sustainability\u0026#34;}\"\u003e\n\n\nSustainability\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/research/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Research\u0026#34;}\"\u003e\n\n\nResearch\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/pixel/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Pixel\u0026#34;}\"\u003e\n\n\nPixel\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/shopping/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Shopping\u0026#34;}\"\u003e\n\n\nShopping\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/outreach-initiatives/entrepreneurs/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Entrepreneurs\u0026#34;}\"\u003e\n\n\nEntrepreneurs\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/developers/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Developers\u0026#34;}\"\u003e\n\n\nDevelopers\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/search/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Search\u0026#34;}\"\u003e\n\n\nSearch\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n    \u003c/ul\u003e\n  \u003c/nav\u003e\n\u003c/div\u003e\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-04-04T14:30:00Z",
  "modifiedTime": null
}
