{
  "id": "3b23e463-a5ba-489e-8aa4-455ab900d514",
  "title": "Google XR glasses hands-on: Lightweight but with a limited field of view",
  "link": "https://www.engadget.com/ar-vr/google-xr-glasses-hands-on-lightweight-but-with-a-limited-field-of-view-213940554.html?src=rss",
  "description": "One of the biggest reveals of Google I/O was that the company is officially back in the mixed reality game with its own prototype XR smart glasses. It's been years since we've seen anything substantial from the search giant on the AR/VR/XR front, but with a swath of hardware partners to go with its XR platform it seems that's finally changing. Following the keynote, Google gave me a very short demo of the prototype device we saw onstage. I only got a few minutes with the device so my impressions are unfortunately very limited, but I was immediately impressed with how light the glasses were compared with Meta's Orion prototype and Snap's augmented reality Spectacles. While both of those are quite chunky, Google's prototype device was lightweight and felt much more like a normal pair of glasses. The frames were a bit thicker than what I typically wear, but not by a whole lot. Karissa Bell for Engadget At the same time, there are some notable differences between Google's XR glasses and what we've seen from Meta and Snap. Google's device only has a display on one side — the right lens, you can see it in the image at the top of this article — so the visuals are more \"glanceable\" than fully immersive. I noted during Google's demo onstage at I/O that the field of view looked narrow and I can confirm that it feels much more limited than even Snap's 46-degree field of view. (Google declined to share specifics on how wide the field of view is on its prototype.) Instead, the display felt a bit similar to the front display of a foldable phone. You can use it to get a quick look at the time and notifications and small snippets of info from your apps, like what music you're listening to.  Gemini is meant to play a major role in the Android XR ecosystem, and Google walked me through a few demos of the AI assistant working on the smart glasses. I could look at a display of books or some art on the wall and ask Gemini questions about what I was looking at. It felt very similar to multimodal capabilities we've seen with Project Astra and elsewhere. There were some bugs, though, even in the carefully orchestrated demo. In one instance, Gemini started to tell me about what I was looking at before I had even finished my question to it, which was followed by an awkward moment where we both paused and interrupted each other. One of the more interesting use cases Google was showing was Google Maps in the glasses. You can get a heads-up view of your next turn, much like Google augmented reality walking directions, and look down to see a little section of map on the floor. However, when I asked Gemini how long it would take to drive to San Francisco from my location it wasn't able to provide an answer. (It actually said something like \"tool output,\" and my demo ended very quickly after.) Engadget I also really liked how Google took advantage of the glasses' onboard camera. When I snapped a photo, a preview of the image immediately popped up on the display so I could see how it turned out. I really appreciated this because framing photos from a camera on smart glasses is inherently unintuitive because the final image can vary so much depending on where the lens is placed. I've often wished for a version of this when taking photos with my Ray-Ban Meta Smart Glasses, so it was cool to see a version of this actually in action.  I honestly still have a lot of questions about Google's vision for XR and what eventual Gemini-powered smart glasses will be capable of. As with so many other mixed reality demos I've seen, it's obviously still very early days. Google was careful to emphasize that this is prototype hardware meant to show off what Android XR is capable of, not a device it's planning on selling anytime soon. So any smart glasses we get from Google or its hardware partners could look very different.  What my few minutes with Android XR was able to show, though, was how Google is thinking about bringing AI and mixed reality together. It's not so different from Meta, which sees smart glasses as key to long-term adoption of its AI assistant too. But now that Gemini is coming to just about every Google product that exists, the company has a very solid foundation to actually accomplish this.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/google-xr-glasses-hands-on-lightweight-but-with-a-limited-field-of-view-213940554.html?src=rss",
  "author": "Karissa Bell",
  "published": "Tue, 20 May 2025 21:52:00 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Technology \u0026 Electronics",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Karissa Bell"
  ],
  "byline": "Karissa Bell",
  "length": 4227,
  "excerpt": "Google is officially back in the mixed reality game with its own prototype XR smart glasses, here's our first impressions.",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "One of the biggest reveals of Google I/O was that the company is officially back in the mixed reality game with its own prototype XR smart glasses. It's been years since we've seen anything substantial from the search giant on the AR/VR/XR front, but with a swath of hardware partners to go with its XR platform it seems that's finally changing.Following the keynote, Google gave me a very short demo of the prototype device we saw onstage. I only got a few minutes with the device so my impressions are unfortunately very limited, but I was immediately impressed with how light the glasses were compared with Meta's Orion prototype and Snap's augmented reality Spectacles. While both of those are quite chunky, Google's prototype device was lightweight and felt much more like a normal pair of glasses. The frames were a bit thicker than what I typically wear, but not by a whole lot. Karissa Bell for EngadgetAt the same time, there are some notable differences between Google's XR glasses and what we've seen from Meta and Snap. Google's device only has a display on one side — the right lens, you can see it in the image at the top of this article — so the visuals are more \"glanceable\" than fully immersive. I noted during Google's demo onstage at I/O that the field of view looked narrow and I can confirm that it feels much more limited than even Snap's 46-degree field of view. (Google declined to share specifics on how wide the field of view is on its prototype.)Instead, the display felt a bit similar to the front display of a foldable phone. You can use it to get a quick look at the time and notifications and small snippets of info from your apps, like what music you're listening to.Gemini is meant to play a major role in the Android XR ecosystem, and Google walked me through a few demos of the AI assistant working on the smart glasses. I could look at a display of books or some art on the wall and ask Gemini questions about what I was looking at. It felt very similar to multimodal capabilities we've seen with Project Astra and elsewhere.There were some bugs, though, even in the carefully orchestrated demo. In one instance, Gemini started to tell me about what I was looking at before I had even finished my question to it, which was followed by an awkward moment where we both paused and interrupted each other.One of the more interesting use cases Google was showing was Google Maps in the glasses. You can get a heads-up view of your next turn, much like Google augmented reality walking directions, and look down to see a little section of map on the floor. However, when I asked Gemini how long it would take to drive to San Francisco from my location it wasn't able to provide an answer. (It actually said something like \"tool output,\" and my demo ended very quickly after.) EngadgetI also really liked how Google took advantage of the glasses' onboard camera. When I snapped a photo, a preview of the image immediately popped up on the display so I could see how it turned out. I really appreciated this because framing photos from a camera on smart glasses is inherently unintuitive because the final image can vary so much depending on where the lens is placed. I've often wished for a version of this when taking photos with my Ray-Ban Meta Smart Glasses, so it was cool to see a version of this actually in action.I honestly still have a lot of questions about Google's vision for XR and what eventual Gemini-powered smart glasses will be capable of. As with so many other mixed reality demos I've seen, it's obviously still very early days. Google was careful to emphasize that this is prototype hardware meant to show off what Android XR is capable of, not a device it's planning on selling anytime soon. So any smart glasses we get from Google or its hardware partners could look very different.What my few minutes with Android XR was able to show, though, was how Google is thinking about bringing AI and mixed reality together. It's not so different from Meta, which sees smart glasses as key to long-term adoption of its AI assistant too. But now that Gemini is coming to just about every Google product that exists, the company has a very solid foundation to actually accomplish this.",
  "image": "https://s.yimg.com/ny/api/res/1.2/DI6icyees7z.slAfUcjqEg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2025-05/a1ba75f0-35c0-11f0-9b5e-aaa531b3365f",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eOne of the biggest reveals of Google I/O was that the company is officially back in the mixed reality game with its own \u003ca data-i13n=\"cpos:1;pos:1\" href=\"https://www.engadget.com/wearables/google-demos-android-xr-glasses-at-io-live-translation-191510280.html\" data-ylk=\"slk:prototype XR smart glasses;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003eprototype XR smart glasses\u003c/a\u003e. It\u0026#39;s been years since we\u0026#39;ve seen anything substantial from the search giant on the AR/VR/XR front, but with a swath of hardware partners to go with its XR platform it seems that\u0026#39;s finally changing.\u003c/p\u003e\u003cp\u003eFollowing the keynote, Google gave me a very short demo of the prototype device we saw onstage. I only got a few minutes with the device so my impressions are unfortunately very limited, but I was immediately impressed with how light the glasses were compared with \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1\" href=\"https://www.engadget.com/ar-vr/metas-orion-prototype-offers-a-glimpse-into-our-ar-future-123038066.html\" data-ylk=\"slk:Meta\u0026#39;s Orion prototype;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas\"\u003eMeta\u0026#39;s Orion prototype\u003c/a\u003e and Snap\u0026#39;s \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1\" href=\"https://www.engadget.com/social-media/snaps-fifth-generation-spectacles-bring-your-hands-into-into-augmented-reality-180026541.html\" data-ylk=\"slk:augmented reality Spectacles;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas\"\u003eaugmented reality Spectacles\u003c/a\u003e. While both of those are quite chunky, Google\u0026#39;s prototype device was lightweight and felt much more like a normal pair of glasses. The frames were a bit thicker than what I typically wear, but not by a whole lot.\u003c/p\u003e\u003cfigure\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Google\u0026#39;s XR prototypes.\" src=\"https://s.yimg.com/ny/api/res/1.2/AW91HuAHcH9oPTqa0UfyTQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTY0MDtoPTQ4MDtjZj13ZWJw/https://s.yimg.com/os/creatr-uploaded-images/2025-05/d374b740-35c0-11f0-bfbf-a6583f76c3e7\" height=\"480\" width=\"640\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cfigcaption\u003e\u003cspan\u003e Karissa Bell for Engadget\u003c/span\u003e\u003c/figcaption\u003e\u003c/p\u003e\u003c/figure\u003e\u003cp\u003eAt the same time, there are some notable differences between Google\u0026#39;s XR glasses and what we\u0026#39;ve seen from Meta and Snap. Google\u0026#39;s device only has a display on one side — the right lens, you can see it in the image at the top of this article — so the visuals are more \u0026#34;glanceable\u0026#34; than fully immersive. I noted during Google\u0026#39;s demo onstage at I/O that the field of view looked narrow and I can confirm that it feels much more limited than even Snap\u0026#39;s 46-degree field of view. (Google declined to share specifics on how wide the field of view is on its prototype.)\u003c/p\u003e\u003cp\u003eInstead, the display felt a bit similar to the front display of a foldable phone. You can use it to get a quick look at the time and notifications and small snippets of info from your apps, like what music you\u0026#39;re listening to.\u003c/p\u003e\u003cp\u003eGemini is meant to play a major role in the Android XR ecosystem, and Google walked me through a few demos of the AI assistant working on the smart glasses. I could look at a display of books or some art on the wall and ask Gemini questions about what I was looking at. It felt very similar to multimodal capabilities we\u0026#39;ve seen with Project Astra and elsewhere.\u003c/p\u003e\u003cp\u003eThere were some bugs, though, even in the carefully orchestrated demo. In one instance, Gemini started to tell me about what I was looking at before I had even finished my question to it, which was followed by an awkward moment where we both paused and interrupted each other.\u003c/p\u003e\u003cp\u003eOne of the more interesting use cases Google was showing was Google Maps in the glasses. You can get a heads-up view of your next turn, much like Google augmented reality walking directions, and look down to see a little section of map on the floor. However, when I asked Gemini how long it would take to drive to San Francisco from my location it wasn\u0026#39;t able to provide an answer. (It actually said something like \u0026#34;tool output,\u0026#34; and my demo ended very quickly after.)\u003c/p\u003e\u003cfigure\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"I liked how you can preview photos taken with the glasses.\" src=\"https://s.yimg.com/ny/api/res/1.2/13S0ooThvnypCWcWnm71.w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTY0MDtoPTM2MDtjZj13ZWJw/https://s.yimg.com/os/creatr-uploaded-images/2025-05/02a698a0-35c4-11f0-bd9d-e31778ff831d\" height=\"360\" width=\"640\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cfigcaption\u003e\u003cspan\u003e Engadget\u003c/span\u003e\u003c/figcaption\u003e\u003c/p\u003e\u003c/figure\u003e\u003cp\u003eI also really liked how Google took advantage of the glasses\u0026#39; onboard camera. When I snapped a photo, a preview of the image immediately popped up on the display so I could see how it turned out. I really appreciated this because framing photos from a camera on smart glasses is inherently unintuitive because the final image can vary so much depending on where the lens is placed. I\u0026#39;ve often wished for a version of this when taking photos with my Ray-Ban Meta Smart Glasses, so it was cool to see a version of this actually in action.\u003c/p\u003e\u003cp\u003eI honestly still have a lot of questions about Google\u0026#39;s vision for XR and what eventual Gemini-powered smart glasses will be capable of. As with so many other mixed reality demos I\u0026#39;ve seen, it\u0026#39;s obviously still very early days. Google was careful to emphasize that this is prototype hardware meant to show off what Android XR is capable of, not a device it\u0026#39;s planning on selling anytime soon. So any smart glasses we get from Google or its hardware partners could look very different.\u003c/p\u003e\u003cp\u003eWhat my few minutes with Android XR was able to show, though, was how Google is thinking about bringing AI and mixed reality together. It\u0026#39;s not so different from Meta, which sees smart glasses as key to long-term adoption of its AI assistant too. But now that Gemini is coming to just about every Google product that exists, the company has a very solid foundation to actually accomplish this.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-05-20T21:52:00Z",
  "modifiedTime": null
}
