{
  "id": "64bab87a-d2e9-4a5a-9559-1f79f979c63d",
  "title": "I have reimplemented Stable Diffusion 3.5 from scratch in pure PyTorch",
  "link": "https://github.com/yousef-rafat/miniDiffusion",
  "description": "Comments",
  "author": "",
  "published": "Sat, 14 Jun 2025 13:56:46 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "yousef-rafat",
  "length": 2075,
  "excerpt": "A reimplementation of Stable Diffusion 3.5 in pure PyTorch - yousef-rafat/miniDiffusion",
  "siteName": "GitHub",
  "favicon": "https://github.githubassets.com/assets/apple-touch-icon-180x180-a80b8e11abe2.png",
  "text": "miniDiffusion miniDiffusion is a reimplementation of the Stable Diffusion 3.5 model in pure PyTorch with minimal dependencies. It's designed for educational, experimenting, and hacking purposes. It's made with the mindset of having the least amount of code necessary to recreate Stable Diffusion 3.5 from scratch, with only ~2800 spanning from VAE to DiT to the Train and Dataset scripts. -Files: The main Stable Diffusion model code is located in dit.py, dit_components.py, and attention.py. The dit.py file contains the main model, dit_components.py contains the embedding, normalization, patch embedding, and help functions for the DiT code, and attention.py contains the Joint Attention implementation. The noise.py is where the Euler Scheduler is located for solving the ODE of Rectified Flow. The text encoders are in t5_encoder.py and clip.py, and their tokenizers are both in tokenizer.py. The metrics.py implements the Fréchet inception distance (FID). The common.py is a place for helper functions for training, the common_ds.py is an implementation of an iterable dataset that converts image data to trainable data for the DiT model. -Folders: The model folder saves the model's checkpoint and logs after training. The encoders folder saves other modules' checkpoints (e.g., VAE, CLIP). ⚠️ Warning: This repository still has experimental features and requires more testing. Components Core Image Generation Modules Implementations of VAE, CLIP, and T5 Text Encoders Implementation of Byte-Pair \u0026 Unigram tokenizers SD3 Components Multi-Modal Diffusion Transformer Model Flow-Matching Euler Scheduler Logit-Normal Sampling Joint Attention Train and Inference Scripts For SD3 Getting Started Get the repo git clone \"https://github.com/yousef-rafat/miniDiffusion\" Install Dependencies pip install -r requirements.txt Install Checkpoints for Models Add a Hugging Face Token in get_checkpoints.py before running the script. python3 encoders/get_checkpoints.py License This project is under the MIT License and is made for educational and experimental purposes.",
  "image": "https://opengraph.githubassets.com/30980c4dda67429bf7978ab4118616b69e41f871808f95a3111017893c8e554a/yousef-rafat/miniDiffusion",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-hpc=\"true\"\u003e\u003carticle itemprop=\"text\"\u003e\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eminiDiffusion\u003c/h2\u003e\u003ca id=\"user-content-minidiffusion\" aria-label=\"Permalink: miniDiffusion\" href=\"#minidiffusion\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/yousef-rafat/miniDiffusion/blob/main/assets/display.png\"\u003e\u003cimg src=\"https://github.com/yousef-rafat/miniDiffusion/raw/main/assets/display.png\" alt=\"SD3 Diagram\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eminiDiffusion is a reimplementation of the Stable Diffusion 3.5 model in pure PyTorch with minimal dependencies. It\u0026#39;s designed for educational, experimenting, and hacking purposes.\nIt\u0026#39;s made with the mindset of having the least amount of code necessary to recreate Stable Diffusion 3.5 from scratch, with only ~2800 spanning from VAE to DiT to the Train and Dataset scripts.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003e-Files:\u003c/strong\u003e The main Stable Diffusion model code is located in dit.py, dit_components.py, and attention.py. The dit.py file contains the main model, dit_components.py contains the embedding, normalization, patch embedding, and help functions for the DiT code, and attention.py contains the Joint Attention implementation.\nThe noise.py is where the Euler Scheduler is located for solving the ODE of Rectified Flow.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eThe text encoders are in t5_encoder.py and clip.py, and their tokenizers are both in tokenizer.py. The metrics.py implements the Fréchet inception distance (FID).\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eThe common.py is a place for helper functions for training, the common_ds.py is an implementation of an iterable dataset that converts image data to trainable data for the DiT model.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003e-Folders:\u003c/strong\u003e The model folder saves the model\u0026#39;s checkpoint and logs after training. The encoders folder saves other modules\u0026#39; checkpoints (e.g., VAE, CLIP).\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp dir=\"auto\"\u003e\u003cg-emoji alias=\"warning\"\u003e⚠️\u003c/g-emoji\u003e \u003cstrong\u003eWarning\u003c/strong\u003e:\nThis repository still has experimental features and requires more testing.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eComponents\u003c/h2\u003e\u003ca id=\"user-content-components\" aria-label=\"Permalink: Components\" href=\"#components\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" dir=\"auto\"\u003eCore Image Generation Modules\u003c/h3\u003e\u003ca id=\"user-content-core-image-generation-modules\" aria-label=\"Permalink: Core Image Generation Modules\" href=\"#core-image-generation-modules\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eImplementations of VAE, CLIP, and T5 Text Encoders\u003c/li\u003e\n\u003cli\u003eImplementation of Byte-Pair \u0026amp; Unigram tokenizers\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" dir=\"auto\"\u003eSD3 Components\u003c/h3\u003e\u003ca id=\"user-content-sd3-components\" aria-label=\"Permalink: SD3 Components\" href=\"#sd3-components\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eMulti-Modal Diffusion Transformer Model\u003c/li\u003e\n\u003cli\u003eFlow-Matching Euler Scheduler\u003c/li\u003e\n\u003cli\u003eLogit-Normal Sampling\u003c/li\u003e\n\u003cli\u003eJoint Attention\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" dir=\"auto\"\u003eTrain and Inference Scripts For SD3\u003c/h3\u003e\u003ca id=\"user-content-train-and-inference-scripts-for-sd3\" aria-label=\"Permalink: Train and Inference Scripts For SD3\" href=\"#train-and-inference-scripts-for-sd3\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eGetting Started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eGet the repo\u003c/p\u003e\n\u003cdiv dir=\"auto\" data-snippet-clipboard-copy-content=\"git clone \u0026#34;https://github.com/yousef-rafat/miniDiffusion\u0026#34;\"\u003e\u003cpre\u003egit clone \u003cspan\u003e\u003cspan\u003e\u0026#34;\u003c/span\u003ehttps://github.com/yousef-rafat/miniDiffusion\u003cspan\u003e\u0026#34;\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eInstall Dependencies\u003c/p\u003e\n\u003cdiv dir=\"auto\" data-snippet-clipboard-copy-content=\"pip install -r requirements.txt\"\u003e\u003cpre\u003epip install -r requirements.txt\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eInstall Checkpoints for Models\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003cem\u003eAdd a Hugging Face Token in get_checkpoints.py before running the script.\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv dir=\"auto\" data-snippet-clipboard-copy-content=\"python3 encoders/get_checkpoints.py\"\u003e\u003cpre\u003epython3 encoders/get_checkpoints.py\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eThis project is under the MIT License and is made for educational and experimental purposes.\u003c/p\u003e\n\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
