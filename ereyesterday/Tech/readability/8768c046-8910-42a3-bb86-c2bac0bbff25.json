{
  "id": "8768c046-8910-42a3-bb86-c2bac0bbff25",
  "title": "UK is going full Minority Report with ‘murder prediction’ research",
  "link": "https://www.engadget.com/ai/uk-is-going-full-minority-report-with-murder-prediction-research-214254968.html?src=rss",
  "description": "The Guardian reported that the UK's Ministry of Justice has been developing an algorithm designed to identify people who could become killers. Initially dubbed the \"homicide prediction project,\" this tool used data from UK police forces, possibly including victims and witnesses as well as suspects. Civil liberty watchdog Statewatch discovered the program through Freedom of Information Act requests. Based on the documents acquired by the group, Statewatch claimed that the program developed its prediction tool based on police data about between 100,000 and 500,000 people. Different categories of information shared with the Ministry of Justice appeared to also cover sensitive topics such as mental health, addiction, suicide and disability. \"​​Time and again, research shows that algorithmic systems for ‘predicting’ crime are inherently flawed,\" Statewatch researcher Sofia Lyall said. \"This latest model, which uses data from our institutionally racist police and Home Office, will reinforce and magnify the structural discrimination underpinning the criminal legal system.\" \"This project is being conducted for research purposes only. It has been designed using existing data held by HM Prison and Probation Service and police forces on convicted offenders to help us better understand the risk of people on probation going on to commit serious violence. A report will be published in due course,\" a representative from the MOJ told The Guardian. Law enforcement has long had a questionable relationship with AI tools. From AI being used to create police reports (bad idea) to misusing programs like ShotSpotter (another bad idea) to adopting tech that poses privacy threats to citizens (also a bad idea), history is not on the side of these being well-implemented technologies.This article originally appeared on Engadget at https://www.engadget.com/ai/uk-is-going-full-minority-report-with-murder-prediction-research-214254968.html?src=rss",
  "author": "Anna Washenko",
  "published": "Tue, 08 Apr 2025 21:42:55 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Society \u0026 Culture",
    "Crime \u0026 Justice",
    "Company Legal \u0026 Law Matters",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Anna Washenko"
  ],
  "byline": "Anna Washenko",
  "length": 1783,
  "excerpt": "The Guardian reported that the UK's Ministry of Justice has been developing an algorithm designed to identify people who could become killers.",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "The Guardian reported that the UK's Ministry of Justice has been developing an algorithm designed to identify people who could become killers. Initially dubbed the \"homicide prediction project,\" this tool used data from UK police forces, possibly including victims and witnesses as well as suspects.Civil liberty watchdog Statewatch discovered the program through Freedom of Information Act requests. Based on the documents acquired by the group, Statewatch claimed that the program developed its prediction tool based on police data about between 100,000 and 500,000 people. Different categories of information shared with the Ministry of Justice appeared to also cover sensitive topics such as mental health, addiction, suicide and disability.\"​​Time and again, research shows that algorithmic systems for ‘predicting’ crime are inherently flawed,\" Statewatch researcher Sofia Lyall said. \"This latest model, which uses data from our institutionally racist police and Home Office, will reinforce and magnify the structural discrimination underpinning the criminal legal system.\"\"This project is being conducted for research purposes only. It has been designed using existing data held by HM Prison and Probation Service and police forces on convicted offenders to help us better understand the risk of people on probation going on to commit serious violence. A report will be published in due course,\" a representative from the MOJ told The Guardian.Law enforcement has long had a questionable relationship with AI tools. From AI being used to create police reports (bad idea) to misusing programs like ShotSpotter (another bad idea) to adopting tech that poses privacy threats to citizens (also a bad idea), history is not on the side of these being well-implemented technologies.",
  "image": "https://s.yimg.com/ny/api/res/1.2/ulVAebVc0N2MszxDuef2gg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03MjA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2025-04/fbe28c50-14c0-11f0-bf3d-a1417375e62a",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cem\u003eThe Guardian\u003c/em\u003e \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1\" href=\"https://www.theguardian.com/uk-news/2025/apr/08/uk-creating-prediction-tool-to-identify-people-most-likely-to-kill\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:reported;elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1;itc:0;sec:content-canvas\"\u003ereported\u003c/a\u003e that the UK\u0026#39;s Ministry of Justice has been developing an algorithm designed to identify people who could become killers. Initially dubbed the \u0026#34;homicide prediction project,\u0026#34; this tool used data from UK police forces, possibly including victims and witnesses as well as suspects.\u003c/p\u003e\u003cp\u003eCivil liberty watchdog Statewatch \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1\" href=\"https://www.statewatch.org/news/2025/april/uk-ministry-of-justice-secretly-developing-murder-prediction-system/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:discovered;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas\"\u003ediscovered\u003c/a\u003e the program through Freedom of Information Act requests. Based on the documents acquired by the group, Statewatch claimed that the program developed its prediction tool based on police data about between 100,000 and 500,000 people. Different categories of information shared with the Ministry of Justice appeared to also cover sensitive topics such as mental health, addiction, suicide and disability.\u003c/p\u003e\u003cp\u003e\u0026#34;​​Time and again, research shows that algorithmic systems for ‘predicting’ crime are inherently flawed,\u0026#34; Statewatch researcher Sofia Lyall said. \u0026#34;This latest model, which uses data from our institutionally racist police and Home Office, will reinforce and magnify the structural discrimination underpinning the criminal legal system.\u0026#34;\u003c/p\u003e\u003cp\u003e\u0026#34;This project is being conducted for research purposes only. It has been designed using existing data held by HM Prison and Probation Service and police forces on convicted offenders to help us better understand the risk of people on probation going on to commit serious violence. A report will be published in due course,\u0026#34; a representative from the MOJ told \u003cem\u003eThe Guardian\u003c/em\u003e.\u003c/p\u003e\u003cp\u003eLaw enforcement has long had a questionable relationship with AI tools. From \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1\" href=\"https://www.engadget.com/ai/aclu-highlights-the-rise-of-ai-generated-police-reports--what-could-go-wrong-133030452.html\" data-ylk=\"slk:AI being used to create police reports;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas\"\u003eAI being used to create police reports\u003c/a\u003e (bad idea) to \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1\" href=\"https://www.engadget.com/lawsuit-chicago-shotspotter-murder-case-094903220.html\" data-ylk=\"slk:misusing programs like ShotSpotter;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas\"\u003emisusing programs like ShotSpotter\u003c/a\u003e (another bad idea) to \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1\" href=\"https://www.engadget.com/2020-02-12-clearview-ai-police-surveillance-explained.html\" data-ylk=\"slk:adopting tech that poses privacy threats to citizens;elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1;itc:0;sec:content-canvas\"\u003eadopting tech that poses privacy threats to citizens\u003c/a\u003e (also a bad idea), history is not on the side of these being well-implemented technologies.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-04-08T21:42:55Z",
  "modifiedTime": null
}
