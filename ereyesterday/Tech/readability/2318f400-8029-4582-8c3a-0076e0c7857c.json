{
  "id": "2318f400-8029-4582-8c3a-0076e0c7857c",
  "title": "Qwen3-Coder: Agentic coding in the world",
  "link": "https://qwenlm.github.io/blog/qwen3-coder/",
  "description": "Comments",
  "author": "",
  "published": "Tue, 22 Jul 2025 21:12:30 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "Qwen Team",
  "length": 7245,
  "excerpt": "GITHUB HUGGING FACE MODELSCOPE DISCORD Today, we’re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we’re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4.",
  "siteName": "Qwen",
  "favicon": "https://qwenlm.github.io/favicon.png",
  "text": "GITHUB HUGGING FACE MODELSCOPE DISCORDToday, we’re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we’re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4.Alongside the model, we’re also open-sourcing a command-line tool for agentic coding: Qwen Code. Forked from Gemini Code, Qwen Code has been adapted with customized prompts and function calling protocols to fully unleash the capabilities of Qwen3-Coder on agentic coding tasks. Qwen3-Coder works seamlessly with the community’s best developer tools. As a foundation model, we hope it can be used anywhere across the digital world — Agentic Coding in the World!Qwen3-CoderPre-TrainingThere’s still room to scale in pretraining—and with Qwen3-Coder, we’re advancing along multiple dimensions to strengthen the model’s core capabilities:Scaling Tokens: 7.5T tokens (70% code ratio), excelling in coding while preserving general and math abilities.Scaling Context: Natively supports 256K context and can be extended up to 1M with YaRN, optimized for repo-scale and dynamic data (e.g., Pull Requests) to empower Agentic Coding.Scaling Synthetic Data: Leveraged Qwen2.5-Coder to clean and rewrite noisy data, significantly improving overall data quality.Post-TrainingScaling Code RL: Hard to Solve, Easy to VerifyUnlike the prevailing focus on competitive-level code generation in the community, we believe all code tasks are naturally well-suited for execution-driven large-scale reinforcement learning. That’s why we scaled up Code RL training on a broader set of real-world coding tasks. By automatically scaling test cases of diversity coding tasks, we created high-quality training instances and successfully unlocked the full potential of reinforcement learning. It not only significantly boosted code execution success rates, but also brought gains to other tasks. This encourages us to keep exploring hard-to-solve, easy-to-verify tasks as fertile ground for large-scale reinforcement learning.Scaling Long-Horizon RLIn real-world software engineering tasks like SWE-Bench, Qwen3-Coder must engage in multi-turn interaction with the environment, involving planning, using tools, receiving feedback, and making decisions. In the post-training phase of Qwen3-Coder, we introduced long-horizon RL (Agent RL) to encourage the model to solve real-world tasks through multi-turn interactions using tools. The key challenge of Agent RL lies in environment scaling. To address this, we built a scalable system capable of running 20,000 independent environments in parallel, leveraging Alibaba Cloud’s infrastructure. The infrastructure provides the necessary feedback for large-scale reinforcement learning and supports evaluation at scale. As a result, Qwen3-Coder achieves state-of-the-art performance among open-source models on SWE-Bench Verified without test-time scaling.Code with Qwen3-CoderQwen CodeQwen Code is a research-purpose CLI tool adapted from Gemini CLI, with enhanced parser and tool support for Qwen-Coder models.Make sure you have installed nodejs 20+:You could install it via the following commands:curl -qL https://www.npmjs.com/install.sh | sh Then install Qwen code via npm manager:npm i -g @qwen-code/qwen-code The other way is to install from the source:git clone https://github.com/QwenLM/qwen-code.git cd qwen-code \u0026\u0026 npm install \u0026\u0026 npm install -g Qwen Code supports the OpenAI SDK when calling LLMs, and you can export the following environment variables or simply put them under the .envfile.export OPENAI_API_KEY=\"your_api_key_here\" export OPENAI_BASE_URL=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\" export OPENAI_MODEL=\"qwen3-coder-plus\" Now enjoy your vibe coding with Qwen-Code and Qwen, by simply typing: qwen!Claude CodeIn addition to Qwen Code, you can now use Qwen3‑Coder with Claude Code. Simply request an API key on Alibaba Cloud Model Studio platform and install Claude Code to start coding.npm install -g @anthropic-ai/claude-code We have provided two entrypoints for seamlessly experiencing coding with Qwen3-Coder.Optional 1: Claude Code proxy APIexport ANTHROPIC_BASE_URL=https://dashscope-intl.aliyuncs.com/api/v2/apps/claude-code-proxy export ANTHROPIC_AUTH_TOKEN=your-dashscope-apikey Then you should be able to use Claude Code with Qwen3-Coder!Optional 2: claude-code-config npm package for router customizationclaude-code-router aims for customizing different backend models for Claude Code. The dashscope team also provide a convenient config npm extension, namely claude-code-config, that provides default configuration for claude-code-router with DashScope support. Run installation:npm install -g @musistudio/claude-code-router npm install -g @dashscope-js/claude-code-config and then run configuration:The command will automatically generate the config json files and plugin directories for ccr. (You could also manually adjust these under ~/.claude-code-router/config.json and ~/.claude-code-router/plugins/ ) Start using claude code via ccr:ClineConfigure the Qwen3-Coder-480B-A35B-Instruct to cline ‒ Go to the Cline configuration settings ‒ For API Provider, select ‘OpenAI Compatible’ ‒ For the OpenAI Compatible API Key, enter the key obtained from Dashscope ‒ Check ‘Use custom base URL’ and enter: https://dashscope-intl.aliyuncs.com/compatible-mode/v1 ‒ Enter qwen3-coder-plus Use CasesExample: Physics-Based Chimney Demolition Simulation with Controlled Explosion NextAPIYou can directly access the API of Qwen3-Coder through Alibaba Cloud Model Studio. Here is a demonstration of how to use this model with the Qwen API.import os from openai import OpenAI # Create client - using intl URL for users outside of China # If you are in mainland China, use the following URL: # \"https://dashscope.aliyuncs.com/compatible-mode/v1\" client = OpenAI( api_key=os.getenv(\"DASHSCOPE_API_KEY\"), base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\", ) prompt = \"Help me create a web page for an online bookstore.\" # Send request to qwen3-coder-plus model completion = client.chat.completions.create( model=\"qwen3-coder-plus\", messages=[ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": prompt} ], ) # Print the response print(completion.choices[0].message.content.strip()) Further WorkWe are still actively working to improve the performance of our Coding Agent, aiming for it to take on more complex and tedious tasks in software engineering, thereby freeing up human productivity. More model sizes of Qwen3-Coder are on the way, delivering strong performance while reducing deployment costs. Additionally, we are actively exploring whether the Coding Agent can achieve self-improvement—an exciting and inspiring direction.",
  "image": "https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://github.com/QwenLM/Qwen3-Coder\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ca href=\"https://huggingface.co/Qwen\" target=\"_blank\"\u003eHUGGING FACE\u003c/a\u003e\n\u003ca href=\"https://modelscope.cn/organization/qwen\" target=\"_blank\"\u003eMODELSCOPE\u003c/a\u003e\n\u003ca href=\"https://discord.gg/yPEP2vHTu4\" target=\"_blank\"\u003eDISCORD\u003c/a\u003e\u003c/p\u003e\u003cp\u003eToday, we’re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we’re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4.\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3-coder-main.jpg\" alt=\"\" width=\"800\"/\u003e\u003c/p\u003e\u003cp\u003eAlongside the model, we’re also open-sourcing a command-line tool for agentic coding: Qwen Code. Forked from Gemini Code, Qwen Code has been adapted with customized prompts and function calling protocols to fully unleash the capabilities of Qwen3-Coder on agentic coding tasks. Qwen3-Coder works seamlessly with the community’s best developer tools. As a foundation model, we hope it can be used anywhere across the digital world — Agentic Coding in the World!\u003c/p\u003e\u003ch2 id=\"qwen3-coder\"\u003eQwen3-Coder\u003c/h2\u003e\u003ch3 id=\"pre-training\"\u003ePre-Training\u003c/h3\u003e\u003cp\u003eThere’s still room to scale in pretraining—and with Qwen3-Coder, we’re advancing along multiple dimensions to strengthen the model’s core capabilities:\u003c/p\u003e\u003cul\u003e\u003cli\u003eScaling Tokens: 7.5T tokens (70% code ratio), excelling in coding while preserving general and math abilities.\u003c/li\u003e\u003cli\u003eScaling Context: Natively supports 256K context and can be extended up to 1M with YaRN, optimized for repo-scale and dynamic data (e.g., Pull Requests) to empower Agentic Coding.\u003c/li\u003e\u003cli\u003eScaling Synthetic Data: Leveraged Qwen2.5-Coder to clean and rewrite noisy data, significantly improving overall data quality.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"post-training\"\u003ePost-Training\u003c/h3\u003e\u003ch4 id=\"scaling-code-rl-hard-to-solve-easy-to-verify\"\u003eScaling Code RL: Hard to Solve, Easy to Verify\u003c/h4\u003e\u003cp\u003e\u003cimg src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/coderl.png\" alt=\"\" width=\"800\"/\u003e\u003c/p\u003e\u003cp\u003eUnlike the prevailing focus on competitive-level code generation in the community, we believe all code tasks are naturally well-suited for execution-driven large-scale reinforcement learning. That’s why we scaled up Code RL training on a broader set of real-world coding tasks. By automatically scaling test cases of diversity coding tasks, we created high-quality training instances and successfully unlocked the full potential of reinforcement learning. It not only significantly boosted code execution success rates, but also brought gains to other tasks. This encourages us to keep exploring hard-to-solve, easy-to-verify tasks as fertile ground for large-scale reinforcement learning.\u003c/p\u003e\u003ch4 id=\"scaling-long-horizon-rl\"\u003eScaling Long-Horizon RL\u003c/h4\u003e\u003cp\u003e\u003cimg src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/swe.jpg\" alt=\"\" width=\"800\"/\u003e\u003c/p\u003e\u003cp\u003eIn real-world software engineering tasks like SWE-Bench, Qwen3-Coder must engage in multi-turn interaction with the environment, involving planning, using tools, receiving feedback, and making decisions. In the post-training phase of Qwen3-Coder, we introduced long-horizon RL (Agent RL) to encourage the model to solve real-world tasks through multi-turn interactions using tools. The key challenge of Agent RL lies in environment scaling. To address this, we built a scalable system capable of running 20,000 independent environments in parallel, leveraging Alibaba Cloud’s infrastructure. The infrastructure provides the necessary feedback for large-scale reinforcement learning and supports evaluation at scale. As a result, Qwen3-Coder achieves state-of-the-art performance among open-source models on SWE-Bench Verified without test-time scaling.\u003c/p\u003e\u003ch2 id=\"code-with-qwen3-coder\"\u003eCode with Qwen3-Coder\u003c/h2\u003e\u003ch3 id=\"qwen-code\"\u003eQwen Code\u003c/h3\u003e\u003cp\u003eQwen Code is a research-purpose CLI tool adapted from Gemini CLI, with enhanced parser and tool support for Qwen-Coder models.\u003c/p\u003e\u003cp\u003eMake sure you have installed nodejs 20+:\u003c/p\u003e\u003cp\u003eYou could install it via the following commands:\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003ecurl -qL https://www.npmjs.com/install.sh \u003cspan\u003e|\u003c/span\u003e sh\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThen install Qwen code via npm manager:\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003enpm i -g @qwen-code/qwen-code\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cblockquote\u003e\u003cp\u003eThe other way is to install from the source:\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003egit clone https://github.com/QwenLM/qwen-code.git\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003ecd\u003c/span\u003e qwen-code \u003cspan\u003e\u0026amp;\u0026amp;\u003c/span\u003e npm install \u003cspan\u003e\u0026amp;\u0026amp;\u003c/span\u003e npm install -g\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/blockquote\u003e\u003cp\u003eQwen Code supports the OpenAI SDK when calling LLMs, and you can export the following environment variables or simply put them under the \u003ccode\u003e.envfile\u003c/code\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eexport\u003c/span\u003e \u003cspan\u003eOPENAI_API_KEY\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;your_api_key_here\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eexport\u003c/span\u003e \u003cspan\u003eOPENAI_BASE_URL\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;https://dashscope-intl.aliyuncs.com/compatible-mode/v1\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eexport\u003c/span\u003e \u003cspan\u003eOPENAI_MODEL\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;qwen3-coder-plus\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNow enjoy your vibe coding with Qwen-Code and Qwen, by simply typing: qwen!\u003c/p\u003e\u003ch3 id=\"claude-code\"\u003eClaude Code\u003c/h3\u003e\u003cp\u003eIn addition to Qwen Code, you can now use Qwen3‑Coder with Claude Code. Simply request an API key on \u003ca href=\"https://modelstudio.console.alibabacloud.com/\"\u003eAlibaba Cloud Model Studio\u003c/a\u003e platform and install Claude Code to start coding.\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003enpm install -g @anthropic-ai/claude-code\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWe have provided two entrypoints for seamlessly experiencing coding with Qwen3-Coder.\u003c/p\u003e\u003ch4 id=\"optional-1-claude-code-proxy-api\"\u003eOptional 1: Claude Code proxy API\u003c/h4\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eexport\u003c/span\u003e \u003cspan\u003eANTHROPIC_BASE_URL\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003ehttps://dashscope-intl.aliyuncs.com/api/v2/apps/claude-code-proxy\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eexport\u003c/span\u003e \u003cspan\u003eANTHROPIC_AUTH_TOKEN\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003eyour-dashscope-apikey\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThen you should be able to use Claude Code with Qwen3-Coder!\u003c/p\u003e\u003ch4 id=\"optional-2-claude-code-config-npm-package-for-router-customization\"\u003eOptional 2: claude-code-config npm package for router customization\u003c/h4\u003e\u003cp\u003eclaude-code-router aims for customizing different backend models for Claude Code. The dashscope team also provide a convenient config npm extension, namely claude-code-config, that provides default configuration for claude-code-router with DashScope support.\nRun installation:\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"bash\"\u003e\u003cspan\u003e\u003cspan\u003enpm install -g @musistudio/claude-code-router\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003enpm install -g @dashscope-js/claude-code-config\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eand then run configuration:\u003c/p\u003e\u003cp\u003eThe command will automatically generate the config json files and plugin directories for ccr. (You could also manually adjust these under ~/.claude-code-router/config.json and ~/.claude-code-router/plugins/ )\nStart using claude code via ccr:\u003c/p\u003e\u003ch3 id=\"cline\"\u003eCline\u003c/h3\u003e\u003cp\u003eConfigure the Qwen3-Coder-480B-A35B-Instruct to cline\n‒ Go to the Cline configuration settings\n‒ For API Provider, select ‘OpenAI Compatible’\n‒ For the OpenAI Compatible API Key, enter the key obtained from Dashscope\n‒ Check ‘Use custom base URL’ and enter: \u003ccode\u003ehttps://dashscope-intl.aliyuncs.com/compatible-mode/v1\u003c/code\u003e\n‒ Enter \u003ccode\u003eqwen3-coder-plus\u003c/code\u003e\u003c/p\u003e\u003cvideo width=\"100%\" muted=\"\" controls=\"\"\u003e\n\u003csource src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3_coder_plus_with_cline.mp4\" type=\"video/mp4\"/\u003e\u003c/video\u003e\u003ch2 id=\"use-cases\"\u003eUse Cases\u003c/h2\u003e\u003cdiv\u003e\u003cp\u003e\u003cspan\u003eExample: Physics-Based Chimney Demolition Simulation with Controlled Explosion\u003c/span\u003e\n\u003ca\u003eNext\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003ch2 id=\"api\"\u003eAPI\u003c/h2\u003e\u003cp\u003eYou can directly access the API of Qwen3-Coder through \u003ca href=\"https://modelstudio.console.alibabacloud.com/\"\u003eAlibaba Cloud Model Studio\u003c/a\u003e. Here is a demonstration of how to use this model with the Qwen API.\u003c/p\u003e\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"python\"\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003eos\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003efrom\u003c/span\u003e \u003cspan\u003eopenai\u003c/span\u003e \u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003eOpenAI\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e# Create client - using intl URL for users outside of China\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e# If you are in mainland China, use the following URL:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e# \u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eclient\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003eOpenAI\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003eapi_key\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003eos\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003egetenv\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003e\u0026#34;DASHSCOPE_API_KEY\u0026#34;\u003c/span\u003e\u003cspan\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003ebase_url\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;https://dashscope-intl.aliyuncs.com/compatible-mode/v1\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eprompt\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003e\u0026#34;Help me create a web page for an online bookstore.\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e# Send request to qwen3-coder-plus model\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003ecompletion\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003eclient\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003echat\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ecompletions\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ecreate\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003emodel\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e\u0026#34;qwen3-coder-plus\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003emessages\u003c/span\u003e\u003cspan\u003e=\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e        \u003cspan\u003e{\u003c/span\u003e\u003cspan\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;system\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;You are a helpful assistant.\u0026#34;\u003c/span\u003e\u003cspan\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e        \u003cspan\u003e{\u003c/span\u003e\u003cspan\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;user\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003eprompt\u003c/span\u003e\u003cspan\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e# Print the response\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003eprint\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ecompletion\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003echoices\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e0\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003emessage\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003econtent\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003estrip\u003c/span\u003e\u003cspan\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"further-work\"\u003eFurther Work\u003c/h2\u003e\u003cp\u003eWe are still actively working to improve the performance of our Coding Agent, aiming for it to take on more complex and tedious tasks in software engineering, thereby freeing up human productivity. More model sizes of Qwen3-Coder are on the way, delivering strong performance while reducing deployment costs. Additionally, we are actively exploring whether the Coding Agent can achieve self-improvement—an exciting and inspiring direction.\u003c/p\u003e\u003c/div\u003e\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-07-22T21:00:00+08:00",
  "modifiedTime": "2025-07-22T21:00:00+08:00"
}
