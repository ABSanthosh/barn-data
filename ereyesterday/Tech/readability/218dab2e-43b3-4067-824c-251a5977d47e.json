{
  "id": "218dab2e-43b3-4067-824c-251a5977d47e",
  "title": "Meta will reportedly soon use AI for most product risk assessments instead of human reviewers",
  "link": "https://www.engadget.com/social-media/meta-will-reportedly-soon-use-ai-for-most-product-risk-assessments-instead-of-human-reviewers-205416849.html?src=rss",
  "description": "According to a report from NPR, Meta plans to shift the task of assessing its products' potential harms away from human reviewers, instead leaning more heavily on AI to speed up the process. Internal documents seen by the publication note that Meta is aiming to have up to 90 percent of risk assessments fall on AI, NPR reports, and is considering using AI reviews even in areas such as youth risk and \"integrity,\" which covers violent content, misinformation and more. Unnamed current and former Meta employees who spoke with NPR warned AI may overlook serious risks that a human team would have been able to identify. Updates and new features for Meta's platforms, including Instagram and WhatsApp, have long been subjected to human reviews before they hit the public, but Meta has reportedly doubled down on the use of AI over the last two months. Now, according to NPR, product teams have to fill out a questionnaire about their product and submit this for review by the AI system, which generally provides an \"instant decision\" that includes the risk areas it's identified. They'll then have to address whatever requirements it laid out to resolve the issues before the product can be released. A former Meta executive told NPR that reducing scrutiny \"means you're creating higher risks. Negative externalities of product changes are less likely to be prevented before they start causing problems in the world.\" In a statement to NPR, Meta said it would still tap \"human expertise\" to evaluate \"novel and complex issues,\" and leave the \"low-risk decisions\" to AI. Read the full report over at NPR. It comes a few days after Meta released its latest quarterly integrity reports — the first since changing its policies on content moderation and fact-checking earlier this year. The amount of content taken down has unsurprisingly decreased in the wake of the changes, per the report. But there was a small rise in bullying and harassment, as well as violent and graphic content.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-will-reportedly-soon-use-ai-for-most-product-risk-assessments-instead-of-human-reviewers-205416849.html?src=rss",
  "author": "Cheyenne MacDonald",
  "published": "Sat, 31 May 2025 20:54:16 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Internet \u0026 Networking Technology",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Cheyenne MacDonald"
  ],
  "byline": "Cheyenne MacDonald",
  "length": 1978,
  "excerpt": "Documents seen by NPR indicate Meta is planning to automate 'up to 90 percent' of risk assessments.",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "According to a report from NPR, Meta plans to shift the task of assessing its products' potential harms away from human reviewers, instead leaning more heavily on AI to speed up the process. Internal documents seen by the publication note that Meta is aiming to have up to 90 percent of risk assessments fall on AI, NPR reports, and is considering using AI reviews even in areas such as youth risk and \"integrity,\" which covers violent content, misinformation and more. Unnamed current and former Meta employees who spoke with NPR warned AI may overlook serious risks that a human team would have been able to identify.Updates and new features for Meta's platforms, including Instagram and WhatsApp, have long been subjected to human reviews before they hit the public, but Meta has reportedly doubled down on the use of AI over the last two months. Now, according to NPR, product teams have to fill out a questionnaire about their product and submit this for review by the AI system, which generally provides an \"instant decision\" that includes the risk areas it's identified. They'll then have to address whatever requirements it laid out to resolve the issues before the product can be released.A former Meta executive told NPR that reducing scrutiny \"means you're creating higher risks. Negative externalities of product changes are less likely to be prevented before they start causing problems in the world.\" In a statement to NPR, Meta said it would still tap \"human expertise\" to evaluate \"novel and complex issues,\" and leave the \"low-risk decisions\" to AI. Read the full report over at NPR.It comes a few days after Meta released its latest quarterly integrity reports — the first since changing its policies on content moderation and fact-checking earlier this year. The amount of content taken down has unsurprisingly decreased in the wake of the changes, per the report. But there was a small rise in bullying and harassment, as well as violent and graphic content.",
  "image": "https://s.yimg.com/ny/api/res/1.2/igcRpiV9gvrW1aUhNi_nXw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2025-05/6d774180-3e60-11f0-aaff-1e3a404b99f4",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAccording to a report from \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1\" href=\"https://www.npr.org/2025/05/31/nx-s1-5407870/meta-ai-facebook-instagram-risks\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:NPR;elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1;itc:0;sec:content-canvas\"\u003e\u003cem\u003e\u003cins\u003eNPR\u003c/ins\u003e\u003c/em\u003e\u003c/a\u003e, Meta plans to shift the task of assessing its products\u0026#39; potential harms away from human reviewers, instead leaning more heavily on AI to speed up the process. Internal documents seen by the publication note that Meta is aiming to have up to 90 percent of risk assessments fall on AI, \u003cem\u003eNPR\u003c/em\u003e reports, and is considering using AI reviews even in areas such as youth risk and \u0026#34;integrity,\u0026#34; which covers violent content, misinformation and more. Unnamed current and former Meta employees who spoke with \u003cem\u003eNPR\u003c/em\u003e warned AI may overlook serious risks that a human team would have been able to identify.\u003c/p\u003e\u003cp\u003eUpdates and new features for Meta\u0026#39;s platforms, including Instagram and WhatsApp, have long been subjected to human reviews before they hit the public, but Meta has reportedly doubled down on the use of AI over the last two months. Now, according to \u003cem\u003eNPR, \u003c/em\u003eproduct teams have to fill out a questionnaire about their product and submit this for review by the \u003ca href=\"https://www.engadget.com/ai/\" data-ylk=\"slk:AI system;elm:context_link;itc:0;sec:content-canvas\"\u003eAI system\u003c/a\u003e, which generally provides an \u0026#34;instant decision\u0026#34; that includes the risk areas it\u0026#39;s identified. They\u0026#39;ll then have to address whatever requirements it laid out to resolve the issues before the product can be released.\u003c/p\u003e\u003cp\u003eA former Meta executive told \u003cem\u003eNPR\u003c/em\u003e that reducing scrutiny \u0026#34;means you\u0026#39;re creating higher risks. Negative externalities of product changes are less likely to be prevented before they start causing problems in the world.\u0026#34; In a statement to \u003cem\u003eNPR\u003c/em\u003e, Meta said it would still tap \u0026#34;human expertise\u0026#34; to evaluate \u0026#34;novel and complex issues,\u0026#34; and leave the \u0026#34;low-risk decisions\u0026#34; to AI. Read the full report over at \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1\" href=\"https://www.npr.org/2025/05/31/nx-s1-5407870/meta-ai-facebook-instagram-risks\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:NPR;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas\"\u003e\u003cem\u003e\u003cins\u003eNPR\u003c/ins\u003e\u003c/em\u003e\u003c/a\u003e\u003cem\u003e.\u003c/em\u003e\u003c/p\u003e\u003cp\u003eIt comes a few days after Meta released its \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1\" href=\"https://www.engadget.com/social-media/facebook-sees-rise-in-violent-content-and-harassment-after-policy-changes-182651544.html\" data-ylk=\"slk:latest quarterly integrity reports;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas\"\u003e\u003cins\u003elatest quarterly integrity reports\u003c/ins\u003e\u003c/a\u003e — the first since \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1\" href=\"https://www.engadget.com/social-media/the-oversight-board-will-weigh-in-on-metas-new-hate-speech-policies-174044682.html\" data-ylk=\"slk:changing its policies on content moderation;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas\"\u003e\u003cins\u003echanging its policies on content moderation\u003c/ins\u003e\u003c/a\u003e and \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1\" href=\"https://www.engadget.com/social-media/meta-is-ditching-third-party-fact-checkers-on-facebook-instagram-142330246.html\" data-ylk=\"slk:fact-checking;elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1;itc:0;sec:content-canvas\"\u003e\u003cins\u003efact-checking\u003c/ins\u003e\u003c/a\u003e earlier this year. The amount of content taken down has unsurprisingly decreased in the wake of the changes, per the report. But there was a small rise in bullying and harassment, as well as violent and graphic content.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-05-31T20:54:16Z",
  "modifiedTime": null
}
