{
  "id": "de340a78-4cca-434f-a1da-2a9365ba5f21",
  "title": "Why pipes sometimes get \"stuck\": buffering",
  "link": "https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/",
  "description": "Comments",
  "author": "",
  "published": "Fri, 29 Nov 2024 16:43:51 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "Julia Evans",
  "length": 10575,
  "excerpt": "Why pipes sometimes get \"stuck\": buffering",
  "siteName": "Julia Evans",
  "favicon": "",
  "text": "Here’s a niche terminal problem that has bothered me for years but that I never really understood until a few weeks ago. Let’s say you’re running this command to watch for some specific output in a log file: tail -f /some/log/file | grep thing1 | grep thing2 If log lines are being added to the file relatively slowly, the result I’d see is… nothing! It doesn’t matter if there were matches in the log file or not, there just wouldn’t be any output. I internalized this as “uh, I guess pipes just get stuck sometimes and don’t show me the output, that’s weird”, and I’d handle it by just running grep thing1 /some/log/file | grep thing2 instead, which would work. So as I’ve been doing a terminal deep dive over the last few months I was really excited to finally learn exactly why this happens. why this happens: buffering The reason why “pipes get stuck” sometimes is that it’s VERY common for programs to buffer their output before writing it to a pipe or file. So the pipe is working fine, the problem is that the program never even wrote the data to the pipe! This is for performance reasons: writing all output immediately as soon as you can uses more system calls, so it’s more efficient to save up data until you have 8KB or so of data to write (or until the program exits) and THEN write it to the pipe. In this example: tail -f /some/log/file | grep thing1 | grep thing2 the problem is that grep thing1 is saving up all of its matches until it has 8KB of data to write, which might literally never happen. programs don’t buffer when writing to a terminal Part of why I found this so disorienting is that tail -f file | grep thing will work totally fine, but then when you add the second grep, it stops working!! The reason for this is that the way grep handles buffering depends on whether it’s writing to a terminal or not. Here’s how grep (and many other programs) decides to buffer its output: Check if stdout is a terminal or not using the isatty function If it’s a terminal, use line buffering (print every line immediately as soon as you have it) Otherwise, use “block buffering” – only print data if you have at least 8KB or so of data to print So if grep is writing directly to your terminal then you’ll see the line as soon as it’s printed, but if it’s writing to a pipe, you won’t. Of course the buffer size isn’t always 8KB for every program, it depends on the implementation. For grep the buffering is handled by libc, and libc’s buffer size is defined in the BUFSIZ variable. Here’s where that’s defined in glibc. (as an aside: “programs do not use 8KB output buffers when writing to a terminal” isn’t, like, a law of terminal physics, a program COULD use an 8KB buffer when writing output to a terminal if it wanted, it would just be extremely weird if it did that, I can’t think of any program that behaves that way) commands that buffer \u0026 commands that don’t One annoying thing about this buffering behaviour is that you kind of need to remember which commands buffer their output when writing to a pipe. Some commands that don’t buffer their output: tail cat tee I think almost everything else will buffer output, especially if it’s a command where you’re likely to be using it for batch processing. Here’s a list of some common commands that buffer their output when writing to a pipe, along with the flag that disables block buffering. grep (--line-buffered) sed (-u) awk (there’s a fflush() function) tcpdump (-l) jq (-u) tr (-u) cut (can’t disable buffering) Those are all the ones I can think of, lots of unix commands (like sort) may or may not buffer their output but it doesn’t matter because sort can’t do anything until it finishes receiving input anyway. Also I did my best to test both the Mac OS and GNU versions of these but there are a lot of variations and I might have made some mistakes. programming languages where the default “print” statement buffers Also, here are a few programming language where the default print statement will buffer output when writing to a pipe, and some ways to disable buffering if you want: C (disable with setvbuf) Python (disable with python -u, or PYTHON_UNBUFFERED=1, or sys.stdout.reconfigure(line_buffering=False), or print(x, flush=True)) Ruby (disable with STDOUT.sync = true) Perl (disable with $| = 1) I assume that these languages are designed this way so that the default print function will be fast when you’re doing batch processing. Also whether output is buffered or not might depend on what print function you use, for example in Rust print! buffers when writing to a pipe but println! will flush its output. when you press Ctrl-C on a pipe, the contents of the buffer are lost Let’s say you’re running this command as a hacky way to watch for DNS requests to example.com, and you forgot to pass -l to tcpdump: sudo tcpdump -ni any port 53 | grep example.com When you press Ctrl-C, what happens? In a magical perfect world, what I would want to happen is for tcpdump to flush its buffer, grep would search for example.com, and I would see all the output I missed. But in the real world, what happens is that all the programs get killed and the output in tcpdump’s buffer is lost. I think this problem is probably unavoidable – I spent a little time with strace to see how this works and grep receives the SIGINT before tcpdump anyway so even if tcpdump tried to flush its buffer grep would already be dead. After a little more investigation, there is a workaround: if you find tcpdump’s PID and kill -TERM $PID, then tcpdump will flush the buffer so you can see the output. That’s kind of a pain but I tested it and it seems to work. redirecting to a file also buffers It’s not just pipes, this will also buffer: sudo tcpdump -ni any port 53 \u003e output.txt Redirecting to a file doesn’t have the same “Ctrl-C will totally destroy the contents of the buffer” problem though – in my experience it usually behaves more like you’d want, where the contents of the buffer get written to the file before the program exits. I’m not 100% sure whether this is something you can always rely on or not. a bunch of potential ways to avoid buffering Okay, let’s talk solutions. Let’s say you’ve run this command or s tail -f /some/log/file | grep thing1 | grep thing2 I asked people on Mastodon how they would solve this in practice and there were 5 basic approaches. Here they are: solution 1: run a program that finishes quickly Historically my solution to this has been to just avoid the “command writing to pipe slowly” situation completely and instead run a program that will finish quickly like this: cat /some/log/file | grep thing1 | grep thing2 | tail This doesn’t do the same thing as the original command but it does mean that you get to avoid thinking about these weird buffering issues. (you could also do grep thing1 /some/log/file but I often prefer to use an “unnecessary” cat) solution 2: remember the “line buffer” flag to grep You could remember that grep has a flag to avoid buffering and pass it like this: tail -f /some/log/file | grep --line-buffered thing1 | grep thing2 solution 3: use awk Some people said that if they’re specifically dealing with a multiple greps situation, they’ll rewrite it to use a single awk instead, like this: tail -f /some/log/file | awk '/thing1/ \u0026\u0026 /thing2/' Or you would write a more complicated grep, like this: tail -f /some/log/file | grep -E 'thing1.*thing2' (awk also buffers, so for this to work you’ll want awk to be the last command in the pipeline) solution 4: use stdbuf stdbuf uses LD_PRELOAD to turn off libc’s buffering, and you can use it to turn off output buffering like this: tail -f /some/log/file | stdbuf -o0 grep thing1 | grep thing2 Like any LD_PRELOAD solution it’s a bit unreliable – it doesn’t work on static binaries, I think won’t work if the program isn’t using libc’s buffering, and doesn’t always work on Mac OS. Harry Marr has a really nice How stdbuf works post. solution 5: use unbuffer unbuffer program will force the program’s output to be a TTY, which means that it’ll behave the way it normally would on a TTY (less buffering, colour output, etc). You could use it in this example like this: tail -f /some/log/file | unbuffer grep thing1 | grep thing2 Unlike stdbuf it will always work, though it might have unwanted side effects, for example grep thing1’s will also colour matches. If you want to install unbuffer, it’s in the expect package. that’s all the solutions I know about! It’s a bit hard for me to say which one is “best”, I think personally I’m mostly likely to use unbuffer because I know it’s always going to work. If I learn about more solutions I’ll try to add them to this post. I’m not really sure how often this comes up I think it’s not very common for me to have a program that slowly trickles data into a pipe like this, normally if I’m using a pipe a bunch of data gets written very quickly, processed by everything in the pipeline, and then everything exits. The only examples I can come up with right now are: tcpdump tail -f watching log files in a different way like with kubectl logs the output of a slow computation what if there were an environment variable to disable buffering? I think it would be cool if there were a standard environment variable to turn off buffering, like PYTHON_UNBUFFERED in Python. I got this idea from a couple of blog posts by Mark Dominus in 2018. Maybe NO_BUFFER like NO_COLOR? The design seems tricky to get right; Mark points out that NETBSD has environment variables called STDBUF, STDBUF1, etc which gives you a ton of control over buffering but I imagine most developers don’t want to implement many different environment variables to handle a relatively minor edge case. I’m also curious about whether there are any programs that just automatically flush their output buffers after some period of time (like 1 second). It feels like it would be nice in theory but I can’t think of any program that does that so I imagine there are some downsides. stuff I left out Some things I didn’t talk about in this post since these posts have been getting pretty long recently and seriously does anyone REALLY want to read 3000 words about buffering? the difference between line buffering and having totally unbuffered output how buffering to stderr is different from buffering to stdout this post is only about buffering that happens inside the program, your operating system’s TTY driver also does a little bit of buffering sometimes other reasons you might need to flush your output other than “you’re writing to a pipe”",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n     \u003cp\u003eHere’s a niche terminal problem that has bothered me for years but that I never\nreally understood until a few weeks ago. Let’s say you’re running this command\nto watch for some specific output in a log file:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file | grep thing1 | grep thing2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf log lines are being added to the file relatively slowly, the result I’d see\nis… nothing! It doesn’t matter if there were matches in the log file or not,\nthere just wouldn’t be any output.\u003c/p\u003e\n\u003cp\u003eI internalized this as “uh, I guess pipes just get stuck sometimes and don’t\nshow me the output, that’s weird”, and I’d handle it by just\nrunning \u003ccode\u003egrep thing1 /some/log/file | grep thing2\u003c/code\u003e instead, which would work.\u003c/p\u003e\n\u003cp\u003eSo as I’ve been doing a terminal deep dive over the last few months I was\nreally excited to finally learn exactly why this happens.\u003c/p\u003e\n\u003ch3 id=\"why-this-happens-buffering\"\u003ewhy this happens: buffering\u003c/h3\u003e\n\u003cp\u003eThe reason why “pipes get stuck” sometimes is that it’s VERY common for\nprograms to buffer their output before writing it to a pipe or file. So the\npipe is working fine, the problem is that the program never even wrote the data\nto the pipe!\u003c/p\u003e\n\u003cp\u003eThis is for performance reasons: writing all output immediately as soon as you\ncan uses more system calls, so it’s more efficient to save up data until you\nhave 8KB or so of data to write (or until the program exits) and THEN write it\nto the pipe.\u003c/p\u003e\n\u003cp\u003eIn this example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file | grep thing1 | grep thing2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ethe problem is that \u003ccode\u003egrep thing1\u003c/code\u003e is saving up all of its matches until it has\n8KB of data to write, which might literally never happen.\u003c/p\u003e\n\u003ch3 id=\"programs-don-t-buffer-when-writing-to-a-terminal\"\u003eprograms don’t buffer when writing to a terminal\u003c/h3\u003e\n\u003cp\u003ePart of why I found this so disorienting is that \u003ccode\u003etail -f file | grep thing\u003c/code\u003e\nwill work totally fine, but then when you add the second \u003ccode\u003egrep\u003c/code\u003e, it stops\nworking!! The reason for this is that the way \u003ccode\u003egrep\u003c/code\u003e handles buffering depends\non whether it’s writing to a terminal or not.\u003c/p\u003e\n\u003cp\u003eHere’s how \u003ccode\u003egrep\u003c/code\u003e (and many other programs) decides to buffer its output:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCheck if stdout is a terminal or not using the \u003ccode\u003eisatty\u003c/code\u003e function\n\u003cul\u003e\n\u003cli\u003eIf it’s a terminal, use line buffering (print every line immediately as soon as you have it)\u003c/li\u003e\n\u003cli\u003eOtherwise, use “block buffering” – only print data if you have at least 8KB or so of data to print\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo if \u003ccode\u003egrep\u003c/code\u003e is writing directly to your terminal then you’ll see the line as\nsoon as it’s printed, but if it’s writing to a pipe, you won’t.\u003c/p\u003e\n\u003cp\u003eOf course the buffer size isn’t always 8KB for every program, it depends on the implementation. For \u003ccode\u003egrep\u003c/code\u003e the buffering is handled by libc, and libc’s buffer size is\ndefined in the \u003ccode\u003eBUFSIZ\u003c/code\u003e variable. \u003ca href=\"https://github.com/bminor/glibc/blob/c69e8cccaff8f2d89cee43202623b33e6ef5d24a/libio/stdio.h#L100\"\u003eHere’s where that’s defined in glibc\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e(as an aside: “programs do not use 8KB output buffers when writing to a\nterminal” isn’t, like, a law of terminal physics, a program COULD use an 8KB\nbuffer when writing output to a terminal if it wanted, it would just be\nextremely weird if it did that, I can’t think of any program that behaves that\nway)\u003c/p\u003e\n\u003ch3 id=\"commands-that-buffer-commands-that-don-t\"\u003ecommands that buffer \u0026amp; commands that don’t\u003c/h3\u003e\n\u003cp\u003eOne annoying thing about this buffering behaviour is that you kind of need to\nremember which commands buffer their output when writing to a pipe.\u003c/p\u003e\n\u003cp\u003eSome commands that \u003cstrong\u003edon’t\u003c/strong\u003e buffer their output:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etail\u003c/li\u003e\n\u003cli\u003ecat\u003c/li\u003e\n\u003cli\u003etee\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI think almost everything else will buffer output, especially if it’s a command\nwhere you’re likely to be using it for batch processing. Here’s a list of some\ncommon commands that buffer their output when writing to a pipe, along with the\nflag that disables block buffering.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003egrep (\u003ccode\u003e--line-buffered\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003esed (\u003ccode\u003e-u\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eawk (there’s a \u003ccode\u003efflush()\u003c/code\u003e function)\u003c/li\u003e\n\u003cli\u003etcpdump (\u003ccode\u003e-l\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ejq (\u003ccode\u003e-u\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003etr (\u003ccode\u003e-u\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ecut (can’t disable buffering)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThose are all the ones I can think of, lots of unix commands (like \u003ccode\u003esort\u003c/code\u003e) may\nor may not buffer their output but it doesn’t matter because \u003ccode\u003esort\u003c/code\u003e can’t do\nanything until it finishes receiving input anyway.\u003c/p\u003e\n\u003cp\u003eAlso I did my best to test both the Mac OS and GNU versions of these but there\nare a lot of variations and I might have made some mistakes.\u003c/p\u003e\n\u003ch3 id=\"programming-languages-where-the-default-print-statement-buffers\"\u003eprogramming languages where the default “print” statement buffers\u003c/h3\u003e\n\u003cp\u003eAlso, here are a few programming language where the default print statement\nwill buffer output when writing to a pipe, and some ways to disable buffering\nif you want:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eC (disable with \u003ccode\u003esetvbuf\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ePython (disable with \u003ccode\u003epython -u\u003c/code\u003e, or \u003ccode\u003ePYTHON_UNBUFFERED=1\u003c/code\u003e, or \u003ccode\u003esys.stdout.reconfigure(line_buffering=False)\u003c/code\u003e, or \u003ccode\u003eprint(x, flush=True)\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eRuby (disable with \u003ccode\u003eSTDOUT.sync = true\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ePerl (disable with \u003ccode\u003e$| = 1\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI assume that these languages are designed this way so that the default print\nfunction will be fast when you’re doing batch processing.\u003c/p\u003e\n\u003cp\u003eAlso whether output is buffered or not might depend on what print function you\nuse, for example in Rust \u003ccode\u003eprint!\u003c/code\u003e buffers when writing to a pipe but \u003ccode\u003eprintln!\u003c/code\u003e\nwill flush its output.\u003c/p\u003e\n\u003ch3 id=\"when-you-press-ctrl-c-on-a-pipe-the-contents-of-the-buffer-are-lost\"\u003ewhen you press \u003ccode\u003eCtrl-C\u003c/code\u003e on a pipe, the contents of the buffer are lost\u003c/h3\u003e\n\u003cp\u003eLet’s say you’re running this command as a hacky way to watch for DNS requests\nto \u003ccode\u003eexample.com\u003c/code\u003e, and you forgot to pass \u003ccode\u003e-l\u003c/code\u003e to tcpdump:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo tcpdump -ni any port 53 | grep example.com\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you press \u003ccode\u003eCtrl-C\u003c/code\u003e, what happens? In a magical perfect world, what I would\n\u003cem\u003ewant\u003c/em\u003e to happen is for \u003ccode\u003etcpdump\u003c/code\u003e to flush its buffer, \u003ccode\u003egrep\u003c/code\u003e would search for\n\u003ccode\u003eexample.com\u003c/code\u003e, and I would see all the output I missed.\u003c/p\u003e\n\u003cp\u003eBut in the real world, what happens is that all the programs get killed and the\noutput in \u003ccode\u003etcpdump\u003c/code\u003e’s buffer is lost.\u003c/p\u003e\n\u003cp\u003eI think this problem is probably unavoidable – I spent a little time with\n\u003ccode\u003estrace\u003c/code\u003e to see how this works and \u003ccode\u003egrep\u003c/code\u003e receives the \u003ccode\u003eSIGINT\u003c/code\u003e before\n\u003ccode\u003etcpdump\u003c/code\u003e anyway so even if \u003ccode\u003etcpdump\u003c/code\u003e tried to flush its buffer \u003ccode\u003egrep\u003c/code\u003e would\nalready be dead.\u003c/p\u003e\n\u003csmall\u003e\n\u003cp\u003eAfter a little more investigation, there is a workaround: if you find\n\u003ccode\u003etcpdump\u003c/code\u003e’s PID and \u003ccode\u003ekill -TERM $PID\u003c/code\u003e, then tcpdump will flush the buffer so\nyou can see the output. That’s kind of a pain but I tested it and it seems to\nwork.\u003c/p\u003e\n\u003c/small\u003e\n\u003ch3 id=\"redirecting-to-a-file-also-buffers\"\u003eredirecting to a file also buffers\u003c/h3\u003e\n\u003cp\u003eIt’s not just pipes, this will also buffer:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo tcpdump -ni any port 53 \u0026gt; output.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRedirecting to a file doesn’t have the same “\u003ccode\u003eCtrl-C\u003c/code\u003e will totally destroy the\ncontents of the buffer” problem though – in my experience it usually behaves\nmore like you’d want, where the contents of the buffer get written to the file\nbefore the program exits. I’m not 100% sure whether this is something you can\nalways rely on or not.\u003c/p\u003e\n\u003ch3 id=\"a-bunch-of-potential-ways-to-avoid-buffering\"\u003ea bunch of potential ways to avoid buffering\u003c/h3\u003e\n\u003cp\u003eOkay, let’s talk solutions. Let’s say you’ve run this command or s\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file | grep thing1 | grep thing2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI asked people on Mastodon how they would solve this in practice and there were\n5 basic approaches. Here they are:\u003c/p\u003e\n\u003ch4 id=\"solution-1-run-a-program-that-finishes-quickly\"\u003esolution 1: run a program that finishes quickly\u003c/h4\u003e\n\u003cp\u003eHistorically my solution to this has been to just avoid the “command writing to\npipe slowly” situation completely and instead run a program that will finish quickly\nlike this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecat /some/log/file | grep thing1 | grep thing2 | tail\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis doesn’t do the same thing as the original command but it does mean that\nyou get to avoid thinking about these weird buffering issues.\u003c/p\u003e\n\u003cp\u003e(you could also do \u003ccode\u003egrep thing1 /some/log/file\u003c/code\u003e but I often prefer to use an\n“unnecessary” \u003ccode\u003ecat\u003c/code\u003e)\u003c/p\u003e\n\u003ch4 id=\"solution-2-remember-the-line-buffer-flag-to-grep\"\u003esolution 2: remember the “line buffer” flag to grep\u003c/h4\u003e\n\u003cp\u003eYou could remember that grep has a flag to avoid buffering and pass it like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file | grep --line-buffered thing1 | grep thing2\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"solution-3-use-awk\"\u003esolution 3: use awk\u003c/h4\u003e\n\u003cp\u003eSome people said that if they’re specifically dealing with a multiple greps\nsituation, they’ll rewrite it to use a single \u003ccode\u003eawk\u003c/code\u003e instead, like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file |  awk \u0026#39;/thing1/ \u0026amp;\u0026amp; /thing2/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOr you would write a more complicated \u003ccode\u003egrep\u003c/code\u003e, like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file |  grep -E \u0026#39;thing1.*thing2\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e(\u003ccode\u003eawk\u003c/code\u003e also buffers, so for this to work you’ll want \u003ccode\u003eawk\u003c/code\u003e to be the last command in the pipeline)\u003c/p\u003e\n\u003ch4 id=\"solution-4-use-stdbuf\"\u003esolution 4: use \u003ccode\u003estdbuf\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003estdbuf\u003c/code\u003e uses LD_PRELOAD to turn off libc’s buffering, and you can use it to turn off output buffering like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file | stdbuf -o0 grep thing1 | grep thing2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLike any \u003ccode\u003eLD_PRELOAD\u003c/code\u003e solution it’s a bit unreliable – it doesn’t work on\nstatic binaries, I think won’t work if the program isn’t using libc’s\nbuffering, and doesn’t always work on Mac OS. Harry Marr has a really nice \u003ca href=\"https://hmarr.com/blog/how-stdbuf-works/\"\u003eHow stdbuf works\u003c/a\u003e post.\u003c/p\u003e\n\u003ch4 id=\"solution-5-use-unbuffer\"\u003esolution 5: use \u003ccode\u003eunbuffer\u003c/code\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ccode\u003eunbuffer program\u003c/code\u003e will force the program’s output to be a TTY, which means\nthat it’ll behave the way it normally would on a TTY (less buffering, colour\noutput, etc). You could use it in this example like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etail -f /some/log/file | unbuffer grep thing1 | grep thing2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUnlike \u003ccode\u003estdbuf\u003c/code\u003e it will always work, though it might have unwanted side\neffects, for example \u003ccode\u003egrep thing1\u003c/code\u003e’s will also colour matches.\u003c/p\u003e\n\u003cp\u003eIf you want to install unbuffer, it’s in the \u003ccode\u003eexpect\u003c/code\u003e package.\u003c/p\u003e\n\u003ch3 id=\"that-s-all-the-solutions-i-know-about\"\u003ethat’s all the solutions I know about!\u003c/h3\u003e\n\u003cp\u003eIt’s a bit hard for me to say which one is “best”, I think personally I’m\nmostly likely to use \u003ccode\u003eunbuffer\u003c/code\u003e because I know it’s always going to work.\u003c/p\u003e\n\u003cp\u003eIf I learn about more solutions I’ll try to add them to this post.\u003c/p\u003e\n\u003ch3 id=\"i-m-not-really-sure-how-often-this-comes-up\"\u003eI’m not really sure how often this comes up\u003c/h3\u003e\n\u003cp\u003eI think it’s not very common for me to have a program that slowly trickles data\ninto a pipe like this, normally if I’m using a pipe a bunch of data gets\nwritten very quickly, processed by everything in the pipeline, and then\neverything exits. The only examples I can come up with right now are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etcpdump\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etail -f\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ewatching log files in a different way like with \u003ccode\u003ekubectl logs\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ethe output of a slow computation\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"what-if-there-were-an-environment-variable-to-disable-buffering\"\u003ewhat if there were an environment variable to disable buffering?\u003c/h3\u003e\n\u003cp\u003eI think it would be cool if there were a standard environment variable to turn\noff buffering, like \u003ccode\u003ePYTHON_UNBUFFERED\u003c/code\u003e in Python. I got this idea from a\n\u003ca href=\"https://blog.plover.com/Unix/stdio-buffering.html\"\u003ecouple\u003c/a\u003e of \u003ca href=\"https://blog.plover.com/Unix/stdio-buffering-2.html\"\u003eblog posts\u003c/a\u003e by Mark Dominus\nin 2018. Maybe \u003ccode\u003eNO_BUFFER\u003c/code\u003e like \u003ca href=\"https://no-color.org/\"\u003eNO_COLOR\u003c/a\u003e?\u003c/p\u003e\n\u003cp\u003eThe design seems tricky to get right; Mark points out that NETBSD has \u003ca href=\"https://man.netbsd.org/setbuf.3\"\u003eenvironment variables called \u003ccode\u003eSTDBUF\u003c/code\u003e, \u003ccode\u003eSTDBUF1\u003c/code\u003e, etc\u003c/a\u003e which gives you a\nton of control over buffering but I imagine most developers don’t want to\nimplement many different environment variables to handle a relatively minor\nedge case.\u003c/p\u003e\n\u003cp\u003eI’m also curious about whether there are any programs that just automatically\nflush their output buffers after some period of time (like 1 second). It feels\nlike it would be nice in theory but I can’t think of any program that does that\nso I imagine there are some downsides.\u003c/p\u003e\n\u003ch3 id=\"stuff-i-left-out\"\u003estuff I left out\u003c/h3\u003e\n\u003cp\u003eSome things I didn’t talk about in this post since these posts have been\ngetting pretty long recently and seriously does anyone REALLY want to read 3000\nwords about buffering?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe difference between line buffering and having totally unbuffered output\u003c/li\u003e\n\u003cli\u003ehow buffering to stderr is different from buffering to stdout\u003c/li\u003e\n\u003cli\u003ethis post is only about buffering that happens \u003cstrong\u003einside the program\u003c/strong\u003e, your\noperating system’s TTY driver also does a little bit of buffering sometimes\u003c/li\u003e\n\u003cli\u003eother reasons you might need to flush your output other than “you’re writing\nto a pipe”\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": null,
  "modifiedTime": null
}
