{
  "id": "e2726751-cb37-4b82-b022-0d239a9ad544",
  "title": "Nvidia’s 50-series cards drop support for PhysX, impacting older games",
  "link": "https://arstechnica.com/gadgets/2025/02/batman-arkham-games-among-those-losing-physx-powers-on-newer-nvidia-gpus/",
  "description": "The 32-bit tech on older games can't bring snazzy effects forward.",
  "author": "Kevin Purdy",
  "published": "Tue, 18 Feb 2025 23:25:45 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "Gaming",
    "Tech",
    "Batman: Arkham City",
    "CUDA",
    "NVIDIA",
    "PhysX",
    "seamus blackley",
    "the witcher 3",
    "Tim Sweeney"
  ],
  "byline": "Kevin Purdy",
  "length": 3160,
  "excerpt": "The 32-bit tech on older games can’t bring snazzy effects forward.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "Nvidia's PhysX offerings to developers didn't always generate warm feelings. As part of its broader GamesWorks package, PhysX was cited as one of the reasons The Witcher 3 ran at notably sub-optimal levels at launch. Protagonist Geralt's hair, rendered in PhysX-powered HairWorks, was a burden on some chipsets. PhysX started appearing in general game engines, like Unity 5, and was eventually open-sourced, first in limited computer and mobile form, then more broadly. As an application wrapped up in Nvidia's 32-bit CUDA API and platform, the PhysX engine had a built-in shelf life. Now the expiration date is known, and it is conditional on buying into Nvidia's 50-series video cards—whenever they approach reasonable human prices. See that smoke? It's from Sweden, originally. Credit: Gearbox/Take 2 See that smoke? It's from Sweden, originally. Credit: Gearbox/Take 2 The real dynamic particles were the friends we made… Nvidia noted in mid-January that 32-bit applications cannot be developed or debugged on the latest versions of its CUDA toolkit. They will still run on cards before the 50 series. Technically, you could also keep an older card installed on your system for compatibility, which is real dedication to early-2010's-era particle physics. Technically, a 64-bit game could still support PhysX on Nvidia's newest GPUs, but the heyday of PhysX, as a stand-alone technology switched on in game settings, tended to coincide with the 32-bit computing era. If you load up a 32-bit game now with PhysX enabled (or forced in a config file) and a 50-series Nvidia GPU installed, there's a good chance the physics work will be passed to the CPU instead of the GPU, likely bottlenecking the game and steeply lowering frame rates. Of course, turning off PhysX entirely raised frame rates above even native GPU support levels. Demanding Borderlands 2 keep using PhysX made it so it \"runs terrible,\" noted one Redditor, even if the dust clouds and flapping cloth strips looked interesting. Other games with PhysX baked in, as listed by ResetEra completists, include Metro 2033, Assassin's Creed IV: Black Flag, and the 2013 Star Trek game. Commenters on Reddit and ResetEra note that many of the games listed had performance issues with PhysX long before Nvidia forced them to either turn off or be loaded onto a CPU. For some games, however, PhysX enabled destructible environments, \"dynamic bank notes\" and \"posters\" (in the Arkham games), fluid simulations, and base gameplay physics. Anyone who works in, or cares about, game preservation has always had their work cut out for them. But it's a particularly tough challenge to see certain aspects of a game's operation lost to the forward march of the CUDA platform, something that's harder to explain than a scratched CD or Windows compatibility.",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/batman1-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n          \n          \n\u003cp\u003eNvidia\u0026#39;s PhysX offerings to developers didn\u0026#39;t always generate warm feelings. As part of its broader GamesWorks package, PhysX was cited as one of the reasons \u003ca href=\"https://arstechnica.com/gaming/2015/05/amd-says-nvidias-gameworks-completely-sabotaged-witcher-3-performance/\"\u003e\u003cem\u003eThe Witcher 3\u003c/em\u003e ran at notably sub-optimal levels\u003c/a\u003e at launch. Protagonist Geralt\u0026#39;s hair, rendered in PhysX-powered HairWorks, was a burden on some chipsets.\u003c/p\u003e\n\u003cp\u003ePhysX started appearing in general game engines, like \u003ca href=\"https://arstechnica.com/gaming/2015/03/unity-5-game-engine-brings-enhanced-graphic-tools-new-cloud-services/\"\u003eUnity 5\u003c/a\u003e, and was eventually open-sourced, first in \u003ca href=\"https://web.archive.org/web/20181205103131/https://developer.nvidia.com/physx-sdk\"\u003elimited computer and mobile form\u003c/a\u003e, then \u003ca href=\"https://web.archive.org/web/20230528035837/https://developer.nvidia.com/blog/open-source-simulation-expands-with-nvidia-physx-5-release/\"\u003emore broadly\u003c/a\u003e. As an application wrapped up in Nvidia\u0026#39;s 32-bit CUDA API and platform, the PhysX engine had a built-in shelf life. Now the expiration date is known, and it is conditional on buying into Nvidia\u0026#39;s 50-series video cards—whenever they approach reasonable human prices.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cdiv\u003e\n            \u003cp\u003e\u003ca data-pswp-width=\"2560\" data-pswp-height=\"1440\" data-pswp-srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-scaled.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1440x810.jpg 1440w\" data-cropped=\"false\" href=\"https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-scaled.jpg\" target=\"_blank\"\u003e\n              \u003cimg width=\"1024\" height=\"576\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1024x576.jpg\" alt=\"Dune buggy in Borderlands 3, dodging rockets shot by a hovering attack craft just over a sand dune, in Borderlands 3.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/02/borderlands3-1440x810.jpg 1440w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n            \u003c/a\u003e\u003c/p\u003e\u003cdiv id=\"caption-2076751\"\u003e\u003cp\u003e\n              See that smoke? It\u0026#39;s from Sweden, originally.\n                              \u003c/p\u003e\u003cp\u003e\n                  Credit:\n                                      Gearbox/Take 2\n                                  \u003c/p\u003e\n                          \u003c/div\u003e\n          \u003c/div\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      See that smoke? It\u0026#39;s from Sweden, originally.\n\n              \u003cspan\u003e\n          Credit:\n\n          \n          Gearbox/Take 2\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003ch2\u003eThe real dynamic particles were the friends we made…\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://nvidia.custhelp.com/app/answers/detail/a_id/5615\"\u003eNvidia noted in mid-January\u003c/a\u003e that 32-bit applications cannot be developed or debugged on the latest versions of its CUDA toolkit. They will still run on cards before the 50 series. Technically, you could also keep an older card installed on your system for compatibility, which is real dedication to early-2010\u0026#39;s-era particle physics.\u003c/p\u003e\n\u003cp\u003eTechnically, a 64-bit game could still support PhysX on Nvidia\u0026#39;s newest GPUs, but the heyday of PhysX, as a stand-alone technology switched on in game settings, tended to coincide with the 32-bit computing era.\u003c/p\u003e\n\u003cp\u003eIf you load up a 32-bit game now with PhysX enabled (or \u003ca href=\"https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/557125/rtx-5090-missing-physx-support/\"\u003eforced in a config file\u003c/a\u003e) and a 50-series Nvidia GPU installed, there\u0026#39;s a good chance the physics work will be passed to the CPU instead of the GPU, likely \u003ca href=\"https://www.youtube.com/watch?v=mJGf0-tGaf4\"\u003ebottlenecking the game and steeply lowering frame rates\u003c/a\u003e. Of course, turning off PhysX entirely raised frame rates above even native GPU support levels.\u003c/p\u003e\n\u003cp\u003eDemanding \u003cem\u003eBorderlands 2\u003c/em\u003e keep using PhysX made it so it \u0026#34;runs terrible,\u0026#34; \u003ca href=\"https://www.reddit.com/r/nvidia/comments/1irs8xk/comment/mdauwh3/?utm_name=web3xcss\"\u003enoted one Redditor\u003c/a\u003e, even if the dust clouds and flapping cloth strips looked interesting. Other games with PhysX baked in, as listed by ResetEra completists, include \u003cem\u003eMetro 2033, \u003c/em\u003e\u003ca href=\"https://arstechnica.com/gaming/2013/10/assassins-creed-iv-review-enormous-but-ultimately-empty/\"\u003e\u003cem\u003eAssassin\u0026#39;s Creed IV: Black Flag\u003c/em\u003e\u003c/a\u003e, and \u003ca href=\"https://en.wikipedia.org/wiki/Star_Trek_(2013_video_game)\"\u003ethe 2013 \u003cem\u003eStar Trek \u003c/em\u003egame\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCommenters on Reddit and ResetEra note that many of the games listed had performance issues with PhysX long before Nvidia forced them to either turn off or be loaded onto a CPU. For some games, however, PhysX enabled destructible environments, \u0026#34;dynamic bank notes\u0026#34; and \u0026#34;posters\u0026#34; (in the \u003cem\u003eArkham\u003c/em\u003e games), fluid simulations, and base gameplay physics.\u003c/p\u003e\n\u003cp\u003eAnyone who works in, or cares about, game preservation has always had their work cut out for them. But it\u0026#39;s a particularly tough challenge to see certain aspects of a game\u0026#39;s operation lost to the forward march of the CUDA platform, something that\u0026#39;s harder to explain than a scratched CD or Windows compatibility.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-02-18T23:25:45Z",
  "modifiedTime": "2025-02-18T23:36:51Z"
}
