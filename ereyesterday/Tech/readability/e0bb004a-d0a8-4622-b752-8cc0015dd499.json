{
  "id": "e0bb004a-d0a8-4622-b752-8cc0015dd499",
  "title": "At TED AI 2024, experts grapple with AI’s growing pains",
  "link": "https://arstechnica.com/ai/2024/10/at-ted-ai-2024-experts-grapple-with-ais-growing-pains/",
  "description": "A year later, a compelling group of TED speakers move from \"what's this?\" to \"what now?\"",
  "author": "Benj Edwards",
  "published": "Wed, 23 Oct 2024 22:32:14 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Biz \u0026 IT",
    "AI conferences",
    "conference",
    "machine learning",
    "San Francisco",
    "TED",
    "TED AI",
    "TED AI 2024",
    "TED Talks"
  ],
  "byline": "Benj Edwards",
  "length": 9943,
  "excerpt": "A year later, a compelling group of TED speakers move from “what’s this?” to “what now?”…",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "A year later, a compelling group of TED speakers move from \"what's this?\" to \"what now?\" The opening moments of TED AI 2024 in San Francisco on October 22, 2024. Credit: Benj Edwards SAN FRANCISCO—On Tuesday, TED AI 2024 kicked off its first day at San Francisco's Herbst Theater with a lineup of speakers that tackled AI's impact on science, art, and society. The two-day event brought a mix of researchers, entrepreneurs, lawyers, and other experts who painted a complex picture of AI with fairly minimal hype. The second annual conference, organized by Walter and Sam De Brouwer, marked a notable shift from last year's broad existential debates and proclamations of AI as being \"the new electricity.\" Rather than sweeping predictions about, say, looming artificial general intelligence (although there was still some of that, too), speakers mostly focused on immediate challenges: battles over training data rights, proposals for hardware-based regulation, debates about human-AI relationships, and the complex dynamics of workplace adoption. The day's sessions covered a wide breadth: physicist Carlo Rovelli explored consciousness and time, Project CETI researcher Patricia Sharma demonstrated attempts to use AI to decode whale communication, Recording Academy CEO Harvey Mason Jr. outlined music industry adaptation strategies, and even a few robots made appearances. The shift from last year's theoretical discussions to practical concerns was particularly evident during a presentation from Ethan Mollick of the Wharton School, who tackled what he called \"the productivity paradox\"—the disconnect between AI's measured impact and its perceived benefits in the workplace. Already, organizations are moving beyond the gee-whiz period after ChatGPT's introduction and into the implications of widespread use. Sam De Brouwer and Walter De Brouwer organized TED AI and selected the speakers. Benj Edwards Drawing from research claiming AI users complete tasks faster and more efficiently, Mollick highlighted a peculiar phenomenon: While one-third of Americans reported using AI in August of this year, managers often claim \"no one's using AI\" in their organizations. Through a live demonstration using multiple AI models simultaneously, Mollick illustrated how traditional work patterns must evolve to accommodate AI's capabilities. He also pointed to the emergence of what he calls \"secret cyborgs\"—employees quietly using AI tools without management's knowledge. Regarding the future of jobs in the age of AI, he urged organizations to view AI as an opportunity for expansion rather than merely a cost-cutting measure. Some giants in the AI field made an appearance. Jakob Uszkoreit, one of the eight co-authors of the now-famous \"Attention is All You Need\" paper that introduced Transformer architecture, reflected on the field's rapid evolution. He distanced himself from the term \"artificial general intelligence,\" suggesting people aren't particularly general in their capabilities. Uszkoreit described how the development of Transformers sidestepped traditional scientific theory, comparing the field to alchemy. \"We still do not know how human language works. We do not have a comprehensive theory of English,\" he noted. Stanford professor Surya Ganguli presenting at TED AI 2024. Benj Edwards And refreshingly, the talks went beyond AI language models. For example, Isomorphic Labs Chief AI Officer Max Jaderberg, who previously worked on Google DeepMind's AlphaFold 3, gave a well-received presentation on AI-assisted drug discovery. He detailed how AlphaFold has already saved \"1 billion years of research time\" by discovering the shapes of proteins and showed how AI agents are now capable of running thousands of parallel drug design simulations that could enable personalized medicine. Danger and controversy While hype was less prominent this year, some speakers still spoke of AI-related dangers. Paul Scharre, executive vice president at the Center for a New American Security, warned about the risks of advanced AI models falling into malicious hands, specifically citing concerns about terrorist attacks with AI-engineered biological weapons. Drawing parallels to nuclear proliferation in the 1960s, Scharre argued that while regulating software is nearly impossible, controlling physical components like specialized chips and fabrication facilities could provide a practical framework for AI governance. ReplikaAI founder Eugenia Kuyda cautioned that AI companions could become \"the most dangerous technology if not done right,\" suggesting that the existential threat from AI might come not from science fiction scenarios but from technology that isolates us from human connections. She advocated for designing AI systems that optimize for human happiness rather than engagement, proposing a \"human flourishing metric\" to measure its success. Ben Zhao, a University of Chicago professor associated with the Glaze and Nightshade projects, painted a dire picture of AI's impact on art, claiming that art schools were seeing unprecedented enrollment drops and galleries were closing at an accelerated rate due to AI image generators, though we have yet to dig through the supporting news headlines he momentarily flashed up on the screen. Some of the speakers represented polar opposites of each other, policy-wise. For example, copyright attorney Angela Dunning offered a defense of AI training as fair use, drawing from historical parallels in technological advancement. A litigation partner at Cleary Gottlieb, which has previously represented the AI image generation service Midjourney in a lawsuit, Dunning quoted Mark Twin saying \"there is no such thing as a new idea\" and argued that copyright law allows for building upon others' ideas while protecting specific expressions. She compared current AI debates to past technological disruptions, noting how photography, once feared as a threat to traditional artists, instead sparked new artistic movements like abstract art and pointillism. \"Art and science can only remain free if we are free to build on the ideas of those that came before,\" Dunning said, challenging more restrictive views of AI training. Copyright lawyer Angela Dunning quoted Mark Twain in her talk about fair use and AI. Benj Edwards Dunning's presentation stood in direct opposition to Ed Newton-Rex, who had earlier advocated for mandatory licensing of training data through his nonprofit Fairly Trained. In fact, the same day, Newton-Rex's organization unveiled a \"Statement on AI training\" signed by many artists that says, \"The unlicensed use of creative works for training generative AI is a major, unjust threat to the livelihoods of the people behind those works, and must not be permitted.\" The issue has not yet been legally settled in US courts, but clearly, the battle lines have been drawn, and no matter which side you take, TED AI did a good job of giving both perspectives to the audience. Looking forward Some speakers explored potential new architectures for AI. Stanford professor Surya Ganguli highlighted the contrast between AI and human learning, noting that while AI models require trillions of tokens to train, humans learn language from just millions of exposures. He proposed \"quantum neuromorphic computing\" as a potential bridge between biological and artificial systems, suggesting a future where computers could potentially match the energy efficiency of the human brain. Also, Guillaume Verdon, founder of Extropic and architect of the Effective Accelerationism (often called \"E/Acc\") movement, presented what he called \"physics-based intelligence\" and claimed his company is \"building a steam engine for AI,\" potentially offering energy efficiency improvements up to 100 million times better than traditional systems—though he acknowledged this figure ignores cooling requirements for superconducting components. The company had completed its first room-temperature chip tape-out just the previous week. The Day One sessions closed out with predictions about the future of AI from OpenAI's Noam Brown, who emphasized the importance of scale in expanding future AI capabilities, and University of Washington professor Pedro Domingos spoke about \"co-intelligence,\" saying, \"People are smart, organizations are stupid\" and proposing that AI could be used to bridge that gap by drawing on the collective intelligence of an organization. When attended TED AI last year, some obvious questions emerged: Is this current wave of AI a fad? Will there be a TED AI next year? I think the second TED AI answered these questions well—AI isn't going away, and there are still endless angles to explore as the field expands rapidly. Benj Edwards is Ars Technica's Senior AI Reporter and founder of the site's dedicated AI beat in 2022. He's also a widely-cited tech historian. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2024/10/IMG_8832.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n            \u003carticle data-id=\"2057656\"\u003e\n  \n  \u003cheader\u003e\n  \u003cdiv\u003e\n    \u003cdiv\u003e\n      \n\n      \n\n      \u003cp\u003e\n        A year later, a compelling group of TED speakers move from \u0026#34;what\u0026#39;s this?\u0026#34; to \u0026#34;what now?\u0026#34;\n      \u003c/p\u003e\n\n      \n    \u003c/div\u003e\n\n          \u003cdiv\u003e\n        \u003cp\u003e\u003cimg width=\"1000\" height=\"1000\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/10/IMG_8832-1000x1000.jpeg\" alt=\"The opening moments of TED AI 2024 in San Francisco on October 22, 2024.\" loading=\"eager\" decoding=\"async\" fetchpriority=\"high\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/10/IMG_8832-1000x1000.jpeg 1000w, https://cdn.arstechnica.net/wp-content/uploads/2024/10/IMG_8832-150x150.jpeg 150w, https://cdn.arstechnica.net/wp-content/uploads/2024/10/IMG_8832-500x500.jpeg 500w\" sizes=\"(max-width: 1000px) 100vw, 1000px\"/\u003e\n        \u003c/p\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      The opening moments of TED AI 2024 in San Francisco on October 22, 2024. \n\n              \u003cspan\u003e\n          Credit:\n\n          \n          Benj Edwards\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/div\u003e\n      \u003c/div\u003e\n\u003c/header\u003e\n\n  \n\n  \n      \n    \n    \u003cdiv\u003e\n                      \n                      \n          \n\u003cp\u003eSAN FRANCISCO—On Tuesday, \u003ca href=\"https://tedai-sanfrancisco.ted.com/ai-conferences/\"\u003eTED AI 2024\u003c/a\u003e kicked off its first day at San Francisco\u0026#39;s Herbst Theater with a lineup of speakers that tackled AI\u0026#39;s impact on science, art, and society. The two-day event brought a mix of researchers, entrepreneurs, lawyers, and other experts who painted a complex picture of AI with fairly minimal hype.\u003c/p\u003e\n\u003cp\u003eThe second annual conference, organized by Walter and Sam De Brouwer, marked a notable shift from last year\u0026#39;s broad existential debates and proclamations of AI as being \u0026#34;\u003ca href=\"https://arstechnica.com/information-technology/2023/10/ted-ai-2023-a-historic-symposium-on-benefits-risks-and-applications-of-ai/\"\u003ethe new electricity\u003c/a\u003e.\u0026#34; Rather than sweeping predictions about, say, looming artificial general intelligence (although there was still some of that, too), speakers mostly focused on immediate challenges: battles over training data rights, proposals for hardware-based regulation, debates about human-AI relationships, and the complex dynamics of workplace adoption.\u003c/p\u003e\n\u003cp\u003eThe day\u0026#39;s sessions covered a wide breadth: physicist Carlo Rovelli explored consciousness and time, Project CETI researcher Patricia Sharma demonstrated attempts to use AI to decode whale communication, Recording Academy CEO Harvey Mason Jr. outlined music industry adaptation strategies, and even a few robots made appearances.\u003c/p\u003e\n\u003cp\u003eThe shift from last year\u0026#39;s theoretical discussions to practical concerns was particularly evident during a presentation from Ethan Mollick of the Wharton School, who tackled what he called \u0026#34;the productivity paradox\u0026#34;—the disconnect between AI\u0026#39;s measured impact and its perceived benefits in the workplace. Already, organizations are moving beyond the gee-whiz period after ChatGPT\u0026#39;s introduction and into the implications of widespread use.\u003c/p\u003e\n\u003cdiv\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 40\"\u003e\u003cdefs\u003e\u003cclipPath id=\"arrow-blocks-right_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v40H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#arrow-blocks-right_svg__a)\"\u003e\u003cpath d=\"M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\n\n    \u003cp\u003e\u003cspan\u003eSam De Brouwer and Walter De Brouwer organized TED AI and selected the speakers.\u003c/span\u003e\n                    \u003cspan\u003e\n                      Benj Edwards\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n\n\u003cp\u003eDrawing from research claiming AI users complete tasks faster and more efficiently, Mollick highlighted a peculiar phenomenon: While one-third of Americans reported using AI in August of this year, managers often claim \u0026#34;no one\u0026#39;s using AI\u0026#34; in their organizations. Through a live demonstration using multiple AI models simultaneously, Mollick illustrated how traditional work patterns must evolve to accommodate AI\u0026#39;s capabilities. He also pointed to the emergence of what he calls \u0026#34;\u003ca href=\"https://arstechnica.com/information-technology/2024/08/chatgpt-hits-200-million-active-weekly-users-but-how-many-will-admit-using-it/\"\u003esecret cyborgs\u003c/a\u003e\u0026#34;—employees quietly using AI tools without management\u0026#39;s knowledge. Regarding the future of jobs in the age of AI, he urged organizations to view AI as an opportunity for expansion rather than merely a cost-cutting measure.\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eSome giants in the AI field made an appearance. Jakob Uszkoreit, one of the eight co-authors of the now-famous \u0026#34;Attention is All You Need\u0026#34; paper that introduced Transformer architecture, reflected on the field\u0026#39;s rapid evolution. He distanced himself from the term \u0026#34;artificial general intelligence,\u0026#34; suggesting people aren\u0026#39;t particularly general in their capabilities. Uszkoreit described how the development of Transformers sidestepped traditional scientific theory, comparing the field to alchemy. \u0026#34;We still do not know how human language works. We do not have a comprehensive theory of English,\u0026#34; he noted.\u003c/p\u003e\n\u003cdiv\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 40\"\u003e\u003cdefs\u003e\u003cclipPath id=\"arrow-blocks-right_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v40H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#arrow-blocks-right_svg__a)\"\u003e\u003cpath d=\"M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\n\n    \u003cp\u003e\u003cspan\u003eStanford professor Surya Ganguli presenting at TED AI 2024.\u003c/span\u003e\n                    \u003cspan\u003e\n                      Benj Edwards\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n\n\u003cp\u003eAnd refreshingly, the talks went beyond AI language models. For example, \u003ca href=\"https://www.isomorphiclabs.com/about-us\"\u003eIsomorphic Labs\u003c/a\u003e Chief AI Officer Max Jaderberg, who previously worked on Google DeepMind\u0026#39;s AlphaFold 3, gave a well-received presentation on AI-assisted drug discovery. He detailed how AlphaFold has already saved \u0026#34;1 billion years of research time\u0026#34; by discovering the shapes of proteins and showed how AI agents are now capable of running thousands of parallel drug design simulations that could enable personalized medicine.\u003c/p\u003e\n\n\u003ch2\u003eDanger and controversy\u003c/h2\u003e\n\u003cp\u003eWhile hype was less prominent this year, some speakers still spoke of AI-related dangers. Paul Scharre, executive vice president at the Center for a New American Security, warned about the risks of advanced AI models falling into malicious hands, specifically citing concerns about terrorist attacks with AI-engineered biological weapons. Drawing parallels to nuclear proliferation in the 1960s, Scharre argued that while regulating software is nearly impossible, controlling physical components like specialized chips and fabrication facilities could provide a practical framework for AI governance.\u003c/p\u003e\n\n\n\u003cp\u003eReplikaAI founder Eugenia Kuyda cautioned that AI companions could become \u0026#34;the most dangerous technology if not done right,\u0026#34; suggesting that the existential threat from AI might come not from science fiction scenarios but from technology that isolates us from human connections. She advocated for designing AI systems that optimize for human happiness rather than engagement, proposing a \u0026#34;human flourishing metric\u0026#34; to measure its success.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eBen Zhao, a University of Chicago professor associated with the \u003ca href=\"https://arstechnica.com/tech-policy/2024/07/glaze-a-tool-protecting-artists-from-ai-bypassed-by-attack-as-demand-spikes/\"\u003eGlaze\u003c/a\u003e and \u003ca href=\"https://arstechnica.com/information-technology/2023/10/university-of-chicago-researchers-seek-to-poison-ai-art-generators-with-nightshade/\"\u003eNightshade\u003c/a\u003e projects, painted a dire picture of AI\u0026#39;s impact on art, claiming that art schools were seeing unprecedented enrollment drops and galleries were closing at an accelerated rate due to AI image generators, though we have yet to dig through the supporting news headlines he momentarily flashed up on the screen.\u003c/p\u003e\n\u003cp\u003eSome of the speakers represented polar opposites of each other, policy-wise. For example, copyright attorney Angela Dunning offered a defense of AI training as fair use, drawing from historical parallels in technological advancement. A litigation partner at Cleary Gottlieb, which has \u003ca href=\"https://www.clearygottlieb.com/news-and-insights/publication-listing/significant-roadblocks-for-plaintiffs-in-generative-artificial-intelligence--lawsuit-california-judge-dismisses-most-claims-against-ai-developers-in-andersen-v-stability-ai\"\u003epreviously represented\u003c/a\u003e the AI image generation service Midjourney in a lawsuit, Dunning quoted Mark Twin \u003ca href=\"https://quoteinvestigator.com/2024/05/08/new-idea/\"\u003esaying\u003c/a\u003e \u0026#34;there is no such thing as a new idea\u0026#34; and argued that copyright law allows for building upon others\u0026#39; ideas while protecting specific expressions. She compared current AI debates to past technological disruptions, noting how photography, once feared as a threat to traditional artists, instead sparked new artistic movements like abstract art and pointillism. \u0026#34;Art and science can only remain free if we are free to build on the ideas of those that came before,\u0026#34; Dunning said, challenging more restrictive views of AI training.\u003c/p\u003e\n\u003cdiv\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 40\"\u003e\u003cdefs\u003e\u003cclipPath id=\"arrow-blocks-right_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v40H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#arrow-blocks-right_svg__a)\"\u003e\u003cpath d=\"M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\n\n    \u003cp\u003e\u003cspan\u003eCopyright lawyer Angela Dunning quoted Mark Twain in her talk about fair use and AI.\u003c/span\u003e\n                    \u003cspan\u003e\n                      Benj Edwards\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n\n\u003cp\u003eDunning\u0026#39;s presentation stood in direct opposition to Ed Newton-Rex, who had earlier advocated for mandatory licensing of training data through his nonprofit \u003ca href=\"https://www.fairlytrained.org/\"\u003eFairly Trained\u003c/a\u003e. In fact, the same day, Newton-Rex\u0026#39;s organization unveiled a \u0026#34;\u003ca href=\"https://www.aitrainingstatement.org/\"\u003eStatement on AI training\u003c/a\u003e\u0026#34; signed by many artists that says, \u0026#34;The unlicensed use of creative works for training generative AI is a major, unjust threat to the livelihoods of the people behind those works, and must not be permitted.\u0026#34; The issue has not yet been legally settled in US courts, but clearly, the battle lines have been drawn, and no matter which side you take, TED AI did a good job of giving both perspectives to the audience.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n\n        \n        \u003cdiv\u003e\n          \n          \n\u003ch2\u003eLooking forward\u003c/h2\u003e\n\u003cp\u003eSome speakers explored potential new architectures for AI. Stanford professor Surya Ganguli highlighted the contrast between AI and human learning, noting that while AI models require trillions of tokens to train, humans learn language from just millions of exposures. He proposed \u0026#34;quantum neuromorphic computing\u0026#34; as a potential bridge between biological and artificial systems, suggesting a future where computers could potentially match the energy efficiency of the human brain.\u003c/p\u003e\n\u003cp\u003eAlso, Guillaume Verdon, founder of Extropic and architect of the Effective Accelerationism (often called \u0026#34;E/Acc\u0026#34;) movement, presented what he called \u0026#34;physics-based intelligence\u0026#34; and claimed his company is \u0026#34;building a steam engine for AI,\u0026#34; potentially offering energy efficiency improvements up to 100 million times better than traditional systems—though he acknowledged this figure ignores cooling requirements for superconducting components. The company had completed its first room-temperature chip tape-out just the previous week.\u003c/p\u003e\n\n\n\u003cp\u003eThe Day One sessions closed out with predictions about the future of AI from OpenAI\u0026#39;s Noam Brown, who emphasized the importance of scale in expanding future AI capabilities, and University of Washington professor Pedro Domingos spoke about \u0026#34;co-intelligence,\u0026#34; saying, \u0026#34;People are smart, organizations are stupid\u0026#34; and proposing that AI could be used to bridge that gap by drawing on the collective intelligence of an organization.\u003c/p\u003e\n\u003cp\u003eWhen attended TED AI last year, some obvious questions emerged: Is this current wave of AI a fad? Will there be a TED AI next year? I think the second TED AI answered these questions well—AI isn\u0026#39;t going away, and there are still endless angles to explore as the field expands rapidly.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\n\n                  \n          \u003cdiv\u003e\n  \u003cdiv\u003e\n          \u003cp\u003e\u003ca href=\"https://arstechnica.com/author/benjedwards/\"\u003e\u003cimg src=\"https://arstechnica.com/wp-content/uploads/2022/08/benj_ega.png\" alt=\"Photo of Benj Edwards\"/\u003e\u003c/a\u003e\u003c/p\u003e\n  \u003c/div\u003e\n\n  \u003cdiv\u003e\n    \n\n    \u003cp\u003e\n      Benj Edwards is Ars Technica\u0026#39;s Senior AI Reporter and founder of the site\u0026#39;s dedicated AI beat in 2022. He\u0026#39;s also a widely-cited tech historian. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.\n    \u003c/p\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\n  \n\n\n  \n\n\n  \n              \u003c/div\u003e\n  \u003c/article\u003e\n\n\n\u003cdiv\u003e\n    \u003cheader\u003e\n      \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 26\"\u003e\u003cdefs\u003e\u003cclipPath id=\"most-read_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"most-read_svg__b\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#most-read_svg__a)\"\u003e\u003cg fill=\"none\" clip-path=\"url(#most-read_svg__b)\"\u003e\u003cpath fill=\"currentColor\" d=\"M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1\"\u003e\u003c/path\u003e\u003cpath fill=\"#ff4e00\" d=\"M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n      \n    \u003c/header\u003e\n    \u003col\u003e\n              \u003cli\u003e\n                      \u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/10/t-mobile-its-alive-768x432-1729188629.jpg\" alt=\"Listing image for first story in Most Read: “I am still alive”: Users say T-Mobile must pay for killing “lifetime” price lock\" decoding=\"async\" loading=\"lazy\"/\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                  \u003c/ol\u003e\n\u003c/div\u003e\n\n\n  \n\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2024-10-23T22:32:14Z",
  "modifiedTime": "2024-10-23T23:05:19Z"
}
