{
  "id": "defdc362-7731-4e51-bb12-32727d2f2353",
  "title": "AI search tools are confidently wrong a lot of the time, study finds",
  "link": "https://mashable.com/article/ai-search-wrong-a-lot-inacurracy-study",
  "description": "A new study tested how well AI tools identified sources. They performed really poorly.",
  "author": "",
  "published": "Sat, 15 Mar 2025 16:54:05 +0000",
  "source": "http://feeds.mashable.com/Mashable",
  "categories": null,
  "byline": "Tim Marcin",
  "length": 2768,
  "excerpt": "60 percent of queries got wrong answers.",
  "siteName": "Mashable",
  "favicon": "https://mashable.com/favicons/android-chrome-512x512.png",
  "text": "60 percent of queries got wrong answers. AI tools have an accuracy problem. Credit: Jakub Porzycki/NurPhoto via Getty Images AI search tools confidently spit out wrong answers at a high clip, a new study found. Columbia Journalism Review (CJR) conducted a study in which it fed eight AI tools an excerpt of an article and asked the chatbots to identify the \"corresponding article’s headline, original publisher, publication date, and URL.\" Collectively, the study noted that the chatbots \"provided incorrect answers to more than 60 percent of queries.\" The mistakes varied. Sometimes, the search tool reportedly speculated or offered incorrect answers to questions it couldn't answer. Sometimes, it invented links or sources. Sometimes, it cited plagiarized versions of the real article. Mashable Light Speed Wrote CJR: \"Most of the tools we tested presented inaccurate answers with alarming confidence, rarely using qualifying phrases such as 'it appears,' 'it’s possible,' 'might,' etc., or acknowledging knowledge gaps with statements like 'I couldn’t locate the exact article.'\"The full study is worth looking at, but it seems reasonable to be skeptical of AI search tools. The problem is that folks don't seem to be doing that. CJR noted that 25 percent of Americans said they use AI to search instead of traditional search engines. Google, the search giant, is increasingly pushing AI on consumers. This month, it announced it would be expanding AI overviews and began testing AI-only search results. The study from CJR is just another point of data showing the inaccuracy of AI. The tools have shown, time and again, that they'll confidently give wrong answers. And the tech giants are forcing AI into just about every product. So be careful what you believe out there. Tim Marcin is an Associate Editor on the culture team at Mashable, where he mostly digs into the weird parts of the internet. You'll also see some coverage of memes, tech, sports, and the occasional hot take. You can find him posting endlessly about Buffalo wings on the website formerly known as Twitter at @timmarcin. These newsletters may contain advertising, deals, or affiliate links. By clicking Subscribe, you confirm you are 16+ and agree to our Terms of Use and Privacy Policy.",
  "image": "https://helios-i.mashable.com/imagery/articles/049v5lBa3W6VPIWMe4fqzC3/hero-image.fill.size_1200x675.v1742057247.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n        \n\n    \n        \n    \u003cp\u003e60 percent of queries got wrong answers.\u003c/p\u003e\n    \n\n    \n\u003c/div\u003e\u003csection data-ga-module=\"content_body\"\u003e\n                        \u003cdiv\u003e\n                \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/049v5lBa3W6VPIWMe4fqzC3/hero-image.fill.size_1248x702.v1742057247.jpg\" alt=\"chatgpt typed into google search bar\" width=\"1248\" height=\"702\" srcset=\"https://helios-i.mashable.com/imagery/articles/049v5lBa3W6VPIWMe4fqzC3/hero-image.fill.size_400x225.v1742057247.jpg 400w, https://helios-i.mashable.com/imagery/articles/049v5lBa3W6VPIWMe4fqzC3/hero-image.fill.size_800x450.v1742057247.jpg 800w, https://helios-i.mashable.com/imagery/articles/049v5lBa3W6VPIWMe4fqzC3/hero-image.fill.size_1248x702.v1742057247.jpg 1600w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eAI tools have an accuracy problem.\u003c/span\u003e\n                \n                                    \u003cspan\u003eCredit: Jakub Porzycki/NurPhoto via Getty Images\u003c/span\u003e\n                            \u003c/p\u003e\n                        \u003c/div\u003e\n\n    \n    \n    \n            \u003carticle id=\"article\" data-autopogo=\"\"\u003e\n                                    \u003cp\u003eAI search tools confidently spit out wrong answers at a high clip, a new study found. \u003c/p\u003e\u003cp\u003eColumbia Journalism Review \u003ca href=\"https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\" title=\"(opens in a new window)\"\u003e(CJR) conducted a study in which it fed eight AI tools an excerpt of an article\u003c/a\u003e and asked the chatbots to identify the \u0026#34;corresponding article’s headline, original publisher, publication date, and URL.\u0026#34; Collectively, the study noted that the chatbots \u0026#34;provided incorrect answers to more than 60 percent of queries.\u0026#34; \u003c/p\u003e\n\u003cp\u003eThe mistakes varied. Sometimes, the search tool reportedly speculated or offered incorrect answers to questions it couldn\u0026#39;t answer. Sometimes, it invented links or sources. Sometimes, it cited plagiarized versions of the real article. \u003c/p\u003e\u003csection x-data=\"window.newsletter()\" x-init=\"init()\" data-ga-impression=\"\" data-ga-category=\"newsletters\" data-ga-module=\"incontent_nl_signup\" data-ga-label=\"mashablelightspeed\"\u003e\n        \u003cp\u003e\n            Mashable Light Speed\n        \u003c/p\u003e\n        \n        \n    \u003c/section\u003e\n\u003cp\u003eWrote CJR: \u0026#34;Most of the tools we tested presented inaccurate answers with alarming confidence, rarely using qualifying phrases such as \u0026#39;it appears,\u0026#39; \u0026#39;it’s possible,\u0026#39; \u0026#39;might,\u0026#39; etc., or acknowledging knowledge gaps with statements like \u0026#39;I couldn’t locate the exact article.\u0026#39;\u0026#34;\u003c/p\u003e\u003cp\u003eThe full study is worth looking at, but it seems reasonable to be skeptical of AI search tools. The problem is that folks don\u0026#39;t seem to be doing that. CJR noted that 25 percent of Americans said they use AI to search instead of traditional search engines. \u003c/p\u003e\u003cp\u003eGoogle, the search giant, is increasingly pushing AI on consumers. This month, it announced \u003ca href=\"https://mashable.com/article/google-ceo-sundar-pichai-isnt-afraid-of-the-ai-overviews-haters\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003eit would be expanding\u003c/a\u003e AI overviews and \u003ca href=\"https://mashable.com/article/google-testing-ai-only-search-results-expands-ai-overviews\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003ebegan testing AI-only search results\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eThe study from CJR is just another point of data showing the inaccuracy of AI. The \u003ca href=\"https://mashable.com/article/google-ai-super-bowl-commercial-hallucination-fix\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003etools have shown\u003c/a\u003e, \u003ca href=\"https://mashable.com/article/google-ai-search-memes-mistakes\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003etime and again\u003c/a\u003e, that \u003ca href=\"https://mashable.com/article/google-ai-overviews-at-6-months-are-they-better\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003ethey\u0026#39;ll confidently give wrong answers\u003c/a\u003e. And the tech giants \u003ca href=\"https://mashable.com/article/google-assistant-gone-gemini-ai-replacement\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003eare forcing\u003c/a\u003e \u003ca href=\"https://mashable.com/article/apple-intelligence-explained-what-is-it-ai\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003eAI into just about\u003c/a\u003e \u003ca href=\"https://mashable.com/article/my-week-with-generative-ai-review\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003eevery product\u003c/a\u003e. So be careful what you believe out there. \u003c/p\u003e\n\n                                        \n                    \u003c/article\u003e\n    \n    \n    \n            \u003cdiv\u003e\n            \u003cdiv\u003e\n                    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/authors/03Lp0IEBs8IXYimAPV3941z/image.fill.size_100x100.v1723813500.jpg\" alt=\"close-up of man\u0026#39;s face\" width=\"100\" height=\"100\" loading=\"lazy\"/\u003e\u003c/p\u003e\n                \u003c/div\u003e\n            \u003cp\u003eTim Marcin is an Associate Editor on the culture team at Mashable, where he mostly digs into the weird parts of the internet. You\u0026#39;ll also see some coverage of memes, tech, sports, and the occasional hot take. You can find him posting endlessly about Buffalo wings on the website formerly known as Twitter at @\u003ca href=\"https://twitter.com/TimMarcin\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\" target=\"_blank\" title=\"(opens in a new window)\"\u003etimmarcin\u003c/a\u003e.   \u003c/p\u003e\n        \u003c/div\u003e\n        \n        \n                    \u003c/section\u003e\u003cdiv x-data=\"window.newsletter()\" x-init=\"init()\" data-ga-impression=\"\" data-ga-category=\"newsletters\" data-ga-module=\"footer_nl_signup\" data-ga-label=\"Top Stories\"\u003e\n    \n\n    \u003cp\u003e\n        These newsletters may contain advertising, deals, or affiliate links. By clicking Subscribe, you confirm you are 16+ and agree to our \u003ca href=\"https://www.ziffdavis.com/terms-of-use\" target=\"_blank\" rel=\"noopener\" title=\"(opens in a new window)\"\u003eTerms of Use\u003c/a\u003e and \u003ca href=\"https://www.ziffdavis.com/ztg-privacy-policy\" target=\"_blank\" rel=\"noopener\" title=\"(opens in a new window)\"\u003ePrivacy Policy\u003c/a\u003e.\n    \u003c/p\u003e\n    \n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-03-15T16:54:05Z",
  "modifiedTime": "2025-03-15T16:54:21Z"
}
