{
  "id": "b3c455fc-61cf-45d0-bf6f-aa9fb9f59fb8",
  "title": "OpenAI Bans Chinese Accounts Using ChatGPT To Edit Code For Social Media Surveillance",
  "link": "https://tech.slashdot.org/story/25/02/21/2356205/openai-bans-chinese-accounts-using-chatgpt-to-edit-code-for-social-media-surveillance?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "OpenAI has banned a group of Chinese accounts using ChatGPT to develop an AI-powered social media surveillance tool. Engadget reports: The campaign, which OpenAI calls Peer Review, saw the group prompt ChatGPT to generate sales pitches for a program those documents suggest was designed to monitor anti-Chinese sentiment on X, Facebook, YouTube, Instagram and other platforms. The operation appears to have been particularly interested in spotting calls for protests against human rights violations in China, with the intent of sharing those insights with the country's authorities. \"This network consisted of ChatGPT accounts that operated in a time pattern consistent with mainland Chinese business hours, prompted our models in Chinese, and used our tools with a volume and variety consistent with manual prompting, rather than automation,\" said OpenAI. \"The operators used our models to proofread claims that their insights had been sent to Chinese embassies abroad, and to intelligence agents monitoring protests in countries including the United States, Germany and the United Kingdom.\" According to Ben Nimmo, a principal investigator with OpenAI, this was the first time the company had uncovered an AI tool of this kind. \"Threat actors sometimes give us a glimpse of what they are doing in other parts of the internet because of the way they use our AI models,\" Nimmo told The New York Times. Much of the code for the surveillance tool appears to have been based on an open-source version of one of Meta's Llama models. The group also appears to have used ChatGPT to generate an end-of-year performance review where it claims to have written phishing emails on behalf of clients in China. Read more of this story at Slashdot.",
  "author": "BeauHD",
  "published": "2025-02-22T00:10:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "china"
  ],
  "byline": "",
  "length": 1702,
  "excerpt": "OpenAI has banned a group of Chinese accounts using ChatGPT to develop an AI-powered social media surveillance tool. Engadget reports: The campaign, which OpenAI calls Peer Review, saw the group prompt ChatGPT to generate sales pitches for a program those documents suggest was designed to monitor a...",
  "siteName": "",
  "favicon": "",
  "text": "OpenAI has banned a group of Chinese accounts using ChatGPT to develop an AI-powered social media surveillance tool. Engadget reports: The campaign, which OpenAI calls Peer Review, saw the group prompt ChatGPT to generate sales pitches for a program those documents suggest was designed to monitor anti-Chinese sentiment on X, Facebook, YouTube, Instagram and other platforms. The operation appears to have been particularly interested in spotting calls for protests against human rights violations in China, with the intent of sharing those insights with the country's authorities. \"This network consisted of ChatGPT accounts that operated in a time pattern consistent with mainland Chinese business hours, prompted our models in Chinese, and used our tools with a volume and variety consistent with manual prompting, rather than automation,\" said OpenAI. \"The operators used our models to proofread claims that their insights had been sent to Chinese embassies abroad, and to intelligence agents monitoring protests in countries including the United States, Germany and the United Kingdom.\" According to Ben Nimmo, a principal investigator with OpenAI, this was the first time the company had uncovered an AI tool of this kind. \"Threat actors sometimes give us a glimpse of what they are doing in other parts of the internet because of the way they use our AI models,\" Nimmo told The New York Times. Much of the code for the surveillance tool appears to have been based on an open-source version of one of Meta's Llama models. The group also appears to have used ChatGPT to generate an end-of-year performance review where it claims to have written phishing emails on behalf of clients in China.",
  "image": "https://a.fsdn.com/sd/topics/china_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-176334621\"\u003e\n\t\n\t\t\n\t\n\n\t\n\t\t\n\t\t\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tOpenAI has \u003ca href=\"https://openai.com/global-affairs/disrupting-malicious-uses-of-ai/\"\u003ebanned\u003c/a\u003e a group of Chinese accounts \u003ca href=\"https://www.engadget.com/ai/openai-bans-chinese-accounts-using-chatgpt-to-edit-code-for-social-media-surveillance-230451036.html\"\u003eusing ChatGPT to develop an AI-powered social media surveillance tool\u003c/a\u003e. Engadget reports: \u003ci\u003e The campaign, which OpenAI calls Peer Review, saw the group prompt ChatGPT to generate sales pitches for a program those documents suggest was designed to monitor anti-Chinese sentiment on X, Facebook, YouTube, Instagram and other platforms. The operation appears to have been particularly interested in spotting calls for protests against human rights violations in China, with the intent of sharing those insights with the country\u0026#39;s authorities.\n\u003cp\u003e \n\u0026#34;This network consisted of ChatGPT accounts that operated in a time pattern consistent with mainland Chinese business hours, prompted our models in Chinese, and used our tools with a volume and variety consistent with manual prompting, rather than automation,\u0026#34; said OpenAI. \u0026#34;The operators used our models to proofread claims that their insights had been sent to Chinese embassies abroad, and to intelligence agents monitoring protests in countries including the United States, Germany and the United Kingdom.\u0026#34;\n\u003c/p\u003e\u003cp\u003e \nAccording to Ben Nimmo, a principal investigator with OpenAI, this was the first time the company had uncovered an AI tool of this kind. \u0026#34;Threat actors sometimes give us a glimpse of what they are doing in other parts of the internet because of the way they use our AI models,\u0026#34; Nimmo \u003ca href=\"https://www.nytimes.com/2025/02/21/technology/openai-chinese-surveillance.html\"\u003etold The New York Times\u003c/a\u003e. Much of the code for the surveillance tool appears to have been based on an open-source version of one of Meta\u0026#39;s Llama models. The group also appears to have used ChatGPT to generate an end-of-year performance review where it claims to have written phishing emails on behalf of clients in China.\u003c/p\u003e\u003c/i\u003e\u003cbr/\u003e\n\t\t \t\n\t\t\u003c/p\u003e\n\n\t\t\n\n\t\t\n\n\t\t\n\t\t\t\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
