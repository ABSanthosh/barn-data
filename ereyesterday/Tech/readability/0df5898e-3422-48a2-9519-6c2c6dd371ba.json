{
  "id": "0df5898e-3422-48a2-9519-6c2c6dd371ba",
  "title": "Researchers secretly experimented on Reddit users with AI-generated comments",
  "link": "https://www.engadget.com/ai/researchers-secretly-experimented-on-reddit-users-with-ai-generated-comments-194328026.html?src=rss",
  "description": "A group of researchers covertly ran a months-long \"unauthorized\" experiment in one of Reddit’s most popular communities using AI-generated comments to test the persuasiveness of large language models. The experiment, which was revealed over the weekend by moderators of r/changemyview, is described by Reddit mods as “psychological manipulation” of unsuspecting users. “The CMV Mod Team needs to inform the CMV community about an unauthorized experiment conducted by researchers from the University of Zurich on CMV users,” the subreddit’s moderators wrote in a lengthy post notifying Redditors about the research. “This experiment deployed AI-generated comments to study how AI could be used to change views.” The researchers used LLMs to create comments in response to posts on r/changemyview, a subreddit where Reddit users post (often controversial or provocative) opinions and request debate from other users. The community has 3.8 million members and often ends up on the front page of Reddit. According to the subreddit’s moderators, the AI took on numerous different identities in comments during the course of the experiment, including a sexual assault survivor, a trauma counselor “specializing in abuse,” and a “Black man opposed to Black Lives Matter.” Many of the original comments have since been deleted, but some can still be viewed in an archive created by 404 Media. In a draft of their paper, the unnamed researchers describe how they not only used AI to generate responses, but attempted to personalize its replies based on information gleaned from the original poster’s prior Reddit history. “In addition to the post’s content, LLMs were provided with personal attributes of the OP (gender, age, ethnicity, location, and political orientation), as inferred from their posting history using another LLM,” they write. The r/chnagemyview moderators note that the researchers’ violated multiple subreddit rules, including a policy requiring the disclosure when AI is used to generate comment and a rule prohibiting bots. They say they filed an official complaint with the University of Zurich and have requested the researchers withhold publication of their paper. Reddit also appears to be considering some kind of legal action. Chief Legal Officer Ben Lee responded to the controversy on Monday, writing that the researchers' actions were \"deeply wrong on both a moral and legal level\" and a violation of Reddit's site-wide rules. We have banned all accounts associated with the University of Zurich research effort. Additionally, while we were able to detect many of these fake accounts, we will continue to strengthen our inauthentic content detection capabilities, and we have been in touch with the moderation team to ensure we’ve removed any AI-generated content associated with this research. We are in the process of reaching out to the University of Zurich and this particular research team with formal legal demands. We want to do everything we can to support the community and ensure that the researchers are held accountable for their misdeeds here. In an email, the University of Zurich researchers directed Engadget to the university's media relations department, which didn't immediately respond to questions. In posts on Reddit and in a draft of their paper, the researchers said their research had been approved by a university ethics committee and that their work could help online communities like Reddit protect users from more “malicious” uses of AI.  “We acknowledge the moderators’ position that this study was an unwelcome intrusion in your community, and we understand that some of you may feel uncomfortable that this experiment was conducted without prior consent,” the researchers wrote in a comment responding to the r/changemyview mods. “We believe the potential benefits of this research substantially outweigh its risks. Our controlled, low-risk study provided valuable insight into the real-world persuasive capabilities of LLMs—capabilities that are already easily accessible to anyone and that malicious actors could already exploit at scale for far more dangerous reasons (e.g., manipulating elections or inciting hateful speech).” The mods for r/changemyview dispute that the research was necessary or novel, noting that OpenAI researchers have conducted experiments using data from r/changemyview “without experimenting on non-consenting human subjects.”  “People do not come here to discuss their views with AI or to be experimented upon,” the moderators wrote. “People who visit our sub deserve a space free from this type of intrusion.” Update, April 28, 2025, 3:45PM PT: This post was updated to add details from a statement by Reddit's Chief Legal Officer.This article originally appeared on Engadget at https://www.engadget.com/ai/researchers-secretly-experimented-on-reddit-users-with-ai-generated-comments-194328026.html?src=rss",
  "author": "Karissa Bell",
  "published": "Mon, 28 Apr 2025 22:45:04 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Social \u0026 Online Media",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Karissa Bell"
  ],
  "byline": "Karissa Bell",
  "length": 4703,
  "excerpt": "Researchers ran an unsanctioned experiment using AI in Reddit's r/changemyview that its mioderators are calling \"psychological manipulation.\"",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "A group of researchers covertly ran a months-long \"unauthorized\" experiment in one of Reddit’s most popular communities using AI-generated comments to test the persuasiveness of large language models. The experiment, which was revealed over the weekend by moderators of r/changemyview, is described by Reddit mods as “psychological manipulation” of unsuspecting users.“The CMV Mod Team needs to inform the CMV community about an unauthorized experiment conducted by researchers from the University of Zurich on CMV users,” the subreddit’s moderators wrote in a lengthy post notifying Redditors about the research. “This experiment deployed AI-generated comments to study how AI could be used to change views.”The researchers used LLMs to create comments in response to posts on r/changemyview, a subreddit where Reddit users post (often controversial or provocative) opinions and request debate from other users. The community has 3.8 million members and often ends up on the front page of Reddit. According to the subreddit’s moderators, the AI took on numerous different identities in comments during the course of the experiment, including a sexual assault survivor, a trauma counselor “specializing in abuse,” and a “Black man opposed to Black Lives Matter.” Many of the original comments have since been deleted, but some can still be viewed in an archive created by 404 Media.In a draft of their paper, the unnamed researchers describe how they not only used AI to generate responses, but attempted to personalize its replies based on information gleaned from the original poster’s prior Reddit history. “In addition to the post’s content, LLMs were provided with personal attributes of the OP (gender, age, ethnicity, location, and political orientation), as inferred from their posting history using another LLM,” they write.The r/chnagemyview moderators note that the researchers’ violated multiple subreddit rules, including a policy requiring the disclosure when AI is used to generate comment and a rule prohibiting bots. They say they filed an official complaint with the University of Zurich and have requested the researchers withhold publication of their paper.Reddit also appears to be considering some kind of legal action. Chief Legal Officer Ben Lee responded to the controversy on Monday, writing that the researchers' actions were \"deeply wrong on both a moral and legal level\" and a violation of Reddit's site-wide rules.We have banned all accounts associated with the University of Zurich research effort. Additionally, while we were able to detect many of these fake accounts, we will continue to strengthen our inauthentic content detection capabilities, and we have been in touch with the moderation team to ensure we’ve removed any AI-generated content associated with this research.We are in the process of reaching out to the University of Zurich and this particular research team with formal legal demands. We want to do everything we can to support the community and ensure that the researchers are held accountable for their misdeeds here.In an email, the University of Zurich researchers directed Engadget to the university's media relations department, which didn't immediately respond to questions. In posts on Reddit and in a draft of their paper, the researchers said their research had been approved by a university ethics committee and that their work could help online communities like Reddit protect users from more “malicious” uses of AI.“We acknowledge the moderators’ position that this study was an unwelcome intrusion in your community, and we understand that some of you may feel uncomfortable that this experiment was conducted without prior consent,” the researchers wrote in a comment responding to the r/changemyview mods. “We believe the potential benefits of this research substantially outweigh its risks. Our controlled, low-risk study provided valuable insight into the real-world persuasive capabilities of LLMs—capabilities that are already easily accessible to anyone and that malicious actors could already exploit at scale for far more dangerous reasons (e.g., manipulating elections or inciting hateful speech).”The mods for r/changemyview dispute that the research was necessary or novel, noting that OpenAI researchers have conducted experiments using data from r/changemyview “without experimenting on non-consenting human subjects.”“People do not come here to discuss their views with AI or to be experimented upon,” the moderators wrote. “People who visit our sub deserve a space free from this type of intrusion.”Update, April 28, 2025, 3:45PM PT: This post was updated to add details from a statement by Reddit's Chief Legal Officer.",
  "image": "https://s.yimg.com/ny/api/res/1.2/FAPTYkEhZSCITjZsDNcjQg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2025-03/e4770360-0413-11f0-9fb7-3b35e2f51b56",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eA group of researchers covertly ran a months-long \u0026#34;unauthorized\u0026#34; experiment in one of Reddit’s most popular communities using AI-generated comments to test the persuasiveness of large language models. The experiment, which \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1\" href=\"https://www.reddit.com/r/changemyview/comments/1k8b2hj/meta_unauthorized_experiment_on_cmv_involving/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:was revealed;elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1;itc:0;sec:content-canvas\"\u003ewas revealed\u003c/a\u003e over the weekend by moderators of r/changemyview, is described by Reddit mods as “psychological manipulation” of unsuspecting users.\u003c/p\u003e\u003cp\u003e“The CMV Mod Team needs to inform the CMV community about an unauthorized experiment conducted by researchers from the University of Zurich on CMV users,” the subreddit’s moderators wrote in a lengthy post notifying Redditors about the research. “This experiment deployed AI-generated comments to study how AI could be used to change views.”\u003c/p\u003e\u003cp\u003eThe researchers used LLMs to create comments in response to posts on r/changemyview, a subreddit where Reddit users post (often controversial or provocative) opinions and request debate from other users. The community has 3.8 million members and often ends up on the front page of Reddit. According to the subreddit’s moderators, the AI took on numerous different identities in comments during the course of the experiment, including a sexual assault survivor, a trauma counselor “specializing in abuse,” and a “Black man opposed to Black Lives Matter.” Many of the original comments have since been deleted, but some can still be viewed in \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1\" href=\"https://embed.documentcloud.org/projects/221375-redditbot-research/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:an archive;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas\"\u003ean archive\u003c/a\u003e created by \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1\" href=\"https://www.404media.co/researchers-secretly-ran-a-massive-unauthorized-ai-persuasion-experiment-on-reddit-users/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:404 Media;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas\"\u003e\u003cem\u003e404 Media\u003c/em\u003e\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIn \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1\" href=\"https://drive.google.com/file/d/1Eo4SHrKGPErTzL1t_QmQhfZGU27jKBjx/view\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:a draft;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas\"\u003ea draft\u003c/a\u003e of their paper, the unnamed researchers describe how they not only used AI to generate responses, but attempted to personalize its replies based on information gleaned from the original poster’s prior Reddit history. “In addition to the post’s content, LLMs were provided with personal attributes of the OP (gender, age, ethnicity, location, and political orientation), as inferred from their posting history using another LLM,” they write.\u003c/p\u003e\u003cp\u003eThe r/chnagemyview moderators note that the researchers’ violated multiple subreddit rules, including a policy requiring the disclosure when AI is used to generate comment and a rule prohibiting bots. They say they filed an official complaint with the University of Zurich and have requested the researchers withhold publication of their paper.\u003c/p\u003e\u003cp\u003eReddit also appears to be considering some kind of legal action. Chief Legal Officer Ben Lee\u003ca data-i13n=\"cpos:5;pos:1\" href=\"https://www.reddit.com/r/changemyview/comments/1k8b2hj/comment/mpk1u3c/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:responded;cpos:5;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003e responded\u003c/a\u003e to the controversy on Monday, writing that the researchers\u0026#39; actions were \u0026#34;deeply wrong on both a moral and legal level\u0026#34; and a violation of Reddit\u0026#39;s site-wide rules.\u003c/p\u003e\u003cdiv data-src=\"\"\u003e\u003cblockquote\u003e\u003cp\u003eWe have banned all accounts associated with the University of Zurich research effort. Additionally, while we were able to detect many of these fake accounts, we will continue to strengthen our inauthentic content detection capabilities, and we have been in touch with the moderation team to ensure we’ve removed any AI-generated content associated with this research.\u003c/p\u003e\u003c/blockquote\u003e\u003c/div\u003e\u003cdiv data-src=\"\"\u003e\u003cblockquote\u003e\u003cp\u003eWe are in the process of reaching out to the University of Zurich and this particular research team with formal legal demands. We want to do everything we can to support the community and ensure that the researchers are held accountable for their misdeeds here.\u003c/p\u003e\u003c/blockquote\u003e\u003c/div\u003e\u003cp\u003eIn an email, the University of Zurich researchers directed Engadget to the university\u0026#39;s media relations department, which didn\u0026#39;t immediately respond to questions. In posts on Reddit and in a draft of their paper, the researchers said their research had been approved by a university ethics committee and that their work could help online communities like Reddit protect users from more “malicious” uses of AI.\u003c/p\u003e\u003cp\u003e“We acknowledge the moderators’ position that this study was an unwelcome intrusion in your community, and we understand that some of you may feel uncomfortable that this experiment was conducted without prior consent,” the researchers wrote in \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1\" href=\"https://www.reddit.com/r/changemyview/comments/1k8b2hj/comment/mp4vgcm/?context=3\u0026amp;share_id=CrWzop477uqjtCq0ZKcxm\u0026amp;utm_content=1\u0026amp;utm_medium=ios_app\u0026amp;utm_name=ioscss\u0026amp;utm_source=share\u0026amp;utm_term=1\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:a comment;elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1;itc:0;sec:content-canvas\"\u003ea comment\u003c/a\u003e responding to the r/changemyview mods. “We believe the potential benefits of this research substantially outweigh its risks. Our controlled, low-risk study provided valuable insight into the real-world persuasive capabilities of LLMs—capabilities that are already easily accessible to anyone and that malicious actors could already exploit at scale for far more dangerous reasons (e.g., manipulating elections or inciting hateful speech).”\u003c/p\u003e\u003cp\u003eThe mods for r/changemyview dispute that the research was necessary or novel, noting that OpenAI researchers have conducted experiments using data from r/changemyview “without experimenting on non-consenting human subjects.”\u003c/p\u003e\u003cp\u003e“People do not come here to discuss their views with AI or to be experimented upon,” the moderators wrote. “People who visit our sub deserve a space free from this type of intrusion.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUpdate, April 28, 2025, 3:45PM PT: \u003c/strong\u003eThis post was updated to add details from a statement by Reddit\u0026#39;s Chief Legal Officer.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-04-28T22:45:04Z",
  "modifiedTime": null
}
