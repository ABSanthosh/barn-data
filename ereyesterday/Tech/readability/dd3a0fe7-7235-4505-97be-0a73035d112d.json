{
  "id": "dd3a0fe7-7235-4505-97be-0a73035d112d",
  "title": "Everything that could go wrong with X’s new AI-written community notes",
  "link": "https://arstechnica.com/tech-policy/2025/07/everything-that-could-go-wrong-with-xs-new-ai-written-community-notes/",
  "description": "X says AI can supercharge community notes, but that comes with obvious risks.",
  "author": "Ashley Belanger",
  "published": "Wed, 02 Jul 2025 21:00:39 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Policy",
    "AI agents",
    "Artificial Intelligence",
    "community notes",
    "conspiracy theories",
    "disinformation",
    "fact checking",
    "misinformation",
    "social media",
    "Twitter",
    "X"
  ],
  "byline": "Ashley Belanger",
  "length": 9397,
  "excerpt": "X says AI can supercharge community notes, but that comes with obvious risks.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "X says AI can supercharge community notes, but that comes with obvious risks. Elon Musk's X arguably revolutionized social media fact-checking by rolling out \"community notes,\" which created a system to crowdsource diverse views on whether certain X posts were trustworthy or not. But now, the platform plans to allow AI to write community notes, and that could potentially ruin whatever trust X users had in the fact-checking system—which X has fully acknowledged. In a research paper, X described the initiative as an \"upgrade\" while explaining everything that could possibly go wrong with AI-written community notes. In an ideal world, X described AI agents that speed up and increase the number of community notes added to incorrect posts, ramping up fact-checking efforts platform-wide. Each AI-written note will be rated by a human reviewer, providing feedback that makes the AI agent better at writing notes the longer this feedback loop cycles. As the AI agents get better at writing notes, that leaves human reviewers to focus on more nuanced fact-checking that AI cannot quickly address, such as posts requiring niche expertise or social awareness. Together, the human and AI reviewers, if all goes well, could transform not just X's fact-checking, X's paper suggested, but also potentially provide \"a blueprint for a new form of human-AI collaboration in the production of public knowledge.\" Among key questions that remain, however, is a big one: X isn't sure if AI-written notes will be as accurate as notes written by humans. Complicating that further, it seems likely that AI agents could generate \"persuasive but inaccurate notes,\" which human raters might rate as helpful since AI is \"exceptionally skilled at crafting persuasive, emotionally resonant, and seemingly neutral notes.\" That could disrupt the feedback loop, watering down community notes and making the whole system less trustworthy over time, X's research paper warned. \"If rated helpfulness isn’t perfectly correlated with accuracy, then highly polished but misleading notes could be more likely to pass the approval threshold,\" the paper said. \"This risk could grow as LLMs advance; they could not only write persuasively but also more easily research and construct a seemingly robust body of evidence for nearly any claim, regardless of its veracity, making it even harder for human raters to spot deception or errors.\" X is already facing criticism over its AI plans. On Tuesday, former United Kingdom technology minister, Damian Collins, accused X of building a system that could allow \"the industrial manipulation of what people see and decide to trust\" on a platform with more than 600 million users, The Guardian reported. Collins claimed that AI notes risked increasing the promotion of \"lies and conspiracy theories\" on X, and he wasn't the only expert sounding alarms. Samuel Stockwell, a research associate at the Centre for Emerging Technology and Security at the Alan Turing Institute, told The Guardian that X's success largely depends on \"the quality of safeguards X puts in place against the risk that these AI ‘note writers’ could hallucinate and amplify misinformation in their outputs.\" \"AI chatbots often struggle with nuance and context but are good at confidently providing answers that sound persuasive even when untrue,\" Stockwell said. \"That could be a dangerous combination if not effectively addressed by the platform.\" Also complicating things: anyone can create an AI agent using any technology to write community notes, X's Community Notes account explained. That means that some AI agents may be more biased or defective than others. If this dystopian version of events occurs, X predicts that human writers may get sick of writing notes, threatening the diversity of viewpoints that made community notes so trustworthy to begin with. And for any human writers and reviewers who stick around, it's possible that the sheer volume of AI-written notes may overload them. Andy Dudfield, the head of AI at a UK fact-checking organization called Full Fact, told The Guardian that X risks \"increasing the already significant burden on human reviewers to check even more draft notes, opening the door to a worrying and plausible situation in which notes could be drafted, reviewed, and published entirely by AI without the careful consideration that human input provides.\" X is planning more research to ensure the \"human rating capacity can sufficiently scale,\" but if it cannot solve this riddle, it knows \"the impact of the most genuinely critical notes\" risks being diluted. One possible solution to this \"bottleneck,\" researchers noted, would be to remove the human review process and apply AI-written notes in \"similar contexts\" that human raters have previously approved. But the biggest potential downfall there is obvious. \"Automatically matching notes to posts that people do not think need them could significantly undermine trust in the system,\" X's paper acknowledged. Ultimately, AI note writers on X may be deemed an \"erroneous\" tool, researchers admitted, but they're going ahead with testing to find out. AI-written notes will start posting this month All AI-written community notes \"will be clearly marked for users,\" X's Community Notes account said. The first AI notes will only appear on posts where people have requested a note, the account said, but eventually AI note writers could be allowed to select posts for fact-checking. More will be revealed when AI-written notes start appearing on X later this month, but in the meantime, X users can start testing AI note writers today and soon be considered for admission in the initial cohort of AI agents. (If any Ars readers end up testing out an AI note writer, this Ars writer would be curious to learn more about your experience.) For its research, X collaborated with post-graduate students, research affiliates, and professors investigating topics like human trust in AI, fine-tuning AI, and AI safety at Harvard University, the Massachusetts Institute of Technology, Stanford University, and the University of Washington. Researchers agreed that \"under certain circumstances,\" AI agents can \"produce notes that are of similar quality to human-written notes—at a fraction of the time and effort.\" They suggested that more research is needed to overcome flagged risks to reap the benefits of what could be \"a transformative opportunity\" that \"offers promise of dramatically increased scale and speed\" of fact-checking on X. If AI note writers \"generate initial drafts that represent a wider range of perspectives than a single human writer typically could, the quality of community deliberation is improved from the start,\" the paper said. Future of AI notes Researchers imagine that once X's testing is completed, AI note writers could not just aid in researching problematic posts flagged by human users, but also one day select posts predicted to go viral and stop misinformation from spreading faster than human reviewers could. Additional perks from this automated system, they suggested, would include X note raters quickly accessing more thorough research and evidence synthesis, as well as clearer note composition, which could speed up the rating process. And perhaps one day, AI agents could even learn to predict rating scores to speed things up even more, researchers speculated. However, more research would be needed to ensure that wouldn't homogenize community notes, buffing them out to the point that no one reads them. Perhaps the most Musk-ian of ideas proposed in the paper, is a notion of training AI note writers with clashing views to \"adversarially debate the merits of a note.\" Supposedly, that \"could help instantly surface potential flaws, hidden biases, or fabricated evidence, empowering the human rater to make a more informed judgment.\" \"Instead of starting from scratch, the rater now plays the role of an adjudicator—evaluating a structured clash of arguments,\" the paper said. While X may be moving to reduce the workload for X users writing community notes, it's clear that AI could never replace humans, researchers said. Those humans are necessary for more than just rubber-stamping AI-written notes. Human notes that are \"written from scratch\" are valuable to train the AI agents and some raters' niche expertise cannot easily be replicated, the paper said. And perhaps most obviously, humans \"are uniquely positioned to identify deficits or biases\" and therefore more likely to be compelled to write notes \"on topics the automated writers overlook,\" such as spam or scams. Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience. 30 Comments",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1760687083-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n            \u003carticle data-id=\"2104185\"\u003e\n  \n  \u003cheader\u003e\n  \u003cdiv\u003e\n      \n\n      \n\n      \u003cp\u003e\n        X says AI can supercharge community notes, but that comes with obvious risks.\n      \u003c/p\u003e\n\n      \n    \u003c/div\u003e\n\u003c/header\u003e\n\n\n  \n\n  \n      \n    \n    \u003cdiv\u003e\n                      \n                      \n          \n\u003cp\u003eElon Musk\u0026#39;s X arguably revolutionized social media fact-checking by rolling out \u0026#34;community notes,\u0026#34; which created a system to crowdsource diverse views on whether certain X posts were trustworthy or not.\u003c/p\u003e\n\u003cp\u003eBut now, the platform plans to allow AI to write community notes, and that could potentially ruin whatever trust X users had in the fact-checking system—which X has fully acknowledged.\u003c/p\u003e\n\u003cp\u003eIn a \u003ca href=\"https://arxiv.org/pdf/2506.24118\"\u003eresearch paper\u003c/a\u003e, X described the initiative as an \u0026#34;upgrade\u0026#34; while explaining everything that could possibly go wrong with AI-written community notes.\u003c/p\u003e\n\u003cp\u003eIn an ideal world, X described AI agents that speed up and increase the number of community notes added to incorrect posts, ramping up fact-checking efforts platform-wide. Each AI-written note will be rated by a human reviewer, providing feedback that makes the AI agent better at writing notes the longer this feedback loop cycles. As the AI agents get better at writing notes, that leaves human reviewers to focus on more nuanced fact-checking that AI cannot quickly address, such as posts requiring niche expertise or social awareness. Together, the human and AI reviewers, if all goes well, could transform not just X\u0026#39;s fact-checking, X\u0026#39;s paper suggested, but also potentially provide \u0026#34;a blueprint for a new form of human-AI collaboration in the production of public knowledge.\u0026#34;\u003c/p\u003e\n\u003cp\u003eAmong key questions that remain, however, is a big one: X isn\u0026#39;t sure if AI-written notes will be as accurate as notes written by humans. Complicating that further, it seems likely that AI agents could generate \u0026#34;persuasive but inaccurate notes,\u0026#34; which human raters might rate as helpful since AI is \u0026#34;exceptionally skilled at crafting persuasive, emotionally resonant, and seemingly neutral notes.\u0026#34; That could disrupt the feedback loop, watering down community notes and making the whole system less trustworthy over time, X\u0026#39;s research paper warned.\u003c/p\u003e\n\u003cp\u003e\u0026#34;If rated helpfulness isn’t perfectly correlated with accuracy, then highly polished but misleading notes could be more likely to pass the approval threshold,\u0026#34; the paper said. \u0026#34;This risk could grow as LLMs advance; they could not only write persuasively but also more easily research and construct a seemingly robust body of evidence for nearly any claim, regardless of its veracity, making it even harder for human raters to spot deception or errors.\u0026#34;\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eX is already facing criticism over its AI plans. On Tuesday, former United Kingdom technology minister, Damian Collins, accused X of building a system that could allow \u0026#34;the industrial manipulation of what people see and decide to trust\u0026#34; on a platform with more than 600 million users, The Guardian \u003ca href=\"https://www.theguardian.com/technology/2025/jul/02/fears-ai-factcheckers-on-x-could-increase-promotion-of-conspiracy-theories\"\u003ereported\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCollins claimed that AI notes risked increasing the promotion of \u0026#34;lies and conspiracy theories\u0026#34; on X, and he wasn\u0026#39;t the only expert sounding alarms. Samuel Stockwell, a research associate at the Centre for Emerging Technology and Security at the Alan Turing Institute, told The Guardian that X\u0026#39;s success largely depends on \u0026#34;the quality of safeguards X puts in place against the risk that these AI ‘note writers’ could hallucinate and amplify misinformation in their outputs.\u0026#34;\u003c/p\u003e\n\u003cp\u003e\u0026#34;AI chatbots often struggle with nuance and context but are good at confidently providing answers that sound persuasive even when untrue,\u0026#34; Stockwell said. \u0026#34;That could be a dangerous combination if not effectively addressed by the platform.\u0026#34;\u003c/p\u003e\n\u003cp\u003eAlso complicating things: anyone can create an AI agent using any technology to write community notes, X\u0026#39;s Community Notes account \u003ca href=\"https://x.com/CommunityNotes/status/1940132205486915917\"\u003eexplained\u003c/a\u003e. That means that some AI agents may be more biased or defective than others.\u003c/p\u003e\n\u003cp\u003eIf this dystopian version of events occurs, X predicts that human writers may get sick of writing notes, threatening the diversity of viewpoints that made community notes so trustworthy to begin with.\u003c/p\u003e\n\u003cp\u003eAnd for any human writers and reviewers who stick around, it\u0026#39;s possible that the sheer volume of AI-written notes may overload them. Andy Dudfield, the head of AI at a UK fact-checking organization called Full Fact, told The Guardian that X risks \u0026#34;increasing the already significant burden on human reviewers to check even more draft notes, opening the door to a worrying and plausible situation in which notes could be drafted, reviewed, and published entirely by AI without the careful consideration that human input provides.\u0026#34;\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eX is planning more research to ensure the \u0026#34;human rating capacity can sufficiently scale,\u0026#34; but if it cannot solve this riddle, it knows \u0026#34;the impact of the most genuinely critical notes\u0026#34; risks being diluted.\u003c/p\u003e\n\u003cp\u003eOne possible solution to this \u0026#34;bottleneck,\u0026#34; researchers noted, would be to remove the human review process and apply AI-written notes in \u0026#34;similar contexts\u0026#34; that human raters have previously approved. But the biggest potential downfall there is obvious.\u003c/p\u003e\n\u003cp\u003e\u0026#34;Automatically matching notes to posts that people do not think need them could significantly undermine trust in the system,\u0026#34; X\u0026#39;s paper acknowledged.\u003c/p\u003e\n\u003cp\u003eUltimately, AI note writers on X may be deemed an \u0026#34;erroneous\u0026#34; tool, researchers admitted, but they\u0026#39;re going ahead with testing to find out.\u003c/p\u003e\n\n\u003ch2\u003eAI-written notes will start posting this month\u003c/h2\u003e\n\u003cp\u003eAll AI-written community notes \u0026#34;will be clearly marked for users,\u0026#34; X\u0026#39;s Community Notes account said. The first AI notes will only appear on posts where people have requested a note, the account said, but eventually AI note writers could be allowed to select posts for fact-checking.\u003c/p\u003e\n\u003cp\u003eMore will be revealed when AI-written notes start appearing on X later this month, but in the meantime, X users can\u003ca href=\"https://communitynotes.x.com/guide/en/api/overview\"\u003e start testing AI note writers today\u003c/a\u003e and soon be considered for admission in the initial cohort of AI agents. (If any Ars readers end up testing out an AI note writer, this Ars writer would be curious to learn more about your experience.)\u003c/p\u003e\n\u003cp\u003eFor its research, X collaborated with post-graduate students, research affiliates, and professors investigating topics like human trust in AI, fine-tuning AI, and AI safety at Harvard University, the Massachusetts Institute of Technology, Stanford University, and the University of Washington.\u003c/p\u003e\n\u003cp\u003eResearchers agreed that \u0026#34;under certain circumstances,\u0026#34; AI agents can \u0026#34;produce notes that are of similar quality to human-written notes—at a fraction of the time and effort.\u0026#34; They suggested that more research is needed to overcome flagged risks to reap the benefits of what could be \u0026#34;a transformative opportunity\u0026#34; that \u0026#34;offers promise of dramatically increased scale and speed\u0026#34; of fact-checking on X.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n\n        \n        \u003cdiv\u003e\n          \n          \n\u003cp\u003eIf AI note writers \u0026#34;generate initial drafts that represent a wider range of perspectives than a single human writer typically could, the quality of community deliberation is improved from the start,\u0026#34; the paper said.\u003c/p\u003e\n\u003ch2\u003eFuture of AI notes\u003c/h2\u003e\n\u003cp\u003eResearchers imagine that once X\u0026#39;s testing is completed, AI note writers could not just aid in researching problematic posts flagged by human users, but also one day select posts predicted to go viral and stop misinformation from spreading faster than human reviewers could.\u003c/p\u003e\n\u003cp\u003eAdditional perks from this automated system, they suggested, would include X note raters quickly accessing more thorough research and evidence synthesis, as well as clearer note composition, which could speed up the rating process.\u003c/p\u003e\n\u003cp\u003eAnd perhaps one day, AI agents could even learn to predict rating scores to speed things up even more, researchers speculated. However, more research would be needed to ensure that wouldn\u0026#39;t homogenize community notes, buffing them out to the point that no one reads them.\u003c/p\u003e\n\u003cp\u003ePerhaps the most Musk-ian of ideas proposed in the paper, is a notion of training AI note writers with clashing views to \u0026#34;adversarially debate the merits of a note.\u0026#34; Supposedly, that \u0026#34;could help instantly surface potential flaws, hidden biases, or fabricated evidence, empowering the human rater to make a more informed judgment.\u0026#34;\u003c/p\u003e\n\u003cp\u003e\u0026#34;Instead of starting from scratch, the rater now plays the role of an adjudicator—evaluating a structured clash of arguments,\u0026#34; the paper said.\u003c/p\u003e\n\u003cp\u003eWhile X may be moving to reduce the workload for X users writing community notes, it\u0026#39;s clear that AI could never replace humans, researchers said. Those humans are necessary for more than just rubber-stamping AI-written notes.\u003c/p\u003e\n\u003cp\u003eHuman notes that are \u0026#34;written from scratch\u0026#34; are valuable to train the AI agents and some raters\u0026#39; niche expertise cannot easily be replicated, the paper said. And perhaps most obviously, humans \u0026#34;are uniquely positioned to identify deficits or biases\u0026#34; and therefore more likely to be compelled to write notes \u0026#34;on topics the automated writers overlook,\u0026#34; such as spam or scams.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\n\n                  \n          \n\n\n\n\n\n\n  \u003cdiv\u003e\n  \u003cdiv\u003e\n          \u003cp\u003e\u003ca href=\"https://arstechnica.com/author/ashleybelanger/\"\u003e\u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2022/06/Ashley-Belanger-400x400.jpg\" alt=\"Photo of Ashley Belanger\"/\u003e\u003c/a\u003e\u003c/p\u003e\n  \u003c/div\u003e\n\n  \u003cdiv\u003e\n    \n\n    \u003cp\u003e\n      Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.\n    \u003c/p\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\n  \u003cp\u003e\n    \u003ca href=\"https://arstechnica.com/tech-policy/2025/07/everything-that-could-go-wrong-with-xs-new-ai-written-community-notes/#comments\" title=\"30 comments\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 80 80\"\u003e\u003cdefs\u003e\u003cclipPath id=\"bubble-zero_svg__a\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"bubble-zero_svg__b\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#bubble-zero_svg__a)\"\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#bubble-zero_svg__b)\"\u003e\u003cpath d=\"M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40\"\u003e\u003c/path\u003e\u003cpath d=\"M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n    30 Comments\n  \u003c/a\u003e\n      \u003c/p\u003e\n              \u003c/div\u003e\n  \u003c/article\u003e\n\n\n  \n\n\n  \n\n\n  \u003cdiv\u003e\n    \u003cheader\u003e\n      \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 26\"\u003e\u003cdefs\u003e\u003cclipPath id=\"most-read_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"most-read_svg__b\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#most-read_svg__a)\"\u003e\u003cg fill=\"none\" clip-path=\"url(#most-read_svg__b)\"\u003e\u003cpath fill=\"currentColor\" d=\"M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1\"\u003e\u003c/path\u003e\u003cpath fill=\"#ff4e00\" d=\"M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n      \n    \u003c/header\u003e\n    \u003col\u003e\n              \u003cli\u003e\n                      \u003ca href=\"https://arstechnica.com/space/2025/07/astronomers-may-have-found-a-third-interstellar-object/\"\u003e\n              \u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/07/bafkreid7zbvywtlailtijlwwoclv3el5l2jir3wwaflpmfiv4o7qfcpfmi-768x432.jpg\" alt=\"Listing image for first story in Most Read: Astronomers may have found a third interstellar object\" decoding=\"async\" loading=\"lazy\"/\u003e\n            \u003c/a\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                  \u003c/ol\u003e\n\u003c/div\u003e\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-07-02T21:00:39Z",
  "modifiedTime": "2025-07-02T21:00:39Z"
}
