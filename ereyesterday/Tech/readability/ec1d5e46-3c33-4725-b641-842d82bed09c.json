{
  "id": "ec1d5e46-3c33-4725-b641-842d82bed09c",
  "title": "AI Firms Say They Can't Respect Copyright. But A Nonprofit's Researchers Just Built a Copyright-Respecting Dataset",
  "link": "https://slashdot.org/story/25/06/07/0527212/ai-firms-say-they-cant-respect-copyright-but-a-nonprofits-researchers-just-built-a-copyright-respecting-dataset?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "Is copyrighted material a requirement for training AI? asks the Washington Post. That's what top AI companies are arguing, and \"Few AI developers have tried the more ethical route — until now. \"A group of more than two dozen AI researchers have found that they could build a massive eight-terabyte dataset using only text that was openly licensed or in public domain. They tested the dataset quality by using it to train a 7 billion parameter language model, which performed about as well as comparable industry efforts, such as Llama 2-7B, which Meta released in 2023.\" A paper published Thursday detailing their effort also reveals that the process was painstaking, arduous and impossible to fully automate. The group built an AI model that is significantly smaller than the latest offered by OpenAI's ChatGPT or Google's Gemini, but their findings appear to represent the biggest, most transparent and rigorous effort yet to demonstrate a different way of building popular AI tools.... As it turns out, the task involves a lot of humans. That's because of the technical challenges of data not being formatted in a way that's machine readable, as well as the legal challenges of figuring out what license applies to which website, a daunting prospect when the industry is rife with improperly licensed data. \"This isn't a thing where you can just scale up the resources that you have available\" like access to more computer chips and a fancy web scraper, said Stella Biderman [executive director of the nonprofit research institute Eleuther AI]. \"We use automated tools, but all of our stuff was manually annotated at the end of the day and checked by people. And that's just really hard.\" Still, the group managed to unearth new datasets that can be used ethically. Those include a set of 130,000 English language books in the Library of Congress, which is nearly double the size of the popular-books dataset Project Gutenberg. The group's initiative also builds on recent efforts to develop more ethical, but still useful, datasets, such as FineWeb from Hugging Face, the open-source repository for machine learning... Still, Biderman remained skeptical that this approach could find enough content online to match the size of today's state-of-the-art models... Biderman said she didn't expect companies such as OpenAI and Anthropic to start adopting the same laborious process, but she hoped it would encourage them to at least rewind back to 2021 or 2022, when AI companies still shared a few sentences of information about what their models were trained on. \"Even partial transparency has a huge amount of social value and a moderate amount of scientific value,\" she said. Read more of this story at Slashdot.",
  "author": "EditorDavid",
  "published": "2025-06-07T23:28:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "ai"
  ],
  "byline": "",
  "length": 2697,
  "excerpt": "Is copyrighted material a requirement for training AI? asks the Washington Post. That's what top AI companies are arguing, and \"Few AI developers have tried the more ethical route — until now. \"A group of more than two dozen AI researchers have found that they could build a massive eight-t...",
  "siteName": "",
  "favicon": "",
  "text": "Is copyrighted material a requirement for training AI? asks the Washington Post. That's what top AI companies are arguing, and \"Few AI developers have tried the more ethical route — until now. \"A group of more than two dozen AI researchers have found that they could build a massive eight-terabyte dataset using only text that was openly licensed or in public domain. They tested the dataset quality by using it to train a 7 billion parameter language model, which performed about as well as comparable industry efforts, such as Llama 2-7B, which Meta released in 2023.\" A paper published Thursday detailing their effort also reveals that the process was painstaking, arduous and impossible to fully automate. The group built an AI model that is significantly smaller than the latest offered by OpenAI's ChatGPT or Google's Gemini, but their findings appear to represent the biggest, most transparent and rigorous effort yet to demonstrate a different way of building popular AI tools.... As it turns out, the task involves a lot of humans. That's because of the technical challenges of data not being formatted in a way that's machine readable, as well as the legal challenges of figuring out what license applies to which website, a daunting prospect when the industry is rife with improperly licensed data. \"This isn't a thing where you can just scale up the resources that you have available\" like access to more computer chips and a fancy web scraper, said Stella Biderman [executive director of the nonprofit research institute Eleuther AI]. \"We use automated tools, but all of our stuff was manually annotated at the end of the day and checked by people. And that's just really hard.\" Still, the group managed to unearth new datasets that can be used ethically. Those include a set of 130,000 English language books in the Library of Congress, which is nearly double the size of the popular-books dataset Project Gutenberg. The group's initiative also builds on recent efforts to develop more ethical, but still useful, datasets, such as FineWeb from Hugging Face, the open-source repository for machine learning... Still, Biderman remained skeptical that this approach could find enough content online to match the size of today's state-of-the-art models... Biderman said she didn't expect companies such as OpenAI and Anthropic to start adopting the same laborious process, but she hoped it would encourage them to at least rewind back to 2021 or 2022, when AI companies still shared a few sentences of information about what their models were trained on. \"Even partial transparency has a huge amount of social value and a moderate amount of scientific value,\" she said.",
  "image": "https://a.fsdn.com/sd/topics/ai_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-177950755\"\u003e\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tIs copyrighted material a requirement for training AI?  \u003ca href=\"https://www.msn.com/en-us/news/technology/ai-firms-say-they-can-t-respect-copyright-these-researchers-tried/ar-AA1G96Ji\"\u003easks the Washington Post\u003c/a\u003e.  That\u0026#39;s what top AI companies are arguing, and \u0026#34;Few AI developers have tried the more ethical route — until now.\u003c/p\u003e\u003cp\u003e \n\n\u0026#34;A group of more than two dozen AI researchers have found that they could build a massive eight-terabyte dataset using only text that was openly licensed or in public domain.  They tested the dataset quality by using it to train a 7 billion parameter language model, which performed about as well as comparable industry efforts, such as Llama 2-7B, which Meta released in 2023.\u0026#34;\n\n\u003ci\u003e \u003ca href=\"https://bit.ly/common-pile-v0p1-paper\"\u003eA paper published Thursday\u003c/a\u003e detailing their effort also reveals that the process was painstaking, arduous and impossible to fully automate. The group built an AI model that is significantly smaller than the latest offered by OpenAI\u0026#39;s ChatGPT or Google\u0026#39;s Gemini, but their findings appear to represent the biggest, most transparent and rigorous effort yet to demonstrate a different way of building popular AI tools.... \u003cp\u003e \n\nAs it turns out, the task involves a lot of humans. That\u0026#39;s because of the technical challenges of data not being formatted in a way that\u0026#39;s machine readable, as well as the legal challenges of figuring out what license applies to which website, a daunting prospect when the industry is rife with \u003ca href=\"https://www.washingtonpost.com/technology/2023/10/25/data-provenance/\"\u003eimproperly licensed data\u003c/a\u003e.  \u0026#34;This isn\u0026#39;t a thing where you can just scale up the resources that you have available\u0026#34; like access to more computer chips and a fancy web scraper, said Stella Biderman [executive director of the nonprofit research institute Eleuther AI]. \u0026#34;We use automated tools, but all of our stuff was manually annotated at the end of the day and checked by people. And that\u0026#39;s just really hard.\u0026#34;\u003c/p\u003e\u003cp\u003e \n\nStill, the group managed to unearth new datasets that can be used ethically. Those include a set of 130,000 English language books in the Library of Congress, which is nearly double the size of the popular-books dataset Project Gutenberg.  The group\u0026#39;s initiative also builds on recent efforts to develop more ethical, but still useful, datasets, such as \u003ca href=\"https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1\"\u003eFineWeb\u003c/a\u003e from Hugging Face, the open-source repository for machine learning...  Still, Biderman remained skeptical that this approach could find enough content online to match the size of today\u0026#39;s state-of-the-art models...  Biderman said she didn\u0026#39;t expect companies such as OpenAI and Anthropic to start adopting the same laborious process, but she hoped it would encourage them to at least rewind back to 2021 or 2022, when AI companies still shared a few sentences of information about what their models were trained on.\u003c/p\u003e\u003cp\u003e \n\n\u0026#34;Even partial transparency has a huge amount of social value and a moderate amount of scientific value,\u0026#34; she said.\n\u003c/p\u003e\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": null,
  "modifiedTime": null
}
