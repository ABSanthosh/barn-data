{
  "id": "636fe0d2-96d6-4312-a822-105454653ba2",
  "title": "Anthropic Builds RAG Directly Into Claude Models With New Citations API",
  "link": "https://slashdot.org/story/25/01/27/2129250/anthropic-builds-rag-directly-into-claude-models-with-new-citations-api?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "An anonymous reader quotes a report from Ars Technica: On Thursday, Anthropic announced Citations, a new API feature that helps Claude models avoid confabulations (also called hallucinations) by linking their responses directly to source documents. The feature lets developers add documents to Claude's context window, enabling the model to automatically cite specific passages it uses to generate answers. \"When Citations is enabled, the API processes user-provided source documents (PDF documents and plaintext files) by chunking them into sentences,\" Anthropic says. \"These chunked sentences, along with user-provided context, are then passed to the model with the user's query.\" The company describes several potential uses for Citations, including summarizing case files with source-linked key points, answering questions across financial documents with traced references, and powering support systems that cite specific product documentation. In its own internal testing, the company says that the feature improved recall accuracy by up to 15 percent compared to custom citation implementations created by users within prompts. While a 15 percent improvement in accurate recall doesn't sound like much, the new feature still attracted interest from AI researchers like Simon Willison because of its fundamental integration of Retrieval Augmented Generation (RAG) techniques. In a detailed post on his blog, Willison explained why citation features are important. \"The core of the Retrieval Augmented Generation (RAG) pattern is to take a user's question, retrieve portions of documents that might be relevant to that question and then answer the question by including those text fragments in the context provided to the LLM,\" he writes. \"This usually works well, but there is still a risk that the model may answer based on other information from its training data (sometimes OK) or hallucinate entirely incorrect details (definitely bad).\" Willison notes that while citing sources helps verify accuracy, building a system that does it well \"can be quite tricky,\" but Citations appears to be a step in the right direction by building RAG capability directly into the model. Anthropic's Alex Albert clarifies that Claude has been trained to cite sources for a while now. What's new with Citations is that \"we are exposing this ability to devs.\" He continued: \"To use Citations, users can pass a new 'citations [...]' parameter on any document type they send through the API.\" Read more of this story at Slashdot.",
  "author": "BeauHD",
  "published": "2025-01-27T23:40:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "ai"
  ],
  "byline": "",
  "length": 2484,
  "excerpt": "An anonymous reader quotes a report from Ars Technica: On Thursday, Anthropic announced Citations, a new API feature that helps Claude models avoid confabulations (also called hallucinations) by linking their responses directly to source documents. The feature lets developers add documents to Claude...",
  "siteName": "",
  "favicon": "",
  "text": "An anonymous reader quotes a report from Ars Technica: On Thursday, Anthropic announced Citations, a new API feature that helps Claude models avoid confabulations (also called hallucinations) by linking their responses directly to source documents. The feature lets developers add documents to Claude's context window, enabling the model to automatically cite specific passages it uses to generate answers. \"When Citations is enabled, the API processes user-provided source documents (PDF documents and plaintext files) by chunking them into sentences,\" Anthropic says. \"These chunked sentences, along with user-provided context, are then passed to the model with the user's query.\" The company describes several potential uses for Citations, including summarizing case files with source-linked key points, answering questions across financial documents with traced references, and powering support systems that cite specific product documentation. In its own internal testing, the company says that the feature improved recall accuracy by up to 15 percent compared to custom citation implementations created by users within prompts. While a 15 percent improvement in accurate recall doesn't sound like much, the new feature still attracted interest from AI researchers like Simon Willison because of its fundamental integration of Retrieval Augmented Generation (RAG) techniques. In a detailed post on his blog, Willison explained why citation features are important. \"The core of the Retrieval Augmented Generation (RAG) pattern is to take a user's question, retrieve portions of documents that might be relevant to that question and then answer the question by including those text fragments in the context provided to the LLM,\" he writes. \"This usually works well, but there is still a risk that the model may answer based on other information from its training data (sometimes OK) or hallucinate entirely incorrect details (definitely bad).\" Willison notes that while citing sources helps verify accuracy, building a system that does it well \"can be quite tricky,\" but Citations appears to be a step in the right direction by building RAG capability directly into the model. Anthropic's Alex Albert clarifies that Claude has been trained to cite sources for a while now. What's new with Citations is that \"we are exposing this ability to devs.\" He continued: \"To use Citations, users can pass a new 'citations [...]' parameter on any document type they send through the API.\"",
  "image": "https://a.fsdn.com/sd/topics/ai_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-176057647\"\u003e\n\t\n\t\t\n\t\n\n\t\n\t\t\n\t\t\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tAn anonymous reader quotes a report from Ars Technica: \u003ci\u003eOn Thursday, Anthropic announced \u003ca href=\"https://www.anthropic.com/news/introducing-citations-api\"\u003eCitations\u003c/a\u003e, a new API feature that helps Claude models avoid confabulations (also called hallucinations) by \u003ca href=\"https://arstechnica.com/ai/2025/01/anthropic-adds-citations-in-bid-to-avoid-confabulating-ai-models/\"\u003elinking their responses directly to source documents\u003c/a\u003e. The feature lets developers add documents to Claude\u0026#39;s context window, enabling the model to automatically cite specific passages it uses to generate answers. \u0026#34;When Citations is enabled, the API processes user-provided source documents (PDF documents and plaintext files) by chunking them into sentences,\u0026#34; Anthropic says. \u0026#34;These chunked sentences, along with user-provided context, are then passed to the model with the user\u0026#39;s query.\u0026#34;\n\u003cp\u003e \nThe company describes several potential uses for Citations, including summarizing case files with source-linked key points, answering questions across financial documents with traced references, and powering support systems that cite specific product documentation. In its own internal testing, the company says that the feature improved recall accuracy by up to 15 percent compared to custom citation implementations created by users within prompts. While a 15 percent improvement in accurate recall doesn\u0026#39;t sound like much, the new feature still attracted interest from AI researchers like Simon Willison because of its fundamental integration of \u003ca href=\"https://www.anthropic.com/news/contextual-retrieval\"\u003eRetrieval Augmented Generation\u003c/a\u003e (RAG) techniques. In a detailed post on his blog, Willison \u003ca href=\"https://simonwillison.net/2025/Jan/24/anthropics-new-citations-api/\"\u003eexplained\u003c/a\u003e why citation features are important.\n\u003c/p\u003e\u003cp\u003e \n\u0026#34;The core of the Retrieval Augmented Generation (RAG) pattern is to take a user\u0026#39;s question, retrieve portions of documents that might be relevant to that question and then answer the question by including those text fragments in the context provided to the LLM,\u0026#34; he writes. \u0026#34;This usually works well, but there is still a risk that the model may answer based on other information from its training data (sometimes OK) or hallucinate entirely incorrect details (definitely bad).\u0026#34; Willison notes that while citing sources helps verify accuracy, building a system that does it well \u0026#34;can be quite tricky,\u0026#34; but Citations appears to be a step in the right direction by building RAG capability directly into the model.\u003c/p\u003e\u003c/i\u003e Anthropic\u0026#39;s Alex Albert \u003ca href=\"https://x.com/alexalbert__/status/1882481281390481790\"\u003eclarifies\u003c/a\u003e that Claude has been trained to cite sources for a while now. What\u0026#39;s new with Citations is that \u0026#34;we are exposing this ability to devs.\u0026#34; He continued: \u0026#34;To use Citations, users can pass a new \u0026#39;citations [...]\u0026#39; parameter on any document type they send through the API.\u0026#34;\u003cbr/\u003e\n\t\t \t\n\t\t\u003c/p\u003e\n\n\t\t\n\n\t\t\n\n\t\t\n\t\t\t\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
