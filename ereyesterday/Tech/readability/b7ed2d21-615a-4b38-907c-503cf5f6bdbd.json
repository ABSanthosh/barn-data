{
  "id": "b7ed2d21-615a-4b38-907c-503cf5f6bdbd",
  "title": "Character.ai can now tell parents which bots their kid is talking to",
  "link": "https://www.theverge.com/news/634974/character-ai-parental-insights-chatbot-report-kids",
  "description": "Chatbot service Character.AI is adding a new ‘Parental Insights’ feature, which lets teens send a weekly report of their chatbot usage to a parents’ email address. As outlined in an announcement from the company, this report includes the daily average time spent across web and mobile, the characters that a user most frequently interacted with, […]",
  "author": "Adi Robertson",
  "published": "2025-03-25T21:00:00-04:00",
  "source": "https://www.theverge.com/rss/index.xml",
  "categories": [
    "AI",
    "News",
    "Tech"
  ],
  "byline": "Adi Robertson",
  "length": 2034,
  "excerpt": "The reports are voluntary.",
  "siteName": "The Verge",
  "favicon": "https://www.theverge.com/static-assets/icons/android-chrome-512x512.png",
  "text": "Adi Robertson is a senior tech and policy editor focused on VR, online platforms, and free expression. Adi has covered video games, biohacking, and more for The Verge since 2011.Chatbot service Character.AI is adding a new ‘Parental Insights’ feature, which lets teens send a weekly report of their chatbot usage to a parents’ email address. As outlined in an announcement from the company, this report includes the daily average time spent across web and mobile, the characters that a user most frequently interacted with, and how much time they spent talking to each character. It’s part of a series of updates designed to address concerns about minors spending too much time with chatbots and encountering inappropriate content during chats.The report, which doesn’t require parents to have an account, is optional and can be set up by minor users in Character.AI’s settings. The company notes that it’s an overview of teens’ activity, not a complete log — so the contents of chatbot conversations won’t be shared. The platform bars kids under 13 years of age in most locations and under 16 in Europe.Character.AI has been introducing new features for underage users since last year, coinciding with concerns — and even legal complaints — about its service. The platform, which is popular with teenagers, allows users to create and customize chatbots that they interact with or share publicly. But multiple lawsuits allege that these bots have offered inappropriately sexualized content or material that promoted self-harm. It also reportedly received warnings from Apple and Google (which hired Character.AI’s founders last year) about its app’s content.The company says that its system has since been redesigned; among other changes, it moved under-18 users to a model trained to avoid “sensitive” output and added more prominent notifications reminding users that the bots weren’t real people. But with enthusiasm for AI regulation and child safety laws booming, this likely won’t be the last step the company is called to take.",
  "image": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/Parental-Insights-01.png?quality=90\u0026strip=all\u0026crop=0%2C3.4613147178592%2C100%2C93.077370564282\u0026w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Adi Robertson\" data-chromatic=\"ignore\" loading=\"lazy\" width=\"36\" height=\"36\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195784/ADI_ROBERTSON.0.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195784/ADI_ROBERTSON.0.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=96 2x\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195784/ADI_ROBERTSON.0.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=96\"/\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.theverge.com/authors/adi-robertson\"\u003eAdi Robertson\u003c/a\u003e \u003cspan\u003eis a senior tech and policy editor focused on VR, online platforms, and free expression. Adi has covered video games, biohacking, and more for The Verge since 2011.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"zephr-anchor\"\u003e\u003cp\u003eChatbot service Character.AI is adding a new ‘Parental Insights’ feature, which lets teens send a weekly report of their chatbot usage to a parents’ email address. As outlined in an announcement from the company, this report includes the daily average time spent across web and mobile, the characters that a user most frequently interacted with, and how much time they spent talking to each character. It’s part of a series of updates designed to address concerns about minors spending too much time with chatbots and encountering inappropriate content during chats.\u003c/p\u003e\u003cp\u003eThe report, which doesn’t require parents to have an account, is optional and can be set up by minor users in Character.AI’s settings. The company notes that it’s an overview of teens’ activity, not a complete log — so the contents of chatbot conversations won’t be shared. The platform bars kids under 13 years of age in most locations and under 16 in Europe.\u003c/p\u003e\u003cp\u003eCharacter.AI has been introducing new features for underage users since last year, coinciding with concerns — and even legal complaints — about its service. The platform, which is popular with teenagers, allows users to create and customize chatbots that they interact with or share publicly. But multiple \u003ca href=\"https://www.theverge.com/2024/12/10/24317839/character-ai-lawsuit-teen-harmful-messages-mental-health\"\u003elawsuits\u003c/a\u003e \u003ca href=\"https://www.theverge.com/2024/10/23/24277962/character-ai-google-wrongful-death-lawsuit\"\u003eallege\u003c/a\u003e that these bots have offered inappropriately sexualized content or material that promoted self-harm. It also \u003ca href=\"https://www.theverge.com/2025/1/27/24352909/apple-and-google-reportedly-worried-character-ais-app-was-inappropriate-for-teens\"\u003ereportedly received warnings\u003c/a\u003e from Apple and Google (which \u003ca href=\"https://www.theverge.com/news/634974/blank\"\u003ehired Character.AI’s founders\u003c/a\u003e last year) about its app’s content.\u003c/p\u003e\u003cp\u003eThe company says that its system has since been redesigned; among other changes, it \u003ca href=\"https://www.theverge.com/2024/12/12/24319050/character-ai-chatbots-teen-model-training-parental-controls\"\u003emoved under-18 users to a model\u003c/a\u003e trained to avoid “sensitive” output and added more prominent notifications reminding users that the bots weren’t real people. But with enthusiasm for AI regulation and child safety laws booming, this likely won’t be the last step the company is called to take.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-03-26T01:00:00Z",
  "modifiedTime": "2025-03-26T01:00:00Z"
}
