{
  "id": "aa109ece-c0a7-462d-9b56-42d8d6712148",
  "title": "ChatGPT made up a product feature out of thin air, so this company created it",
  "link": "https://arstechnica.com/ai/2025/07/chatgpt-made-up-a-product-feature-out-of-thin-air-so-this-company-created-it/",
  "description": "Soundslice caught OpenAI's bot telling users about a fake music notation feature—then built it.",
  "author": "Benj Edwards",
  "published": "Wed, 09 Jul 2025 21:59:25 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Biz \u0026 IT",
    "AI confabulation",
    "AI hallucination",
    "AI misinformation",
    "ChatGPT",
    "generative ai",
    "large language models",
    "machine learning",
    "music",
    "openai",
    "product development",
    "Soundslice",
    "web development"
  ],
  "byline": "Benj Edwards",
  "length": 2537,
  "excerpt": "Soundslice caught OpenAI’s bot telling users about a fake music notation feature—then built it.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "On Monday, sheet music platform Soundslice says it developed a new feature after discovering that ChatGPT was incorrectly telling users the service could import ASCII tablature—a text-based guitar notation format the company had never supported. The incident reportedly marks what might be the first case of a business building functionality in direct response to an AI model's confabulation. Typically, Soundslice digitizes sheet music from photos or PDFs and syncs the notation with audio or video recordings, allowing musicians to see the music scroll by as they hear it played. The platform also includes tools for slowing down playback and practicing difficult passages. Adrian Holovaty, co-founder of Soundslice, wrote in a recent blog post that the recent feature development process began as a complete mystery. A few months ago, Holovaty began noticing unusual activity in the company's error logs. Instead of typical sheet music uploads, users were submitting screenshots of ChatGPT conversations containing ASCII tablature—simple text representations of guitar music that look like strings with numbers indicating fret positions. \"Our scanning system wasn't intended to support this style of notation,\" wrote Holovaty in the blog post. \"Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks—until I messed around with ChatGPT myself.\" When Holovaty tested ChatGPT, he discovered the source of the confusion: The AI model was instructing users to create Soundslice accounts and use the platform to import ASCII tabs for audio playback—a feature that didn't exist. \"We've never supported ASCII tab; ChatGPT was outright lying to people,\" Holovaty wrote. \"And making us look bad in the process, setting false expectations about our service.\" A screenshot of Soundslice's new ASCII tab importer documentation, hallucinated by ChatGPT and made real later. Credit: https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/ When AI models like ChatGPT generate false information with apparent confidence, AI researchers call it a \"hallucination\" or  \"confabulation.\" The problem of AI models confabulating false information has plagued AI models since ChatGPT's public release in November 2022, when people began erroneously using the chatbot as a replacement for a search engine.",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                      \n                      \n          \u003cp\u003eOn Monday, sheet music platform Soundslice \u003ca href=\"https://www.holovaty.com/writing/chatgpt-fake-feature/\"\u003esays\u003c/a\u003e it developed a \u003ca href=\"https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/\"\u003enew feature\u003c/a\u003e after discovering that \u003ca href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\"\u003eChatGPT\u003c/a\u003e was incorrectly telling users the service could import \u003ca href=\"https://en.wikipedia.org/wiki/ASCII_tab\"\u003eASCII tablature\u003c/a\u003e—a text-based guitar notation format the company had never supported. The incident reportedly marks what might be the first case of a business building functionality in direct response to an AI model\u0026#39;s confabulation.\u003c/p\u003e\n\u003cp\u003eTypically, Soundslice digitizes sheet music from photos or PDFs and syncs the notation with audio or video recordings, allowing musicians to see the music scroll by as they hear it played. The platform also includes tools for slowing down playback and practicing difficult passages.\u003c/p\u003e\n\u003cp\u003eAdrian Holovaty, co-founder of \u003ca href=\"https://www.soundslice.com/\"\u003eSoundslice\u003c/a\u003e, wrote in a recent blog post that the recent feature development process began as a complete mystery. A few months ago, Holovaty began noticing unusual activity in the company\u0026#39;s error logs. Instead of typical sheet music uploads, users were submitting screenshots of ChatGPT conversations containing ASCII tablature—simple text representations of guitar music that look like strings with numbers indicating fret positions.\u003c/p\u003e\n\u003cp\u003e\u0026#34;Our scanning system wasn\u0026#39;t intended to support this style of notation,\u0026#34; \u003ca href=\"https://www.holovaty.com/writing/chatgpt-fake-feature/\"\u003ewrote\u003c/a\u003e Holovaty in the blog post. \u0026#34;Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks—until I messed around with ChatGPT myself.\u0026#34;\u003c/p\u003e\n\u003cp\u003eWhen Holovaty tested ChatGPT, he discovered the source of the confusion: The AI model was instructing users to create Soundslice accounts and use the platform to import ASCII tabs for audio playback—a feature that didn\u0026#39;t exist. \u0026#34;We\u0026#39;ve never supported ASCII tab; ChatGPT was outright lying to people,\u0026#34; Holovaty wrote. \u0026#34;And making us look bad in the process, setting false expectations about our service.\u0026#34;\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"1024\" height=\"723\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-1024x723.png\" alt=\"A screenshot of Soundslice\u0026#39;s new ASCII tab importer documentation.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-1024x723.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-640x452.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-768x542.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-980x691.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs.png 1131w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\u003cp\u003e\n      A screenshot of Soundslice\u0026#39;s new ASCII tab importer documentation, hallucinated by ChatGPT and made real later.\n\n              \u003cspan\u003e\n          Credit:\n\n                      \u003ca href=\"https://arstechnica.com/ai/2025/07/chatgpt-made-up-a-product-feature-out-of-thin-air-so-this-company-created-it/Soundslice\" target=\"_blank\"\u003e\n          \n          https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/\n\n                      \u003c/a\u003e\n                  \u003c/span\u003e\n          \u003c/p\u003e\u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eWhen AI models like ChatGPT generate false information with apparent confidence, AI researchers call it a \u0026#34;hallucination\u0026#34; or  \u0026#34;\u003ca href=\"https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/\"\u003econfabulation\u003c/a\u003e.\u0026#34; The problem of AI models confabulating false information has plagued AI models since ChatGPT\u0026#39;s public release in November 2022, when people began erroneously using the chatbot as a replacement for a search engine.\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-07-09T21:59:25Z",
  "modifiedTime": "2025-07-09T21:59:25Z"
}
