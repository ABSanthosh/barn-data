{
  "id": "f621df97-36a4-4942-88ee-ac18fbd870a6",
  "title": "Anthropic lawyers apologize to court over AI ‘hallucination’ in copyright battle with music publishers",
  "link": "https://www.musicbusinessworldwide.com/anthropic-lawyers-apologize-to-court-over-ai-hallucination-in-copyright-battle-with-music-publishers/",
  "description": "Anthropic's lawyers say the Claude chatbot didn't invent a research paper out of thin air, but it did mis-name the paper and its authors Source",
  "author": "Daniel Tencer",
  "published": "Fri, 16 May 2025 10:49:02 +0000",
  "source": "https://www.musicbusinessworldwide.com/feed/",
  "categories": [
    "News",
    "AI hallucinations",
    "Anthropic",
    "Claude AI",
    "copyright lawsuit",
    "Ivana Dukanovic",
    "Olivia Chen"
  ],
  "byline": "Daniel Tencer",
  "length": 4451,
  "excerpt": "Anthropic’s lawyers say the Claude chatbot didn’t invent a research paper out of thin air, but it did mis-name the paper and its authors.",
  "siteName": "Music Business Worldwide",
  "favicon": "https://www.musicbusinessworldwide.com/wp-content/themes/mb/assets/img/icons/favicon-192x192.png",
  "text": "Lawyers for generative AI company Anthropic have apologized to a US federal court for using an incorrect citation generated by Anthropic’s AI in a court filing.In a submission to the court on Thursday (May 15), Anthropic’s lead counsel in the case, Ivana Dukanovic of law firm Latham Watkins, apologized “for the inaccuracy and any confusion this error caused,” but said that Anthropic’s Claude chatbot didn’t invent the academic study cited by Anthropic’s lawyers – it got the title and authors wrong.“Our investigation of the matter confirms that this was an honest citation mistake and not a fabrication of authority,” Dukanovic wrote in her submission, which can be read in full here. The court case in question was brought by music publishers including Universal Music Publishing Group, Concord, and ABKCO in 2023, accusing Anthropic of using copyrighted lyrics to train the Claude chatbot, and alleging that Claude regurgitates copyrighted lyrics when prompted by users.Lawyers for the music publishers and Anthropic are debating how much information Anthropic needs to provide the publishers as part of the case’s discovery process.On April 30, an Anthropic employee and expert witness in the case, Olivia Chen, submitted a court filing in the dispute that cited a research study on statistics published in the journal The American Statistician.On Tuesday (May 13), lawyers for Anthropic said they had tried to track down that paper, including by contacting one of the purported authors, but were told that no such paper existed. In her submission to the court, Dukanovic said the paper in question does exist – but Claude got the paper’s name and authors wrong.“Our manual citation check did not catch that error. Our citation check also missed additional wording errors introduced in the citations during the formatting process using Claude.ai,” Dukanovic wrote.She explained that it was Chen, and not the Claude chatbot, who found the paper, but Claude was asked to write the footnote referencing the paper.“Our investigation of the matter confirms that this was an honest citation mistake and not a fabrication of authority.”Ivana Dukanovic, lawyer representing Anthropic“We have implemented procedures, including multiple levels of additional review, to work to ensure that this does not occur again and have preserved, at the Court’s direction, all information related to Ms. Chen’s declaration,” Dukanovic wrote.The incident is the latest in a growing number of legal cases where lawyers have used AI to speed up their work, only to have the AI “hallucinate” fake information.One recent incident took place in Canada, where a lawyer arguing in front of the Ontario Superior Court is facing a potential contempt of court charge after submitting a legal argument, apparently drafted by ChatGPT and other AI bots, that cited numerous nonexistent cases as precedent. In an article published in The Conversation in March, legal experts explained how this can happen.“This is the result of the AI model attempting to ‘fill in the gaps’ when its training data is inadequate or flawed, and is commonly referred to as ‘hallucination’,” the authors explained.“Consistent failures by lawyers to exercise due care when using these tools has the potential to mislead and congest the courts, harm clients’ interests, and generally undermine the rule of law.”They concluded that “lawyers who use generative AI tools cannot treat it as a substitute for exercising their own judgement and diligence, and must check the accuracy and reliability of the information they receive.”The legal dispute between the music publishers and Anthropic recently saw a setback for the publishers, when Judge Eumi K. Lee of the US District Court for the Northern District of California granted Anthropic’s motion to dismiss most of the charges against the AI company, but gave the publishers leeway to refile their complaint.The music publishers filed an amended complaint against Anthropic on April 25, and on May 9, Anthropic once again filed a motion to dismiss much of the case.A spokesperson for the music publishers told MBW that their amended complaint “bolsters the case against Anthropic for its unauthorized use of song lyrics in both the training and the output of its Claude AI models. For its part, Anthropic’s motion to dismiss simply rehashes some of the arguments from its earlier motion – while giving up on others altogether.”Music Business Worldwide",
  "image": "https://www.musicbusinessworldwide.com/files/2024/09/anthropic.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eLawyers for generative AI company Anthropic have apologized to a US federal court for using an incorrect citation generated by Anthropic’s AI in a court filing.\u003c/p\u003e\u003cp\u003eIn a submission to the court on Thursday (May 15), Anthropic’s lead counsel in the case, \u003cstrong\u003eIvana Dukanovic\u003c/strong\u003e of law firm \u003cstrong\u003eLatham Watkins\u003c/strong\u003e, apologized “for the inaccuracy and any confusion this error caused,” but said that Anthropic’s Claude chatbot didn’t invent the academic study cited by Anthropic’s lawyers – it got the title and authors wrong.\u003c/p\u003e\u003cp\u003e“Our investigation of the matter confirms that this was an honest citation mistake and not a fabrication of authority,” Dukanovic wrote in her submission, which can be read in full \u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/05/Anthropic-UMG-Dukanovic-statement.pdf\" target=\"_blank\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e  \u003cp\u003eThe court case in question was \u003ca href=\"https://www.musicbusinessworldwide.com/ai-company-anthropic-amazon-sued-universal-music-group/\" target=\"_blank\" rel=\"noopener\"\u003ebrought\u003c/a\u003e by music publishers including \u003cstrong\u003e\u003ca title=\"Companies \u0026gt; Universal Music Publishing Group [470 articles]\" href=\"https://www.musicbusinessworldwide.com/companies/universal-music-group/universal-music-publishing-group/\"\u003eUniversal Music Publishing Group\u003c/a\u003e\u003c/strong\u003e, \u003cstrong\u003e\u003ca title=\"Companies \u0026gt; Concord [446 articles]\" href=\"https://www.musicbusinessworldwide.com/companies/concord/\"\u003eConcord\u003c/a\u003e\u003c/strong\u003e, and \u003cstrong\u003eABKCO\u003c/strong\u003e in 2023, accusing Anthropic of using copyrighted lyrics to train the Claude chatbot, and alleging that Claude regurgitates copyrighted lyrics when prompted by users.\u003c/p\u003e\u003cp\u003eLawyers for the music publishers and Anthropic are debating how much information Anthropic needs to provide the publishers as part of the case’s discovery process.\u003c/p\u003e\u003cp\u003eOn April 30, an Anthropic employee and expert witness in the case, \u003cstrong\u003eOlivia Chen\u003c/strong\u003e, submitted a court filing in the dispute that cited a research study on statistics published in the journal \u003cem\u003eThe American Statistician\u003c/em\u003e.\u003c/p\u003e\u003cp\u003eOn Tuesday (May 13), lawyers for Anthropic \u003ca href=\"https://www.musicbusinessworldwide.com/did-anthropics-own-ai-generate-a-hallucination-in-legal-defense-against-song-lyrics-copyright-case/\" target=\"_blank\" rel=\"noopener\"\u003esaid\u003c/a\u003e they had tried to track down that paper, including by contacting one of the purported authors, but were told that no such paper existed.\u003c/p\u003e  \u003cp\u003eIn her submission to the court, Dukanovic said \u003ca href=\"https://www.tandfonline.com/doi/full/10.1080/00031305.2024.2350445\" target=\"_blank\" rel=\"noopener\"\u003ethe paper in question\u003c/a\u003e does exist – but Claude got the paper’s name and authors wrong.\u003c/p\u003e\u003cp\u003e“Our manual citation check did not catch that error. Our citation check also missed additional wording errors introduced in the citations during the formatting process using Claude.ai,” Dukanovic wrote.\u003c/p\u003e\u003cp\u003eShe explained that it was Chen, and not the Claude chatbot, who found the paper, but Claude was asked to write the footnote referencing the paper.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e“Our investigation of the matter confirms that this was an honest citation mistake and not a fabrication of authority.”\u003c/p\u003e\u003cp\u003e\u003cspan\u003eIvana Dukanovic, lawyer representing Anthropic\u003c/span\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e“We have implemented procedures, including multiple levels of additional review, to work to ensure that this does not occur again and have preserved, at the Court’s direction, all information related to Ms. Chen’s declaration,” Dukanovic wrote.\u003c/p\u003e\u003cp\u003eThe incident is the latest in a growing number of legal cases where lawyers have used AI to speed up their work, only to have the AI “hallucinate” fake information.\u003c/p\u003e\u003cp\u003eOne recent incident took place in Canada, where a lawyer arguing in front of the Ontario Superior Court is \u003ca href=\"https://nationalpost.com/news/canada/toronto-lawyer-artificial-intelligence\" target=\"_blank\" rel=\"noopener\"\u003efacing\u003c/a\u003e a potential contempt of court charge after submitting a legal argument, apparently drafted by ChatGPT and other AI bots, that cited numerous nonexistent cases as precedent.\u003c/p\u003e  \u003cp\u003eIn an \u003ca href=\"https://theconversation.com/ai-is-creating-fake-legal-cases-and-making-its-way-into-real-courtrooms-with-disastrous-results-225080\" target=\"_blank\" rel=\"noopener\"\u003earticle\u003c/a\u003e published in \u003cem\u003eThe Conversation \u003c/em\u003ein March, legal experts explained how this can happen.\u003c/p\u003e\u003cp\u003e“This is the result of the AI model attempting to ‘fill in the gaps’ when its training data is inadequate or flawed, and is commonly referred to as ‘hallucination’,” the authors explained.\u003c/p\u003e\u003cp\u003e“Consistent failures by lawyers to exercise due care when using these tools has the potential to mislead and congest the courts, harm clients’ interests, and generally undermine the rule of law.”\u003c/p\u003e\u003cp\u003eThey concluded that “lawyers who use generative AI tools cannot treat it as a substitute for exercising their own judgement and diligence, and must check the accuracy and reliability of the information they receive.”\u003c/p\u003e\u003chr/\u003e\u003cp\u003eThe legal dispute between the music publishers and Anthropic recently saw a setback for the publishers, when Judge \u003cstrong\u003eEumi K. Lee\u003c/strong\u003e of the US District Court for the Northern District of California granted Anthropic’s motion to dismiss most of the charges against the AI company, but gave the publishers leeway to refile their complaint.\u003c/p\u003e\u003cp\u003eThe music publishers \u003ca href=\"https://www.musicbusinessworldwide.com/music-publishers-file-amended-lawsuit-against-ai-firm-anthropic-which-they-say-bolsters-the-case-over-companys-unauthorized-use-of-song-lyrics/\" target=\"_blank\" rel=\"noopener\"\u003efiled an amended complaint\u003c/a\u003e against Anthropic on April 25, and on May 9, Anthropic once again filed a motion to dismiss much of the case.\u003c/p\u003e\u003cp\u003eA spokesperson for the music publishers told \u003cem\u003eMBW\u003c/em\u003e that their amended complaint “bolsters the case against Anthropic for its unauthorized use of song lyrics in both the training and the output of its Claude AI models. For its part, Anthropic’s motion to dismiss simply rehashes some of the arguments from its earlier motion – while giving up on others altogether.”\u003cspan\u003eMusic Business Worldwide\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-05-16T10:49:02Z",
  "modifiedTime": "2025-05-16T13:17:59Z"
}
