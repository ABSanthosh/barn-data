{
  "id": "6cb3cffd-6260-4d5f-9d60-bfccd2677470",
  "title": "AI needs a new UI",
  "link": "https://uxdesign.cc/ai-needs-a-new-ui-60063f49e2d5?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Ken Sigel",
  "published": "Wed, 18 Jun 2025 11:41:16 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "design",
    "ai",
    "ux",
    "product-design",
    "ui"
  ],
  "byline": "Ken Sigel",
  "length": 8451,
  "excerpt": "As the joke goes, the best place to hide a body is on the 2nd page of google results. No one clicks to the next page. Google built the paradigm for all of search around an extremely simple user…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "AI needs a new UIFor AI to succeed, we’ll need to devise new interface patterns that support its capabilities rather than copy those patterns of the technology it seeks to replace.As the joke goes, the best place to hide a body is on the 2nd page of google results. No one clicks to the next page.The Google search paradigmGoogle built the paradigm for all of search around an extremely simple user experience: user asks a simple question (search query) and Google serves up relevant results in the first few entries. A design principle of Google early on was that they would not ask anything more from the user. This was revolutionary–I remember earlier search engines such as Lycos, Alta Vista, Yahoo employing various filtering tools as part of the experience. Google’s genius was doing the opposite: they focused all of the improvements on delivering better results while explicitly never asking more of the user.AltaVista, 1999Text entry field, submit button. User types a question. Google provides an answer. This interaction became the most ubiquitous digital experience on the internet. Everyone has used it thousands of times. The pattern is deeply ingrained in our minds. Any deviation feels wrong.Google, 2025The AI interface mismatchAnd now AI comes along, gives us the exact same UI, and expects us to behave differently. In that familiar text field, a user must write a prompt that has several parts to provide context, persona, desired output format, and more. Then they’re expected to have a back–and–forth conversation with the interface to refine the output and provide additional context.You see the problem?ChatGPT, 2025The interface promises the simplicity of search but demands the complexity of programming. We’ve trained users for 25 years to expect immediate, comprehensive results from brief queries, then asked them to master an entirely different set of skills using an identical user interface.Early adopters and tech enthusiasts will endure this learning curve–the pain of mastering something new is worthwhile when they can envision the potential. But that’s not most people.I’ve been using AI for over a year. Initially, it was frustrating. I believed the hype but couldn’t realize the practical (promised?) value. Only through persistent experimentation did I learn effective prompting techniques and identify valuable–to–me use cases. The technology evolved from awkward and forced to genuinely additive. But the key point: it required significant effort on my part to get there.From one interface, infinite outcomesPerhaps the biggest user challenge is that people can’t grasp the breadth of what AI can accomplish. Consider these wildly different use cases:Blog post: Generate content based on a simple theme or a couple lines of an original idea.Mockup: Generate a clickable prototype of a mobile app based on simple instructions.Training program: Develop a schedule with routine steps to follow so that I can develop a new habit.Presentation: Create an outline for a slide deck presentation.Debate: Help someone think through a complex idea and identify gaps and opportunities.Visual ID: Generate a whole brand identity for a new product.Each started from the same UI: a blank text field.The possibilities feel endless, which paradoxically makes AI feel overwhelming and impractical. Without effective signposts, users can’t keep track of all the many things AI might accomplish for them. The cognitive load of remembering and formulating requests for dozens of potential use cases creates a massive adoption barrier.When it requires more than a conversationFor quick questions and answers, a chat box is a fine interface to use. After all, that’s really just the search experience: ask Google a question and get an answer. AI is striving for richer experiences. Linear dialogues — back-and-forth question and answer with AI will not bring that about.Elizabeth Laraki, Design Partner at Electrical Capital, recently wrote about this on her Substack. In “UI is the limiting factor for AI” she discusses the challenge of using ChatGPT to develop an itinerary for a day in Madrid with her 7-year-old son:“ChatGPT did offer some good ideas and the recommendations were all reasonable. It was the UI that was the problem: The UI didn’t support a conversation that built on itself and didn’t provide any reasonable way to co-create an itinerary.”She notes that human conversation is non-linear — one dives into a sub-topic, jumps back out, changes subjects, tables something for later, comes back. Being able to truly collaborate on an output — in Elizabeth’s case the walking itinerary — where the user can make changes both through conversation (text field entry) and through editing tools, should be the goal. AI doesn’t support that sort of interaction at this time.Building a new interface paradigmWhat should replace the simple search box? This will likely take time to emerge as AI companies experiment with new input controls. While the complete solution remains unclear, several key principles emerge:(I should note that many of these ideas listed are being worked on by AI companies today and have been released in some fashion)Contextual awareness. AI doesn’t need to go in every direction when I first engage it. It should understand who I am, where I am, and what I’m likely trying to accomplish, then adapt to support the most probable use cases. Memory of past interactions was a step-change improvement when LLMs began incorporating conversation history. Google released this to Gemini earlier this year. OpenAI added it to ChatGPT last April. More of this type of recall will help.Adaptive UI. Because possible outputs vary greatly, the inputs will need to be equally different. Sometimes text is optimal. Other times voice, images, or autonomous execution make sense. The UI should morph to match the task rather than forcing everything through a single input method. NN/g released an article last year on this, by Kate Moran and Sarah Gibbons, “Generative UI and Outcome-Oriented Design” where they explore the idea of apps fundamentally changing based on user and intended task.Discrete task-focused components. Rather than cramming infinite possibilities into one box, we need specialized agents that excel at specific functions. These components should understand each other’s function and connect intelligently. When users have a particular need, the appropriate agents should collaborate to deliver an optimal result.Real-time feedback and guidance. Current AI interfaces leave users guessing whether their approach will work. The system should provide insight into what’s working in a prompt and suggest improvements, rather than leaving the user to experiment blindly.Refinement tools. One of the biggest frustrations with AI is a “close-but-not-right” output. It is really hard to make small but important adjustments to an AI output. This is particularly true with image creation or generated prototypes. More precise tooling around editing will be immensely helpful and avoid needlessly starting over. Some companies are starting to offer such editing options. Midjourney offers users some controls. Vercel just added a design mode to v0.v0 design modeThe path forwardThe companies that solve this UI challenge will be doing more than just improving the user experience–they’ll be unlocking AI’s mainstream potential. It isn’t about incremental improvement to chat interfaces. It’s about fundamentally reimagining how humans and AI collaborate.Google’s breakthrough was radical simplification–removing friction that competitors had normalized. AI needs its own paradigm shift. We need interfaces that wrangle the inherent complexity of AI into something that feels effortless and intuitive.AI will transform how we work, create, and solve problems. However, this transformation will remain beyond most people until we redefine the interface in a way that makes sense to humans.Additional readingThe intersection fo AI and product design generates a lot of interest. Here are some additional posts on this topic that I’ve found particularly interesting or useful:“Rethinking interfaces for AI era. Why buttons and text boxes won’t cut it anymore,” by Prashant Singh“UI is the limiting factor for AI,” by Elizabeth Laraki“Generative UI and outcome-oriented design,” by Kate Moran and Sarah Gibbons“Conversational interfaces: the good, the ugly \u0026 the billion-dollar opportunity,” by Julie Zhuo",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*2jAvxCnIKRgvp7hXVAo3Ng.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ch2 id=\"ecd1\" data-testid=\"storyTitle\"\u003eAI needs a new UI\u003c/h2\u003e\u003c/p\u003e\u003cdiv\u003e\u003ch2 id=\"47ce\"\u003eFor AI to succeed, we’ll need to devise new interface patterns that support its capabilities rather than copy those patterns of the technology it seeks to replace.\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@ken_sigel?source=post_page---byline--60063f49e2d5---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Ken Sigel\" src=\"https://miro.medium.com/v2/resize:fill:64:64/2*Hygu7UJPnXWYNyOx6mM6sA.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"a98c\"\u003eAs the joke goes, the best place to hide a body is on the 2nd page of google results. No one clicks to the next page.\u003c/p\u003e\u003ch2 id=\"d9dc\"\u003eThe Google search paradigm\u003c/h2\u003e\u003cp id=\"5512\"\u003eGoogle built the paradigm for all of search around an extremely simple user experience: user asks a simple question (search query) and Google serves up relevant results in the first few entries. A design principle of Google early on was that they would not ask anything more from the user. This was revolutionary–I remember earlier search engines such as Lycos, Alta Vista, Yahoo employing various filtering tools as part of the experience. Google’s genius was doing the opposite: they focused all of the improvements on delivering better results while explicitly never asking more of the user.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eAltaVista, 1999\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"6c04\"\u003eText entry field, submit button. User types a question. Google provides an answer. This interaction became the most ubiquitous digital experience on the internet. Everyone has used it thousands of times. The pattern is deeply ingrained in our minds. Any deviation feels wrong.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eGoogle, 2025\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"2f36\"\u003eThe AI interface mismatch\u003c/h2\u003e\u003cp id=\"a93d\"\u003eAnd now AI comes along, gives us the exact same UI, and expects us to behave differently. In that familiar text field, a user must write a prompt that has several parts to provide context, persona, desired output format, and more. Then they’re expected to have a back–and–forth conversation with the interface to refine the output and provide additional context.\u003c/p\u003e\u003cp id=\"0a9b\"\u003eYou see the problem?\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eChatGPT, 2025\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"9d00\"\u003eThe interface promises the simplicity of search but demands the complexity of programming. We’ve trained users for 25 years to expect immediate, comprehensive results from brief queries, then asked them to master an entirely different set of skills using an identical user interface.\u003c/p\u003e\u003cp id=\"5dab\"\u003eEarly adopters and tech enthusiasts will endure this learning curve–the pain of mastering something new is worthwhile when they can envision the potential. But that’s not most people.\u003c/p\u003e\u003cp id=\"fbba\"\u003eI’ve been using AI for over a year. Initially, it was frustrating. I believed the hype but couldn’t realize the practical (promised?) value. Only through persistent experimentation did I learn effective prompting techniques and identify valuable–to–me use cases. The technology evolved from awkward and forced to genuinely additive. But the key point: it required significant effort on my part to get there.\u003c/p\u003e\u003ch2 id=\"dd5f\"\u003eFrom one interface, infinite outcomes\u003c/h2\u003e\u003cp id=\"12d1\"\u003ePerhaps the biggest user challenge is that people can’t grasp the breadth of what AI can accomplish. Consider these wildly different use cases:\u003c/p\u003e\u003cul\u003e\u003cli id=\"aead\"\u003e\u003cstrong\u003eBlog post:\u003c/strong\u003e Generate content based on a simple theme or a couple lines of an original idea.\u003c/li\u003e\u003cli id=\"fa6a\"\u003e\u003cstrong\u003eMockup:\u003c/strong\u003e Generate a clickable prototype of a mobile app based on simple instructions.\u003c/li\u003e\u003cli id=\"a31b\"\u003e\u003cstrong\u003eTraining program:\u003c/strong\u003e Develop a schedule with routine steps to follow so that I can develop a new habit.\u003c/li\u003e\u003cli id=\"91cb\"\u003e\u003cstrong\u003ePresentation:\u003c/strong\u003e Create an outline for a slide deck presentation.\u003c/li\u003e\u003cli id=\"0428\"\u003e\u003cstrong\u003eDebate:\u003c/strong\u003e Help someone think through a complex idea and identify gaps and opportunities.\u003c/li\u003e\u003cli id=\"186d\"\u003e\u003cstrong\u003eVisual ID:\u003c/strong\u003e Generate a whole brand identity for a new product.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"2f24\"\u003eEach started from the same UI: a blank text field.\u003c/p\u003e\u003cp id=\"726d\"\u003eThe possibilities feel endless, which paradoxically makes AI feel overwhelming and impractical. Without effective signposts, users can’t keep track of all the many things AI might accomplish for them. The cognitive load of remembering and formulating requests for dozens of potential use cases creates a massive adoption barrier.\u003c/p\u003e\u003ch2 id=\"42c7\"\u003eWhen it requires more than a conversation\u003c/h2\u003e\u003cp id=\"7644\"\u003eFor quick questions and answers, a chat box is a fine interface to use. After all, that’s really just the search experience: ask Google a question and get an answer. AI is striving for richer experiences. Linear dialogues — back-and-forth question and answer with AI will not bring that about.\u003c/p\u003e\u003cp id=\"4938\"\u003eElizabeth Laraki, Design Partner at Electrical Capital, recently wrote about this on her Substack. In “\u003ca href=\"https://open.substack.com/pub/elizlaraki/p/ui-is-the-limiting-factor-for-ai?r=eda4n\u0026amp;utm_campaign=post\u0026amp;utm_medium=web\u0026amp;showWelcomeOnShare=false\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUI is the limiting factor for AI\u003c/a\u003e” she discusses the challenge of using ChatGPT to develop an itinerary for a day in Madrid with her 7-year-old son:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"1873\"\u003e“ChatGPT did offer some good ideas and the recommendations were all reasonable. It was the UI that was the problem: The UI didn’t support a conversation that built on itself and didn’t provide any reasonable way to co-create an itinerary.”\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"1b4b\"\u003eShe notes that human conversation is non-linear — one dives into a sub-topic, jumps back out, changes subjects, tables something for later, comes back. Being able to truly collaborate on an output — in Elizabeth’s case the walking itinerary — where the user can make changes both through conversation (text field entry) and through editing tools, should be the goal. AI doesn’t support that sort of interaction at this time.\u003c/p\u003e\u003ch2 id=\"3db7\"\u003eBuilding a new interface paradigm\u003c/h2\u003e\u003cp id=\"57ca\"\u003eWhat should replace the simple search box? This will likely take time to emerge as AI companies experiment with new input controls. While the complete solution remains unclear, several key principles emerge:\u003c/p\u003e\u003cp id=\"1d79\"\u003e(\u003cem\u003eI should note that many of these ideas listed are being worked on by AI companies today and have been released in some fashion\u003c/em\u003e)\u003c/p\u003e\u003cp id=\"4fd8\"\u003e\u003cstrong\u003eContextual awareness\u003c/strong\u003e. AI doesn’t need to go in every direction when I first engage it. It should understand who I am, where I am, and what I’m likely trying to accomplish, then adapt to support the most probable use cases. Memory of past interactions was a step-change improvement when LLMs began incorporating conversation history. Google released this to Gemini \u003ca href=\"https://blog.google/feed/gemini-referencing-past-chats/#:~:text=Starting%20today%2C%20Gemini%20can%20now,chats%20to%20craft%20a%20response.\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eearlier this year\u003c/a\u003e. OpenAI added it to ChatGPT \u003ca href=\"https://www.engadget.com/ai/chatgpt-can-now-remember-all-your-past-conversations-134642785.html#:~:text=The%20next%20time%20you%20conclude,post%20spotted%20by%20The%20Verge.\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003elast April\u003c/a\u003e. More of this type of recall will help.\u003c/p\u003e\u003cp id=\"f422\"\u003e\u003cstrong\u003eAdaptive UI\u003c/strong\u003e. Because possible outputs vary greatly, the inputs will need to be equally different. Sometimes text is optimal. Other times voice, images, or autonomous execution make sense. The UI should morph to match the task rather than forcing everything through a single input method. NN/g released an article last year on this, by Kate Moran and Sarah Gibbons, “\u003ca href=\"https://www.nngroup.com/articles/generative-ui/#:~:text=Generative%20AI\u0026#39;s%20problems%20are%20GenUI\u0026#39;s,have%20hardware%20that%20delivers%20genUIs.\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGenerative UI and Outcome-Oriented Design\u003c/a\u003e” where they explore the idea of apps fundamentally changing based on user and intended task.\u003c/p\u003e\u003cp id=\"0ac4\"\u003e\u003cstrong\u003eDiscrete task-focused components\u003c/strong\u003e. Rather than cramming infinite possibilities into one box, we need specialized agents that excel at specific functions. These components should understand each other’s function and connect intelligently. When users have a particular need, the appropriate agents should collaborate to deliver an optimal result.\u003c/p\u003e\u003cp id=\"498d\"\u003e\u003cstrong\u003eReal-time feedback and guidance\u003c/strong\u003e. Current AI interfaces leave users guessing whether their approach will work. The system should provide insight into what’s working in a prompt and suggest improvements, rather than leaving the user to experiment blindly.\u003c/p\u003e\u003cp id=\"83f1\"\u003e\u003cstrong\u003eRefinement tools\u003c/strong\u003e. One of the biggest frustrations with AI is a “close-but-not-right” output. It is really hard to make small but important adjustments to an AI output. This is particularly true with image creation or generated prototypes. More precise tooling around editing will be immensely helpful and avoid needlessly starting over. Some companies are starting to offer such editing options. Midjourney offers users some controls. Vercel just added a design mode to v0.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003ev0 design mode\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"c491\"\u003eThe path forward\u003c/h2\u003e\u003cp id=\"cd28\"\u003eThe companies that solve this UI challenge will be doing more than just improving the user experience–they’ll be unlocking AI’s mainstream potential. It isn’t about incremental improvement to chat interfaces. It’s about fundamentally reimagining how humans and AI collaborate.\u003c/p\u003e\u003cp id=\"bad8\"\u003eGoogle’s breakthrough was radical simplification–removing friction that competitors had normalized. AI needs its own paradigm shift. We need interfaces that wrangle the inherent complexity of AI into something that feels effortless and intuitive.\u003c/p\u003e\u003cp id=\"b975\"\u003eAI will transform how we work, create, and solve problems. However, this transformation will remain beyond most people until we redefine the interface in a way that makes sense to humans.\u003c/p\u003e\u003ch2 id=\"9b7e\"\u003eAdditional reading\u003c/h2\u003e\u003cp id=\"b1ab\"\u003eThe intersection fo AI and product design generates a lot of interest. Here are some additional posts on this topic that I’ve found particularly interesting or useful:\u003c/p\u003e\u003cul\u003e\u003cli id=\"4648\"\u003e“\u003ca href=\"https://medium.com/@pacificleo/rethinking-interfaces-for-ai-era-why-buttons-and-text-boxes-wont-cut-it-anymore-1af101405284\" rel=\"noopener\"\u003eRethinking interfaces for AI era. Why buttons and text boxes won’t cut it anymore\u003c/a\u003e,” by Prashant Singh\u003c/li\u003e\u003cli id=\"3ae3\"\u003e“\u003ca href=\"https://elizlaraki.substack.com/p/ui-is-the-limiting-factor-for-ai?just_subscribed=true\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUI is the limiting factor for AI\u003c/a\u003e,” by Elizabeth Laraki\u003c/li\u003e\u003cli id=\"68f2\"\u003e“\u003ca href=\"https://www.nngroup.com/articles/generative-ui/#:~:text=Generative%20AI\u0026#39;s%20problems%20are%20GenUI\u0026#39;s,have%20hardware%20that%20delivers%20genUIs.\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGenerative UI and outcome-oriented design\u003c/a\u003e,” by Kate Moran and Sarah Gibbons\u003c/li\u003e\u003cli id=\"0dc5\"\u003e“\u003ca href=\"https://medium.com/@joulee/conversational-interfaces-the-good-the-ugly-the-billion-dollar-opportunity-e4575adb6260\" rel=\"noopener\"\u003eConversational interfaces: the good, the ugly \u0026amp; the billion-dollar opportunity,\u003c/a\u003e” by Julie Zhuo\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-06-16T03:00:51.947Z",
  "modifiedTime": null
}
