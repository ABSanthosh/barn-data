{
  "id": "509e9f30-bc01-43b5-ae71-ca34d7165be8",
  "title": "Designing Use-Case Prompt Suggestions",
  "link": "https://www.nngroup.com/articles/designing-use-case-prompt-suggestions/?utm_source=rss\u0026utm_medium=feed\u0026utm_campaign=rss-syndication",
  "description": "Use-case prompt suggestions show how to effectively prompt AI tools. They aid learnability and creativity, helping users explore what AI tools can do.",
  "author": "Tim Neusesser, Kate Moran",
  "published": "Fri, 27 Jun 2025 17:00:00 +0000",
  "source": "https://www.nngroup.com/feed/rss/",
  "categories": [
    "Article"
  ],
  "byline": "Kate Moran, Tim Neusesser",
  "length": 22952,
  "excerpt": "Use-case prompt suggestions show how to effectively prompt AI tools. They aid learnability and creativity, helping users explore what AI tools can do.",
  "siteName": "Nielsen Norman Group",
  "favicon": "",
  "text": "Summary:  Use-case prompt suggestions show how to effectively prompt AI tools. They aid learnability and creativity, helping users explore what AI tools can do. Use-case prompt suggestions are intended to help users understand what they can use the AI tool for and how to interact with it. When designed well, they set accurate expectations for the system and guide users toward effective prompting. Defining Use-Case Prompt Suggestions Designing Use-Case Prompt Suggestions: Simple vs. Complex Helping New Users Quickly Understand What the System Can Do Teaching and Inspiring Active Users to Use the System Effectively Use Analytics to Optimize Prompt Suggestions Defining Use-Case Prompt Suggestions Use-case prompt suggestions are examples of good AI prompts. They are displayed within most AI tools, usually (but not only) to novice users. Unlike other types of prompt suggestions, which focus on continuing a conversation (followup suggestions) or helping users complete the prompt (prompt autocomplete), use-case prompt suggestions aim to support learnability — helping users quickly understand what the genAI tool can do for them and how. Designing Use-Case Prompt Suggestions: Simple vs. Complex Use-case prompt suggestions vary widely in complexity — from short phrases or single-sentence examples to rich, realistic formats like entire conversations, images, or videos that show full user–system interactions. Prompt suggestions can be simple, such as short phrases or sentences, or complex, such as entire conversations or video replays of interactions with the AI system. Choosing the right level of complexity depends on several key factors: How broad or specialized the AI system’s capabilities are How familiar users are with AI in general The complexity of the typical tasks users perform Where in the interface the prompt suggestion appears Simple, clickable prompts placed inside or near the input field work well for broad systems and low-complexity tasks. Complex prompt suggestions are better suited for specialized systems and high-complexity tasks, where rich examples provide more meaningful guidance. While users are more likely to engage with quick, actionable prompts, rich examples can help them develop a deeper understanding of how to interact with the system effectively. Simple use-case prompt suggestions: When unauthenticated users visited ChatGPT.com, they were shown a set of use-case suggestions in the form of pills positioned directly beneath the input field. These included simple prompt examples like Analyze data, Summarize text, and Help me write. Prompt complexity also affects how suggestions should be displayed. Simple prompts take up little space, allowing multiple suggestions to be shown at once. This is ideal for inline layouts or suggestion lists. Complex prompts, however, require more screen real estate and are better presented one at a time, such as in a carousel, expandable section, or example library. Ultimately, designers must balance two competing goals when choosing the complexity and format of prompt suggestions: Helping new users quickly understand what the system can do Teaching and inspiring active users to use the system effectively Helping New Users Quickly Understand What the System Can Do The primary goal of helping users understand what an AI tool or feature can do is to encourage them to start using it and ultimately increase adoption. This is especially important for unauthenticated users, as organizations hope to convert them into long-term, paying customers. At this stage, users are typically: Just discovering the tool Exploring its capabilities Deciding whether to register, try it out, or subscribe To support this last decision, companies often display simple, curated examples in the preauthentication view. These static suggestions act as marketing nudges: they are quick to scan, easy to understand, and designed to clearly communicate the tool’s key capabilities, ideally motivating users to create an account and get started. Highlight Key System Capabilities For curated use-case prompt suggestions to be effective, their content must be tailored to the user’s level of experience and likely objectives. This alignment helps showcase the AI system’s capabilities in a way that feels relevant and actionable, while also setting realistic expectations for interaction. A critical consideration is deciding which strengths of the AI system to highlight. Depending on the tool’s purpose and audience, prompt suggestions might emphasize abilities such as: Content creation Problem solving Ideation The features showcased should reflect potential users' most common goals. The more closely these suggestions align with user needs, the more likely they are to drive engagement and convert new visitors into active users. While most AI tools support a wide variety of use cases, it’s the product team’s responsibility to identify a focused set of high-impact capabilities. Highlighting the most broadly relevant strengths ensures that the prompt suggestions appeal to the largest possible share of users — especially in early interactions like the preauthentication experience. Showcase Functionality with Minimal Friction These curated examples often function as push revelations — predefined content shown proactively, regardless of user context. While useful for showcasing features, push revelations have well-documented usability pitfalls: they can be intrusive, easily ignored, and quickly forgotten. If these suggestions disrupt rather than assist, they risk undermining their intended purpose. To be effective, prompt suggestions in preauthentication views should follow the same usability principles as other types of onboarding. They must be: Easy to dismiss Visually unobtrusive Clearly tied to common user goals Used thoughtfully, these static prompts can serve as lightweight introductions to system capabilities. But if overdesigned or poorly timed, they may frustrate users rather than support them. Common UI Patterns for Prompt Suggestions Before Login There are several ways to visually present prompt suggestions in preauthentication views, each offering distinct advantages and tradeoffs. Pills Pills are often used to display prompt suggestions as single terms or short phrases. This format is ideal for highlighting a wide range of topics or system capabilities, helping users quickly understand what the AI tool can do. Pills should be interactive — either triggering the prompt directly or inserting a longer prompt into the input field for users to edit before submitting. In preauthentication views, clicking a pill typically leads users to sign in or create an account to continue, in case they must be logged in to use the tool.   ✅ ChatGPT offered simple pill suggestions that, when clicked, brought up autocomplete suggestions. When one of the autocomplete suggestions was selected, the prompt was changed to a question format and some details were added. Pretty clever. Cards Using cards to display use-case prompt suggestions allows for in-depth examples of how to interact with the system. Using cards for prompt suggestions works well when: The AI tool is specialized or primarily used for a small number of tasks. Longer prompts are needed to showcase the system’s capabilities. Like pills, cards should be clickable and direct users to sign in or create an account (if required). Poe.com used cards to show two prompt suggestions to educate new users on the capabilities of the system. Videos Videos are a powerful way to demonstrate how a system works and educate users on its capabilities and interaction patterns. They’re especially useful when users have little to no prior experience with generative AI tools, as they can offer rich context and realistic examples of effective usage.   Notion AI: Before creating an account, Notion AI offered this video to give potential subscribers an impression of what the AI system could do. Carousels Using a carousel is an effective way to showcase multiple curated examples of how to interact with the system. It offers both breadth and depth — allowing users to see a variety of use cases while presenting each one individually. Carousels make it easy to highlight complex interactions and rich examples of the system’s capabilities. Claude: Displaying Multiple System Abilities in a Carousel One example of this approach is Claude’s preauthentication view, which included a curated carousel showcasing four examples of what the system could be used for. The examples highlighted the system’s ability to: Visualize data Organize content Analyze data and create a report Optimize code   Before users signed in, Claude.ai featured a carousel to highlight different use cases. These were extremely simplified “conversations” — they arguably misrepresented the complexity of working with Claude to achieve these goals. Showcasing Claude’s broad abilities makes sense, given that its millions of users likely have a wide variety of goals. Featuring a selection of curated use-case prompt suggestions in the preauthentication view effectively highlighted what the AI could do and helped set realistic expectations for how users can interact with it. However, Claude’s design team has had to sacrifice realistic prompt and interaction examples in order to convey the system’s capabilities quickly. For example, one of the prompt suggestions reads: Claude, make a content calendar for my marketing campaign. To which Claude simply responded, Of course! Here’s the calendar! and provided a complete-looking output. This is not a realistic representation of how someone would create such an output using Claude. Instead, they’d probably need to have a much longer conversation with Claude to achieve their intended result. But this is a tradeoff to consider when designing use-case prompt suggestions to quickly highlight the system’s abilities. Teaching and Inspiring Active Users to Use the System Effectively Once users are authenticated and actively engaging with the AI system, the focus of prompt suggestions shifts from introducing capabilities to supporting ongoing use. At this stage, the primary goals are to: Help users complete tasks more efficiently Accelerate workflows Encourage deeper engagement Inspire new ways to interact with the system Increase user satisfaction and retention over time To achieve these goals, AI systems can not only use curated examples but also surface system-generated prompt suggestions during user interactions. These appear in real time and are tailored to the current context, offering just-in-time guidance and relevant next steps. Contextually Relevant Prompt Suggestions To truly support users and provide value, system-generated prompt suggestions must be context-aware. This means they should: Adapt to the specific situation the user is in Appear at the right moment, ideally when users need guidance or inspiration Offer relevant suggestions that help users move forward, complete tasks, or make decisions By meeting users where they are in the experience and offering timely, specific, and meaningful prompts, designers can not only improve efficiency but also foster continued exploration and trust in the system. Over time, this contributes to stronger engagement and higher retention among active users. Context-aware prompt suggestions are especially valuable in two common scenarios: 1. When Users Face High Ambiguity Ambiguity arises when users are unsure how to proceed or what to focus on, often due to many possible directions. For instance, consider a user planning a trip to Miami, Florida on Tripadvisor.com. Once they arrive on the site, they’re faced with countless options — hotels, activities, restaurants, beaches, nightlife — all competing for attention. Without clear guidance, it can be difficult to know where to begin. To reduce this ambiguity, Tripadvisor’s AI assistant surfaced relevant, situational prompt suggestions like: Which hotels in Miami have ocean views? What are the best rooftop bars in Miami? What are the best beaches in Miami? Where can I find live music in Miami? ✅ Tripadvisor: The AI assistant displayed multiple context-aware prompt suggestions, supporting the user in finding relevant information for their trip to Miami, Florida. Such suggestions provide focused entry points into the planning experience. They reduce cognitive load by surfacing relevant, location-specific queries at the right moment. Instead of sifting through endless possibilities, users are nudged toward prompts that match their interests and context, helping them move forward with clarity and confidence. 2. When Users Lack Domain Knowledge Another situation where context-aware prompt suggestions add value is when users are unfamiliar with a topic or product category. In these cases, users may not have the language, context, or mental model to know where to begin. This is common in ecommerce scenarios where users evaluate complex or unfamiliar items. Imagine someone shopping for a home generator for the first time. They might not know which features matter most — wattage, fuel type, noise level, or portability — or what tradeoffs to consider. Without domain knowledge, it’s hard to know what questions to ask, even if the site offers AI-generated summaries or a product-review chatbot. Context-aware prompt suggestions can bridge this gap by surfacing relevant questions like: What do reviewers say about reliability during power outages? Is it easy to move around? Does it have an automatic shutoff? What kinds of fuel does it work with? How loud is it compared to other generators? These targeted suggestions help users navigate unfamiliar territory, spotlight important product dimensions, and build confidence in their decision, even if they start with little expertise. By anticipating common concerns and aligning prompt suggestions with user goals, friction can be removed and shopping experiences improved. Case Study: Amazon’s Rufus AI Dynamically Adapts Prompts to Product Context Amazon’s Rufus AI chatbot illustrates how context-aware prompt suggestions can be applied in practice. When a user reviewed Birkenstocks, Rufus adapted to the specific product and provided situationally relevant prompt suggestions such as: Do Birkenstocks come in both narrow and wide? Which Birkenstock sandals are best for arch support? Are Birkenstock clogs good for standing all day? Do Birkenstocks require a break-in period? This approach combines both contextual awareness and anticipation of user needs, reducing uncertainty and helping users uncover relevant product information quickly.   ✅ Amazon.com: Rufus AI dynamically adapted its prompt suggestions to the product the user was browsing, ensuring they were situationally relevant and aligned with the user’s immediate needs. Specific Beats Vague: Why Precision Matters in Prompt Suggestions Broad or generic prompt suggestions are rarely effective, even when the goal is to inspire new users or showcase what the AI system can do, as these vague prompts often lack the clarity users need to evaluate whether they are useful. In contrast, specific and targeted suggestions help users quickly determine relevance and are more likely to lead to meaningful interaction. Good Example: Instacart’s Targeted Search Prompts Instacart provided a strong example of how specificity can improve the user experience. When users interacted with the search feature, the system surfaced clear, focused suggestions, rather than showing general categories. For example, they included phrases like: Easy family dinners Nutritious snacks for kids Easy dinner ideas ✅ Instacart: By offering specific prompt suggestions, the system made it easy for users to quickly assess their relevance and decide whether to engage with them. These prompts included enough detail for users to immediately understand their purpose and value. One user captured this sentiment well: “This is more pointed: Easy family dinner ideas — fantastic! Nutritious snacks for kids, Easy dinner ideas — these are extremely helpful buzzwords for me.” By using concrete, situationally relevant language, Instacart’s prompts made it easier for users to decide how to proceed and increased the chances of engagement. Individualization Increases Relevance and Value Prompt suggestions become more useful when they are tailored to the individual user. Instead of offering the same prompts to everyone, systems that adjust to a user’s specific context, such as their level of expertise, browsing behavior, or previous interactions, can provide suggestions that feel much more relevant and helpful. For example, in a project-management app, the system can adapt based on how familiar someone is with the tool: Product: Project-Management App User Journey Stage Meaningful Prompt Prompt Purpose New user How do I create my first project? Help them get started and understand the basics. Intermediate user How do I set up task dependencies between team members? Support more advanced planning and coordination. Experienced user How can I automate recurring tasks in this workspace? Enable efficiency and deeper use of advanced features. By matching the complexity of the prompt to the user’s skill level, the system reduces friction, surfaces relevant functionality, and increases the likelihood of meaningful engagement. This type of individualization can be based on: Previous conversations with the AI Past browsing or search behavior Account history or saved preferences These inputs help the system present focused and timely suggestions that align with the user’s goals. When Personal Data Isn’t Available: Learn from Others In situations where the system doesn’t have enough information about the current user, such as during a first-time visit or an anonymous session, it can still offer helpful suggestions by looking at patterns from other users. For example, the system might: Show popular searches related to the current topic Highlight common tasks completed by others in similar contexts Suggest prompts that other users have found useful in the same area While these suggestions aren’t personalized to the individual, they are still grounded in real user behavior. They reflect what has helped others in similar situations and give new users a strong starting point. Increase Engagement by Placing Prompt Suggestions Near the Input Field For prompt suggestions aimed at teaching or inspiring active users, placement is just as important as content. To support usability and maximize engagement, suggestions should be positioned near the text input field — the primary focus of user attention during interaction with an AI system. The input field serves as the main entry point for user queries. Whether a user is preparing to type or waiting to respond, their attention is naturally drawn to this area. Placing suggestions in close proximity to this field ensures they are noticed at the exact moment users are most likely to engage with them. The format of these suggestions also plays a key role in usability. Two commonly effective formats are: Pills: Short, clickable phrases or questions. Their compact design makes them easy to scan and ideal for surfacing multiple lightweight suggestions without overwhelming the interface. Cards: A more spacious format that allows for longer prompts, brief descriptions, or supporting visuals. Cards are especially useful when additional context is needed to help users understand the suggestion. Both formats should support direct interaction, allowing users to insert a prompt with a single click or tap. This design minimizes interaction cost, particularly for users who are uncertain about what to ask or how to phrase their request. Use an Example Library When More Context Is Needed When users need more information or context to understand how to interact with an AI system, example libraries can be an effective option. These libraries offer a curated collection of prompts paired with outputs, providing both practical guidance and creative inspiration. By showcasing full examples, they help users grasp what’s possible with the system and how to phrase their requests to get meaningful results. This is particularly valuable for systems with complex capabilities or for users who are still developing mental models of how the AI works. Example libraries are especially common in generative AI tools for visual content, such as image or video creation. In these cases, the visual nature of the examples makes the system’s capabilities immediately clear. This approach not only supports new users during onboarding but also keeps experienced users engaged by offering fresh ideas and use cases. ✅ Midjourney: Users could explore a library of examples from other users. The library showcased generated graphics and, when selected, Midjourney also displayed the associated prompt. Use Human Oversight to Ensure Relevance and Appropriateness The examples shown are often based on real user inputs and outputs. However, most product teams should actively select and curate these examples, rather than auto selecting them from recent activity. Manual selection helps maintain a high standard of quality and ensures that all examples align with the brand’s tone, purpose, and values. It also helps avoid displaying inappropriate or off-brand content, such as politically sensitive or overly sexualized material. Use Analytics to Optimize Prompt Suggestions Analytics can play a critical role in helping product teams refine and improve the effectiveness of use-case prompt suggestions. There are two primary ways analytics can support this effort: Identifying common use cases. Usage data can reveal which tasks or goals are most frequently pursued by current users. These insights can inform which prompt suggestions to display to new users, ensuring that suggestions reflect real-world behaviors and needs. Evaluating prompt performance. Analytics can also show which prompt suggestions users engage with the most and which are consistently ignored. This information helps teams make data-informed decisions about which suggestions to keep, improve, or remove. However, it’s important to interpret these metrics with care and be aware of confounding factors. Engagement rates are often influenced by placement, not just content. For example, suggestions shown first in a carousel or positioned near the input field are more likely to be clicked than those located deeper in the interface or behind a More button. To reduce this bias and get a clearer picture of what users find useful, consider randomizing the order in which prompt suggestions are displayed. This approach will allow teams to isolate the impact of content from position, leading to more accurate optimization decisions.",
  "image": "https://media.nngroup.com/media/articles/opengraph_images/Use-case-prompts_Opengraph_copy_2.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp\u003e\u003cspan\u003e\n                  Summary: \n                \u003c/span\u003eUse-case prompt suggestions show how to effectively prompt AI tools. They aid learnability and creativity, helping users explore what AI tools can do.\n              \u003c/p\u003e\u003cdiv\u003e\n              \u003cp\u003eUse-case prompt suggestions are intended to \u003cstrong\u003ehelp users understand what they can use the AI tool for and how to interact with it\u003c/strong\u003e. When designed well, they set accurate expectations for the system and guide users toward effective prompting.\u003c/p\u003e\n\u003cdiv\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-defining-use-case-prompt-suggestions-1\"\u003eDefining Use-Case Prompt Suggestions\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-designing-use-case-prompt-suggestions-simple-vs-complex-2\"\u003eDesigning Use-Case Prompt Suggestions: Simple vs. Complex\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-helping-new-users-quickly-understand-what-the-system-can-do-3\"\u003eHelping New Users Quickly Understand What the System Can Do\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-teaching-and-inspiring-active-users-to-use-the-system-effectively-4\"\u003eTeaching and Inspiring Active Users to Use the System Effectively\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-use-analytics-to-optimize-prompt-suggestions-5\"\u003eUse Analytics to Optimize Prompt Suggestions\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003ch2 id=\"toc-defining-use-case-prompt-suggestions-1\"\u003eDefining Use-Case Prompt Suggestions\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eUse-case prompt suggestions\u003c/strong\u003e are examples of good AI prompts. They are displayed within most AI tools, usually (but not only) to novice users.\u003c/p\u003e\n\u003cp\u003eUnlike \u003ca href=\"https://www.nngroup.com/articles/prompt-suggestions/\"\u003eother types of prompt suggestions\u003c/a\u003e, which focus on continuing a conversation (followup suggestions) or helping users complete the prompt (prompt autocomplete), use-case prompt suggestions aim to support learnability — helping users quickly understand what the genAI tool can do for them and how.\u003c/p\u003e\n\u003ch2 id=\"toc-designing-use-case-prompt-suggestions-simple-vs-complex-2\"\u003eDesigning Use-Case Prompt Suggestions: Simple vs. Complex\u003c/h2\u003e\n\u003cp\u003eUse-case prompt suggestions vary widely in complexity — from short phrases or single-sentence examples to rich, realistic formats like entire conversations, images, or videos that show full user–system interactions.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Diagram showing five levels of AI prompt complexity, from “Pancake ideas” to video demos, progressing from simple to complex suggestions with examples.\" height=\"6300\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2025/06/20/prompt-suggestion-complexity-final.png\" width=\"4422\"/\u003e\n\u003cfigcaption\u003e\u003cem\u003ePrompt suggestions can be simple, such as short phrases or sentences, or complex, such as entire conversations or video replays of interactions with the AI system.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eChoosing the right level of complexity depends on several key factors:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHow broad or specialized the AI system’s capabilities are\u003c/li\u003e\n\u003cli\u003eHow familiar users are with AI in general\u003c/li\u003e\n\u003cli\u003eThe complexity of the typical tasks users perform\u003c/li\u003e\n\u003cli\u003eWhere in the interface the prompt suggestion appears\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSimple, clickable prompts \u003c/strong\u003eplaced inside or near the input field work well for\u003cstrong\u003e broad systems and low-complexity tasks\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eComplex prompt suggestions \u003c/strong\u003eare better suited for\u003cstrong\u003e specialized systems and high-complexity tasks\u003c/strong\u003e, where rich examples provide more meaningful guidance.\u003c/p\u003e\n\u003cp\u003eWhile users are more likely to engage with quick, actionable prompts, rich examples can help them develop a deeper understanding of how to interact with the system effectively.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Chat interface with prompt bar labeled “Ask anything” and options like Attach, Search, Reason, and Voice, plus task buttons like Summarize text and Analyze data.\" height=\"464\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2025/06/17/chat-gpt-simple-use-case-prompt-suggestion.png\" width=\"936\"/\u003e\n\u003cfigcaption\u003e\u003cem\u003eSimple use-case prompt suggestions: When unauthenticated users visited ChatGPT.com, they were shown a set of use-case suggestions in the form of pills positioned directly beneath the input field. These included simple prompt examples like \u003c/em\u003eAnalyze data, Summarize text\u003cem\u003e, and \u003c/em\u003eHelp me write\u003cem\u003e.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003ePrompt complexity also affects how suggestions should be displayed. Simple prompts take up little space, allowing multiple suggestions to be shown at once. This is ideal for inline layouts or suggestion lists.\u003c/p\u003e\n\u003cp\u003eComplex prompts, however, require more screen real estate and are better presented one at a time, such as in a carousel, expandable section, or example library.\u003c/p\u003e\n\u003cp\u003eUltimately, \u003cstrong\u003edesigners must balance two competing goals \u003c/strong\u003ewhen choosing the complexity and format of prompt suggestions:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eHelping new users quickly understand what the system can do\u003c/li\u003e\n\u003cli\u003eTeaching and inspiring active users to use the system effectively\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"toc-helping-new-users-quickly-understand-what-the-system-can-do-3\"\u003eHelping New Users Quickly Understand What the System Can Do\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eThe primary goal \u003c/strong\u003eof helping users understand what an AI tool or feature can do\u003cstrong\u003e is to encourage them to start using it \u003c/strong\u003eand ultimately increase adoption. This is especially important for unauthenticated users, as organizations hope to convert them into long-term, paying customers.\u003c/p\u003e\n\u003cp\u003eAt this stage, users are typically:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eJust discovering the tool\u003c/li\u003e\n\u003cli\u003eExploring its capabilities\u003c/li\u003e\n\u003cli\u003eDeciding whether to register, try it out, or subscribe\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/reports/make-decisions/\"\u003eTo support this last decision\u003c/a\u003e, companies often display simple, curated examples in the preauthentication view. These static suggestions act as marketing nudges: they are \u003cstrong\u003equick to scan, easy to understand, and designed to clearly communicate the tool’s key capabilities\u003c/strong\u003e, ideally motivating users to create an account and get started.\u003c/p\u003e\n\u003ch3\u003eHighlight Key System Capabilities\u003c/h3\u003e\n\u003cp\u003eFor curated use-case prompt suggestions to be effective, their content must be tailored to the user’s level of experience and likely objectives. This alignment helps showcase the AI system’s capabilities in a way that feels relevant and actionable, while also setting realistic expectations for interaction.\u003c/p\u003e\n\u003cp\u003eA critical consideration is deciding \u003cstrong\u003ewhich strengths of the AI system to highlight\u003c/strong\u003e. Depending on the tool’s purpose and audience, prompt suggestions might emphasize abilities such as:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eContent creation\u003c/li\u003e\n\u003cli\u003eProblem solving\u003c/li\u003e\n\u003cli\u003eIdeation\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe features showcased should \u003cstrong\u003ereflect potential users\u0026#39; most common goals\u003c/strong\u003e. The more closely these suggestions align with user needs, the more likely they are to drive engagement and convert new visitors into active users.\u003c/p\u003e\n\u003cp\u003eWhile most AI tools support a wide variety of use cases, it’s the product team’s responsibility to identify a focused set of high-impact capabilities. Highlighting the most broadly relevant strengths ensures that the prompt suggestions appeal to the largest possible share of users — especially in early interactions like the preauthentication experience.\u003c/p\u003e\n\u003ch3\u003eShowcase Functionality with Minimal Friction\u003c/h3\u003e\n\u003cp\u003eThese curated examples often function as \u003ca href=\"https://www.nngroup.com/articles/onboarding-tutorials/\"\u003epush revelations\u003c/a\u003e — predefined content shown proactively, regardless of user context. While useful for showcasing features, push revelations have well-documented usability pitfalls: they can be intrusive, easily ignored, and quickly forgotten. If these suggestions disrupt rather than assist, they risk undermining their intended purpose.\u003c/p\u003e\n\u003cp\u003eTo be effective, prompt suggestions in preauthentication views should follow the same usability principles as other types of onboarding. They must be:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEasy to dismiss\u003c/li\u003e\n\u003cli\u003eVisually unobtrusive\u003c/li\u003e\n\u003cli\u003eClearly tied to common user goals\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUsed thoughtfully, these static prompts can serve as lightweight introductions to system capabilities. But if overdesigned or poorly timed, they may frustrate users rather than support them.\u003c/p\u003e\n\u003ch3\u003eCommon UI Patterns for Prompt Suggestions Before Login\u003c/h3\u003e\n\u003cp\u003eThere are several ways to visually present prompt suggestions in preauthentication views, each offering distinct advantages and tradeoffs.\u003c/p\u003e\n\u003ch4\u003ePills\u003c/h4\u003e\n\u003cp\u003ePills are often used to display prompt suggestions as single terms or short phrases. This format is \u003cstrong\u003eideal for highlighting a wide range of topics or system capabilities\u003c/strong\u003e, helping users quickly understand what the AI tool can do.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePills should be interactive\u003c/strong\u003e — either triggering the prompt directly or inserting a longer prompt into the input field for users to edit before submitting. In preauthentication views, clicking a pill typically leads users to sign in or create an account to continue, in case they must be logged in to use the tool.\u003c/p\u003e\n\u003cfigure\u003e\n\u003cvideo controls=\"controls\" poster=\"\" src=\"https://media.nngroup.com/media/editor/2025/06/17/pills-chatgpt.mp4\" title=\"\"\u003e \u003c/video\u003e\n\u003cfigcaption\u003e✅ \u003cem\u003eChatGPT \u003c/em\u003eoffered \u003cem\u003esimple pill suggestions that, when clicked, brought up autocomplete suggestions. When one of the autocomplete suggestions was selected, the prompt was changed to a question format and some details were added. Pretty clever.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003ch4\u003eCards\u003c/h4\u003e\n\u003cp\u003eUsing cards to display use-case prompt suggestions allows for in-depth examples of how to interact with the system. Using cards for prompt suggestions works well when:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe AI tool is specialized or primarily used for a small number of tasks.\u003c/li\u003e\n\u003cli\u003eLonger prompts are needed to showcase the system’s capabilities.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLike pills, cards should be clickable and direct users to sign in or create an account (if required).\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Prompt suggestions showing two example ideas: an AI app for chibi anime images from photos, and a writing tool using GPT-4o-mini for targeted text feedback.\" height=\"486\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2025/06/17/poe-example-cards.png\" width=\"1516\"/\u003e\n\u003cfigcaption\u003e\u003cem\u003ePoe.com used cards to show two prompt suggestions to educate new users on the capabilities of the system.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003ch4\u003eVideos\u003c/h4\u003e\n\u003cp\u003eVideos are a powerful way to demonstrate how a system works and educate users on its capabilities and interaction patterns. They’re especially useful when users have little to no prior experience with generative AI tools, as they can offer rich context and realistic examples of effective usage.\u003c/p\u003e\n\u003cfigure\u003e\n\u003cvideo controls=\"controls\" poster=\"\" src=\"https://media.nngroup.com/media/editor/2025/06/17/notion-ai.mp4\" title=\"\"\u003e \u003c/video\u003e\n\u003cfigcaption\u003e\u003cem\u003eNotion AI: Before creating an account, Notion AI offered this video to give potential subscribers an impression of what the AI system could do.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003ch4\u003eCarousels\u003c/h4\u003e\n\u003cp\u003eUsing a carousel is an effective way to showcase multiple curated examples of how to interact with the system. It offers both breadth and depth — allowing users to see a variety of use cases while presenting each one individually. Carousels make it easy to highlight complex interactions and rich examples of the system’s capabilities.\u003c/p\u003e\n\u003ch4\u003eClaude: Displaying Multiple System Abilities in a Carousel\u003c/h4\u003e\n\u003cp\u003eOne example of this approach is Claude’s preauthentication view, which included a curated carousel showcasing four examples of what the system could be used for. The examples highlighted the system’s ability to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eVisualize data\u003c/li\u003e\n\u003cli\u003eOrganize content\u003c/li\u003e\n\u003cli\u003eAnalyze data and create a report\u003c/li\u003e\n\u003cli\u003eOptimize code\u003c/li\u003e\n\u003c/ul\u003e\n\u003cfigure\u003e\n\u003cvideo controls=\"controls\" poster=\"\" src=\"https://media.nngroup.com/media/editor/2025/06/17/video-claude_all-example_use-case.mp4\" title=\"\"\u003e \u003c/video\u003e\n\u003cfigcaption\u003e\u003cem\u003eBefore users signed in, Claude.ai featured a carousel to highlight different use cases. These were extremely simplified “conversations” — they arguably misrepresented the complexity of working with Claude to achieve these goals.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eShowcasing Claude’s broad abilities makes sense, given that its millions of users likely have a wide variety of goals. Featuring a selection of curated use-case prompt suggestions in the preauthentication view effectively highlighted what the AI could do and helped set realistic expectations for how users can interact with it.\u003c/p\u003e\n\u003cp\u003eHowever, Claude’s design team has had to sacrifice realistic prompt and interaction examples in order to convey the system’s capabilities quickly. For example, one of the prompt suggestions reads:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003eClaude, make a content calendar for my marketing campaign.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eTo which Claude simply responded, \u003cem\u003eOf course! Here’s the calendar!\u003c/em\u003e and provided a complete-looking output. This is \u003cstrong\u003enot a realistic representation of how someone would create such an output using Claude.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eInstead, they’d probably need to have a much longer conversation with Claude to achieve their intended result. But this is a tradeoff to consider when designing use-case prompt suggestions to quickly highlight the system’s abilities.\u003c/p\u003e\n\u003ch2 id=\"toc-teaching-and-inspiring-active-users-to-use-the-system-effectively-4\"\u003eTeaching and Inspiring Active Users to Use the System Effectively\u003c/h2\u003e\n\u003cp\u003eOnce users are authenticated and actively engaging with the AI system, the focus of prompt suggestions shifts from introducing capabilities to supporting ongoing use. At this stage, the primary goals are to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHelp users complete tasks more efficiently\u003c/li\u003e\n\u003cli\u003eAccelerate workflows\u003c/li\u003e\n\u003cli\u003eEncourage deeper engagement\u003c/li\u003e\n\u003cli\u003eInspire new ways to interact with the system\u003c/li\u003e\n\u003cli\u003eIncrease user satisfaction and retention over time\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo achieve these goals, AI systems can not only use curated examples but also surface system-generated prompt suggestions during user interactions. These appear in real time and are tailored to the current context, offering just-in-time guidance and relevant next steps.\u003c/p\u003e\n\u003ch3\u003eContextually Relevant Prompt Suggestions\u003c/h3\u003e\n\u003cp\u003eTo truly support users and provide value, system-generated prompt suggestions must be context-aware. This means they should:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAdapt to the specific situation\u003c/strong\u003e the user is in\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAppear at the right moment\u003c/strong\u003e, ideally when users need guidance or inspiration\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOffer relevant suggestions\u003c/strong\u003e that help users move forward, complete tasks, or make decisions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy meeting users where they are in the experience and offering timely, specific, and meaningful prompts, designers can not only improve efficiency but also foster continued exploration and trust in the system. Over time, this contributes to stronger engagement and higher retention among active users.\u003c/p\u003e\n\u003cp\u003eContext-aware prompt suggestions are especially valuable in two common scenarios:\u003c/p\u003e\n\u003ch4\u003e1. When Users Face High Ambiguity\u003c/h4\u003e\n\u003cp\u003eAmbiguity arises when users are unsure how to proceed or what to focus on, often due to many possible directions.\u003c/p\u003e\n\u003cp\u003eFor instance, consider a user planning a trip to Miami, Florida on Tripadvisor.com. Once they arrive on the site, they’re faced with countless options — hotels, activities, restaurants, beaches, nightlife — all competing for attention. Without clear guidance, it can be difficult to know where to begin.\u003c/p\u003e\n\u003cp\u003eTo reduce this ambiguity, Tripadvisor’s AI assistant surfaced relevant, situational prompt suggestions like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eWhich hotels in Miami have ocean views?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eWhat are the best rooftop bars in Miami?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eWhat are the best beaches in Miami?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eWhere can I find live music in Miami?\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cfigure\u003e\u003cimg alt=\"Tripadvisor page for Miami, Florida, showing travel advice sections like “Best time to visit” and an AI assistant with suggested travel questions like beaches and bars.\" height=\"1826\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2025/06/17/trip-advisor-example.png\" width=\"2024\"/\u003e\n\u003cfigcaption\u003e✅ \u003cem\u003eTripadvisor: The AI assistant displayed multiple context-aware prompt suggestions, supporting the user in finding relevant information for their trip to Miami, Florida.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eSuch suggestions provide focused entry points into the planning experience. They \u003cstrong\u003ereduce \u003c/strong\u003e\u003ca href=\"https://www.nngroup.com/videos/cognitive-load/\"\u003e\u003cstrong\u003ecognitive load\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e by surfacing relevant, location-specific queries at the right moment\u003c/strong\u003e. Instead of sifting through endless possibilities, users are nudged toward prompts that match their interests and context, helping them move forward with clarity and confidence.\u003c/p\u003e\n\u003ch4\u003e2. When Users Lack Domain Knowledge\u003c/h4\u003e\n\u003cp\u003eAnother situation where context-aware prompt suggestions add value is when users are unfamiliar with a topic or product category. In these cases, users may not have the language, context, or \u003ca href=\"https://www.nngroup.com/articles/mental-models/\"\u003emental model\u003c/a\u003e to know where to begin. This is common in ecommerce scenarios where users evaluate complex or unfamiliar items.\u003c/p\u003e\n\u003cp\u003eImagine someone shopping for a home generator for the first time. They might not know which features matter most — wattage, fuel type, noise level, or portability — or what tradeoffs to consider. Without domain knowledge, it’s hard to know what questions to ask, even if the site offers AI-generated summaries or a product-review chatbot.\u003c/p\u003e\n\u003cp\u003eContext-aware prompt suggestions can bridge this gap by surfacing relevant questions like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eWhat do reviewers say about reliability during power outages?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eIs it easy to move around?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eDoes it have an automatic shutoff?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eWhat kinds of fuel does it work with?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eHow loud is it compared to other generators?\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese targeted suggestions help users navigate unfamiliar territory, spotlight important product dimensions, and build confidence in their decision, even if they start with little expertise. By anticipating common concerns and aligning prompt suggestions with user goals, friction can be removed and shopping experiences improved.\u003c/p\u003e\n\u003ch4\u003eCase Study: Amazon’s Rufus AI Dynamically Adapts Prompts to Product Context\u003c/h4\u003e\n\u003cp\u003eAmazon’s Rufus AI chatbot illustrates how context-aware prompt suggestions can be applied in practice. When a user reviewed Birkenstocks, Rufus adapted to the specific product and provided situationally relevant prompt suggestions such as:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eDo Birkenstocks come in both narrow and wide?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eWhich Birkenstock sandals are best for arch support?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eAre Birkenstock clogs good for standing all day?\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eDo Birkenstocks require a break-in period?\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis approach combines both contextual awareness and anticipation of user needs, reducing uncertainty and helping users uncover relevant product information quickly.\u003c/p\u003e\n\u003cfigure\u003e\n\u003cvideo controls=\"controls\" poster=\"\" src=\"https://media.nngroup.com/media/editor/2025/06/17/rufus-example-video.mp4\" title=\"\"\u003e \u003c/video\u003e\n\u003cfigcaption\u003e✅ \u003cem\u003eAmazon.com: Rufus AI dynamically adapted its prompt suggestions to the product the user was browsing, ensuring they were situationally relevant and aligned with the user’s immediate needs.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003ch3\u003eSpecific Beats Vague: Why Precision Matters in Prompt Suggestions\u003c/h3\u003e\n\u003cp\u003eBroad or generic prompt suggestions are rarely effective, even when the goal is to inspire new users or showcase what the AI system can do, as these vague prompts often lack the clarity users need to evaluate whether they are useful.\u003c/p\u003e\n\u003cp\u003eIn contrast, \u003cstrong\u003especific and targeted suggestions\u003c/strong\u003e \u003cstrong\u003ehelp users quickly determine relevance\u003c/strong\u003e and are more likely to lead to meaningful interaction.\u003c/p\u003e\n\u003ch4\u003eGood Example: Instacart’s Targeted Search Prompts\u003c/h4\u003e\n\u003cp\u003eInstacart provided a strong example of how specificity can improve the user experience. When users interacted with the search feature, the system surfaced clear, focused suggestions, rather than showing general categories. For example, they included phrases like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eEasy family dinners\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eNutritious snacks for kids\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eEasy dinner ideas\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cfigure\u003e\u003cimg alt=\"\" height=\"2148\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2025/06/17/specific-prompt-suggestion_example.png\" width=\"3616\"/\u003e\n\u003cfigcaption\u003e✅ \u003cem\u003eInstacart: \u003c/em\u003e\u003cem\u003eBy offering specific prompt suggestions, the system made it easy for users to quickly assess their relevance and decide whether to engage with them.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eThese prompts included enough detail for users to immediately understand their purpose and value. One user captured this sentiment well:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e“This is more pointed: \u003c/em\u003eEasy family dinner ideas \u003cem\u003e— fantastic! \u003c/em\u003eNutritious snacks for kids\u003cem\u003e, \u003c/em\u003eEasy dinner ideas \u003cem\u003e— these are extremely helpful buzzwords for me.”\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBy using concrete, situationally relevant language, Instacart’s prompts made it easier for users to decide how to proceed and increased the chances of engagement.\u003c/p\u003e\n\u003ch3\u003eIndividualization Increases Relevance and Value\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003ePrompt suggestions become more useful when they are tailored to the individual user\u003c/strong\u003e. Instead of offering the same prompts to everyone, systems that adjust to a user’s specific context, such as their level of expertise, browsing behavior, or previous interactions, can provide suggestions that feel much more relevant and helpful.\u003c/p\u003e\n\u003cp\u003eFor example, in a project-management app, the system can adapt based on how familiar someone is with the tool:\u003c/p\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd colspan=\"3\"\u003e\n\u003cp\u003e\u003cstrong\u003eProduct: Project-Management App\u003c/strong\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003e\u003cstrong\u003eUser Journey Stage\u003c/strong\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003e\u003cstrong\u003eMeaningful Prompt\u003c/strong\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003e\u003cstrong\u003ePrompt Purpose\u003c/strong\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNew user\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003e\u003cem\u003eHow do I create my first project?\u003c/em\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eHelp them get started and understand the basics.\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eIntermediate user\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003e\u003cem\u003eHow do I set up task dependencies between team members?\u003c/em\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eSupport more advanced planning and coordination.\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eExperienced user\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003e\u003cem\u003eHow can I automate recurring tasks in this workspace?\u003c/em\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eEnable efficiency and deeper use of advanced features.\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eBy matching the complexity of the prompt to the user’s skill level, the system reduces friction, surfaces relevant functionality, and increases the likelihood of meaningful engagement.\u003c/p\u003e\n\u003cp\u003eThis type of individualization can be based on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePrevious conversations with the AI\u003c/li\u003e\n\u003cli\u003ePast browsing or search behavior\u003c/li\u003e\n\u003cli\u003eAccount history or saved preferences\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese inputs help the system present focused and timely suggestions that align with the user’s goals.\u003c/p\u003e\n\u003ch4\u003eWhen Personal Data Isn’t Available: Learn from Others\u003c/h4\u003e\n\u003cp\u003eIn situations where the system doesn’t have enough information about the current user, such as during a first-time visit or an anonymous session, it can still offer helpful suggestions by looking at patterns from other users.\u003c/p\u003e\n\u003cp\u003eFor example, the system might:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eShow popular searches related to the current topic\u003c/li\u003e\n\u003cli\u003eHighlight common tasks completed by others in similar contexts\u003c/li\u003e\n\u003cli\u003eSuggest prompts that other users have found useful in the same area\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhile these suggestions aren’t personalized to the individual, they are still grounded in real user behavior. They reflect what has helped others in similar situations and give new users a strong starting point.\u003c/p\u003e\n\u003ch3\u003eIncrease Engagement by Placing Prompt Suggestions Near the Input Field\u003c/h3\u003e\n\u003cp\u003eFor prompt suggestions aimed at teaching or inspiring active users, \u003cstrong\u003eplacement is just as important as content\u003c/strong\u003e. To support usability and maximize engagement, suggestions should be positioned near the text input field — the primary focus of user attention during interaction with an AI system.\u003c/p\u003e\n\u003cp\u003eThe input field serves as the main entry point for user queries. Whether a user is preparing to type or waiting to respond, their attention is naturally drawn to this area. Placing suggestions in close proximity to this field ensures they are noticed at the exact moment users are most likely to engage with them.\u003c/p\u003e\n\u003cp\u003eThe format of these suggestions also plays a key role in usability. Two commonly effective formats are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePills\u003c/strong\u003e: Short, clickable phrases or questions. Their compact design makes them easy to scan and ideal for surfacing multiple lightweight suggestions without overwhelming the interface.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCards\u003c/strong\u003e: A more spacious format that allows for longer prompts, brief descriptions, or supporting visuals. Cards are especially useful when additional context is needed to help users understand the suggestion.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBoth formats should support direct interaction, allowing users to insert a prompt with a single click or tap. This design minimizes \u003ca href=\"https://www.nngroup.com/articles/interaction-cost-definition/\"\u003einteraction cost\u003c/a\u003e, particularly for users who are uncertain about what to ask or how to phrase their request.\u003c/p\u003e\n\u003ch3\u003eUse an Example Library When More Context Is Needed\u003c/h3\u003e\n\u003cp\u003eWhen users need more information or context to understand how to interact with an AI system, example libraries can be an effective option. These \u003cstrong\u003elibraries offer a curated collection of prompts paired with outputs\u003c/strong\u003e, providing both practical guidance and creative inspiration.\u003c/p\u003e\n\u003cp\u003eBy showcasing full examples, they help users grasp what’s possible with the system and how to phrase their requests to get meaningful results. This is particularly valuable for systems with complex capabilities or for users who are still developing mental models of how the AI works.\u003c/p\u003e\n\u003cp\u003eExample libraries are especially common in generative AI tools for visual content, such as image or video creation. In these cases, the visual nature of the examples makes the system’s capabilities immediately clear. This approach not only supports new users during onboarding but also keeps experienced users engaged by offering fresh ideas and use cases.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"User interface showing image grid with a sea turtle artwork highlighted; zoomed-in view on right reveals turtle in vintage postage stamp style with muted red tones.\" height=\"1926\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2025/06/17/midjourney_library_use-case-example.png\" width=\"3616\"/\u003e\n\u003cfigcaption\u003e✅ \u003cem\u003eMidjourney: Users could explore a library of examples from other users. The library showcased generated graphics and, when selected, Midjourney also displayed the associated prompt.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003ch3\u003eUse Human Oversight to Ensure Relevance and Appropriateness\u003c/h3\u003e\n\u003cp\u003eThe examples shown are often based on real user inputs and outputs. However, most product teams should actively select and curate these examples, rather than auto selecting them from recent activity.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eManual selection helps maintain a high standard of quality\u003c/strong\u003e and ensures that all examples align with the brand’s tone, purpose, and values. It also helps avoid displaying inappropriate or off-brand content, such as politically sensitive or overly sexualized material.\u003c/p\u003e\n\u003ch2 id=\"toc-use-analytics-to-optimize-prompt-suggestions-5\"\u003eUse Analytics to Optimize Prompt Suggestions\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/videos/analytics-in-ux/\"\u003e\u003cstrong\u003eAnalytics\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e \u003c/strong\u003ecan play a critical role in helping product teams \u003cstrong\u003erefine and improve the effectiveness of use-case prompt suggestions\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThere are two primary ways analytics can support this effort:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eIdentifying common use cases. \u003c/strong\u003eUsage data can reveal which tasks or goals are most frequently pursued by current users. These insights can inform which prompt suggestions to display to new users, ensuring that suggestions reflect real-world behaviors and needs.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEvaluating prompt performance. \u003c/strong\u003eAnalytics can also show which prompt suggestions users engage with the most and which are consistently ignored. This information helps teams make data-informed decisions about which suggestions to keep, improve, or remove.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eHowever, it’s important to \u003cstrong\u003einterpret these metrics with care\u003c/strong\u003e and be aware of \u003ca href=\"https://www.nngroup.com/videos/confounding-variables-1/\"\u003econfounding factors\u003c/a\u003e. Engagement rates are often influenced by placement, not just content. For example, suggestions shown first in a carousel or positioned near the input field are more likely to be clicked than those located deeper in the interface or behind a \u003cem\u003eMore\u003c/em\u003e button.\u003c/p\u003e\n\u003cp\u003eTo reduce this bias and get a clearer picture of what users find useful, \u003cstrong\u003econsider randomizing the order in which prompt suggestions are displayed\u003c/strong\u003e. This approach will allow teams to isolate the impact of content from position, leading to more accurate optimization decisions.\u003c/p\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "24 min read",
  "publishedTime": "2025-06-27T17:00:00Z",
  "modifiedTime": null
}
