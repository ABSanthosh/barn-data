{
  "id": "a1d04969-12aa-4e9d-a69a-cadd8f57d0ec",
  "title": "AI transparency in UX: Designing clear AI interactions",
  "link": "https://uxdesign.cc/ai-transparency-in-ux-designing-clear-ai-interactions-ba9b6ba4761b?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Allie Paschal",
  "published": "Tue, 04 Mar 2025 08:40:22 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "design-systems",
    "ui",
    "ux",
    "ai",
    "ux-design"
  ],
  "byline": "Allie Paschal",
  "length": 10410,
  "excerpt": "As AI is integrated more and more throughout website and app experiences, it’s critical to distinguish where AI has been implemented from where it has not. Initially, most products introduced AI as a…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Users need more than a sparkle icon and chat-bot to designate embedded AI.As AI is integrated more and more throughout website and app experiences, it’s critical to distinguish where AI has been implemented from where it has not.Initially, most products introduced AI as a chat-bot where users initiated and facilitated their interaction with AI. Now, products are merging AI into dashboards, tasks, and search functions. Users are no longer initiating their experience with AI–it’s pre-existing.Since users no longer control when they trigger usage of AI, users need to be made aware of when they’re shown AI features or content to determine its validity and quality. Not only that, the European Union AI Act (applicable in 2026) will enforce that users are made aware when they communicate or interact with an AI system.This is where design systems come in–implementing specialized visual treatment to consistently separate AI content and features from non-AI content and features.Google’s Material design system documentationUnfortunately, only a few open-source design systems have explicit AI components and patterns today. I’m hoping more will be incorporated soon, but so far, only GitLab’s Pajamas, IBM’s Carbon, and Twilio’s Paste acknowledge AI in their guidelines.Note: I use Design Systems for Figma to benchmark AI components and patterns. I also did not include design systems that only include documentation for AI chat-bots or conversation design since it’s a more standard interaction pattern; this includes Amazon’s Cloudscape and Salesforce’s Lightning.Let’s compare and contrast these design system AI components and patterns and see where they can be optimized for better usability.1. GitLab’s PajamasPajamas currently doesn’t include explicit components or patterns, but it does include interesting documentation about AI-human interactions. The documentation first recommends understanding if the usage of AI will actually benefit the user by identifying when it’s ethical and beneficial to automate (I.E., high-risk vs. low-risk tasks).Next, it recommends being transparent about where AI is used–Pajamas does this with its “GitLab Duo,” an indicator of AI-features, capabilities, and limitations.GitLab Duo is used to indicate where the user can interact with AI in the interfaceSince the “GitLab Duo” is used for AI-features and interactions (and not any AI content), Pajamas also recommends flagging AI-generated content with “\u003cVerb\u003e by AI” (I.E., “Summarized by AI”), as well as a message encouraging users to check the AI-content.GitLab is also working on a framework to practice their guidelines; it’s currently in-progress, but the general work can be viewed in GitLab’s AI UX Patterns. Their goal is to release an AI-pattern library with documentation–just what we need (pleaseee!).GitLab’s vision for their AI UX patterns is split into 4 dimensions to help select the right AI pattern: Mode, Approach, Interactivity, and Task.Mode: The emphasis of the AI-human interaction (focused, supportive, or integrated)Approach: What the AI is improving (automate or augment tasks)Interactivity: How the AI engages with users (proactive or reactive)Task: What the AI system can help the user with (classification, generation, or prediction)For example, their early explorations for AI patterns include low-fidelity mockups of how AI can be integrated in an interface with charts or inline explanations. The patterns clearly mark the usage of AI to help build user understanding and trust with the AI system.Lo-fi integrated chart with markers indicating AI, such as predicted data (via GitLab’s Vision for AI UX)Lo-fi integrated explainer to fill out a form with AI (via GitLab’s Vision for AI UX)VerdictCurrently, GitLab’s documentation is conceptual and generalized to how they want the AI UX experience to be like in the future. But it gives a solid framework that most design systems could adopt–no matter the industry or product.I’m hopeful they release more in-depth information about their AI UX patterns soon. I think it could be a great open-source asset to other design systems developing their AI documentation.2. IBM’s CarbonOut of the open-source design systems, Carbon has the most robust documentation for AI usage. It includes an AI-dedicated section, “Carbon for AI,” which encompasses components, patterns, and guidelines to help users recognize AI-generated content and understand how AI is used in the product.Carbon for AI builds on top of the existing Carbon components–adding a blue glow and gradient to highlight instances of AI. So far, there are 12 components with AI variants, such as a modal, data table, and text input.Carbon for AI’s component list with specific AI variantsThough the AI variants of the components are given a distinct visual treatment, in context, it’s difficult to distinguish which component is currently active (because they all look active).In the below form, AI was used to auto-fill most of the input fields, so these fields use the AI-variants. The AI-variants receive a blue gradient and border even if it’s in a default state–making it hard to visually identify which component is active.The blue gradient and border used on AI-components makes it hard to tell which component is activeUsers can override inputs made by AI, which will swap the AI-variant for the default-variant of the component. This will cause a “revert to AI input” action to replace the AI label in the input field–allowing users to control manual or automated form responses.Carbon’s “revert to AI input” function appears when users override AI-inputIn addition to the AI-variant, it includes an explicit AI label that can display a popover explaining the details of AI in the particular scenario (Carbon calls this pattern “AI explainability”). The user can select the AI label and the popover appears beneath the button.​​Carbon’s AI label includes an explainer popover for the user to get more details on the usage of AIVerdictIt’s exciting to see design system documentation on AI patterns and components that’s as well-developed as Carbon’s. Not only do they have documentation on the general usage of AI, but actually have components and patterns to use.But since the AI-variants of the components make it difficult to distinguish which component is active when used in-context, I think there are usability and accessibility issues. The AI-variants draw too much attention with the color usage, and also look like Carbon’s focus state (which could impact low-vision users reliant on the focus state).Carbon’s AI-variant vs. focus state of the text field3. Twilio’s PasteLastly, Paste offers an “Artificial Intelligence” section under their “Experiences” section. Paste includes general documentation on using AI in user experiences, as well as a few components to use.When designing AI features, Paste recommends allowing users to compare AI outcomes to their current experiences, as well as handle potential errors and risks. To mitigate these errors, Paste advocates for giving the user the ability to review and undo outputs, control data sources, and give feedback to the AI system.Paste also suggests asking yourself, “How would I design this feature if it did the same thing but didn’t use AI?” when designing a new AI feature. Users don’t use products just so they can interact with AI–they’re trying to complete tasks and achieve goals as efficiently as possible.Paste includes an AI UI kit with 5 components: artificial intelligence icon, badge, button, progress bar, and skeleton loader. It also includes components specific to their AI chat experience, such as the AI chat log.What’s most helpful in Paste’s documentation is the examples they provide. This includes signposting, generative features, and the chat.For signposting, Paste suggests using the decorative badge with the artificial intelligence icon to indicate a feature is using AI, such as AI recommendations or predictions. The signposting is non-interactive, but resembles a button, so it looks clickable.Paste’s signposting example using a badge and AI iconThe generative feature gives users prompts to help them use the AI feature, such as “Summarize the data” or “Recommend the next step.” When you select the generative feature, a popover appears below giving the user instructions and what AI model it’s using.Paste’s generative feature includes a button with a popover to instruct the user interacting with AILastly, the chat is pretty typical of AI chat-bots known today, and includes references to their conversational principles to develop the AI’s personality.Paste’s AI chat-bot with an empty state and prompts below the text fieldPaste does have another pattern coming soon with the loading pattern, but we’ll have to wait and see. This pattern will give users a way to control and anticipate the AI output; this includes stopping the output and adapting the state based on how long the AI output will take.VerdictI’m happy to see a mixture of some documentation with real examples we can look at. Though one of the examples is a chat-bot, the other components in the AI UI kit demonstrate how to be transparent when showing AI-usage in an interface.Paste is looking for feedback on their AI UI kit–they have an open Github discussion where you can submit requests.It’s surprising how few design systems have released documentation on components and patterns to address AI-driven content and features (at least publicly). For instance, both Google and Microsoft are leaders in the AI industry, but open-source Material and Fluent design systems don’t include AI patterns.Since these AI leaders are integrating AI into common products a broader user group interacts with (like Gemini and Copilot), they’re establishing the user’s mental model that other products need to also adopt. Even Adobe’s Spectrum, who has integrated AI into many of their products (Adobe Firefly), only has a short blurb acknowledging machine learning and AI when it comes to content and writing about people.Maybe their AI patterns are still in development? Maybe they’re waiting to get it right?Either way, it’s valuable and crucial to identify AI features and generated content to users, so they can better understand what’s being shown to them, as well as trust the product. I’m looking forward to more design system patterns that go beyond the sparkle icon and the chat-bot.Stay tuned!",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*1u9YM2q3K7smIB0rilImbw.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"7fd4\"\u003e\u003cem\u003eUsers need more than a sparkle icon and chat-bot to designate embedded AI.\u003c/em\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://paschalallie.medium.com/?source=post_page---byline--ba9b6ba4761b---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Allie Paschal\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*fpy4J0gheIdnAy3snP-GRg.png\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--ba9b6ba4761b---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"65ec\"\u003eAs AI is integrated more and more throughout website and app experiences, it’s critical to distinguish where AI has been implemented from where it has not.\u003c/p\u003e\u003cp id=\"8f43\"\u003eInitially, most products introduced AI as a chat-bot where users initiated and facilitated their interaction with AI. Now, products are merging AI into dashboards, tasks, and search functions. Users are no longer initiating their experience with AI–it’s pre-existing.\u003c/p\u003e\u003cp id=\"bd0b\"\u003eSince users no longer control when they trigger usage of AI, users need to be made aware of when they’re shown AI features or content to determine its validity and quality. Not only that, the \u003ca href=\"https://www.euaiact.com/key-issue/5#:~:text=Under%20the%20EU%20AI%20Act,of%20that%20AI%20system%20and\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eEuropean Union AI Act\u003c/a\u003e (applicable in 2026) will enforce that users are made aware when they communicate or interact with an AI system.\u003c/p\u003e\u003cp id=\"091f\"\u003e\u003cstrong\u003eThis is where design systems come in–implementing specialized visual treatment to consistently separate AI content and features from non-AI content and features.\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://m3.material.io/components\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoogle’s Material\u003c/a\u003e design system documentation\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"141a\"\u003eUnfortunately, only a few open-source design systems have explicit AI components and patterns today. I’m hoping more will be incorporated soon, but so far, only GitLab’s Pajamas, IBM’s Carbon, and Twilio’s Paste acknowledge AI in their guidelines.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"170a\"\u003eNote: I use \u003ca href=\"https://www.designsystemsforfigma.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDesign Systems for Figma\u003c/a\u003e to benchmark AI components and patterns. I also did not include design systems that only include documentation for AI chat-bots or conversation design since it’s a more standard interaction pattern; this includes \u003ca href=\"https://cloudscape.design/components/genai-components\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAmazon’s Cloudscape\u003c/a\u003e and \u003ca href=\"https://www.lightningdesignsystem.com/2e1ef8501/p/65694b-conversation-design\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSalesforce’s Lightning\u003c/a\u003e.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"266a\"\u003eLet’s compare and contrast these design system AI components and patterns and see where they can be optimized for better usability.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2 id=\"4333\"\u003e1. GitLab’s Pajamas\u003c/h2\u003e\u003cp id=\"9e93\"\u003e\u003ca href=\"https://design.gitlab.com/usability/ai-human-interaction\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePajamas\u003c/a\u003e currently doesn’t include explicit components or patterns, but it does include interesting documentation about AI-human interactions. The documentation first recommends understanding if the usage of AI will actually benefit the user by identifying when it’s ethical and beneficial to automate (I.E., high-risk vs. low-risk tasks).\u003c/p\u003e\u003cp id=\"5f3e\"\u003e\u003cstrong\u003eNext, it recommends being transparent about where AI is used–Pajamas does this with its “GitLab Duo,” an indicator of AI-features, capabilities, and limitations.\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eGitLab Duo is used to indicate where the user can interact with AI in the interface\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"404a\"\u003eSince the “GitLab Duo” is used for AI-features and interactions (and not any AI content), Pajamas also recommends flagging AI-generated content with “\u0026lt;Verb\u0026gt; by AI” (I.E., “Summarized by AI”), as well as a message encouraging users to check the AI-content.\u003c/p\u003e\u003cp id=\"3627\"\u003eGitLab is also working on a framework to practice their guidelines; it’s currently in-progress, but the general work can be viewed in \u003ca href=\"https://gitlab.com/groups/gitlab-org/-/epics/10334\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGitLab’s AI UX Patterns\u003c/a\u003e. Their goal is to release an AI-pattern library with documentation–just what we need (pleaseee!).\u003c/p\u003e\u003cp id=\"bc40\"\u003eGitLab’s vision for their AI UX patterns is split into 4 dimensions to help select the right AI pattern: Mode, Approach, Interactivity, and Task.\u003c/p\u003e\u003cul\u003e\u003cli id=\"d90d\"\u003e\u003cstrong\u003eMode\u003c/strong\u003e: The emphasis of the AI-human interaction (focused, supportive, or integrated)\u003c/li\u003e\u003cli id=\"ebf5\"\u003e\u003cstrong\u003eApproach\u003c/strong\u003e: What the AI is improving (automate or augment tasks)\u003c/li\u003e\u003cli id=\"ca15\"\u003e\u003cstrong\u003eInteractivity\u003c/strong\u003e: How the AI engages with users (proactive or reactive)\u003c/li\u003e\u003cli id=\"0dac\"\u003e\u003cstrong\u003eTask\u003c/strong\u003e: What the AI system can help the user with (classification, generation, or prediction)\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"be22\"\u003eFor example, their early explorations for AI patterns include low-fidelity mockups of how AI can be integrated in an interface with charts or inline explanations. The patterns clearly mark the usage of AI to help build user understanding and trust with the AI system.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eLo-fi integrated chart with markers indicating AI, such as predicted data (via \u003c/em\u003e\u003ca href=\"https://www.youtube.com/watch?v=UXCz2xst_zg\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eGitLab’s Vision for AI UX\u003c/em\u003e\u003c/a\u003e\u003cem\u003e)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eLo-fi integrated explainer to fill out a form with AI (via \u003c/em\u003e\u003ca href=\"https://www.youtube.com/watch?v=UXCz2xst_zg\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eGitLab’s Vision for AI UX\u003c/em\u003e\u003c/a\u003e\u003cem\u003e)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"dae3\"\u003eVerdict\u003c/h2\u003e\u003cp id=\"5d2b\"\u003eCurrently, GitLab’s documentation is conceptual and generalized to how they want the AI UX experience to be like in the future. But it gives a solid framework that most design systems could adopt–no matter the industry or product.\u003c/p\u003e\u003cp id=\"4235\"\u003eI’m hopeful they release more in-depth information about their AI UX patterns soon. I think it could be a great open-source asset to other design systems developing their AI documentation.\u003c/p\u003e\u003ch2 id=\"2186\"\u003e2. IBM’s Carbon\u003c/h2\u003e\u003cp id=\"595b\"\u003eOut of the open-source design systems, \u003ca href=\"https://carbondesignsystem.com/guidelines/carbon-for-ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCarbon\u003c/a\u003e has the most robust documentation for AI usage. It includes an AI-dedicated section, “Carbon for AI,” which encompasses components, patterns, and guidelines to help users recognize AI-generated content and understand how AI is used in the product.\u003c/p\u003e\u003cp id=\"e44a\"\u003eCarbon for AI builds on top of the existing Carbon components–adding a blue glow and gradient to highlight instances of AI. So far, there are 12 components with AI variants, such as a modal, data table, and text input.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eCarbon for AI’s component list with specific AI variants\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"9eb5\"\u003e\u003cstrong\u003eThough the AI variants of the components are given a distinct visual treatment, in context, it’s difficult to distinguish which component is currently active\u003c/strong\u003e (because they all look active).\u003c/p\u003e\u003cp id=\"031b\"\u003eIn the below form, AI was used to auto-fill most of the input fields, so these fields use the AI-variants. The AI-variants receive a blue gradient and border even if it’s in a default state–making it hard to visually identify which component is active.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eThe blue gradient and border used on AI-components makes it hard to tell which component is active\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"763f\"\u003eUsers can override inputs made by AI, which will swap the AI-variant for the default-variant of the component. This will cause a “revert to AI input” action to replace the AI label in the input field–allowing users to control manual or automated form responses.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eCarbon’s “revert to AI input” function appears when users override AI-input\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"f731\"\u003eIn addition to the AI-variant, it includes an explicit AI label that can display a popover explaining the details of AI in the particular scenario (Carbon calls this pattern “AI explainability”). The user can select the AI label and the popover appears beneath the button.​​\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eCarbon’s AI label includes an explainer popover for the user to get more details on the usage of AI\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"bc60\"\u003eVerdict\u003c/h2\u003e\u003cp id=\"fd64\"\u003eIt’s exciting to see design system documentation on AI patterns and components that’s as well-developed as Carbon’s. Not only do they have documentation on the general usage of AI, but actually have components and patterns to use.\u003c/p\u003e\u003cp id=\"e2b0\"\u003eBut since the AI-variants of the components make it difficult to distinguish which component is active when used in-context, I think there are usability and accessibility issues. The AI-variants draw too much attention with the color usage, and also look like Carbon’s focus state (which could impact low-vision users reliant on the focus state).\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eCarbon’s AI-variant vs. focus state of the text field\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"1ac6\"\u003e3. Twilio’s Paste\u003c/h2\u003e\u003cp id=\"1941\"\u003eLastly, \u003ca href=\"https://paste.twilio.design/experiences/artificial-intelligence\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePaste\u003c/a\u003e offers an “Artificial Intelligence” section under their “Experiences” section. Paste includes general documentation on using AI in user experiences, as well as a few components to use.\u003c/p\u003e\u003cp id=\"7899\"\u003eWhen designing AI features, Paste recommends allowing users to compare AI outcomes to their current experiences, as well as handle potential errors and risks. To mitigate these errors, Paste advocates for giving the user the ability to review and undo outputs, control data sources, and give feedback to the AI system.\u003c/p\u003e\u003cp id=\"0018\"\u003e\u003cstrong\u003ePaste also suggests asking yourself, “How would I design this feature if it did the same thing but didn’t use AI?” when designing a new AI feature.\u003c/strong\u003e Users don’t use products just so they can interact with AI–they’re trying to complete tasks and achieve goals as efficiently as possible.\u003c/p\u003e\u003cp id=\"b15b\"\u003ePaste includes an AI UI kit with 5 components: artificial intelligence icon, badge, button, progress bar, and skeleton loader. It also includes components specific to their AI chat experience, such as the AI chat log.\u003c/p\u003e\u003cp id=\"f57a\"\u003eWhat’s most helpful in Paste’s documentation is the examples they provide. This includes signposting, generative features, and the chat.\u003c/p\u003e\u003cp id=\"e743\"\u003eFor signposting, Paste suggests using the decorative badge with the artificial intelligence icon to indicate a feature is using AI, such as AI recommendations or predictions. The signposting is non-interactive, but resembles a button, so it looks clickable.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003ePaste’s signposting example using a badge and AI icon\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"7e19\"\u003eThe generative feature gives users prompts to help them use the AI feature, such as “Summarize the data” or “Recommend the next step.” When you select the generative feature, a popover appears below giving the user instructions and what AI model it’s using.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003ePaste’s generative feature includes a button with a popover to instruct the user interacting with AI\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"4c75\"\u003eLastly, the chat is pretty typical of AI chat-bots known today, and includes references to their conversational principles to develop the AI’s personality.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003ePaste’s AI chat-bot with an empty state and prompts below the text field\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"73d4\"\u003ePaste does have another pattern coming soon with the loading pattern, but we’ll have to wait and see. This pattern will give users a way to control and anticipate the AI output; this includes stopping the output and adapting the state based on how long the AI output will take.\u003c/p\u003e\u003ch2 id=\"283f\"\u003eVerdict\u003c/h2\u003e\u003cp id=\"7e6b\"\u003eI’m happy to see a mixture of some documentation with real examples we can look at. Though one of the examples is a chat-bot, the other components in the AI UI kit demonstrate how to be transparent when showing AI-usage in an interface.\u003c/p\u003e\u003cp id=\"3cae\"\u003ePaste is looking for feedback on their AI UI kit–they have an open \u003ca href=\"https://github.com/twilio-labs/paste/discussions\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGithub discussion\u003c/a\u003e where you can submit requests.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"55a5\"\u003e\u003cstrong\u003eIt’s surprising how few design systems have released documentation on components and patterns to address AI-driven content and features\u003c/strong\u003e (at least publicly). For instance, both Google and Microsoft are leaders in the AI industry, but open-source Material and Fluent design systems don’t include AI patterns.\u003c/p\u003e\u003cp id=\"2367\"\u003eSince these AI leaders are integrating AI into common products a broader user group interacts with (like Gemini and Copilot), they’re establishing the user’s mental model that other products need to also adopt. Even \u003ca href=\"https://spectrum.adobe.com/page/writing-about-people/#Account-for-machine-learning-and-AI\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAdobe’s Spectrum\u003c/a\u003e, who has integrated AI into many of their products (Adobe Firefly), only has a short blurb acknowledging machine learning and AI when it comes to content and writing about people.\u003c/p\u003e\u003cp id=\"50ff\"\u003eMaybe their AI patterns are still in development? Maybe they’re waiting to get it right?\u003c/p\u003e\u003cp id=\"2168\"\u003eEither way, it’s valuable and crucial to identify AI features and generated content to users, so they can better understand what’s being shown to them, as well as trust the product. I’m looking forward to more design system patterns that go beyond the sparkle icon and the chat-bot.\u003c/p\u003e\u003cp id=\"6d35\"\u003eStay tuned!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-03-04T08:40:22.378Z",
  "modifiedTime": null
}
