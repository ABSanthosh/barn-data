{
  "id": "22e6e2c7-d016-435e-bd03-53fdfc0ff622",
  "title": "This is not a pipe: UX, AI, and the risk of satisficed product design",
  "link": "https://uxdesign.cc/this-is-not-a-pipe-ux-ai-and-the-risk-of-satisficed-product-design-89755c86869b?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Mike Schindler",
  "published": "Thu, 29 May 2025 11:46:30 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "product-design",
    "ai",
    "ux",
    "human-centered-design",
    "artificial-intelligence"
  ],
  "byline": "Mike Schindler",
  "length": 7123,
  "excerpt": "You know that old saying—a picture’s worth a thousand words? Well, a prototype is worth a million, especially if you’re a developer, a stakeholder, or a decision-maker trying to make sense of a…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "AI’s grip on design forces us to reconsider our role in shaping perception, reality, and—most importantly—decision-making.Image composed in Figma using AI-generated assets.I love a good prototype.You know that old saying—a picture’s worth a thousand words? Well, a prototype is worth a million, especially if you’re a developer, a stakeholder, or a decision-maker trying to make sense of a complex idea with a lot of moving parts.A prototype compresses context. It gives form to the abstract. It invites feedback for iteration and improvement. I’ve built them my whole career, and I still believe they’re the most powerful artifacts in product design.But I’m also starting to worry.The old daysBack in the early days of the web, I used to prototype in hand-coded HTML. Not because I loved code, but because I cared about quality. Browsers were unpredictable animals. Netscape and IE rendered the same markup in wildly different ways. The best we could do was chase consistency through hours of trial and error—hoping somehow that one of us would find and document the answer for the rest.Then Jeffrey Zeldman came along, armed with his famous pop culture wit and transparent brilliance, rallying the web community behind standards and semantic code. And it worked. Slowly, thankfully, the browser makers listened. We built better websites with better languages. HTML became standardized and meaningful under the hood.That was craft.Not just the mechanics of markup, but the intentionality behind it. Craft, to me, is thoughtful execution learned over time. It’s the subtle accumulation of experience, taste, and judgment. It’s a uniquely human achievement.The new nowFast forward to today, and we’re surrounded by tools promising instant output. AI is the new rallying cry, and its promise is both thrilling and disorienting.Tools like Lovable, Google Stitch, and Figma Make offer prototyping at the speed of thought. With a single prompt, we can summon UI layouts, component libraries, even entire interaction flows. It’s an addictive sort of magic. And in a product world driven by speed and iteration, this kind of acceleration is a godsend.But there’s something quietly unsettling about the ease of it all.Because with great speed comes great risk—perhaps to our users and to our own hard-won standards. And ironically, those who seem to value “craft” as the standard bearers of the current definition—forged exclusively in the conventional tooling of Figma—seem to be the loudest proponents of the new speed.René Magritte, The Treachery of Images (1929). Los Angeles County Museum of Art.This is not a pipeMagritte once painted a pipe and wrote underneath, “Ceci n’est pas une pipe”—This is not a pipe.He was right. It’s just a painting of a pipe, a representation, not the object itself. Postmodern thinkers wasted many French brain cells expanding on this idea, which eventually made its way into popular culture via The Matrix film franchise.In UX, we live and breathe representations. Wireframes, mockups, user flows, prototypes—they’re all stand-ins for future experiences. And yet, stakeholders and product teams often quickly treat them as the final product. The flow becomes the experience. The mockup becomes the truth.Add AI to the mix, and the illusion intensifies exponentially.When an AI-generated interface looks authentic and clickable, it’s dangerously easy to accept it at face value. But what if it’s based on flawed assumptions? What if it reflects patterns that don’t serve our users? What if it simply looks finished, when it’s not even close to holding real value?The risk of satisficingHerbert Simon had a made-up word for this kind of decision-making: satisficing. A blend of “satisfy” and “suffice.” It means settling for a good-enough solution when the perfect one is too costly or too far out of reach.In AI-generated design, satisficing isn’t just a risk—it’s the default.The algorithm gives us something that looks fine, behaves fine, and maybe even tests fine. And in the absence of the right checkpoints for critical thought, we’re liable to ship it. Not because it’s right, but because it’s fast and frictionless.And that worries me.Because over time, we get complacent and stuck in our comfort zones. When that happens, design becomes more template-driven. Interfaces lose connectivity to the humans they’re supposed to serve. And worst of all, we stop asking why.Diagram inspired by Herbert Simon’s model of bounded rationality. Created by author.Shifting times (and how we respond)Now, there’s nothing inherently wrong about satisficed decision making. In fact, Simon viewed the term practically—recognizing that humans, limited in time, knowledge, and processing capacity, operate within what he called a “bounded rationality.”In agile product design, this is the whole point of an MVP.The problem arises when we’re out of sync with one another, when one discipline overrides the other with disregard, deciding that something is “good enough” without considering the wider trade offs.The optimist in me wants to believe we’re well-suited and prepared for this inevitability.I’m currently one of those displaced knowledge workers, looking for my next opportunity in UX / Product Design. I’ve seen the shift from using the term UX Designer to Product Designer in the job descriptions. Leaving the organizational debates and the shameful clickbait aside, this shift seems to signal a natural evolution—traditional UX design roles are moving deeper into product delivery.But if design and product are becoming equal partners in the organizational chart, then our collective vision should be to make decisions together, without being a consensus machine. That means mapping out our processes and synthesizing data into rational decisions within a new bounded reality—one that’s accelerated from the start.Because the point isn’t to eliminate satisficing. It’s to make it conscious, collaborative, and aligned. UX and design professionals need to be embedded in the conversation—not just reacting to outputs, but helping frame the questions and the goals. Otherwise, speed wins by default—leaving craft, context, and care lost in the latest sprint.The new frontierI’m not anti-AI. Quite the opposite. I’m genuinely excited about what these tools can unlock—especially in early design stages, where low fidelity and high experimentation are crucial. We should be moving faster. We should be looking at and testing more ideas. We should be using AI to remove blockers and free up energy for deeper thinking.But we also need to stay alert. We need to protect the human-centered insights and the basic fundamentals of context and critical thought that live outside the models.We can’t let the ease of generation become a substitute for our better judgment. We can’t let groupthink dictate taste. We can’t let empathy get stripped from the process just because the output looks like a viable product to the loudest person in the room.As designers, our job is not just to create. It’s to question. To inform. To shape. To provoke. To guide.And sometimes, to remind the team… This is not a pipe.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*z4h6LS_Kp27x83iW-dUjhg.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"33ea\"\u003eAI’s grip on design forces us to reconsider our role in shaping perception, reality, and—most importantly—decision-making.\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@mschindler?source=post_page---byline--89755c86869b---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Mike Schindler\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*Oo3S32Y2BwsUKXKOLqucYA@2x.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003e\u003cfigure\u003e\u003cpicture\u003e\u003csource srcset=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:4800/format:webp/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 4800w\" sizes=\"(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 100vw\" type=\"image/webp\"/\u003e\u003csource data-testid=\"og\" srcset=\"https://miro.medium.com/v2/resize:fit:640/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:4800/1*z4h6LS_Kp27x83iW-dUjhg.jpeg 4800w\" sizes=\"(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 100vw\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eImage composed in Figma using AI-generated assets.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/p\u003e\u003cdiv\u003e\u003cp id=\"6d35\"\u003e\u003cstrong\u003eI love a good prototype.\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"40b1\"\u003eYou know that old saying—a picture’s worth a thousand words? Well, a prototype is worth a million, especially if you’re a developer, a stakeholder, or a decision-maker trying to make sense of a complex idea with a lot of moving parts.\u003c/p\u003e\u003cp id=\"5cad\"\u003eA prototype compresses context. It gives form to the abstract. It invites feedback for iteration and improvement. I’ve built them my whole career, and I still believe they’re the most powerful artifacts in product design.\u003c/p\u003e\u003cp id=\"0dc4\"\u003eBut I’m also starting to worry.\u003c/p\u003e\u003ch2 id=\"949b\"\u003eThe old days\u003c/h2\u003e\u003cp id=\"0af3\"\u003eBack in the early days of the web, I used to prototype in hand-coded HTML. Not because I loved code, but because I cared about quality. Browsers were unpredictable animals. Netscape and IE rendered the same markup in wildly different ways. The best we could do was chase consistency through hours of trial and error—hoping somehow that one of us would find and document the answer for the rest.\u003c/p\u003e\u003cp id=\"5514\"\u003eThen \u003ca href=\"https://zeldman.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJeffrey Zeldman\u003c/a\u003e came along, armed with his famous pop culture wit and transparent brilliance, rallying the web community behind standards and semantic code. And it worked. Slowly, thankfully, the browser makers listened. We built better websites with better languages. HTML became standardized and meaningful under the hood.\u003c/p\u003e\u003cp id=\"22ed\"\u003eThat was craft.\u003c/p\u003e\u003cp id=\"80f6\"\u003eNot just the mechanics of markup, but the intentionality behind it. Craft, to me, is thoughtful execution learned over time. It’s the subtle accumulation of experience, taste, and judgment. It’s a uniquely human achievement.\u003c/p\u003e\u003ch2 id=\"44d9\"\u003eThe new now\u003c/h2\u003e\u003cp id=\"7040\"\u003eFast forward to today, and we’re surrounded by tools promising instant output. AI is the new rallying cry, and its promise is both thrilling and disorienting.\u003c/p\u003e\u003cp id=\"aabc\"\u003eTools like \u003ca href=\"https://lovable.dev/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLovable\u003c/a\u003e, \u003ca href=\"https://stitch.withgoogle.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoogle Stitch\u003c/a\u003e, and \u003ca href=\"https://www.figma.com/make/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFigma Make\u003c/a\u003e offer prototyping at the speed of thought. With a single prompt, we can summon UI layouts, component libraries, even entire interaction flows. It’s an addictive sort of magic. And in a product world driven by speed and iteration, this kind of acceleration is a godsend.\u003c/p\u003e\u003cp id=\"329f\"\u003eBut there’s something quietly unsettling about the ease of it all.\u003c/p\u003e\u003cp id=\"f763\"\u003eBecause with great speed comes great risk—perhaps to our users and to our own hard-won standards. And ironically, those who seem to value “craft” as the standard bearers of the current definition—forged exclusively in the conventional tooling of Figma—seem to be the loudest proponents of the new speed.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eRené Magritte, The Treachery of Images (1929). Los Angeles County Museum of Art.\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"5d31\"\u003eThis is not a pipe\u003c/h2\u003e\u003cp id=\"4d19\"\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Ren%C3%A9_Magritte\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMagritte\u003c/a\u003e once painted a pipe and wrote underneath, “Ceci n’est pas une pipe”—\u003cem\u003eThis is not a pipe.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"ac2f\"\u003eHe was right. It’s just a painting of a pipe, a representation, not the object itself. Postmodern thinkers wasted many French brain cells expanding on this idea, which eventually made its way into popular culture via \u003cem\u003eThe Matrix\u003c/em\u003e film franchise.\u003c/p\u003e\u003cp id=\"19e1\"\u003eIn UX, we live and breathe representations. Wireframes, mockups, user flows, prototypes—they’re all stand-ins for future experiences. And yet, stakeholders and product teams often quickly treat them as the final product. The flow becomes the experience. The mockup becomes the truth.\u003c/p\u003e\u003cp id=\"eedc\"\u003eAdd AI to the mix, and the illusion intensifies exponentially.\u003c/p\u003e\u003cp id=\"3565\"\u003eWhen an AI-generated interface looks authentic and clickable, it’s dangerously easy to accept it at face value. But what if it’s based on flawed assumptions? What if it reflects patterns that don’t serve our users? What if it simply looks finished, when it’s not even close to holding real value?\u003c/p\u003e\u003ch2 id=\"ed26\"\u003eThe risk of satisficing\u003c/h2\u003e\u003cp id=\"1de2\"\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Herbert_A._Simon\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHerbert Simon\u003c/a\u003e had a made-up word for this kind of decision-making: \u003cem\u003esatisficing.\u003c/em\u003e A blend of “satisfy” and “suffice.” It means settling for a good-enough solution when the perfect one is too costly or too far out of reach.\u003c/p\u003e\u003cp id=\"98c2\"\u003eIn AI-generated design, satisficing isn’t just a risk—it’s the default.\u003c/p\u003e\u003cp id=\"f7ed\"\u003eThe algorithm gives us something that looks fine, behaves fine, and maybe even tests fine. And in the absence of the right checkpoints for critical thought, we’re liable to ship it. Not because it’s \u003cem\u003eright,\u003c/em\u003e but because it’s fast and frictionless.\u003c/p\u003e\u003cp id=\"5c11\"\u003eAnd that worries me.\u003c/p\u003e\u003cp id=\"84dc\"\u003eBecause over time, we get complacent and stuck in our comfort zones. When that happens, design becomes more template-driven. Interfaces lose connectivity to the humans they’re supposed to serve. And worst of all, we stop asking \u003cem\u003ewhy.\u003c/em\u003e\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eDiagram inspired by Herbert Simon’s model of bounded rationality. Created by author.\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"5610\"\u003eShifting times (and how we respond)\u003c/h2\u003e\u003cp id=\"ae84\"\u003eNow, there’s nothing inherently wrong about satisficed decision making. In fact, Simon viewed the term practically—recognizing that humans, limited in time, knowledge, and processing capacity, operate within what he called a “bounded rationality.”\u003c/p\u003e\u003cp id=\"f63c\"\u003eIn agile product design, this is the whole point of an MVP.\u003c/p\u003e\u003cp id=\"8490\"\u003eThe problem arises when we’re out of sync with one another, when one discipline overrides the other with disregard, deciding that something is “\u003ca href=\"https://thedecisionlab.com/biases/bounded-rationality\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003egood enough\u003c/a\u003e” without considering the wider trade offs.\u003c/p\u003e\u003cp id=\"b767\"\u003eThe optimist in me wants to believe we’re well-suited and prepared for this inevitability.\u003c/p\u003e\u003cp id=\"595e\"\u003eI’m currently one of those displaced knowledge workers, looking for my next opportunity in UX / Product Design. I’ve seen the shift from using the term \u003cem\u003eUX Designer\u003c/em\u003e to \u003cem\u003eProduct Designer\u003c/em\u003e in the job descriptions. Leaving the organizational debates and the \u003ca href=\"https://www.dive.club/deep-dives/mig-reyes\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eshameful clickbait\u003c/a\u003e aside, this shift seems to signal a natural evolution—traditional UX design roles are moving deeper into product delivery.\u003c/p\u003e\u003cp id=\"2e35\"\u003eBut if design and product are becoming equal partners in the organizational chart, then our collective vision should be to make decisions together, without being a consensus machine. That means mapping out our processes and synthesizing data into rational decisions within a new bounded reality—one that’s accelerated from the start.\u003c/p\u003e\u003cp id=\"019a\"\u003eBecause the point isn’t to eliminate satisficing. It’s to \u003cstrong\u003emake it conscious, collaborative, and aligned\u003c/strong\u003e. UX and design professionals need to be embedded in the conversation—not just reacting to outputs, but helping frame the questions and the goals. Otherwise, speed wins by default—leaving craft, context, and care lost in the latest sprint.\u003c/p\u003e\u003ch2 id=\"fdca\"\u003eThe new frontier\u003c/h2\u003e\u003cp id=\"de84\"\u003eI’m not anti-AI. Quite the opposite. I’m genuinely excited about what these tools can unlock—especially in early design stages, where low fidelity and high experimentation are crucial. We \u003cem\u003eshould\u003c/em\u003e be moving faster. We \u003cem\u003eshould\u003c/em\u003e be looking at and testing more ideas. We \u003cem\u003eshould\u003c/em\u003e be using AI to remove blockers and free up energy for deeper thinking.\u003c/p\u003e\u003cp id=\"d2db\"\u003eBut we also need to stay alert. We need to protect the human-centered insights and the basic fundamentals of context and critical thought that live outside the models.\u003c/p\u003e\u003cp id=\"aafa\"\u003eWe can’t let the ease of generation become a substitute for our better judgment. We can’t let groupthink dictate taste. We can’t let \u003ca href=\"https://www.fastcompany.com/91339560/empathy-core-strength-philosophy\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eempathy\u003c/a\u003e get stripped from the process just because the output looks like a viable product to the loudest person in the room.\u003c/p\u003e\u003cp id=\"0107\"\u003eAs designers, our job is not just to create. It’s to question. To inform. To shape. To provoke. To guide.\u003c/p\u003e\u003cp id=\"6b4e\"\u003eAnd sometimes, to remind the team… \u003cem\u003eThis is not a pipe.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-05-29T11:46:30.13Z",
  "modifiedTime": null
}
