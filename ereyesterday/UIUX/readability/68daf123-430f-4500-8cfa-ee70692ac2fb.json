{
  "id": "68daf123-430f-4500-8cfa-ee70692ac2fb",
  "title": "How To Argue Against AI-First Research",
  "link": "https://smashingmagazine.com/2025/03/how-to-argue-against-ai-first-research/",
  "description": "Companies have been turning their attention to “synthetic,” AI-driven user testing. However, as convenient as it might seem, it’s dangerous, expensive, and usually diminishes user value. Let’s take a closer look at why exactly it is problematic and how we can argue against it to make a case for UX research with real users. Part of [Smart Interface Design Patterns](https://smart-interface-design-patterns.com) by yours truly.",
  "author": "Vitaly Friedman",
  "published": "Fri, 28 Mar 2025 09:00:00 GMT",
  "source": "https://www.smashingmagazine.com/feed",
  "categories": null,
  "byline": "About The Author",
  "length": 7743,
  "excerpt": "Companies have been turning their attention to “synthetic,” AI-driven user testing. However, as convenient as it might seem, it’s dangerous, expensive, and usually diminishes user value. Let’s take a closer look at why exactly it is problematic and how we can argue against it to make a case for UX research with real users. Part of [Smart Interface Design Patterns](https://smart-interface-design-patterns.com) by yours truly.",
  "siteName": "Smashing Magazine",
  "favicon": "https://smashingmagazine.com/images/favicon/apple-touch-icon.png",
  "text": "6 min readDesign, UXCompanies have been turning their attention to “synthetic,” AI-driven user testing. However, as convenient as it might seem, it’s dangerous, expensive, and usually diminishes user value. Let’s take a closer look at why exactly it is problematic and how we can argue against it to make a case for UX research with real users. Part of Smart Interface Design Patterns by yours truly.With AI upon us, companies have recently been turning their attention to “synthetic” user testing — AI-driven research that replaces UX research. There, questions are answered by AI-generated “customers,” human tasks “performed” by AI agents.However, it’s not just for desk research or discovery that AI is used for; it’s an actual usability testing with “AI personas” that mimic human behavior of actual customers within the actual product. It’s like UX research, just… well, without the users.One of the tools to conduct “synthetic testing,” or AI-generated UX research, without users. (Source: Synthetic Users) (Large preview)If this sounds worrying, confusing, and outlandish, it is — but this doesn’t stop companies from adopting AI “research” to drive business decisions. Although, unsurprisingly, the undertaking can be dangerous, risky, and expensive and usually diminishes user value.This article is part of our ongoing series on UX. You can find more details on design patterns and UX strategy in Smart Interface Design Patterns 🍣 — with live UX training coming up soon. Free preview.Fast, Cheap, Easy… And ImaginaryErika Hall famously noted that “design is only as ‘human-centered’ as the business model allows.” If a company is heavily driven by hunches, assumptions, and strong opinions, there will be little to no interest in properly-done UX research in the first place.The opportunity for business value is in delivering user value when users struggle. By Erika Hall. (Large preview)But unlike UX research, AI research (conveniently called synthetic testing) is fast, cheap, and easy to re-run. It doesn’t raise uncomfortable questions, and it doesn’t flag wrong assumptions. It doesn’t require user recruitment, much time, or long-winded debates.And: it can manage thousands of AI personas at once. By studying AI-generated output, we can discover common journeys, navigation patterns, and common expectations. We can anticipate how people behave and what they would do.Well, that’s the big promise. And that’s where we start running into big problems.LLMs Are People PleasersGood UX research has roots in what actually happened, not what might have happened or what might happen in the future.By nature, LLMs are trained to provide the most “plausible” or most likely output based on patterns captured in its training data. These patterns, however, emerge from expected behaviors by statistically “average” profiles extracted from content on the web. But these people don’t exist, they never have.By default, user segments are not scoped and not curated. They don’t represent the customer base of any product. So to be useful, we must eloquently prompt AI by explaining who users are, what they do, and how they behave. Otherwise, the output won’t match user needs and won’t apply to our users.Every LLM hallucinates, but newer models perform better at some tasks, such as summarizing. By Nature.com. (Large preview)When “producing” user insights, LLMs can’t generate unexpected things beyond what we’re already asking about.In comparison, researchers are only able to define what’s relevant as the process unfolds. In actual user testing, insights can help shift priorities or radically reimagine the problem we’re trying to solve, as well as potential business outcomes.Real insights come from unexpected behavior, from reading behavioral clues and emotions, from observing a person doing the opposite of what they said. We can’t replicate it with LLMs.AI User Research Isn’t “Better Than Nothing”Pavel Samsonov articulates that things that sound like customers might say them are worthless. But things that customers actually have said, done, or experienced carry inherent value (although they could be exaggerated). We just need to interpret them correctly.AI user research isn’t “better than nothing” or “more effective.” It creates an illusion of customer experiences that never happened and are at best good guesses but at worst misleading and non-applicable. Relying on AI-generated “insights” alone isn’t much different than reading tea leaves.The Cost Of Mechanical DecisionsWe often hear about the breakthrough of automation and knowledge generation with AI. Yet we often forget that automation often comes at a cost: the cost of mechanical decisions that are typically indiscriminate, favor uniformity, and erode quality.Some research questions generated by AI could be useful, others useless. By Maria Rosala. (Large preview)As Maria Rosala and Kate Moran write, the problem with AI research is that it most certainly will be misrepresentative, and without real research, you won't catch and correct those inaccuracies. Making decisions without talking to real customers is dangerous, harmful, and expensive.Beyond that, synthetic testing assumes that people fit in well-defined boxes, which is rarely true. Human behavior is shaped by our experiences, situations, habits that can’t be replicated by text generation alone. AI strengthens biases, supports hunches, and amplifies stereotypes.Triangulate Insights Instead Of Verifying ThemOf course AI can provide useful starting points to explore early in the process. But inherently it also invites false impressions and unverified conclusions — presented with an incredible level of confidence and certainty.Starting with human research conducted with real customers using a real product is just much more reliable. After doing so, we can still apply AI to see if we perhaps missed something critical in user interviews. AI can enhance but not replace UX research.Triangluate linear customer journeys by layering them on top of each other to identify the most frequent areas of use. By John Cutler. (Large preview)Also, when we do use AI for desk research, it can be tempting to try to “validate” AI “insights” with actual user testing. However, once we plant a seed of insight in our head, it’s easy to recognize its signs everywhere — even if it really isn’t there.Instead, we study actual customers, then triangulate data: track clusters or most heavily trafficked parts of the product. It might be that analytics and AI desk research confirm your hypothesis. That would give you a much stronger standing to move forward in the process.Wrapping UpI might sound like a broken record, but I keep wondering why we feel the urgency to replace UX work with automated AI tools. Good design requires a good amount of critical thinking, observation, and planning.To me personally, cleaning up after AI-generated output takes way more time than doing the actual work. There is an incredible value in talking to people who actually use your product.I would always choose one day with a real customer instead of one hour with 1,000 synthetic users pretending to be humans.Useful ResourcesSynthetic Users, by Maria Rosala, Kate MoranSynthetic Users: The Next Revolution in UX Research?, by Carolina GuimarãesAI Users Are Neither AI Nor Users, by Debbie LevittPlanning Research with Generative AI, by Maria RosalaSynthetic Testing, by Stéphanie Walter, Nikki Anderson, MAThe Dark Side of Synthetic AI Research, by Greg NudelmanNew: How To Measure UX And Design ImpactMeet Measure UX \u0026 Design Impact (8h), a new practical guide for designers and UX leads to measure and show your UX impact on business. Use the code 🎟 IMPACT to save 20% off today. Jump to the details. (cm)",
  "image": "https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article__content\"\u003e\u003cul\u003e\u003cli\u003e6 min read\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://smashingmagazine.com/category/design\"\u003eDesign\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/ux\"\u003eUX\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003csection aria-label=\"Quick summary\"\u003eCompanies have been turning their attention to “synthetic,” AI-driven user testing. However, as convenient as it might seem, it’s dangerous, expensive, and usually diminishes user value. Let’s take a closer look at why exactly it is problematic and how we can argue against it to make a case for UX research with real users. Part of \u003ca href=\"https://smart-interface-design-patterns.com\"\u003eSmart Interface Design Patterns\u003c/a\u003e by yours truly.\u003c/section\u003e\u003c/p\u003e\u003cp\u003eWith AI upon us, companies have recently been turning their attention to \u003cstrong\u003e“synthetic” user testing\u003c/strong\u003e — AI-driven research that replaces UX research. There, questions are answered by AI-generated “customers,” human tasks “performed” by AI agents.\u003c/p\u003e\u003cp\u003eHowever, it’s not just for desk research or discovery that AI is used for; it’s an \u003cem\u003eactual\u003c/em\u003e usability testing with “AI personas” that \u003cstrong\u003emimic human behavior\u003c/strong\u003e of actual customers within the actual product. It’s like UX research, just… well, without the users.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.syntheticusers.com/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"499\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png\" sizes=\"100vw\" alt=\"One of the tools to conduct synthetic testing, or AI-generated UX research, without users.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eOne of the tools to conduct “synthetic testing,” or AI-generated UX research, without users. (Source: \u003ca href=\"https://www.syntheticusers.com/\"\u003eSynthetic Users\u003c/a\u003e) (\u003ca href=\"https://files.smashing.media/articles/how-to-argue-against-ai-first-research/user-research-without-users-opt.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIf this sounds worrying, confusing, and outlandish, it is — but this doesn’t stop companies from adopting AI “research” to drive business decisions. Although, unsurprisingly, the undertaking can be \u003cstrong\u003edangerous, risky\u003c/strong\u003e, and expensive and usually diminishes user value.\u003c/p\u003e\u003cp\u003eThis article is \u003cstrong\u003epart of our ongoing series\u003c/strong\u003e on \u003ca href=\"https://smashingmagazine.com/category/ux\"\u003eUX\u003c/a\u003e. You can find more details on \u003cstrong\u003edesign patterns and UX strategy\u003c/strong\u003e in \u003ca href=\"https://smart-interface-design-patterns.com/\"\u003eSmart Interface Design Patterns\u003c/a\u003e 🍣 — with live UX training coming up soon. \u003ca href=\"https://www.youtube.com/watch?v=jhZ3el3n-u0\"\u003eFree preview\u003c/a\u003e.\u003c/p\u003e\u003ch2\u003eFast, Cheap, Easy… And Imaginary\u003c/h2\u003e\u003cp\u003eErika Hall \u003ca href=\"https://medium.com/mule-design/a-three-part-plan-to-save-the-world-98653a20a12f\"\u003efamously noted\u003c/a\u003e that “design is only as ‘human-centered’ as the business model allows.” If a company is heavily driven by \u003cstrong\u003ehunches, assumptions, and strong opinions\u003c/strong\u003e, there will be little to no interest in properly-done UX research in the first place.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://medium.com/mule-design/a-three-part-plan-to-save-the-world-98653a20a12f\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"450\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png\" sizes=\"100vw\" alt=\"The opportunity for business value is in delivering user value when users struggle.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eThe opportunity for business value is in delivering user value when users struggle. By \u003ca href=\"https://medium.com/mule-design/a-three-part-plan-to-save-the-world-98653a20a12f\"\u003eErika Hall\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/how-to-argue-against-ai-first-research/value-exchange-opt.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBut unlike UX research, AI research (conveniently called \u003cem\u003esynthetic testing\u003c/em\u003e) is \u003cstrong\u003efast, cheap, and easy\u003c/strong\u003e to re-run. It doesn’t raise uncomfortable questions, and it doesn’t flag wrong assumptions. It doesn’t require user recruitment, much time, or long-winded debates.\u003c/p\u003e\u003cp\u003eAnd: it can manage \u003cstrong\u003ethousands of AI personas\u003c/strong\u003e at once. By studying AI-generated output, we can discover common journeys, navigation patterns, and common expectations. We can anticipate how people behave and what they would do.\u003c/p\u003e\u003cp\u003eWell, that’s the \u003cstrong\u003ebig promise\u003c/strong\u003e. And that’s where we start running into big problems.\u003c/p\u003e\u003ch2\u003eLLMs Are People Pleasers\u003c/h2\u003e\u003cp\u003eGood UX research has roots in \u003cstrong\u003ewhat actually happened\u003c/strong\u003e, not what \u003cem\u003emight\u003c/em\u003e have happened or what \u003cem\u003emight\u003c/em\u003e happen in the future.\u003c/p\u003e\u003cp\u003eBy nature, LLMs are trained to provide the most “\u003cstrong\u003eplausible\u003c/strong\u003e” or most likely output based on patterns captured in its training data. These patterns, however, emerge from expected behaviors by statistically “average” profiles extracted from content on the web. But these people don’t exist, they never have.\u003c/p\u003e\u003cp\u003eBy default, user segments are \u003cstrong\u003enot scoped and not curated\u003c/strong\u003e. They don’t represent the customer base of any product. So to be useful, we must eloquently prompt AI by explaining who users are, what they do, and how they behave. Otherwise, the output won’t match user needs and won’t apply to our users.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.nature.com/articles/d41586-025-00068-5\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"597\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png\" sizes=\"100vw\" alt=\"Every LLM hallucinates, but newer models perform better at some tasks, such as summarizing.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eEvery LLM hallucinates, but newer models perform better at some tasks, such as summarizing. By \u003ca href=\"https://www.nature.com/articles/d41586-025-00068-5\"\u003eNature.com\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/how-to-argue-against-ai-first-research/hallucination-opt.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWhen “producing” user insights, LLMs \u003ca href=\"https://www.ideo.com/journal/the-case-against-ai-generated-users\"\u003ecan’t generate unexpected things\u003c/a\u003e beyond what we’re already asking about.\u003c/p\u003e\u003cp\u003eIn comparison, researchers are only able to define what’s relevant as the process unfolds. In actual user testing, insights can help \u003cstrong\u003eshift priorities\u003c/strong\u003e or radically reimagine the problem we’re trying to solve, as well as potential business outcomes.\u003c/p\u003e\u003cp\u003eReal insights come from \u003cstrong\u003eunexpected behavior\u003c/strong\u003e, from reading behavioral clues and emotions, from observing a person doing the opposite of what they said. We can’t replicate it with LLMs.\u003c/p\u003e\u003ch2\u003eAI User Research Isn’t “Better Than Nothing”\u003c/h2\u003e\u003cp\u003ePavel Samsonov \u003ca href=\"https://uxdesign.cc/no-ai-user-research-is-not-better-than-nothing-its-much-worse-5add678ab9e7\"\u003earticulates\u003c/a\u003e that things that sound like customers \u003cem\u003emight\u003c/em\u003e say them are \u003cstrong\u003eworthless\u003c/strong\u003e. But things that customers \u003cem\u003eactually\u003c/em\u003e have said, done, or experienced carry inherent value (although they could be exaggerated). We just need to interpret them correctly.\u003c/p\u003e\u003cp\u003eAI user research isn’t “better than nothing” or “more effective.” It creates an \u003cstrong\u003eillusion of customer experiences\u003c/strong\u003e that never happened and are at best good guesses but at worst misleading and non-applicable. Relying on AI-generated “insights” alone isn’t much different than reading tea leaves.\u003c/p\u003e\u003ch2\u003eThe Cost Of Mechanical Decisions\u003c/h2\u003e\u003cp\u003eWe often hear about the breakthrough of automation and knowledge generation with AI. Yet we often forget that automation often comes at a cost: the cost of mechanical decisions that are typically \u003cstrong\u003eindiscriminate\u003c/strong\u003e, favor uniformity, and erode quality.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.nngroup.com/articles/plan-research-ai/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"874\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png\" sizes=\"100vw\" alt=\"Some research questions generated by AI could be useful, others useless.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eSome research questions generated by AI could be useful, others useless. By \u003ca href=\"https://www.nngroup.com/articles/plan-research-ai/\"\u003eMaria Rosala\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/how-to-argue-against-ai-first-research/ai-prompt-research-questions-opt.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAs Maria Rosala and Kate Moran \u003ca href=\"https://www.nngroup.com/articles/synthetic-users/\"\u003ewrite\u003c/a\u003e, the problem with AI research is that it most certainly will be \u003cstrong\u003emisrepresentative\u003c/strong\u003e, and without real research, you won\u0026#39;t catch and correct those inaccuracies. Making decisions without talking to real customers is dangerous, harmful, and expensive.\u003c/p\u003e\u003cp\u003eBeyond that, synthetic testing assumes that people fit in well-defined boxes, which is rarely true. Human behavior is shaped by our experiences, situations, habits that can’t be replicated by text generation alone. AI \u003cstrong\u003estrengthens biases, supports hunches\u003c/strong\u003e, and amplifies stereotypes.\u003c/p\u003e\u003ch2\u003eTriangulate Insights Instead Of Verifying Them\u003c/h2\u003e\u003cp\u003eOf course AI can provide \u003cstrong\u003euseful starting points\u003c/strong\u003e to explore early in the process. But inherently it also invites false impressions and unverified conclusions — presented with an incredible level of confidence and certainty.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStarting with human research\u003c/strong\u003e conducted with real customers using a real product is just much more reliable. After doing so, we can still apply AI to see if we perhaps missed something critical in user interviews. AI can enhance but not replace UX research.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.linkedin.com/posts/johnpcutler_whenever-i-see-a-linear-customer-journey-activity-7288764384380624896-P_j6/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"451\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png\" sizes=\"100vw\" alt=\"Triangluate linear customer journeys by layering them on top of each other to identify the most frequent areas of use.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eTriangluate linear customer journeys by layering them on top of each other to identify the most frequent areas of use. By \u003ca href=\"https://www.linkedin.com/posts/johnpcutler_whenever-i-see-a-linear-customer-journey-activity-7288764384380624896-P_j6/\"\u003eJohn Cutler\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/how-to-argue-against-ai-first-research/layering-customer-journeys-opt.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eAlso, when we do use AI for desk research, it can be tempting to try to “\u003cstrong\u003evalidate\u003c/strong\u003e” AI “insights” with actual user testing. However, once we plant a seed of insight in our head, it’s easy to recognize its signs everywhere — even if it really isn’t there.\u003c/p\u003e\u003cp\u003eInstead, we study actual customers, then \u003cstrong\u003etriangulate data\u003c/strong\u003e: track clusters or most heavily trafficked parts of the product. It might be that analytics and AI desk research confirm your hypothesis. That would give you a much stronger standing to move forward in the process.\u003c/p\u003e\u003ch2\u003eWrapping Up\u003c/h2\u003e\u003cp\u003eI might sound like a broken record, but I keep wondering why we feel the urgency to replace UX work with automated AI tools. Good design requires a good amount of \u003cstrong\u003ecritical thinking\u003c/strong\u003e, observation, and planning.\u003c/p\u003e\u003cp\u003eTo me personally, cleaning up after AI-generated output takes way more time than doing the actual work. There is an \u003cstrong\u003eincredible value\u003c/strong\u003e in talking to people who actually use your product.\u003c/p\u003e\u003cp\u003eI would always choose one day with a real customer instead of one hour with 1,000 synthetic users pretending to be humans.\u003c/p\u003e\u003ch2\u003eUseful Resources\u003c/h2\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://www.nngroup.com/articles/synthetic-users/\"\u003eSynthetic Users\u003c/a\u003e, by Maria Rosala, Kate Moran\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://uxdesign.cc/synthetic-users-the-next-revolution-in-ux-research-0d43f7111e7f?sk=v2%2F05a1bb3c-4312-4665-bc5f-06339bbb609e\"\u003eSynthetic Users: The Next Revolution in UX Research?\u003c/a\u003e, by Carolina Guimarães\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://rbefored.com/ai-users-are-neither-ai-nor-users-c701f32fbbc4\"\u003eAI Users Are Neither AI Nor Users\u003c/a\u003e, by Debbie Levitt\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.nngroup.com/articles/plan-research-ai/\"\u003ePlanning Research with Generative AI\u003c/a\u003e, by Maria Rosala\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://blog.uxtweak.com/artificial-participants-and-ai-generated-responses/\"\u003eSynthetic Testing\u003c/a\u003e, by Stéphanie Walter, Nikki Anderson, MA\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.uxforai.com/p/navigating-the-abyss-the-dark-side-of-synthetic-ai-user-research-tools\"\u003eThe Dark Side of Synthetic AI Research\u003c/a\u003e, by Greg Nudelman\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003eNew: How To Measure UX And Design Impact\u003c/h2\u003e\u003cp\u003eMeet Measure UX \u0026amp; Design Impact (8h), a new practical guide for designers and UX leads to measure and show your UX impact on business. Use the code 🎟 \u003ccode\u003eIMPACT\u003c/code\u003e to save 20% off today. \u003ca href=\"https://measure-ux.com/\"\u003eJump to the details\u003c/a\u003e.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://measure-ux.com/\" title=\"How To Measure UX and Design Impact, with Vitaly Friedman\"\u003e\u003cimg width=\"900\" height=\"466\" src=\"https://files.smashing.media/articles/ux-metrics-video-course-release/measure-ux-and-design-impact-course.png\" alt=\"How to Measure UX and Design Impact, with Vitaly Friedman.\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003e\u003cimg src=\"https://www.smashingmagazine.com/images/logo/logo--red.png\" alt=\"Smashing Editorial\" width=\"35\" height=\"46\" loading=\"lazy\" decoding=\"async\"/\u003e\n\u003cspan\u003e(cm)\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-03-28T09:00:00Z",
  "modifiedTime": "2025-03-28T09:00:00Z"
}
