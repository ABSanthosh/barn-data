{
  "id": "2d6251e7-f819-4a57-8786-f27153b2f21c",
  "title": "Treating AI Agents as personas",
  "link": "https://uxdesign.cc/treating-ai-agents-as-personas-6ef0135bdcad?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Paz Perez",
  "published": "Tue, 05 Nov 2024 19:22:12 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "artificial-intelligence",
    "ux",
    "product-design",
    "ai",
    "generative-ai"
  ],
  "byline": "Paz Perez",
  "length": 10306,
  "excerpt": "While the UX community has quickly embraced Large Language Models as design tools, we’ve largely overlooked their more profound implications. Now, as AI agents become integrated throughout our…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Introducing the Agent Computer Interaction era.While the UX community has quickly embraced Large Language Models as design tools, we’ve largely overlooked their more profound implications. Now, as AI agents become integrated throughout our digital products, we face a fundamental transformation: these systems are evolving from tools into active participants in our digital environments, and we need to design for them.AI agents are emerging as a new class of users, independently navigating the interfaces we design and performing complex tasks on our behalf. This marks the beginning of a new era of interaction, the Agent-Computer Interaction, where user experience encompasses not only human-computer relationship, but also the experiences of the AI agents.Admittedly, humans remain integral to this new dynamic, providing oversight and guidance. Still, AI agents should now be considered distinct user personas, with unique needs, capabilities, and objectives. This entails designing the experience for both humans and agents, crafting interfaces that cater to both, and ensuring they have the necessary resources and information to function effectively.Understanding AI AgentsGoogle I/O defined AI agents as intelligent systems capable of reasoning, planning, retaining information, and thinking multiple steps ahead, all while operating across various software and systems under human supervision. Other companies may frame their definitions differently, but they share this essential concept: AI that can think several steps ahead and retain context while working independently. It’s like having a digital assistant that can truly anticipate your needs and proactively solve problems.(Image from Google I/O) — Reminder, these are my personal viewsWhile earlier AI agents relied on solely APIs to interact with other systems, recent breakthroughs, particularly in “computer use” pioneered by models like Claude, have unlocked a new level of agency. These advanced agents can now directly interact with graphical user interfaces, controlling the cursor, entering inputs, and navigating through applications just like a human user. This grants them unprecedented access to browser-based products, allowing them to perform tasks with a level of autonomy and sophistication we’ve never seen before.In this new era of Agent Computer Interaction, AI teams must choose between two approaches for enabling AI agents to interact with software:Direct API Integration or “tool use”: Using function calls and APIs to interact with systems programmatically. This is often more efficient since it avoids the overhead of rendering visual interfaces. However, API quality and coverage can vary.Visual Interface Interaction or “human tools”: Having AI agents interact with software through their graphical user interfaces, just as humans do. While potentially slower, this approach offers greater transparency and allows humans to better monitor and control the AI’s actions.API integration might be ideal for high-volume, well-defined tasks where speed and efficiency matter most. Visual interface interaction could be better suited for tasks requiring careful human oversight, providing more transparency and control. UX practitioners, and cross-functional partners, face a crucial challenge in determining the most effective interaction method for each use case, and the relationships with end users.Anthropic’s computer useDesigning the experience for AI agentsAs AI agents evolve into active users of our digital products, UX designers need to expand their practice to account for these new participants. Just as we research human user needs, we must now understand their capabilities, what they require to function effectively, and how they achieve their assigned goals.While agents ultimately serve human intentions, they often work in complex networks where they interact with other agents to complete tasks. For example, one agent might process data that another agent uses to make recommendations, all in service of a human’s original request. This creates new layers of interaction that designers must consider and support.As we create personas for human users, we should now develop personas for AI agents. These personas should capture the nuances of an agent’s behavior, its strengths and limitations, and its evolving capabilities as technology and context advance. This will enable us to design interfaces and interactions that are optimized for agent workflows, as if they were just people.Agent persona — (Modified FigmaJam template)Prepare to embrace new research methodologies, such as A/B testing different interface designs to determine which best supports agent performance. While AI systems may not be sentient, they possess motivations and can reason, plan, and adapt.This new era presents us with a fundamental question: should interfaces be optimized for humans, agents, or both? The answer remains elusive, as we navigate this uncharted territory. The key lies in recognizing that AI agents are not merely tools, but users in their own right, exploring thoughtful design considerations and a nuanced understanding of agents’ unique needs.When the mobile interrupted the world of desktop, it was first treated as a scaled-down version of the desktop experience. However, we soon unlocked the unique potential of mobile devices, and it changed the world in a way it was difficult to predict before. Similarly, we are now looking at AI advancement through the lens of existing paradigms, and time will show how new experiences will be shaped in a way we don’t expect. What is clear is that we appear to be on a trajectory from web apps to mobile apps, and now towards a future shaped by intelligent agents.Shaping the AI MindLarge Language Models (LLMs) are the “brains” behind AI agents, imbuing them with intelligence and reasoning capabilities. But UX designers have a crucial role to play in shaping these LLMs, going beyond interface design to influence the very core of agent behavior.In “The rise of the model designer” I argued that as designers we needed to get a seat at the table to shape AI models. We possess a unique understanding of user needs and mental models. This expertise is invaluable in crafting effective prompts that guide LLMs towards desired outcomes. By collaborating closely with engineers to develop system prompts aligned with user intent, we can ensure that AI agents provide relevant and meaningful experiences at the service of peopleAI model training \u0026 UX involvement from the “Model designer” articleMoreover, UX designers should actively participate in creating strategies for evaluating agent performance and leveraging user feedback to refine LLM behavior. This involves establishing a data flywheel that continuously improves the agent’s ability to understand and respond to user needs.The key takeaway is this: designing for AI agents requires a shift in mindset. We are not only crafting a product for them to use; we are actively shaping the agents themselves, influencing their intelligence and behavior through careful prompting and continuous feedback. This represents a new frontier for UX, where our expertise extends to the very heart of AI.Keeping Humans in the LoopWhile designing for AI agents presents exciting new challenges, we must never lose sight of our ultimate goal: enhancing human experiences. AI should serve humanity, and our design efforts must prioritize human needs and values.Control is paramount. UX practitioners must carefully consider how to empower users with agency over their AI interactions. This includes designing clear mechanisms for granting permissions, providing context about data access, and offering opt-out options for those who prefer not to engage with AI agents. Establishing trust through user control is essential for the successful adoption of agent-driven experiences.Transparency is equally crucial. Users need clear insights into how AI agents utilize their data, interact with their tools, and collaborate with other agents. In scenarios involving multiple agents from different companies, users should have visibility into the participants and the ability to choose which entities they allow into their digital ecosystem.Fortunately, we can draw upon existing UX frameworks to navigate this complex landscape. System design, for example, offers valuable tools for visualizing the intricate relationships within agent-driven ecosystems while maintaining a human-centered perspective. By adapting mapping techniques like blueprints commonly used in service design, we can effectively represent the interplay between humans, agents, and products, highlighting lines of visibility and control.Agentic experience map draft (Modified FigmaJam template)These modified blueprints, which we might call “agentic experience maps”, should not only depict the flow of interactions but also incorporate elements related to agent training and evaluation. This holistic view will enable us to design systems that are both powerful and trustworthy, ensuring that AI truly puts humans first.ConclusionWe are entering a new phase of digital design where AI agents are becoming active users of our systems, not just tools within them. This shift requires UX designers to expand their perspective, considering how both humans and AI agents interact with interfaces and with each other.While the rapid evolution of AI technology may feel overwhelming, this field is still in its early stages. The core principles of user experience design remain valuable — we’re simply extending them to encompass artificial users alongside human ones. This presents a unique opportunity for designers to shape how AI agents interact with systems and serve human needs.The future of UX lies in understanding and designing for this Agent Computer Interaction. Those who develop expertise in this area now will help define best practices for years to come.So take a deep breath, sign-up for a class, and join the movement to design a future we can all be proud of.Sources:Anthropic — Introducing computer useNNg — Service BlueprintsLatent Space podcast — Language Agents: From Reasoning to ActingCognition — Introducing DevinMIT technology Review — Google’s Astra is its first AI-for-everything agentAlex Klein — The agentic era of UX",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*eIrZIwrtEJefa4uAghcDKQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"1742\"\u003e\u003cstrong\u003eIntroducing the Agent Computer Interaction era.\u003c/strong\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@perez.mpaz?source=post_page---byline--6ef0135bdcad--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Paz Perez\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*N8wZM-QehnW-b0ScR2iPqw.png\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--6ef0135bdcad--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"f79b\"\u003eWhile the UX community has quickly embraced Large Language Models as design tools, we’ve largely overlooked their more profound implications. Now, as AI agents become integrated throughout our digital products, we face a fundamental transformation: these systems are evolving from tools into active participants in our digital environments, and we need to design for them.\u003c/p\u003e\u003cp id=\"af7b\"\u003e\u003cem\u003eAI agents are emerging as a new class of users, independently navigating the interfaces we design and performing complex tasks on our behalf. This marks the beginning of a new era of interaction, the Agent-Computer Interaction, where user experience encompasses not only human-computer relationship, but also the experiences of the AI agents.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"ade3\"\u003eAdmittedly, humans remain integral to this new dynamic, providing oversight and guidance. Still, AI agents should now be considered \u003cstrong\u003edistinct user personas\u003c/strong\u003e, with unique needs, capabilities, and objectives. This entails designing the experience for both humans and agents, crafting interfaces that cater to both, and ensuring they have the necessary resources and information to function effectively.\u003c/p\u003e\u003ch2 id=\"241b\"\u003e\u003cstrong\u003eUnderstanding AI Agents\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"1c8c\"\u003e\u003ca href=\"https://www.youtube.com/watch?v=XEzRZ35urlk\u0026amp;ab_channel=Google\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoogle I/O \u003c/a\u003edefined AI agents as intelligent systems capable of reasoning, planning, retaining information, and thinking multiple steps ahead, all while operating across various software and systems under human supervision. Other companies may frame their definitions differently, but they share this essential concept: AI that can think several steps ahead and retain context while working independently. It’s like having a digital assistant that can truly anticipate your needs and proactively solve problems.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003e(Image from Google I/O) — Reminder, these are my personal views\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"f3c0\"\u003eWhile earlier AI agents relied on solely APIs to interact with other systems, recent breakthroughs, particularly in “\u003ca href=\"https://www.anthropic.com/news/3-5-models-and-computer-use\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecomputer use\u003c/a\u003e” pioneered by models like Claude, have unlocked a new level of agency. These advanced agents can now directly interact with graphical user interfaces, controlling the cursor, entering inputs, and navigating through applications just like a human user. This grants them unprecedented access to browser-based products, allowing them to perform tasks with a level of autonomy and sophistication we’ve never seen before.\u003c/p\u003e\u003cp id=\"3df9\"\u003eIn this new era of Agent Computer Interaction, AI teams must choose between two approaches for enabling AI agents to interact with software:\u003c/p\u003e\u003col\u003e\u003cli id=\"b2cd\"\u003e\u003cstrong\u003eDirect API Integration or “tool use”: \u003c/strong\u003eUsing function calls and APIs to interact with systems programmatically. This is often more efficient since it avoids the overhead of rendering visual interfaces. However, API quality and coverage can vary.\u003c/li\u003e\u003cli id=\"36a8\"\u003e\u003cstrong\u003eVisual Interface Interaction or “human tools”: \u003c/strong\u003eHaving AI agents interact with software through their graphical user interfaces, just as humans do. While potentially slower, this approach offers greater transparency and allows humans to better monitor and control the AI’s actions.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"5365\"\u003eAPI integration might be ideal for high-volume, well-defined tasks where speed and efficiency matter most. Visual interface interaction could be better suited for tasks requiring careful human oversight, providing more transparency and control. UX practitioners, and cross-functional partners, face a crucial challenge in determining the most effective interaction method for each use case, and the relationships with end users.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eAnthropic’s computer use\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"d9ba\"\u003eDesigning the experience for AI agents\u003c/h2\u003e\u003cp id=\"4ff1\"\u003eAs AI agents evolve into active users of our digital products, UX designers need to expand their practice to account for these new participants. Just as we research human user needs, we must now understand their capabilities, what they require to function effectively, and how they achieve their assigned goals.\u003c/p\u003e\u003cp id=\"2027\"\u003eWhile agents ultimately serve human intentions, they often work in complex networks where they interact with other agents to complete tasks. For example, one agent might process data that another agent uses to make recommendations, all in service of a human’s original request. This creates new layers of interaction that designers must consider and support.\u003c/p\u003e\u003cp id=\"a8ce\"\u003eAs we create personas for human users, we should now develop personas for AI agents. These personas should capture the nuances of an agent’s behavior, its strengths and limitations, and its evolving capabilities as technology and context advance. This will enable us to design interfaces and interactions that are optimized for agent workflows, as if they were just people.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eAgent persona — (Modified FigmaJam template)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"5dee\"\u003ePrepare to embrace new research methodologies, such as A/B testing different interface designs to determine which best supports agent performance. While AI systems may not be sentient, they possess motivations and can reason, plan, and adapt.\u003c/p\u003e\u003cp id=\"29f5\"\u003eThis new era presents us with a fundamental question: should interfaces be optimized for humans, agents, or both? The answer remains elusive, as we navigate this uncharted territory. The key lies in recognizing that AI agents are not merely tools, but users in their own right, exploring thoughtful design considerations and a nuanced understanding of agents’ unique needs.\u003c/p\u003e\u003cp id=\"c62b\"\u003eWhen the mobile interrupted the world of desktop, it was first treated as a scaled-down version of the desktop experience. However, we soon unlocked the unique potential of mobile devices, and it changed the world in a way it was difficult to predict before. Similarly, we are now looking at AI advancement through the lens of existing paradigms, and time will show how new experiences will be shaped in a way we don’t expect. What is clear is that we appear to be on a trajectory from web apps to mobile apps, and now towards a future shaped by intelligent agents.\u003c/p\u003e\u003ch2 id=\"59f4\"\u003eShaping the AI Mind\u003c/h2\u003e\u003cp id=\"623a\"\u003eLarge Language Models (LLMs) are the “brains” behind AI agents, imbuing them with intelligence and reasoning capabilities. But UX designers have a crucial role to play in shaping these LLMs, going beyond interface design to influence the very core of agent behavior.\u003c/p\u003e\u003cp id=\"71d2\"\u003eIn “\u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/the-rise-of-the-model-designer-cef429d9c134\"\u003eThe rise of the model designer\u003c/a\u003e” I argued that as designers we needed to get a seat at the table to shape AI models. We possess a unique understanding of user needs and mental models. This expertise is invaluable in crafting effective prompts that guide LLMs towards desired outcomes. By collaborating closely with engineers to develop system prompts aligned with user intent, we can ensure that AI agents provide relevant and meaningful experiences at the service of people\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eAI model training \u0026amp; UX involvement from the “Model designer” article\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"fdc5\"\u003eMoreover, UX designers should actively participate in creating strategies for evaluating agent performance and leveraging user feedback to refine LLM behavior. This involves establishing a data flywheel that continuously improves the agent’s ability to understand and respond to user needs.\u003c/p\u003e\u003cp id=\"4b46\"\u003e\u003cem\u003eThe key takeaway is this: designing for AI agents requires a shift in mindset. We are not only crafting a product for them to use; we are actively shaping the agents themselves, influencing their intelligence and behavior through careful prompting and continuous feedback. This represents a new frontier for UX, where our expertise extends to the very heart of AI.\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"92fa\"\u003eKeeping Humans in the Loop\u003c/h2\u003e\u003cp id=\"b7cc\"\u003eWhile designing for AI agents presents exciting new challenges, we must never lose sight of our ultimate goal: enhancing human experiences. AI should serve humanity, and our design efforts must prioritize human needs and values.\u003c/p\u003e\u003cp id=\"82fc\"\u003eControl is paramount. UX practitioners must carefully consider how to empower users with agency over their AI interactions. This includes designing clear mechanisms for granting permissions, providing context about data access, and offering opt-out options for those who prefer not to engage with AI agents. Establishing trust through user control is essential for the successful adoption of agent-driven experiences.\u003c/p\u003e\u003cp id=\"fc54\"\u003eTransparency is equally crucial. Users need clear insights into how AI agents utilize \u003cstrong\u003etheir\u003c/strong\u003e data, interact with \u003cstrong\u003etheir\u003c/strong\u003e tools, and collaborate with other agents. In scenarios involving multiple agents from different companies, users should have visibility into the participants and the ability to choose which entities they allow into their digital ecosystem.\u003c/p\u003e\u003cp id=\"690e\"\u003eFortunately, we can draw upon existing UX frameworks to navigate this complex landscape. System design, for example, offers valuable tools for visualizing the intricate relationships within agent-driven ecosystems while maintaining a human-centered perspective. By adapting mapping techniques like blueprints commonly used in service design, we can effectively represent the interplay between humans, agents, and products, highlighting lines of visibility and control.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eAgentic experience map draft (Modified FigmaJam template)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"7d80\"\u003eThese modified blueprints, which we might call “agentic experience maps”, should not only depict the flow of interactions but also incorporate elements related to agent training and evaluation. This holistic view will enable us to design systems that are both powerful and trustworthy, ensuring that AI truly puts humans first.\u003c/p\u003e\u003ch2 id=\"9524\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"e88b\"\u003eWe are entering a new phase of digital design where AI agents are becoming active users of our systems, not just tools within them. This shift requires UX designers to expand their perspective, considering how both humans and AI agents interact with interfaces and with each other.\u003c/p\u003e\u003cp id=\"ba2a\"\u003eWhile the rapid evolution of AI technology may feel overwhelming, this field is still in its early stages. The core principles of user experience design remain valuable — we’re simply extending them to encompass artificial users alongside human ones. This presents a unique opportunity for designers to shape how AI agents interact with systems and serve human needs.\u003c/p\u003e\u003cp id=\"3940\"\u003eThe future of UX lies in understanding and designing for this Agent Computer Interaction. Those who develop expertise in this area now will help define best practices for years to come.\u003c/p\u003e\u003cp id=\"cead\"\u003eSo take a deep breath, sign-up for a class, and join the movement to design a future we can all be proud of.\u003c/p\u003e\u003ch2 id=\"d73d\"\u003eSources:\u003c/h2\u003e\u003cul\u003e\u003cli id=\"3627\"\u003e\u003cstrong\u003eAnthropic \u003c/strong\u003e— \u003ca href=\"https://www.anthropic.com/news/3-5-models-and-computer-use\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIntroducing computer use\u003c/a\u003e\u003c/li\u003e\u003cli id=\"86aa\"\u003e\u003cstrong\u003eNNg \u003c/strong\u003e— \u003ca href=\"https://www.nngroup.com/articles/service-blueprints-definition/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eService Blueprints\u003c/a\u003e\u003c/li\u003e\u003cli id=\"58f0\"\u003e\u003cstrong\u003eLatent Space podcast \u003c/strong\u003e— \u003ca href=\"https://youtu.be/8t65bss7U74?si=sxz9x8SXJsi9xdz-\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLanguage Agents: From Reasoning to Acting\u003c/a\u003e\u003c/li\u003e\u003cli id=\"448e\"\u003e\u003cstrong\u003eCognition \u003c/strong\u003e— \u003ca href=\"https://www.cognition.ai/blog/introducing-devin\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIntroducing Devin\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b69d\"\u003e\u003cstrong\u003eMIT technology Review \u003c/strong\u003e— \u003ca href=\"https://www.technologyreview.com/2024/05/14/1092407/googles-astra-is-its-first-ai-for-everything-agent/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoogle’s Astra is its first AI-for-everything agent\u003c/a\u003e\u003c/li\u003e\u003cli id=\"fef8\"\u003e\u003cstrong\u003eAlex Klein \u003c/strong\u003e— \u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/the-agentic-era-of-ux-4b58634e410b\"\u003eThe agentic era of UX\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2024-11-05T19:22:12.569Z",
  "modifiedTime": null
}
