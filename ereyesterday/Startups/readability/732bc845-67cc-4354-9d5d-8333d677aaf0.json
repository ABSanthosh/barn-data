{
  "id": "732bc845-67cc-4354-9d5d-8333d677aaf0",
  "title": "Do new AI reasoning models require new approaches to prompting?",
  "link": "https://venturebeat.com/ai/do-new-ai-reasoning-models-require-new-approaches-to-prompting/",
  "description": "Even when it comes to non-reasoning LLMs such as Claude 3.5 Sonnet, there may be room for regular users to improve their prompting.",
  "author": "Carl Franzen",
  "published": "Mon, 13 Jan 2025 23:27:56 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI, ML and Deep Learning",
    "chain of thought prompting",
    "chain of thought reasoning",
    "Conversational AI",
    "Large Reasoning Models (LRMs)",
    "LLM reasoning",
    "LLMs",
    "NLP",
    "o1",
    "prompting",
    "reasoning models"
  ],
  "byline": "Carl Franzen",
  "length": 4414,
  "excerpt": "Even when it comes to non-reasoning LLMs such as Claude 3.5 Sonnet, there may be room for regular users to improve their prompting.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "January 13, 2025 3:27 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More The era of reasoning AI is well underway. After OpenAI once again kickstarted an AI revolution with its o1 reasoning model introduced back in September 2024 — which takes longer to answer questions but with the payoff of higher performance, especially on complex, multi-step problems in math and science — the commercial AI field has been flooded with copycats and competitors. There’s DeepSeek’s R1, Google Gemini 2 Flash Thinking, and just today, LlamaV-o1, all of which seek to offer similar built-in “reasoning” to OpenAI’s new o1 and upcoming o3 model families. These models engage in “chain-of-thought” (CoT) prompting — or “self-prompting” — forcing them to reflect on their analysis midstream, double back, check over their own work and ultimately arrive at a better answer than just shooting it out of their embeddings as fast as possible, as other large language models (LLMs) do. Yet the high cost of o1 and o1-mini ($15.00/1M input tokens vs. $1.25/1M input tokens for GPT-4o on OpenAI’s API) has caused some to balk at the supposed performance gains. Is it really worth paying 12X as much as the typical, state-of-the-art LLM? As it turns out, there are a growing number of converts — but the key to unlocking reasoning models’ true value may lie in the user prompting them differently. Shawn Wang (founder of AI news service Smol) featured on his Substack over the weekend a guest post from Ben Hylak, the former Apple Inc., interface designer for visionOS (which powers the Vision Pro spatial computing headset). The post has gone viral as it convincingly explains how Hylak prompts OpenAI’s o1 model to receive incredibly valuable outputs (for him). In short, instead of the human user writing prompts for the o1 model, they should think about writing “briefs,” or more detailed explanations that include lots of context up-front about what the user wants the model to output, who the user is and what format in which they want the model to output information for them. As Hylak writes on Substack: With most models, we’ve been trained to tell the model how we want it to answer us. e.g. ‘You are an expert software engineer. Think slowly and carefully“ This is the opposite of how I’ve found success with o1. I don’t instruct it on the how — only the what. Then let o1 take over and plan and resolve its own steps. This is what the autonomous reasoning is for, and can actually be much faster than if you were to manually review and chat as the “human in the loop”. Hylak also includes a great annotated screenshot of an example prompt for o1 that produced a useful results for a list of hikes: This blog post was so helpful, OpenAI’s own president and co-founder Greg Brockman re-shared it on his X account with the message: “o1 is a different kind of model. Great performance requires using it in a new way relative to standard chat models.” I tried it myself on my recurring quest to learn to speak fluent Spanish and here was the result, for those curious. Perhaps not as impressive as Hylak’s well-constructed prompt and response, but definitely showing strong potential. Separately, even when it comes to non-reasoning LLMs such as Claude 3.5 Sonnet, there may be room for regular users to improve their prompting to get better, less constrained results. As Louis Arge, former Teton.ai engineer and current creator of neuromodulation device openFUS, wrote on X, “one trick i’ve discovered is that LLMs trust their own prompts more than my prompts,” and provided an example of how he convinced Claude to be “less of a coward” by first “trigger[ing] a fight” with him over its outputs. All of which goes to show that prompt engineering remains a valuable skill as the AI era wears on. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/01/cfr0z3n_minimalist_graphic_novel_style_splash_page_showing_an_a_7ecc7f0f-6b98-4b7a-a134-af1b0cabea63-1.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-01-13T23:27:56+00:00\" datetime=\"2025-01-13T23:27:56+00:00\"\u003eJanuary 13, 2025 3:27 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/cfr0z3n_minimalist_graphic_novel_style_splash_page_showing_an_a_7ecc7f0f-6b98-4b7a-a134-af1b0cabea63-1.png?w=750\" alt=\"2D simple colorful corporate memphis AI artwork on beige background showing black haired human figure typing on blue computer screen with colorful abstract cloud behind it\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThe era of reasoning AI is well underway.\u003c/p\u003e\n\n\n\n\u003cp\u003eAfter OpenAI once again kickstarted an AI revolution with its \u003ca href=\"https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eo1 reasoning model\u003c/a\u003e introduced back in September 2024 — which takes longer to answer questions but with the payoff of higher performance, especially on complex, multi-step problems in math and science — the commercial AI field has been flooded with copycats and competitors.\u003c/p\u003e\n\n\n\n\u003cp\u003eThere’s \u003ca href=\"https://venturebeat.com/ai/deepseeks-first-reasoning-model-r1-lite-preview-turns-heads-beating-openai-o1-performance/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eDeepSeek’s R1\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/google-unveils-new-reasoning-model-gemini-2-0-flash-thinking-to-rival-openai-o1/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGoogle Gemini 2 Flash Thinking\u003c/a\u003e, and just today, \u003ca href=\"https://venturebeat.com/ai/llamav-o1-is-the-ai-model-that-explains-its-thought-process-heres-why-that-matters/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLlamaV-o1\u003c/a\u003e, all of which seek to offer similar built-in “reasoning” to OpenAI’s new o1 and upcoming o3 model families. These models engage in \u003ca href=\"https://learn.microsoft.com/en-us/dotnet/ai/conceptual/chain-of-thought-prompting\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e“chain-of-thought” (CoT) prompting\u003c/a\u003e — or “self-prompting” — forcing them to reflect on their analysis midstream, double back, check over their own work and ultimately arrive at a better answer than just shooting it out of their \u003ca href=\"https://datasciencedojo.com/blog/embeddings-and-llm/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eembeddings\u003c/a\u003e as fast as possible, as other large language models (LLMs) do.\u003c/p\u003e\n\n\n\n\u003cp\u003eYet the high cost of o1 and o1-mini ($15.00/1M input tokens vs. $1.25/1M input tokens for GPT-4o on \u003ca href=\"https://openai.com/api/pricing/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenAI’s API\u003c/a\u003e) has caused some to balk at the supposed performance gains. Is it really worth paying 12X as much as the typical, state-of-the-art LLM?\u003c/p\u003e\n\n\n\n\u003cp\u003eAs it turns out, there are a growing number of converts — but the key to unlocking reasoning models’ true value may lie in the user prompting them differently.\u003c/p\u003e\n\n\n\n\u003cp\u003eShawn Wang (founder of AI news service \u003ca href=\"https://smol.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSmol\u003c/a\u003e) featured on his \u003ca href=\"https://www.latent.space/p/o1-skill-issue\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSubstack\u003c/a\u003e over the weekend a guest post from Ben Hylak, the former Apple Inc., interface designer for visionOS (which powers the Vision Pro spatial computing headset). The post has gone viral as it convincingly explains how Hylak prompts OpenAI’s o1 model to receive incredibly valuable outputs (for him).\u003c/p\u003e\n\n\n\n\u003cp\u003eIn short, instead of the human user writing prompts for the o1 model, they should think about writing “briefs,” or more detailed explanations that include lots of context up-front about what the user wants the model to output, who the user is and what format in which they want the model to output information for them.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs Hylak writes on \u003ca href=\"https://www.latent.space/p/o1-skill-issue\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSubstack\u003c/a\u003e:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eWith most models, we’ve been trained to tell the model how we want it to answer us. e.g. ‘You are an expert software engineer. Think slowly and carefully\u003c/em\u003e“\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eThis is the opposite of how I’ve found success with o1. I don’t instruct it on the how — only the what. Then let o1 take over and plan and resolve its own steps. This is what the autonomous reasoning is for, and can actually be much faster than if you were to manually review and chat as the “human in the loop”.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eHylak also includes a great annotated screenshot of an example prompt for o1 that produced a useful results for a list of hikes:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1456\" height=\"1212\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?w=721\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp 1456w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=300,250 300w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=768,639 768w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=721,600 721w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=400,333 400w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=750,624 750w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=578,481 578w, https://venturebeat.com/wp-content/uploads/2025/01/5407ad16-67a5-4683-aa4c-0af8caaa0f5f_2020x1682.webp?resize=930,774 930w\" sizes=\"(max-width: 1456px) 100vw, 1456px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThis blog post was so helpful, OpenAI’s own president and co-founder Greg Brockman re-shared it on his X account with the \u003ca href=\"https://x.com/gdb/status/1878489681702310392\" target=\"_blank\" rel=\"noreferrer noopener\"\u003emessage\u003c/a\u003e: “o1 is a different kind of model. Great performance requires using it in a new way relative to standard chat models.”\u003c/p\u003e\n\n\n\n\u003cp\u003eI tried it myself on my recurring quest to learn to speak fluent Spanish and \u003ca href=\"https://chatgpt.com/share/6785a38f-51c0-8001-9d34-969097d759ba\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ehere was the result\u003c/a\u003e, for those curious. Perhaps not as impressive as Hylak’s well-constructed prompt and response, but definitely showing strong potential.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1436\" height=\"1064\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12%E2%80%AFPM.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png 1436w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=300,222 300w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=768,569 768w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=800,593 800w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=400,296 400w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=750,556 750w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=578,428 578w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-13-at-6.39.12 PM.png?resize=930,689 930w\" sizes=\"(max-width: 1436px) 100vw, 1436px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eSeparately, even when it comes to non-reasoning LLMs such as Claude 3.5 Sonnet, there may be room for regular users to improve their prompting to get better, less constrained results.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs Louis Arge, former Teton.ai engineer and current creator of neuromodulation device openFUS, \u003ca href=\"https://x.com/louisvarge/status/1878124855423316073?s=46\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewrote on X\u003c/a\u003e, “one trick i’ve discovered is that LLMs trust their own prompts more than my prompts,” and provided an example of how he convinced Claude to be “less of a coward” by first “trigger[ing] a fight” with him over its outputs.\u003c/p\u003e\n\n\n\n\u003cp\u003eAll of which goes to show that prompt engineering remains a valuable skill as the AI era wears on.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-01-13T23:27:56Z",
  "modifiedTime": "2025-01-13T23:51:33Z"
}
