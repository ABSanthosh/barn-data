{
  "id": "6ce010ea-9e61-4651-9b14-6b852c70f2be",
  "title": "Stop guessing why your LLMs break: Anthropic’s new tool shows you exactly what goes wrong",
  "link": "https://venturebeat.com/ai/stop-guessing-why-your-llms-break-anthropics-new-tool-shows-you-exactly-what-goes-wrong/",
  "description": "Anthropic's open-source circuit tracing tool can help developers debug, optimize, and control AI for reliable and trustable applications.",
  "author": "Ben Dickson",
  "published": "Wed, 04 Jun 2025 22:39:09 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "ai models",
    "AI, ML and Deep Learning",
    "Anthropic",
    "Circuit Tracing",
    "Claude 3.5 Haiku",
    "explainable AI",
    "interpretability",
    "interpretability research",
    "interpretability tools",
    "interpretable AI",
    "large language models",
    "large language models (LLMs)",
    "LLMs",
    "Mechanistic Interpretability",
    "open platform",
    "research"
  ],
  "byline": "Ben Dickson",
  "length": 6505,
  "excerpt": "Anthropic's open-source circuit tracing tool can help developers debug, optimize, and control AI for reliable and trustable applications.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "June 4, 2025 3:39 PM Image credit: VentureBeat with Ideogram Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Large language models (LLMs) are transforming how enterprises operate, but their “black box” nature often leaves enterprises grappling with unpredictability. Addressing this critical challenge, Anthropic recently open-sourced its circuit tracing tool, allowing developers and researchers to directly understand and control models’ inner workings.  This tool allows investigators to investigate unexplained errors and unexpected behaviors in open-weight models. It can also help with granular fine-tuning of LLMs for specific internal functions. Understanding the AI’s inner logic This circuit tracing tool works based on “mechanistic interpretability,” a burgeoning field dedicated to understanding how AI models function based on their internal activations rather than merely observing their inputs and outputs.  While Anthropic’s initial research on circuit tracing applied this methodology to their own Claude 3.5 Haiku model, the open-sourced tool extends this capability to open-weights models. Anthropic’s team has already used the tool to trace circuits in models like Gemma-2-2b and Llama-3.2-1b and has released a Colab notebook that helps use the library on open models. The core of the tool lies in generating attribution graphs, causal maps that trace the interactions between features as the model processes information and generates an output. (Features are internal activation patterns of the model that can be roughly mapped to understandable concepts.) It is like obtaining a detailed wiring diagram of an AI’s internal thought process. More importantly, the tool enables “intervention experiments,” allowing researchers to directly modify these internal features and observe how changes in the AI’s internal states impact its external responses, making it possible to debug models. The tool integrates with Neuronpedia, an open platform for understanding and experimentation with neural networks.  Circuit tracing on Neuronpedia (source: Anthropic blog) Practicalities and future impact for enterprise AI While Anthropic’s circuit tracing tool is a great step toward explainable and controllable AI, it has practical challenges, including high memory costs associated with running the tool and the inherent complexity of interpreting the detailed attribution graphs. However, these challenges are typical of cutting-edge research. Mechanistic interpretability is a big area of research, and most big AI labs are developing models to investigate the inner workings of large language models. By open-sourcing the circuit tracing tool, Anthropic will enable the community to develop interpretability tools that are more scalable, automated, and accessible to a wider array of users, opening the way for practical applications of all the effort that is going into understanding LLMs.  As the tooling matures, the ability to understand why an LLM makes a certain decision can translate into practical benefits for enterprises.  Circuit tracing explains how LLMs perform sophisticated multi-step reasoning. For example, in their study, the researchers were able to trace how a model inferred “Texas” from “Dallas” before arriving at “Austin” as the capital. It also revealed advanced planning mechanisms, like a model pre-selecting rhyming words in a poem to guide line composition. Enterprises can use these insights to analyze how their models tackle complex tasks like data analysis or legal reasoning. Pinpointing internal planning or reasoning steps allows for targeted optimization, improving efficiency and accuracy in complex business processes. Source: Anthropic Furthermore, circuit tracing offers better clarity into numerical operations. For example, in their study, the researchers uncovered how models handle arithmetic, like 36+59=95, not through simple algorithms but via parallel pathways and “lookup table” features for digits. For example, enterprises can use such insights to audit internal computations leading to numerical results, identify the origin of errors and implement targeted fixes to ensure data integrity and calculation accuracy within their open-source LLMs. For global deployments, the tool provides insights into multilingual consistency. Anthropic’s previous research shows that models employ both language-specific and abstract, language-independent “universal mental language” circuits, with larger models demonstrating greater generalization. This can potentially help debug localization challenges when deploying models across different languages. Finally, the tool can help combat hallucinations and improve factual grounding. The research revealed that models have “default refusal circuits” for unknown queries, which are suppressed by “known answer” features. Hallucinations can occur when this inhibitory circuit “misfires.”  Source: Anthropic Beyond debugging existing issues, this mechanistic understanding unlocks new avenues for fine-tuning LLMs. Instead of merely adjusting output behavior through trial and error, enterprises can identify and target the specific internal mechanisms driving desired or undesired traits. For instance, understanding how a model’s “Assistant persona” inadvertently incorporates hidden reward model biases, as shown in Anthropic’s research, allows developers to precisely re-tune the internal circuits responsible for alignment, leading to more robust and ethically consistent AI deployments. As LLMs increasingly integrate into critical enterprise functions, their transparency, interpretability and control become increasingly critical. This new generation of tools can help bridge the gap between AI’s powerful capabilities and human understanding, building foundational trust and ensuring that enterprises can deploy AI systems that are reliable, auditable, and aligned with their strategic objectives. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/06/Interpretable-AI.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-06-04T22:39:09+00:00\" datetime=\"2025-06-04T22:39:09+00:00\"\u003eJune 4, 2025 3:39 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"224\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/Interpretable-AI.webp?w=400\" alt=\"Image credit: VentureBeat with Ideogram\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eImage credit: VentureBeat with Ideogram\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eLarge language models (LLMs) are transforming how enterprises operate, but their “black box” nature often leaves enterprises grappling with unpredictability. Addressing this critical challenge, \u003ca href=\"https://www.anthropic.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAnthropic\u003c/a\u003e recently open-sourced its \u003ca href=\"https://www.anthropic.com/research/open-source-circuit-tracing\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecircuit tracing tool\u003c/a\u003e, allowing developers and researchers to directly understand and control models’ inner workings. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis tool allows investigators to investigate unexplained errors and unexpected behaviors in open-weight models. It can also help with granular fine-tuning of LLMs for specific internal functions.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-understanding-the-ai-s-inner-logic\"\u003eUnderstanding the AI’s inner logic\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis circuit tracing tool works based on “\u003ca href=\"https://venturebeat.com/ai/deepminds-gemma-scope-peers-under-the-hood-of-large-language-models/\"\u003emechanistic interpretability\u003c/a\u003e,” a burgeoning field dedicated to understanding how AI models function based on their internal activations rather than merely observing their inputs and outputs. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile Anthropic’s \u003ca href=\"https://venturebeat.com/ai/anthropic-scientists-expose-how-ai-actually-thinks-and-discover-it-secretly-plans-ahead-and-sometimes-lies/\"\u003einitial research on circuit tracing\u003c/a\u003e applied this methodology to their own \u003ca href=\"https://venturebeat.com/ai/claude-3-5-haiku-chatbot-now-generally-available/\"\u003eClaude 3.5 Haiku model\u003c/a\u003e, the open-sourced tool extends this capability to open-weights models. Anthropic’s team has already used the tool to trace circuits in models like Gemma-2-2b and Llama-3.2-1b and has released a \u003ca href=\"https://github.com/safety-research/circuit-tracer/blob/main/demos/circuit_tracing_tutorial.ipynb\"\u003eColab notebook\u003c/a\u003e that helps use the library on open models.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe core of the tool lies in generating attribution graphs, causal maps that trace the interactions between features as the model processes information and generates an output. (Features are internal activation patterns of the model that can be roughly mapped to understandable concepts.) It is like obtaining a detailed wiring diagram of an AI’s internal thought process. More importantly, the tool enables “intervention experiments,” allowing researchers to directly modify these internal features and observe how changes in the AI’s internal states impact its external responses, making it possible to debug models.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe tool integrates with \u003ca href=\"https://www.neuronpedia.org/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eNeuronpedia\u003c/a\u003e, an open platform for understanding and experimentation with neural networks. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"3790\" height=\"1748\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image.png?w=800\" alt=\"Circuite tracing on Neuronpedia (source: Anthropic blog)\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image.png 3790w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=300,138 300w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=768,354 768w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=800,369 800w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=1536,708 1536w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=2048,945 2048w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=400,184 400w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=750,346 750w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=578,267 578w, https://venturebeat.com/wp-content/uploads/2025/06/image.png?resize=930,429 930w\" sizes=\"(max-width: 3790px) 100vw, 3790px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eCircuit tracing on Neuronpedia (source: Anthropic blog)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-practicalities-and-future-impact-for-enterprise-ai\"\u003ePracticalities and future impact for enterprise AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile Anthropic’s circuit tracing tool is a great step toward explainable and controllable AI, it has practical challenges, including high memory costs associated with running the tool and the inherent complexity of interpreting the detailed attribution graphs.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, these challenges are typical of cutting-edge research. Mechanistic interpretability is a big area of research, and most big AI labs are developing models to investigate the inner workings of large language models. By open-sourcing the circuit tracing tool, Anthropic will enable the community to develop interpretability tools that are more scalable, automated, and accessible to a wider array of users, opening the way for practical applications of all the effort that is going into understanding LLMs. \u003c/p\u003e\n\n\n\n\u003cp\u003eAs the tooling matures, the ability to understand why an LLM makes a certain decision can translate into practical benefits for enterprises. \u003c/p\u003e\n\n\n\n\u003cp\u003eCircuit tracing explains how LLMs perform sophisticated multi-step reasoning. For example, in their study, the researchers were able to trace how a model inferred “Texas” from “Dallas” before arriving at “Austin” as the capital. It also revealed advanced planning mechanisms, like a model pre-selecting rhyming words in a poem to guide line composition. Enterprises can use these insights to analyze how their models tackle complex tasks like data analysis or legal reasoning. Pinpointing internal planning or reasoning steps allows for targeted optimization, improving efficiency and accuracy in complex business processes.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"2008\" height=\"976\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png 2008w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=300,146 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=768,373 768w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=800,389 800w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=1536,747 1536w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=100,50 100w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=400,194 400w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=750,365 750w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=578,281 578w, https://venturebeat.com/wp-content/uploads/2025/06/image_5f896b.png?resize=930,452 930w\" sizes=\"(max-width: 2008px) 100vw, 2008px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSource: Anthropic\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFurthermore, circuit tracing offers better clarity into numerical operations. For example, in their study, the researchers uncovered how models handle arithmetic, like 36+59=95, not through simple algorithms but via parallel pathways and “lookup table” features for digits. For example, enterprises can use such insights to audit internal computations leading to numerical results, identify the origin of errors and implement targeted fixes to ensure data integrity and calculation accuracy within their open-source LLMs.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor global deployments, the tool provides insights into multilingual consistency. Anthropic’s previous research shows that models employ both language-specific and abstract, language-independent “universal mental language” circuits, with larger models demonstrating greater generalization. This can potentially help debug localization challenges when deploying models across different languages.\u003c/p\u003e\n\n\n\n\u003cp\u003eFinally, the tool can help combat hallucinations and improve factual grounding. The research revealed that models have “default refusal circuits” for unknown queries, which are suppressed by “known answer” features. Hallucinations can occur when this inhibitory circuit “misfires.” \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"2460\" height=\"606\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png 2460w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=300,74 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=768,189 768w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=800,197 800w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=1536,378 1536w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=2048,505 2048w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=400,99 400w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=750,185 750w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=578,142 578w, https://venturebeat.com/wp-content/uploads/2025/06/image_a61642.png?resize=930,229 930w\" sizes=\"(max-width: 2460px) 100vw, 2460px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSource: Anthropic\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eBeyond debugging existing issues, this mechanistic understanding unlocks new avenues for \u003ca href=\"https://bdtechtalks.com/2023/07/10/llm-fine-tuning/\"\u003efine-tuning LLMs\u003c/a\u003e. Instead of merely adjusting output behavior through trial and error, enterprises can identify and target the specific internal mechanisms driving desired or undesired traits. For instance, understanding how a model’s “Assistant persona” inadvertently incorporates hidden reward model biases, as shown in Anthropic’s research, allows developers to precisely re-tune the internal circuits responsible for alignment, leading to more robust and ethically consistent AI deployments.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs LLMs increasingly integrate into critical enterprise functions, their transparency, interpretability and control become increasingly critical. This new generation of tools can help bridge the gap between AI’s powerful capabilities and human understanding, building foundational trust and ensuring that enterprises can deploy AI systems that are reliable, auditable, and aligned with their strategic objectives.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-06-04T22:39:09Z",
  "modifiedTime": "2025-06-04T22:39:20Z"
}
