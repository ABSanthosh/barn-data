{
  "id": "66565c5d-ed77-4f10-bf7b-22e5e5a2679d",
  "title": "How to Run DeepSeek R1 Distilled Reasoning Models on RyzenAI and Radeon GPUs",
  "link": "https://www.guru3d.com/story/amd-explains-how-to-run-deepseek-r1-distilled-reasoning-models-on-amd-ryzen-ai-and-radeon/",
  "description": "Article URL: https://www.guru3d.com/story/amd-explains-how-to-run-deepseek-r1-distilled-reasoning-models-on-amd-ryzen-ai-and-radeon/ Comments URL: https://news.ycombinator.com/item?id=42904116 Points: 3 # Comments: 0",
  "author": "waltercool",
  "published": "Sun, 02 Feb 2025 00:27:05 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "Hilbert Hagedoorn",
  "length": 3883,
  "excerpt": "DeepSeek R1 Distilled Reasoning models use chain-of-thought reasoning to analyze complex prompts in detail. Instead of producing immediate replies, they spend time generating a “thinking” sequence, which often involves processing hundreds or thousands of tokens internally.",
  "siteName": "www.guru3d.com",
  "favicon": "https://www.guru3d.com/data/themes/frontend/Guru3D/images/favicon_180x180.png",
  "text": "DeepSeek R1 Distilled Reasoning models use chain-of-thought reasoning to analyze complex prompts in detail. Instead of producing immediate replies, they spend time generating a “thinking” sequence, which often involves processing hundreds or thousands of tokens internally. This approach helps the model to evaluate various perspectives before generating a final response. Although this increases the wait time, it typically delivers more thorough results, which can be valuable for tasks in scientific research, mathematics, and other technical fields. AMD supports different sizes of DeepSeek R1 distillations across its processor and graphics card lineup. Larger processors, such as the Ryzen AI Max+ 395 Series, can run bigger distills like Qwen-32B, while mid-range products like Ryzen AI HX 370 or 7040/8040 often handle Qwen-14B or Llama-14B. For graphics cards, models like the Radeon RX 7900 XTX can accommodate Qwen-32B, but lower-tier cards generally work best with smaller versions. It is recommended to quantize these models in Q4 K M format to reduce memory usage and make the most of the available GPU resources.  To deploy a DeepSeek R1 distill, install the Adrenalin 25.1.1 driver or newer and download LM Studio 0.3.8 or above. Use the “Discover” tab in LM Studio to select your preferred model, confirm Q4 K M quantization, and adjust GPU offload layers to suit your system’s capacity. Once everything is configured, load the model in the “Chat” tab to start interacting with its chain-of-thought process. This local deployment approach can enhance data security and reduce latency since all reasoning is performed directly on AMD hardware. For reliable performance, consult official documentation to confirm your system meets driver and memory requirements.   Step 1: Make sure you are on the 25.1.1 Optional or higher Adrenalin driver. Step 2: Download LM Studio 0.3.8 or above from lmstudio.ai/ryzenai Step 3: Install LM Studio and skip the onboarding screen.Step 4: Click on the discover tab. Step 5: Choose your DeepSeek R1 Distill. Smaller distills like the Qwen 1.5B offer blazing fast performance (and are the recommended starting point) while bigger distills will offer superior reasoning capability. All of them are extremely capable. The table below details the maximum recommended DeepSeek R1 Distill size: ProcessorDeepSeek R1 Distill* (Max Supported)AMD Ryzen™ AI Max+ 395 32GB1, 64 GB2 and 128 GBDeepSeek-R1-Distill-Llama-70B (64GB and 128GB only)DeepSeek-R1-Distill-Qwen-32BAMD Ryzen™ AI HX 370 and 365 24GB and 32 GBDeepSeek-R1-Distill-Qwen-14BAMD Ryzen™ 8040 and Ryzen™ 7040 32 GBDeepSeek-R1-Distill-Llama-14B*= AMD recommends running all distills in Q4 K M quantization.1= Requires Variable Graphics Memory set to Custom: 24GB.   2= Requires Variable Graphics Memory set to High. Graphics CardDeepSeek R1 Distill* (Max Supported1)AMD Radeon™ RX 7900 XTXDeepSeek-R1-Distill-Qwen-32BAMD Radeon™ RX 7900 XTDeepSeek-R1-Distill-Qwen-14BAMD Radeon™ RX 7900 GREDeepSeek-R1-Distill-Qwen-14BAMD Radeon™ RX 7800 XTDeepSeek-R1-Distill-Qwen-14BAMD Radeon™ RX 7700 XTDeepSeek-R1-Distill-Qwen-14BAMD Radeon™ RX 7600 XTDeepSeek-R1-Distill-Qwen-14BAMD Radeon™ RX 7600DeepSeek-R1-Distill-Llama-8B*= AMD recommends running all distills in Q4 K M quantization. 1= Lists the maximum supported distill without partial GPU offload.  Step 6: On the right-hand side, make sure the “Q4 K M” quantization is selected and click “Download”.Step 7: Once downloaded, head back to the chat tab and select the DeepSeek R1 distill from the drop-down menu and make sure “manually select parameters” is checked.Step 8: In the GPU offload layers – move the slider all the way to the max. Step 9: Click model load. Step 10: Interact with a reasoning model running completely on your local AMD hardware You can read all about it in the blog here.",
  "image": "https://www.guru3d.com/data/themes/Guru3D/images/logo_large.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle itemprop=\"articleBody\"\u003e\n                                \u003cdiv\u003e\n                                    \n                        \n                        \u003cp\u003e\u003cimg src=\"https://www.guru3d.com/data/teaser/default/amd-logo.png\" alt=\"teaser\"/\u003e\u003c/p\u003e\u003cp\u003eDeepSeek R1 Distilled Reasoning models use chain-of-thought reasoning to analyze complex prompts in detail. Instead of producing immediate replies, they spend time generating a “thinking” sequence, which often involves processing hundreds or thousands of tokens internally. This approach helps the model to evaluate various perspectives before generating a final response. Although this increases the wait time, it typically delivers more thorough results, which can be valuable for tasks in scientific research, mathematics, and other technical fields.\n                                    \u003c/p\u003e\u003cp\u003eAMD supports different sizes of DeepSeek R1 distillations across its processor and graphics card lineup. Larger processors, such as the Ryzen AI Max+ 395 Series, can run bigger distills like Qwen-32B, while mid-range products like Ryzen AI HX 370 or 7040/8040 often handle Qwen-14B or Llama-14B. For graphics cards, models like the Radeon RX 7900 XTX can accommodate Qwen-32B, but lower-tier cards generally work best with smaller versions. It is recommended to quantize these models in Q4 K M format to reduce memory usage and make the most of the available GPU resources.\u003c/p\u003e\n\u003cp\u003e To deploy a DeepSeek R1 distill, install the Adrenalin 25.1.1 driver or newer and download LM Studio 0.3.8 or above. Use the “Discover” tab in LM Studio to select your preferred model, confirm Q4 K M quantization, and adjust GPU offload layers to suit your system’s capacity. Once everything is configured, load the model in the “Chat” tab to start interacting with its chain-of-thought process. This local deployment approach can enhance data security and reduce latency since all reasoning is performed directly on AMD hardware. For reliable performance, consult official documentation to confirm your system meets driver and memory requirements.  \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStep 1:\u003c/strong\u003e Make sure you are on the 25.1.1 Optional or higher Adrenalin driver.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStep 2:\u003c/strong\u003e Download LM Studio 0.3.8 or above from \u003ca href=\"https://lmstudio.ai/ryzenai\" target=\"_blank\" rel=\"nofollow\"\u003elmstudio.ai/ryzenai\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStep 3:\u003c/strong\u003e Install LM Studio and skip the onboarding screen.\u003cbr/\u003e\u003cstrong\u003e\u003cbr/\u003eStep 4:\u003c/strong\u003e Click on the discover tab.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStep 5:\u003c/strong\u003e Choose your DeepSeek R1 Distill. Smaller distills like the Qwen 1.5B offer blazing fast performance (and are the recommended starting point) while bigger distills will offer superior reasoning capability. All of them are extremely capable. The table below details the maximum recommended DeepSeek R1 Distill size:\u003c/p\u003e\n\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003e\u003cstrong\u003eProcessor\u003c/strong\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003e\u003cstrong\u003eDeepSeek R1 Distill* (Max Supported)\u003c/strong\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Ryzen™ AI Max+ 395 32GB\u003csup\u003e1\u003c/sup\u003e, 64 GB\u003csup\u003e2 \u003c/sup\u003eand 128 GB\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Llama-70B (64GB and 128GB only)\u003cbr/\u003eDeepSeek-R1-Distill-Qwen-32B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Ryzen™ AI HX 370 and 365 24GB and 32 GB\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Ryzen™ 8040 and Ryzen™ 7040 32 GB\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Llama-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cp\u003e*= AMD recommends running all distills in Q4 K M quantization.\u003cbr/\u003e\u003csup\u003e1\u003c/sup\u003e= Requires Variable Graphics Memory set to Custom: 24GB.  \u003c/p\u003e\n\u003cp\u003e\u003csup\u003e2\u003c/sup\u003e= Requires Variable Graphics Memory set to High.\u003c/p\u003e\n\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003e\u003cstrong\u003eGraphics Card\u003c/strong\u003e\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003e\u003cstrong\u003eDeepSeek R1 Distill* (Max Supported\u003csup\u003e1\u003c/sup\u003e)\u003c/strong\u003e\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7900 XTX\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-32B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7900 XT\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7900 GRE\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7800 XT\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7700 XT\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7600 XT\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Qwen-14B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cp\u003eAMD Radeon™ RX 7600\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003eDeepSeek-R1-Distill-Llama-8B\u003c/p\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cp\u003e*= AMD recommends running all distills in Q4 K M quantization.\u003c/p\u003e\n\u003cdiv\u003e\u003cp\u003e\u003csup\u003e1\u003c/sup\u003e= Lists the maximum supported distill without partial GPU offload. \u003c/p\u003e\u003c/div\u003e\n\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eStep 6:\u003c/strong\u003e On the right-hand side, make sure the “Q4 K M” quantization is selected and click “Download”.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 7:\u003c/strong\u003e Once downloaded, head back to the chat tab and select the DeepSeek R1 distill from the drop-down menu and make sure “manually select parameters” is checked.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eStep 8\u003c/strong\u003e: In the GPU offload layers – move the slider all the way to the max.\u003c/p\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eStep 9:\u003c/strong\u003e Click model load.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStep 10:\u003c/strong\u003e Interact with a reasoning model running completely on your local AMD hardware\u003c/p\u003e\n\n\u003cp\u003eYou can read all about it in \u003ca href=\"https://community.amd.com/t5/ai/experience-the-deepseek-r1-distilled-reasoning-models-on-amd/ba-p/740593\" target=\"_blank\" rel=\"nofollow\"\u003ethe blog here\u003c/a\u003e.\u003c/p\u003e\n                                \u003c/div\u003e\n                            \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-01-29T17:04:00Z",
  "modifiedTime": "2025-01-29T18:04:00+01:00"
}
