{
  "id": "0b0d02e4-8022-4fa1-ac8c-a94008078e6f",
  "title": "Getting started with AI agents (part 1): Capturing processes, roles and connections",
  "link": "https://venturebeat.com/ai/getting-started-with-ai-agents-part-1-capturing-processes-roles-and-connections/",
  "description": "To get started with AI agents, we must first identify differences between agents and models and define roles and communication requirements.",
  "author": "Babak Hodjat, Cognizant",
  "published": "Sat, 23 Nov 2024 20:05:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI agents",
    "AI agents for security",
    "AI agents for software development",
    "AI Agents Platform",
    "AI, ML and Deep Learning",
    "category-/Business \u0026 Industrial/Business Operations",
    "category-/Computers \u0026 Electronics",
    "Conversational AI",
    "large language models",
    "NLP"
  ],
  "byline": "Babak Hodjat, Cognizant",
  "length": 10776,
  "excerpt": "To get started with AI agents, we must first identify differences between agents and models and define roles and communication requirements.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "November 23, 2024 12:05 PM VentureBeat/Ideogram Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More A modern-day AI agent consists of, at least, a large language model (LLM) that has been enabled to call some tools. Given the right set of tools for coding, it would start by generating the code, be able to run it in a container, observe the results, modify the code and therefore have a better chance of producing useful code. By contrast, a generative AI model takes some input and, through the process of predicting expectations, produces an output. For example, we give it a coding task, it produces some code, and, depending on the complexity of the task, the code may be usable as is. As they take on different tasks, agents should be allowed to talk to each other. For example, imagine your company intranet with its useful search box directing you to the apps and resources you need. If you are a large enough company, these apps owned by different departments each have their own search boxes. It makes a lot of sense to create agents, maybe by using techniques like retrieval augmented generation (RAG), to augment the search boxes. What does not make sense is to force the user to repeat their query once the search box has identified it as useful given the initial query. Rather, we would prefer the top agent to coordinate with other agents representing various apps and present a consolidated and unified chat interface to you, the user. A multi-agent system representing software or an organization’s various workflows can have several interesting advantages, including improved productivity and robustness, operational resilience and the ability ability to perform faster upgrades of different modules. Hopefully, this article will help you see how this is achieved. But first, how should we go about building these multi-agent systems? Capturing the organization and roles First we should capture the processes, roles, responsible nodes and connections of various actors in the organization. By actors, I mean individuals and/or software apps that act as knowledge workers within the organization. An organizational chart might be a good place to start, but I would suggest starting with workflows, as the same people within an organization tend to act with different processes and people depending on workflows. There are available tools that use AI to help identify workflows, or you can build your own gen AI model. I’ve built one as a GPT which takes the description of a domain or a company name and produces an agent network definition. Because I’m utilizing a multi-agent framework built in-house at my company, the GPT produces the network as a Hocon file, but it should be clear from the generated files what the roles and responsibilities of each agent are and what other agents it is connected to. Note that we want to make sure that the agent network is a directed acyclic graph (DAG). This means that no agent can simultaneously become down-chain and up-chain to any other agent, whether directly or indirectly. This greatly reduces the chances that queries in the agent network fall into a tailspin. In the examples outlined here, all agents are LLM-based. If a node in the multi-agent organization can have zero autonomy, then that agent paired with its human counterpart, should run everything by the human. We will need all processing nodes, be they apps, humans or existing agents, to be represented as agents. Lately there have been many announcements by companies offering specialized agents. We would, of course, want to make use of such agents, if available. We can pull in a preexisting agent and wrap its API into one of our agents so we can make use of our inter-agent communication protocols. This means that such third-party agents will need to have their API available for us to use. How to define agents Various agent architectures have been proposed in the past. For instance, a blackboard architecture requires a centralized point of communication where various agents declare their roles and capabilities, and the blackboard calls them depending on how it plans to fulfill a request (see OAA). I prefer a more distributed architecture that respects the encapsulation of responsibilities. Each agent, having received a request, decides whether it can process it or not, and what it requires to do to process the request, then returns its list of requirements to its requesting up-chain agent. If the agent has down-chains, it asks them if they can help fulfill all or part of the request. If it receives any requirements from the contacted down-chains, it checks with other agents to see if they can fulfill them; if not, it sends them up-chain so that they can ask the human user. This architecture is called the AAOSA architecture and — fun fact — was the architecture used in early versions of Siri. Here is a sample system prompt that can be used to turn an agent into an AAOSA agent. When you receive an inquiry, you will: Call your tools to determine which down-chain agents in your tools are responsible for all or part of it Ask down-chain agents what they need to handle their part of the inquiry. Once requirements are gathered, you will delegate the inquiry and the fulfilled requirements to the appropriate down-chain agents. Once all down-chain agents respond, you will compile their responses and return the final response. You may, in turn, be called by other agents in the system and have to act as a down-chain to them. In addition to the set of roles and responsibilities defined in natural language in each agent’s system prompt, agents may or may not include tools that they can call, with various arguments being passed to the tools. For instance, a product manager agent may need to be able to process various tickets on a virtual Kanban board, or an alerts agent may need to call a tool to issue alerts in an alerting system. Current multi-agent systems such as Microsoft AutoGen have elaborate and often hardcoded agent coordination mechanisms and architectures. I prefer a more robust setup where agents treat their immediate down-chain agents as tools, with loosely defined arguments that can be typed, and the semantics decided by the agents at the time of need. In this setup, a down-chain agent can be defined as a function call: “aaosa_call”: {       “description”: “Depending on the mode, returns a natural language string in response.”,       “parameters”: {           “type”: “object”,           “properties”: {               “inquiry”: {                   “type”: “string”,                   “description”: “The inquiry”               },               “mode”: {                   “type”: “string”,                   “description”: “”” indicates whether the agent is being asked to determine if the inquiry belongs to it in its entirety or in part. or if it is being asked to provide requirements to fulfill the inquiry, if any. or if it is being asked to respond to the inquiry.                   “””               },           },           “required”: [               “inquiry”,               “mode”           ]       } } AI agents in practice An agent network for a company’s intranet. Let’s explore an HR agent scenario. A user might inform the main search box agent of a life-changing event, such as “my significant other passed away,” trigger legal and HR agents that have a role to play in serving the user. This is because they, in turn, received information from some of their down-chain agents, namely legal advice, payroll and benefits agents. The resulting consolidated response that the user receives from the main search box agent will look like this: HR aspects: The benefits agent can the user help understand how the passing might impact benefits, health insurance, and retirement plans. You’ll need to provide information about the types of plans involved and whether your significant other was a dependent. The payroll agent can help manage tasks such as updating tax deductions or handling bereavement leave pay. This requires information about company policies on bereavement leave and current payroll setup. Legal aspects: Legal agents can offer general guidance as to how this passing should it relate to company affairs. Each department requires specific information to offer tailored support. An agent network for a telco with a B2B business. In an IT scenario, meanwhile, the single-entry point is the customer support rep agent that can handle complex multi-faceted requests such as: “Our network is slow. I think it is overloaded since we recently added personnel to our office. I will also need a quote for an upgrade.” An example response will outline the steps: Network performance assessment: The network ops center specialist can help address the slowness and potential overload issues. They need access to network performance data, details about the current network infrastructure, information about the number of personnel added and their network usage patterns. An upgraded quote: The sales engineer and field technician can help provide a quote for an upgrade. To do this they need: Specific information about the current network setup, including equipment and bandwidth requirements. Desired performance improvements. Budgetary constraints and any specific preferences or requirements. The scale of the upgrade and any specific performance goals. I hope this gave you a good idea of what is required to set up a multi-agent network. In the second installment, I will discuss the importance of implementing safeguards when creating multi-agent systems and outline how to build in controls to allow for human intervention and uncertainty checks. I will also detail required steps to create a safe-guard agent to oversee the agent network and dive deeper into challenges of developing multi-agent networks — such as tailspins and overloads — and how to mitigate them using timeouts, task division and redundancy.  Babak Hodjat is CTO for AI at Cognizant. DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2024/11/a-crisp-depiction-of-a-modern-database-with-data-f-8LL5ogcwSJOXI4FeYjS8Vg-bcJEyhzuROCEJaBq4NZf4Q-transformed.jpeg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-11-23T20:05:00+00:00\" datetime=\"2024-11-23T20:05:00+00:00\"\u003eNovember 23, 2024 12:05 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"421\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/a-crisp-depiction-of-a-modern-database-with-data-f-8LL5ogcwSJOXI4FeYjS8Vg-bcJEyhzuROCEJaBq4NZf4Q-transformed.jpeg?w=750\" alt=\"VentureBeat/Ideogram\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Ideogram\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eA modern-day AI agent consists of, at least, a \u003ca href=\"https://venturebeat.com/ai/here-are-3-critical-llm-compression-strategies-to-supercharge-ai-performance/\"\u003elarge language model\u003c/a\u003e (LLM) that has been enabled to call some tools. Given the right set of tools for coding, it would start by generating the code, be able to run it in a container, observe the results, modify the code and therefore have a better chance of producing useful code.\u003c/p\u003e\n\n\n\n\u003cp\u003eBy contrast, a generative AI model takes some input and, through the process of predicting expectations, produces an output. For example, we give it a coding task, it produces some code, and, depending on the complexity of the task, the code may be usable as is.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1392\" height=\"620\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png 1392w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=300,134 300w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=768,342 768w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=800,356 800w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=400,178 400w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=750,334 750w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=578,257 578w, https://venturebeat.com/wp-content/uploads/2024/11/image1_3895e5.png?resize=930,414 930w\" sizes=\"(max-width: 1392px) 100vw, 1392px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eAs they take on different tasks, agents should be allowed to \u003ca href=\"https://venturebeat.com/ai/enter-the-whisperverse-how-ai-voice-agents-will-guide-us-through-our-days/\"\u003etalk to each other\u003c/a\u003e. For example, imagine your company intranet with its useful search box directing you to the apps and resources you need. If you are a large enough company, these apps owned by different departments each have their own search boxes. It makes a lot of sense to create agents, maybe by using techniques like retrieval augmented generation (RAG), to augment the search boxes. What does not make sense is to force the user to repeat their query once the search box has identified it as useful given the initial query. Rather, we would prefer the top agent to coordinate with other agents representing various apps and present a consolidated and unified chat interface to you, the user. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1678\" height=\"874\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image3.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image3.png 1678w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=300,156 300w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=768,400 768w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=800,417 800w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=1536,800 1536w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=400,208 400w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=750,391 750w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=578,301 578w, https://venturebeat.com/wp-content/uploads/2024/11/image3.png?resize=930,484 930w\" sizes=\"(max-width: 1678px) 100vw, 1678px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eA multi-agent system representing software or an organization’s various workflows can have several interesting advantages, including improved productivity and robustness, operational resilience and the ability ability to perform faster upgrades of different modules. Hopefully, this article will help you see how this is achieved.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut first, how should we go about building these multi-agent systems?\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-capturing-the-organization-and-roles\"\u003eCapturing the organization and roles\u003c/h2\u003e\n\n\n\n\u003cp\u003eFirst we should capture the processes, roles, responsible nodes and connections of \u003ca href=\"https://venturebeat.com/ai/our-brains-are-vector-databases-heres-why-thats-helpful-when-using-ai/\"\u003evarious actors\u003c/a\u003e in the organization. By actors, I mean individuals and/or software apps that act as knowledge workers within the organization.\u003c/p\u003e\n\n\n\n\u003cp\u003eAn organizational chart might be a good place to start, but I would suggest starting with workflows, as the same people within an organization tend to act with different processes and people depending on workflows. \u003c/p\u003e\n\n\n\n\u003cp\u003eThere are available tools that use AI to help identify workflows, or you can build your own gen AI model. I’ve built one as a \u003ca href=\"https://chatgpt.com/g/g-sTddXCXO8-neuro-ai-agent-network-generator\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGPT\u003c/a\u003e which takes the description of a domain or a company name and produces an agent network definition. Because I’m utilizing a multi-agent framework built in-house at my company, the GPT produces the network as a Hocon file, but it should be clear from the generated files what the roles and responsibilities of each agent are and what other agents it is connected to.\u003c/p\u003e\n\n\n\n\u003cp\u003eNote that we want to make sure that the agent network is a directed acyclic graph (DAG). This means that no agent can simultaneously become down-chain and up-chain to any other agent, whether directly or indirectly. This greatly reduces the chances that queries in the agent network fall into a tailspin.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn the examples outlined here, all agents are LLM-based. If a node in the \u003ca href=\"https://venturebeat.com/ai/why-multi-agent-ai-conquers-complexities-llms-cant/\"\u003emulti-agent organization\u003c/a\u003e can have zero autonomy, then that agent paired with its human counterpart, should run everything by the human. We will need all processing nodes, be they apps, humans or existing agents, to be represented as agents.\u003c/p\u003e\n\n\n\n\u003cp\u003eLately there have been many announcements by companies offering specialized agents. We would, of course, want to make use of such agents, if available. We can pull in a preexisting agent and wrap its API into one of our agents so we can make use of our inter-agent communication protocols. This means that such third-party agents will need to have their API available for us to use.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-how-to-define-agents\"\u003eHow to define agents\u003c/h2\u003e\n\n\n\n\u003cp\u003eVarious agent architectures have been proposed in the past. For instance, a blackboard architecture requires a centralized point of communication where various agents declare their roles and capabilities, and the blackboard calls them depending on how it plans to fulfill a request (see \u003ca href=\"https://en.wikipedia.org/wiki/Open_Agent_Architecture\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOAA\u003c/a\u003e).\u003c/p\u003e\n\n\n\n\u003cp\u003eI prefer a more distributed architecture that respects the encapsulation of responsibilities. Each agent, having received a request, decides whether it can process it or not, and what it requires to do to process the request, then returns its list of requirements to its requesting up-chain agent. If the agent has down-chains, it asks them if they can help fulfill all or part of the request. If it receives any requirements from the contacted down-chains, it checks with other agents to see if they can fulfill them; if not, it sends them up-chain so that they can ask the human user. This architecture is called the \u003ca href=\"https://link.springer.com/chapter/10.1007/3-540-44564-1_19\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAAOSA\u003c/a\u003e architecture and — fun fact — was the architecture used in early versions of Siri.\u003c/p\u003e\n\n\n\n\u003cp\u003eHere is a sample system prompt that can be used to turn an agent into an AAOSA agent. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhen you receive an inquiry, you will: \u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eCall your tools to determine which down-chain agents in your tools are responsible for all or part of it\u003c/li\u003e\n\n\n\n\u003cli\u003eAsk down-chain agents what they need to handle their part of the inquiry. \u003c/li\u003e\n\n\n\n\u003cli\u003eOnce requirements are gathered, you will delegate the inquiry and the fulfilled requirements to the appropriate down-chain agents.\u003c/li\u003e\n\n\n\n\u003cli\u003eOnce all down-chain agents respond, you will compile their responses and return the final response.\u003c/li\u003e\n\n\n\n\u003cli\u003eYou may, in turn, be called by other agents in the system and have to act as a down-chain to them.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eIn addition to the set of roles and responsibilities defined in natural language in each agent’s system prompt, agents may or may not include tools that they can call, with various arguments being passed to the tools. For instance, a product manager agent may need to be able to process various tickets on a virtual Kanban board, or an alerts agent may need to call a tool to issue alerts in an alerting system.\u003c/p\u003e\n\n\n\n\u003cp\u003eCurrent multi-agent systems such as Microsoft AutoGen have elaborate and often hardcoded agent coordination mechanisms and architectures. I prefer a more robust setup where agents treat their immediate down-chain agents as tools, with loosely defined arguments that can be typed, and the semantics decided by the agents at the time of need.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn this setup, a down-chain agent can be defined as a function call:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e“aaosa_call”: {\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e      “description”: “Depending on the mode, returns a natural language string in response.”,\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e      “parameters”: {\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e          “type”: “object”,\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e          “properties”: {\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e              “inquiry”: {\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e                  “type”: “string”,\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e                  “description”: “The inquiry”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e              \u003c/em\u003e\u003c/strong\u003e\u003cem\u003e},\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e              “mode”: {\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e                  “type”: “string”,\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e                  “description”: “””\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eindicates whether the agent is being asked to determine if the inquiry belongs to it\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003ein its entirety or in part. or if it is being asked to provide requirements to fulfill\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003ethe inquiry, if any. or if it is being asked to respond to the inquiry.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e                  “””\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e              },\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e          },\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e          “required”: [\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e              “inquiry”,\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e              “mode”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e          ]\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e      }\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003e}\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-ai-agents-in-practice\"\u003eAI agents in practice\u003c/h2\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1492\" height=\"1384\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?w=647\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png 1492w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=300,278 300w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=768,712 768w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=647,600 647w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=400,371 400w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=750,696 750w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=578,536 578w, https://venturebeat.com/wp-content/uploads/2024/11/image2_7600db.png?resize=930,863 930w\" sizes=\"(max-width: 1492px) 100vw, 1492px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eAn agent network for a company’s intranet. \u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eLet’s explore an HR agent scenario. A user might inform the main search box agent of a life-changing event, such as “my significant other passed away,” trigger legal and HR agents that have a role to play in serving the user. This is because they, in turn, received information from some of their down-chain agents, namely legal advice, payroll and benefits agents. The resulting consolidated response that the user receives from the \u003ca href=\"https://venturebeat.com/ai/the-great-ai-masquerade-when-automation-wears-an-agent-costume/\"\u003emain search box agent\u003c/a\u003e will look like this:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cem\u003eHR aspects:\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eThe benefits agent can the user help understand how the passing might impact benefits, health insurance, and retirement plans. You’ll need to provide information about the types of plans involved and whether your significant other was a dependent.\u003c/li\u003e\n\n\n\n\u003cli\u003eThe payroll agent can help manage tasks such as updating tax deductions or handling bereavement leave pay. This requires information about company policies on bereavement leave and current payroll setup.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cem\u003eLegal aspects:\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eLegal agents can offer general guidance as to how this passing should it relate to company affairs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eEach department requires specific information to offer tailored support.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"958\" height=\"1354\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?w=425\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png 958w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=283,400 283w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=768,1085 768w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=425,600 425w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=400,565 400w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=750,1060 750w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=578,817 578w, https://venturebeat.com/wp-content/uploads/2024/11/image4_ac182d.png?resize=930,1314 930w\" sizes=\"(max-width: 958px) 100vw, 958px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eAn agent network for a telco with a B2B business.\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIn an IT scenario, meanwhile, the single-entry point is the customer support rep agent that can handle complex multi-faceted requests such as: “Our network is slow. I think it is overloaded since we recently added personnel to our office. I will also need a quote for an upgrade.”\u003c/p\u003e\n\n\n\n\u003cp\u003eAn example response will outline the steps: \u003c/p\u003e\n\n\n\n\u003cp\u003eNetwork performance assessment: The network ops center specialist can help address the slowness and potential overload issues. They need access to network performance data, details about the current network infrastructure, information about the number of personnel added and their network usage patterns.\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\n\u003c/li\u003e\u003c/ol\u003e\n\n\n\n\u003cp\u003eAn upgraded quote: The sales engineer and field technician can help provide a quote for an upgrade. To do this they need:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eSpecific information about the current network setup, including equipment and bandwidth requirements.\u003c/li\u003e\n\n\n\n\u003cli\u003eDesired performance improvements.\u003c/li\u003e\n\n\n\n\u003cli\u003eBudgetary constraints and any specific preferences or requirements.\u003c/li\u003e\n\n\n\n\u003cli\u003eThe scale of the upgrade and any specific performance goals.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eI hope this gave you a good idea of what is required to set up a multi-agent network. In the second installment, I will discuss the importance of implementing safeguards when creating multi-agent systems and outline how to build in controls to allow for human intervention and uncertainty checks. I will also detail required steps to create a safe-guard agent to oversee the agent network and dive deeper into challenges of developing multi-agent networks — such as tailspins and overloads — and how to mitigate them using timeouts, task division and redundancy.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e Babak Hodjat is CTO for AI at \u003ca href=\"https://www.cognizant.com/us/en\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eCognizant\u003c/a\u003e\u003c/em\u003e. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2024-11-23T20:05:00Z",
  "modifiedTime": "2024-11-23T20:30:46Z"
}
