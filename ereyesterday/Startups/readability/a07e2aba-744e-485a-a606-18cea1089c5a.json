{
  "id": "a07e2aba-744e-485a-a606-18cea1089c5a",
  "title": "AI agents are hitting a liability wall. Mixus has a plan to overcome it using human overseers on high-risk workflows",
  "link": "https://venturebeat.com/ai/ai-agents-are-hitting-a-liability-wall-mixus-has-a-plan-to-overcome-it-using-human-overseers-on-high-risk-workflows/",
  "description": "Mixus's \"colleague-in-the-loop\" model blends automation with human judgment for safe deployment of AI agents.",
  "author": "Ben Dickson",
  "published": "Sat, 28 Jun 2025 14:27:45 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "Agentic AI",
    "AI agents",
    "AI Hallucinations",
    "AI, ML and Deep Learning",
    "large language models",
    "LLMs"
  ],
  "byline": "Ben Dickson",
  "length": 6973,
  "excerpt": "Mixus's \"colleague-in-the-loop\" model blends automation with human judgment for safe deployment of AI agents.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "June 28, 2025 7:27 AM Image credit: VentureBeat with ChatGPT Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. Learn more While enterprises face the challenges of deploying AI agents in critical applications, a new, more pragmatic model is emerging that puts humans back in control as a strategic safeguard against AI failure.  One such example is Mixus, a platform that uses a “colleague-in-the-loop” approach to make AI agents reliable for mission-critical work. This approach is a response to the growing evidence that fully autonomous agents are a high-stakes gamble.  The high cost of unchecked AI The problem of AI hallucinations has become a tangible risk as companies explore AI applications. In a recent incident, the AI-powered code editor Cursor saw its own support bot invent a fake policy restricting subscriptions, sparking a wave of public customer cancellations.  Similarly, the fintech company Klarna famously reversed course on replacing customer service agents with AI after admitting the move resulted in lower quality. In a more alarming case, New York City’s AI-powered business chatbot advised entrepreneurs to engage in illegal practices, highlighting the catastrophic compliance risks of unmonitored agents. These incidents are symptoms of a larger capability gap. According to a May 2025 Salesforce research paper, today’s leading agents succeed only 58% of the time on single-step tasks and just 35% of the time on multi-step ones, highlighting “a significant gap between current LLM capabilities and the multifaceted demands of real-world enterprise scenarios.”  The colleague-in-the-loop model To bridge this gap, a new approach focuses on structured human oversight. “An AI agent should act at your direction and on your behalf,” Mixus co-founder Elliot Katz told VentureBeat. “But without built-in organizational oversight, fully autonomous agents often create more problems than they solve.”  This philosophy underpins Mixus’s colleague-in-the-loop model, which embeds human verification directly into automated workflows. For example, a large retailer might receive weekly reports from thousands of stores that contain critical operational data (e.g., sales volumes, labor hours, productivity ratios, compensation requests from headquarters). Human analysts must spend hours manually reviewing the data and making decisions based on heuristics. With Mixus, the AI agent automates the heavy lifting, analyzing complex patterns and flagging anomalies like unusually high salary requests or productivity outliers.  For high-stakes decisions like payment authorizations or policy violations — workflows defined by a human user as “high-risk” — the agent pauses and requires human approval before proceeding. The division of labor between AI and humans has been integrated into the agent creation process. “This approach means humans only get involved when their expertise actually adds value — typically the critical 5-10% of decisions that could have significant impact — while the remaining 90-95% of routine tasks flow through automatically,” Katz said. “You get the speed of full automation for standard operations, but human oversight kicks in precisely when context, judgment, and accountability matter most.” In a demo that the Mixus team showed to VentureBeat, creating an agent is an intuitive process that can be done with plain-text instructions. To build a fact-checking agent for reporters, for example, co-founder Shai Magzimof simply described the multi-step process in natural language and instructed the platform to embed human verification steps with specific thresholds, such as when a claim is high-risk and can result in reputational damage or legal consequences.  One of the platform’s core strengths is its integrations with tools like Google Drive, email, and Slack, allowing enterprise users to bring their own data sources into workflows and interact with agents directly from their communication platform of choice, without having to switch contexts or learn a new interface (for example, the fact-checking agent was instructed to send approval requests to the editor’s email). The platform’s integration capabilities extend further to meet specific enterprise needs. Mixus supports the Model Context Protocol (MCP), which enables businesses to connect agents to their bespoke tools and APIs, avoiding the need to reinvent the wheel for existing internal systems. Combined with integrations for other enterprise software like Jira and Salesforce, this allows agents to perform complex, cross-platform tasks, such as checking on open engineering tickets and reporting the status back to a manager on Slack. Human oversight as a strategic multiplier The enterprise AI space is currently undergoing a reality check as companies move from experimentation to production. The consensus among many industry leaders is that humans in the loop are a practical necessity for agents to perform reliably.  AI Agents will likely follow a self driving trajectory, where you need a human in the loop for a long tail of tasks for a while. The big difference is we’ll get a growing number of autonomous agents along the way, where full self driving is an all or nothing proposition. https://t.co/5dR7cGS7jn— Aaron Levie (@levie) June 20, 2025 Mixus’s collaborative model changes the economics of scaling AI. Mixus predicts that by 2030, agent deployment may grow 1000x and each human overseer will become 50x more efficient as AI agents become more reliable. But the total need for human oversight will still grow.  “Each human overseer manages exponentially more AI work over time, but you still need more total oversight as AI deployment explodes across your organization,” Katz said.  For enterprise leaders, this means human skills will evolve rather than disappear. Instead of being replaced by AI, experts will be promoted to roles where they orchestrate fleets of AI agents and handle the high-stakes decisions flagged for their review. In this framework, building a strong human oversight function becomes a competitive advantage, allowing companies to deploy AI more aggressively and safely than their rivals. “Companies that master this multiplication will dominate their industries, while those chasing full automation will struggle with reliability, compliance, and trust,” Katz said. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/06/ChatGPT-Image-Jun-27-2025-10_10_45-PM.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-06-28T14:27:45+00:00\" datetime=\"2025-06-28T14:27:45+00:00\"\u003eJune 28, 2025 7:27 AM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"500\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/ChatGPT-Image-Jun-27-2025-10_10_45-PM.png?w=750\" alt=\"AI agent and human collaborate\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eImage credit: VentureBeat with ChatGPT\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. \u003ca href=\"http://vbtransform.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLearn more\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eWhile enterprises face the challenges of deploying AI agents in critical applications, a new, more pragmatic model is emerging that puts humans back in control as a strategic safeguard against AI failure. \u003c/p\u003e\n\n\n\n\u003cp\u003eOne such example is \u003ca href=\"https://www.mixus.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMixus\u003c/a\u003e, a platform that uses a “colleague-in-the-loop” approach to make AI agents reliable for mission-critical work. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis approach is a response to the growing evidence that fully autonomous agents are a high-stakes gamble. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-high-cost-of-unchecked-ai\"\u003eThe high cost of unchecked AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe problem of \u003ca href=\"https://arstechnica.com/ai/2025/04/cursor-ai-support-bot-invents-fake-policy-and-triggers-user-uproar/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAI hallucinations\u003c/a\u003e has become a tangible risk as companies explore AI applications. In a recent incident, the AI-powered code editor Cursor saw its own support bot \u003ca href=\"https://arstechnica.com/ai/2025/04/cursor-ai-support-bot-invents-fake-policy-and-triggers-user-uproar/\"\u003einvent a fake policy\u003c/a\u003e restricting subscriptions, sparking a wave of public customer cancellations. \u003c/p\u003e\n\n\n\n\u003cp\u003eSimilarly, the fintech company Klarna famously \u003ca href=\"https://futurism.com/klarna-openai-humans-ai-back\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ereversed course\u003c/a\u003e on replacing customer service agents with AI after admitting the move resulted in lower quality. In a more alarming case, New York City’s AI-powered business chatbot advised entrepreneurs to \u003ca href=\"https://apnews.com/article/new-york-city-chatbot-misinformation-6ebc71db5b770b9969c906a7ee4fae21\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eengage in illegal practices\u003c/a\u003e, highlighting the catastrophic compliance risks of unmonitored agents.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese incidents are symptoms of a larger capability gap. According to a May 2025 Salesforce \u003ca href=\"https://arxiv.org/abs/2505.18878\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eresearch paper\u003c/a\u003e, today’s leading agents succeed only 58% of the time on single-step tasks and just 35% of the time on multi-step ones, highlighting “a significant gap between current LLM capabilities and the multifaceted demands of real-world enterprise scenarios.” \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-colleague-in-the-loop-model\"\u003eThe colleague-in-the-loop model\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo bridge this gap, a new approach focuses on structured human oversight. “An AI agent should act at your direction and on your behalf,” Mixus co-founder Elliot Katz told VentureBeat. “But without built-in organizational oversight, fully autonomous agents often create more problems than they solve.” \u003c/p\u003e\n\n\n\n\u003cp\u003eThis philosophy underpins Mixus’s colleague-in-the-loop model, which embeds human verification directly into automated workflows. For example, a large retailer might receive weekly reports from thousands of stores that contain critical operational data (e.g., sales volumes, labor hours, productivity ratios, compensation requests from headquarters). Human analysts must spend hours manually reviewing the data and making decisions based on heuristics. With Mixus, the AI agent automates the heavy lifting, analyzing complex patterns and flagging anomalies like unusually high salary requests or productivity outliers. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" height=\"469\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png 1612w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=300,176 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=768,451 768w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=800,469 800w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=1536,901 1536w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=400,235 400w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=750,440 750w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=578,339 578w, https://venturebeat.com/wp-content/uploads/2025/06/image_ec02d1.png?resize=930,546 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFor high-stakes decisions like payment authorizations or policy violations — workflows defined by a human user as “high-risk” — the agent pauses and requires human approval before proceeding. The division of labor between AI and humans has been integrated into the agent creation process.\u003c/p\u003e\n\n\n\n\u003cp\u003e“This approach means humans only get involved when their expertise actually adds value — typically the critical 5-10% of decisions that could have significant impact — while the remaining 90-95% of routine tasks flow through automatically,” Katz said. “You get the speed of full automation for standard operations, but human oversight kicks in precisely when context, judgment, and accountability matter most.”\u003c/p\u003e\n\n\n\n\u003cp\u003eIn a demo that the Mixus team showed to VentureBeat, creating an agent is an intuitive process that can be done with plain-text instructions. To build a fact-checking agent for reporters, for example, co-founder Shai Magzimof simply described the multi-step process in natural language and instructed the platform to embed human verification steps with specific thresholds, such as when a claim is high-risk and can result in reputational damage or legal consequences. \u003c/p\u003e\n\n\n\n\u003cp\u003eOne of the platform’s core strengths is its integrations with tools like Google Drive, email, and Slack, allowing enterprise users to bring their own data sources into workflows and interact with agents directly from their communication platform of choice, without having to switch contexts or learn a new interface (for example, the fact-checking agent was instructed to send approval requests to the editor’s email).\u003c/p\u003e\n\n\n\n\u003cp\u003eThe platform’s integration capabilities extend further to meet specific enterprise needs. Mixus supports the \u003ca href=\"https://venturebeat.com/ai/model-context-protocol-a-promising-ai-integration-layer-but-not-a-standard-yet/\"\u003eModel Context Protocol\u003c/a\u003e (MCP), which enables businesses to connect agents to their bespoke tools and APIs, avoiding the need to reinvent the wheel for existing internal systems. Combined with integrations for other enterprise software like Jira and Salesforce, this allows agents to perform complex, cross-platform tasks, such as checking on open engineering tickets and reporting the status back to a manager on Slack.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-human-oversight-as-a-strategic-multiplier\"\u003eHuman oversight as a strategic multiplier\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe enterprise AI space is currently undergoing a reality check as companies move from experimentation to production. The consensus among many industry leaders is that humans in the loop are a practical necessity for agents to perform reliably. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cdiv\u003e\n\u003cblockquote data-width=\"500\" data-dnt=\"true\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003eAI Agents will likely follow a self driving trajectory, where you need a human in the loop for a long tail of tasks for a while. The big difference is we’ll get a growing number of autonomous agents along the way, where full self driving is an all or nothing proposition. \u003ca href=\"https://t.co/5dR7cGS7jn\"\u003ehttps://t.co/5dR7cGS7jn\u003c/a\u003e\u003c/p\u003e— Aaron Levie (@levie) \u003ca href=\"https://twitter.com/levie/status/1935898443794583950?ref_src=twsrc%5Etfw\"\u003eJune 20, 2025\u003c/a\u003e\u003c/blockquote\u003e\n\u003c/div\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eMixus’s collaborative model changes the economics of scaling AI. Mixus predicts that by 2030, agent deployment may grow 1000x and each human overseer will become 50x more efficient as AI agents become more reliable. But the total need for human oversight will still grow. \u003c/p\u003e\n\n\n\n\u003cp\u003e“Each human overseer manages exponentially more AI work over time, but you still need more total oversight as AI deployment explodes across your organization,” Katz said. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" height=\"372\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13%E2%80%AFAM.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png 1346w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=300,140 300w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=768,357 768w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=800,372 800w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=400,186 400w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=750,349 750w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=578,269 578w, https://venturebeat.com/wp-content/uploads/2025/06/Screenshot-2025-06-27-at-7.12.13 AM.png?resize=930,433 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFor enterprise leaders, this means human skills will evolve rather than disappear. Instead of being replaced by AI, experts will be promoted to roles where they orchestrate fleets of AI agents and handle the high-stakes decisions flagged for their review. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn this framework, building a strong human oversight function becomes a competitive advantage, allowing companies to deploy AI more aggressively and safely than their rivals.\u003c/p\u003e\n\n\n\n\u003cp\u003e“Companies that master this multiplication will dominate their industries, while those chasing full automation will struggle with reliability, compliance, and trust,” Katz said.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-06-28T14:27:45Z",
  "modifiedTime": "2025-06-28T20:31:09Z"
}
