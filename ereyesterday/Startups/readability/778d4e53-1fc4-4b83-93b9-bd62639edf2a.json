{
  "id": "778d4e53-1fc4-4b83-93b9-bd62639edf2a",
  "title": "Phi-4 Reasoning Models",
  "link": "https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/",
  "description": "Article URL: https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/ Comments URL: https://news.ycombinator.com/item?id=43852564 Points: 6 # Comments: 0",
  "author": "meetpateltech",
  "published": "Thu, 01 May 2025 01:02:41 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "Weizhu Chen, Ece Kamar",
  "length": 8303,
  "excerpt": "Microsoft continues to add to the conversation by unveiling its newest models, Phi-4-reasoning, Phi-4-reasoning-plus, and Phi-4-mini-reasoning. Learn more.",
  "siteName": "Microsoft Azure Blog",
  "favicon": "",
  "text": "Microsoft continues to add to the conversation by unveiling its newest models, Phi-4-reasoning, Phi-4-reasoning-plus, and Phi-4-mini-reasoning.  A new era of AI  One year ago, Microsoft introduced small language models (SLMs) to customers with the release of Phi-3 on Azure AI Foundry, leveraging research on SLMs to expand the range of efficient AI models and tools available to customers.  Today, we are excited to introduce Phi-4-reasoning, Phi-4-reasoning-plus, and Phi-4-mini-reasoning—marking a new era for small language models and once again redefining what is possible with small and efficient AI.  Reasoning models, the next step forward  Reasoning models are trained to leverage inference-time scaling to perform complex tasks that demand multi-step decomposition and internal reflection. They excel in mathematical reasoning and are emerging as the backbone of agentic applications with complex multi-faceted tasks. Such capabilities are typically found only in large frontier models. Phi- reasoning models introduce a new category of small language models. Using distillation, reinforcement learning, and high-quality data, these models balance size and performance. They are small enough for low-latency environments yet maintain strong reasoning capabilities that rival much bigger models. This blend allows even resource-limited devices to perform complex reasoning tasks efficiently.  Phi-4-mini-reasoning  Phi-4-mini-reasoning is designed to meet the demand for a compact reasoning model. This transformer-based language model is optimized for mathematical reasoning, providing high-quality, step-by-step problem solving in environments with constrained computing or latency. Fine-tuned with synthetic data generated by Deepseek-R1 model, Phi-4-mini-reasoning balances efficiency with advanced reasoning ability. It’s ideal for educational applications, embedded tutoring, and lightweight deployment on edge or mobile systems, and trained on over one million diverse math problems spanning multiple levels of difficulty from middle school to Ph.D. level. Try out the model on Azure AI Foundry or HuggingFace today. Figure 1. The graph compares the performance of various models on popular math benchmarks for long sentence generation. Phi-4-mini-reasoning outperforms its base model on long sentence generation across each evaluation as well as larger models like OpenThinker-7B*, Llama-3.2-3B-instruct, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Llama -8B, and Bespoke-Stratos-7B*. Phi-4-mini-reasoning is comparable to OpenAI o1-mini* across math benchmarks, surpassing the model’s performance during Math-500 and GPQA Diamond evaluations. As seen above, Phi-4-mini-reasoning with 3.8B parameters outperforms models of over twice its size.  For more information about the model, read the technical report that provides additional quantitative insights.  Phi-4-reasoning and Phi-4-reasoning-plus  Phi-4-reasoning is a 14-billion parameter open-weight reasoning model that rivals much larger models on complex reasoning tasks. Trained via supervised fine-tuning of Phi-4 on carefully curated reasoning demonstrations from OpenAI o3-mini, Phi-4-reasoning generates detailed reasoning chains that effectively leverage additional inference-time compute. The model demonstrates that meticulous data curation and high-quality synthetic datasets allow smaller models to compete with larger counterparts. This model is available now on Azure AI Foundry and HuggingFace. Phi-4-reasoning-plus builds upon Phi-4-reasoning capabilities, further trained with reinforcement learning to utilize more inference-time compute, using 1.5x more tokens than Phi-4-reasoning, to deliver higher accuracy. This model is coming to Azure AI Foundry soon, but available today on HuggingFace.  Despite their significantly smaller size, both models achieve better performance than OpenAI o1-mini and DeepSeek-R1-Distill-Llama-70B at most benchmarks, including mathematical reasoning and Ph.D. level science questions. They achieve performance better than the full DeepSeek-R1 model (with 671-billion parameters) on the AIME 2025 test, the 2025 qualifier for the USA Math Olympiad. Figure 2. Phi-4-reasoning performance across representative reasoning benchmarks spanning mathematical and scientific reasoning. We illustrate the performance gains from reasoning-focused post-training of Phi-4 via Phi-4-reasoning (SFT) and Phi-4-reasoning-plus (SFT+RL), alongside a representative set of baselines from two model families: open-weight models from DeepSeek including DeepSeek R1 (671B Mixture-of-Experts) and its distilled dense variant DeepSeek-R1 Distill Llama 70B, and OpenAI’s proprietary frontier models o1-mini and o3-mini. Phi-4-reasoning and Phi-4-reasoning-plus consistently outperform the base model Phi-4 by significant margins, exceed DeepSeek-R1 Distill Llama 70B (5x larger) and demonstrate competitive performance against significantly larger models such as Deepseek-R1. Figure 3. Accuracy of models across general-purpose benchmarks for: long input context QA (FlenQA), instruction following (IFEval), Coding (HumanEvalPlus), knowledge \u0026 language understanding (MMLUPro), safety detection (ToxiGen), and other general skills (ArenaHard and PhiBench).  Phi-4-reasoning models introduce a major improvement over Phi-4, surpass larger models like DeepSeek-R1-Distill-70B and approach Deep-Seek-R1 across various reasoning and general capabilities, including math, coding, algorithmic problem solving, and planning. The technical report provides extensive quantitative evidence of these improvements through diverse reasoning tasks. Phi’s evolution over the last year has continually pushed this envelope of quality vs. size, expanding the family with new to address diverse needs. Across the scale of Windows 11 devices, these models are available to run locally on CPUs and GPUs. As Windows works towards creating a new type of PC, Phi models have become an integral part of Copilot+ PCs with the NPU-optimized Phi Silica variant. This highly efficient and OS-managed version of Phi is designed to be preloaded in memory, and available with blazing fast time to first token responses, and power efficient token throughput so it can be concurrently invoked with other applications running on your PC.  It is used in core experiences like Click to Do providing useful text intelligence tools for any content on your screen and is available as developer APIs to be readily integrated into applications—already being used in several productivity applications like Outlook offering its Copilot summary features offline. These small but mighty models have already been optimized and integrated to be used across several applications across the breadth of our PC ecosystem. The Phi-4-reasoning and Phi-4-mini-reasoning models leverage the low-bit optimizations for Phi Silica and will be available to run soon on Copilot+ PC NPUs.  Safety and Microsoft’s approach to responsible AI  At Microsoft, responsible AI is a fundamental principle guiding the development and deployment of AI systems, including our Phi models. Phi models are developed in accordance with Microsoft AI principles: accountability, transparency, fairness, reliability and safety, privacy and security, and inclusiveness.  The Phi family of models has adopted a robust safety post-training approach, leveraging a combination of Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Reinforcement Learning from Human Feedback (RLHF) techniques. These methods utilize various datasets, including publicly available datasets focused on helpfulness and harmlessness, as well as various safety-related questions and answers. While the Phi family of models is designed to perform a wide range of tasks effectively, it is important to acknowledge that all AI models may exhibit limitations. To better understand these limitations and the measures in place to address them, please refer to the model cards below, which provide detailed information on responsible AI practices and guidelines.  Learn more here:  Try out the new models on Azure AI Foundry. Read the Phi Cookbook. Read about Phi reasoning models on edge devices.",
  "image": "https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/04/Azure_1053431_Blog_250429.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-bi-an=\"Blog Body\"\u003e\n\t\t\t\t\t\t\n\u003carticle id=\"post-39977\"\u003e\n\n\t\n\t\u003cdiv\u003e\n\t\t\u003cp\u003e\n\t\t\tMicrosoft continues to add to the conversation by unveiling its newest models, Phi-4-reasoning, Phi-4-reasoning-plus, and Phi-4-mini-reasoning. \t\t\u003c/p\u003e\n\t\t\n\t\t\n\u003cp\u003e\u003cstrong\u003eA new era of AI \u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eOne year ago, Microsoft introduced \u003cstrong\u003esmall language models\u003c/strong\u003e (SLMs) to customers with the release of \u003cstrong\u003ePhi-3\u003c/strong\u003e on \u003ca href=\"https://ai.azure.com/?tid=72f988bf-86f1-41af-91ab-2d7cd011db47\"\u003eAzure AI Foundry\u003c/a\u003e, leveraging research on SLMs to expand the range of efficient AI models and tools available to customers. \u003c/p\u003e\n\n\n\n\u003cp\u003eToday, we are excited to introduce \u003cstrong\u003ePhi-4-reasoning, Phi-4-reasoning-plus, and Phi-4-mini-reasoning\u003c/strong\u003e—marking a new era for small language models and once again redefining what is possible with small and efficient AI. \u003c/p\u003e\n\n\n\n\n\n\n\n\u003ch2 id=\"reasoning-models-the-next-step-forward\"\u003eReasoning models, the next step forward \u003c/h2\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eReasoning models\u003c/strong\u003e are trained to leverage inference-time scaling to perform complex tasks that demand multi-step decomposition and internal reflection. They excel in mathematical reasoning and are emerging as the backbone of agentic applications with complex multi-faceted tasks. Such capabilities are typically found only in large frontier models. Phi- reasoning models introduce a new category of small language models. Using distillation, reinforcement learning, and high-quality data, these models balance size and performance. They are small enough for low-latency environments yet maintain strong reasoning capabilities that rival much bigger models. This blend allows even resource-limited devices to perform complex reasoning tasks efficiently. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"phi-4-mini-reasoning\"\u003ePhi-4-mini-reasoning \u003c/h2\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003ePhi-4-mini-reasoning\u003c/strong\u003e is designed to meet the demand for a compact reasoning model. This transformer-based language model is optimized for mathematical reasoning, providing high-quality, step-by-step problem solving in environments with constrained computing or latency. Fine-tuned with synthetic data generated by Deepseek-R1 model, Phi-4-mini-reasoning balances efficiency with advanced reasoning ability. It’s ideal for educational applications, embedded tutoring, and lightweight deployment on edge or mobile systems, and trained on over one million diverse math problems spanning multiple levels of difficulty from middle school to Ph.D. level. Try out the model on \u003ca href=\"https://aka.ms/phi4-mini-reasoning/azure\"\u003eAzure AI Foundry\u003c/a\u003e or \u003ca href=\"https://aka.ms/phi4-mini-reasoning/hf\"\u003eHuggingFace\u003c/a\u003e today.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/04/image-8-1024x340.webp\" alt=\"A graph of different colored bars\"/\u003e\u003cfigcaption\u003eFigure 1. The graph compares the performance of various models on popular math benchmarks for long sentence generation. Phi-4-mini-reasoning outperforms its base model on long sentence generation across each evaluation as well as larger models like OpenThinker-7B*, Llama-3.2-3B-instruct, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Llama -8B, and Bespoke-Stratos-7B*. Phi-4-mini-reasoning is comparable to OpenAI o1-mini* across math benchmarks, surpassing the model’s performance during Math-500 and GPQA Diamond evaluations. As seen above, Phi-4-mini-reasoning with 3.8B parameters outperforms models of over twice its size. \u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFor more information about the model, read the \u003ca href=\"https://aka.ms/phi-reasoning/techreport%22%20/t%20%22_blank\" target=\"_blank\" rel=\"noreferrer noopener\"\u003etechnical report\u003c/a\u003e that provides additional quantitative insights. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"phi-4-reasoning-and-phi-4-reasoning-plus\"\u003ePhi-4-reasoning and Phi-4-reasoning-plus \u003c/h2\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003ePhi-4-reasoning \u003c/strong\u003eis a 14-billion parameter open-weight reasoning model that rivals much larger models on complex reasoning tasks. Trained via supervised fine-tuning of Phi-4 on carefully curated reasoning demonstrations from OpenAI o3-mini, Phi-4-reasoning generates detailed reasoning chains that effectively leverage additional inference-time compute. The model demonstrates that meticulous data curation and high-quality synthetic datasets allow smaller models to compete with larger counterparts. This model is available now on Azure AI Foundry and HuggingFace.\u003c/p\u003e\n\n\n\n\u003cp\u003ePhi-4-reasoning-plus builds upon Phi-4-reasoning capabilities, further trained with reinforcement learning to utilize more inference-time compute, using 1.5x more tokens than Phi-4-reasoning, to deliver higher accuracy. This model is coming to Azure AI Foundry soon, but available today on HuggingFace. \u003c/p\u003e\n\n\n\n\u003cp\u003eDespite their significantly smaller size, both models achieve better performance than OpenAI o1-mini and DeepSeek-R1-Distill-Llama-70B at most benchmarks, including mathematical reasoning and Ph.D. level science questions. They achieve performance better than the full DeepSeek-R1 model (with 671-billion parameters) on the AIME 2025 test, the 2025 qualifier for the USA Math Olympiad.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/04/image-9-1024x416.webp\" alt=\"A graph of different colored bars\"/\u003e\u003cfigcaption\u003eFigure 2. Phi-4-reasoning performance across representative reasoning benchmarks spanning mathematical and scientific reasoning. We illustrate the performance gains from reasoning-focused post-training of Phi-4 via Phi-4-reasoning (SFT) and Phi-4-reasoning-plus (SFT+RL), alongside a representative set of baselines from two model families: open-weight models from DeepSeek including DeepSeek R1 (671B Mixture-of-Experts) and its distilled dense variant DeepSeek-R1 Distill Llama 70B, and OpenAI’s proprietary frontier models o1-mini and o3-mini. Phi-4-reasoning and Phi-4-reasoning-plus consistently outperform the base model Phi-4 by significant margins, exceed DeepSeek-R1 Distill Llama 70B (5x larger) and demonstrate competitive performance against significantly larger models such as Deepseek-R1.\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2-1024x359.webp\" alt=\"A graph of numbers and a number of people\" srcset=\"https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2-1024x359.webp 1024w, https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2-300x105.webp 300w, https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2-768x269.webp 768w, https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2-1536x539.webp 1536w, https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2.webp 1600w\" data-orig-src=\"https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/05/image-2-1024x359.webp\"/\u003e\u003cfigcaption\u003eFigure 3. Accuracy of models across general-purpose benchmarks for: long input context QA (FlenQA), instruction following (IFEval), Coding (HumanEvalPlus), knowledge \u0026amp; language understanding (MMLUPro), safety detection (ToxiGen), and other general skills (ArenaHard and PhiBench). \u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003ePhi-4-reasoning models introduce a major improvement over Phi-4, surpass larger models like DeepSeek-R1-Distill-70B and approach Deep-Seek-R1 across various reasoning and general capabilities, including math, coding, algorithmic problem solving, and planning. The \u003ca href=\"https://aka.ms/phi-reasoning/techreport\" target=\"_blank\" rel=\"noreferrer noopener\"\u003etechnical report\u003c/a\u003e provides extensive quantitative evidence of these improvements through diverse reasoning tasks.\u003c/p\u003e\n\n\n\n\n\n\n\n\u003cp\u003ePhi’s evolution over the last year has continually pushed this envelope of quality vs. size, expanding the family with new to address diverse needs. Across the scale of Windows 11 devices, these models are available to run locally on CPUs and GPUs.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs Windows works towards creating a new type of PC, Phi models have become an integral part of Copilot+ PCs with the NPU-optimized \u003ca href=\"https://blogs.windows.com/windowsexperience/2024/12/06/phi-silica-small-but-mighty-on-device-slm/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ePhi Silica variant\u003c/a\u003e. This highly efficient and OS-managed version of Phi is designed to be preloaded in memory, and available with blazing fast time to first token responses, and power efficient token throughput so it can be concurrently invoked with other applications running on your PC. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt is used in core experiences like \u003ca href=\"https://support.microsoft.com/en-us/windows/click-to-do-do-more-with-what-s-on-your-screen-6848b7d5-7fb0-4c43-b08a-443d6d3f5955\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eClick to Do\u003c/a\u003e providing useful text intelligence tools for any content on your screen and is available as \u003ca href=\"https://learn.microsoft.com/en-us/windows/ai/apis/phi-silica?tabs=csharp0%2Ccsharp1%2Ccsharp2%2Ccsharp3\" target=\"_blank\" rel=\"noreferrer noopener\"\u003edeveloper APIs\u003c/a\u003e to be readily integrated into applications—already being used in several productivity applications like Outlook offering its Copilot summary features offline. These small but mighty models have already been optimized and integrated to be used across several applications across the breadth of our PC ecosystem. The Phi-4-reasoning and Phi-4-mini-reasoning models leverage the low-bit optimizations for Phi Silica and will be available to run soon on Copilot+ PC NPUs. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"safety-and-microsoft-s-approach-to-responsible-ai\"\u003eSafety and Microsoft’s approach to responsible AI \u003c/h2\u003e\n\n\n\n\u003cp\u003eAt Microsoft, \u003ca href=\"https://www.microsoft.com/en-us/ai/responsible-ai?msockid=2e923f4e6e1064c017fe2d466fa365a3\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eresponsible AI\u003c/a\u003e is a fundamental principle guiding the development and deployment of AI systems, including our Phi models. Phi models are developed in accordance with Microsoft AI principles: accountability, transparency, fairness, reliability and safety, privacy and security, and inclusiveness. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe Phi family of models has adopted a robust safety post-training approach, leveraging a combination of Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Reinforcement Learning from Human Feedback (RLHF) techniques. These methods utilize various datasets, including publicly available datasets focused on helpfulness and harmlessness, as well as various safety-related questions and answers. While the Phi family of models is designed to perform a wide range of tasks effectively, it is important to acknowledge that all AI models may exhibit limitations. To better understand these limitations and the measures in place to address them, please refer to the model cards below, which provide detailed information on responsible AI practices and guidelines. \u003c/p\u003e\n\n\n\n\n\n\n\n\u003ch2 id=\"learn-more-here\"\u003eLearn more here: \u003c/h2\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aka.ms/tryphi\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eTry out the new models on Azure AI Foundry\u003c/a\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://aka.ms/phicookbook\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRead the Phi Cookbook\u003c/a\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://aka.ms/PhiReasoningEdge\"\u003eRead about Phi reasoning models on edge devices\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\t\t\t\u003c/div\u003e\n\n\t\n\u003c/article\u003e\n\t\t\t\n\n\n\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-05-01T00:00:00Z",
  "modifiedTime": null
}
