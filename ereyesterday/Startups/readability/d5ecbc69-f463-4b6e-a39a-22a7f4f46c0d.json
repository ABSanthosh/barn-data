{
  "id": "d5ecbc69-f463-4b6e-a39a-22a7f4f46c0d",
  "title": "Open-source DeepSeek-R1 uses pure reinforcement learning to match OpenAI o1 — at 95% less cost",
  "link": "https://venturebeat.com/ai/open-source-deepseek-r1-uses-pure-reinforcement-learning-to-match-openai-o1-at-95-less-cost/",
  "description": "The company developed DeepSeek-R1 by using pure reinforcement learning on top of DeepSeek-V3-Base, and matched or beat o1 on some benchmarks.",
  "author": "Shubham Sharma",
  "published": "Mon, 20 Jan 2025 17:55:46 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI, ML and Deep Learning",
    "category-/Science/Computer Science",
    "Conversational AI",
    "Deepseek",
    "DeepSeek pricing",
    "DeepSeek Reasoner",
    "DeepSeek-R1",
    "DeepSeek-R1-Zero",
    "distilled models",
    "Generative AI",
    "language models",
    "LLaMA",
    "LLMs",
    "Mixture-of-Experts model",
    "NLP",
    "OpenAI",
    "openai o1",
    "OpenAI pricing",
    "OpenAI-o1-mini",
    "reasoner model",
    "reasoning model",
    "reasoning models",
    "reinforcement learning",
    "supervised fine tuning"
  ],
  "byline": "Shubham Sharma",
  "length": 6222,
  "excerpt": "The company developed DeepSeek-R1 by using pure reinforcement learning on top of DeepSeek-V3-Base, and matched or beat o1 on some benchmarks.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Chinese AI startup DeepSeek, known for challenging leading AI vendors with open-source technologies, just dropped another bombshell: a new open reasoning LLM called DeepSeek-R1. Based on the recently introduced DeepSeek V3 mixture-of-experts model, DeepSeek-R1 matches the performance of o1, OpenAI’s frontier reasoning LLM, across math, coding and reasoning tasks. The best part? It does this at a much more tempting cost, proving to be 90-95% more affordable than the latter. The release marks a major leap forward in the open-source arena. It showcases that open models are further closing the gap with closed commercial models in the race to artificial general intelligence (AGI). To show the prowess of its work, DeepSeek also used R1 to distill six Llama and Qwen models, taking their performance to new levels. In one case, the distilled version of Qwen-1.5B outperformed much bigger models, GPT-4o and Claude 3.5 Sonnet, in select math benchmarks. These distilled models, along with the main R1, have been open-sourced and are available on Hugging Face under an MIT license. What does DeepSeek-R1 bring to the table? The focus is sharpening on artificial general intelligence (AGI), a level of AI that can perform intellectual tasks like humans. A lot of teams are doubling down on enhancing models’ reasoning capabilities. OpenAI made the first notable move in the domain with its o1 model, which uses a chain-of-thought reasoning process to tackle a problem. Through RL (reinforcement learning, or reward-driven optimization), o1 learns to hone its chain of thought and refine the strategies it uses — ultimately learning to recognize and correct its mistakes, or try new approaches when the current ones aren’t working.  Now, continuing the work in this direction, DeepSeek has released DeepSeek-R1, which uses a combination of RL and supervised fine-tuning to handle complex reasoning tasks and match the performance of o1.  When tested, DeepSeek-R1 scored 79.8% on AIME 2024 mathematics tests and 97.3% on MATH-500. It also achieved a 2,029 rating on Codeforces — better than 96.3% of human programmers. In contrast, o1-1217 scored 79.2%, 96.4% and 96.6% respectively on these benchmarks.  It also demonstrated strong general knowledge, with 90.8% accuracy on MMLU, just behind o1’s 91.8%.  Performance of DeepSeek-R1 vs OpenAI o1 and o1-mini The training pipeline DeepSeek-R1’s reasoning performance marks a big win for the Chinese startup in the US-dominated AI space, especially as the entire work is open-source, including how the company trained the whole thing.  However, the work isn’t as straightforward as it sounds. According to the paper describing the research, DeepSeek-R1 was developed as an enhanced version of DeepSeek-R1-Zero — a breakthrough model trained solely from reinforcement learning.  https://twitter.com/DrJimFan/status/1881353126210687089 The company first used DeepSeek-V3-base as the base model, developing its reasoning capabilities without employing supervised data, essentially focusing only on its self-evolution through a pure RL-based trial-and-error process. Developed intrinsically from the work, this ability ensures the model can solve increasingly complex reasoning tasks by leveraging extended test-time computation to explore and refine its thought processes in greater depth. “During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors,” the researchers note in the paper. “After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with majority voting, the score further improves to 86.7%, matching the performance of OpenAI-o1-0912.” However, despite showing improved performance, including behaviors like reflection and exploration of alternatives, the initial model did show some problems, including poor readability and language mixing. To fix this, the company built on the work done for R1-Zero, using a multi-stage approach combining both supervised learning and reinforcement learning, and thus came up with the enhanced R1 model. “Specifically, we begin by collecting thousands of cold-start data to fine-tune the DeepSeek-V3-Base model,” the researchers explained. “Following this, we perform reasoning-oriented RL like DeepSeek-R1- Zero. Upon nearing convergence in the RL process, we create new SFT data through rejection sampling on the RL checkpoint, combined with supervised data from DeepSeek-V3 in domains such as writing, factual QA, and self-cognition, and then retrain the DeepSeek-V3-Base model. After fine-tuning with the new data, the checkpoint undergoes an additional RL process, taking into account prompts from all scenarios. After these steps, we obtained a checkpoint referred to as DeepSeek-R1, which achieves performance on par with OpenAI-o1-1217.” Far more affordable than o1 In addition to enhanced performance that nearly matches OpenAI’s o1 across benchmarks, the new DeepSeek-R1 is also very affordable. Specifically, where OpenAI o1 costs $15 per million input tokens and $60 per million output tokens, DeepSeek Reasoner, which is based on the R1 model, costs $0.55 per million input and $2.19 per million output tokens.  https://twitter.com/EMostaque/status/1881310721746804810 The model can be tested as “DeepThink” on the DeepSeek chat platform, which is similar to ChatGPT. Interested users can access the model weights and code repository via Hugging Face, under an MIT license, or can go with the API for direct integration. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/07/nuneybits_A_marathon_race_track_with_various_AI_robots_lined_up_b7eb2227-5c1a-4533-828a-bf2a77bd95ad-transformed.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eChinese AI startup \u003ca href=\"https://www.deepseek.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eDeepSeek\u003c/a\u003e, known for challenging leading AI vendors with open-source technologies, just dropped another bombshell: a new open reasoning LLM called DeepSeek-R1.\u003c/p\u003e\n\n\n\n\u003cp\u003eBased on the recently introduced \u003ca href=\"https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/\"\u003eDeepSeek V3\u003c/a\u003e mixture-of-experts model, DeepSeek-R1 matches the performance of o1, OpenAI’s frontier reasoning LLM, across math, coding and reasoning tasks. The best part? It does this at a much more tempting cost, proving to be 90-95% more affordable than the latter.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe release marks a major leap forward in the open-source arena. It showcases that open models are further closing the gap with closed commercial models in the race to artificial general intelligence (AGI). To show the prowess of its work, DeepSeek also used R1 to distill six Llama and Qwen models, taking their performance to new levels. In one case, the distilled version of Qwen-1.5B outperformed much bigger models, GPT-4o and Claude 3.5 Sonnet, in select math benchmarks.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese distilled models, along with the \u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\"\u003emain R1\u003c/a\u003e, have been open-sourced and are available on \u003ca href=\"https://huggingface.co/deepseek-ai\"\u003eHugging Face under an MIT license\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-does-deepseek-r1-bring-to-the-table\"\u003eWhat does DeepSeek-R1 bring to the table?\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe focus is sharpening on artificial general intelligence (AGI), a level of AI that can perform intellectual tasks like humans. A lot of teams are doubling down on enhancing models’ reasoning capabilities. OpenAI made the first notable move in the domain with its \u003ca href=\"https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/\"\u003eo1 model\u003c/a\u003e, which uses a chain-of-thought reasoning process to tackle a problem. Through RL (reinforcement learning, or reward-driven optimization), o1 learns to hone its chain of thought and refine the strategies it uses — ultimately learning to recognize and correct its mistakes, or try new approaches when the current ones aren’t working. \u003c/p\u003e\n\n\n\n\u003cp\u003eNow, continuing the work in this direction, DeepSeek has released DeepSeek-R1, which uses a combination of RL and supervised fine-tuning to handle complex reasoning tasks and match the performance of o1. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhen tested, DeepSeek-R1 scored 79.8% on AIME 2024 mathematics tests and 97.3% on MATH-500. It also achieved a 2,029 rating on Codeforces — better than 96.3% of human programmers. In contrast, o1-1217 scored 79.2%, 96.4% and 96.6% respectively on these benchmarks. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt also demonstrated strong general knowledge, with 90.8% accuracy on MMLU, just behind o1’s 91.8%. \u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdv0FyIk1uPi1rk0_CJxdQV374jVUjrYYjPz861lyNriDX_xh-kk3K3iR7_3QtALxYrKc8c_1PH5v6rvTcqQWhdWyo1RgmHhx1RJxuhayraVF0zKvPviAgv3Auc_OjN5XeiHqreFg?key=1h0mFsXizlc98pD4-awAbQzL\" alt=\"\"/\u003e\u003cfigcaption\u003ePerformance of DeepSeek-R1 vs OpenAI o1 and o1-mini\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003ch2 id=\"h-the-training-pipeline\"\u003eThe training pipeline\u003c/h2\u003e\n\n\n\n\u003cp\u003eDeepSeek-R1’s reasoning performance marks a big win for the Chinese startup in the US-dominated AI space, especially as the entire work is open-source, including how the company trained the whole thing. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, the work isn’t as straightforward as it sounds.\u003c/p\u003e\n\n\n\n\u003cp\u003eAccording to the paper describing the research, DeepSeek-R1 was developed as an enhanced version of DeepSeek-R1-Zero — a breakthrough model trained solely from reinforcement learning. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cp\u003e\nhttps://twitter.com/DrJimFan/status/1881353126210687089\n\u003c/p\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe company first used DeepSeek-V3-base as the base model, developing its reasoning capabilities without employing supervised data, essentially focusing only on its self-evolution through a pure RL-based trial-and-error process. Developed intrinsically from the work, this ability ensures the model can solve increasingly complex reasoning tasks by leveraging extended test-time computation to explore and refine its thought processes in greater depth.\u003c/p\u003e\n\n\n\n\u003cp\u003e“During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors,” the researchers note in the paper. “After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with majority voting, the score further improves to 86.7%, matching the performance of OpenAI-o1-0912.” \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, despite showing improved performance, including behaviors like reflection and exploration of alternatives, the initial model did show some problems, including poor readability and language mixing. To fix this, the company built on the work done for R1-Zero, using a multi-stage approach combining both supervised learning and reinforcement learning, and thus came up with the enhanced R1 model.\u003c/p\u003e\n\n\n\n\u003cp\u003e“Specifically, we begin by collecting thousands of cold-start data to fine-tune the DeepSeek-V3-Base model,” the researchers explained. “Following this, we perform reasoning-oriented RL like DeepSeek-R1- Zero. Upon nearing convergence in the RL process, we create new SFT data through rejection sampling on the RL checkpoint, combined with supervised data from DeepSeek-V3 in domains such as writing, factual QA, and self-cognition, and then retrain the DeepSeek-V3-Base model. After fine-tuning with the new data, the checkpoint undergoes an additional RL process, taking into account prompts from all scenarios. After these steps, we obtained a checkpoint referred to as DeepSeek-R1, which achieves performance on par with OpenAI-o1-1217.” \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-far-more-affordable-than-o1\"\u003eFar more affordable than o1\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn addition to enhanced performance that nearly matches OpenAI’s o1 across benchmarks, the new DeepSeek-R1 is also very affordable. Specifically, where OpenAI o1 costs $15 per million input tokens and $60 per million output tokens, DeepSeek Reasoner, which is based on the R1 model, \u003ca href=\"https://api-docs.deepseek.com/quick_start/pricing\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecosts\u003c/a\u003e $0.55 per million input and $2.19 per million output tokens. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cp\u003e\nhttps://twitter.com/EMostaque/status/1881310721746804810\n\u003c/p\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe model can be tested as “DeepThink” on the \u003ca href=\"https://chat.deepseek.com/\"\u003eDeepSeek chat platform\u003c/a\u003e, which is similar to ChatGPT. Interested users can access the model weights and code repository via Hugging Face, under an MIT license, or can go with the API for direct integration.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-01-20T17:55:46Z",
  "modifiedTime": "2025-01-20T17:55:53Z"
}
