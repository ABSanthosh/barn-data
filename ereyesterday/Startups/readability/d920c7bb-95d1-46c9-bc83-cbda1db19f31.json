{
  "id": "d920c7bb-95d1-46c9-bc83-cbda1db19f31",
  "title": "AI comes alive: From bartenders to surgical aides to puppies, tomorrow’s robots are on their way",
  "link": "https://venturebeat.com/ai/ai-comes-alive-from-bartenders-to-surgical-aides-to-puppies-tomorrows-robots-are-on-their-way/",
  "description": "Beyond performing tasks, machines will integrate into our social fabric, requiring us to navigate new relationships with technology.",
  "author": "Gary Grossman, Edelman",
  "published": "Sun, 19 Jan 2025 21:45:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI robots",
    "AI, ML and Deep Learning",
    "category-/Science/Engineering \u0026 Technology/Robotics",
    "CES",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "robotics",
    "robots"
  ],
  "byline": "Gary Grossman, Edelman",
  "length": 11856,
  "excerpt": "Beyond performing tasks, machines will integrate into our social fabric, requiring us to navigate new relationships with technology.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Humanoid robots are no longer the stuff of science fiction. Imagine a world where robots not only collaborate with us in factories but also greet us in stores, aid in surgeries and care for our loved ones. With Tesla planning to deploy thousands of Optimus robots by 2026, the age of humanoid robots is closer than we think.  This vision is becoming increasingly tangible as more companies showcase groundbreaking innovations. The 2025 Consumer Electronics Show (CES) showcased several examples of how robotics is advancing in both functionality and human-centric design. These included ADAM the robot bartender from Richtech Robotics, which mixes more than 50 types of drinks and interacts with customers, and Tombot Inc.’s puppy dogs that wag their tails and make sounds designed to comfort older adults with dementia. While there may be a market for these and other robots on display at the show, it is still early days for broad deployment of this type of robotic technology. Nevertheless, real technological progress is being made in the field. Increasingly, this includes “humanoid” robots that use generative AI to create more human-like abilities — enabling robots to learn, sense and act in complex environments. From Optimus by Tesla to Aria from Realbotix, the next decade will see a proliferation of humanoid robots.  A conversation with “Aria.” Source: CNET https://youtu.be/2HQ84TVcbMw Despite these promising advancements, some experts caution that achieving fully human-like capabilities is still a distant goal. Citing shortcomings in current technology, Yann LeCun — one of the “Godfathers of AI” — argued recently that AI systems do not “have the capacity to plan, reason … or understand the physical world.” He added that we cannot build smart enough robots today because “we can’t get them to be smart enough.” LeCun might be correct, although that doesn’t mean we will not soon see more humanoid robots. Elon Musk recently said that Tesla will produce several thousand Optimus units in 2025 and that he expects to ship 50,000 to 100,000 of them in 2026. That is a dramatic increase from the handful that exist today performing circumscribed functions. Of course, Musk has been known to get his timelines wrong, such as when he said in 2016 that fully autonomous driving would be achieved within two years.  Nevertheless, it seems clear that significant advances are being made with humanoid robots. Tesla is not alone in pursuing this goal, as other companies including Agility Robotics, Boston Dynamics and Figure AI are among the leaders in the humanoid robotic field.  Business Insider recently had a conversation with Agility Robotics CEO Peggy Johnson, who said it would soon be “very normal” for humanoid robots to become coworkers with humans across a variety of workplaces. Last month, Figure announced in a LinkedIn post: “We delivered F.02 humanoid robots to our commercial client, and they’re currently hard at work.” With significant backing from major investors including Microsoft and Nvidia, Figure will provide fierce competition for the humanoid robot market. Figure 02 humanoid robots at work in a BMW factory. Source: YouTube: https://youtu.be/WlUFoZstcWg Creating a world view LeCun did have a point, however, as more advances are required before robots have more complete human capabilities. It is simpler to move parts in a factory than to navigate dynamic, complex environments. The current generation of robots face three key challenges: processing visual information quickly enough to react in real-time; understanding the subtle cues in human behavior; and adapting to unexpected changes in their environment. Most humanoid robots today are dependent on cloud computing and the resulting network latency can make simple tasks like picking up an object difficult.  One company working to overcome current robotics limitations is startup World Labs, founded by “AI Godmother” Fei Fei Li. Speaking with Wired, Li said: “The physical world for computers is seen through cameras, and the computer brain behind the cameras. Turning that vision into reasoning, generation and eventual interaction involves understanding the physical structure, the physical dynamics of the physical world. And that technology is called spatial intelligence.”  Gen AI powers spatial intelligence by helping robots map their surroundings in real-time, much like humans do, predicting how objects might move or change. Such advancements are crucial for creating autonomous humanoid robots capable of navigating complex, real-world scenarios with the adaptability and decision-making skills needed for success. While spatial intelligence relies on real-time data to build mental maps of the environment, another approach is to help the humanoid robot infer the real world from a single still image. As explained in a pre-published paper, Generative World Explorer (GenEx) uses AI to create a detailed virtual world from a single image, mimicking how humans make inferences about  their surroundings. While still in the research phase, this capability will help robots to make split-second decisions or navigate new environments with limited sensor data. This would allow them to quickly understand and adapt to spaces they have never experienced before. The ChatGPT moment for robotics is coming While World Labs and GenEx push the boundaries of AI reasoning, Nvidia’s Cosmos and GR00T are addressing the challenges of equipping humanoid robots with real-world adaptability and interactive capabilities. Cosmos is a family of AI “world foundation models” that help robots understand physics and spatial relationships, while GR00T (Generalist Robot 00 Technology) allows robots to learn by watching humans — like how an apprentice learns from a master. Together, these technologies help robots understand both what to do and how to do it naturally. These innovations reflect a broader push in the robotics industry to equip humanoid robots with both cognitive and physical adaptability. GR00T could enable humanoid robots to help in healthcare by observing and mimicking medical professionals, while GenEx might allow robots to navigate disaster zones by inferring environments from limited visual input. As reported by Investor’s Business Daily, Nvidia CEO Jensen Huang said: “The ChatGPT moment for robotics is coming.”  Another company working to create physical AI models is Google DeepMind. Timothy Brooks, a research scientist there, posted this month on X about company plans to make large-scale gen models that simulate the physical world.   These emerging physical world models will better predict, plan and learn from experience, all fundamental capabilities for future humanoid robots.  Google is building world simulation models. Source: X.com https://x.com/_tim_brooks/status/1876327325916447140 The robots are coming Early in 2025, humanoid robots are largely prototypes. In the near term, they will focus on specific tasks, such as manufacturing, logistics and disaster response, where automation provides immediate value. Broader applications like caregiving or retail interactions will come later, as technology matures. However, progress with AI and mechanical engineering is accelerating such humanoid robot development. Consulting firm Accenture recently took note of the developing full stack of robotics hardware, software and AI models purpose-built for creating machine autonomy in the human world. In their “2025 Technology Vision” report, the company states: “Over the next decade, we will start to see robots casually and commonly interacting with people, reasoning their way through unplanned tasks, and independently taking actions in any kind of environment.”  A timeline of past and estimated future robot adoption. Source: Accenture Technology Vision 2025 – Technology Vision 2025 Wall Street firm Morgan Stanley has estimated that the number of U.S. humanoid robots could reach eight million by 2040 and 63 million units by 2050. The company said that, in addition to technological advances, long-term demographic shifts creating labor shortages may help drive the development and their adoption. Building trustworthy robots Beyond the purely technical obstacles, potential societal objections must be overcome. Without addressing these concerns, public skepticism could hinder the adoption of humanoid robots, even in sectors where they offer clear benefits. To be successful, deployed humanoid robots would need to be seen as trustworthy, and people will need to believe that they help society. As noted by MIT Technology Review, “few people would feel warm and comfortable with such a robot if it walked into their living room right now.” To address challenges with trust, researchers are exploring how to make robots appear more relatable. For instance, engineers in Japan have created a face mask from human skin cells and attached it to robots. According to a study published last summer and reported by The New York Times, the study’s lead researcher said: “Human-like faces and expressions improve communication and empathy in human-robot interactions, making robots more effective in health care, service and companionship roles.” In other words, human-like appearance will improve trust.  In addition to appearing trustworthy, human-like robots will need to consistently behave ethically and responsibly to ensure human acceptance. In public spaces, for example, humanoid robots with cameras might inadvertently collect sensitive data, such as conversations or facial details, raising concerns about surveillance. Policies ensuring transparent data practices will be critical to mitigate these risks. The next decade In the near term, humanoid robots will focus on specific tasks, such as manufacturing, logistics and disaster response, where automation provides immediate value. These specialized roles highlight their current strengths in structured environments while broader applications, like healthcare, caregiving and retail operations will emerge as technology matures. As humanoid robots become more visible in daily life, their presence will profoundly impact and potentially reshape human interactions and societal norms. Beyond performing tasks, these machines will integrate into the social fabric, requiring humans to navigate new relationships with technology. Their adoption could ease labor shortages in aging societies and improve efficiency in service sectors, but may also provoke debates about job displacement, privacy and human identity in an increasingly automated world. Preparing for these shifts will demand not just technological progress, but thoughtful societal adaptation. By addressing challenges and leveraging the efficiency and adaptability of humanoid robots, we can ensure these technologies serve as tools for progress. Shaping this future isn’t just the responsibility of policymakers and tech leaders — it is a conversation for everyone. Public participation will be essential to ensuring humanoid robots enhance society and address real human needs. Gary Grossman is EVP of technology practice at Edelman and global lead of the Edelman AI Center of Excellence.  DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2025/01/Cover.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eHumanoid robots are no longer the stuff of science fiction. Imagine a world where robots not only collaborate with us in factories but also greet us in stores, aid in surgeries and care for our loved ones. With Tesla planning to deploy thousands of \u003ca href=\"https://finance.yahoo.com/news/teslas-optimus-robots-enter-mass-101736202.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOptimus robots by 2026\u003c/a\u003e, the age of humanoid robots is closer than we think. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis vision is becoming increasingly tangible as more companies showcase groundbreaking innovations. The 2025 Consumer Electronics Show (CES) showcased several examples of how robotics is advancing in both functionality and human-centric design. These included \u003ca href=\"https://www.richtechrobotics.com/adam\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eADAM the robot bartender\u003c/a\u003e from Richtech Robotics, which mixes more than 50 types of drinks and interacts with customers, and \u003ca href=\"https://tombot.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eTombot Inc.’s puppy dogs\u003c/a\u003e that wag their tails and make sounds designed to comfort older adults with dementia. While there may be a market for these and other robots on display at the show, it is still early days for broad deployment of this type of robotic technology.\u003c/p\u003e\n\n\n\n\u003cp\u003eNevertheless, real technological progress is being made in the field. Increasingly, this includes “humanoid” robots that use \u003ca href=\"https://venturebeat.com/ai/anthropomorphizing-ai-dire-consequences-of-mistaking-human-like-for-human-have-already-emerged/\"\u003egenerative AI\u003c/a\u003e to create more human-like abilities — enabling robots to \u003ca href=\"https://venturebeat.com/ai/ai-is-set-to-transform-education-what-enterprise-leaders-can-learn-from-this-development/\"\u003elearn\u003c/a\u003e, sense and act in complex environments. From Optimus by Tesla to Aria from \u003ca href=\"https://www.realbotix.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRealbotix\u003c/a\u003e, the next decade will see a proliferation of humanoid robots. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"480\" height=\"360\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/image1.jpg\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/image1.jpg 480w, https://venturebeat.com/wp-content/uploads/2025/01/image1.jpg?resize=300,225 300w, https://venturebeat.com/wp-content/uploads/2025/01/image1.jpg?resize=400,300 400w\" sizes=\"(max-width: 480px) 100vw, 480px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eA conversation with “Aria.” Source: CNET \u003c/em\u003e\u003ca href=\"https://youtu.be/2HQ84TVcbMw\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003ehttps://youtu.be/2HQ84TVcbMw\u003c/em\u003e\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eDespite these promising advancements, some experts caution that achieving fully human-like capabilities is still a distant goal. Citing shortcomings in current technology, Yann LeCun — one of the “Godfathers of AI” — \u003ca href=\"https://www.pymnts.com/artificial-intelligence-2/2025/meta-large-language-models-will-not-get-to-human-level-intelligence/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eargued recently\u003c/a\u003e that AI systems do not “have the capacity to plan, reason … or understand the physical world.” He added that we cannot build smart enough robots today because “we can’t get them to be smart enough.”\u003c/p\u003e\n\n\n\n\u003cp\u003eLeCun might be correct, although that doesn’t mean we will not soon see more humanoid robots. Elon Musk recently said that Tesla will produce \u003ca href=\"https://www.barrons.com/articles/teslas-robot-elon-musk-3a99c98d\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eseveral thousand Optimus units\u003c/a\u003e in 2025 and that he expects to ship \u003ca href=\"https://x.com/MarioNawfal/status/1877217132217258039?mx=2\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e50,000 to 100,000\u003c/a\u003e of them in 2026. That is a dramatic increase from the handful that exist today performing circumscribed functions. Of course, Musk has been known to get his timelines wrong, such as when \u003ca href=\"https://www.youtube.com/watch?v=wsixsRI-Sz4\u0026amp;t=4675s\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ehe said in 2016\u003c/a\u003e that fully autonomous driving would be achieved within two years. \u003c/p\u003e\n\n\n\n\u003cp\u003eNevertheless, it seems clear that significant advances are being made with humanoid robots. Tesla is not alone in pursuing this goal, as other companies including Agility Robotics, Boston Dynamics and Figure AI are among the leaders in the humanoid robotic field. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eBusiness Insider\u003c/em\u003e recently \u003ca href=\"https://www.businessinsider.com/agility-robotics-humanoid-robots-are-filling-labor-gaps-warehouses-factories-2024-11\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ehad a conversation\u003c/a\u003e with Agility Robotics CEO Peggy Johnson, who said it would soon be “very normal” for humanoid robots to become coworkers with humans across a variety of workplaces. Last month, Figure announced in a \u003ca href=\"https://www.linkedin.com/posts/brettadcock_exciting-news-today-figure-officially-activity-7275629079905624066-RCL3/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLinkedIn post\u003c/a\u003e: “We delivered F.02 humanoid robots to our commercial client, and they’re currently hard at work.” With significant backing from major investors including Microsoft and Nvidia, Figure will provide fierce competition for the humanoid robot market.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"480\" height=\"360\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/image2.jpg\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/image2.jpg 480w, https://venturebeat.com/wp-content/uploads/2025/01/image2.jpg?resize=300,225 300w, https://venturebeat.com/wp-content/uploads/2025/01/image2.jpg?resize=400,300 400w\" sizes=\"(max-width: 480px) 100vw, 480px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eFigure 02 humanoid robots at work in a BMW factory. Source: YouTube: \u003c/em\u003e\u003ca href=\"https://youtu.be/WlUFoZstcWg\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003ehttps://youtu.be/WlUFoZstcWg\u003c/em\u003e\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-creating-a-world-view\"\u003eCreating a world view\u003c/h2\u003e\n\n\n\n\u003cp\u003eLeCun did have a point, however, as more advances are required before robots have more complete human capabilities. It is simpler to move parts in a factory than to navigate dynamic, complex environments.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe current generation of robots face three key challenges: processing visual information quickly enough to react in real-time; understanding the subtle cues in human behavior; and adapting to unexpected changes in their environment. Most humanoid robots today are dependent on cloud computing and the resulting network latency can make simple tasks like picking up an object difficult. \u003c/p\u003e\n\n\n\n\u003cp\u003eOne company working to overcome current robotics limitations is startup World Labs, founded by “AI Godmother” Fei Fei Li. \u003ca href=\"https://www.wired.com/story/plaintext-the-godmother-of-ai-wants-everyone-to-be-a-world-builder/?utm_source=chatgpt.com\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSpeaking with \u003cem\u003eWired\u003c/em\u003e\u003c/a\u003e, Li said: “The physical world for computers is seen through cameras, and the computer brain behind the cameras. Turning that vision into reasoning, generation and eventual interaction involves understanding the physical structure, the physical dynamics of the physical world. And that technology is called spatial intelligence.” \u003c/p\u003e\n\n\n\n\u003cp\u003eGen AI powers spatial intelligence by helping robots map their surroundings in real-time, much like humans do, predicting how objects might move or change. Such advancements are crucial for creating autonomous humanoid robots capable of navigating complex, real-world scenarios with the adaptability and decision-making skills needed for success.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile spatial intelligence relies on real-time data to build mental maps of the environment, another approach is to help the humanoid robot infer the real world from a single still image. As explained in a \u003ca href=\"https://arxiv.org/abs/2411.11844\" target=\"_blank\" rel=\"noreferrer noopener\"\u003epre-published paper\u003c/a\u003e, Generative World Explorer (GenEx) uses AI to create a detailed virtual world from a single image, mimicking how humans make inferences about  their surroundings. While still in the research phase, this capability will help robots to make split-second decisions or navigate new environments with limited sensor data. This would allow them to quickly understand and adapt to spaces they have never experienced before.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-chatgpt-moment-for-robotics-is-coming\"\u003eThe ChatGPT moment for robotics is coming\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile World Labs and GenEx push the boundaries of AI reasoning, Nvidia’s Cosmos and GR00T are addressing the challenges of equipping humanoid robots with real-world adaptability and interactive capabilities. \u003ca href=\"https://venturebeat.com/ai/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai/\"\u003eCosmos\u003c/a\u003e is a family of AI “world foundation models” that help robots understand physics and spatial relationships, while GR00T (Generalist Robot 00 Technology) allows robots to learn by watching humans — like how an apprentice learns from a master. Together, these technologies help robots understand both what to do and how to do it naturally.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese innovations reflect a broader push in the robotics industry to equip humanoid robots with both cognitive and physical adaptability. GR00T could enable humanoid robots to help in healthcare by observing and mimicking medical professionals, while GenEx might allow robots to navigate disaster zones by inferring environments from limited visual input. As reported by \u003ca href=\"https://www.investors.com/news/technology/nvidia-stock-ces-2025-news-physical-ai/?utm_source=chatgpt.com\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003eInvestor’s Business Daily\u003c/em\u003e\u003c/a\u003e, Nvidia CEO Jensen Huang said: “The ChatGPT moment for robotics is coming.” \u003c/p\u003e\n\n\n\n\u003cp\u003eAnother company working to create physical AI models is Google DeepMind. Timothy Brooks, a research scientist there, \u003ca href=\"https://x.com/_tim_brooks/status/1876327325916447140\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eposted\u003c/a\u003e this month on X about company plans to make large-scale gen models that simulate the physical world.  \u003c/p\u003e\n\n\n\n\u003cp\u003eThese emerging physical world models will better predict, plan and learn from experience, all fundamental capabilities for future humanoid robots. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"865\" height=\"453\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/image4.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/image4.png 865w, https://venturebeat.com/wp-content/uploads/2025/01/image4.png?resize=300,157 300w, https://venturebeat.com/wp-content/uploads/2025/01/image4.png?resize=768,402 768w, https://venturebeat.com/wp-content/uploads/2025/01/image4.png?resize=800,419 800w, https://venturebeat.com/wp-content/uploads/2025/01/image4.png?resize=400,209 400w, https://venturebeat.com/wp-content/uploads/2025/01/image4.png?resize=750,393 750w, https://venturebeat.com/wp-content/uploads/2025/01/image4.png?resize=578,303 578w\" sizes=\"(max-width: 865px) 100vw, 865px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eGoogle is building world simulation models. Source: X.com \u003c/em\u003e\u003ca href=\"https://x.com/_tim_brooks/status/1876327325916447140\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003ehttps://x.com/_tim_brooks/status/1876327325916447140\u003c/em\u003e\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-the-robots-are-coming\"\u003eThe robots are coming\u003c/h2\u003e\n\n\n\n\u003cp\u003eEarly in 2025, humanoid robots are largely prototypes. In the near term, they will focus on specific tasks, such as manufacturing, logistics and disaster response, where automation provides immediate value. Broader applications like caregiving or retail interactions will come later, as technology matures. However, progress with AI and mechanical engineering is accelerating such humanoid robot development.\u003c/p\u003e\n\n\n\n\u003cp\u003eConsulting firm Accenture recently took note of the developing full stack of robotics hardware, software and AI models purpose-built for creating machine autonomy in the human world. In their “\u003ca href=\"https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-Tech-Vision-2025.pdf#zoom=40\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e2025 Technology Vision\u003c/a\u003e” report, the company states: “Over the next decade, we will start to see robots casually and commonly interacting with people, reasoning their way through unplanned tasks, and independently taking actions in any kind of environment.”\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"1162\" height=\"624\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg 1162w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=300,161 300w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=768,412 768w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=800,430 800w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=400,215 400w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=750,403 750w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=578,310 578w, https://venturebeat.com/wp-content/uploads/2025/01/image5.jpg?resize=930,499 930w\" sizes=\"(max-width: 1162px) 100vw, 1162px\"/\u003e\u003cfigcaption\u003e\u003cem\u003e A timeline of past and estimated future robot adoption. Source: Accenture Technology Vision 2025 – \u003ca href=\"https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-Tech-Vision-2025.pdf#zoom=40\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eTechnology Vision 2025\u003c/a\u003e\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWall Street firm \u003ca href=\"https://www.morganstanley.com/ideas/humanoid-robot-market-outlook-2024\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMorgan Stanley has estimated\u003c/a\u003e that the number of U.S. humanoid robots could reach eight million by 2040 and 63 million units by 2050. The company said that, in addition to technological advances, long-term demographic shifts creating labor shortages may help drive the development and their adoption.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-building-trustworthy-robots\"\u003eBuilding trustworthy robots\u003c/h2\u003e\n\n\n\n\u003cp\u003eBeyond the purely technical obstacles, potential societal objections must be overcome. Without addressing these concerns, public skepticism could hinder the adoption of humanoid robots, even in sectors where they offer clear benefits. To be successful, deployed humanoid robots would need to be seen as trustworthy, and people will need to believe that they help society. As \u003ca href=\"https://www.technologyreview.com/2024/12/23/1108466/general-purpose-robots-humanoids-ai-remote-assistants/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003enoted\u003c/a\u003e by \u003cem\u003eMIT Technology Review\u003c/em\u003e, “few people would feel warm and comfortable with such a robot if it walked into their living room right now.”\u003c/p\u003e\n\n\n\n\u003cp\u003eTo address challenges with trust, researchers are exploring how to make robots appear more relatable. For instance, engineers in Japan have created a face mask from human skin cells and attached it to robots. According to a study published last summer and \u003ca href=\"https://www.nytimes.com/2024/06/30/science/japan-robots-human-face.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ereported\u003c/a\u003e by \u003cem\u003eThe New York Times\u003c/em\u003e, the study’s lead researcher said: “Human-like faces and expressions improve communication and empathy in human-robot interactions, making robots more effective in health care, service and companionship roles.” In other words, human-like appearance will improve trust. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn addition to appearing trustworthy, human-like robots will need to consistently behave ethically and responsibly to ensure human acceptance. In public spaces, for example, humanoid robots with cameras might inadvertently collect sensitive data, such as conversations or facial details, raising concerns about surveillance. Policies ensuring transparent data practices will be critical to mitigate these risks.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-next-decade\"\u003eThe next decade\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn the near term, humanoid robots will focus on specific tasks, such as manufacturing, logistics and disaster response, where automation provides immediate value. These specialized roles highlight their current strengths in structured environments while broader applications, like healthcare, caregiving and retail operations will emerge as technology matures.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs humanoid robots become more visible in daily life, their presence will profoundly impact and potentially reshape human interactions and societal norms. Beyond performing tasks, these machines will integrate into the social fabric, requiring humans to navigate new relationships with technology. Their adoption could ease labor shortages in aging societies and improve efficiency in service sectors, but may also provoke debates about job displacement, privacy and human identity in an increasingly automated world. Preparing for these shifts will demand not just technological progress, but thoughtful societal adaptation.\u003c/p\u003e\n\n\n\n\u003cp\u003eBy addressing challenges and leveraging the efficiency and adaptability of humanoid robots, we can ensure these technologies serve as tools for progress. Shaping this future isn’t just the responsibility of policymakers and tech leaders — it is a conversation for everyone. Public participation will be essential to ensuring humanoid robots enhance society and address real human needs.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eGary Grossman is EVP of technology practice at \u003ca href=\"https://www.edelman.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eEdelman\u003c/a\u003e and global lead of the Edelman AI Center of Excellence. \u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2025-01-19T21:45:00Z",
  "modifiedTime": "2025-01-19T21:40:37Z"
}
