{
  "id": "c44a803d-b29e-49cf-b69b-eef8b16b599b",
  "title": "5 key questions your developers should be asking about MCP",
  "link": "https://venturebeat.com/ai/5-key-questions-your-developers-should-be-asking-about-mcp/",
  "description": "It’s MCP projects in production, not specification elegance or market buzz, that will determine if MCP (or something else) stays on top.",
  "author": "Meir Wahnon, Descope",
  "published": "Sat, 19 Jul 2025 21:05:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "Programming \u0026 Development",
    "AI, ML and Deep Learning",
    "Generative AI",
    "large language models",
    "MCP",
    "MCP protocol",
    "Model Context Protocol (MCP)"
  ],
  "byline": "Meir Wahnon, Descope",
  "length": 8753,
  "excerpt": "It’s MCP projects in production, not specification elegance or market buzz, that will determine if MCP (or something else) stays on top.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now The Model Context Protocol (MCP) has become one of the most talked-about developments in AI integration since its introduction by Anthropic in late 2024. If you’re tuned into the AI space at all, you’ve likely been inundated with developer “hot takes” on the topic. Some think it’s the best thing ever; others are quick to point out its shortcomings. In reality, there’s some truth to both. One pattern I’ve noticed with MCP adoption is that skepticism typically gives way to recognition: This protocol solves genuine architectural problems that other approaches don’t. I’ve gathered a list of questions below that reflect the conversations I’ve had with fellow builders who are considering bringing MCP to production environments.  1. Why should I use MCP over other alternatives? Of course, most developers considering MCP are already familiar with implementations like OpenAI’s custom GPTs, vanilla function calling, Responses API with function calling, and hardcoded connections to services like Google Drive. The question isn’t really whether MCP fully replaces these approaches — under the hood, you could absolutely use the Responses API with function calling that still connects to MCP. What matters here is the resulting stack. Despite all the hype about MCP, here’s the straight truth: It’s not a massive technical leap. MCP essentially “wraps” existing APIs in a way that’s understandable to large language models (LLMs). Sure, a lot of services already have an OpenAPI spec that models can use. For small or personal projects, the objection that MCP “isn’t that big a deal” is pretty fair. The AI Impact Series Returns to San Francisco - August 5 The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation. Secure your spot now - space is limited: https://bit.ly/3GuuPLF The practical benefit becomes obvious when you’re building something like an analysis tool that needs to connect to data sources across multiple ecosystems. Without MCP, you’re required to write custom integrations for each data source and each LLM you want to support. With MCP, you implement the data source connections once, and any compatible AI client can use them. 2. Local vs. remote MCP deployment: What are the actual trade-offs in production? This is where you really start to see the gap between reference servers and reality. Local MCP deployment using the stdio programming language is dead simple to get running: Spawn subprocesses for each MCP server and let them talk through stdin/stdout. Great for a technical audience, difficult for everyday users. Remote deployment obviously addresses the scaling but opens up a can of worms around transport complexity. The original HTTP+SSE approach was replaced by a March 2025 streamable HTTP update, which tries to reduce complexity by putting everything through a single /messages endpoint. Even so, this isn’t really needed for most companies that are likely to build MCP servers. But here’s the thing: A few months later, support is spotty at best. Some clients still expect the old HTTP+SSE setup, while others work with the new approach — so, if you’re deploying today, you’re probably going to support both. Protocol detection and dual transport support are a must. Authorization is another variable you’ll need to consider with remote deployments. The OAuth 2.1 integration requires mapping tokens between external identity providers and MCP sessions. While this adds complexity, it’s manageable with proper planning. 3. How can I be sure my MCP server is secure? This is probably the biggest gap between the MCP hype and what you actually need to tackle for production. Most showcases or examples you’ll see use local connections with no authentication at all, or they handwave the security by saying “it uses OAuth.”  The MCP authorization spec does leverage OAuth 2.1, which is a proven open standard. But there’s always going to be some variability in implementation. For production deployments, focus on the fundamentals:  Proper scope-based access control that matches your actual tool boundaries  Direct (local) token validation Audit logs and monitoring for tool use However, the biggest security consideration with MCP is around tool execution itself. Many tools need (or think they need) broad permissions to be useful, which means sweeping scope design (like a blanket “read” or “write”) is inevitable. Even without a heavy-handed approach, your MCP server may access sensitive data or perform privileged operations — so, when in doubt, stick to the best practices recommended in the latest MCP auth draft spec. 4. Is MCP worth investing resources and time into, and will it be around for the long term? This gets to the heart of any adoption decision: Why should I bother with a flavor-of-the-quarter protocol when everything AI is moving so fast? What guarantee do you have that MCP will be a solid choice (or even around) in a year, or even six months?  Well, look at MCP’s adoption by major players: Google supports it with its Agent2Agent protocol, Microsoft has integrated MCP with Copilot Studio and is even adding built-in MCP features for Windows 11, and Cloudflare is more than happy to help you fire up your first MCP server on their platform. Similarly, the ecosystem growth is encouraging, with hundreds of community-built MCP servers and official integrations from well-known platforms.  In short, the learning curve isn’t terrible, and the implementation burden is manageable for most teams or solo devs. It does what it says on the tin. So, why would I be cautious about buying into the hype? MCP is fundamentally designed for current-gen AI systems, meaning it assumes you have a human supervising a single-agent interaction. Multi-agent and autonomous tasking are two areas MCP doesn’t really address; in fairness, it doesn’t really need to. But if you’re looking for an evergreen yet still somehow bleeding-edge approach, MCP isn’t it. It’s standardizing something that desperately needs consistency, not pioneering in uncharted territory. 5. Are we about to witness the “AI protocol wars?” Signs are pointing toward some tension down the line for AI protocols. While MCP has carved out a tidy audience by being early, there’s plenty of evidence it won’t be alone for much longer. Take Google’s Agent2Agent (A2A) protocol launch with 50-plus industry partners. It’s complementary to MCP, but the timing — just weeks after OpenAI publicly adopted MCP — doesn’t feel coincidental. Was Google cooking up an MCP competitor when they saw the biggest name in LLMs embrace it? Maybe a pivot was the right move. But it’s hardly speculation to think that, with features like multi-LLM sampling soon to be released for MCP, A2A and MCP may become competitors. Then there’s the sentiment from today’s skeptics about MCP being a “wrapper” rather than a genuine leap forward for API-to-LLM communication. This is another variable that will only become more apparent as consumer-facing applications move from single-agent/single-user interactions and into the realm of multi-tool, multi-user, multi-agent tasking. What MCP and A2A don’t address will become a battleground for another breed of protocol altogether. For teams bringing AI-powered projects to production today, the smart play is probably hedging protocols. Implement what works now while designing for flexibility. If AI makes a generational leap and leaves MCP behind, your work won’t suffer for it. The investment in standardized tool integration absolutely will pay off immediately, but keep your architecture adaptable for whatever comes next. Ultimately, the dev community will decide whether MCP stays relevant. It’s MCP projects in production, not specification elegance or market buzz, that will determine if MCP (or something else) stays on top for the next AI hype cycle. And frankly, that’s probably how it should be. Meir Wahnon is a co-founder at Descope. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/07/cfr0z3n_vibrant_expressionist_blocky_messy_simple_shapes_minima_63d1b56e-29a6-4cf4-a7a8-58e9fbfbe030.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\u003c/em\u003e \u003cem\u003e\u003ca href=\"https://venturebeat.com/newsletters/\"\u003eSubscribe Now\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThe \u003ca href=\"https://www.anthropic.com/news/model-context-protocol\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eModel Context Protocol\u003c/a\u003e (MCP) has become one of the most talked-about developments in AI integration since its introduction by Anthropic in late 2024. If you’re tuned into the AI space at all, you’ve likely been inundated with developer “hot takes” on the topic. Some think it’s the best thing ever; others are quick to point out its shortcomings. In reality, there’s some truth to both.\u003c/p\u003e\n\n\n\n\u003cp\u003eOne pattern I’ve noticed with \u003ca href=\"https://venturebeat.com/ai/the-interoperability-breakthrough-how-mcp-is-becoming-enterprise-ais-universal-language/\"\u003eMCP adoption\u003c/a\u003e is that skepticism typically gives way to recognition: This protocol solves genuine architectural problems that other approaches don’t. I’ve gathered a list of questions below that reflect the conversations I’ve had with fellow builders who are considering bringing MCP to production environments. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-1-why-should-i-use-mcp-over-other-alternatives\"\u003e1. Why should I use MCP over other alternatives?\u003c/h2\u003e\n\n\n\n\u003cp\u003eOf course, most developers considering MCP are already familiar with implementations like OpenAI’s \u003ca href=\"https://openai.com/index/introducing-gpts/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecustom GPTs\u003c/a\u003e, vanilla function calling, \u003ca href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=responses\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eResponses API\u003c/a\u003e with function calling, and hardcoded connections to services like Google Drive. The question isn’t really whether MCP fully \u003cem\u003ereplaces \u003c/em\u003ethese approaches — under the hood, you could absolutely use the Responses API with function calling that still connects to MCP. What matters here is the resulting stack.\u003c/p\u003e\n\n\n\n\u003cp\u003eDespite all the hype about MCP, here’s the straight truth: It’s not a massive technical leap. MCP essentially “wraps” existing APIs in a way that’s understandable to large language models (LLMs). Sure, a lot of services already have an OpenAPI spec that models can use. For small or personal projects, the objection that MCP “isn’t that big a deal” is pretty fair.\u003c/p\u003e\n\n\n\n\u003cdiv id=\"boilerplate_2803147\"\u003e\n\u003chr/\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eThe AI Impact Series Returns to San Francisco - August 5\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.\u003c/p\u003e\n\n\n\n\u003cp\u003eSecure your spot now - space is limited: \u003ca href=\"https://bit.ly/3GuuPLF\"\u003ehttps://bit.ly/3GuuPLF\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThe practical benefit becomes obvious when you’re building something like an analysis tool that needs to connect to data sources across multiple ecosystems. Without MCP, you’re required to write custom integrations for each data source and each LLM you want to support. With MCP, you implement the data source connections \u003cem\u003eonce\u003c/em\u003e, and any compatible AI client can use them.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-2-local-vs-remote-mcp-deployment-what-are-the-actual-trade-offs-in-production\"\u003e2. Local vs. remote MCP deployment: What are the actual trade-offs in production?\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis is where you really start to see the gap between reference servers and reality. Local \u003ca href=\"https://venturebeat.com/ai/mcp-and-the-innovation-paradox-why-open-standards-will-save-ai-from-itself/\"\u003eMCP deployment\u003c/a\u003e using the stdio programming language is dead simple to get running: Spawn subprocesses for each MCP server and let them talk through stdin/stdout. Great for a technical audience, difficult for everyday users.\u003c/p\u003e\n\n\n\n\u003cp\u003eRemote deployment obviously addresses the scaling but opens up a can of worms around transport complexity. The original HTTP+SSE approach was replaced by a March 2025 streamable HTTP update, which tries to reduce complexity by putting everything through a single /messages endpoint. Even so, this isn’t really needed for most companies that are likely to build MCP servers.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut here’s the thing: A few months later, support is spotty at best. Some clients still expect the old HTTP+SSE setup, while others work with the new approach — so, if you’re deploying today, you’re probably going to support both. Protocol detection and dual transport support are a must.\u003c/p\u003e\n\n\n\n\u003cp\u003eAuthorization is another variable you’ll need to consider with remote deployments. The OAuth 2.1 integration requires mapping tokens between external identity providers and MCP sessions. While this adds complexity, it’s manageable with proper planning.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-3-how-can-i-be-sure-my-mcp-server-is-secure\"\u003e3. How can I be sure my MCP server is secure?\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis is probably the biggest gap between the \u003ca href=\"https://venturebeat.com/ai/mcp-isnt-kyc-ready-why-regulated-sectors-are-wary-of-open-agent-exchanges/\"\u003eMCP hype\u003c/a\u003e and what you actually need to tackle for production. Most showcases or examples you’ll see use local connections with no authentication at all, or they handwave the security by saying “it uses OAuth.” \u003c/p\u003e\n\n\n\n\u003cp\u003eThe MCP authorization spec \u003cem\u003edoes \u003c/em\u003eleverage OAuth 2.1, which is a proven open standard. But there’s always going to be some variability in implementation. For production deployments, focus on the fundamentals: \u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eProper scope-based access control that matches your actual tool boundaries \u003c/li\u003e\n\n\n\n\u003cli\u003eDirect (local) token validation\u003c/li\u003e\n\n\n\n\u003cli\u003eAudit logs and monitoring for tool use\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eHowever, the biggest security consideration with MCP is around tool execution itself. Many tools need (or \u003cem\u003ethink\u003c/em\u003e they need) broad permissions to be useful, which means sweeping scope design (like a blanket “read” or “write”) is inevitable. Even without a heavy-handed approach, your MCP server may access sensitive data or perform privileged operations — so, when in doubt, stick to the best practices recommended in the \u003ca href=\"https://modelcontextprotocol.io/specification/draft/basic/authorization\" target=\"_blank\" rel=\"noreferrer noopener\"\u003elatest MCP auth draft spec\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-4-is-mcp-worth-investing-resources-and-time-into-and-will-it-be-around-for-the-long-term\"\u003e4. Is MCP worth investing resources and time into, and will it be around for the long term?\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis gets to the heart of any adoption decision: Why should I bother with a flavor-of-the-quarter protocol when everything AI is moving so fast? What guarantee do you have that MCP will be a solid choice (or even around) in a year, or even six months? \u003c/p\u003e\n\n\n\n\u003cp\u003eWell, look at MCP’s adoption by major players: Google supports it with its Agent2Agent protocol, Microsoft has integrated MCP with \u003ca href=\"https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/introducing-model-context-protocol-mcp-in-copilot-studio-simplified-integration-with-ai-apps-and-agents/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eCopilot Studio\u003c/a\u003e and is even adding built-in \u003ca href=\"https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMCP features\u003c/a\u003e for Windows 11, and Cloudflare is more than happy to help you fire up your first \u003ca href=\"https://developers.cloudflare.com/agents/guides/remote-mcp-server/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMCP server on their platform\u003c/a\u003e. Similarly, the ecosystem growth is encouraging, with hundreds of community-built MCP servers and official integrations from well-known platforms. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn short, the learning curve isn’t terrible, and the implementation burden is manageable for most teams or solo devs. It does what it says on the tin. So, why would I be cautious about buying into the hype?\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://venturebeat.com/ai/model-context-protocol-a-promising-ai-integration-layer-but-not-a-standard-yet/\"\u003eMCP\u003c/a\u003e is fundamentally designed for current-gen AI systems, meaning it assumes you have a human supervising a single-agent interaction. Multi-agent and autonomous tasking are two areas MCP doesn’t really address; in fairness, it doesn’t really need to. But if you’re looking for an evergreen yet still somehow bleeding-edge approach, MCP isn’t it. It’s standardizing something that desperately needs consistency, not pioneering in uncharted territory.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-5-are-we-about-to-witness-the-ai-protocol-wars\"\u003e5. Are we about to witness the “AI protocol wars?”\u003c/h2\u003e\n\n\n\n\u003cp\u003eSigns are pointing toward some tension down the line for AI protocols. While MCP has carved out a tidy audience by being early, there’s plenty of evidence it won’t be alone for much longer.\u003c/p\u003e\n\n\n\n\u003cp\u003eTake Google’s \u003ca href=\"https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAgent2Agent (A2A\u003c/a\u003e) protocol launch with 50-plus industry partners. It’s complementary to MCP, but the timing — just weeks after OpenAI publicly adopted MCP — doesn’t feel coincidental. Was Google cooking up an MCP competitor when they saw the biggest name in LLMs embrace it? Maybe a pivot was the right move. But it’s hardly speculation to think that, with features like \u003ca href=\"https://modelcontextprotocol.io/docs/concepts/sampling\" target=\"_blank\" rel=\"noreferrer noopener\"\u003emulti-LLM sampling\u003c/a\u003e soon to be released for MCP, A2A and MCP may become competitors.\u003c/p\u003e\n\n\n\n\u003cp\u003eThen there’s the sentiment from today’s skeptics about MCP being a “wrapper” rather than a genuine leap forward for API-to-LLM communication. This is another variable that will only become more apparent as consumer-facing applications move from single-agent/single-user interactions and into the realm of multi-tool, multi-user, multi-agent tasking. What MCP and A2A don’t address will become a battleground for another breed of protocol altogether.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor teams bringing AI-powered projects to production today, the smart play is probably hedging protocols. Implement what works now while designing for flexibility. If AI makes a generational leap and leaves MCP behind, your work won’t suffer for it. The investment in standardized tool integration absolutely will pay off immediately, but keep your architecture adaptable for whatever comes next.\u003c/p\u003e\n\n\n\n\u003cp\u003eUltimately, the dev community will decide whether MCP stays relevant. It’s MCP projects in production, not specification elegance or market buzz, that will determine if MCP (or something else) stays on top for the next AI hype cycle. And frankly, that’s probably how it should be.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eMeir Wahnon is a co-founder at \u003ca href=\"https://www.descope.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eDescope\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-07-19T21:05:00Z",
  "modifiedTime": "2025-07-19T21:11:39Z"
}
