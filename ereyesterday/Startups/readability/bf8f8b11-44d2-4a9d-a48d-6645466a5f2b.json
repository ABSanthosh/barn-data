{
  "id": "bf8f8b11-44d2-4a9d-a48d-6645466a5f2b",
  "title": "OSI readies controversial open-source AI definition",
  "link": "https://lwn.net/SubscriberLink/995159/a37fb9817a00ebcb/",
  "description": "Article URL: https://lwn.net/SubscriberLink/995159/a37fb9817a00ebcb/ Comments URL: https://news.ycombinator.com/item?id=41951421 Points: 18 # Comments: 10",
  "author": "rettichschnidi",
  "published": "Sat, 26 Oct 2024 00:23:04 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "By Joe BrockmeierOctober 25, 2024",
  "length": 12286,
  "excerpt": "The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider accepting the discount offer on the right. Thank you for visiting LWN.net!",
  "siteName": "",
  "favicon": "https://static.lwn.net/images/favicon.png",
  "text": "Welcome to LWN.net The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider accepting the discount offer on the right. Thank you for visiting LWN.net! Special discount offer Subscribe to LWN now at the \"professional hacker\" level for at least six months, and you will receive a special discount of 25%. The Open Source Initiative (OSI) has been working on defining Open Source AI—that is what constitutes an AI system that can be used, studied, modified, and shared for any purpose—for almost two years. Its board will be voting on the Open Source AI Definition (OSAID) on Sunday, October 27, with the 1.0 version slated to be published on October 28. It is never possible to please everyone in such an endeavor, and it would be folly to make that a goal. However, a number of prominent figures in the open-source community have voiced concerns that OSI is setting the bar too low with the OSAID—which will undo decades of community work to cajole vendors into adhering to or respecting the original Open Source Definition (OSD). Defining Open Source AI OSI executive director Stefano Maffulli announced the organization's intent to provide a definition for open-source AI in June 2023. He took exception to announcements of \"large language models, foundational models, tooling, services all claiming to be 'open' or 'Open Source'\", while adding restrictions which run afoul of the OSD. A survey of large-language model (LLM) systems in 2023 found that ostensibly open-source LLMs did not live up to the name. The problem is not quite as simple as saying \"use an OSD-compliant license\" for LLMs, because there are many more components to consider. The original OSD is understood to apply to the source code of a program in \"the preferred form in which a programmer would modify the program\". A program is not considered open source if a developer cannot study, use, modify, and share a program, and a license is not OSD‑compliant if it does not preserve those freedoms. A program can include non-free data and still be open source. For example, the game Quake III Arena (Q3A) is available under the GPLv2. That distribution, however, does not include the pak files that contain the maps, textures, and other content required to actually play the commercial game. Despite that, others can still use the Q3A code to create their own games, such as Tremulous. When discussing an \"AI system\", however, things are much more complicated. There is more than just the code that is used to run the models to do work of some kind, and the data is not something that can be wholly separate from the system in the way that it can be with a game. When looking at, say, LLMs, there is the model architecture, the code used to train models, model parameters, the techniques and methodologies used for training, the procedures for labeling training data, the supporting libraries, and (of course) the data used to train the models. OSI has been working on its definition since last year. It held a kickoff meeting on June 21, 2023 at the Mozilla headquarters in San Francisco. It invited participation afterward via a regular series of in-person and online sessions, and with a forum for online discussions. LWN covered one of the sessions, held at FOSDEM 2024, in February. The current draft of the OSAID takes its definition of an AI system from the Organisation for Economic Co-operation and Development (OECD) Recommendation of the Council on Artificial Intelligence: A machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. This includes source code for training and running the system, model parameters \"such as weights or other configuration settings\", as well as \"sufficiently detailed information about the data used to train the system so that a skilled person can build a substantially equivalent system\". Preferred form to make modifications Those elements must all be available under OSI-approved licenses, according to the proposed definition, which seems perfectly in line with what we've come to expect when something is called \"open source\". There is an exception, though, for things like the data information and model parameters which must be available under \"OSI-approved terms\". The definition of OSI-approved terms is not supplied yet. There is no requirement to make the training data available. To be compliant with the current draft of the OSAID, an AI system need only provide \"detailed information\" about the data but not the data itself. The OSI published version 0.0.9 on August 22. It acknowledged then that \"training data is one of the most hotly debated parts of the definition\". However, the OSI was choosing not to require training data: After long deliberation and co-design sessions we have concluded that defining training data as a benefit, not a requirement, is the best way to go. Training data is valuable to study AI systems: to understand the biases that have been learned, which can impact system behavior. But training data is not part of the preferred form for making modifications to an existing AI system. The insights and correlations in that data have already been learned. As it stands, some feel that the OSAID falls short of allowing the four freedoms that it is supposed to ensure. For example, julia ferraioli wrote that without including data, the only things that the OSAID guarantees are the ability to use and distribute an AI system. \"They would be able to build on top of it, through methods such as transfer learning and fine-tuning, but that's it.\" Tom Callaway has written at length on LinkedIn about why open data should be a requirement. He acknowledges that there are good reasons that distributors of an AI system may not want, or be able, to distribute training data. For example, the data itself may have a high monetary value on its own, and a vendor may be unwilling or unable to share it. Acme Corp might license a data set and have permission to create an AI system using it, but not the ability to distribute the data itself. The data might have legal issues, ranging from confidentiality (e.g., medical data sets) to a desire to avoid lawsuits from using copyrighted data. All of those are understandable reasons for not distributing data with an AI system, he said, but they don't argue for crafting a definition that allows companies to call their system open: If we let the Open Source AI definition contain a loophole that makes data optional, we devalue the meaning of \"open source\" in all other contexts. While there are lots of companies who would like to see open source mean less, I think it's critical that we not compromise here, even if it means there are less Open Source AI systems at first. Objections to lack of training data are more than an attachment to the original meaning of open source. Giacomo Tesio posted a list of issues he considered unaddressed in the RC2 version of the OSAID, including a claim that there is inherent insecurity due to the ability to plant undetectable backdoors in machine-learning models. Others weigh in The Free Software Foundation (FSF) announced that it was working on \"a statement of criteria for free machine learning applications\" to call something a free (or libre) machine-learning application. The FSF says that it is close to a definition, and is working on the exact text. However, it adds that \"we believe that we cannot say a ML application 'is free' unless all its training data and the related scripts for processing it respect all users, following the four freedoms\". However, the FSF makes a distinction between non-free and unethical in this case: It may be that some nonfree ML have valid moral reasons for not releasing training data, such as personal medical data. In that case, we would describe the application as a whole as nonfree. But using it could be ethically excusable if it helps you do a specialized job that is vital for society, such as diagnosing disease or injury. The Software Freedom Conservancy has announced an \"aspirational statement\" about LLM-backed generative AI for programming called \"Machine-Learning-Assisted Programming that Respects User Freedom\". Unlike the OSAID, this target focuses solely on computer-assisted programming, and was developed in response to GitHub Copilot. The announcement did not directly name the OSI or the OSAID effort, but said \"we have avoided any process that effectively auto-endorses the problematic practices of companies whose proprietary products are already widely deployed\". It describes an ideal LLM system built only with FOSS, with all components available, and only for the creation of FOSS. Response to criticisms I emailed Maffulli about some of the criticisms of the current OSAID draft, and asked why OSI appears to be \"lowering the bar\" when the OSI has never budged on source availability and use restrictions. He replied: I'll be blunt: you mention \"source redistribution\" in your question and that's what leads people like [Callaway] into a mental trap [...] There are some groups believing that more components are required to guarantee more transparency. Other groups instead believe that model parameters and architecture are enough to modify AI. The Open Source AI Definition, developed publicly with a wide variety of stakeholders worldwide, with deep expertise on building AI (see the list of endorsers), found that while those approaches are legitimate, neither is optimal. The OSAID grants users the rights (with licenses) and the tools (with the list of required components) to meaningfully collaborate and innovate on (and fork, if required) AI systems. We have not compromised on our principles: we learned many new things from actual AI experts along the way. Maffulli objected to the idea that the OSAID was weaker or making concessions, and said that the preferred form for modifying ML systems was what is in the OSAID: \"it's not me nor OSI board saying that, it's in the list of endorsers and in [Carnegie Mellon University's] comment\". He added that OSI had synthesized input from \"AI builders, users, and deployers, content creators, unions, ethicists, lawyers, software developers from all over the world\" to arrive at the definition. A \"simple translation\" of the OSD, he said, would not work. Stephen O'Grady, founder of the RedMonk analyst firm, also makes the case that the OSD does not easily translate to AI projects. But he does not believe that the term open source \"can or should be extended into the AI world\" as he wrote in a blog post on October 22: At its heart, the current deliberation around an open source definition for AI is an attempt to drag a term defined over two decades ago to describe a narrowly defined asset into the present to instead cover a brand new, far more complicated future set of artifacts. O'Grady makes the case that the OSI has set out on a pragmatic path to define open-source AI, which requires nuance. Open source has succeeded, in part, because the OSD removes nuance. Does a license comply with the OSD or doesn't it? It's pretty easy to determine. Less so with the OSAID. The pragmatic path, he said: Involves substantial compromise and, more problematically, requires explanation to be understood. And as the old political adage advises: \"If you're explaining, you're losing.\" It would have been better, he said, if the OSI had not tried to \"bend and reshape a decades old definition\" and instead had tried to craft something from a clean slate. That seems unlikely now, he said, after two years of trying to \"thread the needle between idealism and capitalism to arrive at an ideologically sound and yet commercially acceptable\" definition. Indeed, it seems likely that the OSI board will move forward with the current draft of the OSAID or something close to it. The impact that will have is much less certain.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\u003ccenter\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\n\u003ch3\u003eWelcome to LWN.net\u003c/h3\u003e\n\u003cp\u003e\nThe following subscription-only content has been made available to you \nby an LWN subscriber.  Thousands of subscribers depend on LWN for the \nbest news from the Linux and free software communities.  If you enjoy this \narticle, please consider accepting the discount offer on the right.  Thank you\nfor visiting LWN.net!\n\u003c/p\u003e\u003c/td\u003e\u003ctd\u003e\n\u003cdiv\u003e\n\u003ch3\u003eSpecial discount offer\u003c/h3\u003e\n           \u003cp\u003e\n           \u003ca href=\"https://lwn.net/Promo/sl-discount-3/claim\"\u003eSubscribe to LWN now\u003c/a\u003e at the\n           \u0026#34;professional hacker\u0026#34; level for at least six months,\n           and you will\n           receive a special discount of 25%.\n           \n\u003c/p\u003e\u003c/div\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/center\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://opensource.org/\"\u003eOpen Source Initiative\u003c/a\u003e\n(OSI) has been working on defining \u003ca href=\"https://opensource.org/ai\"\u003eOpen Source AI\u003c/a\u003e—that is what\nconstitutes an AI system that can be used, studied, modified, and\nshared for any purpose—for almost two\nyears. Its \u003ca href=\"https://opensource.org/about/board-of-directors\"\u003eboard\u003c/a\u003e will\nbe voting on the \u003ca href=\"https://opensource.org/ai/drafts/the-open-source-ai-definition-1-0-rc2\"\u003eOpen Source AI Definition\u003c/a\u003e (OSAID) on Sunday,\nOctober 27, with the 1.0 version slated to be published on\nOctober 28. It is never possible to please \u003cem\u003eeveryone\u003c/em\u003e in\nsuch an endeavor, and it would be folly to make that a goal. However,\na number of prominent figures in the open-source community have voiced\nconcerns that OSI is setting the bar too low with the OSAID—which\nwill undo decades of community work to cajole vendors into adhering to\nor respecting the original \u003ca href=\"https://opensource.org/osd\"\u003eOpen Source\nDefinition\u003c/a\u003e (OSD).\u003c/p\u003e\n\n\u003ch4\u003eDefining Open Source AI\u003c/h4\u003e\n\n\u003cp\u003eOSI executive director Stefano Maffulli \u003ca href=\"https://opensource.org/blog/now-is-the-time-to-define-open-source-ai\"\u003eannounced\u003c/a\u003e\nthe organization\u0026#39;s intent to provide a definition for open-source AI\nin June 2023. He took exception to announcements of \n\u0026#34;\u003cq\u003elarge language models, foundational models, tooling, services all\nclaiming to be \u0026#39;open\u0026#39; or \u0026#39;Open Source\u0026#39;\u003c/q\u003e\u0026#34;, while adding restrictions\nwhich run afoul of the OSD. A \u003ca href=\"https://spectrum.ieee.org/open-source-llm-not-open\"\u003esurvey\u003c/a\u003e\nof large-language model (LLM) systems in 2023 found that ostensibly\nopen-source LLMs did not live up to the name.\u003c/p\u003e\n\n\u003cp\u003eThe problem is not quite as simple as saying \u0026#34;use an OSD-compliant\nlicense\u0026#34; for LLMs, because there are many more components to\nconsider. The original OSD is understood to apply to the\nsource code of a program in \u0026#34;\u003cq\u003ethe preferred form in which a\nprogrammer would modify the program\u003c/q\u003e\u0026#34;. A program is not considered\nopen source if a developer cannot study, use, modify, and share a\nprogram, and a license is not OSD‑compliant if it does not\npreserve those freedoms. A program can include non-free data and still\nbe open source. For example, the game \u003ca href=\"https://github.com/id-Software/Quake-III-Arena\"\u003eQuake III Arena\u003c/a\u003e\n(Q3A) is available under the GPLv2. That distribution, however, does\nnot include the \u003ca href=\"https://quakewiki.org/wiki/.pak\"\u003epak\u003c/a\u003e\nfiles that contain the maps, textures, and other content required to\nactually play the commercial game. Despite that, others can still use\nthe Q3A code to create their own games, such as \u003ca href=\"https://tremulous.net/\"\u003eTremulous\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen discussing an \u0026#34;AI system\u0026#34;, however, things are much more\ncomplicated. There is more than just the code that is used to run the\nmodels to do work of some kind, and the data is not something that\ncan be wholly separate from the system in the way that it can be with a\ngame. When looking at, say, LLMs, there is the model architecture, the\ncode used to train models, model parameters, the techniques and methodologies used for\ntraining, the procedures for labeling training data, the supporting\nlibraries, and (of course) the data used to train the models.\u003c/p\u003e\n\n\u003cp\u003eOSI has been working on its definition since last year. It held a kickoff meeting on June 21, 2023 at the\nMozilla headquarters in San Francisco. It \u003ca href=\"https://opensource.org/deepdive/#:~:text=How%20to%20participate\"\u003einvited\nparticipation\u003c/a\u003e afterward via a regular series of in-person\nand \u003ca href=\"https://opensource.org/ai/townhalls\"\u003eonline sessions\u003c/a\u003e,\nand with a \u003ca href=\"https://discuss.opensource.org/\"\u003eforum for online\ndiscussions\u003c/a\u003e. LWN \u003ca href=\"https://lwn.net/Articles/961868/#:~:text=Stefano%20Maffulli,AI%20system\"\u003ecovered\u003c/a\u003e\none of the sessions, held at \u003ca href=\"https://archive.fosdem.org/2024/\"\u003eFOSDEM 2024\u003c/a\u003e, in\nFebruary.\u003c/p\u003e\n\n\u003cp\u003eThe current draft of the OSAID takes its definition of an AI system from the \u003ca href=\"https://www.oecd.org/\"\u003eOrganisation for Economic Co-operation\nand Development\u003c/a\u003e (OECD) \u003ca href=\"https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449\"\u003eRecommendation\nof the Council on Artificial Intelligence\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\nA machine-based system that, for explicit or implicit objectives,\ninfers, from the input it receives, how to generate outputs such as\npredictions, content, recommendations, or decisions that can influence\nphysical or virtual environments.\n\u003c/blockquote\u003e\n\n\u003cp\u003eThis includes source code for training and running the system,\nmodel parameters \u0026#34;\u003cq\u003esuch as weights or other configuration\nsettings\u003c/q\u003e\u0026#34;, as well as \u0026#34;\u003cq\u003esufficiently detailed information about\nthe data used to train the system so that a skilled person can build a\nsubstantially equivalent system\u003c/q\u003e\u0026#34;.\u003c/p\u003e\n\n\u003ch4\u003ePreferred form to make modifications\u003c/h4\u003e\n\n\u003cp\u003eThose elements must all be available under OSI-approved licenses,\naccording to the proposed definition, which seems perfectly in line\nwith what we\u0026#39;ve come to expect when something is called \u0026#34;open\nsource\u0026#34;. There is an exception, though, for things like the data\ninformation and model parameters which must be available under\n\u0026#34;\u003cq\u003eOSI-approved terms\u003c/q\u003e\u0026#34;. The definition of OSI-approved terms is\nnot supplied yet.\u003c/p\u003e\n\n\u003cp\u003eThere is no requirement to make the \u003cem\u003etraining data\u003c/em\u003e available. To be\ncompliant with the current draft of the OSAID, an AI system need only\nprovide \u0026#34;\u003cq\u003edetailed information\u003c/q\u003e\u0026#34; about the data but not the data\nitself.\u003c/p\u003e\n\n\u003cp\u003eThe OSI \u003ca href=\"https://opensource.org/blog/community-input-drives-the-new-draft-of-the-open-source-ai-definition\"\u003epublished\u003c/a\u003e\nversion 0.0.9 on August 22. It acknowledged then that \u0026#34;\u003cq\u003etraining data is\none of the most hotly debated parts of the definition\u003c/q\u003e\u0026#34;. However,\nthe OSI was choosing not to require training data:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eAfter long deliberation and co-design sessions we have concluded\nthat defining training data as a benefit, not a requirement, is the\nbest way to go.\u003c/p\u003e\n\n\u003cp\u003eTraining data is valuable to study AI systems: to understand the\nbiases that have been learned, which can impact system behavior. But\ntraining data is not part of the preferred form for making\nmodifications to an existing AI system. The insights and\ncorrelations in that data have already been learned.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAs it stands, some feel that the OSAID falls short of allowing the\nfour freedoms that it is supposed to ensure. For example, julia\nferraioli \u003ca href=\"https://www.juliaferraioli.com/blog/2024/on-open-source-ai/\"\u003ewrote\u003c/a\u003e\nthat without including data, the only things that the OSAID guarantees\nare the ability to use and distribute an AI system. \u0026#34;\u003cq\u003eThey would be\nable to build on top of it, through methods such as transfer learning\nand fine-tuning, but that\u0026#39;s it.\u003c/q\u003e\u0026#34;\n\n\u003c/p\u003e\u003cp\u003eTom Callaway has \u003ca href=\"https://www.linkedin.com/pulse/why-open-data-necessary-source-ai-tom-callaway-stzcc/\"\u003ewritten\u003c/a\u003e\nat length on LinkedIn about why open data should be a requirement. He \nacknowledges that there are good reasons that distributors of an AI\nsystem may not want, or be able, to distribute training data. For\nexample, the data itself may have a high monetary value on its own,\nand a vendor may be unwilling or unable to share it.\nAcme Corp might license a data set and\nhave permission to create an AI system using it, but not the\nability to distribute the data itself. The data might have legal\nissues, ranging from confidentiality (e.g., medical data sets) to a\ndesire to avoid lawsuits from using copyrighted data.\u003c/p\u003e\n\n\u003cp\u003eAll of those are understandable reasons for not distributing\ndata with an AI system, he said, but they don\u0026#39;t argue for crafting a definition\nthat allows companies to call their system open:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eIf we let the Open Source AI definition contain a loophole that\nmakes data optional, we devalue the meaning of \u0026#34;open source\u0026#34; in all\nother contexts. While there are lots of companies who would like to\nsee open source mean less, I think it\u0026#39;s critical that we not\ncompromise here, even if it means there are less Open Source AI\nsystems at first.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eObjections to lack of training data are more than an attachment to\nthe original meaning of open source. Giacomo Tesio \u003ca href=\"https://discuss.opensource.org/t/list-of-unaddressed-issues-of-osaid-rc2/650\"\u003eposted\u003c/a\u003e\na list of issues he considered unaddressed in the RC2 version of\nthe OSAID, including a claim that there is inherent insecurity due to the\nability to \u003ca href=\"https://arxiv.org/abs/2204.06974\"\u003eplant\nundetectable backdoors\u003c/a\u003e in machine-learning models.\u003c/p\u003e\n\n\u003ch4\u003eOthers weigh in\u003c/h4\u003e\n\n\u003cp\u003eThe Free Software Foundation (FSF) \u003ca href=\"https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications\"\u003eannounced\u003c/a\u003e\nthat it was working on \u0026#34;\u003cq\u003ea statement of criteria for free machine\nlearning applications\u003c/q\u003e\u0026#34; to call something a free (or libre)\nmachine-learning application. The FSF says that it is close to a\ndefinition, and is working on the exact text. However, it adds that\n\u0026#34;\u003cq\u003ewe believe that we cannot say a ML application \u0026#39;is free\u0026#39; unless\nall its training data and the related scripts for processing it\nrespect all users, following the four freedoms\u003c/q\u003e\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003eHowever, the FSF makes a distinction between non-free and\nunethical in this case:\u003c/p\u003e\n\n\u003cblockquote\u003e\nIt may be that some nonfree ML have valid moral reasons for not\nreleasing training data, such as personal medical data. In that case,\nwe would describe the application as a whole as nonfree. But using it\ncould be ethically excusable if it helps you do a specialized job that\nis vital for society, such as diagnosing disease or injury.\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://sfconservancy.org/\"\u003eSoftware Freedom Conservancy\u003c/a\u003e\nhas \u003ca href=\"https://sfconservancy.org/news/2024/oct/25/aspirational-on-llm-generative-ai-programming/\"\u003eannounced\u003c/a\u003e\nan \u0026#34;\u003cq\u003easpirational statement\u003c/q\u003e\u0026#34; about LLM-backed generative AI for\nprogramming called \u0026#34;Machine-Learning-Assisted Programming that\nRespects User Freedom\u0026#34;. Unlike the OSAID, this target focuses solely\non computer-assisted programming, and was developed \u003ca href=\"https://sfconservancy.org/blog/2022/feb/03/github-copilot-copyleft-gpl/\"\u003ein\nresponse\u003c/a\u003e to \u003ca href=\"https://en.wikipedia.org/wiki/GitHub_Copilot\"\u003eGitHub\nCopilot\u003c/a\u003e. The announcement did not directly name the OSI or the OSAID effort, but\nsaid \u0026#34;\u003cq\u003ewe have avoided any process that effectively auto-endorses\nthe problematic practices of companies whose proprietary products are\nalready widely deployed\u003c/q\u003e\u0026#34;. It describes an ideal LLM system built\nonly with FOSS, with all components available, and only for the creation of FOSS.\u003c/p\u003e\n\n\u003ch4\u003eResponse to criticisms\u003c/h4\u003e\n\n\u003cp\u003eI emailed Maffulli about some of the criticisms of the current\nOSAID draft, and asked why OSI appears to be \u0026#34;lowering the bar\u0026#34; when\nthe OSI has never budged on source availability and use\nrestrictions. He replied:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eI\u0026#39;ll be blunt: you mention \u0026#34;source redistribution\u0026#34; in your question\nand that\u0026#39;s what leads people like [Callaway] into a mental trap\n[...]\u003c/p\u003e\n\n\u003cp\u003eThere are some groups believing that more components are required to\nguarantee more transparency. Other groups instead believe that model\nparameters and architecture are enough to modify AI. The Open Source\nAI Definition, developed publicly with a wide variety of stakeholders\nworldwide, with deep expertise on building AI (see the \u003ca href=\"https://opensource.org/ai/endorsements\"\u003elist of endorsers\u003c/a\u003e),\nfound that while those approaches are legitimate, neither is\noptimal. The OSAID grants users the rights (with licenses) and the\ntools (with the list of required components) to meaningfully\ncollaborate and innovate on (and fork, if required) AI systems.  We\nhave not compromised on our principles: we learned many new things\nfrom actual AI experts along the way.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eMaffulli objected to the idea that the OSAID was weaker or making\nconcessions, and said that the preferred form for modifying ML systems\nwas what is in the OSAID: \u0026#34;\u003cq\u003eit\u0026#39;s not me nor OSI board saying that,\nit\u0026#39;s in the list of endorsers and in [Carnegie Mellon University\u0026#39;s] \u003ca href=\"https://www.cmu.edu/engin/programs/about-ofai/cmu-osaid-statement.html\"\u003ecomment\u003c/a\u003e\u003c/q\u003e\u0026#34;. He\nadded that OSI had synthesized input from \u0026#34;\u003cq\u003eAI builders, users, and\ndeployers, content creators, unions, ethicists, lawyers, software\ndevelopers from all over the world\u003c/q\u003e\u0026#34; to arrive at the definition. A\n\u0026#34;\u003cq\u003esimple translation\u003c/q\u003e\u0026#34; of the OSD, he said, would not work.\u003c/p\u003e\n\n\u003cp\u003eStephen O\u0026#39;Grady, founder of the RedMonk analyst firm, also makes\nthe case that the OSD does not easily translate to AI projects. But he\ndoes not believe that the term open source \u0026#34;\u003cq\u003ecan or should be\nextended into the AI world\u003c/q\u003e\u0026#34; as he \u003ca href=\"https://redmonk.com/sogrady/2024/10/22/from-open-source-to-ai/\"\u003ewrote\u003c/a\u003e\nin a blog post on October 22:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eAt its heart, the current deliberation around an open source\ndefinition for AI is an attempt to drag a term defined over two\ndecades ago to describe a narrowly defined asset into the present to\ninstead cover a brand new, far more complicated future set of\nartifacts.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eO\u0026#39;Grady makes the case that the OSI has set out on a pragmatic path\nto define open-source AI, which requires nuance. Open source has\nsucceeded, in part, because the OSD removes nuance. Does a license\ncomply with the OSD or doesn\u0026#39;t it? It\u0026#39;s pretty easy to determine. Less\nso with the OSAID. The pragmatic path, he said:\n\n\u003c/p\u003e\u003cblockquote\u003e\nInvolves substantial compromise and, more problematically,\nrequires explanation to be understood. And as the old political adage\nadvises: \u0026#34;If you\u0026#39;re explaining, you\u0026#39;re losing.\u0026#34;\n\u003c/blockquote\u003e\n\n\u003cp\u003eIt would have been better, he said, if the OSI had not tried to\n\u0026#34;\u003cq\u003ebend and reshape a decades old definition\u003c/q\u003e\u0026#34; and instead had\ntried to craft something from a clean slate. That seems unlikely now,\nhe said, after two years of trying to \u0026#34;\u003cq\u003ethread the needle between\nidealism and capitalism to arrive at an ideologically sound and yet\ncommercially acceptable\u003c/q\u003e\u0026#34; definition.\u003c/p\u003e\n\n\u003cp\u003eIndeed, it seems likely that the OSI board will move forward with\nthe current draft of the OSAID or something close to it. The\nimpact that will have is much less certain.\u003c/p\u003e\n\n\u003cbr clear=\"all\"/\u003e\n               \u003cbr clear=\"all\"/\u003e\n               \u003chr/\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "14 min read",
  "publishedTime": null,
  "modifiedTime": null
}
