{
  "id": "d5cf4631-f5d7-4701-852e-9ab15c66763e",
  "title": "OpenAI brings GPT-4.1 and 4.1 mini to ChatGPT — what enterprises should know",
  "link": "https://venturebeat.com/ai/openai-brings-gpt-4-1-and-4-1-mini-to-chatgpt-what-enterprises-should-know/",
  "description": "As OpenAI continues to evolve its model offerings, GPT-4.1 represents a step forward in democratizing advanced AI for enterprise environments",
  "author": "Carl Franzen",
  "published": "Wed, 14 May 2025 23:46:50 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI, ML and Deep Learning",
    "ChatGPT",
    "Conversational AI",
    "enterprise ai",
    "GPT-4.1",
    "LLMs",
    "NLP",
    "OpenAI"
  ],
  "byline": "Carl Franzen",
  "length": 9317,
  "excerpt": "As OpenAI continues to evolve its model offerings, GPT-4.1 represents a step forward in democratizing advanced AI for enterprise environments",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "May 14, 2025 4:46 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More OpenAI is rolling out GPT-4.1, its new non-reasoning large language model (LLM) that balances high performance with lower cost, to users of ChatGPT. The company is beginning with its paying subscribers on ChatGPT Plus, Pro, and Team, with Enterprise and Education user access expected in the coming weeks. It’s also adding GPT-4.1 mini, which replaces GPT-4o mini as the default for all ChatGPT users, including those on the free tier. The “mini” version provides a smaller-scale parameter and thus, less powerful version with similar safety standards. The models are both available via the “more models” dropdown selection in the top corner of the chat window within ChatGPT, giving users flexibility to choose between GPT-4.1, GPT-4.1 mini, and reasoning models such as o3, o4-mini, and o4-mini-high. Initially intended for use only by third-party software and AI developers through OpenAI’s application programming interface (API), GPT-4.1 was added to ChatGPT following strong user feedback. OpenAI post training research lead Michelle Pokrass confirmed on X the shift was driven by demand, writing: “we were initially planning on keeping this model api only but you all wanted it in chatgpt :) happy coding!” OpenAI Chief Product Officer Kevin Weil posted on X saying: “We built it for developers, so it’s very good at coding and instruction following—give it a try!” An enterprise-focused model GPT-4.1 was designed from the ground up for enterprise-grade practicality. Launched in April 2025 alongside GPT-4.1 mini and nano, this model family prioritized developer needs and production use cases. GPT-4.1 delivers a 21.4-point improvement over GPT-4o on the SWE-bench Verified software engineering benchmark, and a 10.5-point gain on instruction-following tasks in Scale’s MultiChallenge benchmark. It also reduces verbosity by 50% compared to other models, a trait enterprise users praised during early testing. Context, speed, and model access GPT-4.1 supports the standard context windows for ChatGPT: 8,000 tokens for free users, 32,000 tokens for Plus users, and 128,000 tokens for Pro users. According to developer Angel Bogado posting on X, these limits match those used by earlier ChatGPT models, though plans are underway to increase context size further. While the API versions of GPT-4.1 can process up to one million tokens, this expanded capacity is not yet available in ChatGPT, though future support has been hinted at. This extended context capability allows API users to feed entire codebases or large legal and financial documents into the model—useful for reviewing multi-document contracts or analyzing large log files. OpenAI has acknowledged some performance degradation with extremely large inputs, but enterprise test cases suggest solid performance up to several hundred thousand tokens. Evaluations and safety OpenAI has also launched a Safety Evaluations Hub website to give users access to key performance metrics across models. GPT-4.1 shows solid results across these evaluations. In factual accuracy tests, it scored 0.40 on the SimpleQA benchmark and 0.63 on PersonQA, outperforming several predecessors. It also scored 0.99 on OpenAI’s “not unsafe” measure in standard refusal tests, and 0.86 on more challenging prompts. However, in the StrongReject jailbreak test—an academic benchmark for safety under adversarial conditions—GPT-4.1 scored 0.23, behind models like GPT-4o-mini and o3. That said, it scored a strong 0.96 on human-sourced jailbreak prompts, indicating more robust real-world safety under typical use. In instruction adherence, GPT-4.1 follows OpenAI’s defined hierarchy (system over developer, developer over user messages) with a score of 0.71 for resolving system vs. user message conflicts. It also performs well in safeguarding protected phrases and avoiding solution giveaways in tutoring scenarios. Contextualizing GPT-4.1 against predecessors The release of GPT-4.1 comes after scrutiny around GPT-4.5, which debuted in February 2025 as a research preview. That model emphasized better unsupervised learning, a richer knowledge base, and reduced hallucinations—falling from 61.8% in GPT-4o to 37.1%. It also showcased improvements in emotional nuance and long-form writing, but many users found the enhancements subtle. Despite these gains, GPT-4.5 drew criticism for its high price — up to $180 per million output tokens via API —and for underwhelming performance in math and coding benchmarks relative to OpenAI’s o-series models. Industry figures noted that while GPT-4.5 was stronger in general conversation and content generation, it underperformed in developer-specific applications. By contrast, GPT-4.1 is intended as a faster, more focused alternative. While it lacks GPT-4.5’s breadth of knowledge and extensive emotional modeling, it is better tuned for practical coding assistance and adheres more reliably to user instructions. On OpenAI’s API, GPT-4.1 is currently priced at $2.00 per million input tokens, $0.50 per million cached input tokens, and $8.00 per million output tokens. For those seeking a balance between speed and intelligence at a lower cost, GPT-4.1 mini is available at $0.40 per million input tokens, $0.10 per million cached input tokens, and $1.60 per million output tokens. Google’s Flash-Lite and Flash models are available starting at $0.075–$0.10 per million input tokens and $0.30–$0.40 per million output tokens, less than a tenth the cost of GPT-4.1’s base rates. But while GPT-4.1 is priced higher, it offers stronger software engineering benchmarks and more precise instruction following, which may be critical for enterprise deployment scenarios requiring reliability over cost. Ultimately, OpenAI’s GPT-4.1 delivers a premium experience for precision and development performance, while Google’s Gemini models appeal to cost-conscious enterprises needing flexible model tiers and multimodal capabilities. What It means for enterprise decision makers The introduction of GPT-4.1 brings specific benefits to enterprise teams managing LLM deployment, orchestration, and data operations: AI Engineers overseeing LLM deployment can expect improved speed and instruction adherence. For teams managing the full LLM lifecycle—from model fine-tuning to troubleshooting—GPT-4.1 offers a more responsive and efficient toolset. It’s particularly suitable for lean teams under pressure to ship high-performing models quickly without compromising safety or compliance. AI orchestration leads focused on scalable pipeline design will appreciate GPT-4.1’s robustness against most user-induced failures and its strong performance in message hierarchy tests. This makes it easier to integrate into orchestration systems that prioritize consistency, model validation, and operational reliability. Data engineers responsible for maintaining high data quality and integrating new tools will benefit from GPT-4.1’s lower hallucination rate and higher factual accuracy. Its more predictable output behavior aids in building dependable data workflows, even when team resources are constrained. IT security professionals tasked with embedding security across DevOps pipelines may find value in GPT-4.1’s resistance to common jailbreaks and its controlled output behavior. While its academic jailbreak resistance score leaves room for improvement, the model’s high performance against human-sourced exploits helps support safe integration into internal tools. Across these roles, GPT-4.1’s positioning as a model optimized for clarity, compliance, and deployment efficiency makes it a compelling option for mid-sized enterprises looking to balance performance with operational demands. A new step forward While GPT-4.5 represented a scaling milestone in model development, GPT-4.1 centers on utility. It is not the most expensive or the most multimodal, but it delivers meaningful gains in areas that matter to enterprises: accuracy, deployment efficiency, and cost. This repositioning reflects a broader industry trend—away from building the biggest models at any cost, and toward making capable models more accessible and adaptable. GPT-4.1 meets that need, offering a flexible, production-ready tool for teams trying to embed AI deeper into their business operations. As OpenAI continues to evolve its model offerings, GPT-4.1 represents a step forward in democratizing advanced AI for enterprise environments. For decision-makers balancing capability with ROI, it offers a clearer path to deployment without sacrificing performance or safety. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/05/cfr0z3n_stark_white_backdrop_with_colorful_marker_illustration__ec28f705-82a7-40c2-bd35-b4819a1d0290.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-05-14T23:46:50+00:00\" datetime=\"2025-05-14T23:46:50+00:00\"\u003eMay 14, 2025 4:46 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"224\" src=\"https://venturebeat.com/wp-content/uploads/2025/05/cfr0z3n_stark_white_backdrop_with_colorful_marker_illustration__ec28f705-82a7-40c2-bd35-b4819a1d0290.png?w=400\" alt=\"Painted style AI image of pink and white robot above a keyboard surrounded by colorful headshots of various diverse people\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eOpenAI is \u003ca href=\"https://x.com/OpenAI/status/1922707554745909391\" target=\"_blank\" rel=\"noreferrer noopener\"\u003erolling out GPT-4.1\u003c/a\u003e, its new non-reasoning large language model (LLM) that balances high performance with lower cost, to users of ChatGPT. The company is beginning with its paying subscribers on ChatGPT Plus, Pro, and Team, with Enterprise and Education user access expected in the coming weeks. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt’s also adding GPT-4.1 mini, which replaces GPT-4o mini as the default for all ChatGPT users, including those on the free tier. The “mini” version provides a smaller-scale parameter and thus, less powerful version with similar safety standards.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe models are both available via the “more models” dropdown selection in the top corner of the chat window within ChatGPT, giving users flexibility to choose between GPT-4.1, GPT-4.1 mini, and reasoning models such as o3, o4-mini, and o4-mini-high.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"641\" height=\"483\" src=\"https://venturebeat.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-7.28.28%E2%80%AFPM.png\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-7.28.28 PM.png 641w, https://venturebeat.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-7.28.28 PM.png?resize=300,226 300w, https://venturebeat.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-7.28.28 PM.png?resize=400,301 400w, https://venturebeat.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-7.28.28 PM.png?resize=578,436 578w\" sizes=\"(max-width: 641px) 100vw, 641px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eInitially intended for use only by third-party software and AI developers through OpenAI’s application programming interface (API), GPT-4.1 was added to ChatGPT following strong user feedback. \u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI post training research lead \u003ca href=\"https://x.com/michpokrass/status/1922716587468984689\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMichelle Pokrass\u003c/a\u003e confirmed on X the shift was driven by demand, writing: “we were initially planning on keeping this model api only but you all wanted it in chatgpt :) happy coding!”\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI Chief Product Officer Kevin Weil \u003ca href=\"https://x.com/kevinweil/status/1922732062345142306\"\u003eposted on X\u003c/a\u003e saying: “We built it for developers, so it’s very good at coding and instruction following—give it a try!”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-an-enterprise-focused-model\"\u003eAn enterprise-focused model\u003c/h2\u003e\n\n\n\n\u003cp\u003eGPT-4.1 was designed from the ground up for enterprise-grade practicality.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://venturebeat.com/security/openais-new-gpt-4-1-models-can-process-a-million-tokens-and-solve-coding-problems-better-than-ever/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLaunched in April 2025 alongside GPT-4.1 mini and nano\u003c/a\u003e, this model family prioritized developer needs and production use cases. \u003c/p\u003e\n\n\n\n\u003cp\u003eGPT-4.1 delivers a 21.4-point improvement over GPT-4o on the SWE-bench Verified software engineering benchmark, and a 10.5-point gain on instruction-following tasks in Scale’s MultiChallenge benchmark. It also reduces verbosity by 50% compared to other models, a trait enterprise users praised during early testing.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-context-speed-and-model-access\"\u003eContext, speed, and model access\u003c/h2\u003e\n\n\n\n\u003cp\u003eGPT-4.1 supports the standard context windows for ChatGPT: 8,000 tokens for free users, 32,000 tokens for Plus users, and 128,000 tokens for Pro users. \u003c/p\u003e\n\n\n\n\u003cp\u003eAccording to developer \u003ca href=\"https://x.com/Angaisb_/status/1922734124759990406\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAngel Bogado\u003c/a\u003e posting on X, these limits match those used by earlier ChatGPT models, though plans are underway to increase context size further.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile the API versions of GPT-4.1 can process up to one million tokens, this expanded capacity is not yet available in ChatGPT, though future support has been hinted at.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis extended context capability allows API users to feed entire codebases or large legal and financial documents into the model—useful for reviewing multi-document contracts or analyzing large log files.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI has acknowledged some performance degradation with extremely large inputs, but enterprise test cases suggest solid performance up to several hundred thousand tokens.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-evaluations-and-safety\"\u003eEvaluations and safety\u003c/h2\u003e\n\n\n\n\u003cp\u003eOpenAI has also launched a \u003ca href=\"https://openai.com/safety/evaluations-hub/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSafety Evaluations Hub\u003c/a\u003e website to give users access to key performance metrics across models. \u003c/p\u003e\n\n\n\n\u003cp\u003eGPT-4.1 shows solid results across these evaluations. In factual accuracy tests, it scored 0.40 on the SimpleQA benchmark and 0.63 on PersonQA, outperforming several predecessors. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt also scored 0.99 on OpenAI’s “not unsafe” measure in standard refusal tests, and 0.86 on more challenging prompts.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, in the StrongReject jailbreak test—an academic benchmark for safety under adversarial conditions—GPT-4.1 scored 0.23, behind models like GPT-4o-mini and o3. \u003c/p\u003e\n\n\n\n\u003cp\u003eThat said, it scored a strong 0.96 on human-sourced jailbreak prompts, indicating more robust real-world safety under typical use.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn instruction adherence, GPT-4.1 follows OpenAI’s defined hierarchy (system over developer, developer over user messages) with a score of 0.71 for resolving system vs. user message conflicts. It also performs well in safeguarding protected phrases and avoiding solution giveaways in tutoring scenarios.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-contextualizing-gpt-4-1-against-predecessors\"\u003eContextualizing GPT-4.1 against predecessors\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe release of GPT-4.1 comes afte\u003ca href=\"https://venturebeat.com/ai/industry-observers-say-gpt-4-5-is-an-odd-model-question-its-price/\"\u003er scrutiny around GPT-4.5\u003c/a\u003e, which \u003ca href=\"https://venturebeat.com/ai/openai-releases-gpt-4-5/\"\u003edebuted in February 2025\u003c/a\u003e as a research preview. That model emphasized better unsupervised learning, a richer knowledge base, and reduced hallucinations—falling from 61.8% in GPT-4o to 37.1%. It also showcased improvements in emotional nuance and long-form writing, but many users found the enhancements subtle.\u003c/p\u003e\n\n\n\n\u003cp\u003eDespite these gains, GPT-4.5 drew criticism for its high price — up to $180 per million output tokens via API —and for underwhelming performance in math and coding benchmarks relative to OpenAI’s o-series models. Industry figures noted that while GPT-4.5 was stronger in general conversation and content generation, it underperformed in developer-specific applications.\u003c/p\u003e\n\n\n\n\u003cp\u003eBy contrast, GPT-4.1 is intended as a faster, more focused alternative. While it lacks GPT-4.5’s breadth of knowledge and extensive emotional modeling, it is better tuned for practical coding assistance and adheres more reliably to user instructions.\u003c/p\u003e\n\n\n\n\u003cp\u003eOn OpenAI’s API, \u003ca href=\"https://openai.com/api/pricing/\"\u003eGPT-4.1 is currently priced\u003c/a\u003e at $2.00 per million input tokens, $0.50 per million cached input tokens, and $8.00 per million output tokens. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor those seeking a balance between speed and intelligence at a lower cost, GPT-4.1 mini is available at $0.40 per million input tokens, $0.10 per million cached input tokens, and $1.60 per million output tokens. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://ai.google.dev/gemini-api/docs/pricing\"\u003eGoogle’s Flash-Lite and Flash models\u003c/a\u003e are available starting at $0.075–$0.10 per million input tokens and $0.30–$0.40 per million output tokens, less than a tenth the cost of GPT-4.1’s base rates.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut while GPT-4.1 is priced higher, it offers stronger software engineering benchmarks and more precise instruction following, which may be critical for enterprise deployment scenarios requiring reliability over cost.  Ultimately, OpenAI’s GPT-4.1 delivers a premium experience for precision and development performance, while Google’s Gemini models appeal to cost-conscious enterprises needing flexible model tiers and multimodal capabilities.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-it-means-for-enterprise-decision-makers\"\u003eWhat It means for enterprise decision makers\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe introduction of GPT-4.1 brings specific benefits to enterprise teams managing LLM deployment, orchestration, and data operations:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAI Engineers overseeing LLM deployment\u003c/strong\u003e can expect improved speed and instruction adherence. For teams managing the full LLM lifecycle—from model fine-tuning to troubleshooting—GPT-4.1 offers a more responsive and efficient toolset. It’s particularly suitable for lean teams under pressure to ship high-performing models quickly without compromising safety or compliance.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eAI orchestration leads\u003c/strong\u003e focused on scalable pipeline design will appreciate GPT-4.1’s robustness against most user-induced failures and its strong performance in message hierarchy tests. This makes it easier to integrate into orchestration systems that prioritize consistency, model validation, and operational reliability.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eData engineers\u003c/strong\u003e responsible for maintaining high data quality and integrating new tools will benefit from GPT-4.1’s lower hallucination rate and higher factual accuracy. Its more predictable output behavior aids in building dependable data workflows, even when team resources are constrained.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eIT security professionals\u003c/strong\u003e tasked with embedding security across DevOps pipelines may find value in GPT-4.1’s resistance to common jailbreaks and its controlled output behavior. While its academic jailbreak resistance score leaves room for improvement, the model’s high performance against human-sourced exploits helps support safe integration into internal tools.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eAcross these roles, GPT-4.1’s positioning as a model optimized for clarity, compliance, and deployment efficiency makes it a compelling option for mid-sized enterprises looking to balance performance with operational demands.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-new-step-forward\"\u003eA new step forward\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile GPT-4.5 represented a scaling milestone in model development, GPT-4.1 centers on utility. It is not the most expensive or the most multimodal, but it delivers meaningful gains in areas that matter to enterprises: accuracy, deployment efficiency, and cost.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis repositioning reflects a broader industry trend—away from building the biggest models at any cost, and toward making capable models more accessible and adaptable. GPT-4.1 meets that need, offering a flexible, production-ready tool for teams trying to embed AI deeper into their business operations.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs OpenAI continues to evolve its model offerings, GPT-4.1 represents a step forward in democratizing advanced AI for enterprise environments. For decision-makers balancing capability with ROI, it offers a clearer path to deployment without sacrificing performance or safety.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-05-14T23:46:50Z",
  "modifiedTime": "2025-05-14T23:51:04Z"
}
