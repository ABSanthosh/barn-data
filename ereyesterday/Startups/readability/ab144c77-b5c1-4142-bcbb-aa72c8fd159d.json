{
  "id": "ab144c77-b5c1-4142-bcbb-aa72c8fd159d",
  "title": "Large language overkill: How SLMs can beat their bigger, resource-intensive cousins",
  "link": "https://venturebeat.com/ai/large-language-overkill-how-slms-can-beat-their-bigger-resource-intensive-cousins/",
  "description": "Whether a company begins with a proof-of-concept or live deployment, they should start small, test often and build on early successes.",
  "author": "AJ Sunder, Responsive",
  "published": "Sat, 21 Dec 2024 20:25:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "category-/News",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "NLP",
    "small language models",
    "small language models (SLMs)"
  ],
  "byline": "AJ Sunder, Responsive",
  "length": 6737,
  "excerpt": "Whether a company begins with a proof-of-concept or live deployment, they should start small, test often and build on early successes.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "December 21, 2024 12:25 PM VentureBeat/Ideogram Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Two years on from the public release of ChatGPT, conversations about AI are inescapable as companies across every industry look to harness large language models (LLMs) to transform their business processes. Yet, as powerful and promising as LLMs are, many business and IT leaders have come to over-rely on them and to overlook their limitations. This is why I anticipate a future where specialized language models, or SLMs, will play a bigger, complementary role in enterprise IT. SLMs are more typically referred to as “small language models” because they require less data and training time and are “more streamlined versions of LLMs.” But I prefer the word “specialized” because it better conveys the ability of these purpose-built solutions to perform highly specialized work with greater accuracy, consistency and transparency than LLMs. By supplementing LLMs with SLMs, organizations can create solutions that take advantage of each model’s strengths. Trust and the LLM ‘black box’ problem LLMs are incredibly powerful, yet they are also known for sometimes “losing the plot,” or offering outputs that veer off course due to their generalist training and massive data sets. That tendency is made more problematic by the fact that OpenAI’s ChatGPT and other LLMs are essentially “black boxes” that don’t reveal how they arrive at an answer.  This black box problem is going to become a bigger issue going forward, particularly for companies and business-critical applications where accuracy, consistency and compliance are paramount. Think healthcare, financial services and legal as prime examples of professions where inaccurate answers can have huge financial consequences and even life-or-death repercussions. Regulatory bodies are already taking notice and will likely begin to demand explainable AI solutions, especially in industries that rely on data privacy and accuracy. While businesses often deploy a “human-in-the-loop” approach to mitigate these issues, an over-reliance on LLMs can lead to a false sense of security. Over time, complacency can set in and mistakes can slip through undetected. SLMs = greater explainability Fortunately, SLMs are better suited to address many of the limitations of LLMs. Rather than being designed for general-purpose tasks, SLMs are developed with a narrower focus and trained on domain-specific data. This specificity allows them to handle nuanced language requirements in areas where precision is paramount. Rather than relying on vast, heterogeneous datasets, SLMs are trained on targeted information, giving them the contextual intelligence to deliver more consistent, predictable and relevant responses. This offers several advantages. First, they are more explainable, making it easier to understand the source and rationale behind their outputs. This is critical in regulated industries where decisions need to be traced back to a source.  Second, their smaller size means they can often perform faster than LLMs, which can be a crucial factor for real-time applications. Third, SLMs offer businesses more control over data privacy and security, especially if they’re deployed internally or built specifically for the enterprise. Moreover, while SLMs may initially require specialized training, they reduce the risks associated with using third-party LLMs controlled by external providers. This control is invaluable in applications that demand stringent data handling and compliance. Focus on developing expertise (and be wary of vendors who overpromise) I want to be clear that LLMs and SLMs are not mutually exclusive. In practice, SLMs can augment LLMs, creating hybrid solutions where LLMs provide broader context and SLMs ensure precise execution. It’s also still early days even where LLMs are concerned, so I always advise technology leaders to continue exploring the many possibilities and benefits of LLMs.  In addition, while LLMs can scale well for a variety of problems, SLMs may not transfer well to certain use cases. It is therefore important to have a clear understanding upfront as to what use cases to tackle.  It’s also important that business and IT leaders devote more time and attention to building the distinct skills required for training, fine-tuning and testing SLMs. Fortunately, there is a great deal of free information and training available via common sources such Coursera, YouTube and Huggingface.co. Leaders should make sure their developers have adequate time for learning and experimenting with SLMs as the battle for AI expertise intensifies.  I also advise leaders to vet partners carefully. I recently spoke with a company that asked for my opinion on a certain technology provider’s claims. My take was that they were either overstating their claims or were simply out of their depth in terms of understanding the technology’s capabilities.  The company wisely took a step back and implemented a controlled proof-of-concept to test the vendor’s claims. As I suspected, the solution simply wasn’t ready for prime time, and the company was able to walk away with relatively little time and money invested.  Whether a company starts with a proof-of-concept or a live deployment, I advise them to start small, test often and build on early successes. I’ve personally experienced working with a small set of instructions and information, only to find the results veering off course when I then feed the model more information. That’s why slow-and-steady is a prudent approach. In summary, while LLMs will continue to provide ever-more-valuable capabilities, their limitations are becoming increasingly apparent as businesses scale their reliance on AI. Supplementing with SLMs offers a path forward, especially in high-stakes fields that demand accuracy and explainability. By investing in SLMs, companies can future-proof their AI strategies, ensuring that their tools not only drive innovation but also meet the demands of trust, reliability and control.  AJ Sunder is co-founder, CIO and CPO at Responsive. DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2024/12/a-vector-art-illustration-of-a-small-fle_uqOt6VuuSSyz0U6nwUHI8g_sSK28McNSIee3H6LfJRqZA-transformed.jpeg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-12-21T20:25:00+00:00\" datetime=\"2024-12-21T20:25:00+00:00\"\u003eDecember 21, 2024 12:25 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"421\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/a-vector-art-illustration-of-a-small-fle_uqOt6VuuSSyz0U6nwUHI8g_sSK28McNSIee3H6LfJRqZA-transformed.jpeg?w=750\" alt=\"VentureBeat/Ideogram\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Ideogram\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eTwo years on from the public release of ChatGPT, conversations about AI are inescapable as companies across every industry look to harness \u003ca href=\"https://venturebeat.com/ai/weve-come-a-long-way-from-rpa-how-ai-agents-are-revolutionizing-automation/\"\u003elarge language models\u003c/a\u003e (LLMs) to transform their business processes. Yet, as powerful and promising as LLMs are, many business and IT leaders have come to over-rely on them and to overlook their limitations. This is why I anticipate a future where specialized language models, or SLMs, will play a bigger, complementary role in enterprise IT.\u003c/p\u003e\n\n\n\n\u003cp\u003eSLMs are more typically referred to as “small language models” because they require less data and training time and are “\u003ca href=\"https://venturebeat.com/ai/why-small-language-models-are-the-next-big-thing-in-ai/\"\u003emore streamlined versions of LLMs\u003c/a\u003e.” But I prefer the word “specialized” because it better conveys the ability of these purpose-built solutions to perform highly specialized work with greater accuracy, consistency and transparency than LLMs. By supplementing LLMs with SLMs, organizations can create solutions that take advantage of each model’s strengths.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-trust-and-the-llm-black-box-problem\"\u003eTrust and the LLM ‘black box’ problem\u003c/h2\u003e\n\n\n\n\u003cp\u003eLLMs are incredibly powerful, yet they are also known for sometimes “losing the plot,” or offering outputs that veer off course due to their generalist training and massive data sets. That tendency is made more problematic by the fact that \u003ca href=\"https://venturebeat.com/ai/chatgpts-second-birthday-what-will-gen-ai-and-the-world-look-like-in-another-2-years/\"\u003eOpenAI’s ChatGPT\u003c/a\u003e and other LLMs are essentially “black boxes” that don’t reveal how they arrive at an answer. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis black box problem is going to become a bigger issue going forward, particularly for companies and business-critical applications where accuracy, consistency and compliance are paramount. Think healthcare, financial services and legal as prime examples of professions where inaccurate answers can have huge financial consequences and even life-or-death repercussions. Regulatory bodies are already taking notice and will likely begin to demand \u003ca href=\"https://venturebeat.com/ai/synthetic-data-has-its-limits-why-human-sourced-data-can-help-prevent-ai-model-collapse/\"\u003eexplainable AI solutions\u003c/a\u003e, especially in industries that rely on data privacy and accuracy.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile businesses often deploy a “human-in-the-loop” approach to mitigate these issues, an over-reliance on LLMs can lead to a false sense of security. Over time, complacency can set in and mistakes can slip through undetected.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-slms-greater-explainability\"\u003eSLMs = greater explainability\u003c/h2\u003e\n\n\n\n\u003cp\u003eFortunately, SLMs are better suited to address many of the limitations of LLMs. Rather than being designed for general-purpose tasks, SLMs are developed with a narrower focus and trained on domain-specific data. This specificity allows them to handle nuanced language requirements in areas where precision is paramount. Rather than relying on vast, heterogeneous datasets, SLMs are trained on targeted information, giving them the \u003ca href=\"https://venturebeat.com/ai/heres-the-one-thing-you-should-never-outsource-to-an-ai-model/\"\u003econtextual intelligence\u003c/a\u003e to deliver more consistent, predictable and relevant responses.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis offers several advantages. First, they are more explainable, making it easier to understand the source and rationale behind their outputs. This is critical in regulated industries where decisions need to be traced back to a source. \u003c/p\u003e\n\n\n\n\u003cp\u003eSecond, their smaller size means they can often perform faster than LLMs, which can be a crucial factor for real-time applications. Third, SLMs offer businesses more control over data privacy and security, especially if they’re deployed internally or built specifically for the enterprise.\u003c/p\u003e\n\n\n\n\u003cp\u003eMoreover, while SLMs may initially require specialized training, they reduce the risks associated with using third-party LLMs controlled by external providers. This control is invaluable in applications that demand stringent data handling and compliance.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-focus-on-developing-expertise-and-be-wary-of-vendors-who-overpromise\"\u003eFocus on developing expertise (and be wary of vendors who overpromise)\u003c/h2\u003e\n\n\n\n\u003cp\u003eI want to be clear that \u003ca href=\"https://venturebeat.com/ai/getting-started-with-ai-agents-part-1-capturing-processes-roles-and-connections/\"\u003eLLMs and SLMs\u003c/a\u003e are not mutually exclusive. In practice, SLMs can augment LLMs, creating hybrid solutions where LLMs provide broader context and SLMs ensure precise execution. It’s also still early days even where LLMs are concerned, so I always advise technology leaders to continue exploring the many possibilities and benefits of LLMs. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn addition, while LLMs can scale well for a variety of problems, SLMs may not transfer well to certain use cases. It is therefore important to have a clear understanding upfront as to what use cases to tackle. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt’s also important that business and IT leaders devote more time and attention to building the distinct skills required for training, fine-tuning and testing SLMs. Fortunately, there is a great deal of free information and training available via common sources such Coursera, YouTube and \u003ca href=\"https://venturebeat.com/ai/hugging-face-shows-how-test-time-scaling-helps-small-language-models-punch-above-their-weight/\"\u003eHuggingface.co\u003c/a\u003e. Leaders should make sure their developers have adequate time for learning and experimenting with SLMs as the battle for AI expertise intensifies. \u003c/p\u003e\n\n\n\n\u003cp\u003eI also advise leaders to vet partners carefully. I recently spoke with a company that asked for my opinion on a certain technology provider’s claims. My take was that they were either overstating their claims or were simply out of their depth in terms of understanding the technology’s capabilities. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe company wisely took a step back and implemented a controlled proof-of-concept to test the vendor’s claims. As I suspected, the solution simply wasn’t ready for prime time, and the company was able to walk away with relatively little time and money invested. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhether a company starts with a proof-of-concept or a live deployment, I advise them to start small, test often and build on early successes. I’ve personally experienced working with a small set of instructions and information, only to find the results veering off course when I then feed the model more information. That’s why slow-and-steady is a prudent approach.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn summary, while LLMs will continue to provide ever-more-valuable capabilities, their limitations are becoming increasingly apparent as businesses scale their reliance on AI. Supplementing with SLMs offers a path forward, especially in high-stakes fields that demand accuracy and explainability. By investing in SLMs, companies can future-proof their AI strategies, ensuring that their tools not only drive innovation but also meet the demands of trust, reliability and control. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eAJ Sunder is co-founder, CIO and CPO at Responsive. \u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2024-12-21T20:25:00Z",
  "modifiedTime": "2024-12-21T20:30:08Z"
}
