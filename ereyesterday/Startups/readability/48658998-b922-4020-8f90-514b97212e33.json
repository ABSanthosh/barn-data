{
  "id": "48658998-b922-4020-8f90-514b97212e33",
  "title": "Why ‘prosocial AI’ must be the framework for designing, deploying and governing AI",
  "link": "https://venturebeat.com/ai/why-prosocial-ai-must-be-the-framework-for-designing-deploying-and-governing-ai/",
  "description": "Prosocial AI supports a hybrid future where human and machine intelligences co-evolve, guided by shared principles and grounded in truth.",
  "author": "Cornelia C. Walther, University of Pennsylvania",
  "published": "Sat, 25 Jan 2025 20:20:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "category-/People \u0026 Society",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "NLP"
  ],
  "byline": "Cornelia C. Walther, University of Pennsylvania",
  "length": 9857,
  "excerpt": "Prosocial AI supports a hybrid future where human and machine intelligences co-evolve, guided by shared principles and grounded in truth.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "January 25, 2025 12:20 PM VentureBeat/Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More As AI pervades every sphere of modern life, the central challenge facing business leaders, policymakers and innovators is no longer whether to adopt intelligent systems but how. In a world marked by escalating polarization, resource depletion, eroding trust in institutions and volatile information landscapes, the critical imperative is to engineer AI so that it contributes meaningfully and sustainably to human and planetary well-being. Prosocial AI — a framework of design, deployment and governance principles that ensure AI is thoughtfully tailored, trained, tested and targeted to uplift people and the planet — is more than a moral stance or PR veneer. It is a strategic approach to positioning AI within a broader ecology of intelligence that values collective flourishing over narrow optimization. The ABCD of AI’s potential: From gloom to glory  The rationale for prosocial AI emerges from four intertwined realms — agency, bonding, climate and division (ABCD). Each domain highlights the dual character of AI: It can either intensify existing dysfunctions or act as a catalyst for regenerative, inclusive solutions. Agency: Too often, AI-driven platforms rely on addictive loops and opaque recommender systems that erode user autonomy. Prosocial AI, by contrast, can activate agency by revealing the provenance of its suggestions, offering meaningful user controls and respecting the multifaceted nature of human decision-making. It is not merely about “consent” or “transparency” as abstract buzzwords; it is about designing AI interactions that acknowledge human complexity — the interplay of cognition, emotion, bodily experience and social context — and enabling individuals to navigate their digital environments without succumbing to manipulation or distraction. Bonding: Digital technologies can either fracture societies into echo chambers or serve as bridges that connect diverse people and ideas. Prosocial AI applies nuanced linguistic and cultural models to identify shared interests, highlight constructive contributions and foster empathy across boundaries. Instead of fueling outrage for attention, it helps participants discover complementary perspectives, strengthening communal bonds and reinforcing the delicate social fabrics that hold societies together. Climate: AI’s relationship with the environment is fraught with tension. AI can optimize supply chains, enhance climate modeling and support environmental stewardship. However, the computational intensity of training large models often entails a considerable carbon footprint. A prosocial lens demands designs that balance these gains against ecological costs — adopting energy-efficient architectures, transparent lifecycle assessments and ecologically sensitive data practices. Rather than treat the planet as an afterthought, prosocial AI anchors climate considerations as a cardinal priority: AI must not only advise on sustainability but must be sustainable. Division: The misinformation cascades and ideological rifts that define our era are not an inevitable byproduct of technology, but a result of design choices that privilege virality over veracity. Prosocial AI counters this by embedding cultural and historical literacy into its processes, respecting contextual differences and providing fact-checking mechanisms that enhance trust. Rather than homogenizing knowledge or imposing top-down narratives, it nurtures informed pluralism, making digital spaces more navigable, credible and inclusive. Double literacy: Integrating AI and NI  Realizing this vision depends on cultivating what we might call “double literacy.” On one side is AI literacy: mastering the technical intricacies of algorithms, understanding how biases emerge from data and establishing rigorous accountability and oversight mechanisms. On the other side is natural intelligence (NI) literacy: A comprehensive, embodied understanding of human cognition and emotion (brain and body), personal identity (self) and cultural embeddedness (society). This NI literacy is not a soft skill set perched on the margins of innovation; it is fundamental. Human intelligence is shaped by neurobiology, physiology, interoception, cultural narratives and community ethics — an intricate tapestry that transcends reductive notions of “rational actors.” By bringing NI literacy into dialogue with AI literacy, developers, decision-makers and regulators can ensure that digital architectures honor our multidimensional human reality. This holistic approach fosters systems that are ethically sound, context-sensitive and capable of complementing rather than constraining human capacities. AI and NI in synergy: Prosocial AI goes beyond zero-sum thinking The popular imagination often pits machines against humans in a zero-sum contest. Prosocial AI challenges this dichotomy. Consider the beauty of complementarity in healthcare: AI excels at pattern recognition, sifting through vast troves of medical images to detect anomalies that might elude human specialists. Physicians, in turn, draw on their embodied cognition and moral instincts to interpret results, communicate complex information and consider each patient’s broader life context. The outcome is not simply more efficient diagnostics; it is more humane, patient-centered care. Similar paradigms can transform law, finance, governance and education decision-making. By integrating the precision of AI with the nuanced judgment of human experts, we might transition from hierarchical command-and-control models to collaborative intelligence ecosystems. Here, machines handle complexity at scale and humans provide the moral vision and cultural fluency necessary to ensure that these systems serve authentic public interests. To embed prosocial AI at the core of our future, we need a concerted effort across all sectors: Industry and tech companies: Innovators can prioritize “human-in-the-loop” designs and explicitly reward metrics tied to well-being rather than engagement at any cost. Instead of designing AI to hook users, they can build systems that inform, empower and uplift — measured by improvements in health outcomes, educational attainment, environmental sustainability or social cohesion. Example: The Partnership on AI provides frameworks for prosocial innovation, helping guide developers toward responsible practices. Civil society and NGOs: Community groups and advocacy organizations can guide the development and deployment of AI, testing new tools in real-world contexts. They can bring ethnically, linguistically and culturally diverse perspectives to the design table, ensuring that the resulting AI systems serve a broad range of human experiences and needs. Educational Institutions: Schools and universities should integrate double literacy into their curricula while reinforcing critical thinking, ethics and cultural studies. By nurturing AI and NI literacy, educational bodies can help ensure that future generations are skilled in machine learning (ML) and deeply grounded in human values. Example: The MIT Schwarzman College of Computing and Stanford’s Institute for Human-Centered AI exemplify transdisciplinary approaches that unite technical rigor with human inquiry. Governments and policymakers: Legislation and regulatory frameworks can incentivize prosocial innovation, making it economically viable for companies to produce AI systems that are transparent, accountable and aligned with social goals. Citizen assemblies and public consultations can inform these policies, ensuring that the direction of AI reflects society’s diverse voices. Beyond boxes to a holistic hybrid future As AI integrates deeply into the global socio-economic fabric, we must resist the impulse to treat technology as a black box optimized for specific metrics. Instead, we can envision a hybrid future where human and machine intelligences co-evolve, guided by shared principles and grounded in a holistic understanding of ourselves and our environments. Prosocial AI moves beyond a simplistic choice between innovation and responsibility. It offers a richer tapestry of possibilities, where AI empowers rather than addicts, connects rather than fragments and regenerates rather than depletes. The future of AI will not be determined solely by computational prowess or algorithmic cunning. How we organically weave these capabilities into the human sphere will define it, acknowledging the interplay of brain and body, self and society, local nuance and planetary imperatives. In doing so, we create a more expansive standard of success: One measured not only by profit or efficiency but by the flourishing of people and the planet’s resilience. Prosocial AI can serve along that path. The future starts now, with a new ABCD: Aspire to an inclusive society; Believe that you are part in making it happen; Choose which side of history you want to be on; and Do what you feel is right.  Following two decades with UNICEF and the publication of various books, Dr. Cornelia C. Walther is presently a senior fellow at the University of Pennsylvania working on ProSocial AI.  DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2025/01/nuneybits_Vector_art_of_Earth_made_of_computer_code_8d11064c-da9a-4f2d-b13f-e25b7c1a8762-transformed.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-01-25T20:20:00+00:00\" datetime=\"2025-01-25T20:20:00+00:00\"\u003eJanuary 25, 2025 12:20 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/nuneybits_Vector_art_of_Earth_made_of_computer_code_8d11064c-da9a-4f2d-b13f-e25b7c1a8762-transformed.webp?w=750\" alt=\"VentureBeat/Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eAs AI pervades every \u003ca href=\"https://venturebeat.com/ai/ai-comes-alive-from-bartenders-to-surgical-aides-to-puppies-tomorrows-robots-are-on-their-way/\"\u003esphere of modern life\u003c/a\u003e, the central challenge facing business leaders, policymakers and innovators is no longer whether to adopt intelligent systems but how. In a world marked by escalating polarization, resource depletion, eroding trust in institutions and volatile information landscapes, the critical imperative is to engineer AI so that it contributes meaningfully and sustainably to human and planetary well-being. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://link.springer.com/book/10.1007/978-3-031-67823-3\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eProsocial AI\u003c/a\u003e — a framework of design, deployment and governance principles that ensure AI is thoughtfully tailored, trained, tested and targeted to uplift people and the planet — is more than a moral stance or PR veneer. It is a strategic approach to positioning AI within a broader ecology of intelligence that values collective flourishing over narrow optimization.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-abcd-of-ai-s-potential-from-gloom-to-glory\"\u003eThe ABCD of AI’s potential: From gloom to glory \u003c/h2\u003e\n\n\n\n\u003cp\u003eThe rationale for \u003ca href=\"https://venturebeat.com/ai/anthropomorphizing-ai-dire-consequences-of-mistaking-human-like-for-human-have-already-emerged/\"\u003eprosocial AI\u003c/a\u003e emerges from four intertwined realms — agency, bonding, climate and division (ABCD). Each domain highlights the dual character of AI: It can either intensify existing dysfunctions or act as a catalyst for regenerative, inclusive solutions.\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAgency:\u003c/strong\u003e Too often, AI-driven platforms rely on addictive loops and opaque recommender systems that erode user autonomy. Prosocial AI, by contrast, can activate agency by revealing the provenance of its suggestions, offering meaningful user controls and respecting the multifaceted nature of human decision-making. It is not merely about “consent” or “transparency” as abstract buzzwords; it is about designing AI interactions that acknowledge human complexity — the interplay of cognition, emotion, bodily experience and social context — and enabling individuals to navigate their digital environments without succumbing to manipulation or distraction.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eBonding:\u003c/strong\u003e Digital technologies can either fracture societies into echo chambers or serve as bridges that connect diverse people and ideas. Prosocial AI applies nuanced linguistic and cultural models to identify shared interests, highlight constructive contributions and foster empathy across boundaries. Instead of fueling outrage for attention, it helps participants discover complementary perspectives, strengthening communal bonds and reinforcing the delicate social fabrics that hold societies together.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eClimate:\u003c/strong\u003e AI’s relationship with the environment is fraught with tension. AI can optimize supply chains, enhance climate modeling and support environmental stewardship. However, the computational intensity of training large models often entails a considerable carbon footprint. A prosocial lens demands designs that balance these gains against ecological costs — adopting energy-efficient architectures, transparent lifecycle assessments and ecologically sensitive data practices. Rather than treat the planet as an afterthought, prosocial AI anchors climate considerations as a cardinal priority: AI must not only advise on sustainability but must be sustainable.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eDivision:\u003c/strong\u003e The misinformation cascades and ideological rifts that define our era are not an inevitable byproduct of technology, but a result of design choices that privilege virality over veracity. Prosocial AI counters this by embedding cultural and historical literacy into its processes, respecting contextual differences and providing fact-checking mechanisms that enhance trust. Rather than homogenizing knowledge or imposing top-down narratives, it nurtures informed pluralism, making digital spaces more navigable, credible and inclusive.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2 id=\"h-double-literacy-integrating-ai-and-ni\"\u003eDouble literacy: Integrating AI and NI \u003c/h2\u003e\n\n\n\n\u003cp\u003eRealizing this vision depends on cultivating what we might call “double literacy.” On one side is AI literacy: mastering the technical intricacies of algorithms, understanding how biases emerge from data and establishing rigorous accountability and oversight mechanisms. On the other side is natural intelligence (NI) literacy: A comprehensive, embodied understanding of human cognition and emotion (brain and body), personal identity (self) and cultural embeddedness (society).\u003c/p\u003e\n\n\n\n\u003cp\u003eThis NI literacy is not a soft skill set perched on the margins of innovation; it is fundamental. \u003ca href=\"https://venturebeat.com/ai/listen-to-your-technology-users-they-have-led-to-the-most-disruptive-innovations-in-history/\"\u003eHuman intelligence\u003c/a\u003e is shaped by neurobiology, physiology, interoception, cultural narratives and community ethics — an intricate tapestry that transcends reductive notions of “rational actors.” By bringing NI literacy into dialogue with AI literacy, developers, decision-makers and regulators can ensure that digital architectures honor our multidimensional human reality. This holistic approach fosters systems that are ethically sound, context-sensitive and capable of complementing rather than constraining human capacities.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-ai-and-ni-in-synergy-prosocial-ai-goes-beyond-zero-sum-thinking\"\u003eAI and NI in synergy: Prosocial AI goes beyond zero-sum thinking\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe popular imagination often \u003ca href=\"https://venturebeat.com/ai/why-context-aware-ai-agents-will-give-us-superpowers-in-2025/\"\u003epits machines against humans\u003c/a\u003e in a zero-sum contest. Prosocial AI challenges this dichotomy. Consider the beauty of complementarity in healthcare: AI excels at pattern recognition, sifting through vast troves of medical images to detect anomalies that might elude human specialists. Physicians, in turn, draw on their embodied cognition and moral instincts to interpret results, communicate complex information and consider each patient’s broader life context. The outcome is not simply more efficient diagnostics; it is more humane, patient-centered care. Similar paradigms can transform law, finance, governance and education decision-making.\u003c/p\u003e\n\n\n\n\u003cp\u003eBy integrating the precision of AI with the nuanced judgment of human experts, we might transition from hierarchical command-and-control models to collaborative intelligence ecosystems. Here, machines handle complexity at scale and humans provide the moral vision and cultural fluency necessary to ensure that these systems serve authentic public interests.\u003c/p\u003e\n\n\n\n\n\n\n\n\u003cp\u003eTo embed prosocial AI at the core of our future, we need a concerted effort across all sectors:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eIndustry and tech companies:\u003c/strong\u003e Innovators can prioritize “human-in-the-loop” designs and explicitly reward metrics tied to well-being rather than engagement at any cost. Instead of designing AI to hook users, they can build systems that inform, empower and uplift — measured by improvements in health outcomes, educational attainment, environmental sustainability or social cohesion.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eExample:\u003c/em\u003e The \u003ca href=\"https://www.partnershiponai.org/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ePartnership on AI\u003c/a\u003e provides frameworks for prosocial innovation, helping guide developers toward responsible practices.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eCivil society and NGOs:\u003c/strong\u003e Community groups and advocacy organizations can guide the development and deployment of AI, testing new tools in real-world contexts. They can bring ethnically, linguistically and culturally diverse perspectives to the design table, ensuring that the resulting AI systems serve a broad range of human experiences and needs.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eEducational Institutions:\u003c/strong\u003e Schools and universities should integrate double literacy into their curricula while reinforcing critical thinking, ethics and cultural studies. By nurturing AI and NI literacy, educational bodies can help ensure that future generations are skilled in machine learning (ML) and deeply grounded in human values.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eExample:\u003c/em\u003e The \u003ca href=\"https://computing.mit.edu/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMIT Schwarzman College\u003c/a\u003e of Computing and Stanford’s Institute for \u003ca href=\"https://hai.stanford.edu/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHuman-Centered AI\u003c/a\u003e exemplify transdisciplinary approaches that unite technical rigor with human inquiry.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eGovernments and policymakers:\u003c/strong\u003e Legislation and regulatory frameworks can incentivize prosocial innovation, making it economically viable for companies to produce AI systems that are transparent, accountable and aligned with social goals. Citizen assemblies and public consultations can inform these policies, ensuring that the direction of AI reflects society’s diverse voices.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-beyond-boxes-to-a-holistic-hybrid-future\"\u003eBeyond boxes to a holistic hybrid future\u003c/h2\u003e\n\n\n\n\u003cp\u003eAs AI integrates deeply into the global socio-economic fabric, we must resist the impulse to treat technology as a black box optimized for specific metrics. Instead, we can envision a hybrid future where human and machine intelligences co-evolve, guided by shared principles and grounded in a holistic understanding of ourselves and our environments. Prosocial AI moves beyond a simplistic choice between innovation and responsibility. It offers a richer tapestry of possibilities, where AI empowers rather than addicts, connects rather than fragments and regenerates rather than depletes.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe future of AI will not be determined solely by computational prowess or algorithmic cunning. How we organically weave these capabilities into the human sphere will define it, acknowledging the interplay of brain and body, self and society, local nuance and planetary imperatives. In doing so, we create a more expansive standard of success: One measured not only by profit or efficiency but by the flourishing of people and the planet’s resilience. \u003c/p\u003e\n\n\n\n\u003cp\u003eProsocial AI can serve along that path. The future starts now, with a new ABCD: \u003cstrong\u003eA\u003c/strong\u003espire to an inclusive society; \u003cstrong\u003eB\u003c/strong\u003eelieve that you are part in making it happen; \u003cstrong\u003eC\u003c/strong\u003ehoose which side of history you want to be on; and \u003cstrong\u003eD\u003c/strong\u003eo what you feel is right. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eFollowing two decades with UNICEF and the publication of various \u003c/em\u003e\u003ca href=\"https://link.springer.com/search?query=cornelia+walther\u0026amp;facet-content-type=Book\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003ebooks\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, Dr. Cornelia C. Walther\u003c/em\u003e is \u003cem\u003epresently a senior fellow at the University of Pennsylvania working on ProSocial AI. \u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-01-25T20:20:00Z",
  "modifiedTime": "2025-01-25T20:21:09Z"
}
