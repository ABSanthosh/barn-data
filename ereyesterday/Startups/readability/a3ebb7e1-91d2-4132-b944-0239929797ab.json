{
  "id": "a3ebb7e1-91d2-4132-b944-0239929797ab",
  "title": "Omni SenseVoice: High-Speed Speech Recognition with Words Timestamps",
  "link": "https://github.com/lifeiteng/OmniSenseVoice",
  "description": "Article URL: https://github.com/lifeiteng/OmniSenseVoice Comments URL: https://news.ycombinator.com/item?id=41824171 Points: 5 # Comments: 0",
  "author": "ringer007",
  "published": "Sun, 13 Oct 2024 00:48:25 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "lifeiteng",
  "length": 2034,
  "excerpt": "Omni SenseVoice: High-Speed Speech Recognition with words timestamps üó£Ô∏èüéØ - lifeiteng/OmniSenseVoice",
  "siteName": "GitHub",
  "favicon": "https://github.com/fluidicon.png",
  "text": "Omni SenseVoice üöÄ The Ultimate Speech Recognition Solution Built on SenseVoice, Omni SenseVoice is optimized for lightning-fast inference and precise timestamps‚Äîgiving you a smarter, faster way to handle audio transcription! Install Usage omnisense transcribe [OPTIONS] AUDIO_PATH Key Options: --language: Automatically detect the language or specify (auto, zh, en, yue, ja, ko). --textnorm: Choose whether to apply inverse text normalization (withitn for inverse normalized or woitn for raw). --device-id: Run on a specific GPU (default: -1 for CPU). --quantize: Use a quantized model for faster processing. --help: Display detailed help information. Benchmark omnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl Optimize GPU WER ‚¨áÔ∏è RTF ‚¨áÔ∏è Speed Up üî• baseline(onnx) NVIDIA L4 GPU 4.47% 0.1200 1x torch NVIDIA L4 GPU 5.02% 0.0022 50x With Omni SenseVoice, experience up to 50x faster processing without sacrificing accuracy. # LibriTTS DIR=benchmark/data lhotse download libritts -p dev-clean benchmark/dataLibriTTS lhotse prepare libritts -p dev-clean benchmark/data/LibriTTS/LibriTTS benchmark/data/manifests/libritts lhotse cut simple --force-eager -r benchmark/data/manifests/libritts/libritts_recordings_dev-clean.jsonl.gz \\ -s benchmark/data/manifests/libritts/libritts_supervisions_dev-clean.jsonl.gz \\ benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl omnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 - -textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl omnisense benchmark -s --num-workers 4 --device-id 0 --batch-size 16 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl Contributing üôå Step 1: Code Formatting Set up pre-commit hooks: pip install pre-commit==3.6.0 pre-commit install Step 2: Pull Request Submit your awesome improvements through a PR. üòä",
  "image": "https://opengraph.githubassets.com/8d129c13ec7c4c039484f2e21b8604da0b80dd0c8e4abecca70e174cf3269971/lifeiteng/OmniSenseVoice",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-hpc=\"true\"\u003e\u003carticle itemprop=\"text\"\u003e\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eOmni SenseVoice üöÄ\u003c/h2\u003e\u003ca id=\"user-content-omni-sensevoice-\" aria-label=\"Permalink: Omni SenseVoice üöÄ\" href=\"#omni-sensevoice-\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eThe Ultimate Speech Recognition Solution\u003c/h2\u003e\u003ca id=\"user-content-the-ultimate-speech-recognition-solution\" aria-label=\"Permalink: The Ultimate Speech Recognition Solution\" href=\"#the-ultimate-speech-recognition-solution\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eBuilt on \u003ca href=\"https://github.com/FunAudioLLM/SenseVoice\"\u003eSenseVoice\u003c/a\u003e, Omni SenseVoice is optimized for lightning-fast inference and precise timestamps‚Äîgiving you a smarter, faster way to handle audio transcription!\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eInstall\u003c/h2\u003e\u003ca id=\"user-content-install\" aria-label=\"Permalink: Install\" href=\"#install\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv data-snippet-clipboard-copy-content=\"omnisense transcribe [OPTIONS] AUDIO_PATH\"\u003e\u003cpre\u003e\u003ccode\u003eomnisense transcribe [OPTIONS] AUDIO_PATH\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eKey Options:\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ccode\u003e--language\u003c/code\u003e: Automatically detect the language or specify (\u003ccode\u003eauto, zh, en, yue, ja, ko\u003c/code\u003e).\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--textnorm\u003c/code\u003e: Choose whether to apply inverse text normalization (\u003ccode\u003ewithitn for inverse normalized\u003c/code\u003e or \u003ccode\u003ewoitn for raw\u003c/code\u003e).\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--device-id\u003c/code\u003e: Run on a specific GPU (default: -1 for CPU).\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--quantize\u003c/code\u003e: Use a quantized model for faster processing.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e--help\u003c/code\u003e: Display detailed help information.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eBenchmark\u003c/h2\u003e\u003ca id=\"user-content-benchmark\" aria-label=\"Permalink: Benchmark\" href=\"#benchmark\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ccode\u003eomnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\u003c/code\u003e\u003c/p\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eOptimize\u003c/th\u003e\n\u003cth\u003eGPU\u003c/th\u003e\n\u003cth\u003eWER ‚¨áÔ∏è\u003c/th\u003e\n\u003cth\u003eRTF ‚¨áÔ∏è\u003c/th\u003e\n\u003cth\u003eSpeed Up üî•\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ebaseline(onnx)\u003c/td\u003e\n\u003ctd\u003eNVIDIA L4 GPU\u003c/td\u003e\n\u003ctd\u003e4.47%\u003c/td\u003e\n\u003ctd\u003e0.1200\u003c/td\u003e\n\u003ctd\u003e1x\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003etorch\u003c/td\u003e\n\u003ctd\u003eNVIDIA L4 GPU\u003c/td\u003e\n\u003ctd\u003e5.02%\u003c/td\u003e\n\u003ctd\u003e0.0022\u003c/td\u003e\n\u003ctd\u003e50x\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eWith Omni SenseVoice, experience up to 50x faster processing without sacrificing accuracy.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv data-snippet-clipboard-copy-content=\"# LibriTTS\nDIR=benchmark/data\nlhotse download libritts -p dev-clean benchmark/dataLibriTTS\nlhotse prepare libritts -p dev-clean benchmark/data/LibriTTS/LibriTTS benchmark/data/manifests/libritts\n\nlhotse cut simple --force-eager -r benchmark/data/manifests/libritts/libritts_recordings_dev-clean.jsonl.gz \\\n    -s benchmark/data/manifests/libritts/libritts_supervisions_dev-clean.jsonl.gz \\\n    benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\n\nomnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 -\n-textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\n\nomnisense benchmark -s --num-workers 4 --device-id 0 --batch-size 16 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\"\u003e\u003cpre\u003e\u003ccode\u003e# LibriTTS\nDIR=benchmark/data\nlhotse download libritts -p dev-clean benchmark/dataLibriTTS\nlhotse prepare libritts -p dev-clean benchmark/data/LibriTTS/LibriTTS benchmark/data/manifests/libritts\n\nlhotse cut simple --force-eager -r benchmark/data/manifests/libritts/libritts_recordings_dev-clean.jsonl.gz \\\n    -s benchmark/data/manifests/libritts/libritts_supervisions_dev-clean.jsonl.gz \\\n    benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\n\nomnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 -\n-textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\n\nomnisense benchmark -s --num-workers 4 --device-id 0 --batch-size 16 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" dir=\"auto\"\u003eContributing üôå\u003c/h2\u003e\u003ca id=\"user-content-contributing-\" aria-label=\"Permalink: Contributing üôå\" href=\"#contributing-\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" dir=\"auto\"\u003eStep 1: Code Formatting\u003c/h4\u003e\u003ca id=\"user-content-step-1-code-formatting\" aria-label=\"Permalink: Step 1: Code Formatting\" href=\"#step-1-code-formatting\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eSet up pre-commit hooks:\u003c/p\u003e\n\u003cdiv data-snippet-clipboard-copy-content=\"pip install pre-commit==3.6.0\npre-commit install\"\u003e\u003cpre\u003e\u003ccode\u003epip install pre-commit==3.6.0\npre-commit install\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" dir=\"auto\"\u003eStep 2: Pull Request\u003c/h4\u003e\u003ca id=\"user-content-step-2-pull-request\" aria-label=\"Permalink: Step 2: Pull Request\" href=\"#step-2-pull-request\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eSubmit your awesome improvements through a PR. üòä\u003c/p\u003e\n\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
