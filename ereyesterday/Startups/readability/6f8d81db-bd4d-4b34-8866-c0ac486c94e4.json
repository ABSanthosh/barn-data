{
  "id": "6f8d81db-bd4d-4b34-8866-c0ac486c94e4",
  "title": "SambaNova and Gradio are making high-speed AI accessible to everyone—here’s how it works",
  "link": "https://venturebeat.com/ai/sambanova-and-gradio-are-making-high-speed-ai-accessible-to-everyone-heres-how-it-works/",
  "description": "SambaNova and Gradio partner to simplify AI development, offering faster inference and improved energy efficiency, challenging Nvidia's dominance in the evolving AI chip market.",
  "author": "Michael Nuñez",
  "published": "Thu, 17 Oct 2024 23:00:50 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Automation",
    "Business",
    "Data Infrastructure",
    "Programming \u0026 Development",
    "AI Accessibility",
    "AI chips",
    "AI development",
    "AI inference platform",
    "AI infrastructure",
    "AI, ML and Deep Learning",
    "category-/Computers \u0026 Electronics",
    "Data Management",
    "Data Science",
    "Data Storage and Cloud",
    "Energy-efficient AI",
    "Gradio",
    "high-performance computing",
    "large language models",
    "machine learning",
    "NLP",
    "SambaNova Systems",
    "tech startups"
  ],
  "byline": "Michael Nuñez",
  "length": 5061,
  "excerpt": "SambaNova and Gradio partner to simplify AI development, offering faster inference and improved energy efficiency, challenging Nvidia's dominance in the evolving AI chip market.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "October 17, 2024 4:00 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More SambaNova Systems and Gradio have unveiled a new integration that allows developers to access one of the fastest AI inference platforms with just a few lines of code. This partnership aims to make high-performance AI models more accessible and speed up the adoption of artificial intelligence among developers and businesses. “This integration makes it easy for developers to copy code from the SambaNova playground and get a Gradio web app running in minutes with just a few lines of code,” Ahsen Khaliq, ML Growth Lead at Gradio, said in an interview with VentureBeat. “Powered by SambaNova Cloud for super-fast inference, this means a great user experience for developers and end-users alike.” The SambaNova-Gradio integration enables users to create web applications powered by SambaNova’s high-speed AI models using Gradio’s gr.load() function. Developers can now quickly generate a chat interface connected to SambaNova’s models, making it easier to work with advanced AI systems. A snippet of Python code demonstrates the simplicity of integrating SambaNova’s AI models with Gradio’s user interface. Just a few lines are needed to launch a powerful language model, underscoring the partnership’s goal of making advanced AI more accessible to developers. (Credit: SambaNova Systems) Beyond GPUs: The rise of dataflow architecture in AI processing SambaNova, a Silicon Valley startup backed by SoftBank and BlackRock, has been making waves in the AI hardware space with its dataflow architecture chips. These chips are designed to outperform traditional GPUs for AI workloads, with the company claiming to offer the “world’s fastest AI inference service.” SambaNova’s platform can run Meta’s Llama 3.1 405B model at 132 tokens per second at full precision, a speed that is particularly crucial for enterprises looking to deploy AI at scale. This development comes as the AI infrastructure market heats up, with startups like SambaNova, Groq, and Cerebras challenging Nvidia’s dominance in AI chips. These new entrants are focusing on inference — the production stage of AI where models generate outputs based on their training — which is expected to become a larger market than model training. SambaNova’s AI chips show 3-5 times better energy efficiency than Nvidia’s H100 GPU when running large language models, according to the company’s data. (Credit: SambaNova Systems) From code to cloud: The simplification of AI application development For developers, the SambaNova-Gradio integration offers a frictionless entry point to experiment with high-performance AI. Users can access SambaNova’s free tier to wrap any supported model into a web app and host it themselves within minutes. This ease of use mirrors recent industry trends aimed at simplifying AI application development. The integration currently supports Meta’s Llama 3.1 family of models, including the massive 405B parameter version. SambaNova claims to be the only provider running this model at full 16-bit precision at high speeds, a level of fidelity that could be particularly attractive for applications requiring high accuracy, such as in healthcare or financial services. While the integration makes high-performance AI more accessible, questions remain about the long-term effects of the ongoing AI chip competition. As companies race to offer faster processing speeds, concerns about energy use, scalability, and environmental impact grow. The focus on raw performance metrics like tokens per second, while important, may overshadow other crucial factors in AI deployment. As enterprises integrate AI into their operations, they will need to balance speed with sustainability, considering the total cost of ownership, including energy consumption and cooling requirements. Additionally, the software ecosystem supporting these new AI chips will significantly influence their adoption. Although SambaNova and others offer powerful hardware, Nvidia’s CUDA ecosystem maintains an edge with its wide range of optimized libraries and tools that many AI developers already know well. As the AI infrastructure market continues to evolve, collaborations like the SambaNova-Gradio integration may become increasingly common. These partnerships have the potential to foster innovation and competition in a field that promises to transform industries across the board. However, the true test will be in how these technologies translate into real-world applications and whether they can deliver on the promise of more accessible, efficient, and powerful AI for all. VB Daily Stay in the know! Get the latest news in your inbox daily By subscribing, you agree to VentureBeat's Terms of Service. Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_a_high-resolution_photorealistic_close-_d44089e3-6c9e-4c2a-a121-1c702d77a361.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-10-17T23:00:50+00:00\" datetime=\"2024-10-17T23:00:50+00:00\"\u003eOctober 17, 2024 4:00 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_a_high-resolution_photorealistic_close-_d44089e3-6c9e-4c2a-a121-1c702d77a361.webp?w=750\" alt=\"Credit: VentureBeat made with Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://sambanova.ai/\"\u003eSambaNova Systems\u003c/a\u003e and \u003ca href=\"https://gradio.com/\"\u003eGradio\u003c/a\u003e have unveiled a \u003ca href=\"https://github.com/gradio-app/sambanova-gradio\"\u003enew integration\u003c/a\u003e that allows developers to access one of the fastest AI inference platforms with just a few lines of code. This partnership aims to make high-performance AI models more accessible and speed up the adoption of artificial intelligence among developers and businesses.\u003c/p\u003e\n\n\n\n\u003cp\u003e“This integration makes it easy for developers to copy code from the \u003ca href=\"https://docs.sambanova.ai/sambastudio/latest/generative-playground.html\"\u003eSambaNova playground\u003c/a\u003e and get a \u003ca href=\"https://www.gradio.app/\"\u003eGradio web app\u003c/a\u003e running in minutes with just a few lines of code,” Ahsen Khaliq, ML Growth Lead at Gradio, said in an interview with VentureBeat. “Powered by SambaNova Cloud for super-fast inference, this means a great user experience for developers and end-users alike.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThe SambaNova-Gradio integration enables users to create web applications powered by SambaNova’s high-speed AI models using Gradio’s \u003ccode\u003egr.load()\u003c/code\u003e function. Developers can now quickly generate a chat interface connected to SambaNova’s models, making it easier to work with advanced AI systems.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1730\" height=\"1686\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?w=616\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg 1730w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=300,292 300w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=768,748 768w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=616,600 616w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=1536,1497 1536w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=52,52 52w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=400,390 400w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=750,731 750w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=578,563 578w, https://venturebeat.com/wp-content/uploads/2024/10/GaGflDPWMAAugtu.jpg?resize=930,906 930w\" sizes=\"(max-width: 1730px) 100vw, 1730px\"/\u003e\u003cfigcaption\u003eA snippet of Python code demonstrates the simplicity of integrating SambaNova’s AI models with Gradio’s user interface. Just a few lines are needed to launch a powerful language model, underscoring the partnership’s goal of making advanced AI more accessible to developers. (Credit: SambaNova Systems)\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-beyond-gpus-the-rise-of-dataflow-architecture-in-ai-processing\"\u003eBeyond GPUs: The rise of dataflow architecture in AI processing\u003c/h2\u003e\n\n\n\n\u003cp\u003eSambaNova, a Silicon Valley startup backed by \u003ca href=\"https://www.thesoftwarereport.com/enterprise-scale-ai-sambanova-systems-rodrigo-liang/\"\u003eSoftBank\u003c/a\u003e and \u003ca href=\"https://www.reuters.com/article/technology/ai-computing-startup-sambanova-raises-250-million-in-blackrock-led-funding-idUSKCN20K041/\"\u003eBlackRock\u003c/a\u003e, has been making waves in the AI hardware space with its dataflow architecture chips. These chips are designed to outperform traditional GPUs for AI workloads, with the company claiming to offer the “world’s fastest AI inference service.” \u003c/p\u003e\n\n\n\n\u003cp\u003eSambaNova’s platform can run Meta’s \u003ca href=\"https://huggingface.co/meta-llama/Llama-3.1-405B\"\u003eLlama 3.1 405B model\u003c/a\u003e at 132 tokens per second at full precision, a speed that is particularly crucial for enterprises looking to deploy AI at scale.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis development comes as the AI infrastructure market heats up, with startups like \u003ca href=\"https://sambanova.ai/\"\u003eSambaNova\u003c/a\u003e, \u003ca href=\"https://groq.com/\"\u003eGroq\u003c/a\u003e, and \u003ca href=\"https://cerebras.ai/\"\u003eCerebras\u003c/a\u003e challenging \u003ca href=\"https://www.cnbc.com/2024/06/02/nvidia-dominates-the-ai-chip-market-but-theres-rising-competition-.html\"\u003eNvidia’s dominance\u003c/a\u003e in AI chips. These new entrants are focusing on inference — the production stage of AI where models generate outputs based on their training — which is expected to become a larger market than model training.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1496\" height=\"808\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg 1496w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=300,162 300w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=768,415 768w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=800,432 800w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=400,216 400w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=750,405 750w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=578,312 578w, https://venturebeat.com/wp-content/uploads/2024/10/Bbe3os6l.jpg?resize=930,502 930w\" sizes=\"(max-width: 1496px) 100vw, 1496px\"/\u003e\u003cfigcaption\u003eSambaNova’s AI chips show 3-5 times better energy efficiency than Nvidia’s H100 GPU when running large language models, according to the company’s data. (Credit: SambaNova Systems)\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-from-code-to-cloud-the-simplification-of-ai-application-development\"\u003eFrom code to cloud: The simplification of AI application development\u003c/h2\u003e\n\n\n\n\u003cp\u003eFor developers, the SambaNova-Gradio integration offers a frictionless entry point to experiment with high-performance AI. Users can access SambaNova’s free tier to wrap any supported model into a web app and host it themselves within minutes. This ease of use mirrors recent industry trends aimed at simplifying AI application development.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe integration currently supports Meta’s \u003ca href=\"https://ai.meta.com/blog/meta-llama-3-1/\"\u003eLlama 3.1 family of models\u003c/a\u003e, including the massive 405B parameter version. SambaNova claims to be the only provider running this model at full 16-bit precision at high speeds, a level of fidelity that could be particularly attractive for applications requiring high accuracy, such as in healthcare or financial services.\u003c/p\u003e\n\n\n\n\n\n\n\n\u003cp\u003eWhile the integration makes high-performance AI more accessible, questions remain about the long-term effects of the ongoing AI chip competition. As companies race to offer faster processing speeds, concerns about energy use, scalability, and environmental impact grow.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe focus on raw performance metrics like tokens per second, while important, may overshadow other crucial factors in AI deployment. As enterprises integrate AI into their operations, they will need to balance speed with sustainability, considering the total cost of ownership, including energy consumption and cooling requirements.\u003c/p\u003e\n\n\n\n\u003cp\u003eAdditionally, the software ecosystem supporting these new AI chips will significantly influence their adoption. Although SambaNova and others offer powerful hardware, \u003ca href=\"https://developer.nvidia.com/cuda-toolkit\"\u003eNvidia’s CUDA ecosystem\u003c/a\u003e maintains an edge with its wide range of optimized libraries and tools that many AI developers already know well.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs the AI infrastructure market continues to evolve, collaborations like the SambaNova-Gradio integration may become increasingly common. These partnerships have the potential to foster innovation and competition in a field that promises to transform industries across the board. However, the true test will be in how these technologies translate into real-world applications and whether they can deliver on the promise of more accessible, efficient, and powerful AI for all.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eVB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eStay in the know! Get the latest news in your inbox daily\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eBy subscribing, you agree to VentureBeat\u0026#39;s \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003eTerms of Service.\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-10-17T23:00:50Z",
  "modifiedTime": "2024-10-17T23:07:04Z"
}
