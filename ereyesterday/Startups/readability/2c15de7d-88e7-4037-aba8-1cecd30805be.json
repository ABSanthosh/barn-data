{
  "id": "2c15de7d-88e7-4037-aba8-1cecd30805be",
  "title": "Accountability Sinks",
  "link": "https://aworkinglibrary.com/writing/accountability-sinks",
  "description": "Article URL: https://aworkinglibrary.com/writing/accountability-sinks Comments URL: https://news.ycombinator.com/item?id=41891694 Points: 8 # Comments: 1",
  "author": "l0b0",
  "published": "Sat, 19 Oct 2024 23:39:43 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "Mandy Brown",
  "length": 4474,
  "excerpt": "In The Unaccountability Machine, Dan Davies argues that organizations form “accountability sinks,” structures that absorb or obscure the consequences of a decision such that no one can be held dire...",
  "siteName": "A Working Library",
  "favicon": "",
  "text": "2024-10-16 A Reading Note In The Unaccountability Machine, Dan Davies argues that organizations form “accountability sinks,” structures that absorb or obscure the consequences of a decision such that no one can be held directly accountable for it. Here’s an example: a higher up at a hospitality company decides to reduce the size of its cleaning staff, because it improves the numbers on a balance sheet somewhere. Later, you are trying to check into a room, but it’s not ready and the clerk can’t tell you when it will be; they can offer a voucher, but what you need is a room. There’s no one to call to complain, no way to communicate back to that distant leader that they’ve scotched your plans. The accountability is swallowed up into a void, lost forever. Davies proposes that: For an accountability sink to function, it has to break a link; it has to prevent the feedback of the person affected by the decision from affecting the operation of the system. Davies, The Unaccountability Machine, page 17 Once you start looking for accountability sinks, you see them all over the place. When your health insurance declines a procedure; when the airline cancels your flight; when a government agency declares that you are ineligible for a benefit; when an investor tells all their companies to shovel so-called AI into their apps. Everywhere, broken links between the people who face the consequences of the decision and the people making the decisions. That’s assuming, of course, that a person did make a decision at all. Another mechanism of accountability sinks is the way in which decisions themselves cascade and lose any sense of their origins. Davies gives the example of the case of Dominion Systems vs Fox News, in which Fox News repeatedly spread false stories about the election. No one at Fox seems to have explicitly made a decision to lie about voting machines; rather, there was an implicit understanding that they had to do whatever it took to keep their audience numbers up. At some point, someone had declared (or else strongly implied) that audience metrics were the only thing that mattered, and every subsequent decision followed out from that. But who can be accountable to a decision that wasn’t actually made? It’s worth pausing for a moment to consider what we mean by “accountable.” Davies posits that: The fundamental law of accountability: the extent to which you are able to change a decision is precisely the extent to which you can be accountable for it, and vice versa. Davies, The Unaccountability Machine, page 17 Which is useful. I often refer back to Sidney Dekker’s definition of accountability, where an account is something that you tell. How did something happen, what were the conditions that led to it happening, what made the decision seem like a good one at the time? Who were all of the people involved in the decision or event? (It almost never comes down to only one person.) All of those questions and more are necessary for understanding how a decision happened, which is a prerequisite for learning how to make better decisions going forward. If you combine those two frameworks, you could conclude that to be accountable for something you must have the power to change it and understand what you are trying to accomplish when you do. You need both the power and the story of how that power gets used. The comparisons to AI are obvious, inasmuch as delegating decisions to an algorithm is a convenient way to construct a sink. But organizations of any scale—whether corporations or governments or those that occupy the nebulous space between—are already quite good at forming such sinks. The accountability-washing that an AI provides isn’t a new service so much as an escalated and expanded one. Which doesn’t make it any less frightening, of course; but it does perhaps provide a useful clue. Any effort that’s tried and failed to hold a corporation to account isn’t likely to have more success against an algorithm. We need a new bag of tricks. Related books Dan Davies hypothesizes that organizations form “accountability sinks”—structures that serve to obscure, deflect, or otherwise insulate decision makers from the consequences of their decisions. Drawing from safety practices in transportation and medicine, Sidney Dekker outlines how to (and how not to) create a culture of trust, learning, and accountability.",
  "image": "/img/social.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv role=\"main\"\u003e\n      \u003carticle\u003e\n  \u003cheader\u003e\n    \u003ctime datetime=\"2024-10-16 13:57:00 -0400\"\u003e2024-10-16\u003c/time\u003e\n    \n    \u003ch2\u003eA Reading Note\u003c/h2\u003e\n  \u003c/header\u003e\n\n  \n\n  \u003csection\u003e\n    \u003cp\u003eIn \u003cem\u003eThe Unaccountability Machine,\u003c/em\u003e Dan Davies argues that organizations form “accountability sinks,” structures that absorb or obscure the consequences of a decision such that no one can be held directly accountable for it. Here’s an example: a higher up at a hospitality company decides to reduce the size of its cleaning staff, because it improves the numbers on a balance sheet somewhere. Later, you are trying to check into a room, but it’s not ready and the clerk can’t tell you when it will be; they can offer a voucher, but what you need is a room. There’s no one to call to complain, no way to communicate back to that distant leader that they’ve scotched your plans. The accountability is swallowed up into a void, lost forever.\u003c/p\u003e\n\n\u003cp\u003eDavies proposes that:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eFor an accountability sink to function, it has to break a link; it has to prevent the feedback of the person affected by the decision from affecting the operation of the system.\u003c/p\u003e\n  \u003ccite\u003e\u003ca href=\"https://aworkinglibrary.com/reading/unaccountability-machine\"\u003eDavies, \u003cem\u003eThe Unaccountability Machine\u003c/em\u003e, page 17\u003c/a\u003e\u003c/cite\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eOnce you start looking for accountability sinks, you see them all over the place. When your health insurance declines a procedure; when the airline cancels your flight; when a government agency declares that you are ineligible for a benefit; when an investor tells all their companies to shovel so-called AI into their apps. Everywhere, broken links between the people who face the consequences of the decision and the people making the decisions.\u003c/p\u003e\n\n\u003cp\u003eThat’s assuming, of course, that a person \u003cem\u003edid\u003c/em\u003e make a decision at all. Another mechanism of accountability sinks is the way in which decisions themselves cascade and lose any sense of their origins. Davies gives the example of the case of \u003ca href=\"https://en.wikipedia.org/wiki/Dominion_Voting_Systems_v._Fox_News_Network\"\u003eDominion Systems vs Fox News\u003c/a\u003e, in which Fox News repeatedly spread false stories about the election. No one at Fox seems to have explicitly made a decision to lie about voting machines; rather, there was an implicit understanding that they had to do whatever it took to keep their audience numbers up. At some point, someone had declared (or else strongly implied) that audience metrics were the only thing that mattered, and every subsequent decision followed out from that. But who can be accountable to a decision that wasn’t actually made?\u003c/p\u003e\n\n\u003cp\u003eIt’s worth pausing for a moment to consider what we mean by “accountable.” Davies posits that:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eThe fundamental law of accountability: the extent to which you are able to change a decision is precisely the extent to which you can be accountable for it, and vice versa.\u003c/p\u003e\n  \u003ccite\u003e\u003ca href=\"https://aworkinglibrary.com/reading/unaccountability-machine\"\u003eDavies, \u003cem\u003eThe Unaccountability Machine\u003c/em\u003e, page 17\u003c/a\u003e\u003c/cite\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhich is useful. I often refer back to \u003ca href=\"https://aworkinglibrary.com/writing/on-accountability\"\u003eSidney Dekker’s definition of accountability\u003c/a\u003e, where an account is \u003cem\u003esomething that you tell.\u003c/em\u003e How did something happen, what were the conditions that led to it happening, what made the decision seem like a good one at the time? Who were all of the people involved in the decision or event? (It almost never comes down to only one person.) All of those questions and more are necessary for understanding how a decision happened, which is a prerequisite for learning how to make better decisions going forward.\u003c/p\u003e\n\n\u003cp\u003eIf you combine those two frameworks, you could conclude that to be accountable for something you must have the power to change it \u003cem\u003eand\u003c/em\u003e understand what you are trying to accomplish when you do. You need both the power \u003cem\u003eand\u003c/em\u003e the story of how that power gets used.\u003c/p\u003e\n\n\u003cp\u003eThe comparisons to AI are obvious, inasmuch as delegating decisions to an algorithm is a convenient way to construct a sink. But organizations of any scale—whether corporations or governments or those that occupy the nebulous space between—are already quite good at forming such sinks. The accountability-washing that an AI provides isn’t a new service so much as an escalated and expanded one. Which doesn’t make it any less frightening, of course; but it does perhaps provide a useful clue. Any effort that’s tried and failed to hold a corporation to account isn’t likely to have more success against an algorithm. We need a new bag of tricks.\u003cimg width=\"10\" height=\"10\" alt=\"\" src=\"https://aworkinglibrary.com/img/stop.gif\"/\u003e\u003c/p\u003e\n\n  \u003c/section\u003e\n\n\u003c/article\u003e\n\n\n  \u003ch2\u003eRelated books\u003c/h2\u003e\n  \n    \n    \u003carticle\u003e\n  \n  \n  \u003cp\u003eDan Davies hypothesizes that organizations form “accountability sinks”—structures that serve to obscure, deflect, or otherwise insulate decision makers from the consequences of their decisions.\u003c/p\u003e\n\n\u003c/article\u003e\n\n  \n    \n    \u003carticle\u003e\n  \n  \n  \u003cp\u003eDrawing from safety practices in transportation and medicine, Sidney Dekker outlines how to (and how not to) create a culture of trust, learning, and accountability.\u003c/p\u003e\n\n\u003c/article\u003e\n\n  \n\n\n\n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": null,
  "modifiedTime": null
}
