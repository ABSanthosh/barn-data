{
  "id": "313c10a9-cf4a-469b-bad3-d59ffc60405e",
  "title": "Sam Altman at TED 2025: Inside the most uncomfortable — and important — AI interview of the year",
  "link": "https://venturebeat.com/ai/sam-altman-at-ted-2025-inside-the-most-uncomfortable-and-important-ai-interview-of-the-year/",
  "description": "At TED 2025, OpenAI CEO Sam Altman faced tough questions on AI ethics, artist compensation, and the risks of autonomous agents in a tense interview with TED’s Chris Anderson, revealing new details about OpenAI’s explosive growth and future plans.",
  "author": "Michael Nuñez",
  "published": "Tue, 15 Apr 2025 21:17:23 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Automation",
    "Business",
    "Data Infrastructure",
    "Enterprise Analytics",
    "Programming \u0026 Development",
    "Security",
    "800 million ChatGPT users",
    "ai",
    "AI artist compensation",
    "AI ethics debate",
    "AI safety concerns",
    "AI, ML and Deep Learning",
    "artificial general intelligence",
    "artificial intelligence",
    "Autonomous ai agents",
    "Business Intelligence",
    "category-/Business \u0026 Industrial",
    "category-/News",
    "ChatGPT active users",
    "content moderation AI",
    "Conversational AI",
    "Data Management",
    "Data Science",
    "Data Security and Privacy",
    "GPUs melting",
    "Network Security and Privacy",
    "NLP",
    "OpenAI",
    "OpenAI future plans",
    "OpenAI growth",
    "OpenAI valuation",
    "Sam Altman",
    "Sam Altman TED interview"
  ],
  "byline": "Michael Nuñez",
  "length": 9531,
  "excerpt": "At TED 2025, OpenAI CEO Sam Altman faced tough questions on AI ethics, artist compensation, and the risks of autonomous agents in a tense interview with TED’s Chris Anderson, revealing new details about OpenAI’s explosive growth and future plans.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "April 15, 2025 2:17 PM Host Chris Anderson and Sam Altman speak at SESSION 11 at TED 2025: Humanity Reimagined. April 7-11, 2025, Vancouver, BC. Photo: Jason Redmond / TED Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More OpenAI CEO Sam Altman revealed that his company has grown to 800 million weekly active users and is experiencing “unbelievable” growth rates, during a sometimes tense interview at the TED 2025 conference in Vancouver last week. “I have never seen growth in any company, one that I’ve been involved with or not, like this,” Altman told TED head Chris Anderson during their on-stage conversation. “The growth of ChatGPT — it is really fun. I feel deeply honored. But it is crazy to live through, and our teams are exhausted and stressed.” The interview, which closed out the final day of TED 2025: Humanity Reimagined, showcased not just OpenAI’s skyrocketing success but also the increasing scrutiny the company faces as its technology transforms society at a pace that alarms even some of its supporters. ‘Our GPUs are melting’: OpenAI struggles to scale amid unprecedented demand Altman painted a picture of a company struggling to keep up with its own success, noting that OpenAI’s GPUs are “melting” due to the popularity of its new image generation features. “All day long, I call people and beg them to give us their GPUs. We are so incredibly constrained,” he said. This exponential growth comes as OpenAI is reportedly considering launching its own social network to compete with Elon Musk’s X, according to CNBC. Altman neither confirmed nor denied these reports during the TED interview. The company recently closed a $40 billion funding round, valuing it at $300 billion — the largest private tech funding in history — and this influx of capital will likely help address some of these infrastructure challenges. From non-profit to $300 billion giant: Altman responds to ‘Ring of Power’ accusations Throughout the 47-minute conversation, Anderson repeatedly pressed Altman on OpenAI’s transformation from a non-profit research lab to a for-profit company with a $300 billion valuation. Anderson voiced concerns shared by critics, including Elon Musk, who has suggested Altman has been “corrupted by the Ring of Power,” referencing “The Lord of the Rings.” Altman defended OpenAI’s path: “Our goal is to make AGI and distribute it, make it safe for the broad benefit of humanity. I think by all accounts, we have done a lot in that direction. Clearly, our tactics have shifted over time… We didn’t think we would have to build a company around this. We learned a lot about how it goes and the realities of what these systems were going to take from capital.” When asked how he personally handles the enormous power he now wields, Altman responded: “Shockingly, the same as before. I think you can get used to anything step by step… You’re the same person. I’m sure I’m not in all sorts of ways, but I don’t feel any different.” ‘Divvying up revenue’: OpenAI plans to pay artists whose styles are used by AI One of the most concrete policy announcements from the interview was Altman’s acknowledgment that OpenAI is working on a system to compensate artists whose styles are emulated by AI. “I think there are incredible new business models that we and others are excited to explore,” Altman said when pressed about apparent IP theft in AI-generated images. “If you say, ‘I want to generate art in the style of these seven people, all of whom have consented to that,’ how do you divvy up how much money goes to each one?” Currently, OpenAI’s image generator refuses requests to mimic the style of living artists without consent, but will generate art in the style of movements, genres, or studios. Altman suggested a revenue-sharing model could be forthcoming, though details remain scarce. Autonomous AI agents: The ‘most consequential safety challenge’ OpenAI has faced The conversation grew particularly tense when discussing “agentic AI” — autonomous systems that can take actions on the internet on a user’s behalf. OpenAI’s new “Operator” tool allows AI to perform tasks like booking restaurants, raising concerns about safety and accountability. Anderson challenged Altman: “A single person could let that agent out there, and the agent could decide, ‘Well, in order to execute on that function, I got to copy myself everywhere.’ Are there red lines that you have clearly drawn internally, where you know what the danger moments are?” Altman referenced OpenAI’s “preparedness framework” but provided few specifics about how the company would prevent misuse of autonomous agents. “AI that you give access to your systems, your information, the ability to click around on your computer… when they make a mistake, it’s much higher stakes,” Altman acknowledged. “You will not use our agents if you do not trust that they’re not going to empty your bank account or delete your data.” ’14 definitions from 10 researchers’: Inside OpenAI’s struggle to define AGI In a revealing moment, Altman admitted that even within OpenAI, there’s no consensus on what constitutes artificial general intelligence (AGI) — the company’s stated goal. “It’s like the joke, if you’ve got 10 OpenAI researchers in a room and asked to define AGI, you’d get 14 definitions,” Altman said. He suggested that rather than focusing on a specific moment when AGI arrives, we should recognize that “the models are just going to get smarter and more capable and smarter and more capable on this long exponential… We’re going to have to contend and get wonderful benefits from this incredible system.” Loosening the guardrails: OpenAI’s new approach to content moderation Altman also disclosed a significant policy change regarding content moderation, revealing that OpenAI has loosened restrictions on its image generation models. “We’ve given the users much more freedom on what we would traditionally think about as speech harms,” he explained. “I think part of model alignment is following what the user of a model wants it to do within the very broad bounds of what society decides.” This shift could signal a broader move toward giving users more control over AI outputs, potentially aligning with Altman’s expressed preference for letting the hundreds of millions of users — rather than “small elite summits” — determine appropriate guardrails. “One of the cool new things about AI is our AI can talk to everybody on Earth, and we can learn the collective value preference of what everybody wants, rather than have a bunch of people who are blessed by society to sit in a room and make these decisions,” Altman said. ‘My kid will never be smarter than AI’: Altman’s vision of an AI-powered future The interview concluded with Altman reflecting on the world his newborn son will inherit — one where AI will exceed human intelligence. “My kid will never be smarter than AI. They will never grow up in a world where products and services are not incredibly smart, incredibly capable,” he said. “It’ll be a world of incredible material abundance… where the rate of change is incredibly fast and amazing new things are happening.” Anderson closed with a sobering observation: “Over the next few years, you’re going to have some of the biggest opportunities, the biggest moral challenges, the biggest decisions to make of perhaps any human in history.” The billion-user balancing act: How OpenAI navigates power, profit, and purpose Altman’s TED appearance comes at a critical juncture for OpenAI and the broader AI industry. The company faces mounting legal challenges, including copyright lawsuits from authors and publishers, while simultaneously pushing the boundaries of what AI can do. Recent advancements like ChatGPT’s viral image generation feature and video generation tool Sora have demonstrated capabilities that seemed impossible just months ago. At the same time, these tools have sparked debates about copyright, authenticity, and the future of creative work. Altman’s willingness to engage with difficult questions about safety, ethics, and the societal impact of AI shows an awareness of the stakes involved. However, critics may note that concrete answers on specific safeguards and policies remained elusive throughout the conversation. The interview also revealed the competing tensions at the heart of OpenAI’s mission: moving fast to advance AI technology while ensuring safety; balancing profit motives with societal benefit; respecting creative rights while democratizing creative tools; and navigating between elite expertise and public preference. As Anderson noted in his final comment, the decisions Altman and his peers make in the coming years may have unprecedented impacts on humanity’s future. Whether OpenAI can live up to its stated mission of ensuring “all of humanity benefits from artificial general intelligence” remains to be seen. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/TED2025_20250411_2JR4077-medium.jpg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-04-15T21:17:23+00:00\" datetime=\"2025-04-15T21:17:23+00:00\"\u003eApril 15, 2025 2:17 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"500\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/TED2025_20250411_2JR4077-medium.jpg?w=750\" alt=\"\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eHost Chris Anderson and Sam Altman speak at SESSION 11 at TED 2025: Humanity Reimagined. April 7-11, 2025, Vancouver, BC. Photo: Jason Redmond / TED\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://openai.com/\"\u003eOpenAI\u003c/a\u003e CEO \u003ca href=\"https://blog.samaltman.com/\"\u003eSam Altman\u003c/a\u003e revealed that his company has grown to \u003ca href=\"https://fortune.com/2025/04/14/sam-altman-openai-user-base-doubled-few-weeks-10-of-world-uses-system/\"\u003e800 million weekly active users\u003c/a\u003e and is experiencing “unbelievable” growth rates, during a sometimes tense interview at the \u003ca href=\"https://conferences.ted.com/ted2025\"\u003eTED 2025\u003c/a\u003e conference in Vancouver last week.\u003c/p\u003e\n\n\n\n\u003cp\u003e“I have never seen growth in any company, one that I’ve been involved with or not, like this,” Altman told TED head Chris Anderson during their on-stage conversation. “The growth of ChatGPT — it is really fun. I feel deeply honored. But it is crazy to live through, and our teams are exhausted and stressed.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThe interview, which closed out the final day of \u003ca href=\"https://conferences.ted.com/ted2025\"\u003eTED 2025: Humanity Reimagined\u003c/a\u003e, showcased not just OpenAI’s skyrocketing success but also the increasing scrutiny the company faces as its technology transforms society at a pace that alarms even some of its supporters.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cp\u003e\n\u003ciframe title=\"OpenAI’s Sam Altman Talks ChatGPT, AI Agents and Superintelligence — Live at TED2025\" width=\"500\" height=\"281\" src=\"https://www.youtube.com/embed/5MWT_doo68k?start=1\u0026amp;feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\n\u003c/p\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-our-gpus-are-melting-openai-struggles-to-scale-amid-unprecedented-demand\"\u003e‘Our GPUs are melting’: OpenAI struggles to scale amid unprecedented demand\u003c/h2\u003e\n\n\n\n\u003cp\u003eAltman painted a picture of a company struggling to keep up with its own success, noting that OpenAI’s GPUs are “melting” due to the popularity of its new image generation features. “All day long, I call people and beg them to give us their GPUs. We are so incredibly constrained,” he said.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis exponential growth comes as OpenAI is reportedly considering \u003ca href=\"https://www.cnbc.com/2025/04/15/openai-considering-own-social-network-to-compete-with-elon-musks-x.html\"\u003elaunching its own social network\u003c/a\u003e to compete with Elon Musk’s X, according to CNBC. Altman neither confirmed nor denied these reports during the TED interview.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe company recently closed a \u003ca href=\"https://www.cnbc.com/2025/02/07/softbank-set-to-invest-40-billion-in-openai-at-260-billion-valuation-sources-say.html\"\u003e$40 billion funding round\u003c/a\u003e, valuing it at $300 billion — the largest private tech funding in history — and this influx of capital will likely help address some of these infrastructure challenges.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-from-non-profit-to-300-billion-giant-altman-responds-to-ring-of-power-accusations\"\u003eFrom non-profit to $300 billion giant: Altman responds to ‘Ring of Power’ accusations\u003c/h2\u003e\n\n\n\n\u003cp\u003eThroughout the 47-minute conversation, Anderson repeatedly pressed Altman on OpenAI’s transformation from a non-profit research lab to a for-profit company with a $300 billion valuation. Anderson voiced concerns shared by critics, including Elon Musk, who has suggested Altman has been “corrupted by the Ring of Power,” referencing “The Lord of the Rings.”\u003c/p\u003e\n\n\n\n\u003cp\u003eAltman defended OpenAI’s path: “Our goal is to make AGI and distribute it, make it safe for the broad benefit of humanity. I think by all accounts, we have done a lot in that direction. Clearly, our tactics have shifted over time… We didn’t think we would have to build a company around this. We learned a lot about how it goes and the realities of what these systems were going to take from capital.”\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen asked how he personally handles the enormous power he now wields, Altman responded: “Shockingly, the same as before. I think you can get used to anything step by step… You’re the same person. I’m sure I’m not in all sorts of ways, but I don’t feel any different.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-divvying-up-revenue-openai-plans-to-pay-artists-whose-styles-are-used-by-ai\"\u003e‘Divvying up revenue’: OpenAI plans to pay artists whose styles are used by AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eOne of the most concrete policy announcements from the interview was Altman’s acknowledgment that OpenAI is working on a system to compensate artists whose styles are emulated by AI.\u003c/p\u003e\n\n\n\n\u003cp\u003e“I think there are incredible new business models that we and others are excited to explore,” Altman said when pressed about apparent \u003ca href=\"https://hbr.org/2023/04/generative-ai-has-an-intellectual-property-problem\"\u003eIP theft in AI-generated images\u003c/a\u003e. “If you say, ‘I want to generate art in the style of these seven people, all of whom have consented to that,’ how do you divvy up how much money goes to each one?”\u003c/p\u003e\n\n\n\n\u003cp\u003eCurrently, OpenAI’s image generator refuses requests to mimic the style of living artists without consent, but will generate art in the style of movements, genres, or studios. Altman suggested a revenue-sharing model could be forthcoming, though details remain scarce.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-autonomous-ai-agents-the-most-consequential-safety-challenge-openai-has-faced\"\u003eAutonomous AI agents: The ‘most consequential safety challenge’ OpenAI has faced\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe conversation grew particularly tense when discussing “\u003ca href=\"https://blogs.nvidia.com/blog/what-is-agentic-ai/\"\u003eagentic AI\u003c/a\u003e” — autonomous systems that can take actions on the internet on a user’s behalf. OpenAI’s new “\u003ca href=\"https://openai.com/index/introducing-operator/\"\u003eOperator\u003c/a\u003e” tool allows AI to perform tasks like booking restaurants, raising concerns about safety and accountability.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnderson challenged Altman: “A single person could let that agent out there, and the agent could decide, ‘Well, in order to execute on that function, I got to copy myself everywhere.’ Are there red lines that you have clearly drawn internally, where you know what the danger moments are?”\u003c/p\u003e\n\n\n\n\u003cp\u003eAltman referenced OpenAI’s “\u003ca href=\"https://openai.com/index/updating-our-preparedness-framework/\"\u003epreparedness framework\u003c/a\u003e” but provided few specifics about how the company would prevent misuse of autonomous agents.\u003c/p\u003e\n\n\n\n\u003cp\u003e“AI that you give access to your systems, your information, the ability to click around on your computer… when they make a mistake, it’s much higher stakes,” Altman acknowledged. “You will not use our agents if you do not trust that they’re not going to empty your bank account or delete your data.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-14-definitions-from-10-researchers-inside-openai-s-struggle-to-define-agi\"\u003e’14 definitions from 10 researchers’: Inside OpenAI’s struggle to define AGI\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn a revealing moment, Altman admitted that even within OpenAI, there’s no consensus on what constitutes artificial general intelligence (AGI) — the company’s stated goal.\u003c/p\u003e\n\n\n\n\u003cp\u003e“It’s like the joke, if you’ve got 10 OpenAI researchers in a room and asked to define AGI, you’d get 14 definitions,” Altman said.\u003c/p\u003e\n\n\n\n\u003cp\u003eHe suggested that rather than focusing on a specific moment when AGI arrives, we should recognize that “the models are just going to get smarter and more capable and smarter and more capable on this long exponential… We’re going to have to contend and get wonderful benefits from this incredible system.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-loosening-the-guardrails-openai-s-new-approach-to-content-moderation\"\u003eLoosening the guardrails: OpenAI’s new approach to content moderation\u003c/h2\u003e\n\n\n\n\u003cp\u003eAltman also disclosed a significant policy change regarding content moderation, revealing that OpenAI has loosened restrictions on its image generation models.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We’ve given the users much more freedom on what we would traditionally think about as speech harms,” he explained. “I think part of model alignment is following what the user of a model wants it to do within the very broad bounds of what society decides.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThis shift could signal a broader move toward giving users more control over AI outputs, potentially aligning with Altman’s expressed preference for letting the hundreds of millions of users — rather than “small elite summits” — determine appropriate guardrails.\u003c/p\u003e\n\n\n\n\u003cp\u003e“One of the cool new things about AI is our AI can talk to everybody on Earth, and we can learn the collective value preference of what everybody wants, rather than have a bunch of people who are blessed by society to sit in a room and make these decisions,” Altman said.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-my-kid-will-never-be-smarter-than-ai-altman-s-vision-of-an-ai-powered-future\"\u003e‘My kid will never be smarter than AI’: Altman’s vision of an AI-powered future\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe interview concluded with Altman reflecting on the world his newborn son will inherit — one where AI will exceed human intelligence.\u003c/p\u003e\n\n\n\n\u003cp\u003e“My kid will never be smarter than AI. They will never grow up in a world where products and services are not incredibly smart, incredibly capable,” he said. “It’ll be a world of incredible material abundance… where the rate of change is incredibly fast and amazing new things are happening.”\u003c/p\u003e\n\n\n\n\u003cp\u003eAnderson closed with a sobering observation: “Over the next few years, you’re going to have some of the biggest opportunities, the biggest moral challenges, the biggest decisions to make of perhaps any human in history.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-billion-user-balancing-act-how-openai-navigates-power-profit-and-purpose\"\u003eThe billion-user balancing act: How OpenAI navigates power, profit, and purpose\u003c/h2\u003e\n\n\n\n\u003cp\u003eAltman’s TED appearance comes at a critical juncture for OpenAI and the broader AI industry. The company faces mounting legal challenges, including \u003ca href=\"https://www.npr.org/2025/03/26/nx-s1-5288157/new-york-times-openai-copyright-case-goes-forward\"\u003ecopyright lawsuits\u003c/a\u003e from authors and publishers, while simultaneously pushing the boundaries of what AI can do.\u003c/p\u003e\n\n\n\n\u003cp\u003eRecent advancements like ChatGPT’s \u003ca href=\"https://www.cnbc.com/2025/03/27/chatgpts-viral-image-generation-ai-is-melting-openais-gpus.html\"\u003eviral image generation feature\u003c/a\u003e and video generation tool Sora have demonstrated capabilities that seemed impossible just months ago. At the same time, these tools have sparked \u003ca href=\"https://asia.nikkei.com/Business/Technology/Artificial-intelligence/Ghibli-style-AI-images-ignite-debate-over-art-copyright-protections\"\u003edebates about copyright\u003c/a\u003e, authenticity, and the future of creative work.\u003c/p\u003e\n\n\n\n\u003cp\u003eAltman’s willingness to engage with difficult questions about safety, ethics, and the societal impact of AI shows an awareness of the stakes involved. However, critics may note that concrete answers on specific safeguards and policies remained elusive throughout the conversation.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe interview also revealed the competing tensions at the heart of OpenAI’s mission: moving fast to advance AI technology while ensuring safety; balancing profit motives with societal benefit; respecting creative rights while democratizing creative tools; and navigating between elite expertise and public preference.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs Anderson noted in his final comment, the decisions Altman and his peers make in the coming years may have unprecedented impacts on humanity’s future. Whether OpenAI can live up to its stated mission of ensuring “all of humanity benefits from artificial general intelligence” remains to be seen.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-04-15T21:17:23Z",
  "modifiedTime": "2025-04-15T21:17:29Z"
}
