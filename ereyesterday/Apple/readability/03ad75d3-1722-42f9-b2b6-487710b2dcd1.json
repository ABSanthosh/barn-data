{
  "id": "03ad75d3-1722-42f9-b2b6-487710b2dcd1",
  "title": "Hands-On: How Apple’s New Speech APIs Outpace Whisper for Lightning-Fast Transcription",
  "link": "https://www.macstories.net/stories/hands-on-how-apples-new-speech-apis-outpace-whisper-for-lightning-fast-transcription/",
  "description": "Late last Tuesday night, after watching F1: The Movie at the Steve Jobs Theater, I was driving back from dropping Federico off at his hotel when I got a text: Can you pick me up? It was from my son Finn, who had spent the evening nearby and was stalking me in Find My. Of […]",
  "author": "John Voorhees",
  "published": "Tue, 17 Jun 2025 12:25:06 +0000",
  "source": "https://www.macstories.net/feed",
  "categories": [
    "stories",
    "AI",
    "artificial intelligence",
    "developer tools",
    "developers",
    "mac",
    "Tahoe",
    "transcription",
    "utilities"
  ],
  "byline": "John Voorhees",
  "length": 5055,
  "excerpt": "Late last Tuesday night, after watching F1: The Movie at the Steve Jobs Theater, I was driving back from dropping Federico off at his hotel when I got a text: Can you pick me up? It was from my son Finn, who had spent the evening nearby and was stalking me in Find My. Of",
  "siteName": "",
  "favicon": "https://www.macstories.net/app/themes/macstories4/images/apple-touch-icon-152x152-precomposed.png",
  "text": "Late last Tuesday night, after watching F1: The Movie at the Steve Jobs Theater, I was driving back from dropping Federico off at his hotel when I got a text: Can you pick me up? It was from my son Finn, who had spent the evening nearby and was stalking me in Find My. Of course, I swung by and picked him up, and we headed back to our hotel in Cupertino. On the way, Finn filled me in on a new class in Apple’s Speech framework called SpeechAnalyzer and its SpeechTranscriber module. Both the class and module are part of Apple’s OS betas that were released to developers last week at WWDC. My ears perked up immediately when he told me that he’d tested SpeechAnalyzer and SpeechTranscriber and was impressed with how fast and accurate they were. It’s still early days for these technologies, but I’m here to tell you that their speed alone is a game changer for anyone who uses voice transcription to create text from lectures, podcasts, YouTube videos, and more. That’s something I do multiple times every week for AppStories, NPC, and Unwind, generating transcripts that I upload to YouTube because the site’s built-in transcription isn’t very good. What’s frustrated me with other tools is how slow they are. Most are built on Whisper, OpenAI’s open source speech-to-text model, which was released in 2022. It’s cheap at under a penny per one million tokens, but isn’t fast, which is frustrating when you’re in the final steps of a YouTube workflow. I asked Finn what it would take to build a command line tool to transcribe video and audio files with SpeechAnalyzer and SpeechTranscriber. He figured it would only take about 10 minutes, and he wasn’t far off. In the end, it took me longer to get around to installing macOS Tahoe after WWDC than it took Finn to build Yap, a simple command line utility that takes audio and video files as input and outputs SRT- and TXT-formatted transcripts. Yesterday, I finally took the Tahoe plunge and immediately installed Yap. I grabbed the 7GB 4K video version of AppStories episode 441, which is about 34 minutes long, and ran it through Yap. It took just 45 seconds to generate an SRT file. Here’s Yap ripping through nearly 20% of an episode of NPC in 10 seconds: Next, I ran the same file through VidCap and MacWhisper, using its V2 Large and V3 Turbo models. Here’s how each app and model did: App Transcripiton Time Yap 0:45 MacWhisper (Large V3 Turbo) 1:41 VidCap 1:55 MacWhisper (Large V2) 3:55 All three transcription workflows had similar trouble with last names and words like “AppStories,” which LLMs tend to separate into two words instead of camel casing. That’s easily fixed by running a set of find and replace rules, although I’d love to feed those corrections back into the model itself for future transcriptions. What stood out above all else was Yap’s speed. By harnessing SpeechAnalyzer and SpeechTranscriber on-device, the command line tool tore through the 7GB video file a full 55% faster than MacWhisper’s Large V3 Turbo model, with no noticeable difference in transcription quality. At first blush, the difference between 0:45 and 1:41 may seem insignificant, and it arguably is, but those are the results for just one 34-minute video. Extrapolate that to running Yap against the hours of Apple Developer videos released on YouTube with the help of yt-dlp, and suddenly, you’re talking about a significant amount of time. Like all automation, picking up a 55% speed gain one video or audio clip at a time, multiple times each week, adds up quickly. Whether you’re producing video for YouTube and need subtitles, generating transcripts to summarize lectures at school, or doing something else, SpeechAnalyzer and SpeechTranscriber – available across the iPhone, iPad, Mac, and Vision Pro – mark a significant leap forward in transcription speed without compromising on quality. I fully expect this combination to replace Whisper as the default transcription model for transcription apps on Apple platforms. To test Apple’s new model, install the macOS Tahoe beta, which currently requires an Apple developer account, and then install Yap from its GitHub page. Access Extra Content and PerksFounded in 2015, Club MacStories has delivered exclusive content every week for nearly a decade. What started with weekly and monthly email newsletters has blossomed into a family of memberships designed every MacStories fan. Learn more here and from our Club FAQs. Club MacStories: Weekly and monthly newsletters via email and the web that are brimming with apps, tips, automation workflows, longform writing, early access to the MacStories Unwind podcast, periodic giveaways, and more; Club MacStories+: Everything that Club MacStories offers, plus an active Discord community, advanced search and custom RSS features for exploring the Club’s entire back catalog, bonus columns, and dozens of app discounts; Club Premier: All of the above and AppStories+, an extended version of our flagship podcast that’s delivered early, ad-free, and in high-bitrate audio.",
  "image": "https://cdn.macstories.net/cleanshot-2025-06-16-at-19-35-41-2x-1750117164464.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                        \n\u003cp id=\"p2\"\u003eLate last Tuesday night, after watching \u003ca href=\"https://apple.co/3SVXtI7\" rel=\"noopener noreferrer\"\u003eF1: The Movie\u003c/a\u003e at the Steve Jobs Theater, I was driving back from dropping Federico off at his hotel when I got a text:\u003c/p\u003e\n\u003cblockquote id=\"blockquote3\"\u003e\u003cp\u003e\n  Can you pick me up?\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp id=\"p4\"\u003eIt was from my son \u003ca href=\"https://www.finnvoorhees.com\" rel=\"noopener noreferrer\"\u003eFinn\u003c/a\u003e, who had spent the evening nearby and was stalking me in Find My. Of course, I swung by and picked him up, and we headed back to our hotel in Cupertino.\u003c/p\u003e\n\u003cp id=\"p5\"\u003eOn the way, Finn filled me in on a new class in \u003ca href=\"https://developer.apple.com/documentation/speech\" rel=\"noopener noreferrer\"\u003eApple’s Speech framework\u003c/a\u003e called \u003ca href=\"https://developer.apple.com/documentation/speech/speechanalyzer\" rel=\"noopener noreferrer\"\u003eSpeechAnalyzer\u003c/a\u003e and its \u003ca href=\"https://developer.apple.com/documentation/speech/speechtranscriber\" rel=\"noopener noreferrer\"\u003eSpeechTranscriber\u003c/a\u003e module. Both the class and module are \u003ca href=\"https://developer.apple.com/videos/play/wwdc2025/277\" rel=\"noopener noreferrer\"\u003epart of Apple’s OS betas\u003c/a\u003e that were released to developers last week at WWDC. My ears perked up immediately when he told me that he’d tested SpeechAnalyzer and SpeechTranscriber and was impressed with how fast and accurate they were.\u003c/p\u003e\n\u003cp id=\"p6\"\u003eIt’s still early days for these technologies, but I’m here to tell you that their speed alone is a game changer for anyone who uses voice transcription to create text from lectures, podcasts, YouTube videos, and more. That’s something I do multiple times every week for \u003ca href=\"https://appstories.net\" rel=\"noopener noreferrer\"\u003eAppStories\u003c/a\u003e, \u003ca href=\"https://www.macstories.net/npc/\" rel=\"noopener noreferrer\"\u003eNPC\u003c/a\u003e, and \u003ca href=\"https://www.macstories.net/unwind/\" rel=\"noopener noreferrer\"\u003eUnwind\u003c/a\u003e, generating transcripts that I upload to YouTube because the site’s built-in transcription isn’t very good.\u003c/p\u003e\n\u003cp id=\"p7\"\u003eWhat’s frustrated me with other tools is how slow they are. Most are built on \u003ca href=\"https://platform.openai.com/docs/models/whisper-1\" rel=\"noopener noreferrer\"\u003eWhisper\u003c/a\u003e, OpenAI’s open source speech-to-text model, which was released in 2022. It’s cheap at under a penny per one million tokens, but isn’t fast, which is frustrating when you’re in the final steps of a YouTube workflow.\u003c/p\u003e\n\n\u003cp id=\"p9\"\u003eI asked Finn what it would take to build a command line tool to transcribe video and audio files with SpeechAnalyzer and SpeechTranscriber. He figured it would only take about 10 minutes, and he wasn’t far off. In the end, it took me longer to get around to installing macOS Tahoe after WWDC than it took Finn to build \u003ca href=\"https://github.com/finnvoor/yap\" rel=\"noopener noreferrer\"\u003eYap\u003c/a\u003e, a simple command line utility that takes audio and video files as input and outputs SRT- and TXT-formatted transcripts.\u003c/p\u003e\n\u003cp id=\"p10\"\u003eYesterday, I finally took the Tahoe plunge and immediately installed Yap. I grabbed the 7GB 4K video version of \u003ca href=\"https://appstories.net/episodes/441\" rel=\"noopener noreferrer\"\u003eAppStories episode 441\u003c/a\u003e, which is about 34 minutes long, and ran it through Yap. It took just 45 seconds to generate an SRT file. Here’s Yap ripping through nearly 20% of an episode of NPC in 10 seconds:\u003c/p\u003e\n\n\u003cp id=\"p12\"\u003eNext, I ran the same file through \u003ca href=\"https://apps.apple.com/us/app/ai-captions-for-videos-vidcap/id1620725834\" rel=\"noopener noreferrer\"\u003eVidCap\u003c/a\u003e and \u003ca href=\"https://goodsnooze.gumroad.com/l/macwhisper\" rel=\"noopener noreferrer\"\u003eMacWhisper\u003c/a\u003e, using its V2 Large and V3 Turbo models. Here’s how each app and model did:\u003c/p\u003e\n\u003cdiv id=\"div13\"\u003e\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eApp\u003c/th\u003e\n\u003cth\u003eTranscripiton Time\u003c/th\u003e\n\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eYap\u003c/td\u003e\n\u003ctd\u003e0:45\u003c/td\u003e\n\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eMacWhisper (Large V3 Turbo)\u003c/td\u003e\n\u003ctd\u003e1:41\u003c/td\u003e\n\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eVidCap\u003c/td\u003e\n\u003ctd\u003e1:55\u003c/td\u003e\n\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eMacWhisper (Large V2)\u003c/td\u003e\n\u003ctd\u003e3:55\u003c/td\u003e\n\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/div\u003e\u003cp id=\"p14\"\u003eAll three transcription workflows had similar trouble with last names and words like “AppStories,” which LLMs tend to separate into two words instead of camel casing. That’s easily fixed by running a set of find and replace rules, although I’d love to feed those corrections back into the model itself for future transcriptions.\u003c/p\u003e\n\n\u003cp id=\"p16\"\u003eWhat stood out above all else was Yap’s speed. By harnessing SpeechAnalyzer and SpeechTranscriber on-device, the command line tool tore through the 7GB video file a full 55% faster than MacWhisper’s Large V3 Turbo model, with no noticeable difference in transcription quality.\u003c/p\u003e\n\u003cp id=\"p17\"\u003eAt first blush, the difference between 0:45 and 1:41 may seem insignificant, and it arguably is, but those are the results for just one 34-minute video. Extrapolate that to running Yap against the hours of Apple Developer videos released on YouTube with the help of \u003ca href=\"https://github.com/yt-dlp/yt-dlp\" rel=\"noopener noreferrer\"\u003e\u003ccode\u003eyt-dlp\u003c/code\u003e\u003c/a\u003e, and suddenly, you’re talking about a significant amount of time. Like all automation, picking up a 55% speed gain one video or audio clip at a time, multiple times each week, adds up quickly.\u003c/p\u003e\n\u003cp id=\"p18\"\u003eWhether you’re producing video for YouTube and need subtitles, generating transcripts to summarize lectures at school, or doing something else, \u003ca href=\"https://developer.apple.com/videos/play/wwdc2025/277\" rel=\"noopener noreferrer\"\u003eSpeechAnalyzer and SpeechTranscriber\u003c/a\u003e – available across the iPhone, iPad, Mac, and Vision Pro – mark a significant leap forward in transcription speed without compromising on quality. I fully expect this combination to replace Whisper as the default transcription model for transcription apps on Apple platforms.\u003c/p\u003e\n\u003cp id=\"p19\"\u003eTo test Apple’s new model, install the macOS Tahoe beta, which currently requires an Apple developer account, and then \u003ca href=\"https://github.com/finnvoor/yap\" rel=\"noopener noreferrer\"\u003einstall Yap from its GitHub page\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\u003cdiv\u003e\n            \u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://www.macstories.net/app/themes/macstories4/images/logo-shape-gold.svg\" alt=\"Club MacStories\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch3\u003eAccess Extra Content and Perks\u003c/h3\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003eFounded in 2015, \u003ca href=\"https://club.macstories.net/plans?utm_source=ms\u0026amp;utm_medium=web-inline\" rel=\"noopener noreferrer\"\u003eClub MacStories\u003c/a\u003e has delivered exclusive content every week for nearly a decade.\u003c/p\u003e\n\u003cp\u003eWhat started with weekly and monthly email newsletters has blossomed into \u003ca href=\"https://club.macstories.net/plans?utm_source=ms\u0026amp;utm_medium=web-inline\" rel=\"noopener noreferrer\"\u003ea family of memberships\u003c/a\u003e designed every MacStories fan.\u003c/p\u003e\n\u003cp\u003eLearn more \u003ca href=\"https://club.macstories.net/plans?utm_source=ms\u0026amp;utm_medium=web-inline\" rel=\"noopener noreferrer\"\u003ehere\u003c/a\u003e and from our \u003ca href=\"https://club.macstories.net/faq\" rel=\"noopener noreferrer\"\u003eClub FAQs\u003c/a\u003e.\u003c/p\u003e\n\u003c/div\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://club.macstories.net/plans/club\" rel=\"noopener noreferrer\"\u003eClub MacStories\u003c/a\u003e\u003c/strong\u003e: Weekly and monthly newsletters via email and the web that are brimming with apps, tips, automation workflows, longform writing, early access to the \u003ca href=\"https://www.macstories.net/unwind/\" rel=\"noopener noreferrer\"\u003eMacStories Unwind podcast\u003c/a\u003e, periodic giveaways, and more;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://club.macstories.net/plans/plus\" rel=\"noopener noreferrer\"\u003eClub MacStories+\u003c/a\u003e\u003c/strong\u003e: Everything that Club MacStories offers, plus an active Discord community, advanced search and custom RSS features for exploring the Club’s entire back catalog, bonus columns, and dozens of app discounts;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://club.macstories.net/plans/premier\" rel=\"noopener noreferrer\"\u003eClub Premier\u003c/a\u003e\u003c/strong\u003e: All of the above \u003cem\u003eand\u003c/em\u003e AppStories+, an extended version of our flagship podcast that’s delivered early, ad-free, and in high-bitrate audio.\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e        \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-06-17T12:25:06-04:00",
  "modifiedTime": null
}
