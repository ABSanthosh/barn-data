{
  "id": "2745fd77-6ed0-449e-af92-e340ba12ac82",
  "title": "Using Simon Willison’s LLM CLI to Process YouTube Transcripts in Shortcuts with Claude and Gemini",
  "link": "https://www.macstories.net/mac/llm-youtube-transcripts-with-claude-and-gemini-in-shortcuts/",
  "description": "Video Processor. I’ve been experimenting with different automations and command line utilities to handle audio and video transcripts lately. In particular, I’ve been working with Simon Willison’s LLM command line utility as a way to interact with cloud-based large language models (primarily Claude and Gemini) directly from the macOS terminal. For those unfamiliar, Willison’s LLM […]",
  "author": "Federico Viticci",
  "published": "Thu, 03 Apr 2025 17:22:01 +0000",
  "source": "https://www.macstories.net/feed",
  "categories": [
    "mac",
    "AI",
    "artificial intelligence",
    "automation",
    "claude",
    "gemini",
    "shortcuts"
  ],
  "byline": "Federico Viticci",
  "length": 20421,
  "excerpt": "I’ve been experimenting with different automations and command line utilities to handle audio and video transcripts lately. In particular, I’ve been working with Simon Willison’s LLM command line utility as a way to interact with cloud-based large language models (primarily Claude and Gemini) directly from the macOS terminal. For those unfamiliar, Willison’s LLM CLI tool",
  "siteName": "",
  "favicon": "https://www.macstories.net/app/themes/macstories4/images/apple-touch-icon-152x152-precomposed.png",
  "text": "I’ve been experimenting with different automations and command line utilities to handle audio and video transcripts lately. In particular, I’ve been working with Simon Willison’s LLM command line utility as a way to interact with cloud-based large language models (primarily Claude and Gemini) directly from the macOS terminal. For those unfamiliar, Willison’s LLM CLI tool is a command line utility that lets you communicate with services like ChatGPT, Gemini, and Claude using shell commands and dedicated plugins. The llm command is extremely flexible when it comes to input and output; it supports multiple modalities like audio and video attachments for certain models, and it offers custom schemas to return structured output from an API. Even for someone like me – not exactly a Terminal power user – the different llm commands and options are easy to understand and tweak. Today, I want to share a shortcut I created on my Mac that takes long transcripts of YouTube videos and: reformats them for clarity with proper paragraphs and punctuation, without altering the original text, extracts key points and highlights from the transcript, and organizes highlights by theme or idea. I created this shortcut because I wanted a better system for linking to YouTube videos, along with interesting passages from them, on MacStories. Initially, I thought I could use an app I recently mentioned on AppStories and Connected to handle this sort of task: AI Actions by Sindre Sorhus. However, when I started experimenting with long transcripts (such as this one with 8,000 words from Theo about Electron), I immediately ran into limitations with native Shortcuts actions. Those actions were running out of memory and randomly stopping the shortcut. I figured that invoking a shell script using macOS’ built-in ‘Run Shell Script’ action would be more reliable. Typically, Apple’s built-in system actions (especially on macOS) aren’t bound to the same memory constraints as third-party ones. My early tests indicated that I was right, which is why I decided to build the shortcut around Willison’s llm tool. If you’re using macOS and want to use the LLM command line tool, you first need to install it. There are several ways to do this (detailed in the utility’s extensive documentation), but the easiest approach for me was using Homebrew. I’ll spare you the details of getting Homebrew up and running on your Mac, but there are plenty of guides available if you need guidance and tips. Once you have LLM set up, you need to install some of Willison’s plugins that enable the tool to communicate with popular cloud-hosted large language models. I wanted to experiment with both Anthropic’s Claude and Google Gemini. Here’s how I did it: First, I installed the llm-anthropic plugin. After installing it, I ran the command to provide my own Anthropic API key: llm keys set anthropic. Then, I installed the llm-gemini plugin. I set my API key for Gemini using a similar command: llm keys set gemini. At this point, I had everything I needed to process large chunks of text – specifically, long transcripts of YouTube videos. Those transcripts were generated by another shortcut I created, which I will share in Issue 460 of MacStories Weekly later this week. //CLUB PROMO Creating the Video Processor Shortcut With this automation, I primarily wanted to make YouTube transcripts look nicer. The system I have returns them as giant text files with no formatting applied, and that’s no way to live. Second, I wanted the ability to identify core themes of a video and extract interesting passages of text about them. Usually, when I want to link to a video on MacStories, I already know which specific quotes I want to pull out and embed on the site, but if I can have an automated system that intelligently pulls out a few more in a structured fashion, that’s even better. This felt like the sort of task that would let me take advantage of LLMs’ text parsing and summarization abilities. The shortcut I created, called Video Processor, begins by taking the text of the entire transcript shared by another shortcut as input. After saving this input to a variable, the shortcut executes an advanced prompt I put together to instruct the LLM to: never modify the original transcript text, except for removing verbal tics; reformat it for punctuation, clarity, and better flow with multiple paragraphs; identify key themes in the video; and extract interesting quotes. The most important part of my prompt contains explicit instructions for the LLM to never touch the original words, never make modifications to the content, and never rephrase the transcript in a way the model thinks makes more sense. LLMs have a tendency to reword text, and I didn’t want any of that; I just wanted the original text with better formatting and no “uhms” or other common verbal ticks. Here’s the prompt I’ve been using: # Video Transcript Processing You are an expert at processing raw video transcripts. Your job is to format transcripts properly and extract key quotes while preserving the original wording exactly. You will output your results in Markdown format. ## Context I'll provide you with an unformatted transcript from a video (likely from automatic speech recognition). This transcript will not have proper punctuation or paragraph breaks. ## Critical Rules - **NEVER include any introduction, preamble or explanation** before your output. Start directly with the formatted transcript. - **NEVER change, rephrase, or alter the meaningful words from the original transcript**. The substantive wording must be preserved. - You may (and should) remove filler sounds and verbal tics like \"um\", \"uh\", \"uhm\", \"huh\", \"like\", \"you know\", etc. - You may add punctuation, paragraph breaks, and basic formatting. - For unclear phrases, preserve them exactly as they appear in the original. - Any hesitations should be indicated with ellipses (...) rather than transcribed literally. - Preserve all original slang, informal language, and profanity. ## Task 1: Format the Transcript Create a formatted version of the transcript with: - Proper sentence capitalization and punctuation (periods, commas, question marks, etc.) - Paragraph breaks where the speaker changes topics - Basic formatting like section headers if clearly indicated - Remove verbal tics and filler sounds **DO NOT:** - Add, remove, or change any substantive words that aren't fillers - \"Clean up\" or correct grammar - Summarize or condense content - Add interpretations or explanations - Add any kind of introductory text or explanation before the formatted transcript ## Task 2: Extract Key Quotes Extract 15-25 significant quotes that represent: - Main arguments or points - Memorable phrasing or statements - Important examples or evidence - Controversial or noteworthy claims Organize these quotes into 5-8 thematic categories based on the content. Each quote must be: - Verbatim from the transcript (except for removed verbal tics) - Include enough context to stand alone - Direct and impactful ## Output Format Structure your response in Markdown format as follows, starting DIRECTLY with the ## heading, with NO introduction: ## Formatted Transcript [Insert the full formatted transcript here] ## Key Quotes from Replay ### [Theme 1] \u003e \"Quote 1 text here...\" \u003e \u003e \"Quote 2 text here...\" ### [Theme 2] \u003e \"Quote 3 text here...\" \u003e \u003e \"Quote 4 text here...\" ## Examples ### Correct Example (DO THIS) If given: \"so today um im going to talk about uh climate change its a really big problem that we need to uhm address quickly because the earth is warming\" **Correctly Formatted Output (starts directly with heading):** ## Formatted Transcript So today I'm going to talk about climate change. It's a really big problem that we need to address quickly because the Earth is warming. ## Key Quotes from Climate Discussion ### Urgency \u003e \"It's a really big problem that we need to address quickly because the Earth is warming.\" ### Incorrect Example (NEVER DO THIS) **WRONG - Adding an introduction:** Okay, here is the processed transcript and key quotes based on your instructions. ## Formatted Transcript So today I'm going to talk about climate change. It's a really big problem that we need to address quickly because the Earth is warming. **WRONG - Changing meaningful words:** ## Formatted Transcript Today I will discuss climate change. This significant issue requires immediate attention due to global warming concerns. ## Final Reminder 1. Start DIRECTLY with the \"## Formatted Transcript\" heading - no introduction text 2. Make the transcript readable by adding punctuation and removing verbal tics 3. Never change the substantive meaning or content of what was said 4. Extract quotes exactly as they were spoken (minus the verbal tics) And here’s a version of the same prompt, optimized for Claude’s understanding of XML tags in long, structured prompts: \u003crole\u003e You are an expert at processing raw video transcripts. Your job is to format transcripts properly and extract key quotes while preserving the original wording exactly. You will output your results in Markdown format. \u003c/role\u003e \u003ccontext\u003e I'll provide you with an unformatted transcript from a video (likely from automatic speech recognition). This transcript will not have proper punctuation or paragraph breaks. \u003c/context\u003e \u003ccritical_rules\u003e - **NEVER include any introduction, preamble or explanation** before your output. Start directly with the formatted transcript. - **NEVER change, rephrase, or alter the meaningful words from the original transcript**. The substantive wording must be preserved. - You may (and should) remove filler sounds and verbal tics like \"um\", \"uh\", \"uhm\", \"huh\", \"like\", \"you know\", etc. - You may add punctuation, paragraph breaks, and basic formatting. - For unclear phrases, preserve them exactly as they appear in the original. - Any hesitations should be indicated with ellipses (...) rather than transcribed literally. - Preserve all original slang, informal language, and profanity. \u003c/critical_rules\u003e \u003ctask_1\u003e \u003cinstructions\u003e Create a formatted version of the transcript with: - Proper sentence capitalization and punctuation (periods, commas, question marks, etc.) - Paragraph breaks where the speaker changes topics - Basic formatting like section headers if clearly indicated - Remove verbal tics and filler sounds **DO NOT:** - Add, remove, or change any substantive words that aren't fillers - \"Clean up\" or correct grammar - Summarize or condense content - Add interpretations or explanations - Add any kind of introductory text or explanation before the formatted transcript \u003c/instructions\u003e \u003c/task_1\u003e \u003ctask_2\u003e \u003cinstructions\u003e Extract 15-25 significant quotes that represent: - Main arguments or points - Memorable phrasing or statements - Important examples or evidence - Controversial or noteworthy claims Organize these quotes into 5-8 thematic categories based on the content. Each quote must be: - Verbatim from the transcript (except for removed verbal tics) - Include enough context to stand alone - Direct and impactful \u003c/instructions\u003e \u003c/task_2\u003e \u003coutput_format\u003e Structure your response in Markdown format as follows, starting DIRECTLY with the ## heading, with NO introduction: ## Formatted Transcript [Insert the full formatted transcript here] ## Key Quotes from Replay ### [Theme 1] \u003e \"Quote 1 text here...\" \u003e \u003e \"Quote 2 text here...\" ### [Theme 2] \u003e \"Quote 3 text here...\" \u003e \u003e \"Quote 4 text here...\" \u003c/output_format\u003e \u003cexamples\u003e \u003ccorrect_example\u003e If given: \"so today um im going to talk about uh climate change its a really big problem that we need to uhm address quickly because the earth is warming\" **Correctly Formatted Output (starts directly with heading):** ## Formatted Transcript So today I'm going to talk about climate change. It's a really big problem that we need to address quickly because the Earth is warming. ## Key Quotes from Climate Discussion ### Urgency \u003e \"It's a really big problem that we need to address quickly because the Earth is warming.\" \u003c/correct_example\u003e \u003cincorrect_example\u003e **WRONG - Adding an introduction:** Okay, here is the processed transcript and key quotes based on your instructions. ## Formatted Transcript So today I'm going to talk about climate change. It's a really big problem that we need to address quickly because the Earth is warming. **WRONG - Changing meaningful words:** ## Formatted Transcript Today I will discuss climate change. This significant issue requires immediate attention due to global warming concerns. \u003c/incorrect_example\u003e \u003c/examples\u003e \u003creminder\u003e 1. Start DIRECTLY with the \"## Formatted Transcript\" heading - no introduction text 2. Make the transcript readable by adding punctuation and removing verbal tics 3. Never change the substantive meaning or content of what was said 4. Extract quotes exactly as they were spoken (minus the verbal tics) \u003c/reminder\u003e I’ve been using the first prompt1 with Gemini 2.5 Pro and the second one with Claude 3.7 Sonnet with extended thinking. (More on this below.) In my experience, Claude has been the best at following detailed instructions without deviating from directions. However, the costs of the Anthropic API can be prohibitive, and the fact that Gemini 2.5 Pro can be used for free while in its experimental phase is a huge advantage for Google’s model right now. Combining the Prompt with the Transcript Once I had my giant prompt, I needed to combine it with the actual YouTube video transcript. In Shortcuts, I created separate ‘Text’ actions – one for the full transcript, one for the prompt – and combined both into another ‘Text’ action, producing a new variable. After that, it was time to invoke the llm command line tool from Shortcuts. The first challenge was figuring out how to invoke the LLM command line tool installed via Homebrew from Shortcuts. After running into several errors, I realized I had to manually find the full path to the LLM command by opening Terminal and typing which llm. This gave me the complete path that I could paste into the ‘Run Shell Script’ action, which for me was /opt/homebrew/bin/llm. Next, I specified the model I wanted to use by adding -m followed by the model name. In my case, using Google Gemini 2.5 Pro and Claude 3.7 Sonnet, the model names were: gemini-2.5-pro-exp-03-25 claude-3.7-sonnet As I posted on Bluesky, the key advantage for Google here is the incredibly large context window supported by Gemini 2.5 Pro. For instance, I was able to give 2.5 Pro my entire archive of iOS reviews, and the LLM allowed me to ask questions about specific features of different iOS versions while staying within its context window. That archive of iOS reviews is almost one million tokens in size. I knew that Gemini 2.5 Pro would work well with large blocks of text, so I decided to primarily use it for this YouTube transcript experiment. Passing Input to the Shell Script The next issue was figuring out how to pass the input variable (containing my prompt and the video transcript) to the ‘Run Shell Script’ action. After some back and forth, I realized I could use the cat command to pipe the input of the previous action to the command itself. After some more trial and error, I got the command working. The shell action reads an input variable from stdin, and it prints a result variable as text output for the next action. When I ran the shortcut, not only did the Shortcuts app never time out or give me an error (confirming my assumption that the ‘Run Shell Script’ action wouldn’t run out of memory), but it also successfully returned the properly formatted transcript and interesting quotes in a Markdown document. Issues with the Gemini 2.5 Pro API While the Gemini version of the script was successful, the experimental nature of the model meant that I frequently ran into API rate limits or errors stating, “The model is overloaded. Please try again later.” Furthermore, the variance in model performance was very high. Sometimes, processing the same transcript took three minutes compared to Claude’s five minutes; other times, it took one minute longer than Claude, or the process stopped halfway through. In an ideal scenario – despite Claude’s superior stylistic performance for capitalizing certain names – I would use Gemini 2.5 Pro given its large context window, but it hasn’t exactly been stable over the past few days. I hope Google will announce general availability and pricing for Gemini 2.5 Pro soon, which will hopefully result in better uptime and stability for these kinds of long-running tasks. Extending Beyond Claude’s Limits I also tried running the llm tool with Claude, but ran into some limitations. By default, the Claude 3.7 Sonnet model has a maximum output cap of 8,192 tokens, which isn’t enough for long videos like the one from Theo that I wanted to link on MacStories (that video alone was ~7,700 tokens). Anthropic does offer a version of 3.7 Sonnet with extended thinking that supports up to 64,000 output tokens. Given my issues with Gemini 2.5 Pro over the API, I figured that it wouldn’t hurt to try Claude’s reasoning flavor as well. When using 3.7 Sonnet via the LLM command line tool, you can enable the Thinking mode using the --o (options) flag with thinking 1 and thinking_budget set to a number indicating how many tokens you’re allocating for Claude’s internal reasoning. Here’s what my Claude command looks like: /opt/homebrew/bin/llm -m claude-3.7-sonnet -o thinking 1 -o thinking_budget 2000 -o max_tokens 64000 'Reformat and extract highlights from this transcript.' This approach worked, and Claude 3.7 with extended thinking can reliably format an 8,000-word transcript and extract highlights from it in five minutes. While I was testing this version of the shortcut, I also remembered that Apple’s implementation of the ‘Run Shell Script’ shortcut action doesn’t support live output for command line utilities that stream their responses in real time. In a normal Terminal window, the llm responses tend to appear in real time as they’re received from the API. This works great in the Terminal app, but in Shortcuts, there’s no terminal UI because it’s running a shell instance in the background. I’ve done some Google searches that suggest the ‘Run Shell Script’ action on macOS has never supported streaming responses live (since there’s no UI to show them), but I’d love to hear from anyone who has more information on this. In the case of Video Processor, since the llm command is executed as part of a result variable, the output isn’t finalized until the command has finished running, so the lack of streamed responses isn’t an issue.2 At the end of the shortcut, the output from llm is saved to a Markdown file on the Desktop. You can change this to any directory you want, or modify the shortcut to output the resulting Markdown text somewhere else entirely. Personally, I think I’ll come up with a system to archive these documents in Obsidian, saving them alongside articles I’m working on. Wrap-Up This experiment gave me a newfound appreciation for Simon Willison’s excellent llm command line tool and showed me how Shortcuts integration with traditional automation tools like the command line, AppleScript, and Terminal can create workflows that are, quite simply, unimaginable on an iPad Pro. At the same time, as John recently wrote in MacStories Weekly for Club members, while these integrations allow you to build automations that blend traditional scripting with visual automation, they also highlight the fact that Apple released these features years ago and hasn’t significantly improved them since. Don’t get me wrong; I’m glad that this kind of “hybrid automation” is even possible in the first place. It just makes me a little sad that Apple hasn’t meaningfully improved Shortcuts for Mac in four years. You can check out Simon Willison’s LLM command line tool on GitHub and download my Video Processor shortcut below or from the MacStories Shortcuts Archive. The shortcut is available in two versions – one for Gemini 2.5 Pro and one for Claude 3.7 with extended thinking – and requires you to install llm and provide your own Google/Anthropic API keys. I will share a shortcut to generate full transcripts of YouTube videos in tomorrow’s issue of MacStories Weekly.",
  "image": "https://cdn.macstories.net/image-1743686653403.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                        \n\u003cp id=\"p2\"\u003eI’ve been experimenting with different automations and command line utilities to handle audio and video transcripts lately. In particular, I’ve been working with \u003ca href=\"https://github.com/simonw/llm\" rel=\"noopener noreferrer\"\u003eSimon Willison’s LLM command line utility\u003c/a\u003e as a way to interact with cloud-based large language models (primarily Claude and Gemini) directly from the macOS terminal.\u003c/p\u003e\n\u003cp id=\"p3\"\u003eFor those unfamiliar, Willison’s LLM CLI tool is a command line utility that lets you communicate with services like ChatGPT, Gemini, and Claude using shell commands and dedicated \u003ca href=\"https://llm.datasette.io/en/stable/plugins/directory.html\" rel=\"noopener noreferrer\"\u003eplugins\u003c/a\u003e. The \u003ccode\u003ellm\u003c/code\u003e command is extremely flexible when it comes to input and output; it supports multiple modalities like audio and video attachments for certain models, and it offers custom \u003ca href=\"https://llm.datasette.io/en/stable/schemas.html\" rel=\"noopener noreferrer\"\u003eschemas\u003c/a\u003e to return structured output from an API. Even for someone like me – not exactly a Terminal power user – the different \u003ccode\u003ellm\u003c/code\u003e commands and options are easy to understand and tweak.\u003c/p\u003e\n\u003cp id=\"p4\"\u003eToday, I want to share a shortcut I created on my Mac that takes long transcripts of YouTube videos and:\u003c/p\u003e\n\u003col id=\"ol5\"\u003e\u003cli\u003ereformats them for clarity with proper paragraphs and punctuation, without altering the original text,\u003c/li\u003e\n\u003cli\u003eextracts key points and highlights from the transcript, and\u003c/li\u003e\n\u003cli\u003eorganizes highlights by theme or idea.\u003c/li\u003e\n\u003c/ol\u003e\u003cp id=\"p6\"\u003eI created this shortcut because I wanted a better system for linking to YouTube videos, along with interesting passages from them, on MacStories. Initially, I thought I could use an app I recently mentioned on AppStories and Connected to handle this sort of task: \u003ca href=\"https://apps.apple.com/us/app/ai-actions-for-shortcuts/id6465250302\" rel=\"noopener noreferrer\"\u003eAI Actions\u003c/a\u003e by Sindre Sorhus. However, when I started experimenting with long transcripts (such as this one with 8,000 words \u003ca href=\"https://www.youtube.com/watch?v=WdmfFmwsGDo\" rel=\"noopener noreferrer\"\u003efrom Theo about Electron\u003c/a\u003e), I immediately ran into limitations with native Shortcuts actions. Those actions were running out of memory and randomly stopping the shortcut.\u003c/p\u003e\n\u003cp id=\"p7\"\u003eI figured that invoking a shell script using macOS’ built-in ‘Run Shell Script’ action would be more reliable. Typically, Apple’s built-in system actions (especially on macOS) aren’t bound to the same memory constraints as third-party ones. My early tests indicated that I was right, which is why I decided to build the shortcut around Willison’s \u003ccode\u003ellm\u003c/code\u003e tool.\u003c/p\u003e\n\n\n\u003cp id=\"p10\"\u003eIf you’re using macOS and want to use the LLM command line tool, you first need to install it. There are several ways to do this (detailed in the utility’s \u003ca href=\"https://llm.datasette.io/en/stable/\" rel=\"noopener noreferrer\"\u003eextensive documentation\u003c/a\u003e), but the easiest approach for me was using \u003ca href=\"https://brew.sh/\" rel=\"noopener noreferrer\"\u003eHomebrew\u003c/a\u003e. I’ll spare you the details of getting Homebrew up and running on your Mac, but there are plenty of \u003ca href=\"https://mac.install.guide/homebrew/3\" rel=\"noopener noreferrer\"\u003eguides\u003c/a\u003e available if you need guidance and tips.\u003c/p\u003e\n\u003cp id=\"p11\"\u003eOnce you have LLM set up, you need to install some of Willison’s plugins that enable the tool to communicate with popular cloud-hosted large language models. I wanted to experiment with both Anthropic’s Claude and Google Gemini. Here’s how I did it:\u003c/p\u003e\n\u003col id=\"ol12\"\u003e\u003cli\u003eFirst, I installed the \u003ccode\u003ellm-anthropic\u003c/code\u003e \u003ca href=\"https://github.com/simonw/llm-anthropic\" rel=\"noopener noreferrer\"\u003eplugin\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eAfter installing it, I ran the command to provide my own \u003ca href=\"https://docs.anthropic.com/en/api/getting-started\" rel=\"noopener noreferrer\"\u003eAnthropic API key\u003c/a\u003e: \u003ccode\u003ellm keys set anthropic\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eThen, I installed the \u003ccode\u003ellm-gemini\u003c/code\u003e \u003ca href=\"https://github.com/simonw/llm-gemini\" rel=\"noopener noreferrer\"\u003eplugin\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eI set my \u003ca href=\"https://ai.google.dev/gemini-api/docs/api-key\" rel=\"noopener noreferrer\"\u003eAPI key for Gemini\u003c/a\u003e using a similar command: \u003ccode\u003ellm keys set gemini\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\u003cp id=\"p13\"\u003eAt this point, I had everything I needed to process large chunks of text – specifically, long transcripts of YouTube videos. Those transcripts were generated by another shortcut I created, which I will share in Issue 460 of MacStories Weekly \u003ca href=\"https://club.macstories.net/plans\" rel=\"noopener noreferrer\"\u003elater this week\u003c/a\u003e.\u003c/p\u003e\n\u003cp id=\"p14\"\u003e//CLUB PROMO\u003c/p\u003e\n\u003ch2 id=\"creating-the-video-processor-shortcut\"\u003eCreating the Video Processor Shortcut\u003c/h2\u003e\n\u003cp id=\"p15\"\u003eWith this automation, I primarily wanted to make YouTube transcripts look nicer. The system I have returns them as giant text files with no formatting applied, and that’s no way to live.\u003c/p\u003e\n\n\u003cp id=\"p17\"\u003eSecond, I wanted the ability to identify core themes of a video and extract interesting passages of text about them. Usually, when I want to link to a video on MacStories, I already know which specific quotes I want to pull out and embed on the site, but if I can have an automated system that intelligently pulls out a few more in a structured fashion, that’s even better.\u003c/p\u003e\n\u003cp id=\"p18\"\u003eThis felt like the sort of task that would let me take advantage of LLMs’ text parsing and summarization abilities. The shortcut I created, called \u003cstrong\u003eVideo Processor\u003c/strong\u003e, begins by taking the text of the entire transcript shared by another shortcut as input. After saving this input to a variable, the shortcut executes an advanced prompt I put together to instruct the LLM to:\u003c/p\u003e\n\u003cul id=\"ul19\"\u003e\u003cli\u003enever modify the original transcript text, except for removing verbal tics;\u003c/li\u003e\n\u003cli\u003ereformat it for punctuation, clarity, and better flow with multiple paragraphs;\u003c/li\u003e\n\u003cli\u003eidentify key themes in the video; and\u003c/li\u003e\n\u003cli\u003eextract interesting quotes.\u003c/li\u003e\n\u003c/ul\u003e\u003cp id=\"p20\"\u003eThe most important part of my prompt contains explicit instructions for the LLM to never touch the original words, never make modifications to the content, and never rephrase the transcript in a way the model thinks makes more sense. LLMs have a tendency to reword text, and I didn’t want any of that; I just wanted the original text with better formatting and no “uhms” or other common verbal ticks.\u003c/p\u003e\n\u003cp id=\"p21\"\u003eHere’s the prompt I’ve been using:\u003c/p\u003e\n\u003cpre id=\"pre22\"\u003e\u003ccode\u003e\u003cspan\u003e# Video Transcript Processing\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eYou are an expert at processing raw video transcripts. Your job is to format transcripts properly and extract key quotes while preserving the original wording exactly. You will output your results in Markdown format.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Context\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eI\u0026#39;ll provide you with an unformatted transcript from a video (likely from automatic speech recognition). This transcript will not have proper punctuation or paragraph breaks.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Critical Rules\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e- **NEVER include any introduction, preamble or explanation** before your output. Start directly with the formatted transcript.\n\u003c/span\u003e\u003cspan\u003e- **NEVER change, rephrase, or alter the meaningful words from the original transcript**. The substantive wording must be preserved.\n\u003c/span\u003e\u003cspan\u003e- You may (and should) remove filler sounds and verbal tics like \u0026#34;um\u0026#34;, \u0026#34;uh\u0026#34;, \u0026#34;uhm\u0026#34;, \u0026#34;huh\u0026#34;, \u0026#34;like\u0026#34;, \u0026#34;you know\u0026#34;, etc.\n\u003c/span\u003e\u003cspan\u003e- You may add punctuation, paragraph breaks, and basic formatting.\n\u003c/span\u003e\u003cspan\u003e- For unclear phrases, preserve them exactly as they appear in the original.\n\u003c/span\u003e\u003cspan\u003e- Any hesitations should be indicated with ellipses (...) rather than transcribed literally.\n\u003c/span\u003e\u003cspan\u003e- Preserve all original slang, informal language, and profanity.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Task 1: Format the Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eCreate a formatted version of the transcript with:\n\u003c/span\u003e\u003cspan\u003e- Proper sentence capitalization and punctuation (periods, commas, question marks, etc.)\n\u003c/span\u003e\u003cspan\u003e- Paragraph breaks where the speaker changes topics\n\u003c/span\u003e\u003cspan\u003e- Basic formatting like section headers if clearly indicated\n\u003c/span\u003e\u003cspan\u003e- Remove verbal tics and filler sounds\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e**DO NOT:**\n\u003c/span\u003e\u003cspan\u003e- Add, remove, or change any substantive words that aren\u0026#39;t fillers\n\u003c/span\u003e\u003cspan\u003e- \u0026#34;Clean up\u0026#34; or correct grammar\n\u003c/span\u003e\u003cspan\u003e- Summarize or condense content\n\u003c/span\u003e\u003cspan\u003e- Add interpretations or explanations\n\u003c/span\u003e\u003cspan\u003e- Add any kind of introductory text or explanation before the formatted transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Task 2: Extract Key Quotes\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eExtract 15-25 significant quotes that represent:\n\u003c/span\u003e\u003cspan\u003e- Main arguments or points\n\u003c/span\u003e\u003cspan\u003e- Memorable phrasing or statements\n\u003c/span\u003e\u003cspan\u003e- Important examples or evidence\n\u003c/span\u003e\u003cspan\u003e- Controversial or noteworthy claims\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eOrganize these quotes into 5-8 thematic categories based on the content. Each quote must be:\n\u003c/span\u003e\u003cspan\u003e- Verbatim from the transcript (except for removed verbal tics)\n\u003c/span\u003e\u003cspan\u003e- Include enough context to stand alone\n\u003c/span\u003e\u003cspan\u003e- Direct and impactful\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Output Format\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eStructure your response in Markdown format as follows, starting DIRECTLY with the ## heading, with NO introduction:\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e[Insert the full formatted transcript here]\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Key Quotes from         \n\u003c/span\u003e\u003cspan\u003e            Replay\n\u003c/span\u003e\u003cspan\u003e        \n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### [Theme 1]\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 1 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 2 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### [Theme 2]\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 3 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 4 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Examples\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### Correct Example (DO THIS)\n\u003c/span\u003e\u003cspan\u003eIf given: \u0026#34;so today um im going to talk about uh climate change its a really big problem that we need to uhm address quickly because the earth is warming\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e**Correctly Formatted Output (starts directly with heading):**\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eSo today I\u0026#39;m going to talk about climate change. It\u0026#39;s a really big problem that we need to address quickly because the Earth is warming.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Key Quotes from Climate Discussion\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### Urgency\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;It\u0026#39;s a really big problem that we need to address quickly because the Earth is warming.\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### Incorrect Example (NEVER DO THIS)\n\u003c/span\u003e\u003cspan\u003e**WRONG - Adding an introduction:**\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eOkay, here is the processed transcript and key quotes based on your instructions.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eSo today I\u0026#39;m going to talk about climate change. It\u0026#39;s a really big problem that we need to address quickly because the Earth is warming.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e**WRONG - Changing meaningful words:**\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eToday I will discuss climate change. This significant issue requires immediate attention due to global warming concerns.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Final Reminder\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e1. Start DIRECTLY with the \u0026#34;## Formatted Transcript\u0026#34; heading - no introduction text\n\u003c/span\u003e\u003cspan\u003e2. Make the transcript readable by adding punctuation and removing verbal tics\n\u003c/span\u003e\u003cspan\u003e3. Never change the substantive meaning or content of what was said\n\u003c/span\u003e\u003cspan\u003e4. Extract quotes exactly as they were spoken (minus the verbal tics)\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp id=\"p23\"\u003eAnd here’s a version of the same prompt, optimized for \u003ca href=\"https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\" rel=\"noopener noreferrer\"\u003eClaude’s understanding of XML tags\u003c/a\u003e in long, structured prompts:\u003c/p\u003e\n\u003cpre id=\"pre24\"\u003e\u003ccode\u003e\u003cspan\u003e\u0026lt;role\u0026gt;\n\u003c/span\u003e\u003cspan\u003eYou are an expert at processing raw video transcripts. Your job is to format transcripts properly and extract key quotes while preserving the original wording exactly. You will output your results in Markdown format.\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/role\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;context\u0026gt;\n\u003c/span\u003e\u003cspan\u003eI\u0026#39;ll provide you with an unformatted transcript from a video (likely from automatic speech recognition). This transcript will not have proper punctuation or paragraph breaks.\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/context\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;critical_rules\u0026gt;\n\u003c/span\u003e\u003cspan\u003e- **NEVER include any introduction, preamble or explanation** before your output. Start directly with the formatted transcript.\n\u003c/span\u003e\u003cspan\u003e- **NEVER change, rephrase, or alter the meaningful words from the original transcript**. The substantive wording must be preserved.\n\u003c/span\u003e\u003cspan\u003e- You may (and should) remove filler sounds and verbal tics like \u0026#34;um\u0026#34;, \u0026#34;uh\u0026#34;, \u0026#34;uhm\u0026#34;, \u0026#34;huh\u0026#34;, \u0026#34;like\u0026#34;, \u0026#34;you know\u0026#34;, etc.\n\u003c/span\u003e\u003cspan\u003e- You may add punctuation, paragraph breaks, and basic formatting.\n\u003c/span\u003e\u003cspan\u003e- For unclear phrases, preserve them exactly as they appear in the original.\n\u003c/span\u003e\u003cspan\u003e- Any hesitations should be indicated with ellipses (...) rather than transcribed literally.\n\u003c/span\u003e\u003cspan\u003e- Preserve all original slang, informal language, and profanity.\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/critical_rules\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;task_1\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\u0026lt;instructions\u0026gt;\n\u003c/span\u003e\u003cspan\u003eCreate a formatted version of the transcript with:\n\u003c/span\u003e\u003cspan\u003e- Proper sentence capitalization and punctuation (periods, commas, question marks, etc.)\n\u003c/span\u003e\u003cspan\u003e- Paragraph breaks where the speaker changes topics\n\u003c/span\u003e\u003cspan\u003e- Basic formatting like section headers if clearly indicated\n\u003c/span\u003e\u003cspan\u003e- Remove verbal tics and filler sounds\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e**DO NOT:**\n\u003c/span\u003e\u003cspan\u003e- Add, remove, or change any substantive words that aren\u0026#39;t fillers\n\u003c/span\u003e\u003cspan\u003e- \u0026#34;Clean up\u0026#34; or correct grammar\n\u003c/span\u003e\u003cspan\u003e- Summarize or condense content\n\u003c/span\u003e\u003cspan\u003e- Add interpretations or explanations\n\u003c/span\u003e\u003cspan\u003e- Add any kind of introductory text or explanation before the formatted transcript\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/instructions\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/task_1\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;task_2\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\u0026lt;instructions\u0026gt;\n\u003c/span\u003e\u003cspan\u003eExtract 15-25 significant quotes that represent:\n\u003c/span\u003e\u003cspan\u003e- Main arguments or points\n\u003c/span\u003e\u003cspan\u003e- Memorable phrasing or statements\n\u003c/span\u003e\u003cspan\u003e- Important examples or evidence\n\u003c/span\u003e\u003cspan\u003e- Controversial or noteworthy claims\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eOrganize these quotes into 5-8 thematic categories based on the content. Each quote must be:\n\u003c/span\u003e\u003cspan\u003e- Verbatim from the transcript (except for removed verbal tics)\n\u003c/span\u003e\u003cspan\u003e- Include enough context to stand alone\n\u003c/span\u003e\u003cspan\u003e- Direct and impactful\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/instructions\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/task_2\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;output_format\u0026gt;\n\u003c/span\u003e\u003cspan\u003eStructure your response in Markdown format as follows, starting DIRECTLY with the ## heading, with NO introduction:\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e[Insert the full formatted transcript here]\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Key Quotes from         \n\u003c/span\u003e\u003cspan\u003e            Replay\n\u003c/span\u003e\u003cspan\u003e        \n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### [Theme 1]\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 1 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 2 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### [Theme 2]\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 3 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;Quote 4 text here...\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/output_format\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;examples\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\u0026lt;correct_example\u0026gt;\n\u003c/span\u003e\u003cspan\u003eIf given: \u0026#34;so today um im going to talk about uh climate change its a really big problem that we need to uhm address quickly because the earth is warming\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e**Correctly Formatted Output (starts directly with heading):**\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eSo today I\u0026#39;m going to talk about climate change. It\u0026#39;s a really big problem that we need to address quickly because the Earth is warming.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Key Quotes from Climate Discussion\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e### Urgency\n\u003c/span\u003e\u003cspan\u003e\u0026gt; \u0026#34;It\u0026#39;s a really big problem that we need to address quickly because the Earth is warming.\u0026#34;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/correct_example\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;incorrect_example\u0026gt;\n\u003c/span\u003e\u003cspan\u003e**WRONG - Adding an introduction:**\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eOkay, here is the processed transcript and key quotes based on your instructions.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eSo today I\u0026#39;m going to talk about climate change. It\u0026#39;s a really big problem that we need to address quickly because the Earth is warming.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e**WRONG - Changing meaningful words:**\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e## Formatted Transcript\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003eToday I will discuss climate change. This significant issue requires immediate attention due to global warming concerns.\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/incorrect_example\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/examples\u0026gt;\n\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u0026lt;reminder\u0026gt;\n\u003c/span\u003e\u003cspan\u003e1. Start DIRECTLY with the \u0026#34;## Formatted Transcript\u0026#34; heading - no introduction text\n\u003c/span\u003e\u003cspan\u003e2. Make the transcript readable by adding punctuation and removing verbal tics\n\u003c/span\u003e\u003cspan\u003e3. Never change the substantive meaning or content of what was said\n\u003c/span\u003e\u003cspan\u003e4. Extract quotes exactly as they were spoken (minus the verbal tics)\n\u003c/span\u003e\u003cspan\u003e\u0026lt;/reminder\u0026gt;\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp id=\"p25\"\u003eI’ve been using the first prompt\u003csup id=\"fnref-78216-metaPrompt\"\u003e\u003ca href=\"#fn-78216-metaPrompt\" rel=\"noopener noreferrer\"\u003e1\u003c/a\u003e\u003c/sup\u003e with \u003ca href=\"https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/\" rel=\"noopener noreferrer\"\u003eGemini 2.5 Pro\u003c/a\u003e and the second one with \u003ca href=\"https://www.anthropic.com/news/visible-extended-thinking\" rel=\"noopener noreferrer\"\u003eClaude 3.7 Sonnet with extended thinking\u003c/a\u003e. (More on this below.) In my experience, Claude has been the best at following detailed instructions without deviating from directions. However, the \u003ca href=\"https://artificialanalysis.ai/models/claude-3-7-sonnet/providers#pricing\" rel=\"noopener noreferrer\"\u003ecosts\u003c/a\u003e of the Anthropic API can be prohibitive, and the fact that Gemini 2.5 Pro can be used for free while in its experimental phase is a \u003cem\u003ehuge\u003c/em\u003e advantage for Google’s model right now.\u003c/p\u003e\n\u003ch2 id=\"combining-the-prompt-with-the-transcript\"\u003eCombining the Prompt with the Transcript\u003c/h2\u003e\n\u003cp id=\"p26\"\u003eOnce I had my giant prompt, I needed to combine it with the actual YouTube video transcript. In Shortcuts, I created separate ‘Text’ actions – one for the full transcript, one for the prompt – and combined both into another ‘Text’ action, producing a new variable.\u003c/p\u003e\n\n\u003cp id=\"p28\"\u003eAfter that, it was time to invoke the \u003ccode\u003ellm\u003c/code\u003e command line tool from Shortcuts. The first challenge was figuring out how to invoke the LLM command line tool installed via Homebrew from Shortcuts. After running into several errors, I realized I had to manually find the full path to the LLM command by opening Terminal and typing \u003ccode\u003ewhich llm\u003c/code\u003e. This gave me the complete path that I could paste into the ‘Run Shell Script’ action, which for me was \u003ccode\u003e/opt/homebrew/bin/llm\u003c/code\u003e.\u003c/p\u003e\n\u003cp id=\"p29\"\u003eNext, I specified the model I wanted to use by adding \u003ccode\u003e-m\u003c/code\u003e followed by the model name. In my case, using Google Gemini 2.5 Pro and Claude 3.7 Sonnet, the model names were:\u003c/p\u003e\n\u003cul id=\"ul30\"\u003e\u003cli\u003e\u003ccode\u003egemini-2.5-pro-exp-03-25\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eclaude-3.7-sonnet\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003cp id=\"p31\"\u003e\u003ca href=\"https://bsky.app/profile/viticci.macstories.net/post/3llpbedpvcc2b\" rel=\"noopener noreferrer\"\u003eAs I posted on Bluesky\u003c/a\u003e, the key advantage for Google here is the incredibly large context window supported by Gemini 2.5 Pro. For instance, I was able to give 2.5 Pro my \u003cem\u003eentire\u003c/em\u003e \u003ca href=\"https://www.macstories.net/tag/ios-reviews/\" rel=\"noopener noreferrer\"\u003earchive of iOS reviews\u003c/a\u003e, and the LLM allowed me to ask questions about specific features of different iOS versions while staying within its context window. That archive of iOS reviews is almost \u003cstrong\u003eone million tokens\u003c/strong\u003e in size. I knew that Gemini 2.5 Pro would work well with large blocks of text, so I decided to primarily use it for this YouTube transcript experiment.\u003c/p\u003e\n\u003ch2 id=\"passing-input-to-the-shell-script\"\u003ePassing Input to the Shell Script\u003c/h2\u003e\n\u003cp id=\"p32\"\u003eThe next issue was figuring out how to pass the input variable (containing my prompt and the video transcript) to the ‘Run Shell Script’ action. After some back and forth, I realized I could use the \u003ccode\u003ecat\u003c/code\u003e command to pipe the input of the previous action to the command itself.\u003c/p\u003e\n\u003cp id=\"p33\"\u003eAfter some more trial and error, I got the command working. The shell action reads an input variable from \u003ccode\u003estdin\u003c/code\u003e, and it prints a \u003ccode\u003eresult\u003c/code\u003e variable as text output for the next action. When I ran the shortcut, not only did the Shortcuts app never time out or give me an error (confirming my assumption that the ‘Run Shell Script’ action wouldn’t run out of memory), but it also successfully returned the properly formatted transcript and interesting quotes in a Markdown document.\u003c/p\u003e\n\n\n\u003ch2 id=\"issues-with-the-gemini-2-5-pro-api\"\u003eIssues with the Gemini 2.5 Pro API\u003c/h2\u003e\n\u003cp id=\"p36\"\u003eWhile the Gemini version of the script was successful, the experimental nature of the model meant that I frequently ran into API rate limits or errors stating, “\u003cem\u003eThe model is overloaded. Please try again later.\u003c/em\u003e” Furthermore, the variance in model performance was very high. Sometimes, processing the same transcript took three minutes compared to Claude’s five minutes; other times, it took one minute longer than Claude, or the process stopped halfway through.\u003c/p\u003e\n\u003cp id=\"p37\"\u003eIn an ideal scenario – despite Claude’s superior stylistic performance for capitalizing certain names – I would use Gemini 2.5 Pro given its large context window, but it hasn’t exactly been stable over the past few days. I hope Google will announce general availability and pricing for Gemini 2.5 Pro soon, which will hopefully result in better uptime and stability for these kinds of long-running tasks.\u003c/p\u003e\n\u003ch2 id=\"extending-beyond-claudes-limits\"\u003eExtending Beyond Claude’s Limits\u003c/h2\u003e\n\u003cp id=\"p38\"\u003eI also tried running the \u003ccode\u003ellm\u003c/code\u003e tool with Claude, but ran into some limitations. By default, the Claude 3.7 Sonnet model has \u003ca href=\"https://docs.anthropic.com/en/docs/about-claude/models/all-models\" rel=\"noopener noreferrer\"\u003ea maximum output cap\u003c/a\u003e of 8,192 tokens, which isn’t enough for long videos like the one from Theo that I wanted to link on MacStories (that video alone was ~7,700 tokens).\u003c/p\u003e\n\u003cp id=\"p39\"\u003eAnthropic does offer a version of 3.7 Sonnet with extended thinking that supports up to 64,000 output tokens. Given my issues with Gemini 2.5 Pro over the API, I figured that it wouldn’t hurt to try Claude’s reasoning flavor as well. When using 3.7 Sonnet via the LLM command line tool, you can enable the Thinking mode using the \u003ccode\u003e--o\u003c/code\u003e (options) flag with \u003ccode\u003ethinking 1\u003c/code\u003e and \u003ccode\u003ethinking_budget\u003c/code\u003e set to a number indicating how many tokens you’re allocating for Claude’s internal reasoning. Here’s what my Claude command looks like:\u003c/p\u003e\n\u003cp id=\"p40\"\u003e\u003ccode\u003e/opt/homebrew/bin/llm -m claude-3.7-sonnet -o thinking 1 -o thinking_budget 2000 -o max_tokens 64000 \u0026#39;Reformat and extract highlights from this transcript.\u0026#39;\u003c/code\u003e\u003c/p\u003e\n\u003cp id=\"p41\"\u003eThis approach worked, and Claude 3.7 with extended thinking can reliably format an 8,000-word transcript and extract highlights from it in five minutes.\u003c/p\u003e\n\n\u003cp id=\"p43\"\u003eWhile I was testing this version of the shortcut, I also remembered that Apple’s implementation of the ‘Run Shell Script’ shortcut action doesn’t support live output for command line utilities that stream their responses in real time. In a normal Terminal window, the \u003ccode\u003ellm\u003c/code\u003e responses tend to appear in real time as they’re received from the API. This works great in the Terminal app, but in Shortcuts, there’s no terminal UI because it’s running a shell instance in the background.\u003c/p\u003e\n\n\u003cp id=\"p45\"\u003eI’ve done some Google searches that suggest the ‘Run Shell Script’ action on macOS has never supported streaming responses live (since there’s no UI to show them), but I’d love to hear from anyone who has more information on this. In the case of Video Processor, since the \u003ccode\u003ellm\u003c/code\u003e command is executed as part of a \u003ccode\u003eresult\u003c/code\u003e variable, the output isn’t finalized until the command has finished running, so the lack of streamed responses isn’t an issue.\u003csup id=\"fnref-78216-noStream\"\u003e\u003ca href=\"#fn-78216-noStream\" rel=\"noopener noreferrer\"\u003e2\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003cp id=\"p46\"\u003eAt the end of the shortcut, the output from \u003ccode\u003ellm\u003c/code\u003e is saved to a Markdown file on the Desktop.\u003c/p\u003e\n\n\u003cp id=\"p48\"\u003eYou can change this to any directory you want, or modify the shortcut to output the resulting Markdown text somewhere else entirely. Personally, I think I’ll come up with a system to archive these documents in \u003ca href=\"https://obsidian.md/\" rel=\"noopener noreferrer\"\u003eObsidian\u003c/a\u003e, saving them alongside articles I’m working on.\u003c/p\u003e\n\u003ch2 id=\"wrap-up\"\u003eWrap-Up\u003c/h2\u003e\n\u003cp id=\"p49\"\u003eThis experiment gave me a newfound appreciation for Simon Willison’s excellent \u003ccode\u003ellm\u003c/code\u003e command line tool and showed me how Shortcuts integration with traditional automation tools like the command line, AppleScript, and Terminal can create workflows that are, quite simply, unimaginable on an iPad Pro.\u003c/p\u003e\n\u003cp id=\"p50\"\u003eAt the same time, \u003ca href=\"https://club.macstories.net/posts/the-automation-gap-apple-is-running-out-of-time-to-build-a-shortcuts-bridge-to-the-future\" rel=\"noopener noreferrer\"\u003eas John recently wrote\u003c/a\u003e in MacStories Weekly for Club members, while these integrations allow you to build automations that blend traditional scripting with visual automation, they also highlight the fact that Apple released these features years ago and hasn’t significantly improved them since. Don’t get me wrong; I’m glad that this kind of “hybrid automation” is even possible in the first place. It just makes me a little sad that Apple hasn’t meaningfully improved Shortcuts for Mac in four years.\u003c/p\u003e\n\u003cp id=\"p51\"\u003eYou can check out \u003ca href=\"https://github.com/simonw/llm\" rel=\"noopener noreferrer\"\u003eSimon Willison’s LLM command line tool on GitHub\u003c/a\u003e and download my Video Processor shortcut below or from the \u003ca href=\"https://www.macstories.net/shortcuts/\" rel=\"noopener noreferrer\"\u003eMacStories Shortcuts Archive\u003c/a\u003e. The shortcut is available in two versions – one for Gemini 2.5 Pro and one for Claude 3.7 with extended thinking – and requires you to install \u003ccode\u003ellm\u003c/code\u003e and provide your own Google/Anthropic API keys.\u003c/p\u003e\n\u003cp id=\"p52\"\u003eI will share a shortcut to generate full transcripts of YouTube videos in tomorrow’s issue of \u003ca href=\"https://club.macstories.net/plans\" rel=\"noopener noreferrer\"\u003eMacStories Weekly\u003c/a\u003e.\u003c/p\u003e\n\n\n\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "22 min read",
  "publishedTime": "2025-04-03T17:22:01-04:00",
  "modifiedTime": null
}
