{
  "id": "7c08eb6b-bd6f-4eb5-b04d-f53817f2ddbc",
  "title": "Testing citation skills and overconfidence of AI chatbots",
  "link": "https://flowingdata.com/2025/03/17/testing-citation-skills-and-overconfidence-of-ai-chatbots/",
  "description": "When you enter a query in traditional search engines, you get a list…Tags: accuracy, chatbot, citations, Columbia Journalism Review",
  "author": "Nathan Yau",
  "published": "Mon, 17 Mar 2025 17:05:46 +0000",
  "source": "https://flowingdata.com/feed",
  "categories": [
    "Artificial Intelligence",
    "accuracy",
    "chatbot",
    "citations",
    "Columbia Journalism Review"
  ],
  "byline": "Nathan Yau",
  "length": 1176,
  "excerpt": "When you enter a query in traditional search engines, you get a list of results. They are possible answers to your question, and you decide what resources you want to trust. On the other hand, when…",
  "siteName": "FlowingData",
  "favicon": "https://flowingdata.com/wp-content/uploads/2025/01/logo-lone-square512x512-210x210.png",
  "text": "When you enter a query in traditional search engines, you get a list of results. They are possible answers to your question, and you decide what resources you want to trust. On the other hand, when you query via AI chatbot, you get a limited number of answers, as a sentence, that appear confident in the context. For Columbia Journalism Review, Klaudia Jaźwińska and Aisvarya Chandrasekar tested this accuracy and confidence by using several chatbots to cite articles: Overall, the chatbots often failed to retrieve the correct articles. Collectively, they provided incorrect answers to more than 60 percent of queries. Across different platforms, the level of inaccuracy varied, with Perplexity answering 37 percent of the queries incorrectly, while Grok 3 had a much higher error rate, answering 94 percent of the queries incorrectly. So not great. I am sure someone is working on improving that accuracy, but we’ll have to develop our own skills in separating truth from junk, just like we have with past online things. Going forward, maybe keep an eye out for the younger and older generations who tend to accept online things as automatic truth. Things could get dicey.",
  "image": "https://flowingdata.com/wp-content/uploads/2025/03/ai-search-citation-cjr-e1742230613528.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                \n        \n        \u003cp\u003eWhen you enter a query in traditional search engines, you get a list of results. They are possible answers to your question, and you decide what resources you want to trust. On the other hand, when you query via AI chatbot, you get a limited number of answers, as a sentence, that appear confident in the context.\u003c/p\u003e\n\u003cp\u003eFor Columbia Journalism Review, Klaudia Jaźwińska and Aisvarya Chandrasekar \u003ca href=\"https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php\"\u003etested this accuracy and confidence by using several chatbots to cite articles\u003c/a\u003e:\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003eOverall, the chatbots often failed to retrieve the correct articles. Collectively, they provided incorrect answers to more than 60 percent of queries. Across different platforms, the level of inaccuracy varied, with Perplexity answering 37 percent of the queries incorrectly, while Grok 3 had a much higher error rate, answering 94 percent of the queries incorrectly.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eSo not great. \u003c/p\u003e\n\u003cp\u003eI am sure someone is working on improving that accuracy, but we’ll have to develop our own skills in separating truth from junk, just like we have with past online things. Going forward, maybe keep an eye out for the younger and older generations who tend to accept online things as automatic truth. Things could get dicey.\u003c/p\u003e\n    \n\t\n        \n\t\t\n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": "2025-03-17T17:05:46Z",
  "modifiedTime": "2025-03-17T17:05:46Z"
}
