{
  "id": "1fc784d6-5db1-4264-b6c7-bff8e107ba11",
  "title": "How to Make AI Faster and Smarter—With a Little Help from Physics",
  "link": "https://www.wired.com/story/improving-deep-learning-with-a-little-help-from-physics/",
  "description": "Rose Yu has drawn on the principles of fluid dynamics to improve deep learning systems that predict traffic, model the climate, and stabilize drones during flight.",
  "author": "Steve Nadis",
  "published": "Sun, 01 Jun 2025 11:00:00 +0000",
  "source": "https://www.wired.com/feed/category/science/latest/rss",
  "categories": [
    "Science",
    "Science / Physics and Math",
    "Q+A"
  ],
  "byline": "Steve Nadis",
  "length": 10680,
  "excerpt": "Rose Yu has drawn on the principles of fluid dynamics to improve deep learning systems that predict traffic, model the climate, and stabilize drones during flight.",
  "siteName": "WIRED",
  "favicon": "",
  "text": "The original version of this story appeared in Quanta Magazine.When she was 10 years old, Rose Yu got a birthday present that would change her life—and, potentially, the way we study physics. Her uncle got her a computer. That was a rare commodity in China 25 years ago, and the gift did not go unused. At first, Yu mainly played computer games, but in middle school she won an award for web design. It was the first of many computer-related honors.Yu went on to major in computer science at Zhejiang University, where she won a prize for innovative research. For her graduate studies, she chose the University of Southern California (USC), partly because the same uncle—who was the only person she knew in the United States—was then working at the Jet Propulsion Laboratory in nearby Pasadena. Yu earned her doctorate in 2017 with an award for best dissertation. Her most recent honor came in January, when President Joe Biden, in his last week in office, gave her a Presidential Early Career Award.Yu, now an associate professor at the University of California, San Diego (UCSD), is a leader in a field known as “physics-guided deep learning,” having spent years incorporating our knowledge of physics into artificial neural networks. The work has not only introduced novel techniques for building and training these systems, but it’s also allowed her to make progress on several real-world applications. She has drawn on principles of fluid dynamics to improve traffic predictions, sped up simulations of turbulence to enhance our understanding of hurricanes, and devised tools that helped predict the spread of Covid-19.This work has brought Yu closer to her grand dream—deploying a suite of digital lab assistants that she calls AI Scientist. She now envisions what she calls a “partnership” between human researchers and AI tools, fully based on the tenets of physics and thus capable of yielding new scientific insights. Combining inputs from a team of such assistants, in her opinion, may be the best way to boost the discovery process.Quanta spoke with Yu about turbulence in its many guises, how to get more out of AI, and how it might get us out of urban gridlock. The interview has been condensed and edited for clarity.Yu on the UCSD campus, where she is an associate professor. Photograph: Peggy Peattie for Quanta MagazineWhen did you first try to combine physics with deep learning?Rose Yu: It started with traffic. I was a grad student at USC, and the campus is right near the intersection of I-10 and I-110. To get anywhere, you have to go through a lot of traffic, which can be very annoying. In 2016, I began to wonder whether I could do anything about this.Deep learning—which uses multilayered neural networks to elicit patterns from data—was getting really hot back then. There was already a lot of excitement about applications in image classification, but images are just static things. I wondered whether deep learning could help with problems where things are constantly changing. I wasn’t the first person to consider this, but my colleagues and I did find a novel way of framing the problem.What was your new approach?First, we thought of traffic in terms of the physical process of diffusion. In our model, the flow of traffic over a network of roads is analogous to the flow of fluids over a surface—motions that are governed by the laws of fluid dynamics. But our main innovation was to think of traffic as a graph, from the mathematical field of graph theory. Sensors, which monitor traffic on highways and other roads, serve as the nodes of this graph. And the edges of the graph represent the roads (and distances) between those sensors.Yu’s interest in computers began with a gift for her 10th birthday. Photograph: Peggy Peattie for Quanta MagazineA graph provides a snapshot of the entire road network at a given time, telling you the average velocity of cars at every point on the graph. When you put together a series of these snapshots, spaced every five minutes apart, you get a good picture of how traffic is evolving. From there, you can try to predict what will happen in the future.The big challenge in deep learning is that you need a lot of data to train the neural network. Fortunately, one of my advisers, Cyrus Shahabi, had worked for many years on the problem of traffic forecasting, and he’d accumulated a vast amount of LA traffic data that I had access to.So how good were your predictions?Prior to our work, people could only make traffic forecasts that were reliable for about 15 minutes. Our forecasts were valid for one hour—a big improvement. Our code was deployed by Google Maps in 2018. A bit later, Google invited me to become a visiting researcher.That’s about when you began working on climate modeling, right?Yes, that started in 2018, when I gave a talk at the Lawrence Berkeley National Laboratory. Afterward, I spoke with scientists there, and we looked for a problem that would be a good testbed for physics-guided deep learning. We settled on predicting the evolution of turbulent flow, which is a key factor in climate models, as well as an area of major uncertainty.Familiar examples of turbulence are the swirling patterns you see after pouring milk into a cup of coffee and giving it a stir. In the oceans, swirls like this can span thousands of miles. Predictions of turbulent behavior that are based on solving the Navier-Stokes equation, which describes the flow of fluids, are considered the gold standard in this field. But the required calculations are very slow, which is why we don’t have good models for predicting hurricanes and tropical cyclones.The heavy congestion of Los Angeles first inspired Yu to model highway traffic as the flow of fluids. Photograph: Peggy Peattie for Quanta MagazineAnd deep learning can help?The basic idea is that deep neural networks that are trained on our best numerical simulations can learn to imitate—or as we say, “emulate”—those simulations. They do that by recognizing properties and patterns buried within the data. They don’t have to go through time-consuming, brute-force calculations to find approximate solutions. Our models sped up predictions by a factor of 20 in two-dimensional settings and by a factor of 1,000 in three-dimensional settings. Something like our turbulence prediction module might someday be inserted into bigger climate models that can do better at predicting things like hurricanes.Where else does turbulence show up?It’s pretty much everywhere. Turbulence in blood flow, for instance, can lead to strokes or heart attacks. And when I was a postdoc at Caltech, I coauthored a paper that looked into stabilizing drones. Propellor-generated airflows interact with the ground to create turbulence. That, in turn, can cause the drone to wobble. We used a neural network to model the turbulence, and that led to better control of drones during takeoffs and landings.I’m currently working with scientists at UCSD and General Atomics on fusion power. One of the keys to success is learning how to control the plasma, which is a hot, ionized phase of matter. At temperatures of about 100 million degrees, different kinds of turbulence arise within the plasma, and physics-based numerical models that characterize that behavior are very slow. We’re developing a deep learning model that should be able to predict the plasma’s behavior in a split second, but this is still a work in progress.Yu and doctoral student Jianke Yang in her office at UCSD. Photograph: Peggy Peattie for Quanta MagazineWhere did your AI Scientist idea come from?In the past couple of years, my group has developed AI algorithms that can automatically discover symmetry principles from data. For example, our algorithm identified the Lorentz symmetry, which has to do with the constancy of the speed of light. Our algorithm also identified rotational symmetry—the fact, for example, that a sphere doesn’t look any different regardless of how you rotate it—which is something it was not specifically trained to know about. While these are well-known properties, our tools also have the capability to discover new symmetries presently unknown to physics, which would constitute a huge breakthrough.It then occurred to me that if our tools can discover symmetries from raw data, why don’t we try to generalize this? These tools could also generate research ideas or new hypotheses in science. That was the genesis of AI Scientist.What exactly is AI Scientist—just a fancy kind of neural net?It’s not a single neural network, but rather an ensemble of computer programs that can help scientists make new discoveries. My group has already developed algorithms that can help with individual tasks, such as weather forecasting, identifying the drivers of global temperature rise, or trying to discover causal relationships like the effects of vaccination policies on disease transmission.We’re now building a broader “foundation” model that’s versatile enough to handle multiple tasks. Scientists gather data from all types of instruments, and we want our model to include a variety of data types—numbers, text, images, and videos. We have an early prototype, but we want to make our model more comprehensive, more intelligent and better trained before we release it. That could happen within a couple of years.What do you imagine it could do?AI can assist in practically every step of the scientific discovery process. When I say “AI Scientist,” I really mean an AI scientific assistant. The literature survey stage in an experiment, for example, typically requires a massive data-gathering and organization effort. But now, a large language model can read and summarize thousands of books during a single lunch break. What AI is not good at is judging scientific validity. In this case, it can’t compete with an experienced researcher. While AI could help with hypothesis generation, the design of experiments and data analysis, it still cannot carry out sophisticated experiments.How far would you like to see the concept go?As I picture it, an AI Scientist could relieve researchers of some of the drudgery while letting people handle the creative aspects of science. That’s something we’re particularly good at. Rest assured, the goal is not to replace human scientists. I don’t envision—nor would I ever want to see—a machine substituting for, or interfering with, human creativity.Original story reprinted with permission from Quanta Magazine, an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.",
  "image": "https://media.wired.com/photos/682dbf2a520f1c62c099718e/191:100/w_1280,c_limit/RoseYu-cr.PeggyPeattie-Lede-scaled.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-testid=\"ArticlePageChunks\"\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003e\u003cem\u003e\u003cspan\u003eThe original version\u003c/span\u003e of\u003c/em\u003e \u003ca href=\"https://www.quantamagazine.org/improving-deep-learning-with-a-little-help-from-physics-20250423/\"\u003e\u003cem\u003ethis story\u003c/em\u003e\u003c/a\u003e \u003cem\u003eappeared in \u003ca href=\"https://www.quantamagazine.org\"\u003eQuanta Magazine\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\u003cp\u003eWhen she was 10 years old, \u003ca data-offer-url=\"https://roseyu.com/\" data-event-click=\"{\u0026#34;element\u0026#34;:\u0026#34;ExternalLink\u0026#34;,\u0026#34;outgoingURL\u0026#34;:\u0026#34;https://roseyu.com/\u0026#34;}\" href=\"https://roseyu.com/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eRose Yu\u003c/a\u003e got a birthday present that would change her life—and, potentially, the way we study physics. Her uncle got her a computer. That was a rare commodity in China 25 years ago, and the gift did not go unused. At first, Yu mainly played computer games, but in middle school she won an award for web design. It was the first of many computer-related honors.\u003c/p\u003e\u003cp\u003eYu went on to major in computer science at Zhejiang University, where she won a prize for innovative research. For her graduate studies, she chose the University of Southern California (USC), partly because the same uncle—who was the only person she knew in the United States—was then working at the Jet Propulsion Laboratory in nearby Pasadena. Yu earned her doctorate in 2017 with an award for best dissertation. Her most recent honor came in January, when President Joe Biden, in his last week in office, gave her a Presidential Early Career Award.\u003c/p\u003e\u003cp\u003eYu, now an associate professor at the University of California, San Diego (UCSD), is a leader in a field known as “physics-guided deep learning,” having spent years incorporating our knowledge of physics into artificial neural networks. The work has not only introduced novel techniques for building and training these systems, but it’s also allowed her to make progress on several real-world applications. She has drawn on principles of fluid dynamics to improve traffic predictions, sped up simulations of turbulence to enhance our understanding of hurricanes, and devised tools that helped predict the spread of Covid-19.\u003c/p\u003e\u003cp\u003eThis work has brought Yu closer to her grand dream—deploying a suite of digital lab assistants that she calls AI Scientist. She now envisions what she calls a “partnership” between human researchers and AI tools, fully based on the tenets of physics and thus capable of yielding new scientific insights. Combining inputs from a team of such assistants, in her opinion, may be the best way to boost the discovery process.\u003c/p\u003e\u003cp\u003eQuanta spoke with Yu about turbulence in its many guises, how to get more out of AI, and how it might get us out of urban gridlock. The interview has been condensed and edited for clarity.\u003c/p\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e\u003cp\u003eYu on the UCSD campus, where she is an associate professor.\u003c/p\u003e\n\u003c/span\u003e\u003cspan\u003ePhotograph: Peggy Peattie for \u003cem\u003eQuanta Magazine\u003c/em\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003e\u003cstrong\u003eWhen did you first try to combine physics with deep learning?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRose Yu:\u003c/strong\u003e It started with traffic. I was a grad student at USC, and the campus is right near the intersection of I-10 and I-110. To get anywhere, you have to go through a lot of traffic, which can be very annoying. In 2016, I began to wonder whether I could do anything about this.\u003c/p\u003e\u003cp\u003eDeep learning—which uses multilayered neural networks to elicit patterns from data—was getting really hot back then. There was already a lot of excitement about applications in image classification, but images are just static things. I wondered whether deep learning could help with problems where things are constantly changing. I wasn’t the first person to consider this, but my colleagues and I did find a novel way of framing the problem.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat was your new approach?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eFirst, we thought of traffic in terms of the physical process of diffusion. In our model, the flow of traffic over a network of roads is analogous to the flow of fluids over a surface—motions that are governed by the laws of fluid dynamics. But our main innovation was to think of traffic as a graph, from the mathematical field of graph theory. Sensors, which monitor traffic on highways and other roads, serve as the nodes of this graph. And the edges of the graph represent the roads (and distances) between those sensors.\u003c/p\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e\u003cp\u003eYu’s interest in computers began with a gift for her 10th birthday.\u003c/p\u003e\n\u003c/span\u003e\u003cspan\u003ePhotograph: Peggy Peattie for \u003cem\u003eQuanta Magazine\u003c/em\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003eA graph provides a snapshot of the entire road network at a given time, telling you the average velocity of cars at every point on the graph. When you put together a series of these snapshots, spaced every five minutes apart, you get a good picture of how traffic is evolving. From there, you can try to predict what will happen in the future.\u003c/p\u003e\u003cp\u003eThe big challenge in deep learning is that you need a lot of data to train the neural network. Fortunately, one of my advisers, Cyrus Shahabi, had worked for many years on the problem of traffic forecasting, and he’d accumulated a vast amount of LA traffic data that I had access to.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSo how good were your predictions?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003ePrior to our work, people could only make traffic forecasts that were reliable for about 15 minutes. Our forecasts were valid for one hour—a big improvement. Our code was deployed by Google Maps in 2018. A bit later, Google invited me to become a visiting researcher.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThat’s about when you began working on climate modeling, right?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eYes, that started in 2018, when I gave a talk at the Lawrence Berkeley National Laboratory. Afterward, I spoke with scientists there, and we looked for a problem that would be a good testbed for physics-guided deep learning. We settled on predicting the evolution of turbulent flow, which is a key factor in climate models, as well as an area of major uncertainty.\u003c/p\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003eFamiliar examples of turbulence are the swirling patterns you see after pouring milk into a cup of coffee and giving it a stir. In the oceans, swirls like this can span thousands of miles. Predictions of turbulent behavior that are based on solving the Navier-Stokes equation, which describes the flow of fluids, are considered the gold standard in this field. But the required calculations are very slow, which is why we don’t have good models for predicting hurricanes and tropical cyclones.\u003c/p\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e\u003cp\u003eThe heavy congestion of Los Angeles first inspired Yu to model highway traffic as the flow of fluids.\u003c/p\u003e\n\u003c/span\u003e\u003cspan\u003ePhotograph: Peggy Peattie for \u003cem\u003eQuanta Magazine\u003c/em\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003e\u003cstrong\u003eAnd deep learning can help?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThe basic idea is that deep neural networks that are trained on our best numerical simulations can learn to imitate—or as we say, “emulate”—those simulations. They do that by recognizing properties and patterns buried within the data. They don’t have to go through time-consuming, brute-force calculations to find approximate solutions. Our models sped up predictions by a factor of 20 in two-dimensional settings and by a factor of 1,000 in three-dimensional settings. Something like our turbulence prediction module might someday be inserted into bigger climate models that can do better at predicting things like hurricanes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhere else does turbulence show up?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIt’s pretty much everywhere. Turbulence in blood flow, for instance, can lead to strokes or heart attacks. And when I was a postdoc at Caltech, I coauthored a paper that looked into stabilizing drones. Propellor-generated airflows interact with the ground to create turbulence. That, in turn, can cause the drone to wobble. We used a neural network to model the turbulence, and that led to better control of drones during takeoffs and landings.\u003c/p\u003e\u003cp\u003eI’m currently working with scientists at UCSD and General Atomics on fusion power. One of the keys to success is learning how to control the plasma, which is a hot, ionized phase of matter. At temperatures of about 100 million degrees, different kinds of turbulence arise within the plasma, and physics-based numerical models that characterize that behavior are very slow. We’re developing a deep learning model that should be able to predict the plasma’s behavior in a split second, but this is still a work in progress.\u003c/p\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e\u003cp\u003eYu and doctoral student Jianke Yang in her office at UCSD.\u003c/p\u003e\n\u003c/span\u003e\u003cspan\u003ePhotograph: Peggy Peattie for \u003cem\u003eQuanta Magazine\u003c/em\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003e\u003cstrong\u003eWhere did your AI Scientist idea come from?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIn the past couple of years, my group has developed AI algorithms that can automatically discover symmetry principles from data. For example, our algorithm identified the Lorentz symmetry, which has to do with the constancy of the speed of light. Our algorithm also identified rotational symmetry—the fact, for example, that a sphere doesn’t look any different regardless of how you rotate it—which is something it was not specifically trained to know about. While these are well-known properties, our tools also have the capability to discover new symmetries presently unknown to physics, which would constitute a huge breakthrough.\u003c/p\u003e\u003cp\u003eIt then occurred to me that if our tools can discover symmetries from raw data, why don’t we try to generalize this? These tools could also generate research ideas or new hypotheses in science. That was the genesis of AI Scientist.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat exactly is AI Scientist—just a fancy kind of neural net?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eIt’s not a single neural network, but rather an ensemble of computer programs that can help scientists make new discoveries. My group has already developed algorithms that can help with individual tasks, such as weather forecasting, identifying the drivers of global temperature rise, or trying to discover causal relationships like the effects of vaccination policies on disease transmission.\u003c/p\u003e\u003c/div\u003e\u003cdiv data-journey-hook=\"client-content\" data-testid=\"BodyWrapper\"\u003e\u003cp\u003eWe’re now building a broader “foundation” model that’s versatile enough to handle multiple tasks. Scientists gather data from all types of instruments, and we want our model to include a variety of data types—numbers, text, images, and videos. We have an early prototype, but we want to make our model more comprehensive, more intelligent and better trained before we release it. That could happen within a couple of years.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat do you imagine it could do?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAI can assist in practically every step of the scientific discovery process. When I say “AI Scientist,” I really mean an AI scientific assistant. The literature survey stage in an experiment, for example, typically requires a massive data-gathering and organization effort. But now, a large language model can read and summarize thousands of books during a single lunch break. What AI is not good at is judging scientific validity. In this case, it can’t compete with an experienced researcher. While AI could help with hypothesis generation, the design of experiments and data analysis, it still cannot carry out sophisticated experiments.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow far would you like to see the concept go?\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAs I picture it, an AI Scientist could relieve researchers of some of the drudgery while letting people handle the creative aspects of science. That’s something we’re particularly good at. Rest assured, the goal is not to replace human scientists. I don’t envision—nor would I ever want to see—a machine substituting for, or interfering with, human creativity.\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003ca href=\"https://www.quantamagazine.org/improving-deep-learning-with-a-little-help-from-physics-20250423/\"\u003e\u003cem\u003eOriginal story\u003c/em\u003e\u003c/a\u003e \u003cem\u003ereprinted with permission from \u003ca href=\"https://www.quantamagazine.org\"\u003eQuanta Magazine\u003c/a\u003e, an editorially independent publication of the\u003c/em\u003e \u003ca href=\"https://www.simonsfoundation.org\"\u003e\u003cem\u003eSimons Foundation\u003c/em\u003e\u003c/a\u003e \u003cem\u003ewhose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2025-06-01T07:00:00-04:00",
  "modifiedTime": "2025-06-01T11:00:00Z"
}
