{
  "id": "d112470b-b5d0-4121-82b2-9a840037c015",
  "title": "AI fact checks can increase belief in false headlines, study finds",
  "link": "https://phys.org/news/2024-12-ai-fact-belief-false-headlines.html",
  "description": "Although many tech companies and start-ups have touted the potential of automated fact-checking services powered by artificial intelligence to stem the rising tide of online misinformation, a new study led by researchers at Indiana University has found that AI-fact checking can, in some cases, actually increase belief in false headlines whose veracity the AI was unsure about, as well as decrease belief in true headlines mislabeled as false.",
  "author": "",
  "published": "Wed, 04 Dec 2024 17:01:03 EST",
  "source": "https://phys.org/rss-feed/",
  "categories": [
    "Social Sciences Political science"
  ],
  "byline": "Indiana University",
  "length": 3676,
  "excerpt": "Although many tech companies and start-ups have touted the potential of automated fact-checking services powered by artificial intelligence to stem the rising tide of online misinformation, a new study led by researchers at Indiana University has found that AI-fact checking can, in some cases, actually increase belief in false headlines whose veracity the AI was unsure about, as well as decrease belief in true headlines mislabeled as false.",
  "siteName": "Phys.org",
  "favicon": "",
  "text": "Filippo Menczer, right, is the senior author on the study. Credit: Indiana University Although many tech companies and start-ups have touted the potential of automated fact-checking services powered by artificial intelligence to stem the rising tide of online misinformation, a new study led by researchers at Indiana University has found that AI-fact checking can, in some cases, actually increase belief in false headlines whose veracity the AI was unsure about, as well as decrease belief in true headlines mislabeled as false. The work also found that participants given the option to view headlines fact checked by large language model-powered AI were significantly more likely to share both true and false news—but only more likely to believe false headlines, not true headlines. The study, \"Fact-checking information from large language models can decrease headline discernment,\" was published Dec. 4 in the Proceedings of the National Academy of Sciences. The first author is Matthew DeVerna, a Ph.D. student at the Indiana University Luddy School of Informatics, Computing and Engineering in Bloomington. The senior author is Filippo Menczer, IU Luddy Distinguished Professor and director of IU's Observatory on Social Media. \"There is a lot of excitement about leveraging AI to scale up applications like fact-checking, as human fact-checkers cannot keep up with the volume of false or misleading claims spreading on social media, including content generated by AI,\" DeVerna said. \"However, our study highlights that when people interact with AI, unintended consequences can arise, highlighting how important it is to carefully consider how these tools are deployed.\" In the study, IU scientists specifically investigated the impact of fact-checking information generated by a popular large language model on belief in, and sharing intent of, political news headlines in a pre-registered randomized control experiment. Although the model accurately identified 90% of false headlines, the researchers found that this did not significantly improve participants' ability to distinguish between true and false headlines, on average. In contrast, the researchers found the use of human-generated fact checks did enhance users' discernment of true headlines. \"Our findings highlight an important source of potential harm stemming from AI applications and underscore the critical need for policies to prevent or mitigate such unintended consequences,\" said Menczer. \"More research is needed to improve the accuracy of AI fact-checking as well as understand the interactions between humans and AI better.\" Additional contributors to the paper were Kai-Cheng Yang of Northeastern University and Harry Yaojun Yan of the Stanford Social Media Lab. More information: Matthew R. DeVerna et al, Fact-checking information from large language models can decrease headline discernment, Proceedings of the National Academy of Sciences (2024). DOI: 10.1073/pnas.2322823121 Journal information: Proceedings of the National Academy of Sciences",
  "image": "https://scx2.b-cdn.net/gfx/news/hires/2024/ai-fact-checks-can-inc.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n        \u003cdiv\u003e\n\n                \n\u003cfigure data-lightbox=\"\"\u003e\n    \u003cdiv id=\"i1189221\"\u003e\n        \u003ca href=\"https://scx2.b-cdn.net/gfx/news/hires/2024/ai-fact-checks-can-inc.jpg\" target=\"_self\"\u003e\n            \u003cpicture\u003e\n                \u003csource srcset=\"https://scx1.b-cdn.net/csz/news/800a/2024/ai-fact-checks-can-inc.jpg?f=webp 800w, https://scx1.b-cdn.net/csz/news/500a/2024/ai-fact-checks-can-inc.jpg?f=webp 500w\" sizes=\"(max-width: 500px) 500px, 800px\" type=\"image/webp\"/\u003e\n                \u003csource srcset=\"https://scx1.b-cdn.net/csz/news/800a/2024/ai-fact-checks-can-inc.jpg 800w, https://scx1.b-cdn.net/csz/news/500a/2024/ai-fact-checks-can-inc.jpg 500w\" sizes=\"(max-width: 500px) 500px, 800px\"/\u003e\n                \u003cimg src=\"https://scx1.b-cdn.net/csz/news/800a/2024/ai-fact-checks-can-inc.jpg\" width=\"800\" height=\"530\" alt=\"AI fact checks can increase belief in false headlines\" title=\"Filippo Menczer, right, is the senior author on the study. Credit: Indiana University\" loading=\"lazy\"/\u003e\n            \u003c/picture\u003e\n        \u003c/a\u003e\n    \u003c/div\u003e\n\n            \u003cfigcaption\u003e\n            \u003cp\u003eFilippo Menczer, right, is the senior author on the study. Credit: Indiana University\u003c/p\u003e\n        \u003c/figcaption\u003e\n    \u003c/figure\u003e\u003cp\u003eAlthough many tech companies and start-ups have touted the potential of \u003ca href=\"https://medium.com/@rossnesbitt_62306/top-12-rising-ai-startups-fighting-fake-news-and-misinformation-e1a578aacbed\" target=\"_blank\"\u003eautomated fact-checking services\u003c/a\u003e powered by artificial intelligence to stem the rising tide of online misinformation, a new study led by researchers at Indiana University has found that AI-fact checking can, in some cases, actually increase belief in false headlines whose veracity the AI was unsure about, as well as decrease belief in true headlines mislabeled as false.\u003c/p\u003e\n\n                \n                                \n                \n                                                            \u003cp\u003eThe work also found that participants given the option to view headlines fact checked by large language model-powered AI were significantly more likely to share both true and false news—but only more likely to believe false headlines, not true headlines.\u003c/p\u003e\n\u003cp\u003eThe study, \u0026#34;Fact-checking information from large language models can decrease headline discernment,\u0026#34; was \u003ca href=\"https://pnas.org/doi/10.1073/pnas.2322823121\" target=\"_blank\"\u003epublished\u003c/a\u003e Dec. 4 in the \u003ci\u003eProceedings of the National Academy of Sciences\u003c/i\u003e. The first author is Matthew DeVerna, a Ph.D. student at the Indiana University Luddy School of Informatics, Computing and Engineering in Bloomington. The senior author is Filippo Menczer, IU Luddy Distinguished Professor and director of IU\u0026#39;s Observatory on Social Media.\u003c/p\u003e\n\u003cp\u003e\u0026#34;There is a lot of excitement about leveraging AI to scale up applications like fact-checking, as human fact-checkers cannot keep up with the volume of false or misleading claims spreading on social media, including content generated by AI,\u0026#34; DeVerna said. \u0026#34;However, our study highlights that when people interact with AI, unintended consequences can arise, highlighting how important it is to carefully consider how these tools are deployed.\u0026#34;\u003c/p\u003e\n\u003cp\u003eIn the study, IU scientists specifically investigated the impact of fact-checking information generated by a popular large language model on belief in, and sharing intent of, political news headlines in a pre-registered randomized control experiment.\u003c/p\u003e\n\n                                                                                  \n                                                                    \u003cp\u003eAlthough the model accurately identified 90% of false headlines, the researchers found that this did not significantly improve participants\u0026#39; ability to distinguish between true and false headlines, on average.\u003c/p\u003e\n\u003cp\u003eIn contrast, the researchers found the use of human-generated fact checks did enhance users\u0026#39; discernment of true headlines.\u003c/p\u003e\n\u003cp\u003e\u0026#34;Our findings highlight an important source of potential harm stemming from AI applications and underscore the critical need for policies to prevent or mitigate such unintended consequences,\u0026#34; said Menczer. \u0026#34;More research is needed to improve the accuracy of AI \u003ca href=\"https://phys.org/tags/fact-checking/\" rel=\"tag\"\u003efact-checking\u003c/a\u003e as well as understand the interactions between humans and AI better.\u0026#34;\u003c/p\u003e\n\u003cp\u003eAdditional contributors to the paper were Kai-Cheng Yang of Northeastern University and Harry Yaojun Yan of the Stanford Social Media Lab.\u003c/p\u003e\n\n                                                            \n                  \n\n\t\t\t\t\t\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\t\t                            \u003cp\u003e\n                                \u003cstrong\u003eMore information:\u003c/strong\u003e \n                                Matthew R. DeVerna et al, Fact-checking information from large language models can decrease headline discernment, \u003ci\u003eProceedings of the National Academy of Sciences\u003c/i\u003e (2024). \u003ca data-doi=\"1\" href=\"https://dx.doi.org/10.1073/pnas.2322823121\" target=\"_blank\"\u003eDOI: 10.1073/pnas.2322823121\u003c/a\u003e\n                            \u003c/p\u003e\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t                            \u003cp\u003e\n                                \u003cstrong\u003eJournal information:\u003c/strong\u003e \n                                \t\t\t\t\t\t\t\t\t\t\u003ca href=\"https://phys.org/journals/proceedings-of-the-national-academy-of-sciences/\"\u003eProceedings of the National Academy of Sciences\u003c/a\u003e\n                                                                                    \u003ca href=\"http://www.pnas.org/\" target=\"_blank\" rel=\"nofollow\"\u003e\n\t\t\t\t\t\t\t\t\t\t\t\t\u003ci\u003e\u003c/i\u003e\n\t\t\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n                                                                                 \n\t\t\t\t\t\t\t\t                            \u003c/p\u003e\n\t\t\t\t\t\t\t\t\t\t\t\u003c/div\u003e\n                \t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\n                                    \n                \n\n                \t\t\t\t\t    \n\t\t\t\t\u003c/div\u003e\n\t\t  \n    \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2024-12-04T17:01:03-05:00",
  "modifiedTime": null
}
