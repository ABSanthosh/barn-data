{
  "id": "8b4c30e9-9af5-4bd4-a03a-0d0a3d30e3d3",
  "title": "Apple Settles Claim for Siri Eavesdropping",
  "link": "https://www.scientificamerican.com/article/apple-settles-claim-for-siri-eavesdropping/",
  "description": "Apple is paying $95 million over claims that Siri secretly recorded private chats and fed targeted ads",
  "author": "",
  "published": "Tue, 20 May 2025 21:42:00 +0000",
  "source": "http://rss.sciam.com/ScientificAmerican-Global",
  "categories": null,
  "byline": "Deni Ellis Béchard",
  "length": 5119,
  "excerpt": "Apple is paying $95 million over claims that Siri secretly recorded private chats and fed targeted ads",
  "siteName": "Scientific American",
  "favicon": "",
  "text": "Is Your Tech Listening? Apple Settles Claim for Siri EavesdroppingApple is paying $95 million over claims that Siri secretly recorded private chats and fed targeted ads Artur Widak/NurPhoto via Getty ImagesSex, drug deals and doctor visits: according to allegations, Apple’s Siri eavesdropped on these and much more—on people’s iPhones, HomePods and Apple Watches—and used the content to target advertisements on users’ devices. Despite having denied selling our pillow talk to marketers, Apple just cut a $95-million check to settle a lawsuit in which plaintiffs reported eerie coincidences: discussing Air Jordan sneakers and immediately seeing ads for them; mentioning Olive Garden only to be served pasta commercials; talking privately with a doctor about a surgical procedure before seeing a promo for that very treatment. In early May the settlement administrator opened a claims website, allowing U.S. owners of every Siri-enabled gadget bought between September 2014 and December 2024 (essentially the lifespan of “Hey, Siri”) to request a payout of up to 20 bucks per affected device—enough for a drink and a wary glance at your phone.The lawsuit, Lopez v. Apple, dates back to July 2019, when the Guardian published the allegations of an anonymous whistleblower—an Apple subcontractor whose job was to listen to Siri recordings to determine if the voice-activated assistant was being correctly triggered. The whistleblower claimed that accidental Siri activations routinely captured sensitive audio. Despite Apple’s promises that Siri listens only when invited, background noises (often just the sound of a zipper, according to the whistleblower) could switch it on. The contractor said user location and contact information accompanied recordings.Apple had never explicitly told users that humans might review their Siri requests, and within a week of the Guardian report, the company halted the program. The first Lopez v. Apple complaint was filed in August 2019, and two weeks later Apple issued a public apology in which it promised to make human review opt-in-only and to stop retaining audio by default. That apology was framed to allay customer concerns—not as an admission of wrongdoing. Apple denied all allegations in the lawsuit, which is common in class-action settlements in U.S. courts.On supporting science journalismIf you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.If the situation sounds familiar, your memory works. In 2018 Amazon’s Alexa recorded a married couple’s conversation about hardwood floors and sent it to one of the husband’s employees. Amazon blamed an unlikely chain of misheard cues—basically, it came down to Alexa butt-dialing someone with living room chatter. The following year Bloomberg reported that Amazon had thousands of workers transcribing clips to fine-tune the assistant. Later Google faced similar allegations. The pattern was clear: robots needed to be trained to make sure that they were hearing voice commands correctly, and this training needed to come from humans who, in the process, inevitably heard things they shouldn’t via consumer gadgets. Even TVs were implicated: in 2015 Samsung warned owners not to discuss secrets near its smart sets because voice commands were sent to unnamed third parties, a disclaimer that could have been written by George Orwell.This isn’t tin-foil-hat territory. A 2019 survey found that 55 percent of Americans believe their phones listen to them to collect data for targeted ads, and a 2023 poll pushed the number north of 60 percent. In the U.K., a 2021 poll found two thirds of adults had noticed an ad that they felt was tied to a recent real-life chat. But psychologists say this perception of “conversation-related ad creep” often relies on a feedback loop driven by confirmation bias: we ignore the thousands of ads that form a constant backdrop to our lives but build a campfire legend from the one time we mentioned “fire,” and an app tried to sell us tiki torches. The result is a low-grade cultural fear, with people placing masking tape on device mics and TikTokers begging Siri to stop stalking them. Knowing how ravenous tech companies are for data, people can hardly be blamed for this attitude.As for Apple, which once put “What happens on your iPhone, stays on your iPhone” on a Las Vegas billboard, the settlement doesn’t force it to admit fault—but lands a dent in its titanium halo: If the Cupertino, Calif.–based company can’t keep a lid on hot-mic moments, who can?(Asked for comment by Scientific American, Apple shared information on the settlement and emphasized its commitment to privacy. And Amazon reiterated its commitment to privacy, writing, “Access to internal services is highly controlled, and is only granted to a limited number of employees who require these services to train and improve the service.” Samsung and Google had not responded to requests for comment by the time of publication.)",
  "image": "https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2\u003e\u003cp\u003eIs Your Tech Listening? Apple Settles Claim for Siri Eavesdropping\u003c/p\u003e\u003c/h2\u003e\u003cp\u003eApple is paying $95 million over claims that Siri secretly recorded private chats and fed targeted ads\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026amp;w=600\" alt=\"Person holding phone w/ SIRI logi in background\" srcset=\"https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026amp;w=600 600w, https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026amp;w=900 900w, https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/71404cd68146947d/original/Siri_eavesdropping.jpg?m=1747771898.768\u0026amp;w=1350 1350w\" sizes=\"(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw\" fetchpriority=\"high\"/\u003e\u003cfigcaption\u003e \u003cp\u003eArtur Widak/NurPhoto via Getty Images\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp data-block=\"sciam/paragraph\"\u003eSex, drug deals and doctor visits: according to allegations, Apple’s Siri eavesdropped on these and much more—on people’s iPhones, HomePods and Apple Watches—and used the content to target advertisements on users’ devices. Despite having denied selling our pillow talk to marketers, Apple just cut a $95-million check to settle a lawsuit in which plaintiffs reported eerie coincidences: discussing Air Jordan sneakers and immediately seeing ads for them; mentioning Olive Garden only to be served pasta commercials; talking privately with a doctor about a surgical procedure before seeing a promo for that very treatment. In early May the settlement administrator opened a claims website, allowing U.S. owners of every Siri-enabled gadget bought between September 2014 and December 2024 (essentially the lifespan of “Hey, Siri”) to request a payout of up to 20 bucks per affected device—enough for a drink and a wary glance at your phone.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe lawsuit, \u003ci\u003eLopez v. Apple,\u003c/i\u003e dates back to July 2019, when the \u003ci\u003eGuardian\u003c/i\u003e published the allegations of an anonymous whistleblower—an Apple subcontractor whose job was to listen to Siri recordings to determine if the voice-activated assistant was being correctly triggered. The whistleblower claimed that accidental Siri activations routinely captured sensitive audio. Despite Apple’s promises that Siri listens only when invited, background noises (often just the sound of a zipper, according to the whistleblower) could switch it on. The contractor said user location and contact information accompanied recordings.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eApple had never explicitly told users that humans might review their Siri requests, and within a week of the \u003ci\u003eGuardian\u003c/i\u003e report, the company halted the program. The first \u003ci\u003eLopez v. Apple\u003c/i\u003e complaint was filed in August 2019, and two weeks later Apple issued a public apology in which it promised to make human review opt-in-only and to stop retaining audio by default. That apology was framed to allay customer concerns—not as an admission of wrongdoing. Apple denied all allegations in the lawsuit, which is common in class-action settlements in U.S. courts.\u003c/p\u003e\u003chr/\u003e\u003ch2\u003eOn supporting science journalism\u003c/h2\u003e\u003cp\u003eIf you\u0026#39;re enjoying this article, consider supporting our award-winning journalism by \u003ca href=\"https://www.scientificamerican.com/getsciam/\"\u003esubscribing\u003c/a\u003e. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.\u003c/p\u003e\u003chr/\u003e\u003cp data-block=\"sciam/paragraph\"\u003eIf the situation sounds familiar, your memory works. In 2018 Amazon’s Alexa recorded a married couple’s conversation about hardwood floors and sent it to one of the husband’s employees. Amazon blamed an unlikely chain of misheard cues—basically, it came down to Alexa butt-dialing someone with living room chatter. The following year \u003ci\u003eBloomberg\u003c/i\u003e reported that Amazon had thousands of workers transcribing clips to fine-tune the assistant. Later Google faced similar allegations. The pattern was clear: robots needed to be trained to make sure that they were hearing voice commands correctly, and this training needed to come from humans who, in the process, inevitably heard things they shouldn’t via consumer gadgets. Even TVs were implicated: in 2015 Samsung warned owners not to discuss secrets near its smart sets because voice commands were sent to unnamed third parties, a disclaimer that could have been written by George Orwell.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThis isn’t tin-foil-hat territory. A \u003ca href=\"https://www.forbes.com/sites/johnkoetsier/2019/05/31/55-of-americans-say-smartphones-spy-on-conversations-to-customize-ads/\"\u003e2019 survey\u003c/a\u003e found that 55 percent of Americans believe their phones listen to them to collect data for targeted ads, and a \u003ca href=\"https://www.digitalthirdcoast.com/blog/phones-and-privacy-2023\"\u003e2023 poll\u003c/a\u003e pushed the number north of 60 percent. In the U.K., a \u003ca href=\"https://yougov.co.uk/technology/articles/37065-my-phone-listening-my-conversations-britons-believ\"\u003e2021 poll\u003c/a\u003e found two thirds of adults had noticed an ad that they felt was tied to a recent real-life chat. But psychologists say this perception of “conversation-related ad creep” often relies on a feedback loop driven by confirmation bias: we ignore the thousands of ads that form a constant backdrop to our lives but build a campfire legend from the one time we mentioned “fire,” and an app tried to sell us tiki torches. The result is a low-grade cultural fear, with people placing masking tape on device mics and TikTokers begging Siri to stop stalking them. Knowing how ravenous tech companies are for data, people can hardly be blamed for this attitude.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAs for Apple, which once put “What happens on your iPhone, stays on your iPhone” on a \u003ca href=\"https://x.com/chrisvelazco/status/1081330848262062080\"\u003eLas Vegas billboard\u003c/a\u003e, the settlement doesn’t force it to admit fault—but lands a dent in its titanium halo: If the Cupertino, Calif.–based company can’t keep a lid on hot-mic moments, who can?\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003e(Asked for comment by \u003ci\u003eScientific American,\u003c/i\u003e Apple shared \u003ca href=\"https://www.lopezvoiceassistantsettlement.com/faqs\"\u003einformation on the settlement\u003c/a\u003e and emphasized its \u003ca href=\"https://www.apple.com/newsroom/2025/01/our-longstanding-privacy-commitment-with-siri/\"\u003ecommitment to privacy\u003c/a\u003e. And Amazon reiterated its \u003ca href=\"https://www.amazon.com/b/?node=19149155011\u0026amp;ref=aph_ing\"\u003ecommitment to privacy\u003c/a\u003e, writing, “Access to internal services is highly controlled, and is only granted to a limited number of employees who require these services to train and improve the service.” Samsung and Google had not responded to requests for comment by the time of publication.)\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-05-20T17:42:00-04:00",
  "modifiedTime": null
}
