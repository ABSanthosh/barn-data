{
  "id": "89828eaa-cf9a-49b5-94c0-39a75d03d9d3",
  "title": "New Open Source DeepSeek V3 Language Model Making Waves",
  "link": "https://hackaday.com/2025/01/27/new-open-source-deepseek-v3-language-model-making-waves/",
  "description": "In the world of large language models (LLMs) there tend to be relatively few upsets ever since OpenAI barged onto the scene with its transformer-based GPT models a few years …read more",
  "author": "Maya Posch",
  "published": "Mon, 27 Jan 2025 21:00:11 +0000",
  "source": "https://hackaday.com/blog/feed/",
  "categories": [
    "Artificial Intelligence",
    "ai",
    "large language model"
  ],
  "byline": "",
  "length": 1242,
  "excerpt": "In the world of large language models (LLMs) there tend to be relatively few upsets ever since OpenAI barged onto the scene with its transformer-based GPT models a few years ago, yet now it seems t…",
  "siteName": "Hackaday",
  "favicon": "https://hackaday.com/wp-content/themes/hackaday-2/img/hackaday-logo_1024x1024.png?v=3",
  "text": "Skip to content In the world of large language models (LLMs) there tend to be relatively few upsets ever since OpenAI barged onto the scene with its transformer-based GPT models a few years ago, yet now it seems that Chinese company DeepSeek has upended the status quo. Its new DeepSeek-V3 model is not only open source, it also claims to have been trained for only a fraction of the effort required by competing (open \u0026 closed source) models, while performing significantly better. The full training of DeepSeek-V3’s 671B parameters is claimed to have only taken 2.788M hours on NVidia H800 (Hopper-based) GPUs, which is almost a factor of ten less than others. Naturally this has the LLM industry somewhat up in a mild panic, but for those who are not investors in LLM companies or NVidia can partake in this new OSS model that has been released under the MIT license, along with the DeepSeek-R1 reasoning model. Both of these models can be run locally, using both AMD and NVidia GPUs, as well as using the online APIs. If these models do indeed perform as efficiently as claimed, they stand to massively reduce the hardware and power required to not only train but also query LLMs.",
  "image": "https://hackaday.com/wp-content/uploads/2025/01/deepseek-v3_benchmark.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"page\"\u003e\n    \n\n    \u003cp\u003e\u003ca href=\"#content\"\u003eSkip to content\u003c/a\u003e\u003c/p\u003e\n\n    \u003cdiv id=\"content\"\u003e\n        \u003cmain id=\"main\" role=\"main\"\u003e\n\n        \n            \n\u003carticle itemscope=\"\" itemtype=\"http://schema.org/Article\" id=\"post-756516\"\u003e\n    \n\n    \u003cdiv itemprop=\"articleBody\"\u003e\n        \u003cp\u003eIn the world of large language models (LLMs) there tend to be relatively few upsets ever since OpenAI barged onto the scene with its transformer-based GPT models a few years ago, yet now it seems that Chinese company DeepSeek has upended the status quo. Its new \u003ca href=\"https://github.com/deepseek-ai/DeepSeek-V3\" target=\"_blank\"\u003eDeepSeek-V3 model\u003c/a\u003e is not only open source, it also claims to have been trained for only a fraction of the effort required by competing (open \u0026amp; closed source) models, while \u003ca href=\"https://arxiv.org/abs/2412.19437v1\" target=\"_blank\"\u003eperforming significantly better\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe full training of DeepSeek-V3’s 671B parameters is claimed to have only taken 2.788M hours on NVidia H800 (\u003ca href=\"https://www.techpowerup.com/gpu-specs/h800-sxm5.c3975\" target=\"_blank\"\u003eHopper-based\u003c/a\u003e) GPUs, which is almost a factor of ten less than others. Naturally this has the LLM industry somewhat up in a mild panic, but for those who are not investors in LLM companies or NVidia can partake in this new OSS model that has been released under the MIT license, along with the \u003ca href=\"https://github.com/deepseek-ai/DeepSeek-R1\" target=\"_blank\"\u003eDeepSeek-R1 reasoning model\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBoth of these models can be run locally, using both AMD and NVidia GPUs, as well as using the online APIs. If these models do indeed perform as efficiently as claimed, they stand to massively reduce the hardware and power required to not only train but also query LLMs.\u003c/p\u003e\n\t            \u003c/div\u003e\n    \u003cul\u003e\n    \t\t\t\t\t\u003cli\u003e\n    \t\t\t\t\u003ca href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fhackaday.com%2F2025%2F01%2F27%2Fnew-open-source-deepseek-v3-language-model-making-waves%2F\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_face.png\"/\u003e \u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n                        \u003ca href=\"https://twitter.com/intent/tweet?text=New%20Open%20Source%20DeepSeek%20V3%20Language%20Model%20Making%20Waves%20via%20@hackaday\u0026amp;url=https://hackaday.com/2025/01/27/new-open-source-deepseek-v3-language-model-making-waves/\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_twitter.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n    \t\t\t\t\u003ca href=\"https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fhackaday.com%2F2025%2F01%2F27%2Fnew-open-source-deepseek-v3-language-model-making-waves%2F\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_in.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n                \u003ca href=\"mailto:?subject=New+Open+Source+DeepSeek+V3+Language+Model+Making+Waves | Hackaday\u0026amp;body=https%3A%2F%2Fhackaday.com%2F2025%2F01%2F27%2Fnew-open-source-deepseek-v3-language-model-making-waves%2F\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_mail1.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\u003c/ul\u003e\n    \n\u003c/article\u003e\n\n            \t\n\t\n            \n\n            \n\n\n        \n        \n\n        \n        \n\n        \n        \u003c/main\u003e\n    \u003c/div\u003e\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": "2025-01-27T21:00:11Z",
  "modifiedTime": "2025-01-27T22:34:40Z"
}
