{
  "id": "6a4c624e-c3bf-4549-b4ec-74535e973f10",
  "title": "The Reasoning Computer",
  "link": "https://fabisevi.ch/2023/11/10/the-reasoning-computer/",
  "description": "The Turing test is dead, and we killed it. The Turing test is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. From the 1940s 1 to the 2010s people programmed computers, and computers could only do what they were programmed to do in a rules-based deterministic manner. Sometimes a person would program the computer and it would do something unexpected, but 100 out of 100 times the computer was doing what it was programmed to do whether the person liked it or not. While there has been experimentation with what today we call AI since the 1950s, those machines were a long ways away from passing the Turing test. Why does using ChatGPT feel more like a conversation with the smartest person you know than a computer? It's because ChatGPT doesn't solve problems deterministically the way a programmed computer does, it solves them probabilistically. 2 ChatGPT demonstrates the ability to think about something in a logical, sensible way, the definition of reasoning. 3 We've created something completely new here, a reasoning computer. 4",
  "author": "Joe Fabisevich",
  "published": "Fri, 10 Nov 2023 00:00:00 GMT",
  "source": "https://www.fabisevi.ch/feed.xml",
  "categories": null,
  "byline": "",
  "length": 7513,
  "excerpt": "The Turing test is dead, and we killed it. The Turing test is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. From the 1940s to the 2010s people programmed computers, and computers could only do what they were programmed to do in a rules-based deterministic manner. Sometimes a person would program the computer and it would do something unexpected, but 100 out of 100 times the computer was doing what it was programmed to do whether the person liked it or not. While there has been experimentation with what today we call AI since the 1950s, those machines were a long ways away from passing the Turing test. Why does using ChatGPT feel more like a conversation with the smartest person you know than a computer? It's because ChatGPT doesn't solve problems deterministically the way a programmed computer does, it solves them probabilistically. ChatGPT demonstrates the ability to think about something in a logical, sensible way, the definition of reasoning. We've created something completely new here, a reasoning computer.",
  "siteName": "",
  "favicon": "https://fabisevi.ch/icons/icon-512x512.png?v=b60b950dc439294a707fb76cdaca4274",
  "text": "The Turing test is dead, and we killed it. The Turing test is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. From the 1940s 1 to the 2010s people programmed computers, and computers could only do what they were programmed to do in a rules-based deterministic manner. Sometimes a person would program the computer and it would do something unexpected, but 100 out of 100 times the computer was doing what it was programmed to do whether the person liked it or not. While there has been experimentation with what today we call AI since the 1950s, those machines were a long ways away from passing the Turing test. Why does using ChatGPT feel more like a conversation with the smartest person you know than a computer? It's because ChatGPT doesn't solve problems deterministically the way a programmed computer does, it solves them probabilistically. 2 ChatGPT demonstrates the ability to think about something in a logical, sensible way, the definition of reasoning. 3 We've created something completely new here, a reasoning computer. 4 Working With A Reasoning Computer There are so many political, societal, economic, and ethical implications of Large Language Models (LLMs), 5,000 words wouldn’t be enough to cover all those thoughts. (Trust me, there’s a much longer post sitting in my drafts.) But what’s really captivated me is why a reasoning computer really is different than anything we’ve used before, a conclusion I could only arrive at through experience. ChatGPT has been an essential tool for me over the last month, especially over the last week as I've been building Plinky's browser extension. I'm a very experienced iOS developer but have little experience with web development. I know enough TypeScript and React to cobble together something with lots of help and guidance, but it will take me much longer than someone who knows what they're doing. A browser extension is important for Plinky to be successful though, which presents a unique challenge: I know what I want, I know how to describe it, I don't quite know how to get it, but I will know when ChatGPT gives me the wrong answer so with some nudging I can get what I'm looking for. Here's why the process of pairing with ChatGPT works, and how it helped me build a fully functional browser extension that lives up to my standards in less than a week. (With far less frustration than if you took away the tool and gave me a whole month.) A simple browser extension to save links to Plinky's database is a much smaller problem than building a whole app. The problem is self-contained, which makes it quick and easy to test ChatGPT’s results and see if the output matches my expectations. In fields like mathematics or computer science it's generally easier to verify a solution's correctness than come up with a solution in the first place. I may be a novice web developer but I'm a great programmer. Even in a domain where I’m not comfortable I can describe the problem I'm trying to solve, assess whether a solution is good, do some research (on my own or with the aid of Perplexity and ChatGPT), and nudge the reasoning computer in the right direction. This isn't a process where I ask for something and am given exactly what I want, but I can promise you it's much easier than becoming a good enough TypeScript developer to build the high quality browser extension I want. Little by little the browser extension looks and works more and more how I want it to be, until it does exactly what I want it to do. The whole process is interactive so I’m learning about how to get to the right solution. Not only do I have what I want, but this iteration made me a better web developer, I started off only knowing what the wrong output looks like but now I also know how the correct solution should look. This is just one example of how I was able to accomplish something I previously wouldn't have been able to do thanks to an LLM, the number of tasks I turn to LLMs for is growing every day. The same way that GPS becoming ever-present means I haven't opened a map in almost two decades, I find myself turning to ChatGPT or Perplexity rather than opening Google and clicking a bunch of links to find answers. I used to do my own research, I used to be the reasoning machine, but now I'm offloading more and more of that work to Large Language Models. How Can A Reasoning Computer Even Work? People will say that ChatGPT can't do math, and that's true in the most literal sense. A Large Language Model may not know what addition and subtraction mean to a human, but it can synthesize the correct results to add and subtract numbers better than a person. Similarly people point out that ChatGPT can't read, because it's just a stochastic parrot that means it can't provide intelligible output. It's true that LLMs are complex statistical models, yet despite ChatGPT not knowing English from Urdu the way people do it's still capable of translating from English to Urdu to Russian to French in a way that I never would be able to. The fact that Github Copilot 5 doesn't actually know the difference between JavaScript and Swift hasn't stopped it from making programmers 55% faster at coding. Large Language Models use a different form of problem solving that starts with inputs and extrapolates technique. That's the reverse of how humans believe they develop their skills, if you study hard, read a lot, and put in enough hours as a writer you too can become the next Faulkner or Shakespeare. But think about the way you first learned your native language, you listened and watched the world around you for 1-2 years, then reverse-engineered how the technique works. We're reasoning machines too, the difference is that the entirety of the internet wasn't preloaded into our brains the way it was into an LLM. (For the best, I don't know if you know but there's some bad shit on the internet.) When we say ChatGPT can't do this or ChatGPT can't do that what we're doing is anthropomorphizing flaws onto the system, derived from our own experiences of solving problems successfully. The problem solving process may be difficult for people to understand because this is the first computer that doesn't do exactly what you tell it to do. Our intuitions may view this as a flaw, but OpenAI loading the whole internet into ChatGPT and creating a simple model for how to think rather than directly programming the machine is the reason this computer is incredibly useful in new and previously unexplored ways. Simon Willison says that these tools make you more ambitious with what you can accomplish, and I'd like to build upon his axiom. When you have a reasoning computer you only have to know what the wrong result looks like, not how to get the right result, and that alone has the power to change how society solves problems. Joe Fabisevich is an indie developer creating software at Red Panda Club Inc. while writing about design, development, and building a company. Formerly an iOS developer working on societal issues @Twitter. These days I don't tweet, but I do post on Threads.Like my writing? You can keep up with it in your favorite RSS reader, or get posts emailed in newsletter form. I promise to never spam you or send you anything other than my posts, it's just a way for you to read my writing wherever's most comfortable for you.If you'd like to know more, wanna talk, or need some advice, feel free to sign up for office hours, I'm very friendly. 🙂",
  "image": "https://fabisevi.ch/static/pic-f5999ef8dd476bfbf9d65ddbace7e387.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003eThe Turing test is dead, and we killed it. The \u003ca href=\"https://en.wikipedia.org/wiki/Turing_test\"\u003eTuring test\u003c/a\u003e is a test of a machine\u0026#39;s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. From the 1940s \u003csup id=\"fnref-1\"\u003e\u003ca href=\"#fn-1\"\u003e1\u003c/a\u003e\u003c/sup\u003e to the 2010s people programmed computers, and computers could only do what they were programmed to do in a rules-based deterministic manner. Sometimes a person would program the computer and it would do something unexpected, but 100 out of 100 times the computer was doing what it was programmed to do whether the person liked it or not. While there has been experimentation with what today we call AI since the 1950s, those machines were a long ways away from passing the Turing test.\u003c/p\u003e\n\u003cp\u003eWhy does using \u003ca href=\"https://chat.openai.com\"\u003eChatGPT\u003c/a\u003e feel more like a conversation with the smartest person you know than a computer? It\u0026#39;s because ChatGPT doesn\u0026#39;t solve problems deterministically the way a programmed computer does, it solves them probabilistically. \u003csup id=\"fnref-2\"\u003e\u003ca href=\"#fn-2\"\u003e2\u003c/a\u003e\u003c/sup\u003e ChatGPT demonstrates the ability to think about something in a logical, sensible way, the definition of \u003ca href=\"https://www.oxfordlearnersdictionaries.com/us/definition/english/reasoning\"\u003ereasoning\u003c/a\u003e. \u003csup id=\"fnref-3\"\u003e\u003ca href=\"#fn-3\"\u003e3\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003cp\u003eWe\u0026#39;ve created something completely new here, \u003cstrong\u003ea reasoning computer.\u003c/strong\u003e \u003csup id=\"fnref-4\"\u003e\u003ca href=\"#fn-4\"\u003e4\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\n\u003ch3 id=\"working-with-a-reasoning-computer\"\u003e\u003ca href=\"#working-with-a-reasoning-computer\" aria-label=\"working with a reasoning computer permalink\"\u003e\u003c/a\u003eWorking With A Reasoning Computer\u003c/h3\u003e\n\u003cp\u003eThere are so many political, societal, economic, and ethical implications of Large Language Models (LLMs), 5,000 words wouldn’t be enough to cover all those thoughts. (Trust me, there’s a much longer post sitting in my drafts.) But what’s really captivated me is why a reasoning computer really is different than anything we’ve used before, a conclusion I could only arrive at through experience.\u003c/p\u003e\n\u003cp\u003eChatGPT has been an essential tool for me over the last month, especially over the last week as I\u0026#39;ve been building \u003ca href=\"https://plinky.app\"\u003ePlinky\u0026#39;s\u003c/a\u003e browser extension. I\u0026#39;m a very experienced iOS developer but have little experience with web development. I know enough TypeScript and React to cobble together something with lots of help and guidance, but it will take me much longer than someone who knows what they\u0026#39;re doing.\u003c/p\u003e\n\u003cp\u003eA browser extension is important for Plinky to be successful though, which presents a unique challenge: I know what I want, I know how to describe it, I don\u0026#39;t quite know how to get it, but I will know when ChatGPT gives me the wrong answer so with some nudging I can get what I\u0026#39;m looking for. Here\u0026#39;s why the process of pairing with ChatGPT works, and how it helped me build a fully functional browser extension that lives up to my standards in less than a week. (With far less frustration than if you took away the tool and gave me a whole month.)\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eA simple browser extension to save links to Plinky\u0026#39;s database is a much smaller problem than building a whole app. The problem is self-contained, which makes it quick and easy to test ChatGPT’s results and see if the output matches my expectations. In fields like mathematics or computer science it\u0026#39;s generally easier to verify a solution\u0026#39;s correctness than come up with a solution in the first place.\u003c/li\u003e\n\u003cli\u003eI may be a novice web developer but I\u0026#39;m a great programmer. Even in a domain where I’m not comfortable I can describe the problem I\u0026#39;m trying to solve, assess whether a solution is good, do some research (on my own or with the aid of \u003ca href=\"https://perplexity.ai\"\u003ePerplexity\u003c/a\u003e and ChatGPT), and nudge the reasoning computer in the right direction.\u003c/li\u003e\n\u003cli\u003eThis isn\u0026#39;t a process where I ask for something and am given exactly what I want, but I can promise you it\u0026#39;s much easier than becoming a good enough TypeScript developer to build the high quality browser extension I want.\u003c/li\u003e\n\u003cli\u003eLittle by little the browser extension looks and works more and more how I want it to be, until it does exactly what I want it to do.\u003c/li\u003e\n\u003cli\u003eThe whole process is interactive so I’m learning about how to get to the right solution. Not only do I have what I want, but this iteration made me a better web developer, I started off only knowing what the wrong output looks like but now I also know how the correct solution should look.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr/\u003e\n\u003cp\u003eThis is just one example of how I was able to accomplish something I previously wouldn\u0026#39;t have been able to do thanks to an LLM, the number of tasks I turn to LLMs for is growing every day. The same way that GPS becoming ever-present means I haven\u0026#39;t opened a map in almost two decades, I find myself turning to ChatGPT or Perplexity rather than opening Google and clicking a bunch of links to find answers. I used to do my own research, I used to be the reasoning machine, but now I\u0026#39;m offloading more and more of that work to Large Language Models.\u003c/p\u003e\n\u003ch3 id=\"how-can-a-reasoning-computer-even-work\"\u003e\u003ca href=\"#how-can-a-reasoning-computer-even-work\" aria-label=\"how can a reasoning computer even work permalink\"\u003e\u003c/a\u003eHow Can A Reasoning Computer Even Work?\u003c/h3\u003e\n\u003cp\u003ePeople will say that ChatGPT can\u0026#39;t do math, and that\u0026#39;s true in the most literal sense. A Large Language Model may not know what addition and subtraction mean to a human, but it can synthesize the correct results to add and subtract numbers better than a person. Similarly people point out that ChatGPT can\u0026#39;t read, because it\u0026#39;s just a \u003ca href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\"\u003estochastic parrot\u003c/a\u003e that means it can\u0026#39;t provide intelligible output. It\u0026#39;s true that LLMs are complex statistical models, yet despite ChatGPT not knowing English from Urdu the way people do it\u0026#39;s still capable of translating from English to Urdu to Russian to French in a way that I never would be able to. The fact that Github Copilot \u003csup id=\"fnref-5\"\u003e\u003ca href=\"#fn-5\"\u003e5\u003c/a\u003e\u003c/sup\u003e doesn\u0026#39;t actually know the difference between JavaScript and Swift hasn\u0026#39;t stopped it from \u003ca href=\"https://resources.github.com/copilot-for-business/\"\u003emaking programmers 55% faster at coding\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLarge Language Models use a different form of problem solving that starts with inputs and extrapolates technique. That\u0026#39;s the reverse of how humans believe they develop their skills, if you study hard, read a lot, and put in enough hours as a writer you too can become the next Faulkner or Shakespeare. But think about the way you first learned your native language, you listened and watched the world around you for 1-2 years, then reverse-engineered how the technique works. We\u0026#39;re reasoning machines too, the difference is that the entirety of the internet wasn\u0026#39;t preloaded into our brains the way it was into an LLM. (For the best, I don\u0026#39;t know if you know but there\u0026#39;s some bad shit on the internet.)\u003c/p\u003e\n\u003cp\u003eWhen we say ChatGPT can\u0026#39;t do this or ChatGPT can\u0026#39;t do that what we\u0026#39;re doing is anthropomorphizing flaws onto the system, derived from our own experiences of solving problems successfully. The problem solving process may be difficult for people to understand because this is the first computer that doesn\u0026#39;t do exactly what you tell it to do. Our intuitions may view this as a flaw, but OpenAI loading the whole internet into ChatGPT and creating \u003ca href=\"https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/\"\u003ea simple model for how to think\u003c/a\u003e rather than directly programming the machine is the reason this computer is incredibly useful in new and previously unexplored ways.\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003e\u003ca href=\"https://fedi.simonwillison.net/@simon\"\u003eSimon Willison\u003c/a\u003e says that these tools \u003ca href=\"https://simonwillison.net/2023/Mar/27/ai-enhanced-development/\"\u003emake you more ambitious with what you can accomplish\u003c/a\u003e, and I\u0026#39;d like to build upon his axiom. When you have a reasoning computer you only have to know what the wrong result looks like, not how to get the right result, and that alone has the power to change how society solves problems.\u003c/p\u003e\n\u003c/div\u003e\u003cp\u003eJoe Fabisevich is an indie developer creating software at \u003ca href=\"https://redpanda.club\"\u003eRed Panda Club Inc.\u003c/a\u003e while writing about design, development, and building a company. Formerly an iOS developer working on societal issues \u003ca href=\"https://threads.net/mergesort\"\u003e@Twitter\u003c/a\u003e. These days I don\u0026#39;t tweet, but I do post on \u003ca href=\"https://threads.net/mergesort\"\u003eThreads\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eLike my writing? You can keep up with it in your favorite \u003ca href=\"https://fabisevi.ch/feed.xml\"\u003eRSS\u003c/a\u003e reader, or get posts \u003ca href=\"https://mailchi.mp/3237be1819ae/fabisevich-blog-posts\"\u003eemailed\u003c/a\u003e in newsletter form. I promise to never spam you or send you anything other than my posts, it\u0026#39;s just a way for you to read my writing wherever\u0026#39;s most comfortable for you.\u003c/p\u003e\u003cp\u003eIf you\u0026#39;d like to know more, wanna talk, or need some advice, feel free to sign up for \u003ca href=\"https://cal.com/mergesort/office-hours\"\u003eoffice hours\u003c/a\u003e, I\u0026#39;m very friendly. 🙂\u003c/p\u003e\u003c/div\u003e\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": null,
  "modifiedTime": null
}
