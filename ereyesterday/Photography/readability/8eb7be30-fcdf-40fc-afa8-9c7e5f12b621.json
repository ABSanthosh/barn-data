{
  "id": "8eb7be30-fcdf-40fc-afa8-9c7e5f12b621",
  "title": "Robot Photographer Can Snap the Photo You Have in Mind",
  "link": "https://petapixel.com/2024/11/26/robot-photographer-can-snap-the-photo-you-have-in-mind/",
  "description": "Photographers struggling to find the perfect angle for a group shot have often relied upon clumsy tripods, clunky self-timers, or, worst of all, missing out on being in the frame to take the photo themselves. Enter PhotoBot, a robot photographer who promises to capture a good shot and can take instructions and use a reference photo when finding the ideal composition. [Read More]",
  "author": "Jeremy Gray",
  "published": "Tue, 26 Nov 2024 21:39:03 +0000",
  "source": "https://petapixel.com/feed/",
  "categories": [
    "News",
    "Technology",
    "ai",
    "artificialintelligence",
    "photoassistant",
    "photobot",
    "research",
    "robot",
    "science"
  ],
  "byline": "Jeremy Gray",
  "length": 5307,
  "excerpt": "This robot wants to be a helpful photographer.",
  "siteName": "PetaPixel",
  "favicon": "https://petapixel.com/wp-content/themes/petapixel-2017/assets/prod/img/apple-touch-icon-180x180.png",
  "text": "Fig. 1: PhotoBot provides a reference photograph suggestion based on an observation of the scene and a user’s input language query (upper left). The user strikes a pose matching that of the person in the reference photo (upper right) and PhotoBot adjusts its camera accordingly to faithfully capture the layout and composition of the reference image (lower left). The lower-right panel shows an unretouched photograph produced by PhotoBot. Photographers struggling to find the perfect angle for a group shot have often relied upon clumsy tripods, clunky self-timers, or, worst of all, missing out on being in the frame to take the photo themselves. Enter PhotoBot, a robot photographer who promises to capture a good shot and can take instructions and use a reference photo when finding the ideal composition. “We introduce PhotoBot, a framework for fully automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer,” the researchers explain. “We propose to communicate photography suggestions to the user via reference images that are selected from a curated gallery.” “It was a really fun project,” PhotoBot co-creator and researcher Oliver Limoyo tells Spectrum IEEE. Limoyo worked on the project while working at Samsung alongside manager and co-author Jimmy Li. Say cheese! We introduce PhotoBot, a framework for fully automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. PhD candidate @OliverLimoyo will present this work at #IROS2024!Paper: https://t.co/DHGFvfOKJf pic.twitter.com/BPrxDkMxlD — STARS Laboratory (@utiasSTARS) October 3, 2024 Limoyo and Li were already working on a robot that could take pictures when they saw the Getty Image Challenge during COVID lockdowns. This challenge tasked people with recreating their favorite artworks using only three objects they found around their homes. It was a fun, exciting way to keep people engaged and connected during the early days of the pandemic. Beyond achieving this worthwhile task, Getty’s competition also inspired Limoyo and Li to have their PhotoBot use a reference image to inform its novel photo captures. As Spectrum IEEE explains, they had to then engineer a way for PhotoBot to accurately match a reference photo and adjust its camera to match that image. Fig. 2: PhotoBot system diagram. The two main modules are shown: Reference Suggestion and Camera View Adjustment. Given the observed scene and a user query, PhotoBot suggests a reference image to the user and adjusts the camera to take a photo with a similar layout and composition to the reference image. It is even more sophisticated in practice than it initially sounds. PhotoBot requires a written description of the type of photo a person wants. The robot then analyzes its environment, identifying people and objects within its line of sight. PhotoBot finds similar photos with corresponding labels within its database. Next, a large language model (LLM) compares the user’s text input with the objects around PhotoBot and its database to select appropriate reference photographs. Suppose a person wants a picture of them looking happy and is surrounded by a few friends, some flowers in a vase, and maybe a pizza. PhotoBot will see all this, label the people and objects, and then find photos within its database that best match the requested photo and include similar components. Once the user selects the reference shot they like best, PhotoBot will adjust its camera to match the framing and perspective of the reference image. Again, this is a more complex situation than it initially seems, as PhotoBot operates within a three-dimensional space but is trying to match the look of a two-dimensional reference photo. As for how good PhotoBot is at its job, photographers shouldn’t necessarily panic about the impending reality of a robot photographer. However, PhotoBot did a good job, beating eight humans about two-thirds of the time in terms of respondent preference. Fig. 5: Sample photos of users evoking various emotions. The user prompts, from top to bottom, are surprised, confident, guilty, confident, happy, and confident. Columns, from left to right, are: user’s own creative posing; user mimicking the suggested reference using a static camera; photo taken by our PhotoBot system; and reference image suggested by PhotoBot. The checkered background indicates cropping. The black background indicates padding of the reference image to facilitate the PnP solution. PhotoBot automatically crops the photos it takes to match the image template. Li and the rest of the team are no longer working on PhotoBot, but the creator thinks their work has possible implications for smartphone photo assistant apps. “Imagine right on your phone, you see a reference photo. But you also see what the phone is seeing right now, and then that allows you to move around and align,” Li remarks. Image credits: Photos from the research paper, ‘PhotoBot: Reference-Guided Interactive Photography via Natural Language,’ by Limoyo, Li, Rivkin, Kelly, and Dudek. PetaPixel articles may include affiliate links; if you buy something through such a link, PetaPixel may earn a commission.",
  "image": "https://petapixel.com/assets/uploads/2024/11/photobot-4.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\t\t\t\n\u003carticle data-post-id=\"770201\"\u003e\n\n    \u003cheader\u003e\n          \n    \n\n        \n  \u003c/header\u003e\n      \n  \n\n  \u003cdiv\u003e\n    \u003cdiv\u003e\n      \u003cfigure id=\"attachment_770203\" aria-describedby=\"caption-attachment-770203\"\u003e\u003cimg data-perfmatters-preload=\"\" fetchpriority=\"high\" decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2024/11/photobot-2-800x665.jpg\" alt=\"A comic strip of a man interacting with a robotic arm, which suggests a pose and adjusts the camera view for a photo. The man follows the instructions, wearing glasses and a navy sweater with white stripes.\" width=\"800\" height=\"665\" srcset=\"https://petapixel.com/assets/uploads/2024/11/photobot-2-800x665.jpg 800w, https://petapixel.com/assets/uploads/2024/11/photobot-2-320x266.jpg 320w, https://petapixel.com/assets/uploads/2024/11/photobot-2-1536x1276.jpg 1536w, https://petapixel.com/assets/uploads/2024/11/photobot-2.jpg 1600w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption id=\"caption-attachment-770203\"\u003eFig. 1: PhotoBot provides a reference photograph suggestion based on an observation of the scene and a user’s input language query (upper left). The user strikes a pose matching that of the person in the reference photo (upper right) and PhotoBot adjusts its camera accordingly to faithfully capture the layout and composition of the reference image (lower left). The lower-right panel shows an unretouched photograph produced by PhotoBot.\u003c/figcaption\u003e\u003c/figure\u003e \u003cp\u003ePhotographers struggling to find the perfect angle for a group shot have often relied upon clumsy tripods, clunky self-timers, or, worst of all, missing out on being in the frame to take the photo themselves. Enter PhotoBot, a robot photographer who promises to capture a good shot and can take instructions and use a reference photo when finding the ideal composition. \u003c/p\u003e  \u003cp\u003e“We introduce PhotoBot, a framework for fully automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer,” the researchers \u003ca href=\"https://arxiv.org/abs/2401.11061\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003eexplain\u003c/a\u003e. “We propose to communicate photography suggestions to the user via reference images that are selected from a curated gallery.” \u003c/p\u003e \u003cp\u003e“It was a really fun project,” PhotoBot co-creator and researcher Oliver Limoyo \u003ca href=\"https://spectrum.ieee.org/photo-robot\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003etells \u003cem\u003eSpectrum IEEE\u003c/em\u003e\u003c/a\u003e. Limoyo worked on the project while working at Samsung alongside manager and co-author Jimmy Li. \u003c/p\u003e \u003cblockquote data-media-max-width=\"800\"\u003e \u003cp lang=\"en\" dir=\"ltr\"\u003eSay cheese! We introduce PhotoBot, a framework for fully automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. PhD candidate \u003ca href=\"https://twitter.com/OliverLimoyo?ref_src=twsrc%5Etfw\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003e@OliverLimoyo\u003c/a\u003e will present this work at \u003ca href=\"https://twitter.com/hashtag/IROS2024?src=hash\u0026amp;ref_src=twsrc%5Etfw\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003e#IROS2024\u003c/a\u003e!\u003cbr/\u003ePaper: \u003ca href=\"https://t.co/DHGFvfOKJf\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003ehttps://t.co/DHGFvfOKJf\u003c/a\u003e \u003ca href=\"https://t.co/BPrxDkMxlD\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003epic.twitter.com/BPrxDkMxlD\u003c/a\u003e\u003c/p\u003e \u003cp\u003e— STARS Laboratory (@utiasSTARS) \u003ca href=\"https://twitter.com/utiasSTARS/status/1841848262954721325?ref_src=twsrc%5Etfw\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003eOctober 3, 2024\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e  \u003cp\u003eLimoyo and Li were already working on a robot that could take pictures when they saw the \u003ca href=\"https://www.getty.edu/news/getty-artworks-recreated-with-household-items-by-creative-geniuses-the-world-over/\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003eGetty Image Challenge\u003c/a\u003e during COVID lockdowns. This challenge tasked people with recreating their favorite artworks using only three objects they found around their homes. It was a fun, exciting way to keep people engaged and connected during the early days of the pandemic. \u003c/p\u003e\n \u003cp\u003eBeyond achieving this worthwhile task, Getty’s competition also inspired Limoyo and Li to have their PhotoBot use a reference image to inform its novel photo captures. As \u003cem\u003eSpectrum IEEE\u003c/em\u003e explains, they had to then engineer a way for PhotoBot to accurately match a reference photo and adjust its camera to match that image. \u003c/p\u003e \u003cfigure id=\"attachment_770202\" aria-describedby=\"caption-attachment-770202\"\u003e\u003cimg decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2024/11/photobot-1-800x311.jpg\" alt=\"A diagram showing a process for taking a reference picture. The upper section suggests reference photos with text prompts. The lower section details camera view adjustments using a robot controller. Arrows indicate workflow direction.\" width=\"800\" height=\"311\" srcset=\"https://petapixel.com/assets/uploads/2024/11/photobot-1-800x311.jpg 800w, https://petapixel.com/assets/uploads/2024/11/photobot-1-320x124.jpg 320w, https://petapixel.com/assets/uploads/2024/11/photobot-1-1536x596.jpg 1536w, https://petapixel.com/assets/uploads/2024/11/photobot-1.jpg 1600w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption id=\"caption-attachment-770202\"\u003eFig. 2: PhotoBot system diagram. The two main modules are shown: Reference Suggestion and Camera View Adjustment. Given the observed scene and a user query, PhotoBot suggests a reference image to the user and adjusts the camera to take a photo with a similar layout and composition to the reference image.\u003c/figcaption\u003e\u003c/figure\u003e \u003cp\u003eIt is even more sophisticated in practice than it initially sounds. PhotoBot requires a written description of the type of photo a person wants. The robot then analyzes its environment, identifying people and objects within its line of sight. PhotoBot finds similar photos with corresponding labels within its database. Next, a large language model (LLM) compares the user’s text input with the objects around PhotoBot and its database to select appropriate reference photographs. \u003c/p\u003e \u003cp\u003eSuppose a person wants a picture of them looking happy and is surrounded by a few friends, some flowers in a vase, and maybe a pizza. PhotoBot will see all this, label the people and objects, and then find photos within its database that best match the requested photo and include similar components. \u003c/p\u003e \u003cp\u003eOnce the user selects the reference shot they like best, PhotoBot will adjust its camera to match the framing and perspective of the reference image. Again, this is a more complex situation than it initially seems, as PhotoBot operates within a three-dimensional space but is trying to match the look of a two-dimensional reference photo. \u003c/p\u003e \u003cp\u003eAs for how good PhotoBot is at its job, photographers shouldn’t necessarily panic about the impending reality of a robot photographer. However, PhotoBot did a good job, beating eight humans about two-thirds of the time in terms of respondent preference. \u003c/p\u003e \u003cfigure id=\"attachment_770204\" aria-describedby=\"caption-attachment-770204\"\u003e\u003cimg decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2024/11/photobot-3-800x759.jpg\" alt=\"A grid showing four columns: \u0026#34;No PhotoBot,\u0026#34; \u0026#34;Reference Suggestion Only,\u0026#34; \u0026#34;PhotoBot,\u0026#34; and \u0026#34;Reference Picture.\u0026#34; Each row displays different people posing in various ways corresponding to the columns.\" width=\"800\" height=\"759\" srcset=\"https://petapixel.com/assets/uploads/2024/11/photobot-3-800x759.jpg 800w, https://petapixel.com/assets/uploads/2024/11/photobot-3-320x303.jpg 320w, https://petapixel.com/assets/uploads/2024/11/photobot-3-1536x1456.jpg 1536w, https://petapixel.com/assets/uploads/2024/11/photobot-3.jpg 1600w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption id=\"caption-attachment-770204\"\u003eFig. 5: Sample photos of users evoking various emotions. The user prompts, from top to bottom, are \u003cem\u003esurprised\u003c/em\u003e, \u003cem\u003econfident\u003c/em\u003e, \u003cem\u003eguilty\u003c/em\u003e, \u003cem\u003econfident\u003c/em\u003e, \u003cem\u003ehappy\u003c/em\u003e, and \u003cem\u003econfident\u003c/em\u003e. Columns, from left to right, are: user’s own creative posing; user mimicking the suggested reference using a static camera; photo taken by our PhotoBot system; and reference image suggested by PhotoBot. The checkered background indicates cropping. The black background indicates padding of the reference image to facilitate the PnP solution. PhotoBot automatically crops the photos it takes to match the image template.\u003c/figcaption\u003e\u003c/figure\u003e\n \u003cp\u003eLi and the rest of the team are no longer working on PhotoBot, but the creator thinks their work has possible implications for smartphone photo assistant apps. \u003c/p\u003e \u003cp\u003e“Imagine right on your phone, you see a reference photo. But you also see what the phone is seeing right now, and then that allows you to move around and align,” Li remarks. \u003c/p\u003e \u003chr/\u003e \u003cp\u003e\u003cem\u003e\u003cstrong\u003eImage credits:\u003c/strong\u003e Photos from the research paper, ‘\u003ca href=\"https://arxiv.org/pdf/2401.11061\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003ePhotoBot: Reference-Guided Interactive Photography via Natural Language\u003c/a\u003e,’ by Limoyo, Li, Rivkin, Kelly, and Dudek. \u003c/em\u003e\u003c/p\u003e      \u003c/div\u003e\n\n          \n      \n\n              \u003cdiv\u003e\n          \u003cp\u003ePetaPixel articles may include affiliate links; if you buy something through such a link, PetaPixel may earn a commission.\u003c/p\u003e\n        \u003c/div\u003e\n      \n    \n\n    \n          \n      \n\n\n\n\n    \n    \n    \n          \n      \u003c/div\u003e\n\u003c/article\u003e\n\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-11-26T21:39:03Z",
  "modifiedTime": null
}
