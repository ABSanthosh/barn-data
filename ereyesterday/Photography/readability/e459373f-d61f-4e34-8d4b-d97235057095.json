{
  "id": "e459373f-d61f-4e34-8d4b-d97235057095",
  "title": "When AI Can Geolocate a Photo, Is There Any Hope for Vacation Privacy?",
  "link": "https://petapixel.com/2025/06/12/when-ai-can-geolocate-a-photo-is-there-any-hope-for-vacation-privacy/",
  "description": "In April, ChatGPT users stumbled across the AI's unnervingly accurate ability to locate where just about any photo was taken. At first blush, it seems harmless, but a recent story on Vox points out that it's now very easy to stalk someone from just their social media photos. [Read More]",
  "author": "Jaron Schneider",
  "published": "Thu, 12 Jun 2025 19:16:33 +0000",
  "source": "https://petapixel.com/feed/",
  "categories": [
    "Culture",
    "Opinion",
    "Technology",
    "ai",
    "chatgpt",
    "geolocate",
    "geolocation",
    "o3",
    "openai",
    "opinion",
    "vox"
  ],
  "byline": "Jaron Schneider",
  "length": 4254,
  "excerpt": "When AI can pinpoint a location from a seemingly innocuous photo, questions about privacy need to be raised.",
  "siteName": "PetaPixel",
  "favicon": "https://petapixel.com/wp-content/themes/petapixel-2017/assets/prod/img/apple-touch-icon-180x180.png",
  "text": "While this view looks innocuous, when AI can easily identify a scene and pinpoint a location, it doesn’t matter if there isn’t any personal info in the photo: a stalker can make use of just a location. In April, ChatGPT users stumbled across the AI’s unnervingly accurate ability to locate where just about any photo was taken. At first blush, it seems harmless, but a recent story on Vox points out that it’s now very easy to stalk someone from just their social media photos. It’s not a new concern, but it is one that is worth pointing out again. When PetaPixel originally reported on the feature, TechCrunch had asked OpenAI about these privacy concerns. “OpenAI o3 and o4-mini bring visual reasoning to ChatGPT, making it more helpful in areas like accessibility, research, or identifying locations in emergency response. We’ve worked to train our models to refuse requests for private or sensitive information, added safeguards intended to prohibit the model from identifying private individuals in images, and actively monitor for and take action against abuse of our usage policies on privacy.” That doesn’t directly address the problem, however. As Vox writer Kelsey Piper explains, a stalker would get everything they would need out of a photo without it sharing “private or sensitive information.” After sharing a photo of a beach, which just shows sand, waves, and a cloudy sky, OpenAI’s o3 was able to correctly guess the location. ChatGPT was able to guess the location of this photo within a 12 minute walk of its actual location. Not perfect, but close enough. | Photo by Jaron Schneider “To my merely human eye, this image doesn’t look like it contains enough information to guess where my family is staying for vacation. It’s a beach! With sand! And waves! How could you possibly narrow it down further than that?” Piper asks. “But surfing hobbyists tell me there’s far more information in this image than I thought. The pattern of the waves, the sky, the slope, and the sand are all information, and in this case, sufficient information to venture a correct guess about where my family went for vacation.” Previously, unless you are afraid of being tracked by rainbolt, sharing innocuous photos of a vacation spot on social media felt pretty safe. Piper was likely right to assume that most people — a vast majority — wouldn’t be able to figure out where she was from her single ocean-facing photo. But AI can, and the ease with which anyone can access ChatGPT means that no photo is necessarily safe anymore. ChatGPT was bang-on correct when it guessed the location of this photo, which was taken on the slopes of Mount Bandai, near Lake Inawashiro in Fukushima Prefecture, Japan.​ | Photo by Jaron Schneider Some will argue that personal data has not been personal for some time now. Google and Meta have been ravenous for personal data and collect it constantly. But the difference here, as Piper points out, is that Google and Meta use that data to sell ads. OpenAI’s product is far more, well, open. “While Google has incentives not to have a major privacy-related incident — users would be angry with them, regulators would investigate them, and they have a lot of business to lose — the AI companies proliferating today like OpenAI or DeepSeek are much less kept in line by public opinion,” Piper writes. There have been multiple recorded cases of streamers, influencers, and celebrities having issues with stalkers — and that was before the ubiquity of AI tools. Unfortunately, there isn’t an easy solution to these concerns. Outside of more direct regulation of AI companies and the types of tools, they are allowed to add to their platforms, holding them responsible for how a user leverages them maliciously will be difficult legally. Piper points out that New York is considering a law that would regulate AI when they take actions that would be a crime if they were taken by humans, but it remains to be seen if such a law could pass or how it would be enforced. It would also need to be implemented in more than just one state to have any meaningful effect. For now, if you’re concerned about privacy, it’s best not to share any photos of your current location online. Image credits: Photos by Jaron Schneider",
  "image": "https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n      \u003cfigure id=\"attachment_799285\" aria-describedby=\"caption-attachment-799285\"\u003e\u003cimg data-perfmatters-preload=\"\" fetchpriority=\"high\" decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-800x420.jpg\" alt=\"A winding road cuts through dry, rugged mountains under a clear blue sky, with layers of distant hills and mist visible on the horizon.\" width=\"800\" height=\"420\" srcset=\"https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-800x420.jpg 800w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-320x168.jpg 320w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-1536x806.jpg 1536w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-150x79.jpg 150w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-300x157.jpg 300w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-400x209.jpg 400w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy-550x288.jpg 550w, https://petapixel.com/assets/uploads/2025/06/When-AI-Can-Geolocate-Any-Photo-Is-There-Any-Hope-of-Vacation-Privacy.jpg 1600w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption id=\"caption-attachment-799285\"\u003eWhile this view looks innocuous, when AI can easily identify a scene and pinpoint a location, it doesn’t matter if there isn’t any personal info in the photo: a stalker can make use of just a location.\u003c/figcaption\u003e\u003c/figure\u003e \u003cp\u003eIn April, ChatGPT users stumbled across the AI’s unnervingly accurate \u003ca href=\"https://petapixel.com/2025/04/18/chatgpt-is-scarily-good-at-guessing-the-location-of-a-photo/\" data-wpel-link=\"internal\"\u003eability to locate where just about any photo was taken\u003c/a\u003e. At first blush, it seems harmless, but \u003ca href=\"https://www.vox.com/future-perfect/415646/artificial-intelligencer-chatgpt-claude-privacy-surveillance\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003ea recent story on \u003cem\u003eVox\u003c/em\u003e\u003c/a\u003e points out that it’s now very easy to stalk someone from just their social media photos. \u003c/p\u003e  \u003cp\u003eIt’s not a new concern, but it is one that is worth pointing out again. When \u003cem\u003ePetaPixel\u003c/em\u003e originally reported on the feature, \u003ca href=\"https://petapixel.com/2025/04/18/chatgpt-is-scarily-good-at-guessing-the-location-of-a-photo/\" data-wpel-link=\"internal\"\u003e\u003cem\u003eTechCrunch\u003c/em\u003e had asked OpenAI about these privacy concerns\u003c/a\u003e.\u003c/p\u003e \u003cp\u003e“OpenAI o3 and o4-mini bring visual reasoning to ChatGPT, making it more helpful in areas like accessibility, research, or identifying locations in emergency response. We’ve worked to train our models to refuse requests for private or sensitive information, added safeguards intended to prohibit the model from identifying private individuals in images, and actively monitor for and take action against abuse of our usage policies on privacy.”\u003c/p\u003e \u003cp\u003eThat doesn’t directly address the problem, however. \u003ca href=\"https://www.vox.com/future-perfect/415646/artificial-intelligencer-chatgpt-claude-privacy-surveillance\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003eAs \u003cem\u003eVox\u003c/em\u003e writer Kelsey Piper explains\u003c/a\u003e, a stalker would get everything they would need out of a photo without it sharing “private or sensitive information.” After sharing a photo of a beach, which just shows sand, waves, and a cloudy sky, OpenAI’s o3 was able to correctly guess the location.\u003c/p\u003e \u003cfigure id=\"attachment_790328\" aria-describedby=\"caption-attachment-790328\"\u003e\u003ca href=\"https://petapixel.com/2025/04/18/chatgpt-is-scarily-good-at-guessing-the-location-of-a-photo/img_0526/\" rel=\"attachment wp-att-790328\" data-wpel-link=\"internal\"\u003e\u003cimg decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2025/04/IMG_0526-600x800.jpg\" alt=\"A large metal tree sculpture with illuminated branches stands in the center of a cobblestone courtyard surrounded by historic buildings at night.\" width=\"600\" height=\"800\" srcset=\"https://petapixel.com/assets/uploads/2025/04/IMG_0526-600x800.jpg 600w, https://petapixel.com/assets/uploads/2025/04/IMG_0526-240x320.jpg 240w, https://petapixel.com/assets/uploads/2025/04/IMG_0526.jpg 750w\" sizes=\"(max-width: 600px) 100vw, 600px\"/\u003e\u003c/a\u003e\u003cfigcaption id=\"caption-attachment-790328\"\u003eChatGPT was able to guess the location of this photo within a 12 minute walk of its actual location. Not perfect, but close enough. | Photo by Jaron Schneider\u003c/figcaption\u003e\u003c/figure\u003e \u003cp\u003e“To my merely human eye, this image doesn’t look like it contains enough information to guess where my family is staying for vacation. It’s a beach! With sand! And waves! How could you possibly narrow it down further than that?” Piper asks. \u003c/p\u003e\n \u003cp\u003e“But surfing hobbyists tell me there’s far more information in this image than I thought. The pattern of the waves, the sky, the slope, and the sand are all information, and in this case, sufficient information to venture a correct guess about where my family went for vacation.”\u003c/p\u003e \u003cp\u003ePreviously, \u003ca href=\"https://www.instagram.com/georainbolt/?hl=en\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003eunless you are afraid of being tracked by rainbolt\u003c/a\u003e, sharing innocuous photos of a vacation spot on social media felt pretty safe. Piper was likely right to assume that most people — a vast majority — wouldn’t be able to figure out where she was from her single ocean-facing photo. But AI can, and the ease with which anyone can access ChatGPT means that no photo is necessarily safe anymore. \u003c/p\u003e \u003cfigure id=\"attachment_790341\" aria-describedby=\"caption-attachment-790341\"\u003e\u003ca href=\"https://petapixel.com/2025/04/18/chatgpt-is-scarily-good-at-guessing-the-location-of-a-photo/img_0463-2/\" rel=\"attachment wp-att-790341\" data-wpel-link=\"internal\"\u003e\u003cimg decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2025/04/IMG_0463-600x800.jpg\" alt=\"View from a high vantage point of snow-covered buildings, trees, and fields stretching into the distance, with mountains and a partly cloudy sky at dawn or dusk.\" width=\"600\" height=\"800\" srcset=\"https://petapixel.com/assets/uploads/2025/04/IMG_0463-600x800.jpg 600w, https://petapixel.com/assets/uploads/2025/04/IMG_0463-240x320.jpg 240w, https://petapixel.com/assets/uploads/2025/04/IMG_0463.jpg 750w\" sizes=\"(max-width: 600px) 100vw, 600px\"/\u003e\u003c/a\u003e\u003cfigcaption id=\"caption-attachment-790341\"\u003eChatGPT was bang-on correct when it guessed the location of this photo, which was taken on the slopes of Mount Bandai, near Lake Inawashiro in Fukushima Prefecture, Japan.​ | Photo by Jaron Schneider\u003c/figcaption\u003e\u003c/figure\u003e \u003cp\u003eSome will argue that personal data has not been personal for some time now. Google and Meta have been ravenous for personal data and collect it constantly. But the difference here, as Piper points out, is that Google and Meta use that data to sell ads. OpenAI’s product is far more, well, open. \u003c/p\u003e \u003cp\u003e“While Google has incentives not to have a major privacy-related incident — users would be angry with them, regulators would investigate them, and they have a lot of business to lose — the AI companies proliferating today like OpenAI or DeepSeek are much less kept in line by public opinion,” Piper writes. \u003c/p\u003e \u003cp\u003eThere have been multiple recorded cases of \u003ca href=\"https://news.sky.com/story/twitch-creators-warn-other-women-after-stalker-threatens-to-kill-them-during-live-video-stream-13321201\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003estreamers\u003c/a\u003e, \u003ca href=\"https://www.bbc.com/news/articles/cx2xwy3870po\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003einfluencers\u003c/a\u003e, and celebrities having issues with stalkers — and that was before the ubiquity of AI tools. \u003c/p\u003e \u003cp\u003eUnfortunately, there isn’t an easy solution to these concerns. Outside of more direct regulation of AI companies and the types of tools, they are allowed to add to their platforms, holding them responsible for how a user leverages them maliciously will be difficult legally. Piper points out that New York is considering \u003ca href=\"https://legislation.nysenate.gov/pdf/bills/2025/A6453?ref=cognitiverevolution.ai\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003ea law\u003c/a\u003e that would regulate AI when they take actions that would be a crime if they were taken by humans, but it remains to be seen if such a law could pass or how it would be enforced. It would also need to be implemented in more than just one state to have any meaningful effect. \u003c/p\u003e\n \u003cp\u003eFor now, if you’re concerned about privacy, it’s best not to share any photos of your current location online. \u003c/p\u003e \u003chr/\u003e \u003cp\u003e\u003cem\u003e\u003cstrong\u003eImage credits:\u003c/strong\u003e Photos by Jaron Schneider\u003c/em\u003e\u003c/p\u003e      \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-06-12T19:16:33Z",
  "modifiedTime": null
}
