{
  "id": "3fcf53cb-9c7e-4d62-817d-41e7558f884b",
  "title": "ByteDance Shows Off Ultra-Realistic Deepfake Generative AI",
  "link": "https://www.lightstalking.com/bytedance-shows-off-ultra-realistic-deepfake-generative-ai/",
  "description": "A few years back deepfakes seemed to be the latest concern de jour. Now they’re back and with a vengeance although, this time around, they’re part of a broader generative AI wave that’s taking multiple industries by storm. What’s becoming impressive across the board is the sophistication of these models. What’s impressive in this particular […] The post ByteDance Shows Off Ultra-Realistic Deepfake Generative AI appeared first on Light Stalking.",
  "author": "Kehl Bayern",
  "published": "Mon, 10 Feb 2025 17:51:00 +0000",
  "source": "https://www.lightstalking.com/feed/",
  "categories": [
    "Photography News"
  ],
  "byline": "Kehl Bayern",
  "length": 2158,
  "excerpt": "A few years back deepfakes seemed to be the latest concern de jour. ByteDance building. Photo by Claudio Schwarz Now they’re back and with a vengeance although, this time around, they’re part of a broader generative AI wave that’s taking multiple industries by storm. What’s becoming impressive across the board is the sophistication of these models. What’s impressive in this particular case is the model’s ability to generate so much from so little. ByteDance, the company behind TikTok and other popular social media platforms, unveiled a generative AI that needs little more than a single photograph and a brief sound",
  "siteName": "Light Stalking",
  "favicon": "",
  "text": "A few years back deepfakes seemed to be the latest concern de jour. ByteDance building. Photo by Claudio Schwarz Now they’re back and with a vengeance although, this time around, they’re part of a broader generative AI wave that’s taking multiple industries by storm. What’s becoming impressive across the board is the sophistication of these models. What’s impressive in this particular case is the model’s ability to generate so much from so little. ByteDance, the company behind TikTok and other popular social media platforms, unveiled a generative AI that needs little more than a single photograph and a brief sound clip to make a realistic video from both. Some of the examples offered by the company include a video of Einstein giving a speech he never gave and popstar Taylor Swift doing the same. The model, called OmniHuman-1, was trained on some 19,000 hours of video, TechCrunch reports, and has the ability to edit an existing video and change it quite significantly in addition to making things from whole cloth. Naturally, concerns about the provenance of training material and what end uses this will all go toward are still at the top of everyone’s list of grievances when it comes to generative AI. The key problem is that, as things get better, it gets harder for us to detect the fakes. In other words, the better generative AI becomes, the worse things become for those of us who appreciate reality. There are further questions about the kinds of content that generative AI will be able to create and what forums are appropriate for it. For example, generative AI media on social platforms would seem to obviate the entire purpose of the app. We’ve joked for a long time that everything on social media is fantasy – it actually being fantasy is a whole other thing though. Any thoughts that you might have on deepfakes are welcome in the comments. Don’t forget to check out some other articles at this link. Kehl is our staff photography news writer since 2017 and has over a decade of experience in online media and publishing and you can get to know him better here and follow him on Insta.",
  "image": "https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"site-content\" role=\"main\"\u003e\n\t\n\u003carticle id=\"post-516802\"\u003e\n\t\n\t\u003cdiv\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\n\u003cp\u003eA few years back deepfakes seemed to be the latest concern de jour.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cpicture\u003e\u003csource srcset=\"https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y.jpg.webp 800w, https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y-200x300.jpg.webp 200w, https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y-768x1152.jpg.webp 768w\" sizes=\"(max-width: 800px) 100vw, 800px\" type=\"image/webp\"/\u003e\u003cimg decoding=\"async\" width=\"800\" height=\"1200\" src=\"https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y.jpg\" alt=\"a tall building with a sign in front of it\" srcset=\"https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y.jpg 800w, https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y-200x300.jpg 200w, https://www.lightstalking.com/wp-content/uploads/pq5hrwiq38y-768x1152.jpg 768w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eByteDance building. Photo by Claudio Schwarz\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eNow they’re back and with a vengeance although, this time around, they’re part of a broader generative AI wave that’s taking multiple industries by storm.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhat’s becoming impressive across the board is the sophistication of these models.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhat’s impressive in this particular case is the model’s ability to generate so much from so little.\u003c/p\u003e\n\n\n\n\u003cp\u003eByteDance, the company behind TikTok and other popular social media platforms, unveiled a generative AI that needs little more than a single photograph and a brief sound clip to make a realistic video from both.\u003c/p\u003e\n\n\n\n\u003cp\u003eSome of the examples offered by the company include a video of Einstein giving a speech he never gave and popstar Taylor Swift doing the same. The model, called OmniHuman-1, was trained on some 19,000 hours of video, TechCrunch \u003ca href=\"https://techcrunch.com/2025/02/04/deepfake-videos-are-getting-shockingly-good/\"\u003ereports\u003c/a\u003e, and has the ability to edit an existing video and change it quite significantly in addition to making things from whole cloth.\u003c/p\u003e\n\n\n\n\u003cp\u003eNaturally, concerns about the provenance of training material and what end uses this will all go toward are still at the top of everyone’s list of grievances when it comes to generative AI. The key problem is that, as things get better, it gets harder for us to detect the fakes. In other words, the better generative AI becomes, the worse things become for those of us who appreciate reality. There are further questions about the kinds of content that generative AI will be able to create and what forums are appropriate for it. For example, generative AI media on social platforms would seem to obviate the entire purpose of the app. We’ve joked for a long time that everything on social media is fantasy – it actually being fantasy is a whole other thing though.\u003c/p\u003e\n\n\n\n\u003cp\u003eAny thoughts that you might have on deepfakes are welcome in the comments.\u003c/p\u003e\n\n\n\n\u003cp\u003eDon’t forget to check out some other articles \u003ca href=\"https://www.lightstalking.com/category/news/\"\u003eat this link\u003c/a\u003e.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\u003cp\u003e\u003cimg alt=\"\" src=\"https://secure.gravatar.com/avatar/105c790fa869c42d4960f657a087d59c?s=120\u0026amp;r=g\" srcset=\"https://secure.gravatar.com/avatar/105c790fa869c42d4960f657a087d59c?s=240\u0026amp;r=g 2x\" height=\"120\" width=\"120\" decoding=\"async\"/\u003e\t\t\t\u003c/p\u003e\n\t\t\t\u003cp\u003eKehl is our staff photography news writer since 2017 and has over a decade of experience in online media and publishing and you can get to \u003ca href=\"https://www.lightstalking.com/about/\"\u003eknow him better here\u003c/a\u003e and follow him on \u003ca href=\"https://www.instagram.com/kehlbayern/\"\u003eInsta\u003c/a\u003e.\u003c/p\u003e\n\t\t\u003c/div\u003e\t\t\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\t\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-02-10T17:51:00Z",
  "modifiedTime": "2025-02-11T05:55:05Z"
}
