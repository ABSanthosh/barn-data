{
  "id": "c9568b63-d0f9-4210-a6f3-5b3b7c0d1da4",
  "title": "How Meta discovers data flows via lineage at scale",
  "link": "https://engineering.fb.com/2025/01/22/security/how-meta-discovers-data-flows-via-lineage-at-scale/",
  "description": "Data lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for scalable discovery of relevant data and data flows, which supports privacy controls across Meta’s systems. This allows us to verify that our users’ everyday interactions [...] Read More... The post How Meta discovers data flows via lineage at scale appeared first on Engineering at Meta.",
  "author": "",
  "published": "Thu, 23 Jan 2025 05:00:45 +0000",
  "source": "https://engineering.fb.com/feed/",
  "categories": [
    "Security"
  ],
  "byline": "",
  "length": 20210,
  "excerpt": "Data lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for s…",
  "siteName": "Engineering at Meta",
  "favicon": "",
  "text": "Data lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for scalable discovery of relevant data and data flows, which supports privacy controls across Meta’s systems. This allows us to verify that our users’ everyday interactions are protected across our family of apps, such as their religious views in the Facebook Dating app, the example we’ll walk through in this post. In order to build high-quality data lineage, we developed different techniques to collect data flow signals across different technology stacks: static code analysis for different languages, runtime instrumentation, and input and output data matching, etc. We then built an intuitive UX into our tooling that enables developers to effectively consume all of this lineage data in a systematic way, saving significant engineering time for building privacy controls.  As we expanded PAI across Meta, we gained valuable insights about the data lineage space. Our understanding of the privacy space evolved, revealing the need for early focus on data lineage, tooling, a cohesive ecosystem of libraries, and more. These initiatives have assisted in accelerating the development of data lineage and implementing purpose limitation controls more quickly and efficiently. At Meta, we believe that privacy enables product innovation. This belief has led us to developing Privacy Aware Infrastructure (PAI), which offers efficient and reliable first-class privacy constructs embedded in Meta infrastructure to address different privacy requirements, such as purpose limitation, which restricts the purposes for which data can be processed and used.  In this blog, we will delve into an early stage in PAI implementation: data lineage. Data lineage refers to the process of tracing the journey of data as it moves through various systems, illustrating how data transitions from one data asset, such as a database table (the source asset), to another (the sink asset). We’ll also walk through how we track the lineage of users’ “religion” information in our Facebook Dating app. Millions of data assets are vital for supporting our product ecosystem, ensuring the functionality our users anticipate, maintaining high product quality, and safeguarding user safety and integrity. Data lineage enables us to efficiently navigate these assets and protect user data. It enhances the traceability of data flows within systems, ultimately empowering developers to swiftly implement privacy controls and create innovative products. Note that data lineage is dependent on having already completed important and complex preliminary steps to inventory, schematize, and annotate data assets into a unified asset catalog. This took Meta multiple years to complete across our millions of disparate data assets, and we’ll cover each of these more deeply in future blog posts: Inventorying involves collecting various code and data assets (e.g., web endpoints, data tables, AI models) used across Meta. Schematization expresses data assets in structural detail (e.g., indicating that a data asset has a field called “religion”). Annotation labels data to describe its content (e.g., specifying that the identity column contains religion data). Understanding data lineage at Meta To establish robust privacy controls, an essential part of our PAI initiative is to understand how data flows across different systems. Data lineage is part of this discovery step in the PAI workflow, as shown in the following diagram: Data lineage is a key precursor to implementing Policy Zones, our information flow control technology, because it answers the question, “Where does my data come from and where does it go?” – helping inform the right places to apply privacy controls. In conjunction with Policy Zones, data lineage provides the following key benefits to thousands of developers at Meta:  Scalable data flow discovery: Data lineage answers the question above by providing an end-to-end, scalable graph of relevant data flows. We can leverage the lineage graphs to visualize and explain the flow of relevant data from the point where it is collected to all the places where it is processed. Efficient rollout of privacy controls: By leveraging data lineage to track data flows, we can easily pinpoint the optimal integration points for privacy controls like Policy Zones within the codebase, streamlining the rollout process. Thus we have developed a powerful flow discovery tool as part of our PAI tool suite, Policy Zone Manager (PZM), based on data lineage. PZM enables developers to rapidly identify multiple downstream assets from a set of sources simultaneously, thereby accelerating the rollout process of privacy controls. Continuous compliance verification: Once the privacy requirement has been fully implemented, data lineage plays a vital role in monitoring and validating data flows continuously, in addition to the enforcement mechanisms such as Policy Zones. Traditionally, data lineage has been collected via code inspection using manually authored data flow diagrams and spreadsheets. However, this approach does not scale in large and dynamic environments, such as Meta, with billions of lines of continuously evolving code. To tackle this challenge, we’ve developed a robust and scalable lineage solution that uses static code analysis signals as well as runtime signals. Walkthrough: Implementing data lineage for religion data We’ll share how we have automated lineage tracking to identify religion data flows through our core systems, eventually creating an end-to-end, precise view of downstream religion assets being protected, via the following two key stages: Collecting data flow signals: a process to capture data flow signals from many processing activities across different systems, not only for religion, but for all other types of data, to create an end-to-end lineage graph.  Identifying relevant data flows: a process to identify the specific subset of data flows (“subgraph”) within the lineage graph that pertains to religion.  These stages propagate through various systems including function-based systems that load, process, and propagate data through stacks of function calls in different programming languages (e.g., Hack, C++, Python, etc.) such as web systems and backend services, and batch-processing systems that process data rows in batch (mainly via SQL) such as data warehouse and AI systems. For simplicity, we will demonstrate these for the web, the data warehouse, and AI, per the diagram below. Collecting data flow signals for the web system When setting up a profile on the Facebook Dating app, people can populate their religious views. This information is then utilized to identify relevant matches with other people who have specified matched values in their dating preferences. On Dating, religious views are subject to purpose limitation requirements, for example, they will not be used to personalize experiences on other Facebook Products. We start with someone entering their religion information on their dating media profile using their mobile device, which is then transmitted to a web endpoint. The web endpoint subsequently logs the data into a logging table and stores it in a database, as depicted in the following code snippet: Now let’s see how we collect lineage signals. To do this, we need to employ both static and runtime analysis tools to effectively discover data flows, particularly focusing on where religion is logged and stored. By combining static and runtime analysis, we enhance our ability to accurately track and manage data flows. Static analysis tools simulate code execution to map out data flows within our systems. They also emit quality signals to indicate the confidence of whether a data flow signal is a true positive. However, these tools are limited by their lack of access to runtime data, which can lead to false positives from unexecuted code. To address this limitation, we utilize Privacy Probes, a key component of our PAI lineage technologies. Privacy Probes automate data flow discovery by collecting runtime signals. These signals are gathered in real time during the execution of requests, allowing us to trace the flow of data into loggers, databases, and other services.  We have instrumented Meta’s core data frameworks and libraries at both the data origin points (sources) and their eventual outputs (sinks), such as logging framework, which allows for comprehensive data flow tracking. This approach is exemplified in the following code snippet: During runtime execution, Privacy Probes does the following: Capturing payloads: It captures source and sink payloads in memory on a sampled basis, along with supplementary metadata such as event timestamps, asset identifiers, and stack traces as evidence for the data flow.  Comparing payloads: It then compares the source and sink payloads within a request to identify data matches, which helps in understanding how data flows through the system.  Categorizing results: It categorizes results into two sets. The match-set includes pairs of source and sink assets where data matches exactly or one is contained by another, therefore providing high confidence evidence of data flow between the assets. The full-set includes all source and sink pairs within a request no matter whether the sink is tainted by the source. Full-set is a superset of match-set with some noise but still important to send to human reviewers since it may contain transformed data flows.  The above procedure is depicted in the diagram below: Let’s look at the following examples where various religions are received in an endpoint and various values (copied or transformed) being logged in three different loggers: Input Value (source) Output Value (sink) Data Operation Match Result Flow Confidence “Atheist” “Atheist” Data Copy EXACT_MATCH HIGH “Buddhist” {metadata: {religion: Buddhist}} Substring CONTAINS HIGH {religions: [“Catholic”, “Christian”]} {count : 2} Transformed NO_MATCH LOW In the examples above, the first two rows show a precise match of religions in the source and the sink values, thus belonging to the high confidence match-set. The third row depicts a transformed data flow where the input string value is transformed to a count of values before being logged, belonging to full-set.  These signals together are used to construct a lineage graph to understand the flow of data through our web system as shown in the following diagram: Collecting data flow signals for the data warehouse system With the user’s religion logged in our web system, it can propagate to the data warehouse for offline processing. To gather data flow signals, we employ a combination of both runtime instrumentation and static code analysis in a different way from the web system. The involved SQL queries are logged for data processing activities by the Presto and Spark compute engines (among others). Static analysis is then performed for the logged SQL queries and job configs in order to extract data flow signals. Let’s examine a simple SQL query example that processes data for the data warehouse as the following: We’ve developed a SQL analyzer to extract data flow signals between the input table, “safety_log_tbl” and the output table, “safety_training_tbl” as shown in the following diagram. In practice, we also collect more granular-level lineage such as at column-level (e.g., “user_id” -\u003e “target_user_id”, “religion” -\u003e “target_religion”). There are instances where data is not fully processed by SQL queries, resulting in logs that contain data flow signals for either reads or writes, but not both. To ensure we have complete lineage data, we leverage contextual information (such as execution environments; job or trace IDs) collected at runtime to connect these reads and writes together.  The following diagram illustrates how the lineage graph has expanded: Collecting data flow signals for the AI system For our AI systems, we collect lineage signals by tracking relationships between various assets, such as input datasets, features, models, workflows, and inferences. A common approach is to extract data flows from job configurations used for different AI activities such as model training. For instance, in order to improve the relevance of dating matches, we use an AI model to recommend potential matches based on shared religious views from users. Let’s take a look at the following training config example for this model that uses religion data: By parsing this config obtained from the model training service, we can track the data flow from the input dataset (with asset ID asset://hive.table/dating_training_tbl) and feature (with asset ID asset://ai.feature/DATING_USER_RELIGION_SCORE) to the model (with asset ID asset://ai.model/dating_ranking_model). Our AI systems are also instrumented so that asset relationships and data flow signals are captured at various points at runtime, including data-loading layers (e.g., DPP) and libraries (e.g., PyTorch), workflow engines (e.g., FBLearner Flow), training frameworks, inference systems (as backend services), etc. Lineage collection for backend services utilizes the approach for function-based systems described above. By matching the source and sink assets for different data flow signals, we are able to capture a holistic lineage graph at the desired granularities: Identifying relevant data flows from a lineage graph Now that we have the lineage graph at our disposal, how can we effectively distill a subset of data flows pertinent to a specific privacy requirement for religion data? To address this question, we have developed an iterative analysis tool that enables developers to pinpoint precise data flows and systematically filter out irrelevant ones. The tool kicks off a repetitive discovery process aided by the lineage graph and privacy controls from Policy Zones, to narrow down the most relevant flows. This refined data allows developers to make a final determination about the flows they would like to use, producing an optimal path for traversing the lineage graph. The following are the major steps involved, captured holistically in the diagram, below: Discover data flows: identify data flows from source assets and stop at downstream assets with low-confidence flows (yellow nodes).  Exclude and include candidates: Developers or automated heuristics exclude candidates (red nodes) that don’t have religion data or include remaining ones (green nodes). By excluding the red nodes early on, it helps to exclude all of their downstream in a cascaded manner, and thus saves developer efforts significantly. As an additional safeguard, developers also implement privacy controls via Policy Zones, so all relevant data flows can be captured. Repeat discovery cycle: use the green nodes as new sources and repeat the cycle until no more green nodes are confirmed.  With the collection and data flow identification steps complete, developers are able to successfully locate granular data flows that contain religion across Meta’s complex systems, allowing them to move forward in the PAI workflow to apply necessary privacy controls to safeguard the data. This once-intimidating task has been completed efficiently.  Our data lineage technology has provided developers with an unprecedented ability to quickly understand and protect religion and similar sensitive data flows. It enables Meta to scalably and efficiently implement privacy controls via PAI to protect our users’ privacy and deliver products safely. Learnings and challenges As we’ve worked to develop and implement lineage as a core PAI technology, we’ve gained valuable insights and overcome significant challenges, yielding some important lessons: Focus on lineage early and reap the rewards: As we developed privacy technologies like Policy Zones, it became clear that gaining a deep understanding of data flows across various systems is essential for scaling the implementation of privacy controls. By investing in lineage, we not only accelerated the adoption of Policy Zones but also uncovered new opportunities for applying the technology. Lineage can also be extended to other use cases such as security and integrity. Build lineage consumption tools to gain engineering efficiency: We initially focused on building a lineage solution but didn’t give sufficient attention to consumption tools for developers. As a result, owners had to use raw lineage signals to discover relevant data flows, which was overwhelmingly complex. We addressed this issue by developing the iterative tooling to guide engineers in discovering relevant data flows, significantly reducing engineering efforts by orders of magnitude. Integrate lineage with systems to scale the coverage: Collecting lineage from diverse Meta systems was a significant challenge. Initially, we tried to ask every system to collect lineage signals to ingest into the centralized lineage service, but the progress was slow. We overcame this by developing reliable, computationally efficient, and widely applicable PAI libraries with built-in lineage collection logic in various programming languages (Hack, C++, Python, etc.). This enabled much smoother integration with a broad range of Meta’s systems. Measurement improves our outcomes: By incorporating the measurement of coverage, we’ve been able to evolve our data lineage so that we stay ahead of the ever-changing landscape of data and code at Meta. By enhancing our signals and adapting to new technologies, we can maintain a strong focus on privacy outcomes and drive ongoing improvements in lineage coverage across our tech stacks. The future of data lineage Data lineage is a vital component of Meta’s PAI initiative, providing a comprehensive view of how data flows across different systems. While we’ve made significant progress in establishing a strong foundation, our journey is ongoing. We’re committed to: Expanding coverage: continuously enhance the coverage of our data lineage capabilities to ensure a comprehensive understanding of data flows. Improving consumption experience: streamline the consumption experience to make it easier for developers and stakeholders to access and utilize data lineage information. Exploring new frontiers: investigate new applications and use cases for data lineage, driving innovation and collaboration across the industry. By advancing data lineage, we aim to foster a culture of privacy awareness and drive progress in the broader fields of study. Together, we can create a more transparent and accountable data ecosystem. Acknowledgements The authors would like to acknowledge the contributions of many current and former Meta employees who have played a crucial role in developing data lineage technologies over the years. In particular, we would like to extend special thanks to (in alphabetical order) Amit Jain, Aygun Aydin, Ben Zhang, Brian Romanko, Brian Spanton, Daniel Ramagem, David Molnar, Dzmitry Charnahalau, Gayathri Aiyer, George Stasa, Guoqiang Jerry Chen, Graham Bleaney, Haiyang Han, Howard Cheng, Ian Carmichael, Ibrahim Mohamed, Jerry Pan, Jiang Wu, Jonathan Bergeron, Joanna Jiang, Jun Fang, Kiran Badam, Komal Mangtani, Kyle Huang, Maharshi Jha, Manuel Fahndrich, Marc Celani, Lei Zhang, Mark Vismonte, Perry Stoll, Pritesh Shah, Qi Zhou, Rajesh Nishtala, Rituraj Kirti, Seth Silverman, Shelton Jiang, Sushaant Mujoo, Vlad Fedorov, Yi Huang, Xinbo Gao, and Zhaohui Zhang. We would also like to express our gratitude to all reviewers of this post, including (in alphabetical order) Aleksandar Ilic, Avtar Brar, Benjamin Renard, Bogdan Shubravyi, Brianna O’Steen, Chris Wiltz, Daniel Chamberlain, Hannes Roth, Imogen Barnes, Jason Hendrickson, Koosh Orandi, Rituraj Kirti, and Xenia Habekoss. We would like to especially thank Jonathan Bergeron for overseeing the effort and providing all of the guidance and valuable feedback, Supriya Anand for leading the editorial effort to shape the blog content, and Katherine Bates for pulling all required support together to make this blog post happen.",
  "image": "https://engineering.fb.com/wp-content/uploads/2025/01/LINEAGE_HEADER_IMAGE.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n\t\t\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eData lineage is an instrumental part of Meta’s Privacy Aware Infrastructure (PAI) initiative, a suite of technologies that efficiently protect user privacy. It is a critical and powerful tool for scalable discovery of relevant data and data flows, which supports privacy controls across Meta’s systems. This allows us to verify that our users’ everyday interactions are protected across our family of apps, such as their religious views in the Facebook Dating app, the example we’ll walk through in this post.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eIn order to build high-quality data lineage, we developed different techniques to collect data flow signals across different technology stacks: static code analysis for different languages, runtime instrumentation, and input and output data matching, etc. We then built an intuitive UX into our tooling that enables developers to effectively consume all of this lineage data in a systematic way, saving significant engineering time for building privacy controls. \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eAs we expanded PAI across Meta, \u003c/span\u003e\u003ca href=\"#learnings\"\u003e\u003cspan\u003ewe gained valuable insights\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e about the data lineage space. Our understanding of the privacy space evolved, revealing the need for early focus on data lineage, tooling, a cohesive ecosystem of libraries, and more. These initiatives have assisted in accelerating the development of data lineage and implementing purpose limitation controls more quickly and efficiently.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003eAt Meta, we believe that privacy enables product innovation. This belief has led us to developing \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2024/08/27/security/privacy-aware-infrastructure-purpose-limitation-meta/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003ePrivacy Aware Infrastructure (PAI)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, which offers efficient and reliable first-class privacy constructs embedded in Meta infrastructure to address different privacy requirements, such as \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2024/08/27/security/privacy-aware-infrastructure-purpose-limitation-meta/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003epurpose limitation\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, which restricts the purposes for which data can be processed and used. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eIn this blog, we will delve into an early stage in PAI implementation: \u003c/span\u003e\u003ci\u003e\u003cspan\u003edata lineage\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e. Data lineage refers to the process of tracing the journey of data as it moves through various systems, illustrating how data transitions from one data asset, such as a database table (the \u003c/span\u003e\u003ci\u003e\u003cspan\u003esource\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e asset), to another (the \u003c/span\u003e\u003ci\u003e\u003cspan\u003esink\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e asset). We’ll also walk through how we track the lineage of users’ “religion” information in our Facebook Dating app.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eMillions of data assets are vital for supporting our product ecosystem, ensuring the functionality our users anticipate, maintaining high product quality, and safeguarding user safety and integrity. Data lineage enables us to efficiently navigate these assets and protect user data. It enhances the traceability of data flows within systems, ultimately empowering developers to swiftly implement privacy controls and create innovative products.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eNote that data lineage is dependent on having already completed important and complex preliminary steps to inventory, schematize, and annotate data assets into a unified asset catalog. This took Meta multiple years to complete across our millions of disparate data assets, and we’ll cover each of these more deeply in future blog posts:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInventorying\u003c/strong\u003e involves collecting various code and data assets (e.g., web endpoints, data tables, AI models) used across Meta.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSchematization\u003c/strong\u003e expresses data assets in structural detail (e.g., indicating that a data asset has a field called “religion”).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAnnotation\u003c/strong\u003e labels data to describe its content (e.g., specifying that the identity column contains religion data).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003cspan\u003eUnderstanding data lineage at Meta\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eTo establish robust privacy controls, an essential part of our PAI initiative is to understand how data flows across different systems. Data lineage is part of this discovery step in the PAI workflow, as shown in the following diagram:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"217\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png 2710w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=916,194 916w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=768,163 768w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=1024,217 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=1536,326 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=2048,435 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=96,20 96w, https://engineering.fb.com/wp-content/uploads/2025/01/pai_workflow_lineage_s.png?resize=192,41 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eData lineage is a key precursor to implementing Policy Zones, our information flow control technology, because it answers the question, “\u003c/span\u003e\u003cspan\u003eWhere does my data come from and where does it go?” – helping inform the right places to apply privacy controls.\u003c/span\u003e\u003cspan\u003e In conjunction with Policy Zones, data lineage provides the following key benefits to thousands of developers at Meta: \u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eScalable data flow discovery\u003c/b\u003e\u003cspan\u003e: Data lineage answers the question above by providing an end-to-end, scalable graph of relevant data flows. We can leverage the lineage graphs to visualize and explain the flow of relevant data from the point where it is collected to all the places where it is processed.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eEfficient rollout of privacy controls\u003c/b\u003e\u003cspan\u003e: By leveraging data lineage to track data flows, we can easily pinpoint the optimal integration points for privacy controls like Policy Zones within the codebase, streamlining the rollout process. Thus we have developed a powerful flow discovery tool as part of our PAI tool suite, Policy Zone Manager (PZM), based on data lineage. PZM enables developers to rapidly identify multiple downstream assets from a set of sources simultaneously, thereby accelerating the rollout process of privacy controls.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eContinuous compliance verification\u003c/b\u003e\u003cspan\u003e: Once the privacy requirement has been fully implemented, data lineage plays a vital role in monitoring and validating data flows continuously, in addition to the enforcement mechanisms such as Policy Zones.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003eTraditionally, data lineage has been collected via code inspection using manually authored data flow diagrams and spreadsheets. However, this approach does not scale in large and dynamic environments, such as Meta, with billions of lines of continuously evolving code. To tackle this challenge, we’ve developed a robust and scalable lineage solution that uses static code analysis signals as well as runtime signals.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eWalkthrough: Implementing data lineage for religion data\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eWe’ll share how we have automated lineage tracking to identify religion data flows through our core systems, eventually creating an end-to-end, precise view of downstream religion assets being protected, via the following two key stages:\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eCollecting data flow signals\u003c/b\u003e\u003cspan\u003e: a process to capture data flow signals from many processing activities across different systems, not only for religion, but for all other types of data, to create an end-to-end lineage graph. \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eIdentifying relevant data flows\u003c/b\u003e\u003cspan\u003e: a process to identify the specific subset of data flows (“subgraph”) within the lineage graph that pertains to religion. \u003c/span\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cspan\u003eThese stages propagate through various systems including \u003c/span\u003e\u003ci\u003e\u003cspan\u003efunction-based systems\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e that load, process, and propagate data through stacks of function calls in different programming languages (e.g., Hack, C++, Python, etc.) such as web systems and backend services, and \u003c/span\u003e\u003ci\u003e\u003cspan\u003ebatch-processing systems\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e that process data rows in batch (mainly via SQL) such as data warehouse and AI systems. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eFor simplicity, we will demonstrate these for the web, the data warehouse, and AI, per the diagram below.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?w=1024\" alt=\"\" width=\"1024\" height=\"559\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png 2743w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=916,500 916w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=768,419 768w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=1024,559 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=1536,838 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=2048,1118 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=96,52 96w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_e2e_s_updated.png?resize=192,105 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eCollecting data flow signals for the web system\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eWhen setting up a profile on the Facebook Dating app, people can populate their religious views. This information is then utilized to identify relevant matches with other people who have specified matched values in their dating preferences. On Dating, religious views are subject to purpose limitation requirements, for example, \u003c/span\u003e\u003ca href=\"https://about.fb.com/news/2020/10/privacy-matters-facebook-dating/\"\u003e\u003cspan\u003ethey will not be used to personalize experiences on other Facebook Products\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"651\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png 1964w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?resize=916,582 916w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?resize=768,488 768w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?resize=1024,651 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?resize=1536,976 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?resize=96,61 96w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_religion_s.png?resize=192,122 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWe start with someone entering their religion information on their dating media profile using their mobile device, which is then transmitted to a web endpoint. The web endpoint subsequently logs the data into a logging table and stores it in a database, as depicted in the following code snippet:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?w=895\" alt=\"\" width=\"895\" height=\"1024\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png 1504w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?resize=801,916 801w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?resize=768,878 768w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?resize=895,1024 895w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?resize=1343,1536 1343w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?resize=96,110 96w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_profile_endpoint_code.png?resize=192,220 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eNow let’s see how we collect lineage signals. To do this, we need to employ both static and runtime analysis tools to effectively discover data flows, particularly focusing on where religion is logged and stored. \u003c/span\u003e\u003cspan\u003eBy combining static and runtime analysis, we enhance our ability to accurately track and manage data flows.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://engineering.fb.com/2021/10/20/security/static-analysis-award/\u0026#39;\"\u003e\u003cspan\u003eStatic analysis tools\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e simulate code execution to map out data flows within our systems. They also emit quality signals to indicate the confidence of whether a data flow signal is a true positive. However, these tools are limited by their lack of access to runtime data, which can lead to false positives from unexecuted code.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eTo address this limitation, we utilize \u003c/span\u003e\u003cb\u003ePrivacy Probes\u003c/b\u003e\u003cspan\u003e, a key component of our PAI lineage technologies. Privacy Probes automate data flow discovery by collecting runtime signals. These signals are gathered in real time during the execution of requests, allowing us to trace the flow of data into loggers, databases, and other services. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWe have instrumented Meta’s core data frameworks and libraries at both the data origin points (sources) and their eventual outputs (sinks), such as logging framework, which allows for comprehensive data flow tracking. This approach is exemplified in the following code snippet:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png?w=1024\" alt=\"\" width=\"1024\" height=\"791\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png 1404w, https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png?resize=916,707 916w, https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png?resize=768,593 768w, https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png?resize=1024,791 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png?resize=96,74 96w, https://engineering.fb.com/wp-content/uploads/2025/01/endpoint_controller_base_code.png?resize=192,148 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cbr/\u003e\n\u003cspan\u003eDuring runtime execution, Privacy Probes does the following:\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eCapturing payloads\u003c/b\u003e\u003cspan\u003e: It captures source and sink payloads in memory on a sampled basis, along with supplementary metadata such as event timestamps, asset identifiers, and stack traces as evidence for the data flow. \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eComparing payloads\u003c/b\u003e\u003cspan\u003e: It then compares the source and sink payloads within a request to identify data matches, which helps in understanding how data flows through the system. \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eCategorizing results\u003c/b\u003e\u003cspan\u003e: It categorizes results into two sets. The \u003c/span\u003e\u003ci\u003e\u003cspan\u003ematch-set\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e includes pairs of source and sink assets where data matches exactly or one is contained by another, therefore providing high confidence evidence of data flow between the assets. The \u003c/span\u003e\u003ci\u003e\u003cspan\u003efull-set\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e includes all source and sink pairs within a request no matter whether the sink is tainted by the source. Full-set is a superset of match-set with some noise but still important to send to human reviewers since it may contain transformed data flows. \u003c/span\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cspan\u003eThe above procedure is depicted in the diagram below:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"378\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png 2216w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=916,338 916w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=768,283 768w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=1024,378 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=1536,566 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=2048,755 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=96,35 96w, https://engineering.fb.com/wp-content/uploads/2025/01/probes_match_s.png?resize=192,71 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eLet’s look at the following examples where various religions are received in an endpoint and various values (copied or transformed) being logged in three different loggers:\u003c/span\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cb\u003eInput Value (source)\u003c/b\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cb\u003eOutput Value (sink)\u003c/b\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cb\u003eData Operation\u003c/b\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cb\u003eMatch Result\u003c/b\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cb\u003eFlow Confidence\u003c/b\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cspan\u003e“Atheist”\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003e“Atheist”\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eData Copy\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eEXACT_MATCH\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eHIGH\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cspan\u003e“Buddhist”\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003e{metadata: {religion: Buddhist}}\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eSubstring\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eCONTAINS\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eHIGH\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cspan\u003e{religions:\u003cbr/\u003e\n\u003c/span\u003e\u003cspan\u003e[“Catholic”, “Christian”]}\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003e{count : 2}\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eTransformed\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eNO_MATCH\u003c/span\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cspan\u003eLOW\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cspan\u003e\u003cbr/\u003e\nIn the examples above, the first two rows show a precise match of religions in the source and the sink values, thus belonging to the high confidence match-set. The third row depicts a transformed data flow where the input string value is transformed to a count of values before being logged, belonging to full-set. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThese signals together are used to construct a lineage graph to understand the flow of data through our web system as shown in the following diagram:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"312\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png 2437w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=916,279 916w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=768,234 768w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=1024,312 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=1536,468 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=2048,624 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=96,29 96w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_s.png?resize=192,59 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eCollecting data flow signals for the data warehouse system\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eWith the user’s religion logged in our web system, it can propagate to the data warehouse for offline processing. To gather data flow signals, we employ a combination of both runtime instrumentation and static code analysis in a different way from the web system. The involved SQL queries are logged for data processing activities by the \u003c/span\u003e\u003ca href=\"https://research.facebook.com/publications/presto-sql-on-everything/\"\u003e\u003cspan\u003ePresto\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e and \u003c/span\u003e\u003ca href=\"https://spark.apache.org/\"\u003e\u003cspan\u003eSpark\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e compute engines (among others). Static analysis is then performed for the logged SQL queries and job configs in order to extract data flow signals.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eLet’s examine a simple SQL query example that processes data for the data warehouse as the following:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png?w=1024\" alt=\"\" width=\"1024\" height=\"292\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png 1404w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png?resize=916,261 916w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png?resize=768,219 768w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png?resize=1024,292 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png?resize=96,27 96w, https://engineering.fb.com/wp-content/uploads/2025/01/dating_data_sql_code.png?resize=192,55 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003cbr/\u003e\n\u003cspan\u003eWe’ve developed a \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2022/11/30/data-infrastructure/static-analysis-sql-queries/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003eSQL analyzer\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e to extract data flow signals between the input table, “safety_log_tbl” and the output table, “safety_training_tbl” as shown in the following diagram. In practice, we also collect more granular-level lineage such as at column-level (e.g., “user_id” -\u0026gt; “target_user_id”, “religion” -\u0026gt; “target_religion”).\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eT\u003c/span\u003e\u003cspan\u003ehere are instances where data is not fully processed by SQL queries, resulting in logs that contain data flow signals for either reads or writes, but not both.\u003c/span\u003e\u003cspan\u003e To ensure we have complete lineage data, we leverage contextual information (such as execution environments; job or trace IDs) collected at runtime to connect these reads and writes together. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThe following diagram illustrates how the lineage graph has expanded:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"593\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png 2436w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=916,530 916w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=768,445 768w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=1024,593 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=1536,889 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=2048,1185 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=96,56 96w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_s.png?resize=192,111 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan\u003eCollecting data flow signals for the AI system\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eFor our AI systems, we collect lineage signals by tracking relationships between various assets, such as input datasets, features, models, workflows, and inferences. A common approach is to extract data flows from job configurations used for different AI activities such as model training.\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003cspan\u003eFor instance, in order to improve the relevance of dating matches, we use an AI model to recommend potential matches based on shared religious views from users. Let’s take a look at the following training config example for this model that uses religion data:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png?w=1024\" alt=\"\" width=\"1024\" height=\"829\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png 1404w, https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png?resize=916,741 916w, https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png?resize=768,621 768w, https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png?resize=1024,829 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png?resize=96,78 96w, https://engineering.fb.com/wp-content/uploads/2025/01/training_config_code.png?resize=192,155 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eBy parsing this config obtained from the model training service, we can track the data flow from the input dataset (with asset ID asset://hive.table/dating_training_tbl) and feature (with asset ID asset://ai.feature/DATING_USER_RELIGION_SCORE) to the model (with asset ID asset://ai.model/dating_ranking_model).\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eOur AI systems are also instrumented so that asset relationships and data flow signals are captured at various points at runtime, including data-loading layers (e.g., \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2022/09/19/ml-applications/data-ingestion-machine-learning-training-meta/\"\u003e\u003cspan\u003eDPP\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e) and libraries (e.g., \u003c/span\u003e\u003ca href=\"https://pytorch.org/\"\u003e\u003cspan\u003ePyTorch\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e), workflow engines (e.g., \u003c/span\u003e\u003ca href=\"https://engineering.fb.com/2016/05/09/core-infra/introducing-fblearner-flow-facebook-s-ai-backbone/\"\u003e\u003cspan\u003eFBLearner Flow\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e), training frameworks, inference systems (as backend services), etc. Lineage collection for backend services utilizes the approach for function-based systems described above. By matching the source and sink assets for different data flow signals, we are able to capture a holistic lineage graph at the desired granularities:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"600\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png 2416w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=916,537 916w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=768,450 768w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=1024,600 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=1536,900 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=2048,1200 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=96,56 96w, https://engineering.fb.com/wp-content/uploads/2025/01/lineage_exp_web_dw_ai_s.png?resize=192,113 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eIdentifying relevant data flows from a lineage graph\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eNow that we have the lineage graph at our disposal, how can we effectively distill a subset of data flows pertinent to a specific privacy requirement for religion data? \u003c/span\u003e\u003cspan\u003eTo address this question, we have developed an iterative analysis tool that enables developers to pinpoint precise data flows and systematically filter out irrelevant ones\u003c/span\u003e\u003cspan\u003e. The tool kicks off a repetitive discovery process aided by the lineage graph and privacy controls from Policy Zones, to narrow down the most relevant flows. This refined data allows developers to make a final determination about the flows they would like to use, producing an optimal path for traversing the lineage graph. The following are the major steps involved, captured holistically in the diagram, below:\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eDiscover data flows: \u003c/b\u003e\u003cspan\u003eidentify data flows from source assets and stop at downstream assets with low-confidence flows (yellow nodes). \u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eExclude and include candidates: \u003c/b\u003e\u003cspan\u003eDevelopers or automated heuristics exclude candidates (red nodes) that don’t have religion data or include remaining ones (green nodes). By excluding the red nodes early on, it helps to exclude all of their downstream in a cascaded manner, and thus saves developer efforts significantly. As an additional safeguard, developers also implement privacy controls via Policy Zones, so all relevant data flows can be captured.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eRepeat discovery cycle: \u003c/b\u003e\u003cspan\u003euse the green nodes as new sources and repeat the cycle until no more green nodes are confirmed. \u003c/span\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?w=1024\" alt=\"\" width=\"1024\" height=\"711\" srcset=\"https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png 2232w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=916,636 916w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=768,533 768w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=1024,711 1024w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=1536,1066 1536w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=2048,1421 2048w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=96,67 96w, https://engineering.fb.com/wp-content/uploads/2025/01/iterative_tool_s.png?resize=192,133 192w\" sizes=\"auto, (max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWith the collection and data flow identification steps complete, developers are able to successfully locate granular data flows that contain religion across Meta’s complex systems, allowing them to move forward in the PAI workflow to apply necessary privacy controls to safeguard the data. This once-intimidating task has been completed efficiently. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eOur data lineage technology has provided developers with an unprecedented ability to quickly understand and protect religion and similar sensitive data flows. It enables Meta to scalably and efficiently implement privacy controls via PAI to protect our users’ privacy and deliver products safely.\u003c/span\u003e\u003c/p\u003e\n\u003ch2 id=\"learnings\"\u003e\u003cspan\u003eLearnings and challenges\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eAs we’ve worked to develop and implement lineage as a core PAI technology, we’ve gained valuable insights and overcome significant challenges, yielding some important lessons:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eFocus on lineage early and reap the rewards\u003c/b\u003e\u003cspan\u003e: As we developed privacy technologies like Policy Zones, it became clear that gaining a deep understanding of data flows across various systems is essential for scaling the implementation of privacy controls. By investing in lineage, we not only accelerated the adoption of Policy Zones but also uncovered new opportunities for applying the technology. Lineage can also be extended to other use cases such as security and integrity.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eBuild lineage consumption tools to gain engineering efficiency\u003c/b\u003e\u003cspan\u003e: We initially focused on building a lineage solution but didn’t give sufficient attention to consumption tools for developers. As a result, owners had to use raw lineage signals to discover relevant data flows, which was overwhelmingly complex. We addressed this issue by developing the iterative tooling to guide engineers in discovering relevant data flows, significantly reducing engineering efforts by orders of magnitude.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eIntegrate lineage with systems to scale the coverage\u003c/b\u003e\u003cspan\u003e: Collecting lineage from diverse Meta systems was a significant challenge. Initially, we tried to ask every system to collect lineage signals to ingest into the centralized lineage service, but the progress was slow. We overcame this by developing reliable, computationally efficient, and widely applicable PAI libraries with built-in lineage collection logic in various programming languages (Hack, C++, Python, etc.). This enabled much smoother integration with a broad range of Meta’s systems.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eMeasurement improves our outcomes\u003c/b\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003eBy incorporating the measurement of coverage, we’ve been able to evolve our data lineage so that we stay ahead of the ever-changing landscape of data and code at Meta. By enhancing our signals and adapting to new technologies, we can maintain a strong focus on privacy outcomes and drive ongoing improvements in lineage coverage across our tech stacks.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003cspan\u003eThe future of data lineage\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eData lineage is a vital component of Meta’s PAI initiative, providing a comprehensive view of how data flows across different systems. While we’ve made significant progress in establishing a strong foundation, our journey is ongoing. We’re committed to:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eExpanding coverage\u003c/b\u003e\u003cspan\u003e: continuously enhance the coverage of our data lineage capabilities to ensure a comprehensive understanding of data flows.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eImproving consumption experience\u003c/b\u003e\u003cspan\u003e: streamline the consumption experience to make it easier for developers and stakeholders to access and utilize data lineage information.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eExploring new frontiers\u003c/b\u003e\u003cspan\u003e: investigate new applications and use cases for data lineage, driving innovation and collaboration across the industry.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003eBy advancing data lineage, we aim to foster a culture of privacy awareness and drive progress in the broader fields of study. Together, we can create a more transparent and accountable data ecosystem.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eAcknowledgements\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ci\u003e\u003cspan\u003eThe authors would like to acknowledge the contributions of many current and former Meta employees who have played a crucial role in developing data lineage technologies over the years. In particular, we would like to extend special thanks to (in alphabetical order) Amit Jain, Aygun Aydin, Ben Zhang, Brian Romanko, Brian Spanton, Daniel Ramagem, David Molnar, Dzmitry Charnahalau, Gayathri Aiyer, George Stasa, Guoqiang Jerry Chen, Graham Bleaney, Haiyang Han, Howard Cheng, Ian Carmichael, Ibrahim Mohamed, Jerry Pan, Jiang Wu, Jonathan Bergeron, Joanna Jiang, Jun Fang, Kiran Badam, Komal Mangtani, Kyle Huang, Maharshi Jha, Manuel Fahndrich, Marc Celani, Lei Zhang, Mark Vismonte, Perry Stoll, Pritesh Shah, Qi Zhou, Rajesh Nishtala, Rituraj Kirti, Seth Silverman, Shelton Jiang, Sushaant Mujoo, Vlad Fedorov, Yi Huang, Xinbo Gao, and Zhaohui Zhang. We would also like to express our gratitude to all reviewers of this post, including (in alphabetical order) Aleksandar Ilic, Avtar Brar, Benjamin Renard, Bogdan Shubravyi, Brianna O’Steen, Chris Wiltz, Daniel Chamberlain, Hannes Roth, Imogen Barnes, Jason Hendrickson, Koosh Orandi, Rituraj Kirti, and Xenia Habekoss. We would like to especially thank Jonathan Bergeron for overseeing the effort and providing all of the guidance and valuable feedback, Supriya Anand for leading the editorial effort to shape the blog content, and Katherine Bates for pulling all required support together to make this blog post happen.\u003c/span\u003e\u003c/i\u003e\u003c/p\u003e\n\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "22 min read",
  "publishedTime": "2025-01-23T05:00:45Z",
  "modifiedTime": "2025-01-28T17:23:42Z"
}
