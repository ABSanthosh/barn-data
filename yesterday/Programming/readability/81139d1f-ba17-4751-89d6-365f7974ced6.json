{
  "id": "81139d1f-ba17-4751-89d6-365f7974ced6",
  "title": "Breaking to Build: Fuzzing the Kotlin Compiler",
  "link": "https://blog.jetbrains.com/research/2025/07/fuzzing-the-kotlin-compiler/",
  "description": "At JetBrains, we care about Kotlin compiler quality. One powerful way to test it? Fuzzing, an approach that feeds programs unexpected, often random, inputs to uncover bugs that traditional tests may miss. It may sound chaotic, but it works, especially for complex software like compilers. In a previous post, our colleagues introduced kotlinx.fuzz, a powerful […]",
  "author": "Katie Fraser",
  "published": "Thu, 17 Jul 2025 13:00:54 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": [
    "kotlin",
    "research",
    "compiler-fuzzing",
    "fuzzing",
    "jetbrains-research",
    "k1",
    "k2",
    "kotlin-compiler"
  ],
  "byline": "Katie Fraser",
  "length": 18389,
  "excerpt": "At JetBrains, we care about Kotlin compiler quality. One powerful way to test it? Fuzzing, an approach that feeds programs unexpected, often random, inputs to uncover bugs that traditional tests may m",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "JetBrains Research Research is crucial for progress and innovation, which is why at JetBrains we are passionate about both scientific and market research Kotlin Research At JetBrains, we care about Kotlin compiler quality. One powerful way to test it? Fuzzing, an approach that feeds programs unexpected, often random, inputs to uncover bugs that traditional tests may miss. It may sound chaotic, but it works, especially for complex software like compilers. In a previous post, our colleagues introduced kotlinx.fuzz, a powerful tool for uncovering bugs in Kotlin programs. As the Kotlin compiler is a Kotlin program, we can use fuzzing to test it, too.  In this post we will: Explain what fuzzing is and how it compares to traditional compiler testing techniques. Show how we applied it to the Kotlin compiler in collaboration with TU Delft. Share real bugs we caught and fixed, including in the new K2 compiler. Compiler fuzzing vs. traditional compiler testing techniques Compilers are essential to software development, as they transform the code we write into instructions that machines can read and then execute. Compilers are used not once, but multiple times throughout the whole software development stack. Without them you cannot compile your operating system kernel, your system library, or your JavaScript engine. Figure 1 points out where compilers are needed, underlining how crucial they are.  Figure 1: The importance of compilers in the software development stack. Figure 1 shows that compilers are not just an isolated development tool but are also needed to compile your source code in other places in the stack. This means that when something as important as a compiler contains bugs, it can cause bigger problems, such as: Security holes or vulnerabilities Incorrect code generation, subtly inconsistent with the original source code Performance issues via mistriggered optimization Compiler crashes So how do we ensure that compilers are free of errors? The rest of this section will outline some ways to detect bugs, starting with more traditional techniques and then moving on to fuzzing. Uncovering bugs: Traditional techniques Traditional testing techniques focus on program behavior, namely, whether it produces correct output with valid input while properly handling any errors with invalid input. Table 1 lists some common methods. WhatHowUnit testsCheck individual components (e.g., lexer, parser, code generator)Functional testsVerify that all compiler components behave as expected Gold verification tests (regression tests)Compile a suite of known programs and compare compilation result to the expected output (i.e., gold standard)Integration testsCheck whether compiler runs correctly with other tools or systems (e.g., build systems, linkers, or runtime environments)Cross-platform testsTest compiler on different operating systems or platforms for consistency Table 1: Traditional testing techniques. These traditional techniques are essential for compiler development, but they may miss subtle bugs that only appear under specific circumstances. This is where advanced techniques like fuzzing can be more successful. Fuzzing, or the art of breaking things to make them better At its heart, fuzzing is based on a very simple idea: let’s throw a lot of random inputs at a program to see if it breaks. Long before fuzzing was adopted as a named technique, developers have been known to use a form of it. For example, programmers in the 1950s could test programs with a trash-deck technique: they input punch card decks from the trash or random-number punch cards to see when undesirable behavior might occur.  While working on the Apple Macintosh in 1983, Steve Capps developed a tool to test MacWrite and MacPaint applications, which at the time were battling low memory conditions. Called The Monkey, it fed random events to an application and caused the computer (in this case, the Macintosh) to behave as if it were “operated by an incredibly fast, somewhat angry monkey, banging away at the mouse and keyboard, generating clicks and drags at random positions with wild abandon”. To increase testing quality, Capps limited some random events, like menu commands, to a certain percentage, and later Bill Atkinson defined a system flag to disable commands such as quit, so the test could run as long as possible. Although the tool itself became obsolete when later Macintosh iterations freed up more memory, it is an important part of software testing history. The term fuzzing is credited to Professor Barton Miller, who first experienced interference noise on a dial-up link when remotely logging into a Unix system during a storm in 1988. This noise caused the programs to crash, a surprise considering they were common Unix utilities. So that this effect could be explored more in depth, Miller then assigned his students a project to “evaluate the robustness of various Unix utility programs, given an unpredictable input stream”. One student group went on to publish a 1990 paper with Miller on their findings. Fuzzing fundamentals In contrast to carefully designed test cases like those in Table 1 above, fuzzing uses randomly generated inputs that can be unexpected or even deliberately nonsensical. The more diverse the inputs, the more likely the fuzzing tool (i.e., the fuzzer) will be to find unexpected issues. A fuzzer has three essential components: (i) an input data generator, which generates diverse inputs, (ii) the software under test (sometimes abbreviated as SUT), which processes these inputs, and (iii) a reference model, which produces the correct output from the same inputs. Both the software and the reference model produce outputs from the same inputs, and these outputs are compared to one another. Figure 2 depicts the relationship between the three components, the outputs to be compared, and the fuzzing result. Figure 2: Fuzzing basics. The fuzzing result tells us whether or not the software performed correctly with the automatically generated input, as compared to the reference model with that same input. This process is repeated over and over, represented in the above image by multiple windows. This repetition ensures that the inputs used for testing are sufficiently diverse.  The idea is to find inputs which cause the software to fail, either by crashing or producing incorrect results. It’s not so much about testing the intended functionality. That is, fuzzing investigates the edge cases of what the software can or cannot handle. Compiler fuzzing techniques So far, we’ve covered the basic idea of fuzzing and a brief history of it. In this section, we will get more specific, starting with different ways to fuzz compilers. Two fuzzing types that are more advanced are generative fuzzing, which constructs test programs from scratch based on grammar or specification of the target inputs, and mutation-based fuzzing, which starts with existing, valid, programs and modifies them to create new test inputs. Modifications (mutations) can include inserting, deleting, or replacing input parts. Table 2 lists pros and cons for each.  Table 2: A comparison of generative and mutation-based fuzzing. Figure 3 further compares the two techniques to basic fuzzing, underlining their trade-offs on how well they cover different parts of the compiler vs. how deep they can explore it. Figure 3: A comparison of fuzzing types. This section has described fuzzing basics and how fuzzing is an effective method for ensuring a high standard in compiler quality. Going forward, we will focus on fuzzing the Kotlin compiler specifically. Kotlin compiler fuzzing Fuzzing is already a widespread practice for many programming languages, from C++ and JS to Java. At JetBrains, our Kotlin team is no stranger to fuzzing the Kotlin compiler. We have collaborated with external research groups to try to break the compiler with differing fuzzing approaches. One of the first collaborations gave us a great example of how to crash kotlinc using 8 characters and the main function. This is shown below. fun main() {     (when{}) // Crash in Kotlin 1.3, fixed in 1.5 } You can also access the example on Kotlin Playground in Kotlin 1.3 and Kotlin 1.5 versions, i.e., before and after the bug was fixed. The following code blocks contain two more examples of bugs found by fuzzing. fun \u003cbreak\u003e foo() // Compilation crash on type parameter named `break` fun box(){     foo() } This example shows a compiler crash when it encounters a reserved identifier (such as break) in the position of a type parameter. fun box(): String {     return if (true) {         val a = 1 // No error when we are expected to return a `String`     } else {         \"fail:\"     } } fun main(args: Array\u003cString\u003e) {     println(box()) } The above example shows a miscompilation of when the compiler failed to reject an incorrect program: the if expression should return a String, but the true branch does not return anything. Figure 4 displays an incomplete trophy list of found-by-fuzzer bugs, demonstrating fuzzing’s usefulness. Many of the reported bugs greatly helped us in the K2 compiler stabilization. Figure 4: Incomplete trophy list of found-by-fuzzer bugs. Evolutionary generative fuzzing Last year, we collaborated with TU Delft’s SERG team to more rigorously explore the properties of generative fuzzing. In this 2024 paper, we looked at generative fuzzing as an evolutionary algorithm problem and developed a fuzzing approach: Evolutionary Generative Fuzzing. This subsection will describe our approach in more detail. First, let’s break down the term evolutionary generative fuzzing. As discussed above, generative fuzzing is a bottom-up approach to creating program inputs, generating them following a specific set of rules. In the present case, the generation rules are based on the language syntax, or the Kotlin grammar, and its semantics, or the Kotlin specification.  The term’s evolutionary part comes from evolutionary algorithms, an approach that simulates the real evolutionary process. Evolutionary algorithms and a common subtype, genetic algorithms, are optimization techniques that use natural selection and genetic inheritance principles for solving complex problems in programming.  First we will talk about the basic concepts of a genetic algorithm, then we will apply these concepts to fuzzing. Essentially, these types of algorithms are meant to mimic the way living organisms evolve over generations to adapt and survive in their environments. Figure 5 depicts this cycle. Figure 5: Genetic algorithm cycle. As a problem-solving technique, a genetic algorithm starts with a specific problem, and for this problem there are multiple candidate solutions. Each solution represents an individual (sometimes called chromosome), which could be,  for example, a specific input for a function. A set of individuals represents a population, just like in the natural world. To begin the algorithm, an initial population must be generated, typically a set of random individuals (i.e., candidate solutions). After the initial population is generated,  a fitness function evaluates the suitability of each individual within the population, only retaining those individuals most the most fit to move on to the next generation. Then, the set of fit individuals mutate and recombine to form a  new population. This new  combination of individuals make up the next generation’s population. Let’s apply this to our Kotlin compiler fuzzing approach, represented in the more specialized version of the evolutionary cycle in Figure 6. The lighter-colored and smaller rectangles attached to the larger ones represent the relevant action needed to reach each stage.  Figure 6: Genetic algorithm in the evolutionary generative fuzzing approach. To begin, the individuals are Kotlin code snippets created with generative fuzzing. To create the initial population, we sample multiple code snippets, which are then evaluated by a fitness function. And to simulate reproduction, we split each snippet into code blocks, where each block represents an individual’s chromosome. These code-block chromosomes then mutate and recombine to create new code snippets, which are sampled to create the next generation’s population. An important takeaway of the approach is: The evolutionary generative fuzzer is not purely generative: it is also partially mutation-based. As mentioned above, a fitness function plays an integral part in the evolutionary cycle. In this work we hypothesized that structurally diverse code is more likely to exercise different compiler components than more uniform code; by stressing various compiler components, more bugs will be able to be uncovered. To test this, we investigated a baseline and two different ways to calculate the fitness function, with both being attempts to optimize the sampled code’s diversity. As a baseline, our approach used what is called random search (RS), as it samples programs without any fitness function. We also used different measures of diversity realized through the fitness functions to apply two novel types of genetic algorithms (GAs): single-objective and many-objective functions for the single-objective diversity GA (SODGA) and many-objective diversity GA (MODGA), respectively. The details of these two genetic algorithms and the baseline are summarized in Table 3. Table 3: Approaches and their fitness-function details. The generated code was then compiled with both the original K1 compiler and the new K2 compiler released with Kotlin 2.0. This allowed us to focus on K1-to-K2 changes and find situations when the new compiler introduces regressions or unexpected behavior changes. Applying any approach listed in Table 3 results in finding interesting bugs, and the different approaches complement each other in terms of bug-detecting categories: random search (RS in Table 3) is effective for detecting more straightforward differential bugs such as out-of-memory errors and resolution ambiguity, whereas the two genetic algorithms (SODGA and MODGA in Table 3) are successful in detecting nuanced problems such as with conflicting overloads, shown in the code example below. fun main() {     fun p(): Char { return 'c' }     fun p(): Float { return 13.0f } } The intended behavior of the above code block is that the compiler reports a conflicting overloads error, as the two p functions should cause a resolution conflict. The K1 compiler returns the appropriate error, while the K2 compiles the code without any warning. By applying two types of genetic algorithms, we were able to uncover several independent instances of this bug, and we fixed this error in Kotlin 2.0. Overall, our team’s complex approach to Kotlin compiler fuzzing has led to the discovery of previously unknown bugs. In combining both generative and mutation-based fuzzing, we have been able to enhance bug discovery. The future of fuzzing Fuzzing has already enabled our team to find and fix many compiler bugs, improving the Kotlin compiler. Our research collaboration with TU Delft’s SERG team produced a more advanced approach to fuzzing, combining generative and mutation-based methods, and with this foundation we can fine tune fuzzing even more. Fuzzing is an active field of research with many opportunities for advancement, and fuzzing a complex, industrial language like Kotlin presents unique challenges that require careful attention for the advancement of fuzzing, as well as for the results to be useful. These challenges and their possible solutions are listed in Table 4. ChallengePossible solutionMaintaining code validity, with code that is both syntactically correct and semantically meaningful. Often requires fuzzer implementation to include parts tailored to target language.Custom handwritten generators for more complicated parts of KotlinFinding different types of bugs and thoroughly testing all compiler parts to ensure good compiler code coverage.Coverage-guided fuzzing: one component of the fitness function is X if a code snippet reaches so far unexplored compiler partsAfter finding bugs, localizing faults by determining the exact cause and the code responsible. Fuzzers often produce large amounts of test cases, which require manual analysis.  MOGDA, as it naturally prefers generating smaller and easier-to-understand programs A good fuzzer needs to be able to avoid duplicates and instead trigger new, unique bugs, instead of the same bugs repeatedly.For now, this problem is solved manually, but there are different possibilities to do this automatically Table 4: Fuzzing challenges and possible solutions. Our Kotlin compiler team continues to address these challenges by improving fuzzing capabilities in an incremental fashion. We want to keep on providing you with reliable software, and that includes reducing distractions so that you can focus on having fun while developing in Kotlin! More fuzzing resources Curious to explore the research or try out fuzzing on your own Kotlin code? Check out these resources! Our paper in collaboration with TU Delft’s SERG team A post about input reduction in Kotlin compiler fuzzing  The Fuzzing Book, a textbook available online with lots of detailed information and great examples Fuzz Testing: A Beginner’s Guide, an article with more about different types of fuzzing and how to try it yourself A Survey of Compiler Testing, another academic article Discover more",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2025/07/KT-social-BlogSocialShare-1280x720-2x-4.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n    \u003cdiv\u003e\n                        \u003ca href=\"https://blog.jetbrains.com/research/\"\u003e\n                                                                                                                            \u003ch2\u003eJetBrains Research\u003c/h2\u003e\n                                                                                    \u003c/a\u003e\n                                                    \u003cp\u003eResearch is crucial for progress and innovation, which is why at JetBrains we are passionate about both scientific and market research\u003c/p\u003e\n                                            \u003c/div\u003e\n                            \u003csection data-clarity-region=\"article\"\u003e\n                \u003cdiv\u003e\n                    \t\t\t\t\u003cp\u003e\u003ca href=\"https://blog.jetbrains.com/research/category/kotlin/\"\u003eKotlin\u003c/a\u003e\n\t\t\t\u003ca href=\"https://blog.jetbrains.com/research/category/research/\"\u003eResearch\u003c/a\u003e\u003c/p\u003e                    \n                    \n\u003cp\u003eAt JetBrains, we care about \u003ca href=\"https://kotlinlang.org/\" target=\"_blank\" rel=\"noopener\"\u003eKotlin\u003c/a\u003e compiler quality. One powerful way to test it? Fuzzing, an approach that feeds programs unexpected, often random, inputs to uncover bugs that traditional tests may miss. It may sound chaotic, but it works, especially for complex software like compilers.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn \u003ca href=\"https://blog.jetbrains.com/research/2025/04/kotlinxfuzz-kotlin-fuzzing/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ea previous post\u003c/a\u003e, our colleagues introduced \u003ca href=\"https://github.com/JetBrains-Research/kotlinx.fuzz\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003ekotlinx.fuzz\u003c/strong\u003e\u003c/a\u003e, a powerful tool for uncovering bugs in Kotlin programs.  As the Kotlin compiler is a Kotlin program, we can use fuzzing to test it, too.  In this post we will:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eExplain what fuzzing is and how it compares to traditional compiler testing techniques.\u003c/li\u003e\n\n\n\n\u003cli\u003eShow how we applied it to the Kotlin compiler in collaboration with \u003ca href=\"https://se.ewi.tudelft.nl/\" target=\"_blank\" rel=\"noopener\"\u003e\u003c/a\u003e\u003ca href=\"https://se.ewi.tudelft.nl/\" target=\"_blank\" rel=\"noopener\"\u003eTU Delft\u003c/a\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003eShare real bugs we caught and fixed, including in the new K2 compiler.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2 id=\"fuzzing-vs-traditional-compiler-testing-techniques\"\u003eCompiler fuzzing vs. traditional compiler testing techniques\u003c/h2\u003e\n\n\n\n\u003cp\u003eCompilers are essential to software development, as they transform the code we write into instructions that machines can read and then execute. Compilers are used not once, but multiple times throughout the whole software development stack. Without them you cannot compile your operating system kernel, your system library, or your JavaScript engine. Figure 1 points out where compilers are needed, underlining how crucial they are. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" fetchpriority=\"high\" width=\"1804\" height=\"1304\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/900-650-2.png\" alt=\"The importance of compilers in the software development stack\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp id=\"figureone\"\u003e\u003cem\u003eFigure 1: The importance of compilers in the software development stack.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eFigure 1 shows that compilers are not just an isolated development tool but are also needed to compile your source code in other places in the stack. This means that when something as important as a compiler contains bugs, it can cause bigger problems, such as:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eSecurity holes or vulnerabilities\u003c/li\u003e\n\n\n\n\u003cli\u003eIncorrect code generation, subtly inconsistent with the original source code\u003c/li\u003e\n\n\n\n\u003cli\u003ePerformance issues via mistriggered optimization\u003c/li\u003e\n\n\n\n\u003cli\u003eCompiler crashes\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eSo how do we ensure that compilers are free of errors? The rest of this section will outline some ways to detect bugs, starting with more traditional techniques and then moving on to fuzzing.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"uncovering-bugs-traditional-techniques\"\u003eUncovering bugs: Traditional techniques\u003c/h3\u003e\n\n\n\n\u003cp\u003eTraditional testing techniques focus on program behavior, namely, whether it produces correct output with valid input while properly handling any errors with invalid input. Table 1 lists some common methods.\u003c/p\u003e\n\n\n\n\u003cfigure id=\"tableone\"\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cstrong\u003eWhat\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003e\u003cstrong\u003eHow\u003c/strong\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eUnit tests\u003c/td\u003e\u003ctd\u003eCheck individual components (e.g., lexer, parser, code generator)\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eFunctional tests\u003c/td\u003e\u003ctd\u003eVerify that all compiler components behave as expected \u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eGold verification tests (regression tests)\u003c/td\u003e\u003ctd\u003eCompile a suite of known programs and compare compilation result to the expected output (i.e., \u003cem\u003egold standard\u003c/em\u003e)\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eIntegration tests\u003c/td\u003e\u003ctd\u003eCheck whether compiler runs correctly with other tools or systems (e.g., build systems, linkers, or runtime environments)\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eCross-platform tests\u003c/td\u003e\u003ctd\u003eTest compiler on different operating systems or platforms for consistency\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTable 1: Traditional testing techniques.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThese traditional techniques are essential for compiler development, but they may miss subtle bugs that only appear under specific circumstances. This is where advanced techniques like fuzzing can be more successful.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"fuzzing-or-the-art-of-breaking-things-to-make-them-better\"\u003eFuzzing, or the art of breaking things to make them better\u003c/h3\u003e\n\n\n\n\u003cp\u003eAt its heart, fuzzing is based on a very simple idea: let’s throw a lot of random inputs at a program to see if it breaks. Long before \u003cem\u003efuzzing\u003c/em\u003e was adopted as a named technique, developers have been known to use a form of it. For example, programmers in the 1950s could test programs with a trash-deck technique: they input punch card decks from the trash or random-number punch cards to see when undesirable behavior might occur. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile working on the Apple Macintosh in 1983, \u003ca href=\"https://folklore.org/Monkey_Lives.html?sort=date\" target=\"_blank\" rel=\"noopener\"\u003eSteve Capps developed a tool\u003c/a\u003e to test MacWrite and MacPaint applications, which at the time were battling low memory conditions. Called \u003cem\u003eThe Monkey\u003c/em\u003e, it fed random events to an application and caused the computer (in this case, the Macintosh) to behave as if it were “operated by an incredibly fast, somewhat angry monkey, banging away at the mouse and keyboard, generating clicks and drags at random positions with wild abandon”. \u003c/p\u003e\n\n\n\n\u003cp\u003eTo increase testing quality, Capps limited some random events, like menu commands, to a certain percentage, and later Bill Atkinson defined a system flag to disable commands such as \u003cem\u003equit\u003c/em\u003e, so the test could run as long as possible. Although the tool itself became obsolete when later Macintosh iterations freed up more memory, it is an important part of software testing history.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe term \u003cem\u003efuzzing \u003c/em\u003eis \u003ca href=\"https://pages.cs.wisc.edu/~bart/fuzz/Foreword1.html\" target=\"_blank\" rel=\"noopener\"\u003ecredited to Professor Barton Miller\u003c/a\u003e, who first experienced interference noise on a dial-up link when remotely logging into a Unix system during a storm in 1988. This noise caused the programs to crash, a surprise considering they were common Unix utilities. So that this effect could be explored more in depth, Miller then \u003ca href=\"https://fuzzinginfo.wordpress.com/wp-content/uploads/2012/05/cs736-projects-f1988.pdf\" target=\"_blank\" rel=\"noopener\"\u003eassigned his students a project\u003c/a\u003e to “evaluate the robustness of various Unix utility programs, given an unpredictable input stream”. One student group went on to publish \u003ca href=\"https://www.paradyn.org/papers/fuzz.pdf\" target=\"_blank\" rel=\"noopener\"\u003ea 1990 paper\u003c/a\u003e with Miller on their findings.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"fuzzing-fundamentals\"\u003eFuzzing fundamentals\u003c/h3\u003e\n\n\n\n\u003cp\u003eIn contrast to carefully designed test cases like those in \u003ca href=\"#tableone\" data-type=\"internal\" data-id=\"#table1\"\u003eTable 1\u003c/a\u003e above, fuzzing uses randomly generated inputs that can be unexpected or even deliberately nonsensical. The more diverse the inputs, the more likely the fuzzing tool (i.e., the \u003cem\u003efuzzer\u003c/em\u003e) will be to find unexpected issues.\u003c/p\u003e\n\n\n\n\u003cp\u003eA fuzzer has three essential components: (i) an input data generator, which generates diverse inputs, (ii) the software under test (sometimes abbreviated as SUT), which processes these inputs, and (iii) a reference model, which produces the correct output from the same inputs. Both the software and the reference model produce outputs from the same inputs, and these outputs are compared to one another. Figure 2 depicts the relationship between the three components, the outputs to be compared, and the fuzzing result.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1600\" height=\"1139\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/image-9.png\" alt=\"Fuzzing basics\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp id=\"figuretwo\"\u003e\u003cem\u003eFigure 2: Fuzzing basics.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe fuzzing result tells us whether or not the software performed correctly with the automatically generated input, as compared to the reference model with that same input. This process is repeated over and over, represented in the above image by multiple windows.  \u003cstrong\u003eThis repetition ensures that the inputs used for testing are sufficiently diverse.\u003c/strong\u003e \u003c/p\u003e\n\n\n\n\u003cp\u003eThe idea is to find inputs which cause the software to fail, either by crashing or producing incorrect results. It’s not so much about testing the intended functionality. That is, \u003cstrong\u003efuzzing investigates the edge cases of what the software can or cannot handle\u003c/strong\u003e.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"compiler-fuzzing-techniques\"\u003eCompiler fuzzing techniques\u003c/h2\u003e\n\n\n\n\u003cp\u003eSo far, we’ve covered the basic idea of fuzzing and a brief history of it. In this section, we will get more specific, starting with different ways to fuzz compilers.\u003c/p\u003e\n\n\n\n\u003cp\u003eTwo fuzzing types that are more advanced are \u003cstrong\u003e\u003cmark\u003egenerative fuzzing\u003c/mark\u003e\u003c/strong\u003e, which constructs test programs from scratch based on grammar or specification of the target inputs, and \u003cstrong\u003e\u003cmark\u003emutation-based fuzzing\u003c/mark\u003e\u003c/strong\u003e, which starts with existing, valid, programs and modifies them to create new test inputs. Modifications (\u003cem\u003emutations\u003c/em\u003e) can include inserting, deleting, or replacing input parts. Table 2 lists pros and cons for each. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"2790\" height=\"846\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/kotlinfuzzing.comp-genmutation.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTable 2: A comparison of generative and mutation-based fuzzing.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eFigure 3 further compares the two techniques to basic fuzzing, underlining their trade-offs on how well they cover different parts of the compiler vs. how deep they can explore it.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1804\" height=\"904\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/kotlinfuzzing.fuzzingtypescom.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp id=\"figurethree\"\u003e\u003cem\u003eFigure 3: A comparison of fuzzing types.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis section has described fuzzing basics and how fuzzing is an effective method for ensuring a high standard in compiler quality. Going forward, we will focus on fuzzing the Kotlin compiler specifically.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"kotlin-compiler-fuzzing\"\u003eKotlin compiler fuzzing\u003c/h3\u003e\n\n\n\n\u003cp\u003eFuzzing is already a widespread practice for many programming languages, from C++ and JS to Java. At JetBrains, our Kotlin team is no stranger to fuzzing the Kotlin compiler. We have collaborated with external research groups to try to break the compiler with differing fuzzing approaches. One of the first collaborations gave us a great example of how to crash \u003ccode\u003ekotlinc\u003c/code\u003e using 8 characters and the \u003ccode\u003emain\u003c/code\u003e function. This is shown below.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"kotlin\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003efun main() {\n    (when{}) // Crash in Kotlin 1.3, fixed in 1.5\n}\u003c/pre\u003e\n\n\n\n\u003cp\u003eYou can also access the example on Kotlin Playground in \u003ca href=\"https://play.kotlinlang.org/#eyJ2ZXJzaW9uIjoiMS4zLjcyIiwicGxhdGZvcm0iOiJqYXZhIiwiYXJncyI6IiIsIm5vbmVNYXJrZXJzIjp0cnVlLCJ0aGVtZSI6ImlkZWEiLCJjb2RlIjoiZnVuIG1haW4oKSB7XG4gICAgKHdoZW57fSkgLy8gRml4ZWQgaW4gMS41XG59In0=\" target=\"_blank\" rel=\"noopener\"\u003eKotlin 1.3\u003c/a\u003e and \u003ca href=\"https://play.kotlinlang.org/#eyJ2ZXJzaW9uIjoiMS41LjMxIiwicGxhdGZvcm0iOiJqYXZhIiwiYXJncyI6IiIsIm5vbmVNYXJrZXJzIjp0cnVlLCJ0aGVtZSI6ImlkZWEiLCJjb2RlIjoiZnVuIG1haW4oKSB7XG4gICAgKHdoZW57fSkgLy8gRml4ZWQgaW4gMS41XG59In0=\" target=\"_blank\" rel=\"noopener\"\u003eKotlin 1.5\u003c/a\u003e versions, i.e., before and after the bug was fixed. The following code blocks contain two more examples of bugs found by fuzzing.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"kotlin\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003efun \u0026lt;break\u0026gt; foo() // Compilation crash on type parameter named `break`\nfun box(){\n    foo()\n}\u003c/pre\u003e\n\n\n\n\u003cp\u003eThis example shows a compiler crash when it encounters a reserved identifier (such as \u003ccode\u003ebreak\u003c/code\u003e) in the position of a type parameter.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"kotlin\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003efun box(): String {\n    return if (true) {\n        val a = 1 // No error when we are expected to return a `String`\n    } else {\n        \u0026#34;fail:\u0026#34;\n    }\n}\nfun main(args: Array\u0026lt;String\u0026gt;) {\n    println(box())\n}\u003c/pre\u003e\n\n\n\n\u003cp\u003eThe above example shows a miscompilation of when the compiler failed to reject an incorrect program: the \u003ccode\u003eif\u003c/code\u003e expression should return a \u003ccode\u003eString\u003c/code\u003e, but the \u003ccode\u003etrue\u003c/code\u003e branch does not return anything.\u003c/p\u003e\n\n\n\n\u003cp\u003eFigure 4 displays an incomplete trophy list of found-by-fuzzer bugs, demonstrating fuzzing’s usefulness. Many of the reported bugs greatly helped us in the K2 compiler stabilization.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1195\" height=\"771\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/kotlinfuzzing-trophylist.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp id=\"figurefour\"\u003e\u003cem\u003eFigure 4: Incomplete trophy list of found-by-fuzzer bugs.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003ch3 id=\"evolutionary-generative-fuzzing\"\u003eEvolutionary generative fuzzing\u003c/h3\u003e\n\n\n\n\u003cp\u003eLast year, we collaborated with TU Delft’s \u003ca href=\"https://se.ewi.tudelft.nl/\" target=\"_blank\" rel=\"noopener\"\u003eSERG\u003c/a\u003e team to more rigorously explore the properties of generative fuzzing. In this \u003ca href=\"https://arxiv.org/abs/2401.06653\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e2024 paper\u003c/a\u003e, we looked at generative fuzzing as an evolutionary algorithm problem and developed a fuzzing approach: \u003cstrong\u003eEvolutionary Generative Fuzzing\u003c/strong\u003e. This subsection will describe our approach in more detail.\u003c/p\u003e\n\n\n\n\u003cp\u003eFirst, let’s break down the term \u003cem\u003eevolutionary generative fuzzing\u003c/em\u003e. As discussed above, \u003cem\u003egenerative \u003c/em\u003efuzzing is a bottom-up approach to creating program inputs, generating them following a specific set of rules. In the present case, the generation rules are based on the language syntax, or the Kotlin grammar, and its semantics, or the Kotlin specification. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe term’s \u003cem\u003eevolutionary \u003c/em\u003epart comes from \u003cem\u003eevolutionary algorithms\u003c/em\u003e, an approach that simulates the real evolutionary process. Evolutionary algorithms and a common subtype, genetic algorithms, are optimization techniques that use natural selection and genetic inheritance principles for solving complex problems in programming. \u003c/p\u003e\n\n\n\n\u003cp\u003eFirst we will talk about the basic concepts of a genetic algorithm, then we will apply these concepts to fuzzing. Essentially, these types of algorithms are meant to mimic the way living organisms evolve over generations to adapt and survive in their environments. Figure 5 depicts this cycle.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1804\" height=\"1004\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/kotlinfuzzing-evogen-simple.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp id=\"figurefive\"\u003e\u003cem\u003eFigure 5: Genetic algorithm cycle.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eAs a problem-solving technique, a genetic algorithm starts with a specific problem, and for this problem there are multiple candidate solutions. Each solution represents an \u003cem\u003eindividual\u003c/em\u003e (sometimes called \u003cem\u003echromosome\u003c/em\u003e), which could be,  for example, a specific input for a function. A set of individuals represents a \u003cem\u003epopulation\u003c/em\u003e, just like in the natural world. \u003c/p\u003e\n\n\n\n\u003cp\u003eTo begin the algorithm, an initial population must be generated, typically a set of random individuals (i.e., candidate solutions). After the initial population is generated,  a fitness function evaluates the suitability of each individual within the population, only retaining those individuals most the most fit to move on to the next generation. Then, the set of fit individuals mutate and recombine to form a  new population. This new  combination of individuals make up the next generation’s population.\u003c/p\u003e\n\n\n\n\u003cp\u003eLet’s apply this to our Kotlin compiler fuzzing approach, represented in the more specialized version of the evolutionary cycle in Figure 6. The lighter-colored and smaller rectangles attached to the larger ones represent the relevant action needed to reach each stage. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1804\" height=\"1004\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/07/kotlinfuzzing-evogen-complex.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp id=\"figuresix\"\u003e\u003cem\u003eFigure 6: Genetic algorithm in the evolutionary generative fuzzing approach.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eTo begin, the individuals are Kotlin code snippets created with generative fuzzing. To create the initial population, we sample multiple code snippets, which are then evaluated by a fitness function. And to simulate reproduction, we split each snippet into code blocks, where each block represents an individual’s chromosome. These code-block chromosomes then mutate and recombine to create new code snippets, which are sampled to create the next generation’s population. An important takeaway of the approach is: \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eThe evolutionary generative fuzzer is not purely generative: it is also partially mutation-based\u003c/strong\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs mentioned above, a fitness function plays an integral part in the evolutionary cycle. In this work we hypothesized that structurally diverse code is more likely to exercise different compiler components than more uniform code; by stressing various compiler components, more bugs will be able to be uncovered. To test this, we investigated a baseline and two different ways to calculate the fitness function, with both being attempts to optimize the sampled code’s diversity.\u003c/p\u003e\n\n\n\n\u003cp id=\"mogda\"\u003eAs a baseline, our approach used what is called random search (RS), as it samples programs without any fitness function. We also used different measures of diversity realized through the fitness functions to apply two novel types of genetic algorithms (GAs): single-objective and many-objective functions for the single-objective diversity GA (SODGA) and many-objective diversity GA (MODGA), respectively. The details of these two genetic algorithms and the baseline are summarized in Table 3.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfCiLxtfpXCDop2iqr5r_k3JExq5Z6jz4jFvFJMwKth4jPsfHvnSQpEBfpwiPTmq6hfl-k8HjuUHxGyFlZp13ZFV7q_eInmFoJBkAZ8Ddj_GxM9ESyDWsGO6Ith7sZ9_jb-d6p7Lg?key=KybN-7ZTATk0aJMGDbA7XA\"/\u003e\u003c/p\u003e\n\n\n\n\u003cp id=\"tablethree\"\u003e\u003cem\u003eTable 3: Approaches and their fitness-function details.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe generated code was then compiled with both the original K1 compiler and the new \u003ca href=\"https://blog.jetbrains.com/kotlin/2024/05/celebrating-kotlin-2-0-fast-smart-and-multiplatform/\"\u003eK2 compiler\u003c/a\u003e released with Kotlin 2.0. This allowed us to focus on K1-to-K2 changes and find situations when the new compiler introduces regressions or unexpected behavior changes.\u003c/p\u003e\n\n\n\n\u003cp\u003eApplying any approach listed in Table 3 results in finding interesting bugs, and the different approaches complement each other in terms of bug-detecting categories: random search (RS in Table 3) is effective for detecting more straightforward differential bugs such as out-of-memory errors and resolution ambiguity, whereas the two genetic algorithms (SODGA and MODGA in Table 3) are successful in detecting nuanced problems such as with conflicting overloads, shown in the code example below.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"kotlin\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003efun main() {\n    fun p(): Char { return \u0026#39;c\u0026#39; }\n    fun p(): Float { return 13.0f }\n}\u003c/pre\u003e\n\n\n\n\u003cp\u003eThe intended behavior of the above code block is that the compiler reports a \u003cem\u003econflicting overloads \u003c/em\u003eerror, as the two \u003ccode\u003ep\u003c/code\u003e functions should cause a resolution conflict. The K1 compiler returns the appropriate error, while the K2 compiles the code without any warning. By applying two types of genetic algorithms, we were able to uncover several independent instances of this bug, and we fixed this error in Kotlin 2.0.\u003c/p\u003e\n\n\n\n\u003cp\u003eOverall, our team’s complex approach to Kotlin compiler fuzzing has led to the discovery of previously unknown bugs. In combining both generative and mutation-based fuzzing, we have been able to enhance bug discovery.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"the-future-of-fuzzing\"\u003eThe future of fuzzing\u003c/h2\u003e\n\n\n\n\u003cp\u003eFuzzing has already enabled our team to find and fix many compiler bugs, improving the Kotlin compiler. Our research collaboration with TU Delft’s \u003ca href=\"https://se.ewi.tudelft.nl/\" target=\"_blank\" rel=\"noopener\"\u003eSERG\u003c/a\u003e team produced a more advanced approach to fuzzing, combining generative and mutation-based methods, and with this foundation we can fine tune fuzzing even more.\u003c/p\u003e\n\n\n\n\u003cp\u003eFuzzing is an active field of research with many opportunities for advancement, and fuzzing a complex, industrial language like Kotlin presents unique challenges that require careful attention for the advancement of fuzzing, as well as for the results to be useful. These challenges and their possible solutions are listed in Table 4.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cstrong\u003eChallenge\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003e\u003cstrong\u003ePossible solution\u003c/strong\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cem\u003eMaintaining code validity\u003c/em\u003e, with code that is both syntactically correct and semantically meaningful. Often requires fuzzer implementation to include parts tailored to target language.\u003c/td\u003e\u003ctd\u003eCustom handwritten generators for more complicated parts of Kotlin\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eFinding different types of bugs and thoroughly testing all compiler parts to \u003cem\u003eensure good compiler code coverage.\u003c/em\u003e\u003c/td\u003e\u003ctd\u003eCoverage-guided fuzzing: one component of the fitness function is X if a code snippet reaches so far unexplored compiler parts\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eAfter finding bugs,\u003cem\u003e\u003cstrong\u003e \u003c/strong\u003elocalizing faults \u003c/em\u003eby determining the exact cause and the code responsible. Fuzzers often produce large amounts of test cases, which require manual analysis. \u003c/td\u003e\u003ctd\u003e \u003ca href=\"#mogda\" data-type=\"internal\" data-id=\"#mogda\"\u003eMOGDA\u003c/a\u003e, as it naturally prefers generating smaller and easier-to-understand programs \u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eA good fuzzer needs to be able to \u003cem\u003eavoid duplicates\u003c/em\u003e and instead trigger new, unique bugs, instead of the same bugs repeatedly.\u003c/td\u003e\u003ctd\u003eFor now, this problem is solved manually, but there are different possibilities to do this automatically\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTable 4: Fuzzing challenges and possible solutions.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eOur Kotlin compiler team continues to address these challenges by improving fuzzing capabilities in an incremental fashion. We want to keep on providing you with reliable software, and that includes reducing distractions so that you can focus on having fun while developing in Kotlin!\u003c/p\u003e\n\n\n\n\u003ch2\u003eMore fuzzing resources\u003c/h2\u003e\n\n\n\n\u003cp\u003eCurious to explore the research or try out fuzzing on your own Kotlin code? Check out these resources!\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2401.06653\" target=\"_blank\" rel=\"noopener\"\u003eOur paper\u003c/a\u003e in collaboration with TU Delft’s \u003ca href=\"https://se.ewi.tudelft.nl/\" target=\"_blank\" rel=\"noopener\"\u003eSERG\u003c/a\u003e team\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://medium.com/ase-conference/reduktor-how-we-stopped-worrying-about-bugs-in-kotlin-compiler-71d8b5e1a1b0\" target=\"_blank\" rel=\"noopener\"\u003eA post\u003c/a\u003e about input reduction in Kotlin compiler fuzzing \u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.fuzzingbook.org/\" target=\"_blank\" rel=\"noopener\"\u003eThe Fuzzing Book\u003c/a\u003e, a textbook available online with lots of detailed information and great examples\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://betterstack.com/community/guides/testing/fuzz-testing/\" target=\"_blank\" rel=\"noopener\"\u003eFuzz Testing: A Beginner’s Guide\u003c/a\u003e, an article with more about different types of fuzzing and how to try it yourself\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.software-lab.org/publications/csur2019_compiler_testing.pdf\" target=\"_blank\" rel=\"noopener\"\u003e\nA Survey of Compiler Testing\u003c/a\u003e, another academic article\u003c/li\u003e\n\u003c/ul\u003e\n                    \n                                                                                                                                                                                                                                    \u003c/div\u003e\n                \u003ca href=\"#\"\u003e\u003c/a\u003e\n                \n                \n            \u003c/section\u003e\n                    \u003cdiv\u003e\n                \u003cp\u003e\n                    \u003ch2\u003eDiscover more\u003c/h2\u003e\n                \u003c/p\u003e\n                \n            \u003c/div\u003e\n                \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "20 min read",
  "publishedTime": null,
  "modifiedTime": null
}
