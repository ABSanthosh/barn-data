{
  "id": "0402c1d0-a412-4a08-bb81-c667abb58583",
  "title": "Highlights from Git 2.49",
  "link": "https://github.blog/open-source/git/highlights-from-git-2-49/",
  "description": "The open source Git project just released Git 2.49. Here is GitHub’s look at some of the most interesting features and changes introduced since last time. The post Highlights from Git 2.49 appeared first on The GitHub Blog.",
  "author": "Taylor Blau",
  "published": "Fri, 14 Mar 2025 17:19:46 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "Git",
    "Open Source"
  ],
  "byline": "Taylor Blau",
  "length": 15216,
  "excerpt": "The open source Git project just released Git 2.49. Here is GitHub’s look at some of the most interesting features and changes introduced since last time.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "The open source Git project just released Git 2.49 with features and bug fixes from over 89 contributors, 24 of them new. We last caught up with you on the latest in Git back when 2.48 was released. To celebrate this most recent release, here is GitHub’s look at some of the most interesting features and changes introduced since last time. Faster packing with name-hash v2 Many times over this series of blog posts, we have talked about Git’s object storage model, where objects can be written individually (known as “loose” objects), or grouped together in packfiles. Git uses packfiles in a wide variety of functions, including local storage (when you repack or GC your repository), as well as when sending data to or from another Git repository (like fetching, cloning, or pushing). Storing objects together in packfiles has a couple of benefits over storing them individually as loose. One obvious benefit is that object lookups can be performed much more quickly in pack storage. When looking up a loose object, Git has to make multiple system calls to find the object you’re looking for, open it, read it, and close it. These system calls can be made faster using the operating system’s block cache, but because objects are looked up by a SHA-1 (or SHA-256) of their contents, this pseudo-random access isn’t very cache-efficient. But most interesting to our discussion is that since loose objects are stored individually, we can only compress their contents in isolation, and can’t store objects as deltas of other similar objects that already exist in your repository. For example, say you’re making a series of small changes to a large blob in your repository. When those objects are initially written, they are each stored individually and zlib compressed. But if the majority of the file’s content remains unchanged among edit pairs, Git can further compress these objects by storing successive versions as deltas of earlier ones. Roughly speaking, this allows Git to store the changes made to an object (relative to some other object) instead of multiple copies of nearly identical blobs. But how does Git figure out which pairs of objects are good candidates to store as delta-base pairs? One useful proxy is to compare objects that appear at similar paths. Git does this today by computing what it calls a “name hash”, which is effectively a sortable numeric hash that weights more heavily towards the final 16 non-whitespace characters in a filepath (source). This function comes from Linus all the way back in 2006, and excels at grouping functions with similar extensions (all ending in .c, .h, etc.), or files that were moved from one directory to another (a/foo.txt to b/foo.txt). But the existing name-hash implementation can lead to poor compression when there are many files that have the same basename but very different contents, like having many CHANGELOG.md files for different subsystems stored together in your repository. Git 2.49 introduces a new variant of the hash function that takes more of the directory structure into account when computing its hash. Among other changes, each layer of the directory hierarchy gets its own hash, which is downshifted and then XORed into the overall hash. This creates a hash function which is more sensitive to the whole path, not just the final 16 characters. This can lead to significant improvements both in packing performance, but also in the resulting pack’s overall size. For instance, using the new hash function was able to improve the time it took to repack microsoft/fluentui from ~96 seconds to ~34 seconds, and slimming down the resulting pack’s size from 439 MiB to just 160 MiB (source). While this feature isn’t (yet) compatible with Git’s reachability bitmaps feature, you can try it out for yourself using either git repack’s or git pack-objects’s new --name-hash-version flag via the latest release. [source] Backfill historical blobs in partial clones Have you ever been working in a partial clone and gotten this unfriendly output? $ git blame README.md remote: Enumerating objects: 1, done. remote: Counting objects: 100% (1/1), done. remote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0) Receiving objects: 100% (1/1), 1.64 KiB | 8.10 MiB/s, done. remote: Enumerating objects: 1, done. remote: Counting objects: 100% (1/1), done. remote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0) Receiving objects: 100% (1/1), 1.64 KiB | 7.30 MiB/s, done. [...] What happened here? To understand the answer to that question, let’s work through an example scenario: Suppose that you are working in a partial clone that you cloned with --filter=blob:none. In this case, your repository is going to have all of its trees, commit, and annotated tag objects, but only the set of blobs which are immediately reachable from HEAD. Put otherwise, your local clone only has the set of blobs it needs to populate a full checkout at the latest revision, and loading any historical blobs will fault in any missing objects from wherever you cloned your repository. In the above example, we asked for a blame of the file at path README.md. In order to construct that blame, however, we need to see every historical version of the file in order to compute the diff at each layer to figure out whether or not a revision modified a given line. But here we see Git loading in each historical version of the object one by one, leading to bloated storage and poor performance. Git 2.49 introduces a new tool, git backfill, which can fault in any missing historical blobs from a --filter=blob:none clone in a small number of batches. These requests use the new path-walk API (also introduced in Git 2.49) to group together objects that appear at the same path, resulting in much better delta compression in the packfile(s) sent back from the server. Since these requests are sent in batches instead of one-by-one, we can easily backfill all missing blobs in only a few packs instead of one pack per blob. After running git backfill in the above example, our experience looks more like: $ git clone --sparse --filter=blob:none git@github.com:git/git.git[...] # downloads historical commits/trees/tags $ cd git $ git sparse-checkout add builtin [...] # downloads current contents of builtin/ $ git backfill --sparse [...] # backfills historical contents of builtin/ $ git blame -- builtin/backfill.c 85127bcdeab (Derrick Stolee 2025-02-03 17:11:07 +0000 1) /* We need this macro to access core_apply_sparse_checkout */ 85127bcdeab (Derrick Stolee 2025-02-03 17:11:07 +0000 2) #define USE_THE_REPOSITORY_VARIABLE 85127bcdeab (Derrick Stolee 2025-02-03 17:11:07 +0000 3) [...] But running git backfill immediately after cloning a repository with --filter=blob:none doesn’t bring much benefit, since it would have been more convenient to simply clone the repository without an object filter enabled in the first place. When using the backfill command’s --sparse option (the default whenever the sparse checkout feature is enabled in your repository), Git will only download blobs that appear within your sparse checkout, avoiding objects that you wouldn’t checkout anyway. To try it out, run git backfill in any --filter=blob:none clone of a repository using Git 2.49 today! [source, source] We discussed above that Git uses compression powered by zlib when writing loose objects, or individual objects within packs and so forth. zlib is an incredibly popular compression library, and has an emphasis on portability. Over the years, there have been a couple of popular forks (like intel/zlib and cloudflare/zlib) that contain optimizations not present in upstream zlib. The zlib-ng fork merges many of the optimizations made above, as well as removes dead code and workarounds for historical compilers from upstream zlib, placing a further emphasis on performance. For instance, zlib-ng has support for SIMD instruction sets (like SSE2, and AVX2) built-in to its core algorithms. Though zlib-ng is a drop-in replacement for zlib, the Git project needed to update its compatibility layer to accommodate zlib-ng. In Git 2.49, you can now build Git with zlib-ng by passing ZLIB_NG when building with the GNU Make, or the zlib_backend option when building with Meson. Early experimental results show a ~25% speed-up when printing the contents of all objects in the Git repository (from ~52.1 seconds down to ~40.3 seconds). [source] This release marks a major milestone in the Git project with the first pieces of Rust code being checked in. Specifically, this release introduces two Rust crates: libgit-sys, and libgit which are low- and high-level wrappers around a small portion of Git’s library code, respectively. The Git project has long been evolving its code to be more library-oriented, doing things like replacing functions that exit the program with ones that return an integer and let the caller decide to exit or, cleaning up memory leaks, etc. This release takes advantage of that work to provide a proof-of-concept Rust crate that wraps part of Git’s config.h API. This isn’t a fully-featured wrapper around Git’s entire library interface, and there is still much more work to be done throughout the project before that can become a reality, but this is a very exciting step along the way. [source] Speaking of the “libification” effort, there were a handful of other related changes that went into this release. The ongoing effort to move away from global variables like the_repository continues, and many more commands in this release use the provided repository instead of using the global one. This release also saw a lot of effort being put into squelching -Wsign-compare warnings, which occur when a signed value is compared against an unsigned one. This can lead to surprising behavior when comparing, say, negative signed values against unsigned ones, where a comparison like -1 \u003c 2 (which should return true) ends up returning false instead. Hopefully you won’t notice these changes in your day-to-day use of Git, but they are important steps along the way to bringing the project closer to being able to be used as a standalone library. [source, source, source, source, source] Long-time readers might remember our coverage of Git 2.39 where we discussed git repack’s new --expire-to option. In case you’re new around here or could use a refresher, we’ve got you covered. The --expire-to option in git repack controls the behavior of unreachable objects which were pruned out of the repository. By default, pruned objects are simply deleted, but --expire-to allows you to move them off to the side in case you want to hold onto them for backup purposes, etc. git repack is a fairly low-level command though, and most users will likely interact with Git’s garbage collection feature through git gc. In large part, git gc is a wrapper around functionality that is implemented in git repack, but up until this release, git gc didn’t expose its own command-line option to use --expire-to. That changed in Git 2.49, where you can now experiment with this behavior via git gc --expire-to! [source] You may have read that Git’s help.autocorrect feature is too fast for Formula One drivers. In case you haven’t, here are the details. If you’ve ever seen output like: $ git psuh git: 'psuh' is not a git command. See 'git --help'. The most similar command is push …then you have used Git’s autocorrect feature. But its configuration options don’t quite match the convention of other, similar options. For instance, in other parts of Git, specifying values like “true”, “yes”, “on”, or “1” for boolean-valued settings all meant the same thing. But help.autocorrect deviates from that trend slightly: it has special meanings for “never”, “immediate”, and “prompt”, but interprets a numeric value to mean that Git should automatically run whatever command it suggests after waiting that many deciseconds. So while you might have thought that setting help.autocorrect to “1” would enable the autocorrect behavior, you’d be wrong: it will instead run the corrected command before you can even blink your eyes1. Git 2.49 changes the convention of help.autocorrect to interpret “1” like other boolean-valued commands, and positive numbers greater than 1 as it would have before. While you can’t specify that you want the autocorrect behavior in exactly 1 decisecond anymore, you probably never meant to anyway. [source, source] You might be aware of git clone’s various options like --branch or --tag. When given, these options allow you to clone a repository’s history leading up to a specific branch or tag instead of the whole thing. These options are often used in CI farms when they want to clone a specific branch or tag for testing. But what if you want to clone a specific revision that isn’t at any branches or tags in your repository, what do you do? Prior to Git 2.49, the only thing you could do is initialize an empty repository and fetch a specific revision after adding the repository you’re fetching from as a remote. Git 2.49 introduces a much more convenient method to round out the --branch and --tag options by adding a new --revision option that fetches history leading up to the specified revision, regardless of whether or not there is a branch or tag pointing at it. [source] Speaking of remotes, you might know that the git remote command uses your repository’s configuration to store the list of remotes that it knows about. You might not know that there were actually two different mechanisms which preceded storing remotes in configuration files. In the very early days, remotes were configured via separate files in $GIT_DIR/branches (source). A couple of weeks later, the convention changed to use $GIT_DIR/remote instead of the /branches directory (source). Both conventions have long since been deprecated and replaced with the configuration-based mechanism we’re familiar with today (source, source). But Git has maintained support for them over the years as part of its backwards compatibility. When Git 3.0 is eventually released, these features will be removed entirely. If you want to learn more about Git’s upcoming breaking changes, you can read all about them in Documentation/BreakingChanges.adoc. If you really want to live on the bleeding edge, you can build Git with the WITH_BREAKING_CHANGES compile time switch, which compiles out features that will be removed in Git 3.0. [source, source] Last but not least, the Git project had two wonderful Outreachy interns that recently completed their projects! Usman Akinyemi worked on adding support to include uname information in Git’s user agent when making HTTP requests, and Seyi Kuforiji worked on converting more unit tests to use the Clar testing framework. You can learn more about their projects here and here. Congratulations, Usman and Seyi! [source, source, source, source] The rest of the iceberg That’s just a sample of changes from the latest release. For more, check out the release notes for 2.49, or any previous version in the Git repository. Written by Taylor Blau is a Staff Software Engineer at GitHub where he works on Git.",
  "image": "https://github.blog/wp-content/uploads/2025/03/Git-249.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003eThe open source Git project just \u003ca href=\"https://lore.kernel.org/git/xmqqfrjfilc8.fsf@gitster.g/\"\u003ereleased Git 2.49\u003c/a\u003e with features and bug fixes from over 89 contributors, 24 of them new. We last caught up with you on the latest in Git back when \u003ca href=\"https://github.blog/open-source/git/highlights-from-git-2-48/\"\u003e2.48 was released\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo celebrate this most recent release, here is GitHub’s look at some of the most interesting features and changes introduced since last time.\u003c/p\u003e\n\u003ch2 id=\"faster-packing-with-name-hash-v2\" id=\"faster-packing-with-name-hash-v2\"\u003eFaster packing with name-hash v2\u003ca href=\"#faster-packing-with-name-hash-v2\" aria-label=\"Faster packing with name-hash v2\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eMany times over this series of blog posts, we have talked about Git’s object storage model, where objects can be written individually (known as “loose” objects), or grouped together in \u003ca href=\"https://git-scm.com/book/en/v2/Git-Internals-Packfiles\"\u003epackfiles\u003c/a\u003e. Git uses packfiles in a wide variety of functions, including local storage (when you repack or GC your repository), as well as when sending data to or from another Git repository (like fetching, cloning, or pushing).\u003c/p\u003e\n\u003cp\u003eStoring objects together in packfiles has a couple of benefits over storing them individually as loose. One obvious benefit is that object lookups can be performed much more quickly in pack storage. When looking up a loose object, Git has to make multiple \u003ca href=\"https://en.wikipedia.org/wiki/System_call\"\u003esystem calls\u003c/a\u003e to find the object you’re looking for, open it, read it, and close it. These system calls can be made faster using the operating system’s \u003ca href=\"https://en.wikipedia.org/wiki/Bcache\"\u003eblock cache\u003c/a\u003e, but because objects are looked up by a \u003ca href=\"https://en.wikipedia.org/wiki/SHA-1\"\u003eSHA-1\u003c/a\u003e (or \u003ca href=\"https://en.wikipedia.org/wiki/SHA-2\"\u003eSHA-256\u003c/a\u003e) of their \u003ca href=\"https://en.wikipedia.org/wiki/Content-addressable_storage\"\u003econtents\u003c/a\u003e, this pseudo-random access isn’t very cache-efficient.\u003c/p\u003e\n\u003cp\u003eBut most interesting to our discussion is that since loose objects are stored individually, we can only compress their contents in isolation, and can’t store objects as \u003ca href=\"https://git-scm.com/docs/gitformat-pack/2.49.0#_deltified_representation\"\u003edeltas\u003c/a\u003e of other similar objects that already exist in your repository. For example, say you’re making a series of small changes to a large blob in your repository. When those objects are initially written, they are each stored individually and \u003ca href=\"https://en.wikipedia.org/wiki/Zlib\"\u003ezlib compressed\u003c/a\u003e. But if the majority of the file’s content remains unchanged among edit pairs, Git can further compress these objects by storing successive versions as deltas of earlier ones. Roughly speaking, this allows Git to store the changes made to an object (relative to some other object) instead of multiple copies of nearly identical blobs.\u003c/p\u003e\n\u003cp\u003eBut how does Git figure out which pairs of objects are good candidates to store as delta-base pairs? One useful proxy is to compare objects that appear at similar \u003ca href=\"https://en.wikipedia.org/wiki/Path_(computing)#:~:text=A%20path%20(or%20filepath%2C%20file,delimiting%20character%2C%20represent%20each%20directory.\"\u003epaths\u003c/a\u003e. Git does this today by computing what it calls a “name hash”, which is effectively a sortable numeric \u003ca href=\"https://en.wikipedia.org/wiki/Hash_function\"\u003ehash\u003c/a\u003e that weights more heavily towards the final 16 non-whitespace characters in a filepath (\u003ca href=\"https://github.com/git/git/blob/v2.49.0/pack-objects.h#L191-L209\"\u003esource\u003c/a\u003e). This function comes from Linus all the way back \u003ca href=\"https://github.com/git/git/commit/ce0bd64299ae148ef61a63edcac635de41254cb5\"\u003ein 2006\u003c/a\u003e, and excels at grouping functions with similar extensions (all ending in \u003ccode\u003e.c\u003c/code\u003e, \u003ccode\u003e.h\u003c/code\u003e, etc.), or files that were moved from one directory to another (\u003ccode\u003ea/foo.txt\u003c/code\u003e to \u003ccode\u003eb/foo.txt\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eBut the existing name-hash implementation can lead to poor compression when there are many files that have the same basename but very different contents, like having many \u003ccode\u003eCHANGELOG.md\u003c/code\u003e files for different subsystems stored together in your repository. Git 2.49 introduces \u003ca href=\"https://github.com/git/git/blob/v2.49.0/pack-objects.h#L211-L237\"\u003ea new variant\u003c/a\u003e of the hash function that takes more of the directory structure into account when computing its hash. Among other changes, each layer of the directory hierarchy gets its own hash, which is \u003ca href=\"https://en.wikipedia.org/wiki/Bitwise_operation#Bit_shifts\"\u003edownshifted\u003c/a\u003e and then \u003ca href=\"https://en.wikipedia.org/wiki/Exclusive_or\"\u003eXOR\u003c/a\u003eed into the overall hash. This creates a hash function which is more sensitive to the whole path, not just the final 16 characters.\u003c/p\u003e\n\u003cp\u003eThis can lead to significant improvements both in packing performance, but also in the resulting pack’s overall size. For instance, using the new hash function was able to improve the time it took to repack \u003ccode\u003emicrosoft/fluentui\u003c/code\u003e from ~96 seconds to ~34 seconds, and slimming down the resulting pack’s size from 439 MiB to just 160 MiB (\u003ca href=\"https://github.com/git/git/commit/30696be71f64ca3764b1d334927da927d6d8df78\"\u003esource\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eWhile this feature isn’t (yet) compatible with Git’s \u003ca href=\"https://git-scm.com/docs/bitmap-format#_pack_and_multi_pack_bitmaps\"\u003ereachability bitmaps\u003c/a\u003e feature, you can try it out for yourself using either \u003ccode\u003egit repack\u003c/code\u003e’s or \u003ccode\u003egit pack-objects\u003c/code\u003e’s new \u003ccode\u003e--name-hash-version\u003c/code\u003e flag via the latest release.\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/388218fac77d0405a5083cd4b4ee20f6694609c3...b4cf68476a983ff063846b43cd46ee9805f2c0bb\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003ch2 id=\"backfill-historical-blobs-in-partial-clones\" id=\"backfill-historical-blobs-in-partial-clones\"\u003eBackfill historical blobs in partial clones\u003ca href=\"#backfill-historical-blobs-in-partial-clones\" aria-label=\"Backfill historical blobs in partial clones\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHave you ever been working in a partial clone and gotten this unfriendly output?\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git blame README.md\nremote: Enumerating objects: 1, done.\nremote: Counting objects: 100% (1/1), done.\nremote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\nReceiving objects: 100% (1/1), 1.64 KiB | 8.10 MiB/s, done.\nremote: Enumerating objects: 1, done.\nremote: Counting objects: 100% (1/1), done.\nremote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\nReceiving objects: 100% (1/1), 1.64 KiB | 7.30 MiB/s, done.\n[...]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhat happened here? To understand the answer to that question, let’s work through an example scenario:\u003c/p\u003e\n\u003cp\u003eSuppose that you are working in a partial clone that you cloned with \u003ccode\u003e--filter=blob:none\u003c/code\u003e. In this case, your repository is going to have all of its trees, commit, and annotated tag objects, but only the set of blobs which are immediately reachable from \u003ccode\u003eHEAD\u003c/code\u003e. Put otherwise, your local clone only has the set of blobs it needs to populate a full checkout at the latest revision, and loading any historical blobs will fault in any missing objects from wherever you cloned your repository.\u003c/p\u003e\n\u003cp\u003eIn the above example, we asked for a \u003ca href=\"https://git-scm.com/docs/git-blame\"\u003e\u003ccode\u003eblame\u003c/code\u003e\u003c/a\u003e of the file at path \u003ccode\u003eREADME.md\u003c/code\u003e. In order to construct that blame, however, we need to see every historical version of the file in order to compute the diff at each layer to figure out whether or not a revision modified a given line. But here we see Git loading in each historical version of the object one by one, leading to bloated storage and poor performance.\u003c/p\u003e\n\u003cp\u003eGit 2.49 introduces a new tool, \u003ccode\u003egit backfill\u003c/code\u003e, which can fault in any missing historical blobs from a \u003ccode\u003e--filter=blob:none\u003c/code\u003e clone in a small number of batches. These requests use the new path-walk API (also introduced in Git 2.49) to group together objects that appear at the same path, resulting in much better delta compression in the packfile(s) sent back from the server. Since these requests are sent in batches instead of one-by-one, we can easily backfill all missing blobs in only a few packs instead of one pack per blob.\u003c/p\u003e\n\u003cp\u003eAfter running \u003ccode\u003egit backfill\u003c/code\u003e in the above example, our experience looks more like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone --sparse --filter=blob:none git@github.com:git/git.git[...] # downloads historical commits/trees/tags\n$ cd git\n$ git sparse-checkout add builtin\n[...] # downloads current contents of builtin/\n$ git backfill --sparse\n[...] # backfills historical contents of builtin/\n$ git blame -- builtin/backfill.c\n85127bcdeab (Derrick Stolee 2025-02-03 17:11:07 +0000   1) /* We need this macro to access core_apply_sparse_checkout */\n85127bcdeab (Derrick Stolee 2025-02-03 17:11:07 +0000   2) #define USE_THE_REPOSITORY_VARIABLE\n85127bcdeab (Derrick Stolee 2025-02-03 17:11:07 +0000   3)\n[...]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBut running \u003ccode\u003egit backfill\u003c/code\u003e immediately after cloning a repository with \u003ccode\u003e--filter=blob:none\u003c/code\u003e doesn’t bring much benefit, since it would have been more convenient to simply clone the repository without an object filter enabled in the first place. When using the backfill command’s \u003ccode\u003e--sparse\u003c/code\u003e option (the default whenever the sparse checkout feature is enabled in your repository), Git will only download blobs that appear within your sparse checkout, avoiding objects that you wouldn’t checkout anyway.\u003c/p\u003e\n\u003cp\u003eTo try it out, run \u003ccode\u003egit backfill\u003c/code\u003e in any \u003ccode\u003e--filter=blob:none\u003c/code\u003e clone of a repository using Git 2.49 today!\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/da898a5c645ce9b6d72c2d39abe1bc3d48cb0fdb...b224e8e36cf22df3c058990cfdd8c1d5c51fc5ae\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/03944513488db4a81fdb4c21c3b515e4cb260b05...85127bcdeab5ab34f9c738da3fcc88d637f39089\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003chr/\u003e\n\u003cul\u003e\n\u003cli\u003eWe discussed above that Git uses compression powered by \u003ca href=\"https://en.wikipedia.org/wiki/Zlib\"\u003ezlib\u003c/a\u003e when writing loose objects, or individual objects within packs and so forth. zlib is an incredibly popular compression library, and has an emphasis on portability. Over the years, there have been a couple of popular forks (like \u003ca href=\"https://github.com/intel/zlib\"\u003eintel/zlib\u003c/a\u003e and \u003ca href=\"https://github.com/cloudflare/zlib\"\u003ecloudflare/zlib\u003c/a\u003e) that contain optimizations not present in upstream zlib.\n\u003cp\u003eThe zlib-ng fork merges many of the optimizations made above, as well as removes dead code and workarounds for historical compilers from upstream zlib, placing a further emphasis on performance. For instance, zlib-ng has support for \u003ca href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_data\"\u003eSIMD instruction sets\u003c/a\u003e (like \u003ca href=\"https://en.wikipedia.org/wiki/SSE2\"\u003eSSE2\u003c/a\u003e, and \u003ca href=\"https://en.wikipedia.org/wiki/Advanced_Vector_Extensions\"\u003eAVX2\u003c/a\u003e) built-in to its core algorithms. Though zlib-ng is a drop-in replacement for zlib, the Git project needed to update its compatibility layer to accommodate zlib-ng.\u003c/p\u003e\n\u003cp\u003eIn Git 2.49, you can now build Git with zlib-ng by passing \u003ccode\u003eZLIB_NG\u003c/code\u003e when building with the GNU Make, or the \u003ccode\u003ezlib_backend\u003c/code\u003e option when building with Meson. Early experimental results show a ~25% speed-up when printing the contents of all objects in the Git repository (from ~52.1 seconds down to ~40.3 seconds).\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/9fad473faed7862855ced123de81a53fa27187d9...78cdeed4c79d165c915e8de0355cc3fb7f5797c5\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThis release marks a major milestone in the Git project with the first pieces of \u003ca href=\"https://en.wikipedia.org/wiki/Rust_%5C(programming_language%5C)\"\u003eRust\u003c/a\u003e code being checked in. Specifically, this release introduces two Rust \u003ca href=\"https://doc.rust-lang.org/book/ch07-01-packages-and-crates.html\"\u003ecrates\u003c/a\u003e: libgit-sys, and libgit which are low- and high-level wrappers around a small portion of Git’s library code, respectively.\u003c/p\u003e\n\u003cp\u003eThe Git project has long been evolving its code to be more library-oriented, doing things like replacing functions that exit the program with ones that return an integer and let the caller decide to exit or, cleaning up memory leaks, etc. This release takes advantage of that work to provide a proof-of-concept Rust crate that wraps part of Git’s \u003ccode\u003econfig.h\u003c/code\u003e API.\u003c/p\u003e\n\u003cp\u003eThis isn’t a fully-featured wrapper around Git’s entire library interface, and there is still much more work to be done throughout the project before that can become a reality, but this is a very exciting step along the way.\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/3f3fd0f34617bc9901d5cfaca9a5b5a12eec8cf4...65c10aa8d5000e0ecab34a9652056f0520fe51ed\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSpeaking of the “libification” effort, there were a handful of other related changes that went into this release. The ongoing effort to move away from global variables like \u003ccode\u003ethe_repository\u003c/code\u003e continues, and many more commands in this release use the provided \u003ccode\u003erepository\u003c/code\u003e instead of using the global one.\u003c/p\u003e\n\u003cp\u003eThis release also saw a lot of effort being put into squelching \u003ca href=\"https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\"\u003e\u003ccode\u003e-Wsign-compare\u003c/code\u003e warnings\u003c/a\u003e, which occur when a signed value is compared against an unsigned one. This can lead to surprising behavior when comparing, say, negative signed values against unsigned ones, where a comparison like \u003ccode\u003e-1 \u0026lt; 2\u003c/code\u003e (which should return true) ends up \u003ca href=\"https://en.wikipedia.org/wiki/Two%27s_complement\"\u003ereturning false instead\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eHopefully you won’t notice these changes in your day-to-day use of Git, but they are important steps along the way to bringing the project closer to being able to be used as a standalone library.\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/d6a7cace21e689dbbc6a4135d21a1ff6bdc04ce7...d4cd757051d1c779f1d95557b7ac523a6e1803fc\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/66e01e510a7cca4235489eac128913b069fa58a4...24027256aa9614a445563707a72af7ce5ff49b5b\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/8d335468eca3c8b37d7b939f7d7f17b31c514e8f...49b299215dd779b781c5a39af85a5acb6294acbd\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/73e055d71ea39c54e78b6e9a28ea0d8e7999a5cb...33319b0976ff9975e7509b6096887370146893f4\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/2d2a71ce85026edcc40f469678a1035df0dfcf57...a3b56f5f431d2421b575f329d401361e3196b467\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLong-time readers might remember \u003ca href=\"https://github.blog/open-source/git/highlights-from-git-2-39/\"\u003eour coverage of Git 2.39\u003c/a\u003e where we discussed \u003ccode\u003egit repack\u003c/code\u003e’s new \u003ccode\u003e--expire-to\u003c/code\u003e option. In case you’re new around here or could use a refresher, we’ve got you covered. The \u003ccode\u003e--expire-to\u003c/code\u003e option in \u003ccode\u003egit repack\u003c/code\u003e controls the behavior of unreachable objects which were pruned out of the repository. By default, pruned objects are simply deleted, but \u003ccode\u003e--expire-to\u003c/code\u003e allows you to move them off to the side in case you want to hold onto them for backup purposes, etc.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003egit repack\u003c/code\u003e is a fairly low-level command though, and most users will likely interact with Git’s garbage collection feature through \u003ccode\u003egit gc\u003c/code\u003e. In large part, \u003ccode\u003egit gc\u003c/code\u003e is a wrapper around functionality that is implemented in \u003ccode\u003egit repack\u003c/code\u003e, but up until this release, \u003ccode\u003egit gc\u003c/code\u003e didn’t expose its own command-line option to use \u003ccode\u003e--expire-to\u003c/code\u003e. That changed in Git 2.49, where you can now experiment with this behavior via \u003ccode\u003egit gc --expire-to\u003c/code\u003e!\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/a4af0b6288e25eb327ae9018cee09def9e43f1cd...08032fa30fefa3101bec4b774e79f4d091b516a6\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou may have read that Git’s \u003ccode\u003ehelp.autocorrect\u003c/code\u003e feature is \u003ca href=\"https://blog.gitbutler.com/why-is-git-autocorrect-too-fast-for-formula-one-drivers/\"\u003etoo fast for Formula One drivers\u003c/a\u003e. In case you haven’t, here are the details. If you’ve ever seen output like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git psuh\ngit: \u0026#39;psuh\u0026#39; is not a git command. See \u0026#39;git --help\u0026#39;.\n\nThe most similar command is\npush\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e…then you have used Git’s autocorrect feature. But its \u003ca href=\"https://git-scm.com/docs/git-config/2.48.0#Documentation/git-config.txt-helpautoCorrect\"\u003econfiguration options\u003c/a\u003e don’t quite match the convention of other, similar options. For instance, in other parts of Git, specifying values like “true”, “yes”, “on”, or “1” for boolean-valued settings all meant the same thing. But \u003ccode\u003ehelp.autocorrect\u003c/code\u003e deviates from that trend slightly: it has special meanings for “never”, “immediate”, and “prompt”, but interprets a numeric value to mean that Git should automatically run whatever command it suggests after waiting that many deciseconds.\u003c/p\u003e\n\u003cp\u003eSo while you might have thought that setting \u003ccode\u003ehelp.autocorrect\u003c/code\u003e to “1” would enable the autocorrect behavior, you’d be wrong: it will instead run the corrected command before you can even blink your eyes\u003csup id=\"fnref-83226-1\"\u003e\u003ca href=\"#fn-83226-1\" title=\"Read footnote.\"\u003e1\u003c/a\u003e\u003c/sup\u003e. Git 2.49 changes the convention of \u003ccode\u003ehelp.autocorrect\u003c/code\u003e to interpret “1” like other boolean-valued commands, and positive numbers greater than 1 as it would have before. While you can’t specify that you want the autocorrect behavior in exactly 1 decisecond anymore, you probably never meant to anyway.\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/0a99ffb4d6645142e68517c59db61b7e58a4f7cc...4e3dd47c9d5f9dcae0a0d6c59c6676213914ac0e\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/39de0ffbe33fbb6498a3027207deb3a5d30ff678...e4542d8b35788c355164794457d46667378e9354\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou might be aware of \u003ccode\u003egit clone\u003c/code\u003e’s various options like \u003ccode\u003e--branch\u003c/code\u003e or \u003ccode\u003e--tag\u003c/code\u003e. When given, these options allow you to clone a repository’s history leading up to a specific branch or tag instead of the whole thing. These options are often used in CI farms when they want to clone a specific branch or tag for testing.\u003c/p\u003e\n\u003cp\u003eBut what if you want to clone a specific revision that isn’t at any branches or tags in your repository, what do you do? Prior to Git 2.49, the only thing you could do is initialize an empty repository and fetch a specific revision after adding the repository you’re fetching from as a remote.\u003c/p\u003e\n\u003cp\u003eGit 2.49 introduces a much more convenient method to round out the \u003ccode\u003e--branch\u003c/code\u003e and \u003ccode\u003e--tag\u003c/code\u003e options by adding a new \u003ccode\u003e--revision\u003c/code\u003e option that fetches history leading up to the specified revision, regardless of whether or not there is a branch or tag pointing at it.\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/0cc13007e5d50b096c95047680ace56749c18789...337855629f59a3f435dabef900e22202ce8e00e1\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSpeaking of remotes, you might know that the \u003ccode\u003egit remote\u003c/code\u003e command uses your repository’s configuration to store the list of remotes that it knows about. You might not know that there were actually two different mechanisms which preceded storing remotes in configuration files. In the very early days, remotes were configured via separate files in \u003ccode\u003e$GIT_DIR/branches\u003c/code\u003e (\u003ca href=\"https://github.com/git/git/commit/f170e4b39d87365cda17b80436ba6db4a2044e88\"\u003esource\u003c/a\u003e). A couple of weeks later, the convention changed to use \u003ccode\u003e$GIT_DIR/remote\u003c/code\u003e instead of the \u003ccode\u003e/branches\u003c/code\u003e directory (\u003ca href=\"https://github.com/git/git/commit/6687f8fea22e1e43ab163a8fe180155a0a0a956a\"\u003esource\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eBoth conventions have long since been deprecated and replaced with the configuration-based mechanism we’re familiar with today (\u003ca href=\"https://github.com/git/git/commit/a1d4aa742416953a3ac9be9154c55e90a4193cd6\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/commit/3d3d282146e13f2d7f055ad056956fd8e5d7ed29\"\u003esource\u003c/a\u003e). But Git has maintained support for them over the years as part of its backwards compatibility. When Git 3.0 is eventually released, these features will be removed entirely.\u003c/p\u003e\n\u003cp\u003eIf you want to learn more about Git’s upcoming breaking changes, you can read all about them \u003ca href=\"https://github.com/git/git/blob/v2.49.0-rc2/Documentation/BreakingChanges.adoc\"\u003ein \u003ccode\u003eDocumentation/BreakingChanges.adoc\u003c/code\u003e\u003c/a\u003e. If you really want to live on the bleeding edge, you can build Git with the \u003ccode\u003eWITH_BREAKING_CHANGES\u003c/code\u003e compile time switch, which compiles out features that will be removed in Git 3.0.\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/c43136d67b7c6a9ecfa988004eb4a87bfbe957a0...8ccc75c2452b5814d2445d60d54266293ca48674\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/68c3be61fc58cafe3786625f5a2b5cf8e7186392...887758c998c31a7f461c808cb3931318f4e5ea3f\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLast but not least, the Git project had two wonderful Outreachy interns that recently completed their projects! \u003ca href=\"http://github.com/Unique-Usman\"\u003eUsman Akinyemi\u003c/a\u003e worked on adding support to include \u003ca href=\"https://en.wikipedia.org/wiki/Uname\"\u003euname\u003c/a\u003e information in Git’s user agent when making HTTP requests, and \u003ca href=\"https://github.com/Seyi007\"\u003eSeyi Kuforiji\u003c/a\u003e worked on converting more unit tests to use the \u003ca href=\"https://github.com/clar-test/clar\"\u003eClar testing framework\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can learn more about their projects \u003ca href=\"https://www.outreachy.org/outreachy-dec-2024-internship-cohort/communities/git/finish-adding-a-os-version-capability-to-git-proto/cfp/\"\u003ehere\u003c/a\u003e and \u003ca href=\"https://www.outreachy.org/outreachy-dec-2024-internship-cohort/communities/git/convert-unit-tests-to-use-the-clar-testing-framewo/cfp/\"\u003ehere\u003c/a\u003e. Congratulations, Usman and Seyi!\u003c/p\u003e\n\u003cp\u003e[\u003ca href=\"https://github.com/git/git/compare/08bdfd453584e489d5a551aecbdcb77584e1b958...cf7ee481902df64b26ac8b1741eca861a8d2f7cc\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/246569bf83f2a586268d26559c7d6ea54c9316b6...af8bf677c150144166454f311642825a0b08e506\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/73c152e6106c3ead1f15f920f4b4f4c38fbfcdb3...43850dcf9c4ca6407abdd167aa3acc098e0e0f7c\"\u003esource\u003c/a\u003e, \u003ca href=\"https://github.com/git/git/compare/f0a371a39d8b9945b2e0a414a32aa861614e5352...ffbd3f98f999102cab47fda4c992d7fa07e1d912\"\u003esource\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"the-rest-of-the-iceberg\" id=\"the-rest-of-the-iceberg\"\u003eThe rest of the iceberg\u003ca href=\"#the-rest-of-the-iceberg\" aria-label=\"The rest of the iceberg\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThat’s just a sample of changes from the latest release. For more, check out the release notes for \u003ca href=\"https://github.com/git/git/blob/v2.49.0/Documentation/RelNotes/2.49.0.adoc\"\u003e2.49\u003c/a\u003e, or \u003ca href=\"https://github.com/git/git/tree/v2.49.0/Documentation/RelNotes\"\u003eany previous version\u003c/a\u003e in \u003ca href=\"https://github.com/git/git\"\u003ethe Git repository\u003c/a\u003e.\u003c/p\u003e\n\n\n\t\n\n\t\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tWritten by\t\u003c/h2\u003e\n\t\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/443245?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/443245?v=4\u0026amp;s=200\" alt=\"Taylor Blau\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\t\t\t\t\n\t\t\t\t\t\u003cp\u003eTaylor Blau is a Staff Software Engineer at GitHub where he works on Git.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": "2025-03-14T17:19:46Z",
  "modifiedTime": null
}
