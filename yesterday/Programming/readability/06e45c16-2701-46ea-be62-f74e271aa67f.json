{
  "id": "06e45c16-2701-46ea-be62-f74e271aa67f",
  "title": "Airbnb at KDD 2024",
  "link": "https://medium.com/airbnb-engineering/airbnb-at-kdd-2024-d5c2fa81a119?source=rss----53c7c27702d5---4",
  "description": "",
  "author": "Huiji Gao",
  "published": "Tue, 17 Dec 2024 18:02:43 GMT",
  "source": "https://medium.com/feed/airbnb-engineering",
  "categories": [
    "machine-learning",
    "engineering",
    "deep-learning",
    "artificial-intelligence",
    "data-science"
  ],
  "byline": "Huiji Gao",
  "length": 20968,
  "excerpt": "Airbnb had a large presence at the 2024 KDD conference hosted in Barcelona, Spain. Our Data Scientist and Engineers presented on topics like Deep Learning \u0026 Search Ranking, Online Experimentation \u0026…",
  "siteName": "The Airbnb Tech Blog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "Airbnb had a large presence at the 2024 KDD conference hosted in Barcelona, Spain. Our Data Scientist and Engineers presented on topics like Deep Learning \u0026 Search Ranking, Online Experimentation \u0026 Measurement, Product Quality \u0026 Customer Journey, and Two-sided Marketplaces. This blog post summarizes our contributions to KDD for 2024 and provides access to the academic papers presented during the conference.Authors: Huiji Gao, Peter Coles, Carolina Barcenas, Sanjeev KatariyaKDD (Knowledge and Data Mining) is one of the most prestigious global conferences in data mining and machine learning. Hosted annually by a special interest group of the Association for Computing Machinery (ACM), it’s where attendees learn about some of the most ground-breaking AI developments in data mining, machine learning, knowledge discovery, and large-scale data analytics.This year, the 30th KDD conference was held at Barcelona, Spain, attracting thousands of researchers and scientists from academia and industry. Various companies contributed to and attended the conference including Google, Meta, Apple, Amazon, Airbnb, Pinterest, LinkedIn, Booking, Expedia, ByteDance etc. There were 151 Applied Data Science (ADS) track papers and 411 Research track papers accepted, 34 tutorials, and 30 workshops.Airbnb had a significant presence at KDD 2024 with three full ADS track papers (acceptance rate under 20%), one workshop, and seven workshop papers and invited talks accepted into the main conference proceedings. The topics of our work spanned Deep learning \u0026 Search Ranking, Online Experimentation \u0026 Measurement, Causal Inference \u0026 Machine Learning, and Two-sided Marketplaces.In this blog post, we will summarize our teams’ contributions and share highlights from an exciting week-long conference with research and industry talks, workshops, panel discussions, and more.Deep Learning and Search RankingIntelligent search ranking — the process of accurately matching a guest with a listing based on their preference, a listing’s features, and additional search context — still remains a nuanced challenge that researchers are constantly trying to solve.Making optimal guest-host matches has remained an issue in a two-sided marketplace for a variety of reasons — the timespan of guest searches (ranging between days and weeks), unpredictable host behavior and ratings (the potential for hosts to cancel a booking or receive low ratings), and limited understanding of guest preference across multiple interfaces. We published several papers addressing the issue of search ranking as part of our presence at KDD.Learning to Rank for Maps at AirbnbAirbnb brings together hosts who rent listings to prospective guests from around the globe. Results from a guest’s search for listings are displayed primarily through two interfaces: (1) as a list of rectangular cards that contain on them the listing image, price, rating, and other details, referred to as list-results, and (2) as oval pins on a map showing the listing price, called map-results. Both these interfaces, since their inception, have used the same ranking algorithm that orders listings by their booking probabilities and selects the top listings for display.However, some of the basic assumptions underlying ranking are built for a world where search results are presented as lists and simply break down for map-results. In this work, we rebuilt ranking for maps by revising the mathematical foundations of how users interact with map search results. Our iterative and experiment-driven approach led us through a path full of twists and turns, ending in a unified theory for the two interfaces.Our journey shows how assumptions taken for granted when designing machine learning algorithms may not apply equally across all user interfaces, and how they can be adapted. The net impact was one of the largest improvements in user experience for Airbnb which we discuss as a series of experimental validations. The work introduced in this paper is merely the beginning of future exciting research projects, such as making learning to rank unbiased for map-results and demarcating the map pins to direct the user attention towards more relevant ones.Multi-objective Learning to Rank by Model DistillationIn online marketplaces, the objective of search ranking is not only on optimizing purchasing or conversion rate (primary objective), but also the purchase outcomes (secondary objectives), e.g. order cancellation, review rating, customer service inquiries, platform long term growth. To balance these primary and secondary objectives, several multi-objective learning to rank approaches have been widely studiedTraditional approaches in industrial search and recommender systems encounter challenges such as expensive parameter tuning that leads to sub-optimal solutions, suffering from imbalanced data sparsity issues, and lack of compatibility with ad-hoc objectives. In this work, we propose a distillation-based ranking solution for multi-objective ranking, which optimizes the end-to-end ranking system at Airbnb across multiple ranking models on different objectives, along with various considerations to optimize training and serving efficiency that meets industry standards.Compared with traditional approaches, the proposed solution not only significantly meets and increases the primary objective of conversion by a large margin, but also addresses the secondary objective constraints while improving model stability. Furthermore, we demonstrated the proposed system could be further simplified by model self-distillation. We also did additional simulations to show that this approach could help us efficiently inject ad-hoc non-differentiable business objectives into the ranking system, while enabling us to balance our optimization objectives.Online Experimentation and MeasurementOnline experimentation (e.g., A/B testing) is a common way for organizations like Airbnb to make data-driven decisions. But high variance is frequently a challenge. For example, it’s hard to prove that a change in our search UX will drive value because bookings can be infrequent and depend on a large number of interactions over a long period of time.Metric Decomposition in A/B TestsMore than a decade ago, CUPED (Controlled Experiments Utilizing Pre-Experiment Data) mainstreamed the idea of variance reduction leveraging pre-experiment covariates. Since its introduction, it has been implemented, extended, and modernized by major online experimentation platforms. Despite the wide adoption, it is known by practitioners that the variance reduction rate from CUPED, utilizing pre-experimental data, varies case by case and has a theoretical limit. In theory, CUPED can be extended to augment a treatment effect estimator utilizing in-experiment data, but practical guidance on how to construct such an augmentation is lacking.In this work, we fill this gap by proposing a new direction for sensitivity improvement via treatment effect augmentation, whereby a target metric of interest is decomposed intotwo or more components in an attempt to isolate those with high signal and low noise from those with low signal and high noise. We show through theory, simulation, and empirical examples that if such a decomposition exists (or can be engineered), sensitivity may be increased via approximately null augmentation (in a frequentist setting) and reduced posterior variance (in a Bayesian setting).We provide three real world applications demonstrating different flavors of metric decomposition. These applications illustrate the gain in agility metric decomposition yields relative to an un-decomposed analysis, indicating both empirically and theoretically the value of this practice in both frequentist and Bayesian settings. An important extension to this work would be to next consider sample size determination in both the frequentist or Bayesian contexts; while a boost in sensitivity typically means less data is required for a given analysis, a methodology that determines the smallest sample size required to control various operating characteristics in this context would be of practical value.Two-sided Marketplace OptimizationAirbnb employees hosted a workshop on Two-sided Marketplace Optimization: Search, Pricing, Matching \u0026 Growth. This workshop brought practitioners of two-sided marketplaces together and discussed the evolution of content ranking, recommendation systems, and data mining when solving for producers and consumers on these platforms.Two-sided marketplaces have recently emerged as viable business models for many real-world applications. They model transactions as a network with two distinct types of participants: one type to represent the supply and another the demand of a specific good. Traditionally, research related to online marketplaces focused on how to better satisfy demand. But with two-sided marketplaces, there is more nuance at play. Modern global examples, like Airbnb, operate platforms where users provide services; users may be hosts,or guests. Such platforms must develop models that address all their users’ needs and goals at scale. Machine learning-powered methods and algorithms are essential in every aspect of such complex, internet-scale-sized, two-sided marketplaces.Airbnb is a community based on connection and belonging–we strive to connect people and places. Our contributions to this workshop showcase the work we’re doing to support this mission by optimizing guest experiences, finding equilibrium spots for listing prices, reducing the incidence of poor interactions (and customer support costs as a side effect), detecting when operational staff should follow up on activity at scale, and more.Guest Intention Modeling for PersonalizationAirbnb has transformed the way people travel by offering unique and personalized stays in destinations worldwide. To provide a seamless and tailored experience, understanding user intent plays an important role.However, limited user data and unpredictable guest behavior can make it difficult to understand the essential intent from guests on listings from hosts. Our work shows how we approach this challenging problem. We describe how we apply a deep learning approach to predict difficult-to-infer details for a user’s travel plan, such as the next destination and travel dates. The framework analyzes high-level information from users’ in-app browsing history, booking history, search queries, and other engagement signals, and produces multiple user intent signals.Marketing emails, flexible travel search (e.g., for “Europe in the summer”), and recommendations on the app home page are three guest interactions that benefit from correct intention modeling. Hosts also benefit, since a clear understanding of guest demand can help them optimize listings to increase satisfaction and bookings.Guest Demand UnderstandingHosts can find it difficult to correctly price their listings in two-sided marketplaces serviced by end users. Most hosts are not professional hospitality workers, and would benefit from access to data and advice on how guests see their listings and how they compare to other listings in their neighborhood. We constantly look for ways to give guidance on how hosts can optimally price their listings. The same information can then be used to help guests find their ideal stay.In our paper, we presented an example of how this problem can be solved in general.As illustrated above, both demand and supply change over time, influencing the equilibrium price for a property at a specific point. A historical optimum (such as A above) has to be adjusted to find the current optimum (point C). It is difficult to run experiments since any large-scale experiment we might run will cause the environment to change in complex ways. We tackle this problem by combining economic modeling with causal inference techniques. We segment guests and estimate how price-sensitive each guest segment is, and fine-tune them with empirical data from small targeted experiments and larger-scale natural ones, which are used to adjust estimates for the price sensitivity of each guest segment. Hosts can then use the models’ output to make informed tradeoffs between higher occupancy and higher nightly rates.Listing Embedding for Host-side ProductsIn order to facilitate the matching of listings and guests, Airbnb provides numerous products and services to both hosts and guests. Many of these tools are based on the ability to compare listings, i.e. finding similar listings or listings that may be viewed as equivalent substitutes. Our work presents a study on the application and learning of listing embeddings in Airbnb’s two-sided marketplace. Specifically, we discuss the architecture and training of a neural network embedding model using guest side engagement data, which is then applied to host-side product surfaces. We address the key technical challenges we encountered, including the formulation of negative training examples, correction of training data sampling bias, and the scaling and speeding up training with the help of in-model caching. Additionally, we discuss our comprehensive approach to evaluation, which ranges from in-batch metrics and vocabulary-based evaluation to the properties of similar listings. Finally, we share our insights from utilizing listing embeddings in Airbnb products, such as host calendar similar listings.Customer Support Optimization in Search RankingAs of the date of the paper, Airbnb had more than 7.7 million listings from more than 5 million hosts worldwide. Airbnb is investing both in rapid growth and in making sure that the booking experience is pleasant for hosts and guests. It would, however, be ideal to avoid poor experiences in the first place. Our work highlights how we prevent poor experiences without significantly reducing growth.We use the mass of accumulated support data at Airbnb to model the probability that, if the current user were to book a listing, they would require CS support. Our model discovered multiple features about the searcher, home, and hosts that accurately predict CS requirements. For example, same-day bookings tend to require more support, and a responsive host tends to reduce support needs. So, if a guest chooses a same-day booking, matching them with a highly responsive host can lead to a better experience overall. We incorporate the output of our CS support model in search result rankings; booked homes will sometimes rank lower if we predict a booking will lead to a negative experience.LLM Pretraining using Activity LogsIt’s often important to follow up with users after they’ve had a long series of interactions with a two-sided marketplace to help make sure that their experiences are of high quality. When user interactions meet certain business criteria, operations agents create tickets to follow up with them. For example, user retention and reactivation agents might review user activity logs and decide to follow up with the user, to encourage them to re-engage with the platform.We propose transforming structured data (activity logs) into a more manageable text format and then leveraging modern language models (i.e., BERT) to pretrain a large language model based on user activities. We then performed fine-tuning on the model using historical data about which users were followed up with and checked its predictions. Our work demonstrates the large language model trained on pre-processed activity can successfully identify when a user should be followed up with, at an experimentally significant rate. Our preliminary results suggest that our framework may outperform by 80% the average precision of a similar model that was designed relying heavily on feature engineering.Product Quality and Customer Journey OptimizationTypically, product quality is evaluated based on structured data. Customer ratings, types of support issues, resolution times, and other factors are used as a proxy for how someone booking on Airbnb might value a listing. This kind of data has limitations — more popular listings have more data, often users don’t leave feedback, and feedback is usually biased towards the positive (users with negative experiences tend to churn and not give feedback).In the Workshop on Causal Inference and Machine Learning in Practice, we highlighted an example of how we push the boundaries of product quality assessment techniques and applications, mixing traditional casual inference with cutting-edge machine learning research. In our work “Understanding Product Quality with Unstructured Data: An Application of LLMs and Embeddings at Airbnb”, we presented how an approach based on text embeddings and LLMs can be combined with approaches based on structured data to significantly improve product quality evaluations. We generate text embeddings on a mix of listing and review texts, then cluster the embeddings based on rebooking and churn rates. Once we have clear clusters, we extract keywords from the original data, and use these keywords to calculate a listing quality score, based on their similarity to the keyword list.In addition, we were invited to give a talk on Quality Foundations at Airbnb, at KDD’s 3rd Workshop on End-End Customer Journey Optimization. It’s often hard to differentiate the quality of customer experiences using simple review ratings, in part due to the tightness of their distribution. In this talk, we present an alternative notion of quality based on customer revealed preference: did a customer return to use the platform again after their experience? We describe how a metric — Guest Return Propensity (GRP) — leverages this concept and can differentiate quality, capture platform externalities, and predict future returns.In practice, this measure may not be suited to many common business use cases due to its lagging nature and an inability to easily explain why it has changed. We describe a quality measurement system that builds on the conceptual foundation of GRP by modeling it as an outcome of upstream realized quality signals. These signals — from sources like reviews and customer support — are weighted by their impact on return propensity and mapped to a quality taxonomy to aid in explainability. The resulting score is capable of finely differentiating the quality of customer experiences, aiding tradeoff decisions, and providing timely insights.ConclusionThe 2024 edition of KDD was an amazing opportunity for data scientists and machine learning engineers from across the globe and industry, government, and academia, to connect and exchange learnings and discoveries. We were honored to have the opportunity to share some of our knowledge and techniques, generalizing what we have been learning when we apply machine learning to problems we see at Airbnb. We continue to focus on improving our customers’ experience and growing our business, and the information we’ve shared has been crucial to our success. We’re excited to continue learning from peers and contribute our work back to our community. We eagerly await advancements and improvements that might come about as others build upon the work we’ve shared.Below, you’ll find a complete list of the talks and papers shared in this article along with the team members who contributed. If this type of work interests you, we encourage you to apply for an open position today.List of papers and talksLearning to Rank for Maps at Airbnb (link)Authors: Malay Haldar, Hongwei Zhang, Kedar Bellare, Sherry Chen, Soumyadip Banerjee, Xiaotang Wang, Mustafa Abdool, Huiji Gao, Pavan Tapadia, Liwei He, Sanjeev KatariyaMulti-objective Learning to Rank by Model Distillation (link)Authors: Jie Tang, Huiji Gao, Liwei He, Sanjeev KatariyaMetric Decomposition in A/B Tests (link)Authors: Alex Deng (former employee at Airbnb), Luke Hagar (University of Waterloo), Nathaniel T. Stevens (University of Waterloo), Tatiana Xifara (Airbnb), Amit Gandhi (University of Pennsylvania)Understanding Guest Preferences and Optimizing Two-sided Marketplaces: Airbnb as an Example (link)Authors: Yufei Wu, Daniel SchmiererPredicting Potential Customer Support Needs and Optimizing Search Ranking in a Two-Sided Marketplace (link)Authors: Do-kyum Kim, Han Zhao, Huiji Gao, Liwei He, Malay Haldar, Sanjeev Katariya​​Understanding User Booking Intent at Airbnb (link)Authors: Xiaowei Liu, Weiwei Guo, Jie Tang, Sherry Chen, Huiji Gao, Liwei He, Pavan Tapadia, Sanjeev KatariyaCan Language Models Accelerate Prototyping for Non-Language Data? Classification \u0026 Summarization of Activity Logs as Text (link)Authors: José González-BrenesLearning and Applying Airbnb Listing Embeddings in Two-Sided Marketplace (link)Authors: Siarhei Bykau, Dekun ZouUnderstanding Product Quality with Unstructured Data: An Application of LLMs and Embeddings at Airbnb (link)Authors: Jikun Zhu, Zhiying Gu, Brad Li, Linsha ChenInvited Talk: Quality Foundations at AirbnbSpeakers: Peter Coles, Mike Egesdal",
  "image": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*JnSzLDm3Uh2hY6c2",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca rel=\"noopener follow\" href=\"https://medium.com/@huiji.gao?source=post_page---byline--d5c2fa81a119--------------------------------\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Huiji Gao\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*QJBw9p2GFxG32ybruPxGMQ.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/airbnb-engineering?source=post_page---byline--d5c2fa81a119--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"The Airbnb Tech Blog\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*MlNQKg-sieBGW5prWoe9HQ.jpeg\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"e81e\"\u003eAirbnb had a large presence at the 2024 KDD conference hosted in Barcelona, Spain. Our Data Scientist and Engineers presented on topics like Deep Learning \u0026amp; Search Ranking, Online Experimentation \u0026amp; Measurement, Product Quality \u0026amp; Customer Journey, and Two-sided Marketplaces. This blog post summarizes our contributions to KDD for 2024 and provides access to the academic papers presented during the conference.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"ec1b\"\u003eAuthors: \u003ca href=\"mailto:huiji.gao@airbnb.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHuiji Gao\u003c/a\u003e, \u003ca href=\"mailto:peter.coles@airbnb.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePeter Coles\u003c/a\u003e, \u003ca href=\"mailto:carolina.barcenas@airbnb.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCarolina Barcenas\u003c/a\u003e, \u003ca href=\"mailto:sanjeev.katariya@airbnb.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSanjeev Katariya\u003c/a\u003e\u003c/p\u003e\u003cp id=\"a038\"\u003e\u003ca href=\"https://kdd.org/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKDD\u003c/a\u003e (Knowledge and Data Mining) is one of the most prestigious global conferences in data mining and machine learning. Hosted annually by a special interest group of the Association for Computing Machinery (ACM), it’s where attendees learn about some of the most ground-breaking AI developments in data mining, machine learning, knowledge discovery, and large-scale data analytics.\u003c/p\u003e\u003cp id=\"6289\"\u003eThis year, the 30th KDD conference was held at Barcelona, Spain, attracting thousands of researchers and scientists from academia and industry. Various companies contributed to and attended the conference including Google, Meta, Apple, Amazon, Airbnb, Pinterest, LinkedIn, Booking, Expedia, ByteDance etc. There were 151 Applied Data Science (ADS) track papers and 411 Research track papers accepted, 34 tutorials, and 30 workshops.\u003c/p\u003e\u003cp id=\"20e0\"\u003eAirbnb had a significant presence at KDD 2024 with three full \u003ca href=\"https://kdd2024.kdd.org/applied-data-science-track-papers\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eADS track\u003c/a\u003e papers (acceptance rate under 20%), one workshop, and seven workshop papers and invited talks accepted into the main conference proceedings. The topics of our work spanned Deep learning \u0026amp; Search Ranking, Online Experimentation \u0026amp; Measurement, Causal Inference \u0026amp; Machine Learning, and Two-sided Marketplaces.\u003c/p\u003e\u003cp id=\"1ce8\"\u003eIn this blog post, we will summarize our teams’ contributions and share highlights from an exciting week-long conference with research and industry talks, workshops, panel discussions, and more.\u003c/p\u003e\u003ch2 id=\"0a84\"\u003e\u003cstrong\u003eDeep Learning and Search Ranking\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"8bbb\"\u003eIntelligent search ranking — the process of accurately matching a guest with a listing based on their preference, a listing’s features, and additional search context — still remains a nuanced challenge that researchers are constantly trying to solve.\u003c/p\u003e\u003cp id=\"f211\"\u003eMaking optimal guest-host matches has remained an issue in a two-sided marketplace for a variety of reasons — the timespan of guest searches (ranging between days and weeks), unpredictable host behavior and ratings (the potential for hosts to cancel a booking or receive low ratings), and limited understanding of guest preference across multiple interfaces. We published several papers addressing the issue of search ranking as part of our presence at KDD.\u003c/p\u003e\u003cp id=\"25ee\"\u003e\u003ca href=\"https://arxiv.org/abs/2407.00091\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eLearning to Rank for Maps at Airbnb\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"dadd\"\u003eAirbnb brings together hosts who rent listings to prospective guests from around the globe. Results from a guest’s search for listings are displayed primarily through two interfaces: (1) as a list of rectangular cards that contain on them the listing image, price, rating, and other details, referred to as list-results, and (2) as oval pins on a map showing the listing price, called map-results. Both these interfaces, since their inception, have used the same ranking algorithm that orders listings by their booking probabilities and selects the top listings for display.\u003c/p\u003e\u003cp id=\"22ea\"\u003eHowever, some of the basic assumptions underlying ranking are built for a world where search results are presented as lists and simply break down for map-results. In this work, we rebuilt ranking for maps by revising the mathematical foundations of how users interact with map search results. Our iterative and experiment-driven approach led us through a path full of twists and turns, ending in a unified theory for the two interfaces.\u003c/p\u003e\u003cp id=\"825a\"\u003eOur journey shows how assumptions taken for granted when designing machine learning algorithms may not apply equally across all user interfaces, and how they can be adapted. The net impact was one of the largest improvements in user experience for Airbnb which we discuss as a series of experimental validations. The work introduced in this paper is merely the beginning of future exciting research projects, such as making learning to rank unbiased for map-results and demarcating the map pins to direct the user attention towards more relevant ones.\u003c/p\u003e\u003cp id=\"e93f\"\u003e\u003ca href=\"https://arxiv.org/abs/2407.07181\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eMulti-objective Learning to Rank by Model Distillation\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"1903\"\u003eIn online marketplaces, the objective of search ranking is not only on optimizing purchasing or conversion rate (primary objective), but also the purchase outcomes (secondary objectives), e.g. order cancellation, review rating, customer service inquiries, platform long term growth. To balance these primary and secondary objectives, several multi-objective learning to rank approaches have been widely studied\u003c/p\u003e\u003cp id=\"4d38\"\u003eTraditional approaches in industrial search and recommender systems encounter challenges such as expensive parameter tuning that leads to sub-optimal solutions, suffering from imbalanced data sparsity issues, and lack of compatibility with ad-hoc objectives. In this work, we propose a distillation-based ranking solution for multi-objective ranking, which optimizes the end-to-end ranking system at Airbnb across multiple ranking models on different objectives, along with various considerations to optimize training and serving efficiency that meets industry standards.\u003c/p\u003e\u003cp id=\"23dc\"\u003eCompared with traditional approaches, the proposed solution not only significantly meets and increases the primary objective of conversion by a large margin, but also addresses the secondary objective constraints while improving model stability. Furthermore, we demonstrated the proposed system could be further simplified by model self-distillation. We also did additional simulations to show that this approach could help us efficiently inject ad-hoc non-differentiable business objectives into the ranking system, while enabling us to balance our optimization objectives.\u003c/p\u003e\u003ch2 id=\"f7ba\"\u003e\u003cstrong\u003eOnline Experimentation and Measurement\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"b5bc\"\u003eOnline experimentation (e.g., A/B testing) is a common way for organizations like Airbnb to make data-driven decisions. But high variance is frequently a challenge. For example, it’s hard to prove that a change in our search UX will drive value because bookings can be infrequent and depend on a large number of interactions over a long period of time.\u003c/p\u003e\u003cp id=\"05b9\"\u003e\u003ca href=\"https://dl.acm.org/doi/pdf/10.1145/3637528.3671556\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eMetric Decomposition in A/B Tests\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"605f\"\u003eMore than a decade ago, CUPED (Controlled Experiments Utilizing Pre-Experiment Data) mainstreamed the idea of variance reduction leveraging pre-experiment covariates. Since its introduction, it has been implemented, extended, and modernized by major online experimentation platforms. Despite the wide adoption, it is known by practitioners that the variance reduction rate from CUPED, utilizing pre-experimental data, varies case by case and has a theoretical limit. In theory, CUPED can be extended to augment a treatment effect estimator utilizing in-experiment data, but practical guidance on how to construct such an augmentation is lacking.\u003c/p\u003e\u003cp id=\"0d99\"\u003eIn this work, we fill this gap by proposing a new direction for sensitivity improvement via treatment effect augmentation, whereby a target metric of interest is decomposed into\u003c/p\u003e\u003cp id=\"4656\"\u003etwo or more components in an attempt to isolate those with high signal and low noise from those with low signal and high noise. We show through theory, simulation, and empirical examples that if such a decomposition exists (or can be engineered), sensitivity may be increased via approximately null augmentation (in a frequentist setting) and reduced posterior variance (in a Bayesian setting).\u003c/p\u003e\u003cp id=\"eb97\"\u003eWe provide three real world applications demonstrating different flavors of metric decomposition. These applications illustrate the gain in agility metric decomposition yields relative to an un-decomposed analysis, indicating both empirically and theoretically the value of this practice in both frequentist and Bayesian settings. An important extension to this work would be to next consider sample size determination in both the frequentist or Bayesian contexts; while a boost in sensitivity typically means less data is required for a given analysis, a methodology that determines the smallest sample size required to control various operating characteristics in this context would be of practical value.\u003c/p\u003e\u003ch2 id=\"5546\"\u003eTwo-sided Marketplace Optimization\u003c/h2\u003e\u003cp id=\"7199\"\u003eAirbnb employees hosted a workshop on \u003ca href=\"https://sites.google.com/view/tsmo2024/home?authuser=0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTwo-sided Marketplace Optimization: Search, Pricing, Matching \u0026amp; Growth\u003c/a\u003e. This workshop brought practitioners of two-sided marketplaces together and discussed the evolution of content ranking, recommendation systems, and data mining when solving for producers and consumers on these platforms.\u003c/p\u003e\u003cp id=\"70ec\"\u003eTwo-sided marketplaces have recently emerged as viable business models for many real-world applications. They model transactions as a network with two distinct types of participants: one type to represent the supply and another the demand of a specific good. Traditionally, research related to online marketplaces focused on how to better satisfy demand. But with two-sided marketplaces, there is more nuance at play. Modern global examples, like Airbnb, operate platforms where users provide services; users may be hosts,or guests. Such platforms must develop models that address all their users’ needs and goals at scale. Machine learning-powered methods and algorithms are essential in every aspect of such complex, internet-scale-sized, two-sided marketplaces.\u003c/p\u003e\u003cp id=\"c7d4\"\u003eAirbnb is a community based on connection and belonging–we strive to connect people and places. Our contributions to this workshop showcase the work we’re doing to support this mission by optimizing guest experiences, finding equilibrium spots for listing prices, reducing the incidence of poor interactions (and customer support costs as a side effect), detecting when operational staff should follow up on activity at scale, and more.\u003c/p\u003e\u003cp id=\"4ad8\"\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Understanding-User-Booking-Intent-at-Airbnb.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eGuest Intention Modeling for Personalization\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"6b36\"\u003eAirbnb has transformed the way people travel by offering unique and personalized stays in destinations worldwide. To provide a seamless and tailored experience, understanding user intent plays an important role.\u003c/p\u003e\u003cp id=\"fd91\"\u003eHowever, limited user data and unpredictable guest behavior can make it difficult to understand the essential intent from guests on listings from hosts. Our work shows how we approach this challenging problem. We describe how we apply a deep learning approach to predict difficult-to-infer details for a user’s travel plan, such as the next destination and travel dates. The framework analyzes high-level information from users’ in-app browsing history, booking history, search queries, and other engagement signals, and produces multiple user intent signals.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"563f\"\u003eMarketing emails, flexible travel search (e.g., for “Europe in the summer”), and recommendations on the app home page are three guest interactions that benefit from correct intention modeling. Hosts also benefit, since a clear understanding of guest demand can help them optimize listings to increase satisfaction and bookings.\u003c/p\u003e\u003cp id=\"ac50\"\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Understanding-Guest-Preferences-and-Optimizing-.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eGuest Demand Understanding\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"a123\"\u003eHosts can find it difficult to correctly price their listings in two-sided marketplaces serviced by end users. Most hosts are not professional hospitality workers, and would benefit from access to data and advice on how guests see their listings and how they compare to other listings in their neighborhood. We constantly look for ways to give guidance on how hosts can optimally price their listings. The same information can then be used to help guests find their ideal stay.\u003c/p\u003e\u003cp id=\"3b70\"\u003eIn our paper, we presented an example of how this problem can be solved in general.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"8bf7\"\u003eAs illustrated above, both demand and supply change over time, influencing the equilibrium price for a property at a specific point. A historical optimum (such as A above) has to be adjusted to find the current optimum (point C). It is difficult to run experiments since any large-scale experiment we might run will cause the environment to change in complex ways. We tackle this problem by combining economic modeling with causal inference techniques. We segment guests and estimate how price-sensitive each guest segment is, and fine-tune them with empirical data from small targeted experiments and larger-scale natural ones, which are used to adjust estimates for the price sensitivity of each guest segment. Hosts can then use the models’ output to make informed tradeoffs between higher occupancy and higher nightly rates.\u003c/p\u003e\u003cp id=\"c53a\"\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Learning-and-Applying-Airbnb-Listing-Embeddings-.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eListing Embedding for Host-side Products\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"ffda\"\u003eIn order to facilitate the matching of listings and guests, Airbnb provides numerous products and services to both hosts and guests. Many of these tools are based on the ability to compare listings, i.e. finding similar listings or listings that may be viewed as equivalent substitutes. Our work presents a study on the application and learning of listing embeddings in Airbnb’s two-sided marketplace. Specifically, we discuss the architecture and training of a neural network embedding model using guest side engagement data, which is then applied to host-side product surfaces. We address the key technical challenges we encountered, including the formulation of negative training examples, correction of training data sampling bias, and the scaling and speeding up training with the help of in-model caching. Additionally, we discuss our comprehensive approach to evaluation, which ranges from in-batch metrics and vocabulary-based evaluation to the properties of similar listings. Finally, we share our insights from utilizing listing embeddings in Airbnb products, such as host calendar similar listings.\u003c/p\u003e\u003cp id=\"237a\"\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Predicting-Potential-Customer-Support-Needs-and-OptimizingSearch-Ranking.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eCustomer Support Optimization in Search Ranking\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"107f\"\u003eAs of the date of the paper, Airbnb had more than 7.7 million listings from more than 5 million hosts worldwide. Airbnb is investing both in rapid growth and in making sure that the booking experience is pleasant for hosts and guests. It would, however, be ideal to avoid poor experiences in the first place. Our work highlights how we prevent poor experiences without significantly reducing growth.\u003c/p\u003e\u003cp id=\"f09a\"\u003eWe use the mass of accumulated support data at Airbnb to model the probability that, if the current user were to book a listing, they would require CS support. Our model discovered multiple features about the searcher, home, and hosts that accurately predict CS requirements. For example, same-day bookings tend to require more support, and a responsive host tends to reduce support needs. So, if a guest chooses a same-day booking, matching them with a highly responsive host can lead to a better experience overall. We incorporate the output of our CS support model in search result rankings; booked homes will sometimes rank lower if we predict a booking will lead to a negative experience.\u003c/p\u003e\u003cp id=\"2de6\"\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Can-Language-Models-Accelerate-Prototyping-for-Non-Language-Data-Classification-Summarization-of-Activity-Logs-as-Text.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eLLM Pretraining using Activity Logs\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"4c19\"\u003eIt’s often important to follow up with users after they’ve had a long series of interactions with a two-sided marketplace to help make sure that their experiences are of high quality. When user interactions meet certain business criteria, operations agents create tickets to follow up with them. For example, user retention and reactivation agents might review user activity logs and decide to follow up with the user, to encourage them to re-engage with the platform.\u003c/p\u003e\u003cp id=\"2a4b\"\u003eWe propose transforming structured data (activity logs) into a more manageable text format and then leveraging modern language models (i.e., BERT) to pretrain a large language model based on user activities. We then performed fine-tuning on the model using historical data about which users were followed up with and checked its predictions. Our work demonstrates the large language model trained on pre-processed activity can successfully identify when a user should be followed up with, at an experimentally significant rate. Our preliminary results suggest that our framework may outperform by 80% the average precision of a similar model that was designed relying heavily on feature engineering.\u003c/p\u003e\u003ch2 id=\"2da2\"\u003eProduct Quality and Customer Journey Optimization\u003c/h2\u003e\u003cp id=\"1c72\"\u003eTypically, product quality is evaluated based on structured data. Customer ratings, types of support issues, resolution times, and other factors are used as a proxy for how someone booking on Airbnb might value a listing. This kind of data has limitations — more popular listings have more data, often users don’t leave feedback, and feedback is usually biased towards the positive (users with negative experiences tend to churn and not give feedback).\u003c/p\u003e\u003cp id=\"0380\"\u003eIn the Workshop on Causal Inference and Machine Learning in Practice, we highlighted an example of how we push the boundaries of product quality assessment techniques and applications, mixing traditional casual inference with cutting-edge machine learning research. In our work “\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Understanding-Product-Quality-with-Unstructured-Data.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUnderstanding Product Quality with Unstructured Data: An Application of LLMs and Embeddings at Airbnb\u003c/a\u003e”, we presented how an approach based on text embeddings and LLMs can be combined with approaches based on structured data to significantly improve product quality evaluations. We generate text embeddings on a mix of listing and review texts, then cluster the embeddings based on rebooking and churn rates. Once we have clear clusters, we extract keywords from the original data, and use these keywords to calculate a listing quality score, based on their similarity to the keyword list.\u003c/p\u003e\u003cp id=\"6763\"\u003eIn addition, we were invited to give a talk \u003ca href=\"https://sites.google.com/view/kdd-workshop-2023\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eon Quality Foundations at Airbnb\u003c/a\u003e, at KDD’s 3r\u003ca href=\"https://sites.google.com/view/kdd-workshop-2023\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ed Workshop on End-End Customer Journey Optimization.\u003c/a\u003e It’s often hard to differentiate the quality of customer experiences using simple review ratings, in part due to the tightness of their distribution. In this talk, we present an alternative notion of quality based on customer revealed preference: did a customer return to use the platform again after their experience? We describe how a metric — Guest Return Propensity (GRP) — leverages this concept and can differentiate quality, capture platform externalities, and predict future returns.\u003c/p\u003e\u003cp id=\"a984\"\u003eIn practice, this measure may not be suited to many common business use cases due to its lagging nature and an inability to easily explain why it has changed. We describe a quality measurement system that builds on the conceptual foundation of GRP by modeling it as an outcome of upstream realized quality signals. These signals — from sources like reviews and customer support — are weighted by their impact on return propensity and mapped to a quality taxonomy to aid in explainability. The resulting score is capable of finely differentiating the quality of customer experiences, aiding tradeoff decisions, and providing timely insights.\u003c/p\u003e\u003ch2 id=\"427f\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"807d\"\u003eThe 2024 edition of KDD was an amazing opportunity for data scientists and machine learning engineers from across the globe and industry, government, and academia, to connect and exchange learnings and discoveries. We were honored to have the opportunity to share some of our knowledge and techniques, generalizing what we have been learning when we apply machine learning to problems we see at Airbnb. We continue to focus on improving our customers’ experience and growing our business, and the information we’ve shared has been crucial to our success. We’re excited to continue learning from peers and contribute our work back to our community. We eagerly await advancements and improvements that might come about as others build upon the work we’ve shared.\u003c/p\u003e\u003cp id=\"47c2\"\u003eBelow, you’ll find a complete list of the talks and papers shared in this article along with the team members who contributed. If this type of work interests you, we encourage you to apply for an\u003ca href=\"https://careers.airbnb.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e open position\u003c/a\u003e today.\u003c/p\u003e\u003ch2 id=\"2ba1\"\u003eList of papers and talks\u003c/h2\u003e\u003cp id=\"a0b3\"\u003e\u003cstrong\u003eLearning to Rank for Maps at Airbnb (\u003c/strong\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3637528.3671648\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"c177\"\u003eAuthors: Malay Haldar, Hongwei Zhang, Kedar Bellare, Sherry Chen, Soumyadip Banerjee, Xiaotang Wang, Mustafa Abdool, Huiji Gao, Pavan Tapadia, Liwei He, Sanjeev Katariya\u003c/p\u003e\u003cp id=\"cf4a\"\u003e\u003cstrong\u003eMulti-objective Learning to Rank by Model Distillation (\u003c/strong\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3637528.3671597\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"3764\"\u003eAuthors: Jie Tang, Huiji Gao, Liwei He, Sanjeev Katariya\u003c/p\u003e\u003cp id=\"8c47\"\u003e\u003cstrong\u003eMetric Decomposition in A/B Tests (\u003c/strong\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3637528.3671556\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"f246\"\u003eAuthors: Alex Deng (former employee at Airbnb), Luke Hagar (University of Waterloo), Nathaniel T. Stevens (University of Waterloo), Tatiana Xifara (Airbnb), Amit Gandhi (University of Pennsylvania)\u003c/p\u003e\u003cp id=\"eb18\"\u003e\u003cstrong\u003eUnderstanding Guest Preferences and Optimizing Two-sided Marketplaces: Airbnb as an Example (\u003c/strong\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Understanding-Guest-Preferences-and-Optimizing-.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"a0d4\"\u003eAuthors: Yufei Wu, Daniel Schmierer\u003c/p\u003e\u003cp id=\"37cf\"\u003e\u003cstrong\u003ePredicting Potential Customer Support Needs and Optimizing Search Ranking in a Two-Sided Marketplace (\u003c/strong\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Predicting-Potential-Customer-Support-Needs-and-OptimizingSearch-Ranking.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"c490\"\u003eAuthors: Do-kyum Kim, Han Zhao, Huiji Gao, Liwei He, Malay Haldar, Sanjeev Katariya\u003c/p\u003e\u003cp id=\"2fad\"\u003e\u003cstrong\u003e​​Understanding User Booking Intent at Airbnb (\u003c/strong\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Understanding-User-Booking-Intent-at-Airbnb.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"dcfd\"\u003eAuthors: Xiaowei Liu, Weiwei Guo, Jie Tang, Sherry Chen, Huiji Gao, Liwei He, Pavan Tapadia, Sanjeev Katariya\u003c/p\u003e\u003cp id=\"8513\"\u003e\u003cstrong\u003eCan Language Models Accelerate Prototyping for Non-Language Data? Classification \u0026amp; Summarization of Activity Logs as Text (\u003c/strong\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Can-Language-Models-Accelerate-Prototyping-for-Non-Language-Data-Classification-Summarization-of-Activity-Logs-as-Text.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"d1e0\"\u003eAuthors: José González-Brenes\u003c/p\u003e\u003cp id=\"ebc4\"\u003e\u003cstrong\u003eLearning and Applying Airbnb Listing Embeddings in Two-Sided Marketplace (\u003c/strong\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Learning-and-Applying-Airbnb-Listing-Embeddings-.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"0063\"\u003eAuthors: Siarhei Bykau, Dekun Zou\u003c/p\u003e\u003cp id=\"ff3a\"\u003e\u003cstrong\u003eUnderstanding Product Quality with Unstructured Data: An Application of LLMs and Embeddings at Airbnb (\u003c/strong\u003e\u003ca href=\"https://airbnb.tech/wp-content/uploads/sites/19/2024/12/Understanding-Product-Quality-with-Unstructured-Data.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elink\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e)\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"eb06\"\u003eAuthors: Jikun Zhu, Zhiying Gu, Brad Li, Linsha Chen\u003c/p\u003e\u003cp id=\"e276\"\u003e\u003cstrong\u003eInvited Talk: Quality Foundations at Airbnb\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"9aaa\"\u003eSpeakers: Peter Coles, Mike Egesdal\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "22 min read",
  "publishedTime": "2024-12-17T18:02:43.59Z",
  "modifiedTime": null
}
