{
  "id": "6e585770-6294-4d48-b9a5-03c29ad92cb6",
  "title": "Apache Hudi 1.0 Now Generally Available",
  "link": "https://www.infoq.com/news/2025/01/apache-hudi/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "The Apache Software Foundation has recently announced the general availability of Apache Hudi 1.0, the transactional data lake platform with support for near real-time analytics. Initially introduced in 2017, Apache Hudi provides an open table format optimized for efficient writes in incremental data pipelines and fast query performance. By Renato Losio",
  "author": "Renato Losio",
  "published": "Sat, 18 Jan 2025 06:14:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Data Analytics",
    "Apache Hadoop",
    "Open Source",
    "Data Lake",
    "Architecture \u0026 Design",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Renato Losio",
  "length": 3905,
  "excerpt": "The Apache Software Foundation has recently announced the general availability of Apache Hudi 1.0, the transactional data lake platform with support for near real-time analytics. Initially introduced",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250116231205/apple-touch-icon.png",
  "text": "The Apache Software Foundation has recently announced the general availability of Apache Hudi 1.0, the transactional data lake platform with support for near real-time analytics. Initially introduced in 2017, Apache Hudi provides an open table format optimized for efficient writes in incremental data pipelines and fast query performance. Originally developed at Uber as an incremental processing framework on Apache Hadoop and submitted to the Apache Software Foundation in 2019, Hudi is designed to bridge the gap between database-like functionality and open data lakehouse architectures. Hudi’s main strength lies in its ability to support both near real-time and batch queries simultaneously. The latest release introduces new features aimed at transforming data lakehouses into what the project community considers a fully-fledged \"Data Lakehouse Management System\" (DLMS). Vinoth Chandar, creator of the Hudi Project at Uber and CEO at Onehouse, writes: Hudi shines by providing a high-performance open table format as well as a comprehensive open-source software stack that can ingest, store, optimize and effectively self-manage a data lakehouse. This distinction between open formats and open software is often lost in translation inside the large vendor ecosystem in which Hudi operates. Still, it has been and remains a key consideration for Hudi’s users to avoid compute-lockin to any given data vendor. Released under an Apache License 2.0, Hudi 1.0 introduces a new secondary indexing system designed to enhance query performance and reduce data scanning costs. Users can now create SQL-based indexes on secondary columns, significantly speeding up query execution. The release also includes expression-based indexing, similar to a feature in PostgreSQL, which replaces traditional partitioning strategies to enable more flexible and efficient data organization. When the preview was announced last year, Boris Litvak, principal software engineer at Snyk, wrote: Among the big 3 ACID storage formats on Object Storage, Apache Hudi 1.0 (beta) is the first one introducing \"functional indexes\" over the data. We usually call it \"secondary indexes\" in SQL DB jargon. When will Delta.io and Apache Iceberg follow? Source: Apache Hudi Blog The release introduces support for partial updates, which improves storage and compute efficiency by allowing updates to specific fields instead of entire rows. Additionally, non-blocking concurrency control enables multiple streaming jobs to write to the same dataset without causing bottlenecks or failures. Discussing the database architecture, Chandar adds: Regarding full-fledged DLMS functionality, the closest experience Hudi 1.0 offers is through Apache Spark. Users can deploy a Spark server (or Spark Connect) with Hudi 1.0 installed, submit SQL/jobs, orchestrate table services via SQL commands, and enjoy new secondary index functionality to speed up queries like a DBMS. Hudi 1.0 introduces enhancements to the storage engine, including the adoption of a log-structured merge (LSM) tree for efficient timeline management. This supports long-term data retention and ensures high-performance query planning, even for datasets containing billions of records. Bhavani Sudha Saktheeswaran, software engineer at Onehouse and Apache Hudi PMC, comments: Whether you're building an open data platform, streaming into the data lakehouse, moving away from data warehouses, or optimizing for high-performance queries, Hudi 1.0.0 makes it easier than ever to work with lakehouses. Saktheeswaran and Saketh Chintapalli, software engineer at Uber, presented a session on incremental data processing with Apache Hudi at QCon San Francisco. The session recording is available on InfoQ. About the Author Renato Losio",
  "image": "https://res.infoq.com/news/2025/01/apache-hudi/en/headerimage/generatedHeaderImage-1736180192737.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eThe Apache Software Foundation has recently announced the \u003ca href=\"https://hudi.apache.org/blog/2024/12/16/announcing-hudi-1-0-0/\"\u003egeneral availability of Apache Hudi 1.0\u003c/a\u003e, the transactional data lake platform with support for near real-time analytics. Initially introduced in 2017, \u003ca href=\"https://hudi.apache.org/docs/overview/\"\u003eApache Hudi\u003c/a\u003e provides an open table format optimized for efficient writes in incremental data pipelines and fast query performance.\u003c/p\u003e\n\n\u003cp\u003eOriginally developed at Uber as an \u003ca href=\"https://www.uber.com/en-DE/blog/hoodie/\"\u003eincremental processing framework\u003c/a\u003e on \u003ca href=\"https://hadoop.apache.org/\"\u003eApache Hadoop\u003c/a\u003e and \u003ca href=\"https://www.uber.com/en-DE/blog/apache-hudi/\"\u003esubmitted to the Apache Software Foundation\u003c/a\u003e in 2019, Hudi is designed to bridge the gap between database-like functionality and open data lakehouse architectures. Hudi’s main strength lies in its ability to support both near real-time and batch queries simultaneously.\u003c/p\u003e\n\n\u003cp\u003eThe latest release introduces new features aimed at transforming data lakehouses into what the project community considers a fully-fledged \u0026#34;Data Lakehouse Management System\u0026#34; (DLMS). \u003ca href=\"https://www.linkedin.com/in/vinothchandar/\"\u003eVinoth Chandar\u003c/a\u003e, creator of the Hudi Project at Uber and CEO at Onehouse, writes:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eHudi shines by providing a high-performance open table format as well as a comprehensive open-source software stack that can ingest, store, optimize and effectively self-manage a data lakehouse. This distinction between open formats and open software is often lost in translation inside the large vendor ecosystem in which Hudi operates. Still, it has been and remains a key consideration for Hudi’s users to avoid compute-lockin to any given data vendor.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eReleased under an Apache License 2.0, Hudi 1.0 introduces a new secondary indexing system designed to enhance query performance and reduce data scanning costs. Users can now create SQL-based indexes on secondary columns, significantly speeding up query execution. The release also includes expression-based indexing, similar to a feature in PostgreSQL, which replaces traditional partitioning strategies to enable more flexible and efficient data organization. When the \u003ca href=\"https://medium.com/onehouse-blogs/apache-hudi-1-0-preview-a-database-experience-on-the-data-lake-a4c3ae55ab46\"\u003epreview was announced last year\u003c/a\u003e, Boris Litvak, principal software engineer at Snyk, \u003ca href=\"https://www.linkedin.com/posts/borislitvak_among-the-big-3-acid-storage-formats-on-object-activity-7180827259732140032-fqYF?utm_source=share\u0026amp;utm_medium=member_desktop\"\u003ewrote\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eAmong the big 3 ACID storage formats on Object Storage, Apache Hudi 1.0 (beta) is the first one introducing \u0026#34;functional indexes\u0026#34; over the data. We usually call it \u0026#34;secondary indexes\u0026#34; in SQL DB jargon. When will Delta.io and Apache Iceberg follow?\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2025/01/apache-hudi/en/resources/1hudi-stack-1-x-1736180407907.png\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2025/01/apache-hudi/en/resources/1hudi-stack-1-x-1736180407907.png\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eSource: Apache Hudi Blog\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eThe release introduces support for partial updates, which improves storage and compute efficiency by allowing updates to specific fields instead of entire rows. Additionally, non-blocking concurrency control enables multiple streaming jobs to write to the same dataset without causing bottlenecks or failures. Discussing the database architecture, Chandar adds:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eRegarding full-fledged DLMS functionality, the closest experience Hudi 1.0 offers is through Apache Spark. Users can deploy a Spark server (or Spark Connect) with Hudi 1.0 installed, submit SQL/jobs, orchestrate table services via SQL commands, and enjoy new secondary index functionality to speed up queries like a DBMS.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eHudi 1.0 introduces enhancements to the storage engine, including the adoption of a log-structured merge (LSM) tree for efficient timeline management. This supports long-term data retention and ensures high-performance query planning, even for datasets containing billions of records. \u003ca href=\"https://www.linkedin.com/in/bhasudha\"\u003eBhavani Sudha Saktheeswaran\u003c/a\u003e, software engineer at Onehouse and Apache Hudi PMC, \u003ca href=\"https://www.linkedin.com/posts/bhasudha_announcing-apache-hudi-10-and-the-next-generation-activity-7274846069241331712-Ytin?utm_source=share\u0026amp;utm_medium=member_desktop\"\u003ecomments\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eWhether you\u0026#39;re building an open data platform, streaming into the data lakehouse, moving away from data warehouses, or optimizing for high-performance queries, Hudi 1.0.0 makes it easier than ever to work with lakehouses.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eSaktheeswaran and \u003ca href=\"https://www.linkedin.com/in/saketh24/\"\u003eSaketh Chintapalli\u003c/a\u003e, software engineer at Uber, presented a session on incremental data processing with Apache Hudi at QCon San Francisco. The session recording is \u003ca href=\"https://www.infoq.com/presentations/incremental-data-processing/\"\u003eavailable on InfoQ\u003c/a\u003e.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Renato-Losio\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRenato Losio\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-01-18T00:00:00Z",
  "modifiedTime": null
}
