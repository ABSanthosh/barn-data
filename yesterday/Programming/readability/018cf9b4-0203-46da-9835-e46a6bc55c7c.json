{
  "id": "018cf9b4-0203-46da-9835-e46a6bc55c7c",
  "title": "Nvidia Nemotron Models Aim to Accelerate AI Agent Development",
  "link": "https://www.infoq.com/news/2025/01/nvidia-nemotron-agents/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Nvidia has launched Llama Nemotron large language models (LLMs) and Cosmos Nemotron vision language models (VLMs) with a special emphasis on workflows powered by AI agents such as customer support, fraud detection, product supply chain optimization, and more. Models in the Nemotron family come in Nano, Super, and Ultra sizes to better fit the requirements of diverse systems. By Sergio De Simone",
  "author": "Sergio De Simone",
  "published": "Sat, 11 Jan 2025 21:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Agents",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Sergio De Simone",
  "length": 2778,
  "excerpt": "Nvidia has launched Llama Nemotron large language models (LLMs) and Cosmos Nemotron vision language models (VLMs) with a special emphasis on workflows powered by AI agents such as customer support, fr",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250109115555/apple-touch-icon.png",
  "text": "Nvidia introduced Llama Nemotron large language models (LLMs) and Cosmos Nemotron vision language models (VLMs) with a special emphasis on workflows powered by AI agents such as customer support, fraud detection, product supply chain optimization, and more. Models in the Nemotron family come in Nano, Super, and Ultra sizes to better fit the requirements of diverse systems. AI agents are a new frontier of generative AI evolution, says Nvidia, aiming to create systems able to act autonomously to carry complex tasks through. This requires combining language skills, as displayed by LLMs, with the ability to perceive and interact with the environment. To be effective, many AI agents need both language skills and the ability to perceive the world and respond with the appropriate action. That explains why the Nemotron Model family includes models derived from Meta's LLaMA models as well as new Cosmos Nemotron VLMs that enable analyzing and responding to images and video captured in the user environment. The availability of agents with vision capabilities, says Nvidia, could make it feasible to analyze videos from industrial cameras in a multitude of environments in real-time to help detect incidents, reduce defects, or guide humans through some course of action. Currently, according to the company, less than 1% of video from industrial cameras is watched live by humans. According to Nvidia, they trained Llama Nemotron models to efficiently execute a number of common agentic tasks so you can use just one single model whereas you would normally use multiple specialized models. The models are pruned to reduce latency and improve compute efficiency, then retrained using a hiqh-quality dataset with distillation and alignment methods to increase accuracy across tasks. This results in smaller models with high accuracy and throughput. Nemotron models are optimized for distinct compute requirements, including Nano for PC application developers, Super to provide high performance on a single GPU, and Ultra, designed for data-center-scale applications. The Nvidia Nemotron ecosystem also includes Nvidia NeMo to customize models with proprietary data, and NeMo Aligner to better align a model to follow instruction and generate human preferred responses. Additionally, Nvidia provides Nvidia AI Blueprints as a tool to quickly create AI agents by using NIM microservices as building blocks to serve Nemotron models. On a related note, Nvidia also announced its Cosmos world foundation models which are specially tailored to generate physics-aware videos for robotics and autonomous vehicles. About the Author Sergio De Simone",
  "image": "https://res.infoq.com/news/2025/01/nvidia-nemotron-agents/en/headerimage/nvidia-nemotron-agents-1736626280284.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://blogs.nvidia.com/blog/nemotron-model-families/\"\u003eNvidia introduced Llama Nemotron large language models (LLMs) and Cosmos Nemotron vision language models (VLMs)\u003c/a\u003e with a special emphasis on workflows powered by AI agents such as customer support, fraud detection, product supply chain optimization, and more. Models in the Nemotron family come in Nano, Super, and Ultra sizes to better fit the requirements of diverse systems.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://developer.nvidia.com/blog/llama-nemotron-models-accelerate-agentic-ai-workflows-with-accuracy-and-efficiency/\"\u003eAI agents are a new frontier of generative AI evolution\u003c/a\u003e, says Nvidia, aiming to create systems able to act autonomously to carry complex tasks through. This requires combining language skills, as displayed by LLMs, with the ability to perceive and interact with the environment.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eTo be effective, many AI agents need both language skills and the ability to perceive the world and respond with the appropriate action.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThat explains why the Nemotron Model family includes models derived from Meta\u0026#39;s LLaMA models as well as new Cosmos Nemotron VLMs that enable analyzing and responding to images and video captured in the user environment.\u003c/p\u003e\n\n\u003cp\u003eThe availability of agents with vision capabilities, says Nvidia, could make it feasible to \u003ca href=\"https://blogs.nvidia.com/blog/metropolis-ai-blueprint-video/\"\u003eanalyze videos from industrial cameras\u003c/a\u003e in a multitude of environments in real-time to help detect incidents, reduce defects, or guide humans through some course of action. Currently, according to the company, less than 1% of video from industrial cameras is watched live by humans.\u003c/p\u003e\n\n\u003cp\u003eAccording to Nvidia, they trained Llama Nemotron models to efficiently execute a number of common agentic tasks so you can use just one single model whereas you would normally use multiple specialized models.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe models are pruned to reduce latency and improve compute efficiency, then retrained using a hiqh-quality dataset with distillation and alignment methods to increase accuracy across tasks. This results in smaller models with high accuracy and throughput.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eNemotron models are optimized for distinct compute requirements, including \u003cstrong\u003eNano\u003c/strong\u003e for PC application developers, \u003cstrong\u003eSuper\u003c/strong\u003e to provide high performance on a single GPU, and \u003cstrong\u003eUltra\u003c/strong\u003e, designed for data-center-scale applications.\u003c/p\u003e\n\n\u003cp\u003eThe Nvidia Nemotron ecosystem also includes \u003ca href=\"https://www.nvidia.com/en-us/ai-data-science/products/nemo/\"\u003eNvidia NeMo\u003c/a\u003e to customize models with proprietary data, and \u003ca href=\"https://github.com/NVIDIA/NeMo-Aligner\"\u003eNeMo Aligner\u003c/a\u003e to better align a model to follow instruction and generate human preferred responses. Additionally, Nvidia provides \u003ca href=\"https://blogs.nvidia.com/blog/agentic-ai-blueprints\"\u003eNvidia AI Blueprints\u003c/a\u003e as a tool to quickly create AI agents by using \u003ca href=\"http://build.nvidia.com/\"\u003eNIM microservices\u003c/a\u003e as building blocks to serve Nemotron models.\u003c/p\u003e\n\n\u003cp\u003eOn a related note, Nvidia also announced its \u003ca href=\"https://nvidianews.nvidia.com/news/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai-development\"\u003eCosmos world foundation models\u003c/a\u003e which are specially tailored to generate physics-aware videos for robotics and autonomous vehicles.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Sergio-De-Simone\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSergio De Simone\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-01-11T00:00:00Z",
  "modifiedTime": null
}
