{
  "id": "366932e7-7882-4348-9cc6-ec9a974df45c",
  "title": "Google DeepMind Unveils Gemini 2.0: A Leap in AI Performance and Multimodal Integration",
  "link": "https://www.infoq.com/news/2024/12/google-gemini-2/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Google DeepMind has introduced Gemini 2.0, an AI model that outperforms its predecessor, Gemini 1.5 Pro, with double the processing speed. The model supports complex multimodal tasks, combining text, images, and other inputs for advanced reasoning. Built on the JAX/XLA framework, Gemini 2.0 is optimized at scale and includes new features like Deep Research for exploring complex topics. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Thu, 12 Dec 2024 19:55:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Gemini",
    "Google",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 4643,
  "excerpt": "Google DeepMind has introduced Gemini 2.0, an AI model that outperforms its predecessor, Gemini 1.5 Pro, with double the processing speed. The model supports complex multimodal tasks, combining text,",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20241210082243/apple-touch-icon.png",
  "text": "InfoQ Homepage News Google DeepMind Unveils Gemini 2.0: A Leap in AI Performance and Multimodal Integration Dec 12, 2024 2 min read Write for InfoQ Feed your curiosity. Help 550k+ global senior developers each month stay ahead.Get in touch Google DeepMind has introduced Gemini 2.0, an AI model that outperforms its predecessor, Gemini 1.5 Pro, with double the processing speed. The model supports complex multimodal tasks, combining text, images, and other inputs for advanced reasoning. Built on the JAX/XLA framework, Gemini 2.0 is optimized at scale and includes new features like Deep Research for exploring complex topics. Available now to developers and trusted testers, it will soon be integrated into Google products like Gemini and Search. The new model demonstrates a leap forward in speed and accuracy compared to its predecessors. For instance, Gemini 2.0 Flash outperforms the earlier 1.5 Pro model on key benchmarks while maintaining twice the processing speed. Additionally, it showcases multimodal integration by supporting tasks such as combining text and visual reasoning or executing complex instructions that span multiple types of input and output. Source: Google Blog Bill Jia, a vice president of engineering at Google, added: Gemini 2.0 is fully built and trained on JAX/XLA AI framework/compiler, which we are open-sourcing and sharing with the world. The model training was at a massive scale. The model optimization, fine-tuning, evaluation, and integration into end-user products all pushed the cutting-edge techs. We’re getting 2.0 into the hands of developers and trusted testers today. And we’re working quickly to get it into our products, leading with Gemini and Search. Starting today, our Gemini 2.0 Flash experimental model will be available to all Gemini users. We're also launching a new feature called Deep Research, which uses advanced reasoning and long-context capabilities to act as a research assistant, exploring complex topics and compiling reports on your behalf. It's available in Gemini Advanced today. Gemini 2.0’s capabilities make it well-suited for a range of practical applications. Among the highlights are: Project Astra, a prototype showcasing advanced multimodal understanding for AI assistants, capable of using Google Maps, Search, and Lens. Project Mariner, which demonstrates how Gemini 2.0 can perform tasks like filling forms or analyzing content directly within a web browser. Jules, a development assistant designed to integrate with GitHub workflows, assisting in coding tasks under human supervision. Beyond practical tools, Gemini 2.0 is finding uses in gaming, where it can analyze gameplay in real-time, providing strategic suggestions and advice. Its ability for spatial reasoning is also being tested in robotics, and its potential applications include navigation and problem-solving in the physical world. Google DeepMind emphasizes safety as a core principle in Gemini 2.0’s development. Mechanisms to prevent unauthorized actions, protect user privacy, and address risks like malicious prompt injections have been integrated. Additionally, the model’s design allows users to manage sensitive information through robust privacy controls. The feedback from the community about Gemini 2.0 has been enthusiastic. For example, Raj Nair, a CX leader, remarked: Impressive strides by Google in AI development! The capabilities of Gemini 2.0, Project Mariner, and the coding agent are all signs of how AI is moving from experimental to practical applications. Integrating such advanced tech into daily tasks, from web browsing to development workflows, will definitely reshape industries. More information can be found in the official documentation.  About the Author Robert Krzaczyński Related Sponsored Content [eBook] Getting Started with Azure Kubernetes Service",
  "image": "https://res.infoq.com/news/2024/12/google-gemini-2/en/headerimage/generatedHeaderImage-1734032477720.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                    \n\t\u003carticle data-type=\"news\"\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\n\n\n\n\n\n\n\u003cp\u003e\n\t\u003cspan data-nosnippet=\"\"\u003e\u003ca href=\"https://www.infoq.com/\" title=\"InfoQ Homepage\"\u003eInfoQ Homepage\u003c/a\u003e\u003c/span\u003e\n\t\n\t\t\n\t\t\t\n\t\t\t\n                \u003cspan data-nosnippet=\"\"\u003e\u003ca href=\"https://www.infoq.com/news\" title=\"News\"\u003eNews\u003c/a\u003e\u003c/span\u003e\n            \n\t\t\n\t\t\u003cspan data-nosnippet=\"\"\u003eGoogle DeepMind Unveils Gemini 2.0: A Leap in AI Performance and Multimodal Integration\u003c/span\u003e\n\t\n\t\n    \n        \n    \n\u003c/p\u003e\n\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\n\n\n\n\n\n\n\n\n\t\t\n\t\t\n\n\n\t\t\t\t\n\t\t\t\t\u003cdiv data-col=\"4/6\"\u003e\n\t\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\u003cp\u003eDec 12, 2024\u003cspan\u003e\u003c/span\u003e\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\tmin read\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\u003c/p\u003e\n\n\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\u003cdiv data-nosnippet=\"\"\u003e\n   \u003ch4\u003eWrite for InfoQ\u003c/h4\u003e\n   \u003cp\u003e\u003cstrong\u003eFeed your curiosity.\u003c/strong\u003e\n   \u003cspan\u003eHelp 550k+ global \u003cbr/\u003esenior developers \u003cbr/\u003eeach month stay ahead.\u003c/span\u003e\u003ca href=\"https://docs.google.com/forms/d/e/1FAIpQLSehsV5jwuXFRFPIoOQoSXm9aRjYam9bQjKbEHvGZBxsioyGGw/viewform \" target=\"_blank\"\u003eGet in touch\u003c/a\u003e\n\n      \n\u003c/p\u003e\u003c/div\u003e\n\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\u003c/div\u003e\n\t\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/\"\u003eGoogle DeepMind has introduced Gemini 2.0\u003c/a\u003e, an AI model that outperforms its predecessor, Gemini 1.5 Pro, with double the processing speed. The model supports complex multimodal tasks, combining text, images, and other inputs for advanced reasoning. Built on the JAX/XLA framework, Gemini 2.0 is optimized at scale and includes new features like Deep Research for exploring complex topics. Available now to developers and trusted testers, it will soon be integrated into Google products like Gemini and Search.\u003c/p\u003e\u003cp\u003e\n\nThe new model demonstrates a leap forward in speed and accuracy compared to its predecessors. For instance, Gemini 2.0 Flash outperforms the earlier 1.5 Pro model on key benchmarks while maintaining twice the processing speed. Additionally, it showcases multimodal integration by supporting tasks such as combining text and visual reasoning or executing complex instructions that span multiple types of input and output.\u003c/p\u003e\u003cmeta charset=\"utf-8\"/\u003e\u003cp\u003e\u003cb id=\"docs-internal-guid-1f7b5eeb-7fff-5bcb-a606-83bae0a78f3f\"\u003e\u003cimg height=\"601\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeHaZ6zs-V-lpqL4kAdxyVHAMEoMHICZ_gxolX5vY1Gj7p4zgWtEYVlCfRAVweKqLf17HeUheCHmfGiL_BH4Ws5YFcP6C-IPug_WX2wuqflQkMLuLZfFoht2rP6UfQr91H389cksA?key=5m91G876f3L1i7RuWqvBHubp\" width=\"602\" rel=\"share\"/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\n\n\u003cp\u003e\u003cem\u003eSource: Google Blog\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cbr/\u003e\nBill Jia, a vice president of engineering at Google, \u003ca href=\"http://www.linkedin.com/posts/billjiafacebook_introducing-gemini-20-the-latest-llm-model-activity-7272643214426169347-8GrZ?utm_source=share\u0026amp;utm_medium=member_desktop\"\u003eadded\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eGemini 2.0 is fully built and trained on JAX/XLA AI framework/compiler, which we are open-sourcing and sharing with the world. The model training was at a massive scale. The model optimization, fine-tuning, evaluation, and integration into end-user products all pushed the cutting-edge techs.\u003cbr/\u003e\nWe’re getting 2.0 into the hands of developers and trusted testers today. And we’re working quickly to get it into our products, leading with Gemini and Search. Starting today, our Gemini 2.0 Flash experimental model will be available to all Gemini users. We\u0026#39;re also launching a new feature called Deep Research, which uses advanced reasoning and long-context capabilities to act as a research assistant, exploring complex topics and compiling reports on your behalf. It\u0026#39;s available in Gemini Advanced today.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eGemini 2.0’s capabilities make it well-suited for a range of practical applications. Among the highlights are:\u003c/p\u003e\n\n\u003cul\u003e\n\t\u003cli\u003e\u003ca href=\"https://deepmind.google/technologies/gemini/project-astra/\"\u003eProject Astra\u003c/a\u003e, a prototype showcasing advanced multimodal understanding for AI assistants, capable of using Google Maps, Search, and Lens.\u003c/li\u003e\n\t\u003cli\u003eProject Mariner, which demonstrates how Gemini 2.0 can perform tasks like filling forms or analyzing content directly within a web browser.\u003c/li\u003e\n\t\u003cli\u003eJules, a development assistant designed to integrate with GitHub workflows, assisting in coding tasks under human supervision.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv\u003e\u003cp\u003eBeyond practical tools, Gemini 2.0 is finding uses in gaming, where it can analyze gameplay in real-time, providing strategic suggestions and advice. Its ability for spatial reasoning is also being tested in robotics, and its potential applications include navigation and problem-solving in the physical world.\u003c/p\u003e\u003cp\u003e\n\nGoogle DeepMind emphasizes safety as a core principle in Gemini 2.0’s development. Mechanisms to prevent unauthorized actions, protect user privacy, and address risks like malicious prompt injections have been integrated. Additionally, the model’s design allows users to manage sensitive information through robust privacy controls.\u003c/p\u003e\u003cp\u003e\n\nThe feedback from the community about Gemini 2.0 has been enthusiastic. For example, Raj Nair, a CX leader, \u003ca href=\"https://www.linkedin.com/feed/update/urn:li:ugcPost:7272716537889787904?commentUrn=urn%3Ali%3Acomment%3A%28ugcPost%3A7272716537889787904%2C7272868988437549057%29\u0026amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287272868988437549057%2Curn%3Ali%3AugcPost%3A7272716537889787904%29\"\u003eremarked\u003c/a\u003e:\u003c/p\u003e\u003c/div\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eImpressive strides by Google in AI development! The capabilities of Gemini 2.0, Project Mariner, and the coding agent are all signs of how AI is moving from experimental to practical applications. Integrating such advanced tech into daily tasks, from web browsing to development workflows, will definitely reshape industries.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eMore information can be found in the \u003ca href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2\"\u003eofficial documentation\u003c/a\u003e. \u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\u003cul\u003e\n    \u003cli\u003e\n        \n    \u003c/li\u003e\n    \u003cli\u003e\n        \u003cul data-place=\"BOTTOM\" data-trk-view=\"true\" data-trk-impr=\"true\"\u003e\n            \u003ch4\u003eRelated Sponsored Content\u003c/h4\u003e\n            \n            \n            \n                \n                    \u003cli\u003e\n                        \u003cspan\u003e\u003c/span\u003e\n                        \u003ch5\u003e\n                            \n                            \u003ca href=\"https://www.infoq.com/url/f/c0c84ee3-eb0b-40f4-b270-81ecb8bf3081/\" rel=\"nofollow\"\u003e\n                                [eBook] Getting Started with Azure Kubernetes Service\n                            \u003c/a\u003e\n                        \u003c/h5\u003e\n                    \u003c/li\u003e\n                \n            \n        \u003c/ul\u003e\n    \u003c/li\u003e\n    \n        \u003cli\u003e\n           \n        \u003c/li\u003e\n    \n    \n    \n\u003c/ul\u003e\n\n\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\u003c/div\u003e\n\t\t\t\u003c/div\u003e\n\t\u003c/article\u003e\n\n\n\n\n\n                \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-12-12T00:00:00Z",
  "modifiedTime": null
}
