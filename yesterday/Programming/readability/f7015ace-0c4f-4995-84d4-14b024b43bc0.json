{
  "id": "f7015ace-0c4f-4995-84d4-14b024b43bc0",
  "title": "Anthropic Publishes Model Context Protocol Specification for LLM App Integration",
  "link": "https://www.infoq.com/news/2024/12/anthropic-model-context-protocol/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Anthropic recently released their Model Context Protocol (MCP), an open standard describing a protocol for integrating external resources and tools with LLM apps. The release includes SDKs implementing the protocol, as well as an open-source repository of reference implementations of MCP. By Anthony Alford",
  "author": "Anthony Alford",
  "published": "Tue, 24 Dec 2024 14:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Generative AI",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Anthony Alford",
  "length": 3600,
  "excerpt": "Anthropic recently released their Model Context Protocol (MCP), an open standard describing a protocol for integrating external resources and tools with LLM apps. The release includes SDKs implementin",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20241210082243/apple-touch-icon.png",
  "text": "Anthropic recently released their Model Context Protocol (MCP), an open standard describing a protocol for integrating external resources and tools with LLM apps. The release includes SDKs implementing the protocol, as well as an open-source repository of reference implementations of MCP. The MCP is intended to solve the \"MxN\" problem: the combinatorial difficulty of integrating M different LLMs with N different tools. Instead, MCP provides a standard protocol that LLM vendors and tool builders can follow. MCP uses a client-server architecture; AI apps like Claude for Desktop or an IDE use an MCP client to connect to MCP servers which front datasources or tools. For developers who wish to start using MCP right away, there are SDKs for both Python and TypeScript as well as a growing list of reference implementations and community-contributed servers. According to Anthropic: We’re committed to building MCP as a collaborative, open-source project and ecosystem, and we’re eager to hear your feedback. Whether you’re an AI tool developer, an enterprise looking to leverage existing data, or an early adopter exploring the frontier, we invite you to build the future of context-aware AI together. The MCP spec defines a set of JSON-RPC messages for communication between Clients and Servers; these messages implement building blocks called primitives. Servers support three primitives: Prompts, Resources, and Tools; Clients support two: Roots and Sampling. The Server primitives are for \"adding context to language models.\" Prompts are instructions or templates for instructions. Resources are structured data which can be included in the LLM prompt context. Tools are \"executable functions\" which LLMs can call to retrieve information or perform actions. Roots are an entry point into a filesystem and give Servers access to files on the Client side. Sampling lets Servers request \"completions\" or \"generations\" from a Client-side LLM. Anthropic says that Sampling could be used implementing agentic behavior by nesting LLM calls inside Server actions, but warns that \"there SHOULD always be a human in the loop with the ability to deny sampling requests.\" To showcase what developers can build with MCP, the documentation provides several examples and tutorials. The Quickstart example demonstrates how to use a Claude LLM to fetch weather forecasts and warnings. To do this, the developer creates a Python program to implement the MCP server. This program exposes a Tool primitive that wraps the calls to a public web service that returns weather data. The developer can then use an LLM via the Claude for Desktop app, which has a built-in MCP client, to call the MCP server and get the weather data. Anthropic developer Justin Spahr-Summers joined a Hacker News discussion about MCP. When several users wondered if MCP would help solve the \"MxN\" problem, Spahr-Summers said \"we definitely hope [it] will.\" When asked about how MCP is different from existing tool-usage in LLMs, he replied: On tools specifically, we went back and forth about whether the other primitives of MCP ultimately just reduce to tool use, but ultimately concluded that separate concepts of \"prompts\" and \"resources\" are extremely useful to express different _intentions_ for server functionality. They all have a part to play! The Model Context Protocol specification, documentation, and SDKs for Python and TypeScript are available on GitHub. About the Author Anthony Alford",
  "image": "https://res.infoq.com/news/2024/12/anthropic-model-context-protocol/en/headerimage/generatedHeaderImage-1734183356504.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eAnthropic recently released their \u003ca href=\"https://www.anthropic.com/news/model-context-protocol\"\u003eModel Context Protocol\u003c/a\u003e (MCP), an open standard describing a protocol for integrating external resources and tools with LLM apps. The release includes SDKs implementing the protocol, as well as an open-source repository of reference implementations of MCP.\u003c/p\u003e\n\n\u003cp\u003eThe MCP is intended to solve the \u0026#34;MxN\u0026#34; problem: the combinatorial difficulty of integrating M different LLMs with N different tools. Instead, MCP provides a standard protocol that LLM vendors and tool builders can follow. MCP uses a client-server architecture; AI apps like \u003ca href=\"https://claude.ai/download\"\u003eClaude for Desktop\u003c/a\u003e or an IDE use an MCP client to connect to MCP servers which front datasources or tools. For developers who wish to start using MCP right away, there are SDKs for both \u003ca href=\"https://github.com/modelcontextprotocol/python-sdk\"\u003ePython\u003c/a\u003e and \u003ca href=\"https://github.com/modelcontextprotocol/typescript-sdk\"\u003eTypeScript\u003c/a\u003e as well as a \u003ca href=\"https://github.com/modelcontextprotocol/servers\"\u003egrowing list\u003c/a\u003e of reference implementations and community-contributed servers. According to Anthropic:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eWe’re committed to building MCP as a collaborative, open-source project and ecosystem, and we’re eager to hear your feedback. Whether you’re an AI tool developer, an enterprise looking to leverage existing data, or an early adopter exploring the frontier, we invite you to build the future of context-aware AI together.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://spec.modelcontextprotocol.io/specification/\"\u003eMCP spec\u003c/a\u003e defines a set of JSON-RPC messages for communication between Clients and Servers; these messages implement building blocks called \u003cem\u003eprimitives\u003c/em\u003e. Servers support three primitives: Prompts, Resources, and Tools; Clients support two: Roots and Sampling.\u003c/p\u003e\n\n\u003cp\u003eThe Server primitives are for \u0026#34;adding context to language models.\u0026#34; Prompts are instructions or templates for instructions. Resources are structured data which can be included in the LLM prompt context. Tools are \u0026#34;executable functions\u0026#34; which LLMs can call to retrieve information or perform actions.\u003c/p\u003e\n\n\u003cp\u003eRoots are an entry point into a filesystem and give Servers access to files on the Client side. Sampling lets Servers request \u0026#34;completions\u0026#34; or \u0026#34;generations\u0026#34; from a Client-side LLM. Anthropic says that Sampling could be used implementing agentic behavior by nesting LLM calls inside Server actions, but warns that \u0026#34;there SHOULD always be a human in the loop with the ability to deny sampling requests.\u0026#34;\u003c/p\u003e\n\n\u003cp\u003eTo showcase what developers can build with MCP, the \u003ca href=\"https://modelcontextprotocol.io/introduction\"\u003edocumentation\u003c/a\u003e provides several \u003ca href=\"https://modelcontextprotocol.io/examples\"\u003eexamples\u003c/a\u003e and tutorials. The \u003ca href=\"https://modelcontextprotocol.io/quickstart\"\u003eQuickstart example\u003c/a\u003e demonstrates how to use a Claude LLM to fetch weather forecasts and warnings. To do this, the developer creates a Python program to implement the MCP server. This program exposes a Tool primitive that wraps the calls to a public web service that returns weather data. The developer can then use an LLM via the Claude for Desktop app, which has a built-in MCP client, to call the MCP server and get the weather data.\u003c/p\u003e\n\n\u003cp\u003eAnthropic developer Justin Spahr-Summers joined a Hacker News \u003ca href=\"https://news.ycombinator.com/item?id=42237424\"\u003ediscussion about MCP\u003c/a\u003e. When several users wondered if MCP would help solve the \u0026#34;MxN\u0026#34; problem, Spahr-Summers said \u0026#34;we definitely hope [it] will.\u0026#34; When asked about how MCP is different from existing tool-usage in LLMs, he replied:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eOn tools specifically, we went back and forth about whether the other primitives of MCP ultimately just reduce to tool use, but ultimately concluded that separate concepts of \u0026#34;prompts\u0026#34; and \u0026#34;resources\u0026#34; are extremely useful to express different _intentions_ for server functionality. They all have a part to play!\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://github.com/modelcontextprotocol\"\u003eModel Context Protocol\u003c/a\u003e specification, documentation, and SDKs for Python and TypeScript are available on GitHub.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Anthony-Alford\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eAnthony Alford\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2024-12-24T00:00:00Z",
  "modifiedTime": null
}
