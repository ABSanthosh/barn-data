{
  "id": "a122816f-45f6-496d-b4fd-7f6b60c7e536",
  "title": "Introducing Configurable Metaflow",
  "link": "https://netflixtechblog.com/introducing-configurable-metaflow-d2fb8e9ba1c6?source=rss----2615bd06b42e---4",
  "description": "",
  "author": "Netflix Technology Blog",
  "published": "Fri, 20 Dec 2024 07:11:37 GMT",
  "source": "https://netflixtechblog.com/feed",
  "categories": [
    "machine-learning",
    "mlops",
    "metaflow"
  ],
  "byline": "Netflix Technology Blog",
  "length": 23416,
  "excerpt": "David J. Berg*, David Casler^, Romain Cledat*, Qian Huang*, Rui Lin*, Nissan Pow*, Nurcan Sonmez*, Shashank Srikanth*, Chaoying Wang*, Regina Wang*, Darin Yu* *: Model Development Team, Machine…",
  "siteName": "Netflix TechBlog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "David J. Berg*, David Casler^, Romain Cledat*, Qian Huang*, Rui Lin*, Nissan Pow*, Nurcan Sonmez*, Shashank Srikanth*, Chaoying Wang*, Regina Wang*, Darin Yu**: Model Development Team, Machine Learning Platform^: Content Demand Modeling TeamA month ago at QConSF, we showcased how Netflix utilizes Metaflow to power a diverse set of ML and AI use cases, managing thousands of unique Metaflow flows. This followed a previous blog on the same topic. Many of these projects are under constant development by dedicated teams with their own business goals and development best practices, such as the system that supports our content decision makers, or the system that ranks which language subtitles are most valuable for a specific piece of content.As a central ML and AI platform team, our role is to empower our partner teams with tools that maximize their productivity and effectiveness, while adapting to their specific needs (not the other way around). This has been a guiding design principle with Metaflow since its inception.Metaflow infrastructure stackStanding on the shoulders of our extensive cloud infrastructure, Metaflow facilitates easy access to data, compute, and production-grade workflow orchestration, as well as built-in best practices for common concerns such as collaboration, versioning, dependency management, and observability, which teams use to setup ML/AI experiments and systems that work for them. As a result, Metaflow users at Netflix have been able to run millions of experiments over the past few years without wasting time on low-level concerns.A long standing FAQ: configurable flowsWhile Metaflow aims to be un-opinionated about some of the upper levels of the stack, some teams within Netflix have developed their own opinionated tooling. As part of Metaflow’s adaptation to their specific needs, we constantly try to understand what has been developed and, more importantly, what gaps these solutions are filling.In some cases, we determine that the gap being addressed is very team specific, or too opinionated at too high a level in the stack, and we therefore decide to not develop it within Metaflow. In other cases, however, we realize that we can develop an underlying construct that aids in filling that gap. Note that even in that case, we do not always aim to completely fill the gap and instead focus on extracting a more general lower level concept that can be leveraged by that particular user but also by others. One such recurring pattern we noticed at Netflix is the need to deploy sets of closely related flows, often as part of a larger pipeline involving table creations, ETLs, and deployment jobs. Frequently, practitioners want to experiment with variants of these flows, testing new data, new parameterizations, or new algorithms, while keeping the overall structure of the flow or flows intact.A natural solution is to make flows configurable using configuration files, so variants can be defined without changing the code. Thus far, there hasn’t been a built-in solution for configuring flows, so teams have built their bespoke solutions leveraging Metaflow’s JSON-typed Parameters, IncludeFile, and deploy-time Parameters or deploying their own home-grown solution (often with great pain). However, none of these solutions make it easy to configure all aspects of the flow’s behavior, decorators in particular.Requests for a feature like Metaflow ConfigOutside Netflix, we have seen similar frequently asked questions on the Metaflow community Slack as shown in the user quotes above:how can I adjust the @resource requirements, such as CPU or memory, without having to hardcode the values in my flows?how to adjust the triggering @schedule programmatically, so our production and staging deployments can run at different cadences?New in Metaflow: Configs!Today, to answer the FAQ, we introduce a new — small but mighty — feature in Metaflow: a Config object. Configs complement the existing Metaflow constructs of artifacts and Parameters, by allowing you to configure all aspects of the flow, decorators in particular, prior to any run starting. At the end of the day, artifacts, Parameters and Configs are all stored as artifacts by Metaflow but they differ in when they are persisted as shown in the diagram below:Different data artifacts in MetaflowSaid another way:An artifact is resolved and persisted to the datastore at the end of each task.A parameter is resolved and persisted at the start of a run; it can therefore be modified up to that point. One common use case is to use triggers to pass values to a run right before executing. Parameters can only be used within your step code.A config is resolved and persisted when the flow is deployed. When using a scheduler such as Argo Workflows, deployment happens when create’ing the flow. In the case of a local run, “deployment” happens just prior to the execution of the run — think of “deployment” as gathering all that is needed to run the flow. Unlike parameters, configs can be used more widely in your flow code, particularly, they can be used in step or flow level decorators as well as to set defaults for parameters. Configs can of course also be used within your flow.As an example, you can specify a Config that reads a pleasantly human-readable configuration file, formatted as TOML. The Config specifies a triggering ‘@schedule’ and ‘@resource’ requirements, as well as application-specific parameters for this specific deployment:[schedule]cron = \"0 * * * *\"[model]optimizer = \"adam\"learning_rate = 0.5[resources]cpu = 1Using the newly released Metaflow 2.13, you can configure a flow with a Config like above, as demonstrated by this flow:import pprintfrom metaflow import FlowSpec, step, Config, resources, config_expr, schedule@schedule(cron=config_expr(\"config.schedule.cron\"))class ConfigurableFlow(FlowSpec): config = Config(\"config\", default=\"myconfig.toml\", parser=\"tomllib.loads\") @resources(cpu=config.resources.cpu) @step def start(self): print(\"Config loaded:\") pprint.pp(self.config) self.next(self.end) @step def end(self): passif __name__ == \"__main__\": ConfigurableFlow()There is a lot going on in the code above, a few highlights:you can refer to configs before they have been defined using ‘config_expr’.you can define arbitrary parsers — using a string means the parser doesn’t even have to be present remotely!From the developer’s point of view, Configs behave like dictionary-like artifacts. For convenience, they support the dot-syntax (when possible) for accessing keys, making it easy to access values in a nested configuration. You can also unpack the whole Config (or a subtree of it) with Python’s standard dictionary unpacking syntax, ‘**config’. The standard dictionary subscript notation is also available.Since Configs turn into dictionary artifacts, they get versioned and persisted automatically as artifacts. You can access Configs of any past runs easily through the Client API. As a result, your data, models, code, Parameters, Configs, and execution environments are all stored as a consistent bundle — neatly organized in Metaflow namespaces — paving the way for easily reproducible, consistent, low-boilerplate, and now easily configurable experiments and robust production deployments.More than a humble config fileWhile you can get far by accompanying your flow with a simple config file (stored in your favorite format, thanks to user-definable parsers), Configs unlock a number of advanced use cases. Consider these examples from the updated documentation:You can choose the right level of runtime configurability versus fixed deployments by mixing Parameters and Configs. For instance, you can use a Config to define a default value for a parameter which can be overridden by a real-time event as a run is triggered.You can define a custom parser to validate the configuration, e.g. using the popular Pydantic library.You are not limited to using a single file: you can leverage a configuration manager like OmegaConf or Hydra to manage a hierarchy of cascading configuration files. You can also use a domain-specific tool for generating Configs, such as Netflix’s Metaboost which we cover below.You can also generate configurations on the fly, e.g. fetch Configs from an external service, or inspect the execution environment, such as the current GIT branch, and include it as an extra piece of context in runs.A major benefit of Config over previous more hacky solutions for configuring flows is that they work seamlessly with other features of Metaflow: you can run steps remotely and deploy flows to production, even when relying on custom parsers, without having to worry about packaging Configs or parsers manually or keeping Configs consistent across tasks. Configs also work with the Runner and Deployer.The Hollywood principle: don’t call us, we’ll call youWhen used in conjunction with a configuration manager like Hydra, Configs enable a pattern that is highly relevant for ML and AI use cases: orchestrating experiments over multiple configurations or sweeping over parameter spaces. While Metaflow has always supported sweeping over parameter grids easily using foreaches, it hasn’t been easily possible to alter the flow itself, e.g. to change @resources or @pypi/@conda dependencies for every experiment.In a typical case, you trigger a Metaflow flow that consumes a configuration file, changing how a run behaves. With Hydra, you can invert the control: it is Hydra that decides what gets run based on a configuration file. Thanks to Metaflow’s new Runner and Deployer APIs, you can create a Hydra app that operates Metaflow programmatically — for instance, to deploy and execute hundreds of variants of a flow in a large-scale experiment.Take a look at two interesting examples of this pattern in the documentation. As a teaser, this video shows Hydra orchestrating deployment of tens of Metaflow flows, each of which benchmarks PyTorch using a varying number of CPU cores and tensor sizes, updating a visualization of the results in real-time as the experiment progresses:Example using Hydra with MetaflowMetaboosting Metaflow — based on a true storyTo give a motivating example of what configurations look like at Netflix in practice, let’s consider Metaboost, an internal Netflix CLI tool that helps ML practitioners manage, develop and execute their cross-platform projects, somewhat similar to the open-source Hydra discussed above but with specific integrations to the Netflix ecosystem. Metaboost is an example of an opinionated framework developed by a team already using Metaflow. In fact, a part of the inspiration for introducing Configs in Metaflow came from this very use case.Metaboost serves as a single interface to three different internal platforms at Netflix that manage ETL/Workflows (Maestro), Machine Learning Pipelines (Metaflow) and Data Warehouse Tables (Kragle). In this context, having a single configuration system to manage a ML project holistically gives users increased project coherence and decreased project risk.Configuration in MetaboostEase of configuration and templatizing are core values of Metaboost. Templatizing in Metaboost is achieved through the concept of bindings, wherein we can bind a Metaflow pipeline to an arbitrary label, and then create a corresponding bespoke configuration for that label. The binding-connected configuration is then merged into a global set of configurations containing such information as GIT repository, branch, etc. Binding a Metaflow, will also signal to Metaboost that it should instantiate the Metaflow flow once per binding into our orchestration cluster.Imagine a ML practitioner on the Netflix Content ML team, sourcing features from hundreds of columns in our data warehouse, and creating a multitude of models against a growing suite of metrics. When a brand new content metric comes along, with Metaboost, the first version of the metric’s predictive model can easily be created by simply swapping the target column against which the model is trained.Subsequent versions of the model will result from experimenting with hyper parameters, tweaking feature engineering, or conducting feature diets. Metaboost’s bindings, and their integration with Metaflow Configs, can be leveraged to scale the number of experiments as fast as a scientist can create experiment based configurations.Scaling experiments with Metaboost bindings — backed by Metaflow ConfigConsider a Metaboost ML project named `demo` that creates and loads data to custom tables (ETL managed by Maestro), and then trains a simple model on this data (ML Pipeline managed by Metaflow). The project structure of this repository might look like the following:├── metaflows│ ├── custom -\u003e custom python code, used by| | | Metaflow│ │ ├── data.py│ │ └── model.py│ └── training.py -\u003e defines our Metaflow pipeline├── schemas│ ├── demo_features_f.tbl.yaml -\u003e table DDL, stores our ETL| | output, Metaflow input│ └── demo_predictions_f.tbl.yaml -\u003e table DDL,| stores our Metaflow output├── settings│ ├── settings.configuration.EXP_01.yaml -\u003e defines the additive| | config for Experiment 1│ ├── settings.configuration.EXP_02.yaml -\u003e defines the additive| | config for Experiment 2│ ├── settings.configuration.yaml -\u003e defines our global| | configuration│ └── settings.environment.yaml -\u003e defines parameters based on| git branch (e.g. READ_DB)├── tests├── workflows│ ├── sql│ ├── demo.demo_features_f.sch.yaml -\u003e Maestro workflow, defines ETL│ └── demo.main.sch.yaml -\u003e Maestro workflow, orchestrates| ETLs and Metaflow└── metaboost.yaml -\u003e defines our project for MetaboostThe configuration files in the settings directory above contain the following YAML files:# settings.configuration.yaml (global configuration)model: fit_intercept: Trueconda: numpy: '1.22.4' \"scikit-learn\": '1.4.0'# settings.configuration.EXP_01.yamltarget_column: metricAfeatures: - runtime - content_type - top_billed_talent# settings.configuration.EXP_02.yamltarget_column: metricAfeatures: - runtime - director - box_officeMetaboost will merge each experiment configuration (*.EXP*.yaml) into the global configuration (settings.configuration.yaml) individually at Metaboost command initialization. Let’s take a look at how Metaboost combines these configurations with a Metaboost command:(venv-demo) ~/projects/metaboost-demo [branch=demoX] $ metaboost metaflow settings show --yaml-path=configurationbinding=EXP_01:model: -\u003e defined in setting.configuration.yaml (global) fit_intercept: trueconda: -\u003e defined in setting.configuration.yaml (global) numpy: 1.22.4 \"scikit-learn\": 1.4.0target_column: metricA -\u003e defined in setting.configuration.EXP_01.yamlfeatures: -\u003e defined in setting.configuration.EXP_01.yaml- runtime- content_type- top_billed_talentbinding=EXP_02:model: -\u003e defined in setting.configuration.yaml (global) fit_intercept: trueconda: -\u003e defined in setting.configuration.yaml (global) numpy: 1.22.4 \"scikit-learn\": 1.4.0target_column: metricA -\u003e defined in setting.configuration.EXP_02.yamlfeatures: -\u003e defined in setting.configuration.EXP_02.yaml- runtime- director- box_officeMetaboost understands it should deploy/run two independent instances of training.py — one for the EXP_01 binding and one for the EXP_02 binding. You can also see that Metaboost is aware that the tables and ETL workflows are not bound, and should only be deployed once. These details of which artifacts to bind and which to leave unbound are encoded in the project’s top-level metaboost.yaml file.(venv-demo) ~/projects/metaboost-demo [branch=demoX] $ metaboost project listTables (metaboost table list):schemas/demo_predictions_f.tbl.yaml (binding=default): table_path=prodhive/demo_db/demo_predictions_fschemas/demo_features_f.tbl.yaml (binding=default): table_path=prodhive/demo_db/demo_features_fWorkflows (metaboost workflow list):workflows/demo.demo_features_f.sch.yaml (binding=default): cluster=sandbox, workflow.id=demo.branch_demox.demo_features_fworkflows/demo.main.sch.yaml (binding=default): cluster=sandbox, workflow.id=demo.branch_demox.mainMetaflows (metaboost metaflow list):metaflows/training.py (binding=EXP_01): -\u003e EXP_01 instance of training.py cluster=sandbox, workflow.id=demo.branch_demox.EXP_01.training metaflows/training.py (binding=EXP_02): -\u003e EXP_02 instance of training.py cluster=sandbox, workflow.id=demo.branch_demox.EXP_02.trainingBelow is a simple Metaflow pipeline that fetches data, executes feature engineering, and trains a LinearRegression model. The work to integrate Metaboost Settings into a user’s Metaflow pipeline (implemented using Metaflow Configs) is as easy as adding a single mix-in to the FlowSpec definition:from metaflow import FlowSpec, Parameter, conda_base, stepfrom custom.data import feature_engineer, get_datafrom metaflow.metaboost import MetaboostSettings@conda_base( libraries=MetaboostSettings.get_deploy_time_settings(\"configuration.conda\"))class DemoTraining(FlowSpec, MetaboostSettings): prediction_date = Parameter(\"prediction_date\", type=int, default=-1) @step def start(self): # get show_settings() for free with the mixin # and get convenient debugging info self.show_settings(exclude_patterns=[\"artifact*\", \"system*\"]) self.next(self.get_features) @step def get_features(self): # feature engineers on our extracted data self.fe_df = feature_engineer( # loads data from our ETL pipeline data=get_data(prediction_date=self.prediction_date), features=self.settings.configuration.features + [self.settings.configuration.target_column] ) self.next(self.train) @step def train(self): from sklearn.linear_model import LinearRegression # trains our model self.model = LinearRegression( fit_intercept=self.settings.configuration.model.fit_intercept ).fit( X=self.fe_df[self.settings.configuration.features], y=self.fe_df[self.settings.configuration.target_column] ) print(f\"Fit slope: {self.model.coef_[0]}\") print(f\"Fit intercept: {self.model.intercept_}\") self.next(self.end) @step def end(self): passif __name__ == \"__main__\": DemoTraining()The Metaflow Config is added to the FlowSpec by mixing in the MetaboostSettings class. Referencing a configuration value is as easy as using the dot syntax to drill into whichever parameter you’d like.Finally let’s take a look at the output from our sample Metaflow above. We execute experiment EXP_01 withmetaboost metaflow run --binding=EXP_01which upon execution will merge the configurations into a single settings file (shown previously) and serialize it as a yaml file to the .metaboost/settings/compiled/ directory.You can see the actual command and args that were sub-processed in the Metaboost Execution section below. Please note the –config argument pointing to the serialized yaml file, and then subsequently accessible via self.settings. Also note the convenient printing of configuration values to stdout during the start step using a mixed in function named show_settings().(venv-demo) ~/projects/metaboost-demo [branch=demoX] $ metaboost metaflow run --binding=EXP_01Metaboost Execution: - python3.10 /root/repos/cdm-metaboost-irl/metaflows/training.py --no-pylint --package-suffixes=.py --environment=conda --config settings .metaboost/settings/compiled/settings.branch_demox.EXP_01.training.mP4eIStG.yaml run --prediction_date20241006Metaflow 2.12.39+nflxfastdata(2.13.5);nflx(2.13.5);metaboost(0.0.27) executing DemoTraining for user:dcaslerValidating your flow... The graph looks good!Bootstrapping Conda environment... (this could take a few minutes)All packages already cached in s3.All environments already cached in s3.Workflow starting (run-id 50), see it in the UI athttps://metaflowui.prod.netflix.net/DemoTraining/50[50/start/251640833] Task is starting.[50/start/251640833] Configuration Values:[50/start/251640833] settings.configuration.conda.numpy = 1.22.4[50/start/251640833] settings.configuration.features.0 = runtime[50/start/251640833] settings.configuration.features.1 = content_type[50/start/251640833] settings.configuration.features.2 = top_billed_talent[50/start/251640833] settings.configuration.model.fit_intercept = True[50/start/251640833] settings.configuration.target_column = metricA[50/start/251640833] settings.environment.READ_DATABASE = data_warehouse_prod[50/start/251640833] settings.environment.TARGET_DATABASE = demo_dev[50/start/251640833] Task finished successfully.[50/get_features/251640840] Task is starting.[50/get_features/251640840] Task finished successfully.[50/train/251640854] Task is starting.[50/train/251640854] Fit slope: 0.4702672504331096[50/train/251640854] Fit intercept: -6.247919678070083[50/train/251640854] Task finished successfully.[50/end/251640868] Task is starting.[50/end/251640868] Task finished successfully.Done! See the run in the UI athttps://metaflowui.prod.netflix.net/DemoTraining/50TakeawaysMetaboost is an integration tool that aims to ease the project development, management and execution burden of ML projects at Netflix. It employs a configuration system that combines git based parameters, global configurations and arbitrarily bound configuration files for use during execution against internal Netflix platforms.Integrating this configuration system with the new Config in Metaflow is incredibly simple (by design), only requiring users to add a mix-in class to their FlowSpec — similar to this example in Metaflow documentation — and then reference the configuration values in steps or decorators. The example above templatizes a training Metaflow for the sake of experimentation, but users could just as easily use bindings/configs to templatize their flows across target metrics, business initiatives or any other arbitrary lines of work.Try it at homeIt couldn’t be easier to get started with Configs! Justpip install -U metaflowto get the latest version and head to the updated documentation for examples. If you are impatient, you can find and execute all config-related examples in this repository as well.If you have any questions or feedback about Config (or other Metaflow features), you can reach out to us at the Metaflow community Slack.AcknowledgmentsWe would like to thank Outerbounds for their collaboration on this feature; for rigorously testing it and developing a repository of examples to showcase some of the possibilities offered by this feature.",
  "image": "https://miro.medium.com/v2/resize:fit:1143/1*XrOVl25ZLx8_4nHLRxNgDg.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://netflixtechblog.medium.com/?source=post_page---byline--d2fb8e9ba1c6--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Netflix Technology Blog\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*BJWRqfSMf9Da9vsXG9EBRQ.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://netflixtechblog.com/?source=post_page---byline--d2fb8e9ba1c6--------------------------------\" rel=\"noopener  ugc nofollow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Netflix TechBlog\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*ty4NvNrGg4ReETxqU2N3Og.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"156c\"\u003e\u003ca href=\"https://www.linkedin.com/in/david-j-berg/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eDavid J. Berg\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/david-casler-05a5278/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eDavid Casler\u003c/em\u003e\u003c/a\u003e^, \u003ca href=\"https://www.linkedin.com/in/romain-cledat-4a211a5/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eRomain Cledat\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/qian-huang-emma/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eQian Huang\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/rui-lin-483a83111/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eRui Lin\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/nissanpow/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eNissan Pow\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/nurcansonmez/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eNurcan Sonmez\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/shashanksrikanth/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eShashank Srikanth\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/chaoying-wang/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eChaoying Wang\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/reginalw/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eRegina Wang\u003c/em\u003e\u003c/a\u003e*\u003cem\u003e, \u003c/em\u003e\u003ca href=\"https://www.linkedin.com/in/zitingyu/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eDarin Yu\u003c/em\u003e\u003c/a\u003e*\u003cbr/\u003e*: Model Development Team, Machine Learning Platform\u003cbr/\u003e^: Content Demand Modeling Team\u003c/p\u003e\u003cp id=\"8a5d\"\u003eA month ago at QConSF, we showcased how \u003ca href=\"https://qconsf.com/presentation/nov2024/supporting-diverse-ml-systems-netflix\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNetflix utilizes Metaflow to power a diverse set of ML and AI use cases\u003c/a\u003e, managing thousands of unique Metaflow flows. This followed a previous \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://netflixtechblog.com/supporting-diverse-ml-systems-at-netflix-2d2e6b6d205d\"\u003eblog\u003c/a\u003e on the same topic. Many of these projects are under constant development by dedicated teams with their own business goals and development best practices, such as the system that \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://netflixtechblog.com/supporting-content-decision-makers-with-machine-learning-995b7b76006f\"\u003esupports our content decision makers\u003c/a\u003e, or the system that ranks which language subtitles are most valuable for a specific piece of content.\u003c/p\u003e\u003cp id=\"8a83\"\u003eAs a central ML and AI platform team, our role is to empower our partner teams with tools that maximize their productivity and effectiveness, while adapting to their specific needs (not the other way around). This has been a guiding design principle with \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9\"\u003eMetaflow since its inception\u003c/a\u003e.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eMetaflow infrastructure stack\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"46ac\"\u003eStanding on the shoulders of our extensive cloud infrastructure, Metaflow facilitates easy access to data, compute, and \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://netflixtechblog.com/maestro-netflixs-workflow-orchestrator-ee13a06f9c78\"\u003eproduction-grade workflow orchestration\u003c/a\u003e, as well as built-in best practices for common concerns such as \u003ca href=\"https://docs.metaflow.org/scaling/tagging\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecollaboration\u003c/a\u003e, \u003ca href=\"https://docs.metaflow.org/metaflow/basics#artifacts\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eversioning\u003c/a\u003e, \u003ca href=\"https://docs.metaflow.org/scaling/dependencies\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edependency management\u003c/a\u003e, and \u003ca href=\"https://outerbounds.com/blog/metaflow-dynamic-cards\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eobservability\u003c/a\u003e, which teams use to setup ML/AI experiments and systems that work for them. As a result, Metaflow users at Netflix have been able to run millions of experiments over the past few years without wasting time on low-level concerns.\u003c/p\u003e\u003ch2 id=\"15f1\"\u003eA long standing FAQ: configurable flows\u003c/h2\u003e\u003cp id=\"8abd\"\u003eWhile Metaflow aims to be un-opinionated about some of the upper levels of the stack, some teams within Netflix have developed their own opinionated tooling. As part of Metaflow’s adaptation to their specific needs, we constantly try to understand what has been developed and, more importantly, what gaps these solutions are filling.\u003c/p\u003e\u003cp id=\"bd7e\"\u003eIn some cases, we determine that the gap being addressed is very team specific, or too opinionated at too high a level in the stack, and we therefore decide to not develop it within Metaflow. In other cases, however, we realize that we can develop an underlying construct that aids in filling that gap. Note that even in that case, we do not always aim to completely fill the gap and instead focus on extracting a more general lower level concept that can be leveraged by that particular user but also by others. One such recurring pattern we noticed at Netflix is the need to deploy sets of closely related flows, often as part of a larger pipeline involving table creations, ETLs, and deployment jobs. Frequently, practitioners want to \u003ca href=\"https://docs.metaflow.org/production/coordinating-larger-metaflow-projects\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eexperiment with variants\u003c/a\u003e of these flows, testing new data, new parameterizations, or new algorithms, while keeping the overall structure of the flow or flows intact.\u003c/p\u003e\u003cp id=\"64c6\"\u003eA natural solution is to make flows configurable using configuration files, so variants can be defined without changing the code. Thus far, there hasn’t been a built-in solution for configuring flows, so teams have built their bespoke solutions leveraging Metaflow’s \u003ca href=\"https://docs.metaflow.org/metaflow/basics#advanced-parameters\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJSON-typed Parameters\u003c/a\u003e, \u003ca href=\"https://docs.metaflow.org/scaling/data#data-in-local-files\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIncludeFile\u003c/a\u003e, and \u003ca href=\"https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-aws-step-functions#deploy-time-parameters\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edeploy-time Parameters\u003c/a\u003e or deploying their own home-grown solution (often with great pain). However, none of these solutions make it easy to configure all aspects of the flow’s behavior, decorators in particular.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eRequests for a feature like Metaflow Config\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"0e00\"\u003eOutside Netflix, we have seen similar frequently asked questions on the \u003ca href=\"http://chat.metaflow.org\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMetaflow community Slack\u003c/a\u003e as shown in the user quotes above:\u003c/p\u003e\u003cul\u003e\u003cli id=\"8010\"\u003ehow can I adjust \u003ca href=\"https://docs.metaflow.org/scaling/remote-tasks/requesting-resources\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethe @resource requirements\u003c/a\u003e, such as CPU or memory, without having to hardcode the values in my flows?\u003c/li\u003e\u003cli id=\"129c\"\u003ehow to adjust \u003ca href=\"https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows#time-based-triggering\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethe triggering @schedule\u003c/a\u003e programmatically, so our production and staging deployments can run at different cadences?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"69ac\"\u003eNew in Metaflow: Configs!\u003c/h2\u003e\u003cp id=\"36e8\"\u003eToday, to answer the FAQ, we introduce a new — small but mighty — feature in Metaflow: \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/introduction\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ea Config object\u003c/a\u003e. Configs complement the existing Metaflow constructs of artifacts and Parameters, by allowing you to configure all aspects of the flow, decorators in particular, prior to any run starting. At the end of the day, artifacts, Parameters and Configs are all stored as artifacts by Metaflow but they differ in when they are persisted as shown in the diagram below:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eDifferent data artifacts in Metaflow\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"448b\"\u003eSaid another way:\u003c/p\u003e\u003cul\u003e\u003cli id=\"b920\"\u003eAn\u003cstrong\u003e artifact\u003c/strong\u003e is resolved and persisted to the datastore at the end of each task.\u003c/li\u003e\u003cli id=\"73c1\"\u003eA\u003cstrong\u003e parameter\u003c/strong\u003e is resolved and persisted at the start of a run; it can therefore be modified up to that point. One common use case is to use \u003ca href=\"https://docs.metaflow.org/production/event-triggering\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etriggers\u003c/a\u003e to pass values to a run right before executing. Parameters can only be used within your step code.\u003c/li\u003e\u003cli id=\"61b0\"\u003eA\u003cstrong\u003e config\u003c/strong\u003e is resolved and persisted when the flow is deployed. When using a scheduler such as \u003ca href=\"https://docs.metaflow.org/production/scheduling-metaflow-flows/scheduling-with-argo-workflows\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eArgo Workflows\u003c/a\u003e, deployment happens when create’ing the flow. In the case of a local run, “deployment” happens just prior to the execution of the run — think of “deployment” as gathering all that is needed to run the flow. Unlike parameters, configs can be used more widely in your flow code, particularly, they can be used in step or flow level decorators as well as to set defaults for parameters. Configs can of course also be used within your flow.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"226d\"\u003eAs an example, you can specify a Config that reads a pleasantly human-readable configuration file, formatted as \u003ca href=\"https://toml.io/en/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTOML\u003c/a\u003e. The Config specifies a triggering ‘@schedule’ and ‘@resource’ requirements, as well as application-specific parameters for this specific deployment:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"5155\"\u003e[schedule]\u003cbr/\u003ecron = \u0026#34;0 * * * *\u0026#34;\u003cp\u003e[model]\u003cbr/\u003eoptimizer = \u0026#34;adam\u0026#34;\u003cbr/\u003elearning_rate = 0.5\u003c/p\u003e\u003cp\u003e[resources]\u003cbr/\u003ecpu = 1\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"be39\"\u003eUsing the newly released Metaflow 2.13, you can configure a flow with a Config like above, as demonstrated by this flow:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"ce75\"\u003eimport pprint\u003cbr/\u003efrom metaflow import FlowSpec, step, Config, resources, config_expr, schedule\u003cp\u003e@schedule(cron=config_expr(\u0026#34;config.schedule.cron\u0026#34;))\u003cbr/\u003eclass ConfigurableFlow(FlowSpec):\u003cbr/\u003e    config = Config(\u0026#34;config\u0026#34;, default=\u0026#34;myconfig.toml\u0026#34;, parser=\u0026#34;tomllib.loads\u0026#34;)\u003c/p\u003e\u003cp\u003e    @resources(cpu=config.resources.cpu)\u003cbr/\u003e    @step\u003cbr/\u003e    def start(self):\u003cbr/\u003e        print(\u0026#34;Config loaded:\u0026#34;)\u003cbr/\u003e        pprint.pp(self.config)\u003cbr/\u003e        self.next(self.end)\u003c/p\u003e\u003cp\u003e    @step\u003cbr/\u003e    def end(self):\u003cbr/\u003e        pass\u003c/p\u003e\u003cp\u003eif __name__ == \u0026#34;__main__\u0026#34;:\u003cbr/\u003e    ConfigurableFlow()\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"251b\"\u003eThere is a lot going on in the code above, a few highlights:\u003c/p\u003e\u003cul\u003e\u003cli id=\"cc56\"\u003eyou can refer to configs \u003cem\u003ebefore\u003c/em\u003e they have been defined using ‘config_expr’.\u003c/li\u003e\u003cli id=\"2cf7\"\u003eyou can define arbitrary \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/parsing-configs\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eparsers\u003c/a\u003e — using a string means the parser doesn’t even have to be present remotely!\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"1590\"\u003eFrom the developer’s point of view, Configs behave like dictionary-like artifacts. For convenience, they support the dot-syntax (when possible) for accessing keys, making it easy to access values in a nested configuration. You can also unpack the whole Config (or a subtree of it) with Python’s standard dictionary unpacking syntax, ‘**config’. The standard dictionary subscript notation is also available.\u003c/p\u003e\u003cp id=\"5e1e\"\u003eSince Configs turn into dictionary artifacts, they get versioned and persisted automatically as artifacts. You can \u003ca href=\"https://docs.metaflow.org/metaflow/client\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eaccess Configs of any past runs easily through the Client API\u003c/a\u003e. As a result, your data, models, code, Parameters, Configs, and \u003ca href=\"https://docs.metaflow.org/scaling/dependencies\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eexecution environments\u003c/a\u003e are all stored as a consistent bundle — neatly organized in \u003ca href=\"https://docs.metaflow.org/scaling/tagging\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMetaflow namespaces\u003c/a\u003e — paving the way for easily reproducible, consistent, low-boilerplate, and now easily configurable experiments and robust production deployments.\u003c/p\u003e\u003ch2 id=\"9d64\"\u003eMore than a humble config file\u003c/h2\u003e\u003cp id=\"ee02\"\u003eWhile you can get far by accompanying your flow with a simple config file (stored in your favorite format, thanks to \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/parsing-configs\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003euser-definable parsers\u003c/a\u003e), Configs unlock a number of advanced use cases. Consider these examples from the updated documentation:\u003c/p\u003e\u003cul\u003e\u003cli id=\"626e\"\u003eYou can \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/basic-configuration#mixing-configs-and-parameters\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003echoose the right level of runtime configurability\u003c/strong\u003e\u003c/a\u003e versus fixed deployments by mixing Parameters and Configs. For instance, you can use a Config to define a default value for a parameter which can be \u003ca href=\"https://docs.metaflow.org/production/event-triggering/external-events#passing-parameters-in-events\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eoverridden by a real-time event\u003c/a\u003e as a run is triggered.\u003c/li\u003e\u003cli id=\"83e8\"\u003eYou can define a custom parser to \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/parsing-configs#validating-configs-with-pydantic\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003evalidate the configuration\u003c/strong\u003e\u003c/a\u003e, e.g. using the popular \u003ca href=\"https://docs.pydantic.dev/latest/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePydantic\u003c/a\u003e library.\u003c/li\u003e\u003cli id=\"19d3\"\u003eYou are not limited to using a single file: you can leverage a configuration manager like \u003ca href=\"https://omegaconf.readthedocs.io/en/2.3_branch/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eOmegaConf\u003c/a\u003e or \u003ca href=\"https://hydra.cc/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHydra\u003c/a\u003e to \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/parsing-configs#advanced-configurations-with-omegaconf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003emanage a hierarchy of cascading configuration files\u003c/strong\u003e\u003c/a\u003e. You can also use a domain-specific tool for generating Configs, such as Netflix’s \u003cem\u003eMetaboost\u003c/em\u003e which we cover below.\u003c/li\u003e\u003cli id=\"ca32\"\u003eYou can also \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/custom-parsers#generating-configs-programmatically\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003egenerate configurations on the fly\u003c/strong\u003e\u003c/a\u003e, e.g. fetch Configs from an external service, or inspect the execution environment, such as the current GIT branch, and include it as an extra piece of context in runs.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"ac3f\"\u003eA major benefit of Config over previous more hacky solutions for configuring flows is that they work seamlessly with other features of Metaflow: you can run steps remotely and deploy flows to production, even when relying on custom parsers, without having to worry about packaging Configs or parsers manually or keeping Configs consistent across tasks. Configs also work with the \u003ca href=\"https://docs.metaflow.org/metaflow/managing-flows/runner\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRunner\u003c/a\u003e and \u003ca href=\"https://docs.metaflow.org/metaflow/managing-flows/deployer\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDeployer\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"8ae8\"\u003eThe Hollywood principle: don’t call us, we’ll call you\u003c/h2\u003e\u003cp id=\"84f1\"\u003eWhen used in conjunction with a configuration manager like \u003ca href=\"https://hydra.cc\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHydra\u003c/a\u003e, Configs enable a pattern that is highly relevant for ML and AI use cases: orchestrating experiments over multiple configurations or sweeping over parameter spaces. While Metaflow has always supported \u003ca href=\"https://docs.outerbounds.com/grid-search-with-metaflow/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esweeping over parameter grids\u003c/a\u003e easily using foreaches, it hasn’t been easily possible to alter the flow itself, e.g. to change \u003ca href=\"https://docs.metaflow.org/api/step-decorators/resources\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e@resources\u003c/a\u003e or \u003ca href=\"https://docs.metaflow.org/api/step-decorators/conda\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e@pypi/@conda\u003c/a\u003e dependencies for every experiment.\u003c/p\u003e\u003cp id=\"f7ef\"\u003eIn a typical case, you trigger a Metaflow flow that consumes a configuration file, changing \u003cem\u003ehow\u003c/em\u003e a run behaves. With Hydra, you can \u003ca href=\"https://en.wikipedia.org/wiki/Inversion_of_control\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003einvert the control\u003c/a\u003e: it is Hydra that decides \u003cem\u003ewhat\u003c/em\u003e gets run based on a configuration file. Thanks to Metaflow’s new \u003ca href=\"https://docs.metaflow.org/metaflow/managing-flows/runner\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRunner\u003c/a\u003e and \u003ca href=\"https://docs.metaflow.org/metaflow/managing-flows/deployer\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDeployer\u003c/a\u003e APIs, you can create a Hydra app that operates Metaflow programmatically — for instance, to deploy and execute hundreds of variants of a flow in a large-scale experiment.\u003c/p\u003e\u003cp id=\"1fda\"\u003e\u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/config-driven-experimentation\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTake a look at two interesting examples of this pattern\u003c/a\u003e in the documentation. As a teaser, this video shows Hydra orchestrating deployment of tens of Metaflow flows, each of which benchmarks PyTorch using a varying number of CPU cores and tensor sizes, updating a visualization of the results in real-time as the experiment progresses:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eExample using Hydra with Metaflow\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"88a6\"\u003eMetaboosting Metaflow — based on a true story\u003c/h2\u003e\u003cp id=\"4282\"\u003eTo give a motivating example of what configurations look like at Netflix in practice, let’s consider \u003cem\u003eMetaboost\u003c/em\u003e, an internal Netflix CLI tool that helps ML practitioners manage, develop and execute their cross-platform projects, somewhat similar to the open-source Hydra discussed above but with specific integrations to the Netflix ecosystem. Metaboost is an example of an opinionated framework developed by a team already using Metaflow. In fact, a part of the inspiration for introducing Configs in Metaflow came from this very use case.\u003c/p\u003e\u003cp id=\"9322\"\u003eMetaboost serves as a single interface to three different internal platforms at Netflix that manage ETL/Workflows (\u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://netflixtechblog.com/maestro-netflixs-workflow-orchestrator-ee13a06f9c78\"\u003e\u003cem\u003eMaestro\u003c/em\u003e\u003c/a\u003e), Machine Learning Pipelines (\u003ca href=\"https://docs.metaflow.org\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eMetaflow\u003c/em\u003e\u003c/a\u003e) and Data Warehouse Tables (\u003cem\u003eKragle\u003c/em\u003e). In this context, having a single configuration system to manage a ML project holistically gives users increased project coherence and decreased project risk.\u003c/p\u003e\u003ch2 id=\"fbf6\"\u003eConfiguration in Metaboost\u003c/h2\u003e\u003cp id=\"a6d0\"\u003eEase of configuration and templatizing are core values of Metaboost. Templatizing in Metaboost is achieved through the concept of \u003cem\u003ebindings\u003c/em\u003e, wherein we can \u003cem\u003ebind\u003c/em\u003e a Metaflow pipeline to an arbitrary label, and then create a corresponding bespoke configuration for that label. The binding-connected configuration is then merged into a global set of configurations containing such information as GIT repository, branch, etc. Binding a Metaflow, will also signal to Metaboost that it should instantiate the Metaflow flow once per binding into our orchestration cluster.\u003c/p\u003e\u003cp id=\"747b\"\u003eImagine a ML practitioner on the Netflix Content ML team, sourcing features from hundreds of columns in our data warehouse, and creating a multitude of models against a \u003cem\u003egrowing\u003c/em\u003e suite of metrics. When a brand new content metric comes along, with Metaboost, the first version of the metric’s predictive model can easily be created by simply swapping the target column against which the model is trained.\u003c/p\u003e\u003cp id=\"dd0d\"\u003eSubsequent versions of the model will result from experimenting with hyper parameters, tweaking feature engineering, or conducting feature diets. Metaboost’s bindings, and their integration with Metaflow Configs, can be leveraged to scale the number of experiments as fast as a scientist can create experiment based configurations.\u003c/p\u003e\u003ch2 id=\"edb4\"\u003eScaling experiments with Metaboost bindings — backed by Metaflow Config\u003c/h2\u003e\u003cp id=\"9ad4\"\u003eConsider a Metaboost ML project named `demo` that creates and loads data to custom tables (ETL managed by Maestro), and then trains a simple model on this data (ML Pipeline managed by Metaflow). The project structure of this repository might look like the following:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"abe4\"\u003e├── metaflows\u003cbr/\u003e│   ├── custom                               -\u0026gt; custom python code, used by\u003cbr/\u003e|   |   |                                       Metaflow\u003cbr/\u003e│   │   ├── data.py\u003cbr/\u003e│   │   └── model.py\u003cbr/\u003e│   └── training.py                          -\u0026gt; defines our Metaflow pipeline\u003cbr/\u003e├── schemas\u003cbr/\u003e│   ├── demo_features_f.tbl.yaml             -\u0026gt; table DDL, stores our ETL\u003cbr/\u003e|   |                                           output, Metaflow input\u003cbr/\u003e│   └── demo_predictions_f.tbl.yaml          -\u0026gt; table DDL,\u003cbr/\u003e|                                               stores our Metaflow output\u003cbr/\u003e├── settings\u003cbr/\u003e│   ├── settings.configuration.EXP_01.yaml   -\u0026gt; defines the additive\u003cbr/\u003e|   |                                           config for Experiment 1\u003cbr/\u003e│   ├── settings.configuration.EXP_02.yaml   -\u0026gt; defines the additive\u003cbr/\u003e|   |                                           config for Experiment 2\u003cbr/\u003e│   ├── settings.configuration.yaml          -\u0026gt; defines our global\u003cbr/\u003e|   |                                           configuration\u003cbr/\u003e│   └── settings.environment.yaml            -\u0026gt; defines parameters based on\u003cbr/\u003e|                                               git branch (e.g. READ_DB)\u003cbr/\u003e├── tests\u003cbr/\u003e├── workflows\u003cbr/\u003e│   ├── sql\u003cbr/\u003e│   ├── demo.demo_features_f.sch.yaml        -\u0026gt; Maestro workflow, defines ETL\u003cbr/\u003e│   └── demo.main.sch.yaml                   -\u0026gt; Maestro workflow, orchestrates\u003cbr/\u003e|                                               ETLs and Metaflow\u003cbr/\u003e└── metaboost.yaml                           -\u0026gt; defines our project for\u003cbr/\u003e                                                Metaboost\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"f679\"\u003eThe configuration files in the settings directory above contain the following YAML files:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"1929\"\u003e# settings.configuration.yaml (global configuration)\u003cbr/\u003emodel:\u003cbr/\u003e  fit_intercept: True\u003cbr/\u003econda:\u003cbr/\u003e  numpy: \u0026#39;1.22.4\u0026#39;\u003cbr/\u003e  \u0026#34;scikit-learn\u0026#34;: \u0026#39;1.4.0\u0026#39;\u003c/span\u003e\u003c/pre\u003e\u003cpre\u003e\u003cspan id=\"9ce6\"\u003e# settings.configuration.EXP_01.yaml\u003cbr/\u003etarget_column: metricA\u003cbr/\u003efeatures:\u003cbr/\u003e  - runtime\u003cbr/\u003e  - content_type\u003cbr/\u003e  - top_billed_talent\u003c/span\u003e\u003c/pre\u003e\u003cpre\u003e\u003cspan id=\"2b0b\"\u003e# settings.configuration.EXP_02.yaml\u003cbr/\u003etarget_column: metricA\u003cbr/\u003efeatures:\u003cbr/\u003e  - runtime\u003cbr/\u003e  - director\u003cbr/\u003e  - box_office\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"069e\"\u003eMetaboost will merge each experiment configuration (\u003cem\u003e*.EXP*.yaml\u003c/em\u003e) into the global configuration (settings.configuration.yaml) \u003cem\u003eindividually\u003c/em\u003e at Metaboost command initialization. Let’s take a look at how Metaboost combines these configurations with a Metaboost command:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"4715\"\u003e(venv-demo) ~/projects/metaboost-demo [branch=demoX] \u003cbr/\u003e$ metaboost metaflow settings show --yaml-path=configuration\u003cp\u003ebinding=EXP_01:\u003cbr/\u003emodel:                     -\u0026gt; defined in setting.configuration.yaml (global)\u003cbr/\u003e  fit_intercept: true\u003cbr/\u003econda:                     -\u0026gt; defined in setting.configuration.yaml (global)\u003cbr/\u003e  numpy: 1.22.4\u003cbr/\u003e  \u0026#34;scikit-learn\u0026#34;: 1.4.0\u003cbr/\u003etarget_column: metricA     -\u0026gt; defined in setting.configuration.EXP_01.yaml\u003cbr/\u003efeatures:                  -\u0026gt; defined in setting.configuration.EXP_01.yaml\u003cbr/\u003e- runtime\u003cbr/\u003e- content_type\u003cbr/\u003e- top_billed_talent\u003c/p\u003e\u003cp\u003ebinding=EXP_02:\u003cbr/\u003emodel:                     -\u0026gt; defined in setting.configuration.yaml (global)\u003cbr/\u003e  fit_intercept: true\u003cbr/\u003econda:                     -\u0026gt; defined in setting.configuration.yaml (global)\u003cbr/\u003e  numpy: 1.22.4\u003cbr/\u003e  \u0026#34;scikit-learn\u0026#34;: 1.4.0\u003cbr/\u003etarget_column: metricA     -\u0026gt; defined in setting.configuration.EXP_02.yaml\u003cbr/\u003efeatures:                  -\u0026gt; defined in setting.configuration.EXP_02.yaml\u003cbr/\u003e- runtime\u003cbr/\u003e- director\u003cbr/\u003e- box_office\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"a78e\"\u003eMetaboost understands it should deploy/run two independent instances of training.py — one for the EXP_01 binding and one for the EXP_02 binding. You can also see that Metaboost is aware that the tables and ETL workflows are \u003cem\u003enot bound\u003c/em\u003e, and should only be deployed once. These details of which artifacts to bind and which to leave unbound are encoded in the project’s top-level metaboost.yaml file.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"9346\"\u003e(venv-demo) ~/projects/metaboost-demo [branch=demoX] \u003cbr/\u003e$ metaboost project list\u003cp\u003eTables (metaboost table list):\u003cbr/\u003eschemas/demo_predictions_f.tbl.yaml (binding=default):\u003cbr/\u003e    table_path=prodhive/demo_db/demo_predictions_f\u003cbr/\u003eschemas/demo_features_f.tbl.yaml (binding=default):\u003cbr/\u003e    table_path=prodhive/demo_db/demo_features_f\u003c/p\u003e\u003cp\u003eWorkflows (metaboost workflow list):\u003cbr/\u003eworkflows/demo.demo_features_f.sch.yaml (binding=default):\u003cbr/\u003e    cluster=sandbox, workflow.id=demo.branch_demox.demo_features_f\u003cbr/\u003eworkflows/demo.main.sch.yaml (binding=default):\u003cbr/\u003e    cluster=sandbox, workflow.id=demo.branch_demox.main\u003c/p\u003e\u003cp\u003eMetaflows (metaboost metaflow list):\u003cbr/\u003emetaflows/training.py (binding=EXP_01): -\u0026gt; EXP_01 instance of training.py\u003cbr/\u003e    cluster=sandbox, workflow.id=demo.branch_demox.EXP_01.training   \u003cbr/\u003emetaflows/training.py (binding=EXP_02): -\u0026gt; EXP_02 instance of training.py\u003cbr/\u003e    cluster=sandbox, workflow.id=demo.branch_demox.EXP_02.training\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"c673\"\u003eBelow is a simple Metaflow pipeline that fetches data, executes feature engineering, and trains a LinearRegression model. The work to integrate Metaboost Settings into a user’s Metaflow pipeline (implemented using Metaflow Configs) is as easy as adding a single mix-in to the FlowSpec definition:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"6889\"\u003efrom metaflow import FlowSpec, Parameter, conda_base, step\u003cbr/\u003efrom custom.data import feature_engineer, get_data\u003cbr/\u003efrom metaflow.metaboost import MetaboostSettings\u003cp\u003e@conda_base(\u003cbr/\u003e    libraries=MetaboostSettings.get_deploy_time_settings(\u0026#34;configuration.conda\u0026#34;)\u003cbr/\u003e)\u003cbr/\u003eclass DemoTraining(FlowSpec, MetaboostSettings):\u003cbr/\u003e    prediction_date = Parameter(\u0026#34;prediction_date\u0026#34;, type=int, default=-1)\u003c/p\u003e\u003cp\u003e    @step\u003cbr/\u003e    def start(self):\u003cbr/\u003e        # get show_settings() for free with the mixin\u003cbr/\u003e        # and get convenient debugging info\u003cbr/\u003e        self.show_settings(exclude_patterns=[\u0026#34;artifact*\u0026#34;, \u0026#34;system*\u0026#34;])\u003c/p\u003e\u003cp\u003e        self.next(self.get_features)\u003c/p\u003e\u003cp\u003e    @step\u003cbr/\u003e    def get_features(self):\u003cbr/\u003e        # feature engineers on our extracted data\u003cbr/\u003e        self.fe_df = feature_engineer(\u003cbr/\u003e            # loads data from our ETL pipeline\u003cbr/\u003e            data=get_data(prediction_date=self.prediction_date),\u003cbr/\u003e            features=self.settings.configuration.features +\u003cbr/\u003e                [self.settings.configuration.target_column]\u003cbr/\u003e        )\u003c/p\u003e\u003cp\u003e        self.next(self.train)\u003c/p\u003e\u003cp\u003e    @step\u003cbr/\u003e    def train(self):\u003cbr/\u003e        from sklearn.linear_model import LinearRegression\u003c/p\u003e\u003cp\u003e        # trains our model\u003cbr/\u003e        self.model = LinearRegression(\u003cbr/\u003e            fit_intercept=self.settings.configuration.model.fit_intercept\u003cbr/\u003e        ).fit(\u003cbr/\u003e            X=self.fe_df[self.settings.configuration.features],\u003cbr/\u003e            y=self.fe_df[self.settings.configuration.target_column]\u003cbr/\u003e        )\u003cbr/\u003e        print(f\u0026#34;Fit slope: {self.model.coef_[0]}\u0026#34;)\u003cbr/\u003e        print(f\u0026#34;Fit intercept: {self.model.intercept_}\u0026#34;)\u003c/p\u003e\u003cp\u003e        self.next(self.end)\u003c/p\u003e\u003cp\u003e    @step\u003cbr/\u003e    def end(self):\u003cbr/\u003e        pass\u003c/p\u003e\u003cp\u003eif __name__ == \u0026#34;__main__\u0026#34;:\u003cbr/\u003e    DemoTraining()\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"1fa8\"\u003eThe Metaflow Config is added to the FlowSpec by mixing in the MetaboostSettings class. Referencing a configuration value is as easy as using the dot syntax to drill into whichever parameter you’d like.\u003c/p\u003e\u003cp id=\"5872\"\u003eFinally let’s take a look at the output from our sample Metaflow above. We execute experiment EXP_01 with\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"77b1\"\u003emetaboost metaflow run --binding=EXP_01\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"ea6c\"\u003ewhich upon execution will merge the configurations into a single \u003cem\u003esettings\u003c/em\u003e file (shown previously) and serialize it as a yaml file to the \u003cem\u003e.metaboost/settings/compiled/\u003c/em\u003e directory.\u003c/p\u003e\u003cp id=\"0e34\"\u003eYou can see the actual command and args that were sub-processed in the \u003cem\u003eMetaboost Execution\u003c/em\u003e section below. Please note the \u003cstrong\u003e–config\u003c/strong\u003e argument pointing to the serialized yaml file, and then subsequently accessible via \u003cstrong\u003eself.settings\u003c/strong\u003e. Also note the convenient printing of configuration values to stdout during the start step using a mixed in function named \u003cstrong\u003eshow_settings()\u003c/strong\u003e.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"6902\"\u003e(venv-demo) ~/projects/metaboost-demo [branch=demoX] \u003cbr/\u003e$ metaboost metaflow run --binding=EXP_01\u003cp\u003eMetaboost Execution: \u003cbr/\u003e - python3.10 /root/repos/cdm-metaboost-irl/metaflows/training.py\u003cbr/\u003e   --no-pylint --package-suffixes=.py --environment=conda\u003cbr/\u003e   --config settings\u003cbr/\u003e   .metaboost/settings/compiled/settings.branch_demox.EXP_01.training.mP4eIStG.yaml\u003cbr/\u003e   run --prediction_date20241006\u003c/p\u003e\u003cp\u003eMetaflow 2.12.39+nflxfastdata(2.13.5);nflx(2.13.5);metaboost(0.0.27)\u003cbr/\u003e  executing DemoTraining for user:dcasler\u003cbr/\u003eValidating your flow...\u003cbr/\u003e    The graph looks good!\u003cbr/\u003eBootstrapping Conda environment... (this could take a few minutes)\u003cbr/\u003eAll packages already cached in s3.\u003cbr/\u003eAll environments already cached in s3.\u003c/p\u003e\u003cp\u003eWorkflow starting (run-id 50), see it in the UI at\u003cbr/\u003ehttps://metaflowui.prod.netflix.net/DemoTraining/50\u003c/p\u003e\u003cp\u003e[50/start/251640833] Task is starting.\u003cbr/\u003e[50/start/251640833] Configuration Values:\u003cbr/\u003e[50/start/251640833]   settings.configuration.conda.numpy            = 1.22.4\u003cbr/\u003e[50/start/251640833]   settings.configuration.features.0             = runtime\u003cbr/\u003e[50/start/251640833]   settings.configuration.features.1             = content_type\u003cbr/\u003e[50/start/251640833]   settings.configuration.features.2             = top_billed_talent\u003cbr/\u003e[50/start/251640833]   settings.configuration.model.fit_intercept    = True\u003cbr/\u003e[50/start/251640833]   settings.configuration.target_column          = metricA\u003cbr/\u003e[50/start/251640833]   settings.environment.READ_DATABASE            = data_warehouse_prod\u003cbr/\u003e[50/start/251640833]   settings.environment.TARGET_DATABASE          = demo_dev\u003cbr/\u003e[50/start/251640833] Task finished successfully.\u003c/p\u003e\u003cp\u003e[50/get_features/251640840] Task is starting.\u003cbr/\u003e[50/get_features/251640840] Task finished successfully.\u003c/p\u003e\u003cp\u003e[50/train/251640854] Task is starting.\u003cbr/\u003e[50/train/251640854] Fit slope: 0.4702672504331096\u003cbr/\u003e[50/train/251640854] Fit intercept: -6.247919678070083\u003cbr/\u003e[50/train/251640854] Task finished successfully.\u003c/p\u003e\u003cp\u003e[50/end/251640868] Task is starting.\u003cbr/\u003e[50/end/251640868] Task finished successfully.\u003c/p\u003e\u003cp\u003eDone! See the run in the UI at\u003cbr/\u003ehttps://metaflowui.prod.netflix.net/DemoTraining/50\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003ch2 id=\"d6d2\"\u003eTakeaways\u003c/h2\u003e\u003cp id=\"feb6\"\u003eMetaboost is an integration tool that aims to ease the project development, management and execution burden of ML projects at Netflix. It employs a configuration system that combines git based parameters, global configurations and arbitrarily \u003cem\u003ebound\u003c/em\u003e configuration files for use during execution against internal Netflix platforms.\u003c/p\u003e\u003cp id=\"7ec5\"\u003eIntegrating this configuration system with the new Config in Metaflow is incredibly simple (by design), only requiring users to add a mix-in class to their FlowSpec — \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/custom-parsers#including-default-configs-in-flows\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esimilar to this example in Metaflow documentation\u003c/a\u003e — and then reference the configuration values in steps or decorators. The example above templatizes a training Metaflow for the sake of experimentation, but users could just as easily use bindings/configs to templatize their flows across target metrics, business initiatives or any other arbitrary lines of work.\u003c/p\u003e\u003ch2 id=\"d730\"\u003eTry it at home\u003c/h2\u003e\u003cp id=\"2f85\"\u003eIt couldn’t be easier to get started with Configs! Just\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"872c\"\u003epip install -U metaflow\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"e0ec\"\u003eto get the latest version and \u003ca href=\"https://docs.metaflow.org/metaflow/configuring-flows/introduction\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehead to the updated documentation\u003c/a\u003e for examples. If you are impatient, you can find and execute \u003ca href=\"https://github.com/outerbounds/config-examples\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eall config-related examples in this repository\u003c/a\u003e as well.\u003c/p\u003e\u003cp id=\"53e2\"\u003eIf you have any questions or feedback about Config (or other Metaflow features), you can reach out to us at the \u003ca href=\"http://chat.metaflow.org\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMetaflow community Slack\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"24a8\"\u003eAcknowledgments\u003c/h2\u003e\u003cp id=\"97f9\"\u003eWe would like to thank \u003ca href=\"https://outerbounds.co\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eOuterbounds\u003c/a\u003e for their collaboration on this feature; for rigorously testing it and developing a repository of examples to showcase some of the possibilities offered by this feature.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "25 min read",
  "publishedTime": "2024-12-20T07:10:37.289Z",
  "modifiedTime": null
}
