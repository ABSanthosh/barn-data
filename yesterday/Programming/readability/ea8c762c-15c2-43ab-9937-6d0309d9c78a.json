{
  "id": "ea8c762c-15c2-43ab-9937-6d0309d9c78a",
  "title": "How to build secure and scalable remote MCP servers",
  "link": "https://github.blog/ai-and-ml/generative-ai/how-to-build-secure-and-scalable-remote-mcp-servers/",
  "description": "More context can mean more attack surfaces for your projects. Be prepared for what lies ahead with this guide. The post How to build secure and scalable remote MCP servers appeared first on The GitHub Blog.",
  "author": "Den Delimarsky",
  "published": "Fri, 25 Jul 2025 17:12:02 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "AI \u0026 ML",
    "Generative AI",
    "AI agents",
    "MCP"
  ],
  "byline": "Den Delimarsky",
  "length": 16913,
  "excerpt": "More context can mean more attack surfaces for your projects. Be prepared for what lies ahead with this guide.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "Model Context Protocol (MCP) enables AI agents to connect to external tools and data sources without having to implement API-specific connectors. Whether you’re extracting key data from invoices, summarizing support tickets, or searching for code snippets across a large codebase, MCP provides a standardized way to connect LLMs with the context they need.  Below we’ll dig into why security is such a crucial component to MCP usage, especially with a recent specification release, as well as how developers of both MCP clients and MCP servers can build secure integrations from the get-go. Why security matters for MCP Unlike traditional APIs that serve known clients in somewhat controlled environments, MCP servers act as bridges between AI agents and an unlimited number of data sources that can include sensitive enterprise resources. So, a security breach won’t just compromise data — it can give malicious actors the ability to manipulate AI behavior and access connected systems. To help prevent common pitfalls, the MCP specification now includes security guidelines and best practices that address common attack vectors, like confused deputy problems, token passthrough vulnerabilities, and session hijacking. Following these patterns from the start can help you build systems that can handle sensitive tools and data. Understanding the MCP authorization The MCP specification uses OAuth 2.1 for secure authorization. This allows MCP, at the protocol level, to take advantage of many modern security capabilities, including: Authorization server discovery: MCP servers implement OAuth 2.0 Protected Resource Metadata (PRM) (RFC 9728) to advertise the authorization servers that they support. When a client attempts to access a protected MCP server, the server will respond with a HTTP 401 Unauthorized and include a WWW-Authenticate header pointing to the metadata endpoint. Dynamic client registration: This is automatic client registration using OAuth 2.0 Dynamic Client Registration Protocol (RFC 7591). This removes the need for manual client setup when AI agents connect to MCP servers dynamically. Resource indicators: The specification also mandates RFC 8707 Resource Indicators, ensuring that tokens are bound to specific MCP servers. This prevents token reuse attacks and helps maintain clear security boundaries. Even with the latest changes to authorization specs, like the clean split between the responsibilities of the authorization server and the resource server, developers don’t need to worry about implementing security infrastructure from scratch. (Because the requirement to follow the OAuth2.1 conventions didn’t change.) So developers can just use off-the-shelf authorization servers and identity providers.  Because MCP requires implementers to snap to OAuth 2.1 as the default approach to authorization, this also means that developers can use existing OAuth libraries to build the authorization capabilities into their MCP servers without anything super-custom. This is a massive time and effort saver. The complete authorization flow When it comes to connecting to protected MCP servers, a MCP client will need to somehow find out what credentials the server needs. Luckily, because of the aforementioned discovery mechanism, this is a relatively straightforward flow: Discovery phase. MCP client attempts to access MCP server without credentials (that is a token). Server response. MCP server returns a HTTP 401 Unauthorized response with a metadata URL in the WWW-Authenticate header. Metadata retrieval. MCP client fetches Protected Resource Metadata, parses it, and then gets the authorization server endpoints. Client registration. MCP client automatically registers with authorization server (if supported). Some clients may be pre-registered. Authorization request. MCP client initiates OAuth flow with Proof Key for Code Exchange (PKCE) and the resource parameter. User consent. The user authorizes access through the authorization server. Token exchange. MCP client exchanges authorization code for access token. Authenticated requests. All subsequent requests from MCP client to MCP server include Bearer token. Nothing in the flow here is MCP-specific, and that’s the beauty of MCP snapping to a common industry standard. There’s no need to reinvent the wheel because a robust solution already exists. Implementing authorization in MCP Most OAuth providers work well for MCP server authorization without any additional configuration, though one of the more challenging gaps today is the availability of Dynamic Client Registration. However, support for that feature is slowly rolling out across the identity ecosystem, and we expect it to be more common as MCP gains traction. Aside from the authorization server, when implementing authorization for your MCP server, you will need to consider several key components and behaviors: PRM endpoint. The MCP server must implement the /.well-known/oauth-protected-resource endpoint to advertise supported authorization server scopes. The MCP TypeScript SDK already integrates this capability natively, with other MCP SDK support coming very soon. Token validation middleware. You need to make sure that your MCP server is only accepting tokens meant for it. Many open source solutions, like PyJWT, can help you here by: Extracting Bearer tokens from Authorization headers Validating token signatures using your OAuth provider’s JSON Web Key Sets (JWKS) endpoint Checking token expiration and audience claims Ensuring tokens were issued specifically for your MCP server (this part is critical for the security of your infrastructure) Error handling. Your MCP server will need to return proper HTTP status codes (HTTP 401 Unauthorized for missing/invalid tokens, HTTP 403 Forbidden for insufficient permissions) with appropriate WWW-Authenticate headers. Anthropic, together with the broader MCP community, is working on integrating a lot of these capabilities directly into the MCP SDKs, removing the need to implement many of the requirements from scratch. For MCP server developers, this will be the recommended path when it comes to building implementations that conform to the MCP specification and will be able to work with any MCP client out there. Handling multi-user scenarios Multi-tenancy in MCP servers introduces unique security challenges that go beyond simple authorization and token validation. When your MCP server handles requests from multiple users — each with their own identities, permissions, and data — you must enforce strict boundaries to prevent unauthorized access and data leakage. This is a classic “confused deputy” problem, where a legitimate user could inadvertently trick the MCP server into accessing resources they shouldn’t. OAuth tokens are the foundation for securely identifying users. They often contain the necessary user information embedded within their claims (like the sub claim for user ID), but this data must be rigorously validated, and not blindly trusted. As mentioned earlier in the blog post, your MCP server is responsible for: Extracting and validating user identity. After validating the token’s signature and expiration, it can extract the user identifier from the claims. Enforcing authorization policies. Map the user identifier to an internal user profile to determine their specific permissions. Just because a user is authenticated doesn’t mean they are authorized to perform every action or access every piece of data that the MCP server makes available. Ensure correct token audience: Double-check that the token was issued specifically for your MCP server by validating the audience (e.g., in a JSON Web Token this can be the aud claim). This prevents a token obtained for one MCP server from being used to access another. With the user’s identity and permissions established, data isolation becomes the next critical layer of defense. Every database query, downstream API request, cache lookup, and log entry must be scoped to the current user. Failure to do so can lead to one user’s data being accidentally exposed to another. Adhering to the principle of least privilege — where a user can only access the data and perform the actions strictly necessary for their tasks — is paramount. As with other security-sensitive operations, we strongly recommend you use existing, well-tested libraries and frameworks for handling user sessions and data scoping rather than implementing your own from scratch. Scaling with AI gateways As your MCP server gains visibility and adoption, raw performance and basic authorization capabilities won’t be enough. You’ll face challenges like traffic spikes from AI agents making rapid-fire requests, the need to transform between different protocol versions as clients evolve at different speeds, and the complexity of managing security policies consistently across multiple server instances. An AI gateway, similar to what you might’ve seen with API gateways before, sits between your MCP client and MCP server, acting as both a shield and a traffic director. It handles the mundane but critical tasks that would otherwise clutter your business logic, such as rate limiting aggressive clients, validating JWT tokens before they reach your servers, and adding security headers that protect against common web vulnerabilities. AI gateway configuration for MCP servers The great thing about using an AI gateway lies in centralizing cross-cutting concerns. Rather than implementing rate limiting in every MCP server instance, you configure it once at the gateway level. The same applies to JWT validation. Let the gateway handle token verification against your OAuth provider’s requirements, then forward only validated requests with clean user context to your MCP server. This separation of concerns makes maintainability and diagnostics much easier, as you don’t need to worry about spaghetti code mixing responsibilities in one MCP server implementation. Consider implementing these essential policies: Rate limiting to prevent resource exhaustion from runaway AI agents Request/response transformation to handle protocol evolution gracefully Caching for expensive operations that don’t change frequently Circuit breakers that fail fast when downstream services are struggling The AI gateway also becomes your first line of defense for CORS handling and automatic security header injections. Production-ready patterns With the basics out of the way, you’re probably wondering what special considerations you need to keep in mind when deploying MCP servers to production. This section is all about best practices that we recommend you adopt to build secure and scalable MCP infrastructure. Better secrets management We cannot not talk about secrets. Chances are that your MCP server needs to handle its own collection of secrets to talk to many different services, databases, or APIs that are out of direct reach of the MCP server consumers. You wouldn’t want someone to be able to have direct access to the credentials stored on the MCP server to talk to your internal APIs, for example. Knowing this, secrets in MCP servers present a unique challenge: They’re needed frequently for things like OAuth validation, external API calls, and database connections, which makes them prime targets for attackers. Compromising a MCP server often means gaining access to a wide array of downstream systems. Robust secrets management is a non-negotiable requirement for anything with Internet access. What we often see is that developers default to very basic implementations that are just enough to get things working, usually based on environment variables. While these are convenient for local development, they are a security anti-pattern in production. Environment variables are difficult to rotate, often leak into logs or build artifacts, and provide a static target for attackers. The modern approach is to move secrets out of your application’s configuration and into a dedicated secrets management service like Azure Key Vault, AWS Secrets Manager, or HashiCorp Vault. These services provide encrypted storage, fine-grained access control, detailed audit trails, and centralized management. But the most secure way to access these vaults is by eliminating the “bootstrap secret” problem altogether using workload identities (you might’ve heard the term “secretless” or “keyless”). Different providers might have a different term or implementation of it, but the gist is that instead of storing a credential to access the vault, your application is assigned a secure identity by the cloud platform itself. This identity can then be granted specific, limited permissions (e.g., “read-only access to the database credential“) in the secrets vault. Your MCP server authenticates using this identity, retrieves the secrets it needs at runtime, and never has to handle long-lived credentials in its own configuration. This architecture enables you to treat secrets as dynamic, short-lived resources rather than static configuration. You can implement startup validation to fail fast when required secrets are missing and builtin runtime secret rotation capabilities. All your static secrets, such as API keys, can be easily and quickly refreshed without server downtime, dramatically reducing the window of opportunity for an attacker. Finally, the principle of least privilege is critical at scale. Each instance of your MCP server should only have access to the secrets it absolutely needs for its specific tasks. This compartmentalization limits the blast radius of any single compromised instance, containing the potential damage. Observability and monitoring Building scalable and secure MCP servers implies that you have full visibility into their operations. That means that you need effective observability, having full access to a combination of logs, metrics, and traces. Structured logging forms the foundation. The key is consistency across request boundaries. When an AI agent makes a complex request that triggers multiple tool calls or external API interactions, a unique correlation ID should be attached to every log entry. This lets you trace the entire journey through your logs, from the initial request to the final response. Beyond basic logs, distributed tracing provides a detailed, hop-by-hop view of a request’s lifecycle. Using standards like OpenTelemetry, you can visualize how a request flows through your MCP server and any downstream services it calls. This is invaluable for pinpointing performance bottlenecks, like if a specific tool invocation is taking too long. Security event logging deserves special attention in MCP servers because they’re high-value targets. Every authentication attempt, authorization failure, and unusual access pattern should be captured with enough context for future forensic analysis. This isn’t just compliance theater; it’s your early warning system for attacks in progress. In turn, metrics collection should focus on the signals that matter: request latency (because AI agents have short attention spans), error rates (especially for authentication and authorization), and resource utilization. You should also implement a dedicated health endpoint that provides a simple up/down status, allowing load balancers and orchestration systems to automatically manage server instances. Finally, all this data is useless without alerting and visualization. Set up automated alerts to notify you when key metrics cross critical thresholds (e.g., a sudden spike in HTTP 500 errors). Create dashboards that provide an at-a-glance view of your MCP server’s health, performance, and security posture. The goal is to gain end-to-end visibility that helps you detect and diagnose emerging issues before they impact users at scale. Take this with you Building secure and scalable MCP servers requires attention to authentication, authorization, and deployment architecture. The patterns in this guide will give you a head start in creating reliable MCP servers that can handle sensitive tools and data. When building on top of a fast-paced technology like MCP, it’s key that you start with security as a foundation, not an afterthought. The MCP specification provides basic security primitives, and modern cloud platforms provide the infrastructure to scale them. Want to dive deeper? Check out the MCP authorization specification and recommended security best practices for complete technical details. Want to dive deeper? Check out the MCP authorization specification and recommended security best practices for complete technical details. Written by Principal Product Manager",
  "image": "https://github.blog/wp-content/uploads/2025/07/wallpaper-generic-blue.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003e\u003ca href=\"https://modelcontextprotocol.io/introduction\"\u003eModel Context Protocol\u003c/a\u003e (MCP) enables AI agents to connect to external tools and data sources without having to implement API-specific connectors. Whether you’re extracting key data from invoices, summarizing support tickets, or searching for code snippets across a large codebase, MCP provides a standardized way to connect LLMs with the context they need. \u003c/p\u003e\n\n\n\n\u003cp\u003eBelow we’ll dig into why security is such a crucial component to MCP usage, especially with a \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization\"\u003erecent specification release\u003c/a\u003e, as well as how developers of both MCP clients and MCP servers can build secure integrations from the get-go.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-why-security-matters-for-mcp\"\u003eWhy security matters for MCP\u003c/h2\u003e\n\n\n\n\u003cp\u003eUnlike traditional APIs that serve known clients in somewhat controlled environments, MCP servers act as bridges between AI agents and an unlimited number of data sources that can include sensitive enterprise resources. So, a security breach won’t just compromise data — it can give malicious actors the ability to manipulate AI behavior and access connected systems.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo help prevent common pitfalls, the MCP specification now includes \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices\"\u003esecurity guidelines\u003c/a\u003e and best practices that address common attack vectors, like confused deputy problems, token passthrough vulnerabilities, and session hijacking. Following these patterns from the start can help you build systems that can handle sensitive tools and data.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-understanding-the-mcp-authorization\"\u003eUnderstanding the MCP authorization\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe MCP specification uses \u003ca href=\"https://datatracker.ietf.org/doc/html/draft-ietf-oauth-v2-1-13\"\u003eOAuth 2.1\u003c/a\u003e for secure authorization. This allows MCP, at the protocol level, to take advantage of many modern security capabilities, including:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAuthorization server discovery\u003c/strong\u003e: MCP servers implement OAuth 2.0 Protected Resource Metadata (PRM) (\u003ca href=\"https://datatracker.ietf.org/doc/html/rfc9728/\"\u003eRFC 9728\u003c/a\u003e) to advertise the authorization servers that they support. When a client attempts to access a protected MCP server, the server will respond with a \u003ccode\u003eHTTP 401 Unauthorized\u003c/code\u003e and include a \u003ccode\u003eWWW-Authenticate\u003c/code\u003e header pointing to the metadata endpoint.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eDynamic client registration\u003c/strong\u003e: This is automatic client registration using OAuth 2.0 Dynamic Client Registration Protocol (\u003ca href=\"https://datatracker.ietf.org/doc/html/rfc7591/\"\u003eRFC 7591\u003c/a\u003e). This removes the need for manual client setup when AI agents connect to MCP servers dynamically.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eResource indicators\u003c/strong\u003e: The specification also mandates \u003ca href=\"https://datatracker.ietf.org/doc/html/rfc8707\"\u003eRFC 8707\u003c/a\u003e Resource Indicators, ensuring that tokens are bound to specific MCP servers. This prevents token reuse attacks and helps maintain clear security boundaries.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eEven with the latest changes to \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization\"\u003eauthorization specs\u003c/a\u003e, like the clean split between the responsibilities of the authorization server and the resource server, developers don’t need to worry about implementing security infrastructure from scratch. (Because the requirement to follow the OAuth2.1 conventions didn’t change.) So developers can just use off-the-shelf authorization servers and identity providers. \u003c/p\u003e\n\n\n\n\u003cp\u003eBecause MCP requires implementers to snap to OAuth 2.1 as the default approach to authorization, this also means that developers can use existing OAuth libraries to build the authorization capabilities into their MCP servers without anything super-custom. This is a massive time and effort saver.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-the-complete-authorization-flow\"\u003eThe complete authorization flow\u003c/h3\u003e\n\n\n\n\u003cp\u003eWhen it comes to connecting to protected MCP servers, a MCP client will need to \u003cem\u003esomehow\u003c/em\u003e find out what credentials the server needs. Luckily, because of the aforementioned discovery mechanism, this is a relatively straightforward flow:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eDiscovery phase\u003c/strong\u003e. MCP client attempts to access MCP server without credentials (that is a token).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eServer response\u003c/strong\u003e. MCP server returns a \u003ccode\u003eHTTP 401 Unauthorized\u003c/code\u003e response with a metadata URL in the \u003ccode\u003eWWW-Authenticate\u003c/code\u003e header.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eMetadata retrieval\u003c/strong\u003e. MCP client fetches Protected Resource Metadata, parses it, and then gets the authorization server endpoints.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eClient registration\u003c/strong\u003e. MCP client automatically registers with authorization server (if supported). Some clients may be pre-registered.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eAuthorization request\u003c/strong\u003e. MCP client initiates OAuth flow with Proof Key for Code Exchange (PKCE) and the \u003ccode\u003eresource\u003c/code\u003e parameter.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eUser consent\u003c/strong\u003e. The user authorizes access through the authorization server.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eToken exchange\u003c/strong\u003e. MCP client exchanges authorization code for access token.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eAuthenticated requests\u003c/strong\u003e. All subsequent requests from MCP client to MCP server include \u003ccode\u003eBearer\u003c/code\u003e token.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eNothing in the flow here is MCP-specific, and that’s the beauty of MCP snapping to a common industry standard. There’s no need to reinvent the wheel because a robust solution already exists.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-implementing-authorization-in-mcp\"\u003eImplementing authorization in MCP\u003c/h2\u003e\n\n\n\n\u003cp\u003eMost OAuth providers work well for MCP server authorization without any additional configuration, though one of the more challenging gaps today is the availability of Dynamic Client Registration. However, support for that feature is slowly rolling out across the identity ecosystem, and we expect it to be more common as MCP gains traction.\u003c/p\u003e\n\n\n\n\u003cp\u003eAside from the authorization server, when implementing authorization for your MCP server, you will need to consider several key components and behaviors:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePRM endpoint\u003c/strong\u003e. The MCP server must implement the \u003ccode\u003e/.well-known/oauth-protected-resource\u003c/code\u003e endpoint to advertise supported authorization server scopes. The \u003ca href=\"https://github.com/modelcontextprotocol/typescript-sdk\"\u003eMCP TypeScript SDK\u003c/a\u003e already integrates this capability natively, with other MCP SDK support coming very soon.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eToken validation middleware\u003c/strong\u003e. You need to make sure that your MCP server is only accepting tokens meant for it. Many open source solutions, like \u003ca href=\"https://github.com/jpadilla/pyjwt\"\u003ePyJWT\u003c/a\u003e, can help you here by:\n\u003cul\u003e\n\u003cli\u003eExtracting Bearer tokens from Authorization headers\u003c/li\u003e\n\n\n\n\u003cli\u003eValidating token signatures using your OAuth provider’s JSON Web Key Sets (JWKS) endpoint\u003c/li\u003e\n\n\n\n\u003cli\u003eChecking token expiration and audience claims\u003c/li\u003e\n\n\n\n\u003cli\u003eEnsuring tokens were issued specifically for your MCP server (this part is critical for the security of your infrastructure)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eError handling\u003c/strong\u003e. Your MCP server will need to return proper HTTP status codes (\u003ccode\u003eHTTP 401 Unauthorized\u003c/code\u003e for missing/invalid tokens, \u003ccode\u003eHTTP 403 Forbidden\u003c/code\u003e for insufficient permissions) with appropriate \u003ccode\u003eWWW-Authenticate\u003c/code\u003e headers.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eAnthropic, together with the broader MCP community, is working on integrating a lot of these capabilities directly into the MCP SDKs, removing the need to implement many of the requirements from scratch. For MCP server developers, this will be the recommended path when it comes to building implementations that conform to the MCP specification and will be able to work with \u003cem\u003eany\u003c/em\u003e MCP client out there.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-handling-multi-user-scenarios\"\u003eHandling multi-user scenarios\u003c/h3\u003e\n\n\n\n\u003cp\u003eMulti-tenancy in MCP servers introduces unique security challenges that go beyond simple authorization and token validation. When your MCP server handles requests from multiple users — each with their own identities, permissions, and data — you must enforce strict boundaries to prevent unauthorized access and data leakage. This is a classic “confused deputy” problem, where a legitimate user could inadvertently trick the MCP server into accessing resources they shouldn’t.\u003c/p\u003e\n\n\n\n\u003cp\u003eOAuth tokens are the foundation for securely identifying users. They often contain the necessary user information embedded within their claims (like the \u003ccode\u003esub\u003c/code\u003e claim for user ID), but this data must be rigorously validated, and not blindly trusted.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs mentioned earlier in the blog post, your MCP server is responsible for:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eExtracting and validating user identity\u003c/strong\u003e. After validating the token’s signature and expiration, it can extract the user identifier from the claims.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eEnforcing authorization policies\u003c/strong\u003e. Map the user identifier to an internal user profile to determine their specific permissions. Just because a user is authenticated doesn’t mean they are authorized to perform every action or access every piece of data that the MCP server makes available.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eEnsure correct token audience\u003c/strong\u003e: Double-check that the token was issued specifically for your MCP server by validating the audience (e.g., in a JSON Web Token this can be the \u003ccode\u003eaud\u003c/code\u003e claim). This prevents a token obtained for one MCP server from being used to access another.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eWith the user’s identity and permissions established, data isolation becomes the next critical layer of defense. Every database query, downstream API request, cache lookup, and log entry must be scoped to the current user. Failure to do so can lead to one user’s data being accidentally exposed to another. Adhering to the principle of least privilege — where a user can only access the data and perform the actions strictly necessary for their tasks — is paramount.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs with other security-sensitive operations, we strongly recommend you use existing, well-tested libraries and frameworks for handling user sessions and data scoping rather than implementing your own from scratch.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-scaling-with-ai-gateways\"\u003eScaling with AI gateways\u003c/h2\u003e\n\n\n\n\u003cp\u003eAs your MCP server gains visibility and adoption, raw performance and basic authorization capabilities won’t be enough. You’ll face challenges like traffic spikes from AI agents making rapid-fire requests, the need to transform between different protocol versions as clients evolve at different speeds, and the complexity of managing security policies consistently across multiple server instances.\u003c/p\u003e\n\n\n\n\u003cp\u003eAn \u003ca href=\"https://learn.microsoft.com/azure/api-management/genai-gateway-capabilities\"\u003eAI gateway\u003c/a\u003e, similar to what you might’ve seen with API gateways before, sits between your MCP client and MCP server, acting as both a shield and a traffic director. It handles the mundane but critical tasks that would otherwise clutter your business logic, such as rate limiting aggressive clients, validating JWT tokens before they reach your servers, and adding security headers that protect against common web vulnerabilities.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-ai-gateway-configuration-for-mcp-servers\"\u003eAI gateway configuration for MCP servers\u003c/h3\u003e\n\n\n\n\u003cp\u003eThe great thing about using an AI gateway lies in centralizing cross-cutting concerns. Rather than implementing rate limiting in every MCP server instance, you configure it once at the gateway level. The same applies to JWT validation. Let the gateway handle token verification against your OAuth provider’s requirements, then forward only validated requests with clean user context to your MCP server. This separation of concerns makes maintainability and diagnostics much easier, as you don’t need to worry about spaghetti code mixing responsibilities in one MCP server implementation.\u003c/p\u003e\n\n\n\n\u003cp\u003eConsider implementing these essential policies:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eRate limiting to prevent resource exhaustion from runaway AI agents\u003c/li\u003e\n\n\n\n\u003cli\u003eRequest/response transformation to handle protocol evolution gracefully\u003c/li\u003e\n\n\n\n\u003cli\u003eCaching for expensive operations that don’t change frequently\u003c/li\u003e\n\n\n\n\u003cli\u003eCircuit breakers that fail fast when downstream services are struggling\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThe AI gateway also becomes your first line of defense for CORS handling and automatic security header injections.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-production-ready-patterns\"\u003eProduction-ready patterns\u003c/h2\u003e\n\n\n\n\u003cp\u003eWith the basics out of the way, you’re probably wondering what special considerations you need to keep in mind when deploying MCP servers to production. This section is all about best practices that we recommend you adopt to build secure and scalable MCP infrastructure.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-better-secrets-management\"\u003eBetter secrets management\u003c/h3\u003e\n\n\n\n\u003cp\u003eWe cannot not talk about secrets. Chances are that your MCP server needs to handle its own collection of secrets to talk to many different services, databases, or APIs that are out of direct reach of the MCP server consumers. You wouldn’t want someone to be able to have direct access to the credentials stored on the MCP server to talk to your internal APIs, for example.\u003c/p\u003e\n\n\n\n\u003cp\u003eKnowing this, secrets in MCP servers present a unique challenge: They’re needed frequently for things like OAuth validation, external API calls, and database connections, which makes them prime targets for attackers. Compromising a MCP server often means gaining access to a wide array of downstream systems. Robust secrets management is a non-negotiable requirement for anything with Internet access.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhat we often see is that developers default to very basic implementations that are just enough to get things working, usually based on environment variables. While these are convenient for local development, they are a security anti-pattern in production. Environment variables are difficult to rotate, often leak into logs or build artifacts, and provide a static target for attackers.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe modern approach is to move secrets out of your application’s configuration and into a dedicated secrets management service like \u003ca href=\"https://learn.microsoft.com/azure/key-vault/general/basic-concepts\"\u003eAzure Key Vault\u003c/a\u003e, \u003ca href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\"\u003eAWS Secrets Manager\u003c/a\u003e, or \u003ca href=\"https://developer.hashicorp.com/vault/docs/about-vault/what-is-vault\"\u003eHashiCorp Vault\u003c/a\u003e. These services provide encrypted storage, fine-grained access control, detailed audit trails, and centralized management.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut the most secure way to access these vaults is by eliminating the “bootstrap secret” problem altogether using \u003cstrong\u003eworkload identities\u003c/strong\u003e (you might’ve heard the term “secretless” or “keyless”). Different providers might have a different term or implementation of it, but the gist is that instead of storing a credential to access the vault, your application is assigned a secure identity by the cloud platform itself. This identity can then be granted specific, limited permissions (e.g., “\u003cem\u003eread-only access to the database credential\u003c/em\u003e“) in the secrets vault. Your MCP server authenticates using this identity, retrieves the secrets it needs at runtime, and never has to handle long-lived credentials in its own configuration.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis architecture enables you to treat secrets as dynamic, short-lived resources rather than static configuration. You can implement startup validation to fail fast when required secrets are missing and builtin runtime secret rotation capabilities. All your static secrets, such as API keys, can be easily and quickly refreshed without server downtime, dramatically reducing the window of opportunity for an attacker.\u003c/p\u003e\n\n\n\n\u003cp\u003eFinally, the principle of least privilege is critical at scale. Each instance of your MCP server should only have access to the secrets it absolutely needs for its specific tasks. This compartmentalization limits the blast radius of any single compromised instance, containing the potential damage.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-observability-and-monitoring\"\u003eObservability and monitoring\u003c/h3\u003e\n\n\n\n\u003cp\u003eBuilding scalable and secure MCP servers implies that you have full visibility into their operations. That means that you need effective observability, having full access to a combination of logs, metrics, and traces.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eStructured logging\u003c/strong\u003e forms the foundation. The key is consistency across request boundaries. When an AI agent makes a complex request that triggers multiple tool calls or external API interactions, a unique correlation ID should be attached to every log entry. This lets you trace the entire journey through your logs, from the initial request to the final response.\u003c/p\u003e\n\n\n\n\u003cp\u003eBeyond basic logs, \u003cstrong\u003edistributed tracing\u003c/strong\u003e provides a detailed, hop-by-hop view of a request’s lifecycle. Using standards like \u003ca href=\"https://opentelemetry.io/\"\u003eOpenTelemetry\u003c/a\u003e, you can visualize how a request flows through your MCP server and any downstream services it calls. This is invaluable for pinpointing performance bottlenecks, like if a specific tool invocation is taking too long.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eSecurity event logging\u003c/strong\u003e deserves special attention in MCP servers because they’re high-value targets. Every authentication attempt, authorization failure, and unusual access pattern should be captured with enough context for future forensic analysis. This isn’t just compliance theater; it’s your early warning system for attacks in progress.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn turn, \u003cstrong\u003emetrics collection\u003c/strong\u003e should focus on the signals that matter: request latency (because AI agents have short attention spans), error rates (especially for authentication and authorization), and resource utilization. You should also implement a dedicated health endpoint that provides a simple up/down status, allowing load balancers and orchestration systems to automatically manage server instances.\u003c/p\u003e\n\n\n\n\u003cp\u003eFinally, all this data is useless without \u003cstrong\u003ealerting and visualization\u003c/strong\u003e. Set up automated alerts to notify you when key metrics cross critical thresholds (e.g., a sudden spike in \u003ccode\u003eHTTP 500\u003c/code\u003e errors). Create dashboards that provide an at-a-glance view of your MCP server’s health, performance, and security posture. The goal is to gain end-to-end visibility that helps you detect and diagnose emerging issues before they impact users at scale.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-take-this-with-you\"\u003eTake this with you\u003c/h2\u003e\n\n\n\n\u003cp\u003eBuilding secure and scalable MCP servers requires attention to authentication, authorization, and deployment architecture. The patterns in this guide will give you a head start in creating reliable MCP servers that can handle sensitive tools and data.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen building on top of a fast-paced technology like MCP, it’s key that you start with security as a foundation, not an afterthought. The MCP specification provides basic security primitives, and modern cloud platforms provide the infrastructure to scale them.\u003c/p\u003e\n\n\n\n\u003cp\u003eWant to dive deeper? Check out the \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization\"\u003eMCP authorization specification\u003c/a\u003e and recommended \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices\"\u003esecurity best practices\u003c/a\u003e for complete technical details.\u003c/p\u003e\n\n\n\n\u003cdiv\u003e\n\u003cp\u003e\u003cstrong\u003eWant to dive deeper? \u003c/strong\u003eCheck out the \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization\"\u003eMCP authorization specification\u003c/a\u003e and recommended \u003ca href=\"https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices\"\u003esecurity best practices\u003c/a\u003e for complete technical details.\u003c/p\u003e\n\u003c/div\u003e\n\n\t\n\n\t\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tWritten by\t\u003c/h2\u003e\n\t\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/53200638?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/53200638?v=4\u0026amp;s=200\" alt=\"Den Delimarsky\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\t\t\t\t\n\t\t\t\t\t\u003cp\u003ePrincipal Product Manager\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\u003c/div\u003e",
  "readingTime": "18 min read",
  "publishedTime": "2025-07-25T17:12:02Z",
  "modifiedTime": "2025-07-25T17:12:04Z"
}
