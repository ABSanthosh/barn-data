{
  "id": "31b76332-b5f7-49d7-b4b1-ce2a0569876d",
  "title": "Google Cloud Launches A4 VMs with NVIDIA Blackwell GPUs for AI Workloads",
  "link": "https://www.infoq.com/news/2025/03/google-a4-vms-nvidia-blackwell/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Google Cloud has launched A4 VMs, powered by NVIDIA's Blackwell B200 GPUs, revolutionizing AI workloads with a 2.25x performance boost and advanced networking. Key features include tight integration with Google Kubernetes Engine and Vertex AI, enhancing deployment and management of large-scale projects. This innovative partnership sets a new standard in cloud infrastructure for AI. By Steef-Jan Wiggers",
  "author": "Steef-Jan Wiggers",
  "published": "Fri, 21 Mar 2025 10:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Cloud",
    "Artificial Intelligence",
    "Google Cloud Platform",
    "Google",
    "Virtual Machines",
    "DevOps",
    "Development",
    "Architecture \u0026 Design",
    "news"
  ],
  "byline": "Steef-Jan Wiggers",
  "length": 3462,
  "excerpt": "Google Cloud has launched A4 VMs, powered by NVIDIA's Blackwell B200 GPUs, revolutionizing AI workloads with a 2.25x performance boost and advanced networking. Key features include tight integration w",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250320073856_u1/apple-touch-icon.png",
  "text": "Google Cloud has unveiled its new A4 virtual machines (VMs) in preview, powered by NVIDIA's Blackwell B200 GPUs, to address the increasing demands of advanced artificial intelligence (AI) workloads. The offering aims to accelerate AI model training, fine-tuning, and inference by combining Google's infrastructure with NVIDIA's hardware. The A4 VM features eight Blackwell GPUs interconnected via fifth-generation NVIDIA NVLink, providing a 2.25x increase in peak compute and high bandwidth memory (HBM) capacity compared to the previous generation A3 High VMs. This performance enhancement addresses the growing complexity of AI models, which require powerful accelerators and high-speed interconnects. Key features include enhanced networking, Google Kubernetes Engine (GKE) integration, Vertex AI accessibility, open software optimization, a hypercompute cluster, and flexible consumption models. Thomas Kurian, CEO of Google Cloud, announced the launch on X, highlighting Google Cloud as the first cloud provider to bring the NVIDIA B200 GPUs to customers. Blackwell has made its Google Cloud debut by launching our new A4 VMs powered by NVIDIA B200. We're the first cloud provider to bring B200 to customers, and we can't wait to see how this powerful platform accelerates your AI workloads. Specifically, the A4 VMs utilize Google's Titanium ML network adapter and NVIDIA ConnectX-7 NICs, delivering 3.2 Tbps of GPU-to-GPU traffic with RDMA over Converged Ethernet (RoCE). The Jupiter network fabric supports scaling to tens of thousands of GPUs with 13 Petabits/sec of bi-sectional bandwidth. Native integration with GKE, supporting up to 65,000 nodes per cluster, facilitates a robust AI platform. The VMs are accessible through Vertex AI, Google's unified AI development platform, powered by the AI Hypercomputer architecture. Google is also collaborating with NVIDIA to optimize JAX and XLA for efficient collective communication and computation on GPUs. Furthermore, a new hypercompute cluster system simplifies the deployment and management of large-scale AI workloads across thousands of A4 VMs. This system focuses on high performance through co-location, optimized resource scheduling with GKE and Slurm, reliability through self-healing capabilities, enhanced observability, and automated provisioning. Flexible consumption models provide optimized AI workload consumption, including the Dynamic Workload Scheduler with Flex Start and Calendar modes. Sai Ruhul, an entrepreneur on X, highlighted analyst estimates that the Blackwell GPUs could be 10-100x faster than NVIDIA's current Hopper/A100 GPUs for large transformer model workloads requiring multi-GPU scaling. This represents a significant leap in scale for accelerating \"Trillion-Parameter AI\" models. In addition, Naeem Aslam, a CIO at Zaye Capital Markets, tweeted on X: Google's integration of NVIDIA Blackwell GPUs into its cloud with A4 VMs could enhance computational power for AI and data processing. This partnership is likely to increase demand for NVIDIA’s GPUs, boosting its position in cloud infrastructure markets. Lastly, this release provides developers access to the latest NVIDIA Blackwell GPUs within Google Cloud's infrastructure, offering substantial performance improvements for AI applications. About the Author Steef-Jan Wiggers",
  "image": "https://res.infoq.com/news/2025/03/google-a4-vms-nvidia-blackwell/en/headerimage/generatedHeaderImage-1742223458534.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eGoogle Cloud has unveiled its new A4 virtual machines (VMs) in preview, powered by \u003ca href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\"\u003eNVIDIA\u0026#39;s Blackwell B200 GPUs\u003c/a\u003e, to address the increasing demands of advanced artificial intelligence (AI) workloads. The offering aims to accelerate AI model training, fine-tuning, and inference by combining Google\u0026#39;s infrastructure with NVIDIA\u0026#39;s hardware.\u003c/p\u003e\n\n\u003cp\u003eThe A4 VM features eight Blackwell GPUs interconnected via \u003ca href=\"https://www.nvidia.com/en-us/data-center/nvlink/\"\u003efifth-generation NVIDIA NVLink\u003c/a\u003e, providing a 2.25x increase in peak compute and high bandwidth memory (HBM) capacity compared to the previous generation A3 High VMs. This performance enhancement addresses the growing complexity of AI models, which require powerful accelerators and high-speed interconnects. Key features include enhanced networking, \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE) integration, Vertex AI accessibility, open software optimization, a hypercompute cluster, and flexible consumption models.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://x.com/ThomasOrTK/\"\u003eThomas Kurian\u003c/a\u003e, CEO of Google Cloud, announced the launch on X, highlighting Google Cloud as the first cloud provider to bring the NVIDIA B200 GPUs to customers.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eBlackwell has made its Google Cloud debut by launching our new A4 VMs powered by NVIDIA B200. We\u0026#39;re the first cloud provider to bring B200 to customers, and we can\u0026#39;t wait to see how this powerful platform accelerates your AI workloads.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eSpecifically, the A4 VMs utilize Google\u0026#39;s Titanium ML network adapter and NVIDIA ConnectX-7 NICs, delivering 3.2 Tbps of GPU-to-GPU traffic with RDMA over Converged Ethernet (RoCE). The Jupiter network fabric supports scaling to tens of thousands of GPUs with 13 Petabits/sec of bi-sectional bandwidth. Native integration with GKE, supporting up to 65,000 nodes per cluster, facilitates a robust AI platform. The VMs are accessible through \u003ca href=\"https://cloud.google.com/vertex-ai\"\u003eVertex AI\u003c/a\u003e, Google\u0026#39;s unified AI development platform, powered by the AI Hypercomputer architecture. Google is also collaborating with NVIDIA to optimize JAX and XLA for efficient collective communication and computation on GPUs.\u003c/p\u003e\n\n\u003cp\u003eFurthermore, a new hypercompute cluster system simplifies the deployment and management of large-scale AI workloads across thousands of A4 VMs. This system focuses on high performance through co-location, optimized resource scheduling with GKE and \u003ca href=\"https://slurm.schedmd.com/overview.html\"\u003eSlurm\u003c/a\u003e, reliability through self-healing capabilities, enhanced observability, and automated provisioning. Flexible consumption models provide optimized AI workload consumption, including the Dynamic Workload Scheduler with Flex Start and Calendar modes.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://x.com/sairahul1/\"\u003eSai Ruhul\u003c/a\u003e, an entrepreneur on X, \u003ca href=\"https://x.com/sairahul1/status/1770008788697002235\"\u003ehighlighted\u003c/a\u003e analyst estimates that the Blackwell GPUs could be 10-100x faster than NVIDIA\u0026#39;s current Hopper/A100 GPUs for large transformer model workloads requiring multi-GPU scaling. This represents a significant leap in scale for accelerating \u0026#34;Trillion-Parameter AI\u0026#34; models.\u003c/p\u003e\n\n\u003cp\u003eIn addition, \u003ca href=\"https://x.com/NaeemAslam23/\"\u003eNaeem Aslam\u003c/a\u003e, a CIO at Zaye Capital Markets, \u003ca href=\"https://x.com/NaeemAslam23/status/1885362857740505512\"\u003etweeted\u003c/a\u003e on X:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eGoogle\u0026#39;s integration of NVIDIA Blackwell GPUs into its cloud with A4 VMs could enhance computational power for AI and data processing. This partnership is likely to increase demand for NVIDIA’s GPUs, boosting its position in cloud infrastructure markets.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eLastly, this release provides developers access to the latest NVIDIA Blackwell GPUs within Google Cloud\u0026#39;s infrastructure, offering substantial performance improvements for AI applications.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Steef~Jan-Wiggers\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSteef-Jan Wiggers\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-03-21T00:00:00Z",
  "modifiedTime": null
}
