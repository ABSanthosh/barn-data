{
  "id": "afe16005-a63f-488a-8443-8acfd84fbd97",
  "title": "",
  "link": "http://scripting.com/2024/12/25.html#a163255",
  "description": "I am ready to start programming ChatGPT, the same way I have built my own code writing and deploying software on Macintosh. I want to create rules in some kind of macro language that it will never violate. I find it has huge problems with memory, it says it's remembering something, but has forgotten it 24 hours later. This is like the Fail Whale in the early days of Twitter. Cute, because the system is doing something so new, futuristic and useful, but after a while it's not cute because we're using the system for real work. The web is programmable, our operating systems are, of course the AI-o-verse will be programmable too. We are able to create entirely new development environments, these platforms deserve a fresh new look at everything. I'd also like to note that at the same time, the platforms are breaking through in web user interfaces. Remarkable progress. Far beyond what we were doing in the very stagnant Web 2.0 world. They're still stuck on whether or not our writing can have titles. So bizarre to have to exist in a world that is deliberately hobbled, and another with infinite horizons. Anyway this is what I'm thinking about just before hunkering down with my Knicks and popcorn, a Christmas tradition for many many years. Ho ho ho.",
  "author": "",
  "published": "Wed, 25 Dec 2024 16:32:55 GMT",
  "source": "http://scripting.com/rss.xml",
  "categories": null,
  "byline": "",
  "length": 1304,
  "excerpt": "Dave Winer, OG blogger, podcaster, developed first apps in many categories. Old enough to know better. It's even worse than it appears.",
  "siteName": "Scripting News",
  "favicon": "",
  "text": "It's even worse than it appears.. I am ready to start programming ChatGPT, the same way I have built my own code writing and deploying software on Macintosh. I want to create rules in some kind of macro language that it will never violate. I find it has huge problems with memory, it says it's remembering something, but has forgotten it 24 hours later. This is like the Fail Whale in the early days of Twitter. Cute, because the system is doing something so new, futuristic and useful, but after a while it's not cute because we're using the system for real work. The web is programmable, our operating systems are, of course the AI-o-verse will be programmable too. We are able to create entirely new development environments, these platforms deserve a fresh new look at everything. I'd also like to note that at the same time, the platforms are breaking through in web user interfaces. Remarkable progress. Far beyond what we were doing in the very stagnant Web 2.0 world. They're still stuck on whether or not our writing can have titles. So bizarre to have to exist in a world that is deliberately hobbled, and another with infinite horizons. Anyway this is what I'm thinking about just before hunkering down with my Knicks and popcorn, a Christmas tradition for many many years. Ho ho ho. #",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"idPageTopText\"\u003e\n\t\n\t\u003cp\u003eIt\u0026#39;s even worse than it appears..\u003c/p\u003e\n\t\u003c/div\u003e\u003cdiv id=\"idDayContainer\"\u003e\n\t\t\t\t\n\u003cp\u003e\u003ca name=\"a163255\"\u003e\u003c/a\u003e\u003cimg src=\"https://imgs.scripting.com/2024/12/25/leftfacingsanta.png\"/\u003eI am ready to start programming ChatGPT, the same way I have  built my own code writing and deploying software on Macintosh. I want to create rules in some kind of macro language that it will never violate. I find it has huge problems with memory, it says it\u0026#39;s remembering something, but has forgotten it 24 hours later. This is like the \u003ca href=\"https://www.theatlantic.com/technology/archive/2015/01/the-story-behind-twitters-fail-whale/384313/?gift=f35zZN0v_gDFE8xNwlQAHSNkdwehtNpsP-bh1d4EoU4\u0026amp;utm_source=copy-link\u0026amp;utm_medium=social\u0026amp;utm_campaign=share\"\u003eFail Whale\u003c/a\u003e in the early days of Twitter. Cute, because the system is doing something so new, futuristic and useful, but after a while it\u0026#39;s not cute because we\u0026#39;re using the system for real work. The web is programmable, our operating systems are, of course the AI-o-verse will be programmable too. We are able to create entirely new development environments, these platforms deserve a fresh new look at \u003ci\u003eeverything.\u003c/i\u003e I\u0026#39;d also like to note that at the same time, the platforms are breaking through in web user interfaces. Remarkable progress. Far beyond what we were doing in the very stagnant Web 2.0 world. They\u0026#39;re still stuck on whether or not our writing can have titles. So bizarre to have to exist in a world that is deliberately hobbled, and another with infinite horizons. Anyway this is what I\u0026#39;m thinking about just before hunkering down with my Knicks and popcorn, a Christmas tradition for many many years. Ho ho ho. \u003cspan\u003e\u003ca href=\"http://scripting.com/2024/12/25.html#a163255\" title=\"Direct link to this item.\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\n\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
