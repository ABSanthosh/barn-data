{
  "id": "fcccce0f-a0bf-4080-944c-9ee76c5db881",
  "title": "Announcing GenAI Processors: Build powerful and flexible Gemini applications",
  "link": "https://developers.googleblog.com/en/genai-processors/",
  "description": "GenAI Processors is a new open-source Python library from Google DeepMind designed to simplify the development of AI applications, especially those handling multimodal input and requiring real-time responsiveness, by providing a consistent \"Processor\" interface for all steps from input handling to model calls and output processing, for seamless chaining and concurrent execution.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Andre Elisseeff, Alexey Guseynov, Oskar Bunyan, Shrestha Basu Mallick",
  "length": 8544,
  "excerpt": "GenAI Processors is a new open-source Python library from Google DeepMind designed to simplify the development of AI applications, especially those handling multimodal input and requiring real-time responsiveness, by providing a consistent \"Processor\" interface for all steps from input handling to model calls and output processing, for seamless chaining and concurrent execution.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Building sophisticated AI applications with Large Language Models (LLMs), especially those handling multimodal input and requiring real-time responsiveness, often feels like assembling a complex puzzle: you're stitching together diverse data processing steps, asynchronous API calls, and custom logic. As complexity grows, this can lead to brittle, hard-to-maintain code.Today, we're introducing GenAI Processors, a new open-source Python library from Google DeepMind designed to bring structure and simplicity to these challenges. GenAI Processors provides an abstraction layer, defining a consistent Processor interface for everything from input handling and pre-processing to model calls and output processing.At its core, GenAI Processors treat all input and output as asynchronous streams of ProcessorParts (i.e. two-way aka bidirectional streaming). Think of it as standardized data parts (e.g., a chunk of audio, a text transcription, an image frame) flowing through your pipeline along with associated metadata. This stream-based API allows for seamless chaining and composition of different operations, from low-level data manipulation to high-level model calls. The GenAI Processors library is designed to optimize the concurrent execution of a Processor. Any part in this example of execution flow can be generated concurrently when all its ancestors in the graph are computed, e.g. `c'12` can be generated concurrently to `a’1`. The flow maintains the ordering of the output stream with respect to the input stream and will be executed to minimize Time To First Token (prefer `a12` to `d12` whenever possible). This concurrency optimization is done under the hood: applying a Processor to a stream of input will automatically trigger this concurrent execution whenever possible. For example, you can easily build a \"Live Agent\" capable of processing audio and video streams in real-time using the Gemini Live API with just a few lines of code. In the following example, notice how input sources and processing steps are combined using the + operator, creating a clear data flow (full code on GitHub): from genai_processors.core import audio_io, live_model, video # Input processor: combines camera streams and audio streams input_processor = video.VideoIn() + audio_io.PyAudioIn(...) # Output processor: plays the audio parts. Handles interruptions and pauses # audio output when the user is speaking. play_output = audio_io.PyAudioOut(...) # Gemini Live API processor live_processor = live_model.LiveProcessor(...) # Compose the agent: mic+camera -\u003e Gemini Live API -\u003e play audio live_processor = live_model.LiveProcessor(...) live_agent = input_processor + live_processor + play_output async for part in live_agent(streams.endless_stream()): # Process the output parts (e.g., print transcription, model output, metadata) print(part) Python Copied You can also build your own Live agent, leveraging a standard text-based LLM, using the bidirectional streaming capability of the GenAI Processor library and the Google Speech API (full code on GitHub): from genai_processors.core import genai_model, realtime, speech_to_text, text_to_speech # Input processor: gets input from audio in (mic) and transcribes into text input_processor = audio_io.PyAudioIn(...) + speech_to_text.SpeechToText(... ) play_output = audio_io.PyAudioOut(...) # Main model that will be used to generate the response. genai_processor = genai_model.GenaiModel(...), # TTS processor that will be used to convert the text response to audio. Note # the rate limit audio processor that will be used to stream back small audio # chunks to the client at the same rate as how they are played back. tts = text_to_speech.TextToSpeech(...) + rate_limit_audio.RateLimitAudio(...) # Creates an agent as: # mic -\u003e speech to text -\u003e text conversation -\u003e text to speech -\u003e play audio live_agent = ( input_processor + realtime.LiveModelProcessor(turn_processor=genai_processor + tts) + play_output ) async for part in live_agent(streams.endless_stream()): … Python Copied We anticipate a growing need for proactive LLM applications where responsiveness is critical. Even for non-streaming use cases, processing data as soon as it is available can significantly reduce latency and time to first token (TTFT), which is essential for building a good user experience. While many LLM APIs prioritize synchronous, simplified interfaces, GenAI Processors – by leveraging native Python features – offer a way for writing responsive applications without making code more complex. Trip planner and Research Agent examples demonstrate how turn-based agents can use the concurrency feature of GenAI Processors to increase responsiveness.Core design principlesAt the heart of GenAI Processors is the concept of a Processor: a fundamental building block that encapsulates a specific unit of work. It takes a stream of inputs, performs an operation, and outputs a stream of results. This simple, consistent API is a cornerstone of the library's power and flexibility.Here's a look at the core design decisions and their benefits for developers:Modular design: Break down complex workflows into self-contained Processor units. This ensures code reusability, testability, and significantly simplifies maintaining intricate pipelines.Asynchronous \u0026 concurrent: Fully leverages Python's asyncio for efficient handling of I/O-bound and compute-bound tasks. This enables responsive applications without manual threading or complex concurrency management.Integrated with Gemini API: Dedicated processors like GenaiModel (for turn-based interaction) and LiveProcessor (for real-time streaming) simplify interaction with the Gemini API, including the complexities of the Live API. This reduces boilerplate and accelerates integration.Extensible: Easily create custom processors by inheriting from base classes or using decorators. Integrate your own data processing logic, external APIs, or specialized operations seamlessly into your pipelines.Unified multimodal handling: The ProcessorPart wrapper provides a consistent interface for handling diverse data types (text, images, audio, JSON, etc.) within the pipeline.Stream manipulation utilities: Built-in utilities for splitting, concatenating, and merging asynchronous streams. This provides fine-grained control over data flow within complex pipelines.Getting startedGetting started with GenAI Processors is straightforward. You can install it with pip: pip install genai-processors Python Copied To help you get familiar with the library, we provide a series of Colab notebooks that walk you through the core concepts and demonstrate how to build various types of processors and applications. We recommend starting with the Content API Colab and Processor Intro Colab.You can also explore the examples/ directory in the repository for practical demonstrations of how to build more complex applications, such as a research agent and a live commentary agent.Looking aheadGenAI Processors is currently in its early stages, and we believe it provides a solid foundation for tackling complex workflow and orchestration challenges in AI applications. While the Google GenAI SDK is available in multiple languages, GenAI Processors currently only support Python.The core/ directory contains fundamental processors, and we actively encourage community contributions for more specialized functionalities in the contrib/ directory. We're excited to collaborate with the developer community to expand the library and build even more sophisticated AI systems.Ready to build more robust and responsive Gemini applications?Check out the GenAI Processors repository on GitHub: https://github.com/google-gemini/genai-processorsWe look forward to seeing what you create!AcknowledgmentsGenAI Processors is the result of the dedication and hard work of a fantastic team. We'd like to acknowledge the following individuals who played a key role in bringing this library to life: Juliette Love, KP Sawhney, Antoine He, Will Thompson, Arno Eigenwillig, Ke Wang, Parth Kothari, Tim Blyth, Philipp Schmid, Patrick Löber, Omar Sanseviero, Alexey Kolganov, Adam Langley, Evan Senter, Seth Odoom, Thierry Coppey, and Murat Ozturk.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/GenAI-processor-meta.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"aobfm\"\u003eBuilding sophisticated AI applications with Large Language Models (LLMs), especially those handling multimodal input and requiring real-time responsiveness, often feels like assembling a complex puzzle: you\u0026#39;re stitching together diverse data processing steps, asynchronous API calls, and custom logic. As complexity grows, this can lead to brittle, hard-to-maintain code.\u003c/p\u003e\u003cp data-block-key=\"aivdi\"\u003eToday, we\u0026#39;re introducing GenAI Processors, a new open-source Python library from Google DeepMind designed to bring structure and simplicity to these challenges. GenAI Processors provides an abstraction layer, defining a consistent \u003ccode\u003eProcessor\u003c/code\u003e interface for everything from input handling and pre-processing to model calls and output processing.\u003c/p\u003e\u003cp data-block-key=\"603d6\"\u003eAt its core, GenAI Processors treat all input and output as asynchronous streams of \u003ccode\u003eProcessorParts\u003c/code\u003e (i.e. two-way aka bidirectional streaming). Think of it as standardized data parts (e.g., a chunk of audio, a text transcription, an image frame) flowing through your pipeline along with associated metadata. This stream-based API allows for seamless chaining and composition of different operations, from low-level data manipulation to high-level model calls.\u003c/p\u003e\n\u003c/div\u003e   \n\n\n    \n    \u003cdiv\u003e\n            \n                \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_kBE2xzY.original.png\" alt=\"GenAI Processors library\"/\u003e\u003c/p\u003e\u003cp\u003e\n                        The GenAI Processors library is designed to optimize the concurrent execution of a Processor. Any part in this example of execution flow can be generated concurrently when all its ancestors in the graph are computed, e.g. `c\u0026#39;12` can be generated concurrently to `a’1`. The flow maintains the ordering of the output stream with respect to the input stream and will be executed to minimize Time To First Token (prefer `a12` to `d12` whenever possible). This concurrency optimization is done under the hood: applying a Processor to a stream of input will automatically trigger this concurrent execution whenever possible.\n                    \u003c/p\u003e\n                \n            \n        \u003c/div\u003e\n  \u003cp data-block-key=\"aobfm\"\u003eFor example, you can easily build a \u0026#34;Live Agent\u0026#34; capable of processing audio and video streams in real-time using the Gemini Live API with just a few lines of code. In the following example, notice how input sources and processing steps are combined using the \u003ccode\u003e+\u003c/code\u003e operator, creating a clear data flow (\u003ca href=\"https://github.com/google-gemini/genai-processors/blob/main/examples/live_simple_cli.py\"\u003efull code on GitHub\u003c/a\u003e):\u003c/p\u003e  \u003cdiv\u003e\n    \u003cpre\u003e\u003ccode\u003efrom genai_processors.core import audio_io, live_model, video\n\n# Input processor: combines camera streams and audio streams\ninput_processor = video.VideoIn() + audio_io.PyAudioIn(...)\n\n# Output processor: plays the audio parts. Handles interruptions and pauses\n# audio output when the user is speaking.\nplay_output = audio_io.PyAudioOut(...)\n\n# Gemini Live API processor\nlive_processor = live_model.LiveProcessor(...)\n\n# Compose the agent: mic+camera -\u0026gt; Gemini Live API -\u0026gt; play audio\nlive_processor = live_model.LiveProcessor(...)\nlive_agent = input_processor + live_processor + play_output\n\nasync for part in live_agent(streams.endless_stream()):\n  # Process the output parts (e.g., print transcription, model output, metadata)\n  print(part)\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003e\n        Python\n    \u003c/p\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n    \n    \n\u003c/div\u003e  \u003cp data-block-key=\"aobfm\"\u003eYou can also build your own Live agent, leveraging a standard text-based LLM, using the bidirectional streaming capability of the GenAI Processor library and the Google Speech API (\u003ca href=\"https://github.com/google-gemini/genai-processors/blob/main/examples/realtime_simple_cli.py\"\u003efull code on GitHub\u003c/a\u003e):\u003c/p\u003e  \u003cdiv\u003e\n    \u003cpre\u003e\u003ccode\u003efrom genai_processors.core import genai_model, realtime, speech_to_text, text_to_speech\n\n# Input processor: gets input from audio in (mic) and transcribes into text\ninput_processor = audio_io.PyAudioIn(...) + speech_to_text.SpeechToText(... )\nplay_output = audio_io.PyAudioOut(...)\n\n# Main model that will be used to generate the response.\ngenai_processor = genai_model.GenaiModel(...),\n\n# TTS processor that will be used to convert the text response to audio. Note\n# the rate limit audio processor that will be used to stream back small audio\n# chunks to the client at the same rate as how they are played back.  \ntts = text_to_speech.TextToSpeech(...) + rate_limit_audio.RateLimitAudio(...)\n\n\n# Creates an agent as:\n# mic -\u0026gt; speech to text -\u0026gt; text conversation -\u0026gt; text to speech -\u0026gt; play audio\nlive_agent = (\n     input_processor\n     + realtime.LiveModelProcessor(turn_processor=genai_processor + tts)\n     + play_output\n )\nasync for part in live_agent(streams.endless_stream()):\n     …\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003e\n        Python\n    \u003c/p\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"aobfm\"\u003eWe anticipate a growing need for proactive LLM applications where responsiveness is critical. Even for non-streaming use cases, processing data as soon as it is available can significantly reduce latency and time to first token (TTFT), which is essential for building a good user experience. While many LLM APIs prioritize synchronous, simplified interfaces, GenAI Processors – by leveraging native Python features – offer a way for writing responsive applications without making code more complex. \u003ca href=\"https://github.com/google-gemini/genai-processors/blob/main/examples/trip_request_cli.py\"\u003eTrip planner and Research Agent\u003c/a\u003e examples demonstrate how turn-based agents can use the concurrency feature of GenAI Processors to increase responsiveness.\u003c/p\u003e\u003ch2 data-block-key=\"g0i26\" id=\"core-design-principles\"\u003e\u003cbr/\u003eCore design principles\u003c/h2\u003e\u003cp data-block-key=\"io4b\"\u003eAt the heart of GenAI Processors is the concept of a \u003ccode\u003eProcessor\u003c/code\u003e: a fundamental building block that encapsulates a specific unit of work. It takes a stream of inputs, performs an operation, and outputs a stream of results. This simple, consistent API is a cornerstone of the library\u0026#39;s power and flexibility.\u003c/p\u003e\u003cp data-block-key=\"3or42\"\u003eHere\u0026#39;s a look at the core design decisions and their benefits for developers:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"c6jha\"\u003e\u003cb\u003eModular design:\u003c/b\u003e Break down complex workflows into self-contained \u003ccode\u003eProcessor\u003c/code\u003e units. This ensures code reusability, testability, and significantly simplifies maintaining intricate pipelines.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"4mg5u\"\u003e\u003cb\u003eAsynchronous \u0026amp; concurrent:\u003c/b\u003e Fully leverages Python\u0026#39;s \u003ccode\u003easyncio\u003c/code\u003e for efficient handling of I/O-bound and compute-bound tasks. This enables responsive applications without manual threading or complex concurrency management.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"2i7hj\"\u003e\u003cb\u003eIntegrated with Gemini API:\u003c/b\u003e Dedicated processors like \u003ccode\u003eGenaiModel\u003c/code\u003e (for turn-based interaction) and \u003ccode\u003eLiveProcessor\u003c/code\u003e (for real-time streaming) simplify interaction with the \u003ca href=\"https://ai.google.dev/\"\u003eGemini API\u003c/a\u003e, including the complexities of the Live API. This reduces boilerplate and accelerates integration.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"373o2\"\u003e\u003cb\u003eExtensible:\u003c/b\u003e Easily create custom processors by inheriting from base classes or using decorators. Integrate your own data processing logic, external APIs, or specialized operations seamlessly into your pipelines.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"2g6d8\"\u003e\u003cb\u003eUnified multimodal handling:\u003c/b\u003e The \u003ccode\u003eProcessorPart\u003c/code\u003e wrapper provides a consistent interface for handling diverse data types (text, images, audio, JSON, etc.) within the pipeline.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"9ts3p\"\u003e\u003cb\u003eStream manipulation utilities:\u003c/b\u003e Built-in utilities for splitting, concatenating, and merging asynchronous streams. This provides fine-grained control over data flow within complex pipelines.\u003c/li\u003e\u003c/ul\u003e\u003ch2 data-block-key=\"x5m8u\" id=\"getting-started\"\u003e\u003cbr/\u003eGetting started\u003c/h2\u003e\u003cp data-block-key=\"ae2o1\"\u003eGetting started with GenAI Processors is straightforward. You can install it with pip:\u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cpre\u003e\u003ccode\u003epip install genai-processors\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003e\n        Python\n    \u003c/p\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"iupu0\"\u003eTo help you get familiar with the library, we provide a series of \u003ca href=\"https://github.com/google-gemini/genai-processors/tree/main/notebooks\"\u003eColab notebooks\u003c/a\u003e that walk you through the core concepts and demonstrate how to build various types of processors and applications. We recommend starting with the \u003ca href=\"https://colab.research.google.com/github/google-gemini/genai-processors/blob/main/notebooks/content_api_intro.ipynb\"\u003eContent API Colab\u003c/a\u003e and \u003ca href=\"https://colab.research.google.com/github/google-gemini/genai-processors/blob/main/notebooks/processor_intro.ipynb\"\u003eProcessor Intro Colab\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"k93t\"\u003eYou can also explore the \u003ca href=\"https://github.com/google-gemini/genai-processors/blob/main/examples\"\u003eexamples/\u003c/a\u003e directory in the repository for practical demonstrations of how to build more complex applications, such as a research agent and a live commentary agent.\u003c/p\u003e\u003ch2 data-block-key=\"hqt1i\" id=\"looking-ahead\"\u003e\u003cbr/\u003eLooking ahead\u003c/h2\u003e\u003cp data-block-key=\"51hek\"\u003eGenAI Processors is currently in its early stages, and we believe it provides a solid foundation for tackling complex workflow and orchestration challenges in AI applications. While the Google GenAI SDK is available in multiple languages, GenAI Processors currently only support Python.\u003c/p\u003e\u003cp data-block-key=\"cncnq\"\u003eThe \u003ca href=\"https://github.com/google-gemini/genai-processors/tree/main/genai_processors/core\"\u003ecore/\u003c/a\u003e directory contains fundamental processors, and we actively encourage community contributions for more specialized functionalities in the \u003ca href=\"https://github.com/google-gemini/genai-processors/tree/main/genai_processors/contrib\"\u003econtrib/\u003c/a\u003e directory. We\u0026#39;re excited to collaborate with the developer community to expand the library and build even more sophisticated AI systems.\u003c/p\u003e\u003cp data-block-key=\"98soq\"\u003eReady to build more robust and responsive Gemini applications?\u003c/p\u003e\u003cp data-block-key=\"fp43p\"\u003eCheck out the GenAI Processors repository on GitHub: \u003ca href=\"https://github.com/google-gemini/genai-processors\"\u003ehttps://github.com/google-gemini/genai-processors\u003c/a\u003e\u003c/p\u003e\u003cp data-block-key=\"7kihi\"\u003eWe look forward to seeing what you create!\u003c/p\u003e\u003chr/\u003e\u003ch3 data-block-key=\"tjd2z\" id=\"acknowledgments\"\u003e\u003cb\u003eAcknowledgments\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"ds27f\"\u003e\u003csup\u003eGenAI Processors is the result of the dedication and hard work of a fantastic team. We\u0026#39;d like to acknowledge the following individuals who played a key role in bringing this library to life: Juliette Love, KP Sawhney, Antoine He, Will Thompson, Arno Eigenwillig, Ke Wang, Parth Kothari, Tim Blyth, Philipp Schmid, Patrick Löber, Omar Sanseviero, Alexey Kolganov, Adam Langley, Evan Senter, Seth Odoom, Thierry Coppey, and Murat Ozturk.\u003c/sup\u003e\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-07-10T00:00:00Z",
  "modifiedTime": null
}
