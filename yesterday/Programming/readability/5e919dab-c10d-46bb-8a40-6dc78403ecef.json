{
  "id": "5e919dab-c10d-46bb-8a40-6dc78403ecef",
  "title": "xAI Unveils a New API Service for Grok Models",
  "link": "https://www.infoq.com/news/2024/11/xai-grok-api/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Elon Musk’s xAI has launched a public beta for its API service, enabling developers to integrate xAI's large language models (LLMs) into their applications. By Daniel Dominguez",
  "author": "Daniel Dominguez",
  "published": "Tue, 05 Nov 2024 22:59:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Artificial Intelligence",
    "OpenAI",
    "API",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Daniel Dominguez",
  "length": 2360,
  "excerpt": "Elon Musk’s xAI has launched a public beta for its API service, enabling developers to integrate xAI's large language models (LLMs) into their applications.",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20241105073656/apple-touch-icon.png",
  "text": "Elon Musk’s xAI has launched a public beta for its API service, enabling developers to integrate xAI's large language models (LLMs) into their applications. Musk announced the service's availability on X, stating: The @xAI API is now live! The xAI API, similar to those offered by OpenAI and Anthropic, provides access to xAI's Grok models via the xAI Console. Currently, only the Grok-beta model is available, while Grok-2 and Grok-2 mini are expected to be accessible soon. Grok models can generate and understand text, code, and images. The xAI Console serves as a centralized hub for developers, offering tools for API key creation, team management, billing, model comparison, usage tracking, and access to API documentation. Notably, xAI's inference servers support multiple regions, and the backend system is developed in Rust. However, during the beta phase, the service is limited to the us-east region. In terms of pricing, the xAI API differs from OpenAI's models. According to the API portal, Grok-2 and Grok-2 mini are priced higher than OpenAI's GPT-4o and GPT-4o mini. The Grok-beta can handle 131,072 tokens for both input and output, while OpenAI's GPT-4o supports 1 million tokens. Grok-beta costs $5 for 131,072 input tokens, compared to GPT-4o's $2.50 for 1 million. For output, Grok-beta charges $15 for its limited token count, while GPT-4o costs $10 for 1 million tokens. Additionally, OpenAI provides Batch API pricing that is at least 50% cheaper than standard API requests. Developer Ofer Mendelevitch, expressed their enthusiasm on the X platform: Congrats on the @xai API being live. Grok-beta shows a 4.6% hallucination rate on @vectara hallucination leaderboard While Software Developer Aleksandr Vasilenko, shared in Reddit: xAI API is expensive and the console is very slow. Also there is no playground on the console, you need to interact with the API directly by making API calls yourself. Other notable features of the xAI API include the ability to integrate with OpenAI and Anthropic SDKs using JavaScript and Python. Developers can also implement xAI APIs in their applications via REST, gRPC, or the xAI Python SDK, as detailed in the documentation. About the Author Daniel Dominguez",
  "image": "https://res.infoq.com/news/2024/11/xai-grok-api/en/headerimage/generatedHeaderImage-1730653473726.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eElon Musk’s \u003ca href=\"https://x.ai/\"\u003exAI\u003c/a\u003e has launched a public beta for its API service, enabling developers to integrate xAI\u0026#39;s large language models (LLMs) into their applications.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://x.com/elonmusk/status/1848398370219364385\"\u003eMusk\u003c/a\u003e announced the service\u0026#39;s availability on \u003ca href=\"https://x.com/elonmusk/status/1848398370219364385\"\u003eX\u003c/a\u003e, stating:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe @xAI API is now live!\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://docs.x.ai/docs\"\u003exAI API\u003c/a\u003e, similar to those offered by OpenAI and Anthropic, provides access to \u003ca href=\"https://huggingface.co/xai-org\"\u003exAI\u0026#39;s Grok\u003c/a\u003e models via the xAI Console. Currently, only the Grok-beta model is available, while Grok-2 and Grok-2 mini are expected to be accessible soon. \u003ca href=\"https://huggingface.co/xai-org\"\u003eGrok models\u003c/a\u003e can generate and understand text, code, and images.\u003c/p\u003e\n\n\u003cp\u003eThe xAI Console serves as a centralized hub for developers, offering tools for API key creation, team management, billing, model comparison, usage tracking, and access to API documentation. Notably, \u003ca href=\"https://github.com/xai-org/grok-1/discussions/234\"\u003exAI\u0026#39;s inference\u003c/a\u003e servers support multiple regions, and the backend system is developed in Rust. However, during the beta phase, the service is limited to the us-east region.\u003c/p\u003e\n\n\u003cp\u003eIn terms of pricing, the xAI API differs from OpenAI\u0026#39;s models. According to the \u003ca href=\"https://openai.com/api/pricing/\"\u003eAPI portal\u003c/a\u003e, Grok-2 and Grok-2 mini are priced higher than OpenAI\u0026#39;s GPT-4o and GPT-4o mini. The Grok-beta can handle 131,072 tokens for both input and output, while OpenAI\u0026#39;s GPT-4o supports 1 million tokens. Grok-beta costs $5 for 131,072 input tokens, compared to GPT-4o\u0026#39;s $2.50 for 1 million. For output, Grok-beta charges $15 for its limited token count, while GPT-4o costs $10 for 1 million tokens. Additionally, OpenAI provides Batch API pricing that is at least 50% cheaper than standard API requests.\u003c/p\u003e\n\n\u003cp\u003eDeveloper \u003ca href=\"https://x.com/ofermend/status/1849579384598036695\"\u003eOfer Mendelevitch\u003c/a\u003e, expressed their enthusiasm on the \u003ca href=\"https://x.com/ofermend/status/1849579384598036695\"\u003eX\u003c/a\u003e platform:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eCongrats on the @xai API being live. Grok-beta shows a 4.6% hallucination rate on @vectara hallucination leaderboard\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhile Software Developer \u003ca href=\"https://www.reddit.com/r/singularity/comments/1g8v8f4/comment/lt1e6fm/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003eAleksandr Vasilenko\u003c/a\u003e, shared in \u003ca href=\"https://www.reddit.com/r/singularity/comments/1g8v8f4/comment/lt1e6fm/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003eReddit\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003exAI API is expensive and the console is very slow. Also there is no playground on the console, you need to interact with the API directly by making API calls yourself.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eOther notable features of the xAI API include the ability to integrate with \u003ca href=\"https://platform.openai.com/docs/libraries\"\u003eOpenAI\u003c/a\u003e and \u003ca href=\"https://docs.anthropic.com/en/api/client-sdks\"\u003eAnthropic\u003c/a\u003e SDKs using JavaScript and Python. Developers can also implement xAI APIs in their applications via REST, gRPC, or the xAI Python SDK, as detailed in the documentation.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Daniel-Dominguez\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eDaniel Dominguez\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2024-11-05T00:00:00Z",
  "modifiedTime": null
}
