{
  "id": "f61ce626-58a0-4fed-b12a-9b315f77d1df",
  "title": "Finding leaked passwords with AI: How we built Copilot secret scanning",
  "link": "https://github.blog/engineering/platform-security/finding-leaked-passwords-with-ai-how-we-built-copilot-secret-scanning/",
  "description": "Passwords are notoriously difficult to detect with conventional programming approaches. AI can help us find passwords better because it understands context. This blog post will explore the technical challenges we faced with building the feature and the novel and creative ways we solved them. The post Finding leaked passwords with AI: How we built Copilot secret scanning appeared first on The GitHub Blog.",
  "author": "Ashwin Mohan",
  "published": "Tue, 04 Mar 2025 17:00:24 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "Engineering",
    "Platform security",
    "GitHub Advanced Security",
    "GitHub Copilot",
    "Secret Scanning"
  ],
  "byline": "Ashwin Mohan, Courtney Claessens",
  "length": 11992,
  "excerpt": "Passwords are notoriously difficult to detect with conventional programming approaches. AI can help us find passwords better because it understands context.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "In October 2024, we announced the general availability of Copilot secret scanning, leveraging AI to detect generic passwords in users’ codebases. This post describes how Copilot secret scanning works under the hood, the challenges we ran into when developing it, and the framework we use for testing and iteration. What is Copilot secret scanning? Copilot secret scanning is a feature of GitHub Secret Protection, which protects millions of repositories on GitHub by detecting hundreds of pattern types through our partner program. The precision of these detections is paramount for security teams and developers when dealing with security alerts. Historically, our detection approach has relied on regular expressions, which is an effective method for identifying secrets with strict, provider-minted formats. However, this method struggles with the nuanced and varied structures of generic passwords, often generating excessive noise for security teams and developers. We now detect generic passwords with GitHub Copilot, using AI to analyze context—such as the usage and location of a potential secret—to limit noise and deliver relevant alerts that are critical to the health and security of your repositories. Getting to the point where we were confident in our password precision was a journey over many test cases, prompt iterations, and model changes. Let’s dive in to explore what we learned along the way and find out where we’re going. The private preview highlighted a problem early on: unconventional file types and structures At the core of Copilot secret scanning lies a request to a large language model (LLM), expressed through an LLM prompt consisting of: General information about the type of vulnerability, in this case passwords. The source code location and contents of the file where we believe the vulnerability may exist. A strict JSON format specification for the model output, to allow for automated processing. Our first iteration of the prompt used the few-shot prompting technique, which provides the LLM with example inputs and outputs to demonstrate how to perform the task. We wanted a resource-effective model to run the detections at scale and landed on GPT-3.5-Turbo. In parallel, we developed a basic offline evaluation framework, including manually curated test cases with both positive and negative findings, to help us validate that our approach was sound before deploying it to customers. We deployed this first iteration to our private preview participants and immediately noticed a problem. While it worked reasonably well at identifying credentials in our offline evaluation, it would fail spectacularly in some customer repositories. The model had difficulty interpreting file types and structures not typically seen in the conventional coding languages and patterns that LLMs train on. This experience revealed the complexity of the problem and the limiting nature of LLMs. We had to reevaluate our approach. The road to public preview: Improving offline evaluation and prompting In response to these initial results, we enhanced the offline evaluation framework in a few key ways. First, we added reports from private preview participants to increase the diversity of our test cases. Next, we enhanced the framework so that we could visually identify and analyze deviations resulting from model or prompt changes. This allowed us to better see the impact of customizing different steps in our prompting strategy. Finally, we leveraged the GitHub Code Security team’s evaluation processes to create a data collection pipeline, and used GPT-4 to create our own test cases based on learnings from existing secret scanning alerts in open source repositories. This improved offline evaluation and gave us the breadth needed to measure both precision and recall. Precision is the ability to find secrets more accurately, with concerns to the false positive rate, while recall is the ability to find secrets more reliably, with concerns to the false negative rate. Walber, CC BY-SA 4.0, via Wikimedia Commons From here, we ran a series of experiments to evaluate detection quality: What if we tried a different model? What if we ran the prompt multiple times and somehow combined the responses? What if we ran two different prompts on two different models in sequence? How do we better handle the nondeterministic nature of LLM responses? More specifically, we started experimenting with a few different mechanisms to improve our detection with the LLM. We tried voting (asking the model the same question many times), which allowed for more deterministic responses but had no material impact on our precision. We also tried using a larger model (GPT-4) trained on a larger set of parameters as a confirming scanner, to validate the accuracy of candidates found by GPT-3.5-Turbo. This helped improve precision without reducing our recall, but was also more resource intensive. We also tried a few different prompting strategies, such as Fill-in-the-Middle, Zero-Shot, and Chain-of-Thought. We ended up collaborating with our colleagues at Microsoft and used their MetaReflection technique, a novel offline reinforcement learning technique that allows experiential learnings from past trials to come up with a hybrid Chain of Thought (CoT) and few-shot prompt that improves precision with a small penalty in recall. We ultimately ended up using a combination of all these techniques and moved Copilot secret scanning into public preview, opening it widely to all GitHub Secret Protection customers. This brings us to our next hurdle: scale. Scaling out capacity for a public preview Secret scanning not only scans incoming Git pushes, but also your entire Git history on all branches. With each new customer, the necessary resources increase linearly. Rather than simply expanding LLM capacity, we focused on striking the most effective balance between value and cost to ensure optimal performance and efficiency. Before tackling how we managed the resources, we tried to find ways to reduce resource usage itself by: Identifying and excluding a class of changes from scanning (such as media files or language files that contain “test,” “mock,” or “spec” in the filepath), because we expected they would never contain credentials or they would be incomprehensible to the model. Experimenting with newer models, such as GPT-4-Turbo and GPT-4o-mini, that were expected to be less resource intensive without compromising on performance and latency. Experimenting with different context windows to find one that reduced resources without significantly increasing latency for the LLM to respond to our queries. Making improvements to how we tokenize the content we want to scan, including retaining some memory of previous tokenizations while processing new parts of a file. While some of these efforts proved fruitful, such as limiting the content we scanned, other efforts were less effective. For example, breaking down content into smaller pieces didn’t have much of an impact, while using a more powerful model did. Ultimately, the most impactful change came from creating a workload-aware request management system that allowed us to maximize and equitably share LLM capacity against the variety of different workloads we run during scans. In building the system, we noticed a fundamental problem that needed addressing in our capacity management: assigning specific rate limits to individual workloads (such as scanning incoming Git commits or scanning the full history) was suboptimal. As each workload was tied to specific traffic patterns—Git commits, for example, tend to correlate with working hours, while full history scanning correlates with discrete events like a security manager or administrator enabling the feature on a new organization—it was easy to land in a situation where an individual workload could run into rate limits within its operational context, leaving additional resources available elsewhere unused. We drew significant inspiration from existing solutions in this space, such as Doorman, GitHub’s own Freno, and various other weighted, fair-priority, queue-related algorithms. We came up with an algorithm that allows us to set a range of limits for each workload, preventing the workload from completely overwhelming the LLM, while allowing it to tap into resources from other workloads going unused at the moment. This strategy was so effective at maximizing utilization that we ended up using it within Copilot Autofix and security campaigns as well. Mirror testing our way to general availability Achieving confidence in detection quality was crucial for moving Copilot secret scanning to general availability. We implemented a mirror testing framework that ran our prompt and filtering changes against a subset of repositories that participated in our public preview. Rescanning these repositories with our latest improvements allowed us to assess the change in real alert volumes and false positive resolutions, without impacting users. We found a huge drop in detections and false positives with very few missing real passwords. In some cases, we saw a 94% reduction in false positives across organizations! This before-and-after comparison indicated that all the different changes we made during private and public preview led to increased precision without sacrificing recall, and that we were ready to provide a reliable and efficient detection mechanism to all GitHub Secret Protection customers. Lessons for the future Copilot secret scanning is now detecting passwords on nearly 35% of all GitHub Secret Protection repositories. We’re continuing to monitor performance and apply lessons learned as we leverage the tooling we created along the way: A focus on precision: Security and development teams need accurate and actionable alerts without the noise—this is always our primary goal. Including diverse test cases: We continue to incorporate examples based on learnings from customer feedback into our test bed as we refine our detection capabilities. Effective resource management: We always need to balance scalability with performance. Collaborative innovation: Partnering with other GitHub and Microsoft teams helps us push the boundaries of what Copilot can achieve. These learnings are also shared across Copilot Autofix, which continues to expand coverage for code scanning alerts and helps development teams remediate code scanning alerts quickly. Since our general availability launch, enablement for Copilot secret scanning has been included in security configurations, allowing you to control which repositories are detecting secrets across your organizations or enterprise. We’re dedicated to continuous improvement through ongoing monitoring, mirror testing, and approach refinement based on customer feedback and detection trends. Copilot secret scanning serves as a critical component for robust application security and will evolve to meet the dynamic needs of our users. Copilot secret scanning is a feature of GitHub Secret Protection, which offers enterprise-ready solutions for preventing accidental secret exposure in your repositories. GitHub Secret Protection is available to purchase starting April 1, 2025. Tags: GitHub Advanced Security GitHub Copilot Secret Scanning Explore more from GitHub Docs Everything you need to master GitHub, all in one place. Go to Docs GitHub Build what’s next on GitHub, the place for anyone from anywhere to build anything. Start building Customer stories Meet the companies and engineering teams that build with GitHub. Learn more Work at GitHub! Check out our current job openings. Apply now",
  "image": "https://github.blog/wp-content/uploads/2023/10/Security-DarkMode-3.png?fit=1200%2C630",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003eIn October 2024, we announced the \u003ca href=\"https://github.blog/changelog/2024-10-21-copilot-secret-scanning-for-generic-passwords-is-generally-available/\"\u003egeneral availability of Copilot secret scanning\u003c/a\u003e, leveraging AI to detect generic passwords in users’ codebases. This post describes how Copilot secret scanning works under the hood, the challenges we ran into when developing it, and the framework we use for testing and iteration.\u003c/p\u003e\n\u003ch2 id=\"what-is-copilot-secret-scanning\" id=\"what-is-copilot-secret-scanning\"\u003eWhat is Copilot secret scanning?\u003ca href=\"#what-is-copilot-secret-scanning\" aria-label=\"What is Copilot secret scanning?\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eCopilot secret scanning is a feature of \u003ca href=\"https://resources.github.com/evolving-github-advanced-security\"\u003eGitHub Secret Protection\u003c/a\u003e, which protects millions of repositories on GitHub by detecting hundreds of pattern types through \u003ca href=\"https://docs.github.com/en/code-security/secret-scanning/secret-scanning-partnership-program/secret-scanning-partner-program\"\u003eour partner program\u003c/a\u003e. The precision of these detections is paramount for security teams and developers when dealing with security alerts. Historically, our detection approach has relied on regular expressions, which is an effective method for identifying secrets with strict, provider-minted formats. However, this method struggles with the nuanced and varied structures of generic passwords, often generating excessive noise for security teams and developers.\u003c/p\u003e\n\u003cp\u003eWe now detect generic passwords with GitHub Copilot, using AI to analyze context—such as the usage and location of a potential secret—to limit noise and deliver relevant alerts that are critical to the health and security of your repositories.\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/03/password.png?resize=1024%2C691\" alt=\"A secret scanning alert for a password detected by Copilot secret scanning.\" width=\"1024\" height=\"691\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/03/password.png?w=1600 1600w, https://github.blog/wp-content/uploads/2025/03/password.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/password.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/password.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/password.png?w=1536 1536w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/p\u003e\n\u003cp\u003eGetting to the point where we were confident in our password precision was a journey over many test cases, prompt iterations, and model changes. Let’s dive in to explore what we learned along the way and find out where we’re going.\u003c/p\u003e\n\u003ch2 id=\"the-private-preview-highlighted-a-problem-early-on-unconventional-file-types-and-structures\" id=\"the-private-preview-highlighted-a-problem-early-on-unconventional-file-types-and-structures\"\u003eThe private preview highlighted a problem early on: unconventional file types and structures\u003ca href=\"#the-private-preview-highlighted-a-problem-early-on-unconventional-file-types-and-structures\" aria-label=\"The private preview highlighted a problem early on: unconventional file types and structures\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAt the core of Copilot secret scanning lies a request to a large language model (LLM), expressed through an LLM prompt consisting of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGeneral information about the type of vulnerability, in this case passwords.  \u003c/li\u003e\n\u003cli\u003eThe source code location and contents of the file where we believe the vulnerability may exist.  \u003c/li\u003e\n\u003cli\u003eA strict JSON format specification for the model output, to allow for automated processing.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOur first iteration of the prompt used the few-shot prompting technique, which provides the LLM with example inputs and outputs to demonstrate how to perform the task. We wanted a resource-effective model to run the detections at scale and landed on GPT-3.5-Turbo. In parallel, we developed a basic offline evaluation framework, including manually curated test cases with both positive and negative findings, to help us validate that our approach was sound before deploying it to customers.\u003c/p\u003e\n\u003cp\u003eWe deployed this first iteration to our private preview participants and immediately noticed a problem. While it worked reasonably well at identifying credentials in our offline evaluation, it would fail spectacularly in some customer repositories. The model had difficulty interpreting file types and structures not typically seen in the conventional coding languages and patterns that LLMs train on.\u003c/p\u003e\n\u003cp\u003eThis experience revealed the complexity of the problem and the limiting nature of LLMs. We had to reevaluate our approach.\u003c/p\u003e\n\u003ch2 id=\"the-road-to-public-preview-improving-offline-evaluation-and-prompting\" id=\"the-road-to-public-preview-improving-offline-evaluation-and-prompting\"\u003eThe road to public preview: Improving offline evaluation and prompting\u003ca href=\"#the-road-to-public-preview-improving-offline-evaluation-and-prompting\" aria-label=\"The road to public preview: Improving offline evaluation and prompting\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn response to these initial results, we enhanced the offline evaluation framework in a few key ways. First, we added reports from private preview participants to increase the diversity of our test cases. Next, we enhanced the framework so that we could visually identify and analyze deviations resulting from model or prompt changes. This allowed us to better see the impact of customizing different steps in our prompting strategy. Finally, we leveraged the GitHub Code Security team’s \u003ca href=\"https://github.blog/engineering/platform-security/fixing-security-vulnerabilities-with-ai/#evaluation-and-iteration\"\u003eevaluation processes\u003c/a\u003e to create a data collection pipeline, and used GPT-4 to create our own test cases based on learnings from existing secret scanning alerts in open source repositories.\u003c/p\u003e\n\u003cp\u003eThis improved offline evaluation and gave us the breadth needed to measure both precision and recall. Precision is the ability to find secrets more accurately, with concerns to the false positive rate, while recall is the ability to find secrets more reliably, with concerns to the false negative rate.\u003c/p\u003e\n\u003cfigure id=\"attachment_82981\"\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" width=\"422\" height=\"768\" src=\"https://github.blog/wp-content/uploads/2025/03/positives.png?resize=422%2C768\" alt=\"A diagram illustrating the difference between precision and recall.\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/03/positives.png?w=422 422w, https://github.blog/wp-content/uploads/2025/03/positives.png?w=165 165w\" sizes=\"auto, (max-width: 422px) 100vw, 422px\"/\u003e\u003cfigcaption\u003e\u003ca href=\"https://commons.wikimedia.org/wiki/File:Precisionrecall.svg\"\u003eWalber\u003c/a\u003e, \u003ca href=\"https://creativecommons.org/licenses/by-sa/4.0\"\u003eCC BY-SA 4.0\u003c/a\u003e, via Wikimedia Commons\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003eFrom here, we ran a series of experiments to evaluate detection quality:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat if we tried a different model?  \u003c/li\u003e\n\u003cli\u003eWhat if we ran the prompt multiple times and somehow combined the responses?   \u003c/li\u003e\n\u003cli\u003eWhat if we ran two different prompts on two different models in sequence?  \u003c/li\u003e\n\u003cli\u003eHow do we better handle the nondeterministic nature of LLM responses?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMore specifically, we started experimenting with a few different mechanisms to improve our detection with the LLM.\u003c/p\u003e\n\u003cp\u003eWe tried voting (asking the model the same question many times), which allowed for more deterministic responses but had no material impact on our precision.\u003c/p\u003e\n\u003cp\u003eWe also tried using a larger model (GPT-4) trained on a larger set of parameters as a confirming scanner, to validate the accuracy of candidates found by GPT-3.5-Turbo. This helped improve precision without reducing our recall, but was also more resource intensive.\u003c/p\u003e\n\u003cp\u003eWe also tried a few different prompting strategies, such as Fill-in-the-Middle, Zero-Shot, and Chain-of-Thought. We ended up collaborating with our colleagues at Microsoft and used \u003ca href=\"https://www.microsoft.com/en-us/research/publication/metareflection-learning-instructions-for-language-agents-using-past-reflections/\"\u003etheir MetaReflection technique\u003c/a\u003e, a novel offline reinforcement learning technique that allows experiential learnings from past trials to come up with a hybrid Chain of Thought (CoT) and few-shot prompt that improves precision with a small penalty in recall.\u003c/p\u003e\n\u003cp\u003eWe ultimately ended up using a combination of all these techniques and moved Copilot secret scanning into public preview, opening it widely to all GitHub Secret Protection customers. This brings us to our next hurdle: scale.\u003c/p\u003e\n\u003ch2 id=\"scaling-out-capacity-for-a-public-preview\" id=\"scaling-out-capacity-for-a-public-preview\"\u003eScaling out capacity for a public preview\u003ca href=\"#scaling-out-capacity-for-a-public-preview\" aria-label=\"Scaling out capacity for a public preview\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eSecret scanning not only scans incoming Git pushes, but also your entire Git history on all branches. With each new customer, the necessary resources increase linearly. Rather than simply expanding LLM capacity, we focused on striking the most effective balance between value and cost to ensure optimal performance and efficiency. Before tackling how we managed the resources, we tried to find ways to reduce resource usage itself by:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIdentifying and excluding a class of changes from scanning (such as media files or language files that contain “test,” “mock,” or “spec” in the filepath), because we expected they would never contain credentials or they would be incomprehensible to the model.  \u003c/li\u003e\n\u003cli\u003eExperimenting with newer models, such as GPT-4-Turbo and GPT-4o-mini, that were expected to be less resource intensive without compromising on performance and latency.   \u003c/li\u003e\n\u003cli\u003eExperimenting with different context windows to find one that reduced resources without significantly increasing latency for the LLM to respond to our queries.   \u003c/li\u003e\n\u003cli\u003eMaking improvements to how we tokenize the content we want to scan, including retaining some memory of previous tokenizations while processing new parts of a file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhile some of these efforts proved fruitful, such as limiting the content we scanned, other efforts were less effective. For example, breaking down content into smaller pieces didn’t have much of an impact, while using a more powerful model did.\u003c/p\u003e\n\u003cp\u003eUltimately, the most impactful change came from creating a workload-aware request management system that allowed us to maximize and equitably share LLM capacity against the variety of different workloads we run during scans.\u003c/p\u003e\n\u003cp\u003eIn building the system, we noticed a fundamental problem that needed addressing in our capacity management: assigning specific rate limits to individual workloads (such as scanning incoming Git commits or scanning the full history) was suboptimal. As each workload was tied to specific traffic patterns—Git commits, for example, tend to correlate with working hours, while full history scanning correlates with discrete events like a security manager or administrator enabling the feature on a new organization—it was easy to land in a situation where an individual workload could run into rate limits within its operational context, leaving additional resources available elsewhere unused.\u003c/p\u003e\n\u003cp\u003eWe drew significant inspiration from existing solutions in this space, such as \u003ca href=\"https://github.com/youtube/doorman\"\u003eDoorman\u003c/a\u003e, GitHub’s own \u003ca href=\"https://github.com/github/freno\"\u003eFreno\u003c/a\u003e, and various other weighted, fair-priority, queue-related algorithms. We came up with an algorithm that allows us to set a range of limits for each workload, preventing the workload from completely overwhelming the LLM, while allowing it to tap into resources from other workloads going unused at the moment. This strategy was so effective at maximizing utilization that we ended up using it within \u003ca href=\"https://github.blog/changelog/2024-08-14-copilot-autofix-for-codeql-code-scanning-alerts-is-now-generally-available/\"\u003eCopilot Autofix\u003c/a\u003e and \u003ca href=\"https://github.blog/changelog/2024-10-29-security-campaigns-with-copilot-autofix-are-now-in-public-preview/\"\u003esecurity campaigns\u003c/a\u003e as well.\u003c/p\u003e\n\u003ch2 id=\"mirror-testing-our-way-to-general-availability\" id=\"mirror-testing-our-way-to-general-availability\"\u003eMirror testing our way to general availability\u003ca href=\"#mirror-testing-our-way-to-general-availability\" aria-label=\"Mirror testing our way to general availability\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAchieving confidence in detection quality was crucial for moving Copilot secret scanning to general availability. We implemented a mirror testing framework that ran our prompt and filtering changes against a subset of repositories that participated in our public preview. Rescanning these repositories with our latest improvements allowed us to assess the change in real alert volumes and false positive resolutions, without impacting users.\u003c/p\u003e\n\u003cp\u003eWe found a huge drop in detections and false positives with very few missing real passwords. In some cases, we saw a \u003cstrong\u003e94% reduction in false positives across organizations\u003c/strong\u003e! This before-and-after comparison indicated that all the different changes we made during private and public preview led to increased precision without sacrificing recall, and that we were ready to provide a reliable and efficient detection mechanism to all GitHub Secret Protection customers.\u003c/p\u003e\n\u003ch2 id=\"lessons-for-the-future\" id=\"lessons-for-the-future\"\u003eLessons for the future\u003ca href=\"#lessons-for-the-future\" aria-label=\"Lessons for the future\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eCopilot secret scanning is now detecting passwords on nearly 35% of all GitHub Secret Protection repositories. We’re continuing to monitor performance and apply lessons learned as we leverage the tooling we created along the way:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eA focus on precision:\u003c/strong\u003e Security and development teams need accurate and actionable alerts without the noise—this is always our primary goal.  \u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIncluding diverse test cases:\u003c/strong\u003e We continue to incorporate examples based on learnings from customer feedback into our test bed as we refine our detection capabilities.   \u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEffective resource management:\u003c/strong\u003e We always need to balance scalability with performance.   \u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCollaborative innovation:\u003c/strong\u003e Partnering with other GitHub and Microsoft teams helps us push the boundaries of what Copilot can achieve.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese learnings are also shared across Copilot Autofix, which continues to expand coverage for code scanning alerts and helps development teams remediate code scanning alerts quickly.\u003c/p\u003e\n\u003cp\u003eSince our general availability launch, enablement for Copilot secret scanning has been included in security configurations, allowing you to control which repositories are detecting secrets across your organizations or enterprise. We’re dedicated to continuous improvement through ongoing monitoring, mirror testing, and approach refinement based on customer feedback and detection trends. Copilot secret scanning serves as a critical component for robust application security and will evolve to meet the dynamic needs of our users.\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003eCopilot secret scanning is a feature of \u003cstrong\u003e\u003ca href=\"https://github.blog/changelog/2025-03-04-introducing-github-secret-protection-and-github-code-security\"\u003eGitHub Secret Protection\u003c/a\u003e\u003c/strong\u003e, which offers enterprise-ready solutions for preventing accidental secret exposure in your repositories. \u003cstrong\u003eGitHub Secret Protection\u003c/strong\u003e is available to purchase starting April 1, 2025.\u003c/p\u003e\u003c/blockquote\u003e\n\n\t\n\u003csection\u003e\n\t\u003chr/\u003e\n\t\u003cdiv\u003e\n\t\t\u003ch2\u003eTags:\u003c/h2\u003e\n\t\t\u003cul\u003e\n\t\t\t\t\t\t\t\u003cli\u003e\n\t\t\t\t\t\u003ca href=\"https://github.blog/tag/github-advanced-security/\" rel=\"tag\"\u003e\n\t\t\t\t\t\tGitHub Advanced Security\t\t\t\t\t\u003c/a\u003e\n\t\t\t\t\u003c/li\u003e\n\t\t\t\t\t\t\t\u003cli\u003e\n\t\t\t\t\t\u003ca href=\"https://github.blog/tag/github-copilot/\" rel=\"tag\"\u003e\n\t\t\t\t\t\tGitHub Copilot\t\t\t\t\t\u003c/a\u003e\n\t\t\t\t\u003c/li\u003e\n\t\t\t\t\t\t\t\u003cli\u003e\n\t\t\t\t\t\u003ca href=\"https://github.blog/tag/secret-scanning/\" rel=\"tag\"\u003e\n\t\t\t\t\t\tSecret Scanning\t\t\t\t\t\u003c/a\u003e\n\t\t\t\t\u003c/li\u003e\n\t\t\t\t\t\u003c/ul\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\n\t\n\u003c/section\u003e\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tExplore more from GitHub\t\u003c/h2\u003e\n\t\u003cdiv\u003e\n\t\t\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon-Circle.svg\" width=\"44\" height=\"44\" alt=\"Docs\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tDocs\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eEverything you need to master GitHub, all in one place.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Go to Docs; ref_location:bottom recirculation;\" href=\"https://docs.github.com/\" target=\"_blank\" aria-label=\"Go to Docs\"\u003e\n\t\t\t\t\tGo to Docs\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon_95220f.svg\" width=\"44\" height=\"44\" alt=\"GitHub\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tGitHub\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eBuild what’s next on GitHub, the place for anyone from anywhere to build anything.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Start building; ref_location:bottom recirculation;\" href=\"https://github.blog/developer-skills/github/\" target=\"_blank\" aria-label=\"Start building\"\u003e\n\t\t\t\t\tStart building\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 16 16\" fill=\"none\"\u003e\u003cpath fill=\"currentColor\" d=\"M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z\"\u003e\u003c/path\u003e\u003cpath stroke=\"currentColor\" d=\"M1.75 8H11\" stroke-width=\"1.5\" stroke-linecap=\"round\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon_da43dc.svg\" width=\"44\" height=\"44\" alt=\"Customer stories\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tCustomer stories\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eMeet the companies and engineering teams that build with GitHub.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Learn more; ref_location:bottom recirculation;\" href=\"https://github.com/customer-stories\" target=\"_blank\" aria-label=\"Learn more\"\u003e\n\t\t\t\t\tLearn more\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2022/05/careers.svg\" width=\"44\" height=\"44\" alt=\"Work at GitHub!\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tWork at GitHub!\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eCheck out our current job openings.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Apply now; ref_location:bottom recirculation;\" href=\"https://www.github.careers/careers-home\" target=\"_blank\" aria-label=\"Apply now\"\u003e\n\t\t\t\t\tApply now\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\t\u003c/div\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2025-03-04T17:00:24Z",
  "modifiedTime": null
}
