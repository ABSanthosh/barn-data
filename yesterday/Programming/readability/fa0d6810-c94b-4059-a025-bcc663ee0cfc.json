{
  "id": "fa0d6810-c94b-4059-a025-bcc663ee0cfc",
  "title": "OpenAI Introduces GPT‑4.1 Family With Enhanced Performance and Long-Context Support",
  "link": "https://www.infoq.com/news/2025/05/openai-gpt-4-1/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "OpenAI has released a new family of language models—GPT‑4.1, GPT‑4.1 mini, and GPT‑4.1 nano—available via its API. The models improve on GPT‑4o and GPT‑4.5 across several technical benchmarks and introduce support for up to 1 million tokens of context. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Mon, 12 May 2025 17:40:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Benchmark",
    "OpenAI",
    "GPT-4",
    "ChatGPT",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 3118,
  "excerpt": "OpenAI has released a new family of language models—GPT‑4.1, GPT‑4.1 mini, and GPT‑4.1 nano—available via its API. The models improve on GPT‑4o and GPT‑4.5 across several technical benchmarks and intr",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250506220132/apple-touch-icon.png",
  "text": "OpenAI has released a new family of language models—GPT‑4.1, GPT‑4.1 mini, and GPT‑4.1 nano—available via its API. The models improve on GPT‑4o and GPT‑4.5 across several technical benchmarks and introduce support for up to 1 million tokens of context. According to OpenAI, GPT‑4.1 improves coding capabilities, instruction following, and long-context comprehension. On the SWE-bench Verified benchmark, which measures real-world software engineering tasks, GPT‑4.1 achieves 54.6% accuracy. This is a 21-point increase over GPT‑4o (33.2%) and 26.6 points higher than GPT‑4.5. The model also shows a 10.5-point improvement over GPT‑4o on Scale’s MultiChallenge instruction benchmark. Source: OpenAI Blog OpenAI also tested the model’s ability to process extended inputs. All models in the GPT‑4.1 family can handle up to 1 million tokens. Internal evaluations, including OpenAI-MRCR and Graphwalks, indicate that GPT‑4.1 performs reliably across long-context tasks, such as retrieving and reasoning over dispersed information. For example, GPT‑4.1 scored 61.7% on Graphwalks, a benchmark for multi-hop reasoning, compared to 42% for GPT‑4o. Source: OpenAI Blog In addition to the main model, GPT‑4.1 mini offers similar performance at lower latency and cost. OpenAI says it matches or exceeds GPT‑4o on most intelligence evaluations while reducing cost by 83%. GPT‑4.1 nano is the smallest and fastest in the series. It is designed for simpler tasks like classification and autocomplete, but still posts high scores, such as 80.1% on MMLU and 50.3% on GPQA. The company also emphasized improvements in code editing. In Aider’s polyglot benchmark, which tests the ability to generate diffs rather than full-file rewrites, GPT‑4.1 outperforms all previous models, including GPT‑4.5. The model produces fewer unnecessary edits, decreasing from 9% in GPT‑4o to 2% in GPT‑4.1. OpenAI confirmed that GPT‑4.5 Preview will be deprecated on July 14, 2025. The company cited cost and performance improvements in GPT‑4.1 as reasons for the transition. This aligns with speculation in the community about the temporary nature of GPT‑4.5. One Reddit user commented: GPT-4.5 was just a preview, not even a 'public beta.' It was just to see what they were (or are) doing regarding new models. Since it is not an official version, it could be said that GPT-4.5 'never' existed, and that is why the new version is GPT-4.1… During the period in which it was available, OpenAI was collecting data… to make, perhaps, a more capable and not so expensive distilled model, which ended up being GPT-4.1. Pricing has also been adjusted. GPT‑4.1 is around 26% cheaper than GPT‑4o for typical queries. Prompt caching discounts have been raised to 75%, and long-context usage no longer incurs additional charges beyond standard per-token costs. The GPT‑4.1 family is now accessible via the OpenAI API. It is not yet available in ChatGPT, where updates to GPT‑4o are ongoing. About the Author Robert Krzaczyński",
  "image": "https://res.infoq.com/news/2025/05/openai-gpt-4-1/en/headerimage/generatedHeaderImage-1747069893415.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eOpenAI has released a \u003ca href=\"https://openai.com/index/gpt-4-1/\"\u003enew family of language models\u003c/a\u003e—GPT‑4.1, GPT‑4.1 mini, and GPT‑4.1 nano—available via its API. The models improve on GPT‑4o and GPT‑4.5 across several technical benchmarks and introduce support for up to 1 million tokens of context.\u003c/p\u003e\n\n\u003cp\u003eAccording to OpenAI, GPT‑4.1 improves coding capabilities, instruction following, and long-context comprehension. On the \u003ca href=\"https://www.swebench.com/\"\u003eSWE-bench Verified benchmark\u003c/a\u003e, which measures real-world software engineering tasks, GPT‑4.1 achieves 54.6% accuracy. This is a 21-point increase over GPT‑4o (33.2%) and 26.6 points higher than GPT‑4.5. The model also shows a 10.5-point improvement over GPT‑4o on\u003ca href=\"https://scale.com/research/multichallenge\"\u003e Scale’s MultiChallenge instruction benchmark\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003cmeta charset=\"utf-8\"/\u003e\u003cb id=\"docs-internal-guid-7af52c7c-7fff-c670-aa42-bbeec71446ec\"\u003e\u003cimg alt=\"swe-bench verified accuracy\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXco2tkmeQ6pJWiWT4m-0qzv5N6RgrCh_btEmolsyTbYIgZq5_wU2RxvQFmJq2hKmxM3nrfVTkKh7TalRHdYJX9KnOgD7s6wLreqSmDPrzxc51eKNNRqickPmpWgFBo9fwxjKhivEg?key=3jSVEOTs9k_GANIwEy1XoA\" rel=\"share\"/\u003e\u003c/b\u003e\u003cbr/\u003e\n\u003cem\u003eSource: OpenAI Blog\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eOpenAI also tested the model’s ability to process extended inputs. All models in the GPT‑4.1 family can handle up to 1 million tokens. Internal evaluations, including \u003ca href=\"https://huggingface.co/datasets/openai/mrcr\"\u003eOpenAI-MRCR\u003c/a\u003e and \u003ca href=\"https://huggingface.co/datasets/openai/graphwalks\"\u003eGraphwalks\u003c/a\u003e, indicate that GPT‑4.1 performs reliably across long-context tasks, such as retrieving and reasoning over dispersed information. For example, GPT‑4.1 scored 61.7% on Graphwalks, a benchmark for multi-hop reasoning, compared to 42% for GPT‑4o.\u003c/p\u003e\n\n\u003cp\u003e\u003cmeta charset=\"utf-8\"/\u003e\u003cb id=\"docs-internal-guid-c93dbc8f-7fff-e2d4-ccd5-276d08b02e99\"\u003e\u003cimg alt=\"openai-mrcr accuracy \" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdISxzvOu4VqSssWDBfh50fTh4WJKjz3SJHKRxuDhFDLTSHgyIFamdiHOSMGfQQprAff_XclArGNvvxTvnzlxYXY1B6O71WiJUpy0XvecaLvs_Sid2p3GiZfOSkSY6q0sOn3QYu?key=3jSVEOTs9k_GANIwEy1XoA\" rel=\"share\"/\u003e\u003c/b\u003e\u003cbr/\u003e\n\u003cem\u003eSource: OpenAI Blog\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eIn addition to the main model, GPT‑4.1 mini offers similar performance at lower latency and cost. OpenAI says it matches or exceeds GPT‑4o on most intelligence evaluations while reducing cost by 83%. GPT‑4.1 nano is the smallest and fastest in the series. It is designed for simpler tasks like classification and autocomplete, but still posts high scores, such as 80.1% on \u003ca href=\"https://zilliz.com/glossary/mmlu-benchmark\"\u003eMMLU\u003c/a\u003e and 50.3% on \u003ca href=\"https://arxiv.org/abs/2311.12022\"\u003eGPQA\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eThe company also emphasized improvements in code editing. In \u003ca href=\"https://aider.chat/docs/leaderboards/\"\u003eAider’s polyglot benchmark\u003c/a\u003e, which tests the ability to generate diffs rather than full-file rewrites, GPT‑4.1 outperforms all previous models, including GPT‑4.5. The model produces fewer unnecessary edits, decreasing from 9% in GPT‑4o to 2% in GPT‑4.1.\u003c/p\u003e\n\n\u003cp\u003eOpenAI confirmed that \u003ca href=\"https://openai.com/index/introducing-gpt-4-5/\"\u003eGPT‑4.5 Preview\u003c/a\u003e will be deprecated on July 14, 2025. The company cited cost and performance improvements in GPT‑4.1 as reasons for the transition. This aligns with speculation in the community about the temporary nature of GPT‑4.5. One Reddit user \u003ca href=\"https://www.reddit.com/r/OpenAI/comments/1jzbplj/comment/mn5vbmk/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003ecommented\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eGPT-4.5 was just a preview, not even a \u0026#39;public beta.\u0026#39; It was just to see what they were (or are) doing regarding new models. Since it is not an official version, it could be said that GPT-4.5 \u0026#39;never\u0026#39; existed, and that is why the new version is GPT-4.1… During the period in which it was available, OpenAI was collecting data… to make, perhaps, a more capable and not so expensive distilled model, which ended up being GPT-4.1.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cdiv\u003e\u003cp\u003ePricing has also been adjusted. GPT‑4.1 is around 26% cheaper than GPT‑4o for typical queries. Prompt caching discounts have been raised to 75%, and long-context usage no longer incurs additional charges beyond standard per-token costs.\u003c/p\u003e\u003cp\u003e\n\nThe GPT‑4.1 family is now accessible via the OpenAI API. It is not yet available in ChatGPT, where updates to GPT‑4o are ongoing.\u003c/p\u003e\u003c/div\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-05-12T00:00:00Z",
  "modifiedTime": null
}
