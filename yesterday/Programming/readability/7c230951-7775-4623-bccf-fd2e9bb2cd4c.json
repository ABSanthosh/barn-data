{
  "id": "7c230951-7775-4623-bccf-fd2e9bb2cd4c",
  "title": "Adopting Bazel for Web at Scale",
  "link": "https://medium.com/airbnb-engineering/adopting-bazel-for-web-at-scale-a784b2dbe325?source=rss----53c7c27702d5---4",
  "description": "",
  "author": "Sharmila Jesupaul",
  "published": "Tue, 12 Nov 2024 18:22:17 GMT",
  "source": "https://medium.com/feed/airbnb-engineering",
  "categories": [
    "bazel",
    "migration",
    "web",
    "typescript",
    "engineering"
  ],
  "byline": "Sharmila Jesupaul",
  "length": 15006,
  "excerpt": "At Airbnb, we’ve recently adopted Bazel — Google’s open source build tool–as our universal build system across backend, web, and iOS platforms. This post will cover our experience adopting Bazel for…",
  "siteName": "The Airbnb Tech Blog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "How and Why We Migrated Airbnb’s Large-Scale Web Monorepo to BazelBy: Brie Bunge and Sharmila JesupaulIntroductionAt Airbnb, we’ve recently adopted Bazel — Google’s open source build tool–as our universal build system across backend, web, and iOS platforms. This post will cover our experience adopting Bazel for Airbnb’s large-scale (over 11 million lines of code) web monorepo. We’ll share how we prepared the code base, the principles that guided the migration, and the process of migrating selected CI jobs. Our goal is to share information that would have been valuable to us when we embarked on this journey and to contribute to the growing discussion around Bazel for web development.Why did we do this?Historically, we wrote bespoke build scripts and caching logic for various continuous integration (CI) jobs that proved challenging to maintain and consistently reached scaling limits as the repo grew. For example, our linter, ESLint, and TypeScript’s type checking did not support multi-threaded concurrency out-of-the-box. We extended our unit testing tool, Jest, to be the runner for these tools because it had an API to leverage multiple workers.It was not sustainable to continually create workarounds to overcome the inefficiencies of our tooling which did not support concurrency and we were incurring a long-run maintenance cost. To tackle these challenges and to best support our growing codebase, we found that Bazel’s sophistication, parallelism, caching, and performance fulfilled our needs.Additionally, Bazel is language agnostic. This facilitated consolidation onto a single, universal build system across Airbnb and allowed us to share common infrastructure and expertise. Now, an engineer who works on our backend monorepo can switch to the web monorepo and know how to build and test things.Why was this hard?When we began the migration in 2021, there was no publicized industry precedent for integrating Bazel with web at scale outside of Google. Open source tooling didn’t work out-of-the-box, and leveraging remote build execution (RBE) introduced additional challenges. Our web codebase is large and contains many loose files, which led to performance issues when transmitting them to the remote environment. Additionally, we established migration principles that included improving or maintaining overall performance and reducing the impact on developers contributing to the monorepo during the transition. We effectively achieved both of these goals. Read on for more details.Readying the RepositoryWe did some work up front to make the repository Bazel-ready–namely, cycle breaking and automated BUILD.bazel file generation.Cycle BreakingOur monorepo is laid out with projects under a top-level frontend/ directory. To start, we wanted to add BUILD.bazel files to each of the ~1000 top-level frontend directories. However, doing so created cycles in the dependency graph. This is not allowed in Bazel because there needs to be a DAG of build targets. Breaking these often felt like battling a hydra, as removing one cycle spawns more in its place. To accelerate the process, we modeled the problem as finding the minimum feedback arc set (MFAS)¹ to identify the minimal set of edges to remove leaving a DAG. This set presented the least disruption, level of effort, and surfaced pathological edges.Automated BUILD.bazel GenerationWe automatically generate BUILD.bazel files for the following reasons:Most contents are knowable from statically analyzable import / require statements.Automation allowed us to quickly iterate on BUILD.bazel changes as we refined our rule definitions.It would take time for the migration to complete and we didn’t want to ask users to keep these files up-to-date when they weren’t yet gaining value from them.Manually keeping these files up-to-date would constitute an additional Bazel tax, regressing the developer experience.We have a CLI tool called sync-configs that generates dependency-based configurations in the monorepo (e.g., tsconfig.json, project configuration, now BUILD.bazel). It uses jest-haste-map and watchman with a custom version of the dependencyExtractor to determine the file-level dependency graph and part of Gazelle to emit BUILD.bazel files. This CLI tool is similar to Gazelle but also generates additional web specific configuration files such as tsconfig.json files used in TypeScript compilation.CI MigrationWith preparation work complete, we proceeded to migrate CI jobs to Bazel. This was a massive undertaking, so we divided the work into incremental milestones. We audited our CI jobs and chose to migrate the ones that would benefit the most: type checking, linting, and unit testing². To reduce the burden on our developers, we assigned the central Web Platform team the responsibility for porting CI jobs to Bazel. We proceeded one job at a time to deliver incremental value to developers sooner, gain confidence in our approach, focus our efforts, and build momentum. With each job, we ensured that the developer experience was high-quality, that performance improved, CI failures were reproducible locally, and that the tooling Bazel replaced was fully deprecated and removed.Enabling TypeScriptWe started with the TypeScript (TS) CI job. We first tried the open source ts_project rule³. However, it didn’t work well with RBE due to the sheer number of inputs, so we wrote a custom rule to reduce the number and size of the inputs.The biggest source of inputs came from node_modules. Prior to this, the files for each npm package were being uploaded individually. Since Bazel works well with Java, we packaged up a full tar and a TS-specific tar (only containing the *.ts and package.json) for each npm package along the lines of Java JAR files (essentially zips).Another source of inputs came through transitive dependencies. Transitive node_modules and d.ts files in the sandbox were being included because technically they can be needed for subsequent project compilations. For example, suppose project foo depends on bar, and types from bar are exposed in foo’s emit. As a result, project baz which depends on foo would also need bar’s outputs in the sandbox. For long chains of dependencies, this can bloat the inputs significantly with files that aren’t actually needed. TypeScript has a — listFiles flag that tells us which files are part of the compilation. We can package up this limited set of files along with the emitted d.ts files into an output tsc.tar.gz file⁴. With this, targets need only include direct dependencies, rather than all transitive dependencies⁵.Diagram showing how we use tars and the — listFiles flag to prune inputs/outputs of :types targetsThis custom rule unblocked switching to Bazel for TypeScript, as the job was now well under our CI runtime budget.Bar chart showing the speed up from switching to using our custom genruleEnabling ESLintWe migrated the ESLint job next. Bazel works best with actions that are independent and have a narrow set of inputs. Some of our lint rules (e.g., special internal rules, import/export, import/extensions) inspected files outside of the linted file. We restricted our lint rules to those that could operate in isolation as a way of reducing input size and having only to lint directly affected files. This meant moving or deleting lint rules (e.g., those that were made redundant with TypeScript). As a result, we reduced CI times by over 70%.Time series graph showing the runtime speed-up in early May from only running ESLint on directly affected targetsEnabling JestOur next challenge was enabling Jest. This presented unique challenges, as we needed to bring along a much larger set of first and third-party dependencies, and there were more Bazel-specific failures to fix.Worker and Docker CacheWe tarred up dependencies to reduce input size, but extraction was still slow. To address this, we introduced caching. One layer of cache is on the remote worker and another is on the worker’s Docker container, baked into the image at build time. The Docker layer exists to avoid losing our cache when remote workers are auto-scaled. We run a cron job once a week to update the Docker image with the newest set of cached dependencies, striking a balance of keeping them fresh while avoiding image thrashing. For more details, check out this Bazel Community Day talk.Diagram showing symlinked npm dependencies to a Docker cache and worker cacheThis added caching provided us with a ~25% speed up of our Jest unit testing CI job overall and reduced the time to extract our dependencies from 1–3 minutes to 3–7 seconds per target. This implementation required us to enable the NodeJS preserve-symlinks option and patch some of our tools that followed symlinks to their real paths. We extended this caching strategy to our Babel transformation cache, another source of poor performance.Implicit DependenciesNext, we needed to fix Bazel-specific test failures. Most of these were due to missing files. For any inputs not statically analyzable (e.g., referenced as a string without an import, babel plugin string referenced in .babelrc), we added support for a Bazel keep comment (e.g., // bazelKeep: path/to/file) which acts as though the file were imported. The advantages of this approach are:1. It is colocated with the code that uses the dependency,2. BUILD.bazel files don’t need to be manually edited to add/move # keep comments,3. There is no effect on runtime.A small number of tests were unsuitable for Bazel because they required a large view of the repository or a dynamic and implicit set of dependencies. We moved these tests out of our unit testing job to separate CI checks.Preventing BackslidingWith over 20,000 test files and hundreds of people actively working in the same repository, we needed to pursue test fixes such that they would not be undone as product development progressed.Our CI has three types of build queues:1. “Required”, which blocks changes,2. “Optional”, which is non-blocking,3. “Hidden”, which is non-blocking and not shown on PRs.As we fixed tests, we moved them from “hidden” to “required” via a rule attribute. To ensure a single source of truth, tests run in “required” under Bazel were not run under the Jest setup being replaced.# frontend/app/script/__tests__/BUILD.bazeljest_test( name = \"jest_test\", is_required = True, # makes this target a required check on pull requests deps = [ \":source_library\", ],)Example jest_test rule. This signifies that this target will run on the “required” build queue.We wrote a script comparing before and after Bazel to determine migration-readiness, using the metrics of test runtime, code coverage stats, and failure rate. Fortunately, the bulk of tests could be enabled without additional changes, so we enabled these in batches. We divided and conquered the remaining burndown list of failures with the central team, Web Platform, fixing and updating tests in Bazel to avoid putting this burden on our developers. After a grace period, we fully disabled and deleted the non-Bazel Jest infrastructure and removed the is_required param.Local Bazel ExperienceIn tandem with our CI migration, we ensured that developers can run Bazel locally to reproduce and iterate on CI failures. Our migration principles included delivering only what was on par with or superior to the existing developer experience and performance. JavaScript tools have developer-friendly CLI experiences (e.g., watch mode, targeting select files, rich interactivity) and IDE integrations that we wanted to retain. By default, frontend developers can continue using the tools they know and love, and in cases where it is beneficial they can opt into Bazel. Discrepancies between Bazel and non-Bazel are rare and when they do occur, developers have a means of resolving the issue. For example, developers can run a single script, failed-on-pr which will re-run any targets failing CI locally to easily reproduce issues.Annotations on a failing build with scripts to recreate the failures, e.g. yak script jest:failed-on-prWe also do some normalization of platform specific binaries so that we can reuse the cache between Linux and MacOS builds. This speeds up local development and CI jobs by sharing cache between a local developer’s macbook and linux machines in CI. For native npm packages (node-gyp dependencies) we exclude platform-specific files and build the package on the execution machine. The execution machine will be the machine executing the test or build process. We also use “universal binaries” (e.g., for node and zstd), where all platform binaries are included as inputs (so that inputs are consistent no matter which platform the action is run from) and the proper binary is chosen at runtime.ConclusionAdopting Bazel for our core CI jobs yielded significant performance improvements for TypeScript type checking (34% faster), ESLint linting (35% faster), and Jest unit tests (42% faster incremental runs, 29% overall). Moreover, our CI can now better scale as the repo grows.Next, to further improve Bazel performance, we will be focusing on persisting a warm Bazel host across CI runs, taming our build graph, powering CI jobs that do not use Bazel with the Bazel build graph, and potentially exploring SquashFS to further compress and optimize our Bazel sandboxes.We hope that sharing our journey has provided insights for organizations considering a Bazel migration for web.AcknowledgmentsThank you Madison Capps, Meghan Dow, Matt Insler, Janusz Kudelka, Joe Lencioni, Rae Liu, James Robinson, Joel Snyder, Elliott Sprehn, Fanying Ye, and various other internal and external partners who helped bring Bazel to Airbnb.We are also grateful to the broader Bazel community for being welcoming and sharing ideas.****************[1]: This problem is NP-complete, though approximation algorithms have been devised that still guarantee no cycles; we chose the implementation outlined in “Breaking Cycles in Noisy Hierarchies”.[2]: After initial evaluation, we considered migrating web asset bundling as out of scope (though we may revisit this in the future) due to high level of effort, unknowns in the bundler landscape, and neutral return on investment given our recent adoption of Metro, as Metro’s architecture already factors in scalability features (e.g. parallelism, local and remote caching, and incremental builds).[3]: There are newer TS rules that may work well for you here.[4]: We later switched to using zstd instead of gzip because it produces archives that are better compressed and more deterministic, keeping tarballs consistent across different platforms.[5]: While unnecessary files may still be included, it’s a much narrower set (and could be pruned as a further optimization).All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*uMA-yyBcSyRjQBwdQnbDdw.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cdiv\u003e\u003ch2 id=\"dfaa\"\u003eHow and Why We Migrated Airbnb’s Large-Scale Web Monorepo to Bazel\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca rel=\"noopener follow\" href=\"https://medium.com/@sharmila.jesupaul?source=post_page---byline--a784b2dbe325--------------------------------\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Sharmila Jesupaul\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*oSKV94STFMJ-V0q6hJPUVA.png\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/airbnb-engineering?source=post_page---byline--a784b2dbe325--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"The Airbnb Tech Blog\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*MlNQKg-sieBGW5prWoe9HQ.jpeg\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"3dee\"\u003e\u003cstrong\u003eBy:\u003c/strong\u003e \u003ca href=\"https://www.linkedin.com/in/bbunge/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBrie Bunge\u003c/a\u003e and \u003ca href=\"https://www.linkedin.com/in/sharmilajesupaul/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSharmila Jesupaul\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"227d\"\u003eIntroduction\u003c/h2\u003e\u003cp id=\"ab69\"\u003eAt Airbnb, we’ve recently adopted \u003ca href=\"https://bazel.build/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBazel\u003c/a\u003e — Google’s open source build tool–as our universal build system across backend, web, and \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/migrating-our-ios-build-system-from-buck-to-bazel-ddd6f3f25aa3\"\u003eiOS\u003c/a\u003e platforms. This post will cover our experience adopting Bazel for Airbnb’s large-scale (over 11 million lines of code) web monorepo. We’ll share how we prepared the code base, the principles that guided the migration, and the process of migrating selected CI jobs. Our goal is to share information that would have been valuable to us when we embarked on this journey and to contribute to the growing discussion around Bazel for web development.\u003c/p\u003e\u003ch2 id=\"698d\"\u003eWhy did we do this?\u003c/h2\u003e\u003cp id=\"eb0e\"\u003eHistorically, we wrote bespoke build scripts and caching logic for various continuous integration (CI) jobs that proved challenging to maintain and consistently reached scaling limits as the repo grew. For example, our linter, \u003ca href=\"https://eslint.org/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eESLint\u003c/a\u003e, and TypeScript’s type checking did not support multi-threaded concurrency out-of-the-box. We extended our unit testing tool, \u003ca href=\"https://jestjs.io/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJest\u003c/a\u003e, to be the runner for these tools because it had an API to leverage multiple workers.\u003c/p\u003e\u003cp id=\"9ec5\"\u003eIt was not sustainable to continually create workarounds to overcome the inefficiencies of our tooling which did not support concurrency and we were incurring a long-run maintenance cost. To tackle these challenges and to best support our growing codebase, we found that Bazel’s sophistication, parallelism, caching, and performance fulfilled our needs.\u003c/p\u003e\u003cp id=\"c7ba\"\u003eAdditionally, Bazel is language agnostic. This facilitated consolidation onto a single, universal build system across Airbnb and allowed us to share common infrastructure and expertise. Now, an engineer who works on our backend monorepo can switch to the web monorepo and know how to build and test things.\u003c/p\u003e\u003ch2 id=\"7c6e\"\u003eWhy was this hard?\u003c/h2\u003e\u003cp id=\"2081\"\u003eWhen we began the migration in 2021, there was no publicized industry precedent for integrating Bazel with web at scale outside of Google. Open source tooling didn’t work out-of-the-box, and leveraging \u003ca href=\"https://bazel.build/remote/rbe\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eremote build execution\u003c/a\u003e (RBE) introduced additional challenges. Our web codebase is large and contains many loose files, which led to performance issues when transmitting them to the remote environment. Additionally, we established migration principles that included improving or maintaining overall performance and reducing the impact on developers contributing to the monorepo during the transition. We effectively achieved both of these goals. Read on for more details.\u003c/p\u003e\u003ch2 id=\"f50f\"\u003eReadying the Repository\u003c/h2\u003e\u003cp id=\"8d95\"\u003eWe did some work up front to make the repository Bazel-ready–namely, cycle breaking and automated BUILD.bazel file generation.\u003c/p\u003e\u003ch2 id=\"b949\"\u003eCycle Breaking\u003c/h2\u003e\u003cp id=\"18d1\"\u003eOur monorepo is laid out with projects under a top-level frontend/ directory. To start, we wanted to add BUILD.bazel files to each of the ~1000 top-level frontend directories. However, doing so created cycles in the dependency graph. This is not allowed in Bazel because there needs to be a \u003ca href=\"https://en.wikipedia.org/wiki/Directed_acyclic_graph\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDAG\u003c/a\u003e of build targets. Breaking these often felt like battling a hydra, as removing one cycle spawns more in its place. To accelerate the process, we modeled the problem as finding the \u003ca href=\"https://en.wikipedia.org/wiki/Feedback_arc_set\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eminimum feedback arc set (MFAS)\u003c/a\u003e¹ to identify the minimal set of edges to remove leaving a \u003ca href=\"https://en.wikipedia.org/wiki/Directed_acyclic_graph\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDAG\u003c/a\u003e. This set presented the least disruption, level of effort, and surfaced pathological edges.\u003c/p\u003e\u003ch2 id=\"6725\"\u003eAutomated BUILD.bazel Generation\u003c/h2\u003e\u003cp id=\"fd5c\"\u003eWe automatically generate BUILD.bazel files for the following reasons:\u003c/p\u003e\u003col\u003e\u003cli id=\"80c7\"\u003eMost contents are knowable from statically analyzable import / require statements.\u003c/li\u003e\u003cli id=\"915f\"\u003eAutomation allowed us to quickly iterate on BUILD.bazel changes as we refined our rule definitions.\u003c/li\u003e\u003cli id=\"bc18\"\u003eIt would take time for the migration to complete and we didn’t want to ask users to keep these files up-to-date when they weren’t yet gaining value from them.\u003c/li\u003e\u003cli id=\"104c\"\u003eManually keeping these files up-to-date would constitute an additional Bazel tax, regressing the developer experience.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"8ed0\"\u003eWe have a CLI tool called sync-configs that generates dependency-based configurations in the monorepo (e.g., tsconfig.json, project configuration, now BUILD.bazel). It uses \u003ca href=\"https://github.com/jestjs/jest/tree/main/packages/jest-haste-map\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ejest-haste-map\u003c/a\u003e and \u003ca href=\"https://facebook.github.io/watchman/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ewatchman\u003c/a\u003e with a custom version of the \u003ca href=\"https://github.com/jestjs/jest/blob/main/packages/jest-haste-map/src/lib/dependencyExtractor.ts\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edependencyExtractor\u003c/a\u003e to determine the file-level dependency graph and part of \u003ca href=\"https://github.com/bazelbuild/bazel-gazelle\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGazelle\u003c/a\u003e to emit BUILD.bazel files. This CLI tool is similar to \u003ca href=\"https://github.com/bazelbuild/bazel-gazelle\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGazelle\u003c/a\u003e but also generates additional web specific configuration files such as tsconfig.json files used in TypeScript compilation.\u003c/p\u003e\u003ch2 id=\"234e\"\u003eCI Migration\u003c/h2\u003e\u003cp id=\"5b70\"\u003eWith preparation work complete, we proceeded to migrate CI jobs to Bazel. This was a massive undertaking, so we divided the work into incremental milestones. We audited our CI jobs and chose to migrate the ones that would benefit the most: type checking, linting, and unit testing². To reduce the burden on our developers, we assigned the central Web Platform team the responsibility for porting CI jobs to Bazel. We proceeded one job at a time to deliver incremental value to developers sooner, gain confidence in our approach, focus our efforts, and build momentum. With each job, we ensured that the developer experience was high-quality, that performance improved, CI failures were reproducible locally, and that the tooling Bazel replaced was fully deprecated and removed.\u003c/p\u003e\u003ch2 id=\"3986\"\u003eEnabling TypeScript\u003c/h2\u003e\u003cp id=\"a5df\"\u003eWe started with the TypeScript (TS) CI job. We first tried the open source \u003ca href=\"https://github.com/bazelbuild/rules_nodejs/blob/5.x/nodejs/private/ts_project.bzl\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ets_project rule\u003c/a\u003e³. However, it didn’t work well with RBE due to the sheer number of inputs, so we wrote a \u003ca href=\"https://gist.github.com/brieb/8439c7869fa058554c58377fb52a3c84\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecustom rule\u003c/a\u003e to reduce the number and size of the inputs.\u003c/p\u003e\u003cp id=\"6ae1\"\u003eThe biggest source of inputs came from \u003ca href=\"https://a0.muscache.com/im/pictures/airbnb-platform-assets/AirbnbPlatformAssets-Bazel%20blogpost/original/6826576e-79dc-4382-bc37-a62d9be3f597.png\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003enode_modules\u003c/a\u003e. Prior to this, the files for each npm package were being uploaded individually. Since Bazel works well with Java, we packaged up a full tar and a TS-specific tar (only containing the *.ts and package.json) for each npm package along the lines of Java JAR files (essentially zips).\u003c/p\u003e\u003cp id=\"5f2f\"\u003eAnother source of inputs came through transitive dependencies. Transitive node_modules and d.ts files in the sandbox were being included because technically they can be needed for subsequent project compilations. For example, suppose project foo depends on bar, and types from bar are exposed in foo’s emit. As a result, project baz which depends on foo would also need bar’s outputs in the sandbox. For long chains of dependencies, this can bloat the inputs significantly with files that aren’t actually needed. TypeScript has a \u003ca href=\"https://www.typescriptlang.org/tsconfig/#listFiles\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e— listFiles flag\u003c/a\u003e that tells us which files are part of the compilation. We can package up this limited set of files along with the emitted d.ts files into an output tsc.tar.gz file⁴. With this, targets need only include direct dependencies, rather than all transitive dependencies⁵.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eDiagram showing how we use tars and the — listFiles flag to prune inputs/outputs of :types targets\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"e8de\"\u003eThis custom rule unblocked switching to Bazel for TypeScript, as the job was now well under our CI runtime budget.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eBar chart showing the speed up from switching to using our custom genrule\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"74c1\"\u003eEnabling ESLint\u003c/h2\u003e\u003cp id=\"56cc\"\u003eWe migrated the \u003ca href=\"https://eslint.org/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eESLint\u003c/a\u003e job next. Bazel works best with actions that are independent and have a narrow set of inputs. Some of our lint rules (e.g., special internal rules, \u003ca href=\"https://github.com/import-js/eslint-plugin-import/blob/main/docs/rules/export.md\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eimport/export\u003c/a\u003e, \u003ca href=\"https://github.com/import-js/eslint-plugin-import/blob/main/docs/rules/extensions.md\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eimport/extensions\u003c/a\u003e) inspected files outside of the linted file. We restricted our lint rules to those that could operate in isolation as a way of reducing input size and having only to lint directly affected files. This meant moving or deleting lint rules (e.g., those that were made redundant with TypeScript). As a result, we reduced CI times by over 70%.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eTime series graph showing the runtime speed-up in early May from only running ESLint on directly affected targets\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"c4df\"\u003eEnabling Jest\u003c/h2\u003e\u003cp id=\"5a30\"\u003eOur next challenge was enabling \u003ca href=\"https://jestjs.io\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJest\u003c/a\u003e. This presented unique challenges, as we needed to bring along a much larger set of first and third-party dependencies, and there were more Bazel-specific failures to fix.\u003c/p\u003e\u003ch2 id=\"59b6\"\u003eWorker and Docker Cache\u003c/h2\u003e\u003cp id=\"6263\"\u003eWe tarred up dependencies to reduce input size, but extraction was still slow. To address this, we introduced caching. One layer of cache is on the remote worker and another is on the worker’s Docker container, baked into the image at build time. The Docker layer exists to avoid losing our cache when remote workers are auto-scaled. We run a cron job once a week to update the Docker image with the newest set of cached dependencies, striking a balance of keeping them fresh while avoiding image thrashing. For more details, check out \u003ca href=\"https://blog.engflow.com/2023/06/01/bazel-community-day--san-francisco/#taming-node_modules-in-rbe-airbnbs-journey-sharmila-jesupaul-airbnb\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethis Bazel Community Day talk\u003c/a\u003e.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eDiagram showing symlinked npm dependencies to a Docker cache and worker cache\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"dd3c\"\u003eThis added caching provided us with a ~25% speed up of our Jest unit testing CI job overall and reduced the time to extract our dependencies from 1–3 minutes to 3–7 seconds per target. This implementation required us to enable the NodeJS \u003ca href=\"https://nodejs.org/api/cli.html#--preserve-symlinks\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003epreserve-symlinks\u003c/a\u003e option and patch some of our tools that followed symlinks to their real paths. We extended this caching strategy to our \u003ca href=\"https://github.com/jestjs/jest/tree/main/packages/babel-jest\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBabel\u003c/a\u003e transformation cache, another source of poor performance.\u003c/p\u003e\u003ch2 id=\"d47d\"\u003eImplicit Dependencies\u003c/h2\u003e\u003cp id=\"d5ff\"\u003eNext, we needed to fix Bazel-specific test failures. Most of these were due to missing files. For any inputs not statically analyzable (e.g., referenced as a string without an import, babel plugin string referenced in .babelrc), we added support for a Bazel keep comment (e.g., // bazelKeep: path/to/file) which acts as though the file were imported. The advantages of this approach are:\u003c/p\u003e\u003cp id=\"e5ba\"\u003e1. It is colocated with the code that uses the dependency,\u003c/p\u003e\u003cp id=\"55e0\"\u003e2. BUILD.bazel files don’t need to be manually edited to add/move \u003ca href=\"https://github.com/bazelbuild/bazel-gazelle?tab=readme-ov-file#keep-comments\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e# keep comments\u003c/a\u003e,\u003c/p\u003e\u003cp id=\"f6e2\"\u003e3. There is no effect on runtime.\u003c/p\u003e\u003cp id=\"028e\"\u003eA small number of tests were unsuitable for Bazel because they required a large view of the repository or a dynamic and implicit set of dependencies. We moved these tests out of our unit testing job to separate CI checks.\u003c/p\u003e\u003ch2 id=\"3737\"\u003ePreventing Backsliding\u003c/h2\u003e\u003cp id=\"87da\"\u003eWith over 20,000 test files and hundreds of people actively working in the same repository, we needed to pursue test fixes such that they would not be undone as product development progressed.\u003c/p\u003e\u003cp id=\"9301\"\u003eOur CI has three types of build queues:\u003c/p\u003e\u003cp id=\"128e\"\u003e1. “Required”, which blocks changes,\u003c/p\u003e\u003cp id=\"9ed5\"\u003e2. “Optional”, which is non-blocking,\u003c/p\u003e\u003cp id=\"24b8\"\u003e3. “Hidden”, which is non-blocking and not shown on PRs.\u003c/p\u003e\u003cp id=\"d527\"\u003eAs we fixed tests, we moved them from “hidden” to “required” via a rule attribute. To ensure a single source of truth, tests run in “required” under Bazel were not run under the Jest setup being replaced.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"c531\"\u003e# frontend/app/script/__tests__/BUILD.bazel\u003cbr/\u003ejest_test(\u003cbr/\u003e    name = \u0026#34;jest_test\u0026#34;,\u003cbr/\u003e    is_required = True, # makes this target a required check on pull requests \u003cbr/\u003e    deps = [\u003cbr/\u003e        \u0026#34;:source_library\u0026#34;,\u003cbr/\u003e    ],\u003cbr/\u003e)\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"9878\"\u003e\u003cem\u003eExample jest_test rule. This signifies that this target will run on the “required” build queue.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"347e\"\u003eWe wrote a script comparing before and after Bazel to determine migration-readiness, using the metrics of test runtime, code coverage stats, and failure rate. Fortunately, the bulk of tests could be enabled without additional changes, so we enabled these in batches. We divided and conquered the remaining burndown list of failures with the central team, Web Platform, fixing and updating tests in Bazel to avoid putting this burden on our developers. After a grace period, we fully disabled and deleted the non-Bazel Jest infrastructure and removed the is_required param.\u003c/p\u003e\u003ch2 id=\"8272\"\u003eLocal Bazel Experience\u003c/h2\u003e\u003cp id=\"1574\"\u003eIn tandem with our CI migration, we ensured that developers can run Bazel locally to reproduce and iterate on CI failures. Our migration principles included delivering only what was on par with or superior to the existing developer experience and performance. JavaScript tools have developer-friendly CLI experiences (e.g., watch mode, targeting select files, rich interactivity) and IDE integrations that we wanted to retain. By default, frontend developers can continue using the tools they know and love, and in cases where it is beneficial they can opt into Bazel. Discrepancies between Bazel and non-Bazel are rare and when they do occur, developers have a means of resolving the issue. For example, developers can run a single script, failed-on-pr which will re-run any targets failing CI locally to easily reproduce issues.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eAnnotations on a failing build with scripts to recreate the failures, e.g. yak script jest:failed-on-pr\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"3f8f\"\u003eWe also do some normalization of platform specific binaries so that we can reuse the cache between Linux and MacOS builds. This speeds up local development and CI jobs by sharing cache between a local developer’s macbook and linux machines in CI. For native npm packages (\u003ca href=\"https://github.com/nodejs/node-gyp\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003enode-gyp\u003c/a\u003e dependencies) we exclude platform-specific files and build the package on the execution machine. The execution machine will be the machine executing the test or build process. We also use “universal binaries” (e.g., for node and zstd), where all platform binaries are included as inputs (so that inputs are consistent no matter which platform the action is run from) and the proper binary is \u003ca href=\"https://gist.github.com/brieb/3c0fdb614122e928b4546c5d85c97ab3\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003echosen at runtime\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"1f29\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"b136\"\u003eAdopting Bazel for our core CI jobs yielded significant performance improvements for TypeScript type checking (34% faster), ESLint linting (35% faster), and Jest unit tests (42% faster incremental runs, 29% overall). Moreover, our CI can now better scale as the repo grows.\u003c/p\u003e\u003cp id=\"55c4\"\u003eNext, to further improve Bazel performance, we will be focusing on persisting a warm Bazel host across CI runs, taming our build graph, powering CI jobs that do not use Bazel with the Bazel build graph, and potentially exploring \u003ca href=\"https://en.wikipedia.org/wiki/SquashFS\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSquashFS\u003c/a\u003e to further compress and optimize our Bazel sandboxes.\u003c/p\u003e\u003cp id=\"63a9\"\u003eWe hope that sharing our journey has provided insights for organizations considering a Bazel migration for web.\u003c/p\u003e\u003ch2 id=\"9171\"\u003eAcknowledgments\u003c/h2\u003e\u003cp id=\"453a\"\u003eThank you Madison Capps, Meghan Dow, Matt Insler, Janusz Kudelka, Joe Lencioni, Rae Liu, James Robinson, Joel Snyder, Elliott Sprehn, Fanying Ye, and various other internal and external partners who helped bring Bazel to Airbnb.\u003c/p\u003e\u003cp id=\"980b\"\u003eWe are also grateful to the broader Bazel community for being welcoming and sharing ideas.\u003c/p\u003e\u003ch2 id=\"65fa\"\u003e****************\u003c/h2\u003e\u003cp id=\"c4da\"\u003e[1]: This problem is \u003ca href=\"https://en.wikipedia.org/wiki/NP-completeness\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNP-complete\u003c/a\u003e, though approximation algorithms have been devised that still guarantee no cycles; we chose the \u003ca href=\"https://github.com/zhenv5/breaking_cycles_in_noisy_hierarchies\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eimplementation\u003c/a\u003e outlined in “\u003ca href=\"https://dl.acm.org/doi/pdf/10.1145/3091478.3091495\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBreaking Cycles in Noisy Hierarchies\u003c/a\u003e”.\u003c/p\u003e\u003cp id=\"2d1c\"\u003e[2]: After initial evaluation, we considered migrating web asset bundling as out of scope (though we may revisit this in the future) due to high level of effort, unknowns in the bundler landscape, and neutral return on investment given our recent adoption of \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/faster-javascript-builds-with-metro-cfc46d617a1f\"\u003eMetro\u003c/a\u003e, as Metro’s architecture already factors in scalability features (e.g. parallelism, local and remote caching, and incremental builds).\u003c/p\u003e\u003cp id=\"b864\"\u003e[3]: There are newer TS rules that may work well for you \u003ca href=\"https://github.com/aspect-build/rules_ts\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp id=\"3098\"\u003e[4]: We later switched to using \u003ca href=\"https://github.com/facebook/zstd\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ezstd\u003c/a\u003e instead of gzip because it produces archives that are better compressed and more deterministic, keeping tarballs consistent across different platforms.\u003c/p\u003e\u003cp id=\"79f9\"\u003e[5]: While unnecessary files may still be included, it’s a much narrower set (and could be pruned as a further optimization).\u003c/p\u003e\u003cp id=\"a7cd\"\u003e\u003cem\u003eAll product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": "2024-11-12T18:22:17.235Z",
  "modifiedTime": null
}
