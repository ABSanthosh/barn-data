{
  "id": "fd2ab7c2-7d43-4469-9c8f-78a3cbca9f49",
  "title": "Evolving the Responsible Generative AI Toolkit with new tools for every LLM",
  "link": "https://developers.googleblog.com/en/evolving-the-responsible-generative-ai-toolkit-with-new-tools-for-every-llm/",
  "description": "The Responsible Generative AI Toolkit is being expanded with new features to support responsible AI development across all LLMs, including SynthID Text for watermarking.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Ryan Mullins",
  "length": 4570,
  "excerpt": "The Responsible Generative AI Toolkit is being expanded with new features to support responsible AI development across all LLMs, including SynthID Text for watermarking.",
  "siteName": "",
  "favicon": "",
  "text": "Products More Solutions Events Learn Community Developer Program Blog Building AI responsibly is crucial. That's why we created the Responsible GenAI Toolkit, providing resources to design, build, and evaluate open AI models. And we're not stopping there! We're now expanding the toolkit with new features designed to work with any LLMs, whether it's Gemma, Gemini, or any other model. This set of tools and features empower everyone to build AI responsibly, regardless of the model they choose.Here's what's new:SynthID Text: watermarking and detecting AI-generated contentIs it difficult to tell if a text was written by a human or generated by AI? SynthID Text has you covered. This technology allows you to watermark and detect text generated by your GenAI product.How it works: SynthID watermarks and identifies AI-generated content by embedding digital watermarks directly into AI-generated text.Open source for developers: SynthID for text is accessible to all developers through Hugging Face and the Responsible GenAI Toolkit.Learn more:Dive into the full technical details in the Nature paper.Discover how to apply SynthID responsibly on the Responsible GenAI Toolkit website.Explore the SynthID Technology Page for a comprehensive overview of SynthID's capabilities across all modalities.Use it today:A production-grade implementation is available in the Hugging Face Transformers library. Check out the Hugging Face Space for a step-by-step guide to configuring SynthID for your GenAI applications.A reference implementation is also available on GitHub and PyPI, with a Colab Notebook for interactive learning.We invite the open source community to help us expand the reach of SynthID Text across frameworks, based on the implementations above. Reach out on GitHub or Discord with questions.Model Alignment: refine your prompts with LLM assistanceCrafting prompts that effectively enforce your business policies is crucial for generating high-quality outputs.The Model Alignment library helps you refine your prompts with support from LLMs.Provide feedback about how you want your model's outputs to change as a holistic critique or a set of guidelines.Use Gemini or your preferred LLM to transform your feedback into a prompt that aligns your model's behavior with your application’s needs and content policies.Use it today:Experiment with the interactive demo in Colab and see how Gemini can help align and improve prompts for Gemma.Access the library on PyPI.Utilize these methods in Vertex AI Studio with Refine Prompt. Sorry, your browser doesn't support playback for this video Prompt Debugging: streamline LIT deployment on Google CloudDebugging prompts is essential for responsible AI development. We're making it easier and faster with an improved deployment experience for the Learning Interpretability Tool (LIT) on Google Cloud.Efficient, versatile model serving: Leverage LIT's new model server container to deploy any Hugging Face or Keras LLM with support for generation, tokenization, and salience scoring on Cloud Run GPUs.Expanded connectivity from the LIT App: Seamlessly connect to self-hosted models or Gemini via the Vertex API (generation only).Learn more: Explore LIT’s capabilities for responsible model alignment on the Responsible GenAI Toolkit website. We value your feedback!Join the conversation on the Google Developer Community Discord and share your thoughts on these new additions. We're eager to hear from you and continue building a responsible AI future together.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/86.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\n        \n        \n        \n\n        \n\n\t\t\t\t\n        \n\n\n\n\n\u003cdiv top-level-nav=\"\"\u003e\n  \u003cnav aria-label=\"Side menu\"\u003e\n    \n    \u003cdiv\u003e\n        \u003cul\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/products\" data-label=\"Tab: Products\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Products\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003cspan tabindex=\"0\" data-label=\"More Products\"\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    More\n                  \u003c/span\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    \n                  \u003c/span\u003e\n                \u003c/span\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/solutions/catalog\" data-label=\"Tab: Solutions\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Solutions\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/events\" data-label=\"Tab: Events\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Events\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/learn\" data-label=\"Tab: Learn\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Learn\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/community\" data-label=\"Tab: Community\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Community\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/profile/u/me\" data-label=\"Tab: Developer Program\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Developer Program\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.googleblog.com/\" data-label=\"Tab: Blog\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Blog\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/div\u003e\n  \u003c/nav\u003e\n  \u003c/div\u003e\n\n\n\n        \n  \u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"ao3ra\"\u003eBuilding AI responsibly is crucial. That\u0026#39;s why we created the \u003ca href=\"https://ai.google.dev/responsible\"\u003eResponsible GenAI Toolkit\u003c/a\u003e, providing resources to design, build, and evaluate open AI models. And we\u0026#39;re not stopping there! We\u0026#39;re now expanding the toolkit with new features designed to work with any LLMs, whether it\u0026#39;s Gemma, Gemini, or any other model. This set of tools and features empower everyone to build AI responsibly, regardless of the model they choose.\u003c/p\u003e\u003ch3 data-block-key=\"3o2m6\"\u003e\u003cb\u003e\u003cbr/\u003eHere\u0026#39;s what\u0026#39;s new:\u003c/b\u003e\u003c/h3\u003e\u003ch2 data-block-key=\"7u4dp\"\u003e\u003cb\u003eSynthID Text: watermarking and detecting AI-generated content\u003c/b\u003e\u003c/h2\u003e\u003cp data-block-key=\"cu1m1\"\u003eIs it difficult to tell if a text was written by a human or generated by AI? SynthID Text has you covered. This technology allows you to \u003cb\u003ewatermark and detect\u003c/b\u003e text generated by your GenAI product.\u003c/p\u003e\u003cp data-block-key=\"o433\"\u003e\u003cb\u003eHow it works:\u003c/b\u003e SynthID watermarks and identifies AI-generated content by embedding digital watermarks directly into AI-generated text.\u003c/p\u003e\u003cp data-block-key=\"btvia\"\u003e\u003cb\u003eOpen source for developers:\u003c/b\u003e SynthID for text is accessible to all developers through Hugging Face and the Responsible GenAI Toolkit.\u003c/p\u003e\u003ch3 data-block-key=\"eerqi\"\u003e\u003cb\u003e\u003cbr/\u003eLearn more:\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"8618r\"\u003eDive into the full technical details in the \u003ca href=\"https://www.nature.com/articles/s41586-024-08025-4\"\u003e\u003ci\u003eNature\u003c/i\u003e paper\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"5bpj1\"\u003eDiscover how to apply SynthID responsibly on the \u003ca href=\"https://ai.google.dev/responsible/docs/safeguards/synthid\"\u003eResponsible GenAI Toolkit website\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"9g4g8\"\u003eExplore the \u003ca href=\"https://deepmind.google/technologies/synthid/\"\u003eSynthID Technology Page\u003c/a\u003e for a comprehensive overview of SynthID\u0026#39;s capabilities across all modalities.\u003c/li\u003e\u003c/ul\u003e\u003ch3 data-block-key=\"1cfcj\"\u003e\u003cb\u003e\u003cbr/\u003eUse it today:\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"e5se\"\u003eA production-grade implementation is available in the \u003ca href=\"https://huggingface.co/docs/transformers/v4.46.0/en/internal/generation_utils\"\u003eHugging Face Transformers library\u003c/a\u003e. Check out the \u003ca href=\"https://huggingface.co/spaces/google/synthid-text\"\u003eHugging Face Space\u003c/a\u003e for a step-by-step guide to configuring SynthID for your GenAI applications.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"brp14\"\u003eA reference implementation is also available on \u003ca href=\"https://github.com/google-deepmind/synthid-text\"\u003eGitHub\u003c/a\u003e and \u003ca href=\"https://pypi.org/project/synthid-text\"\u003ePyPI\u003c/a\u003e, with a \u003ca href=\"https://colab.research.google.com/github/google-deepmind/synthid-text/blob/main/notebooks/synthid_text_huggingface_integration.ipynb\"\u003eColab Notebook\u003c/a\u003e for interactive learning.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"u00k\"\u003eWe invite the open source community to help us expand the reach of SynthID Text across frameworks, based on the implementations above. Reach out on \u003ca href=\"https://github.com/google-deepmind/synthid-text/discussions\"\u003eGitHub\u003c/a\u003e or \u003ca href=\"https://discord.gg/google-dev-community\"\u003eDiscord\u003c/a\u003e with questions.\u003c/p\u003e\u003ch2 data-block-key=\"f7658\"\u003e\u003cb\u003e\u003cbr/\u003eModel Alignment: refine your prompts with LLM assistance\u003c/b\u003e\u003c/h2\u003e\u003cp data-block-key=\"akklo\"\u003eCrafting prompts that effectively enforce your business policies is crucial for generating high-quality outputs.\u003c/p\u003e\u003cp data-block-key=\"f9qpb\"\u003eThe Model Alignment library helps you \u003cb\u003erefine your prompts\u003c/b\u003e with support from LLMs.\u003c/p\u003e\u003cp data-block-key=\"f2lhk\"\u003e\u003cb\u003eProvide feedback\u003c/b\u003e about how you want your model\u0026#39;s outputs to change as a holistic critique or a set of guidelines.\u003c/p\u003e\u003cp data-block-key=\"alf5a\"\u003eUse Gemini or your preferred LLM to \u003cb\u003etransform your feedback into a prompt\u003c/b\u003e that aligns your model\u0026#39;s behavior with your application’s needs and content policies.\u003c/p\u003e\u003ch3 data-block-key=\"7me0h\"\u003e\u003cb\u003e\u003cbr/\u003eUse it today:\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"98a1k\"\u003eExperiment with the interactive demo in \u003ca href=\"https://colab.research.google.com/github/pair-code/model-alignment/blob/main/notebooks/Gemma_for_Model_Alignment.ipynb\"\u003eColab\u003c/a\u003e and see how Gemini can help align and improve prompts for Gemma.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"3f4c9\"\u003eAccess the library on \u003ca href=\"https://pypi.org/project/model-alignment/\"\u003ePyPI\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"11der\"\u003eUtilize these methods in Vertex AI Studio with \u003ca href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/ai-powered-prompt-writing#refine_prompts\"\u003eRefine Prompt\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-utii8fy__thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/Model-Alignment-Library.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"ao3ra\"\u003e\u003cb\u003ePrompt Debugging: streamline LIT deployment on Google Cloud\u003c/b\u003e\u003c/h2\u003e\u003cp data-block-key=\"5oati\"\u003e\u003ca href=\"https://pair-code.github.io/lit/tutorials/sequence-salience/\"\u003eDebugging prompts\u003c/a\u003e is essential for responsible AI development. We\u0026#39;re making it easier and faster with an improved deployment experience for the \u003ca href=\"https://codelabs.developers.google.com/codelabs/responsible-ai/lit-on-gcp\"\u003eLearning Interpretability Tool (LIT) on Google Cloud\u003c/a\u003e.\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"6lo21\"\u003e\u003cb\u003eEfficient, versatile model serving:\u003c/b\u003e Leverage LIT\u0026#39;s new model server container to deploy any Hugging Face or Keras LLM with support for generation, tokenization, and salience scoring on Cloud Run GPUs.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"1vnga\"\u003e\u003cb\u003eExpanded connectivity from the LIT App:\u003c/b\u003e Seamlessly connect to self-hosted models or Gemini via the Vertex API (generation only).\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"1fmko\"\u003e\u003cb\u003eLearn more:\u003c/b\u003e Explore LIT’s capabilities for responsible model alignment on the \u003ca href=\"https://ai.google.dev/responsible/docs/alignment/lit\"\u003eResponsible GenAI Toolkit website\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_9kmMFvV.original.png\" alt=\"Learning Interpretability Tool (LIT) on Google Cloud.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"ao3ra\"\u003e\u003cb\u003eWe value your feedback!\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"1ij0\"\u003eJoin the conversation on the \u003ca href=\"https://discord.gg/google-dev-community\"\u003eGoogle Developer Community Discord\u003c/a\u003e and share your thoughts on these new additions. We\u0026#39;re eager to hear from you and continue building a responsible AI future together.\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\n\n\n\t\t\t\t\n\t\t\t\t\n\n\n\n\n\n        \n\t\t\t\t\n\n        \n        \n        \n        \n\n        \n\n        \n  \n\n    \n\n\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-10-23T00:00:00Z",
  "modifiedTime": null
}
