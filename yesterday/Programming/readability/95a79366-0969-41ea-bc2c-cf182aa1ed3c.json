{
  "id": "95a79366-0969-41ea-bc2c-cf182aa1ed3c",
  "title": "Batch Mode in the Gemini API: Process more for less",
  "link": "https://developers.googleblog.com/en/scale-your-ai-workloads-batch-mode-gemini-api/",
  "description": "The new batch mode in the Gemini API is designed for high-throughput, non-latency-critical AI workloads, simplifying large jobs by handling scheduling and processing, and making tasks like data analysis, bulk content creation, and model evaluation more cost-effective and scalable, so developers can process large volumes of data efficiently.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Lucia Loher, Vishal Dharmadhikari",
  "length": 4424,
  "excerpt": "The new batch mode in the Gemini API is designed for high-throughput, non-latency-critical AI workloads, simplifying large jobs by handling scheduling and processing, and making tasks like data analysis, bulk content creation, and model evaluation more cost-effective and scalable, so developers can process large volumes of data efficiently.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Products More Solutions Events Learn Community Developer Program Blog Gemini models are now available in Batch ModeToday, we’re excited to introduce a batch mode in the Gemini API, a new asynchronous endpoint designed specifically for high-throughput, non-latency-critical workloads. The Gemini API Batch Mode allows you to submit large jobs, offload the scheduling and processing, and retrieve your results within 24 hours—all at a 50% discount compared to our synchronous APIs.Process more for lessBatch Mode is the perfect tool for any task where you have your data ready upfront and don’t need an immediate response. By separating these large jobs from your real-time traffic, you unlock three key benefits:Cost savings: Batch jobs are priced at 50% less than the standard rate for a given modelHigher throughput: Batch Mode has even higher rate limitsEasy API calls: No need to manage complex client-side queuing or retry logic. Available results are returned within a 24-hour window.A simple workflow for large jobsWe’ve designed the API to be simple and intuitive. You package all your requests into a single file, submit it, and retrieve your results once the job is complete. Here are some ways developers are leveraging Batch Mode for tasks today:Bulk content generation and processing: Specializing in deep video understanding, Reforged Labs uses Gemini 2.5 Pro to analyze and label vast quantities of video ads monthly. Implementing Batch Mode has revolutionized their operations by significantly cutting costs, accelerating client deliverables, and enabling the massive scalability needed for meaningful market insights. Model evaluations: Vals AI benchmarks foundation models on real-world use cases, including legal, finance, tax and healthcare. They’re using Batch Mode to submit large volumes of evaluation queries without being constrained by rate limits. Get started in just a few lines of codeYou can start using Batch Mode today with the Google GenAI Python SDK: # Create a JSONL that contains these lines: # {\"key\": \"request_1\", \"request\": {\"contents\": [{\"parts\": [{\"text\": \"Explain how AI works in a few words\"}]}]}}, # {\"key\": \"request_2\", \"request\": {\"contents\": [{\"parts\": [{\"text\": \"Explain how quantum computing works in a few words\"}]}]}} uploaded_batch_requests = client.files.upload(file=\"batch_requests.json\") batch_job = client.batches.create( model=\"gemini-2.5-flash\", src=uploaded_batch_requests.name, config={ 'display_name': \"batch_job-1\", }, ) print(f\"Created batch job: {batch_job.name}\") # Wait for up to 24 hours if batch_job.state.name == 'JOB_STATE_SUCCEEDED': result_file_name = batch_job.dest.file_name file_content_bytes = client.files.download(file=result_file_name) file_content = file_content_bytes.decode('utf-8') for line in file_content.splitlines(): print(line) Python Copied To learn more, check out the official documentation and pricing pages.Read the documentationCheck the cookbook guideView pricingWe're rolling out Batch Mode for the Gemini API today and tomorrow to all users. This is just the start for batch processing, and we're actively working on expanding its capabilities. Stay tuned for more powerful and flexible options!",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-api-meta.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\n        \n        \n        \n\n        \n\n\t\t\t\t\n        \n\n\n\n\n\u003cdiv top-level-nav=\"\"\u003e\n  \u003cnav aria-label=\"Side menu\"\u003e\n    \n    \u003cdiv\u003e\n        \u003cul\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/products\" data-label=\"Tab: Products\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Products\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003cspan tabindex=\"0\" data-label=\"More Products\"\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    More\n                  \u003c/span\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    \n                  \u003c/span\u003e\n                \u003c/span\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/solutions/catalog\" data-label=\"Tab: Solutions\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Solutions\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/events\" data-label=\"Tab: Events\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Events\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/learn\" data-label=\"Tab: Learn\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Learn\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/community\" data-label=\"Tab: Community\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Community\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/profile/u/me\" data-label=\"Tab: Developer Program\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Developer Program\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.googleblog.com/\" data-label=\"Tab: Blog\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Blog\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/div\u003e\n  \u003c/nav\u003e\n  \u003c/div\u003e\n\n\n\n        \n  \u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003ch2 data-block-key=\"11hqd\" id=\"gemini-models-are-now-available-in-batch-mode\"\u003e\u003cb\u003eGemini models are now available in Batch Mode\u003c/b\u003e\u003c/h2\u003e\u003cp data-block-key=\"fs5gd\"\u003e\u003cbr/\u003eToday, we’re excited to introduce a batch mode in the Gemini API, a new asynchronous endpoint designed specifically for high-throughput, non-latency-critical workloads. The \u003ca href=\"https://ai.google.dev/gemini-api/docs/batch-mode\"\u003eGemini API Batch Mode\u003c/a\u003e allows you to submit large jobs, offload the scheduling and processing, and retrieve your results within 24 hours—all at a \u003cb\u003e50% discount\u003c/b\u003e compared to our synchronous APIs.\u003c/p\u003e\u003ch2 data-block-key=\"tk6g8\" id=\"process-more-for-less\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eProcess more for less\u003c/h2\u003e\u003cp data-block-key=\"cvt5u\"\u003eBatch Mode is the perfect tool for any task where you have your data ready upfront and don’t need an immediate response. By separating these large jobs from your real-time traffic, you unlock three key benefits:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"el71r\"\u003e\u003cb\u003eCost savings:\u003c/b\u003e Batch jobs are priced at 50% less than the standard rate for a given model\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"46go3\"\u003e\u003cb\u003eHigher throughput:\u003c/b\u003e Batch Mode has even higher \u003ca href=\"https://ai.google.dev/gemini-api/docs/rate-limits\"\u003erate limits\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"ce5lq\"\u003e\u003cb\u003eEasy API calls:\u003c/b\u003e No need to manage complex client-side queuing or retry logic. Available results are returned within a 24-hour window.\u003c/li\u003e\u003c/ul\u003e\u003ch2 data-block-key=\"qlyrk\" id=\"a-simple-workflow-for-large-jobs\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eA simple workflow for large jobs\u003c/h2\u003e\u003cp data-block-key=\"1eaf2\"\u003eWe’ve designed the API to be simple and intuitive. You package all your requests into a single file, submit it, and retrieve your results once the job is complete. Here are some ways developers are leveraging Batch Mode for tasks today:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"1d2m2\"\u003e\u003cb\u003eBulk content generation and processing:\u003c/b\u003e Specializing in deep video understanding, \u003ca href=\"https://reforgedlabs.com/\"\u003eReforged Labs\u003c/a\u003e uses Gemini 2.5 Pro to analyze and label vast quantities of video ads monthly. Implementing Batch Mode has revolutionized their operations by significantly cutting costs, accelerating client deliverables, and enabling the massive scalability needed for meaningful market insights.\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\n    \n    \u003cdiv\u003e\n        \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_qhTloW2.original.png\" alt=\"Bulk content generation and processing\"/\u003e\n            \n            \n        \u003c/p\u003e\n    \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cul\u003e\u003cli data-block-key=\"yd7th\"\u003e\u003cb\u003eModel evaluations:\u003c/b\u003e \u003ca href=\"https://www.vals.ai/home\"\u003eVals AI\u003c/a\u003e benchmarks foundation models on real-world use cases, including legal, finance, tax and healthcare. They’re using Batch Mode to submit large volumes of evaluation queries without being constrained by rate limits.\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\n    \n    \u003cdiv\u003e\n        \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_uvTbuTT.original.png\" alt=\"Model evaluations\"/\u003e\n            \n            \n        \u003c/p\u003e\n    \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"qj374\" id=\"get-started-in-just-a-few-lines-of-code\"\u003eGet started in just a few lines of code\u003c/h2\u003e\u003cp data-block-key=\"ac011\"\u003eYou can start using Batch Mode today with the Google GenAI Python SDK:\u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cpre\u003e\u003ccode\u003e# Create a JSONL that contains these lines:\n# {\u0026#34;key\u0026#34;: \u0026#34;request_1\u0026#34;, \u0026#34;request\u0026#34;: {\u0026#34;contents\u0026#34;: [{\u0026#34;parts\u0026#34;: [{\u0026#34;text\u0026#34;: \u0026#34;Explain how AI works in a few words\u0026#34;}]}]}},\n# {\u0026#34;key\u0026#34;: \u0026#34;request_2\u0026#34;, \u0026#34;request\u0026#34;: {\u0026#34;contents\u0026#34;: [{\u0026#34;parts\u0026#34;: [{\u0026#34;text\u0026#34;: \u0026#34;Explain how quantum computing works in a few words\u0026#34;}]}]}}\n\nuploaded_batch_requests = client.files.upload(file=\u0026#34;batch_requests.json\u0026#34;)\n\nbatch_job = client.batches.create(\n    model=\u0026#34;gemini-2.5-flash\u0026#34;,\n    src=uploaded_batch_requests.name,\n    config={\n        \u0026#39;display_name\u0026#39;: \u0026#34;batch_job-1\u0026#34;,\n    },\n)\n\nprint(f\u0026#34;Created batch job: {batch_job.name}\u0026#34;)\n\n# Wait for up to 24 hours\n\nif batch_job.state.name == \u0026#39;JOB_STATE_SUCCEEDED\u0026#39;:\n    result_file_name = batch_job.dest.file_name\n    file_content_bytes = client.files.download(file=result_file_name)\n    file_content = file_content_bytes.decode(\u0026#39;utf-8\u0026#39;)\n\n    for line in file_content.splitlines():\n      print(line)\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003e\n        Python\n    \u003c/p\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"avai1\"\u003eTo learn more, check out the official documentation and pricing pages.\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"4m96u\"\u003e\u003ca href=\"https://ai.google.dev/gemini-api/docs/batch-mode\"\u003e\u003cb\u003eRead the documentation\u003c/b\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"2tvt0\"\u003e\u003ca href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Batch_mode.ipynb\"\u003e\u003cb\u003eCheck the cookbook guide\u003c/b\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"2of9k\"\u003e\u003ca href=\"https://ai.google.dev/pricing\"\u003e\u003cb\u003eView pricing\u003c/b\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"aj762\"\u003e\u003cbr/\u003eWe\u0026#39;re rolling out Batch Mode for the Gemini API today and tomorrow to all users. This is just the start for batch processing, and we\u0026#39;re actively working on expanding its capabilities. Stay tuned for more powerful and flexible options!\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\n\n\n\t\t\t\t\n\t\t\t\t\n\n\n\n\n\n        \n\t\t\t\t\n\n        \n        \n        \n        \n\n        \n\n        \n  \n  \n\n    \n\n\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-07-07T00:00:00Z",
  "modifiedTime": null
}
