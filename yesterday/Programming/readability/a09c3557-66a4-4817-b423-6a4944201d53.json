{
  "id": "a09c3557-66a4-4817-b423-6a4944201d53",
  "title": "Advancing agentic AI development with Firebase Studio",
  "link": "https://developers.googleblog.com/en/advancing-agentic-ai-development-with-firebase-studio/",
  "description": "Updates in Firebase Studio include new Agent modes, foundational support for the Model Context Protocol (MCP), and Gemini CLI integration, all designed to redefine AI-assisted development allow developers to create full-stack applications from a single prompt and integrate powerful AI capabilities directly into their workflow.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Jeanine Banks",
  "length": 5449,
  "excerpt": "Updates in Firebase Studio include new Agent modes, foundational support for the Model Context Protocol (MCP), and Gemini CLI integration, all designed to redefine AI-assisted development allow developers to create full-stack applications from a single prompt and integrate powerful AI capabilities directly into their workflow.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Jeanine Banks Vice President \u0026 General Manager Developer X At Google Cloud Summit London, we shared how Google Cloud is transforming development with AI and unlocking your ability to build the next generation of agentic applications. As part of this, we're excited to announce significant advancements in Firebase Studio, our cloud-based AI workspace where you can create full-stack AI applications, whether you want to use multimodal prompts to generate code or write code directly. These updates–versatile Agent modes, foundational support for the Model Context Protocol (MCP), and Gemini CLI integration–are designed to redefine AI-assisted development and integrate powerful AI capabilities directly into your workflow.Introducing autonomous Agent mode: Your AI partner, defined by youThree distinct modes are available now in Firebase Studio for interacting with Gemini, including a new autonomous Agent mode–whether you want to have a conversation, delegate tasks with step-by-step control or let Gemini work independently on your behalf. You can seamlessly toggle between modes to accelerate development tasks thanks to the deep code understanding and powerful reasoning capabilities of Gemini 2.5. AskThis mode can be used for discussion and planning with Gemini, and is ideal for brainstorming, planning code, and discussing complex problems collaboratively. The ”Ask” mode is purely conversational – no changes will be made to your files. Sorry, your browser doesn't support playback for this video AgentIn this mode, Gemini can propose changes to your app, but you are always in the loop. You must approve any proposed changes in “Agent“ mode before any files are modified. This gives you complete oversight and allows you to easily code review changes before they are integrated into your project. Sorry, your browser doesn't support playback for this video Agent (Auto-run)When you use ”Agent (Auto-run)” mode, Gemini can autonomously reason and generate entire apps or add features to existing apps. For example, it can code changes across multiple files, write tests, fix errors, and refactor components, all from a single prompt. For security, it will always require your permission before deleting files, running terminal commands or using external tools. Sorry, your browser doesn't support playback for this video The Agent modes can leverage personalized guidance from a variety of project-level rule files to ensure Gemini adheres to your specific design patterns and preferences. It automatically detects and loads instructions from files like .idx/airules.md, GEMINI.md or .cursorrules at the project root providing a cohesive and highly customizable experience.Unlocking extensibility with Model Context Protocol (MCP)Alongside these new Agent modes, we're previewing foundational support for the Model Context Protocol (MCP) in Firebase Studio. Now you can add MCP servers to your workspace, extending and personalizing your workflows with Gemini in Firebase. For example, you can use the Firebase MCP server to explore your data in Cloud Firestore using natural language while you are building or debugging your application, or use Context7 to get library specific context for Gemini (i.e. try building app with MediaPipe’s on-device ML). We want to gather your feedback as we further integrate the functionality. Sorry, your browser doesn't support playback for this video Gemini CLI Firebase StudioWe recently launched Gemini CLI, offering you a powerful, free-to-use tool for a wide range of tasks beyond just code, including content generation and research. It is available with generous usage tiers, advanced AI features, integration with Google Search for real-time context, and an open-source architecture for customization and contributions. And we’re excited to share that now Gemini CLI is directly integrated in Firebase Studio.If you spend a significant amount of time in the terminal on tasks like code generation, debugging, executing commands, or managing project files, Gemini CLI provides a seamless, AI-powered experience without the need to switch contexts to a separate chat window.These new updates build on that momentum, extending powerful AI features deeper into Firebase Studio. Sorry, your browser doesn't support playback for this video Real-world impact: Firebase Studio in actionWe’re already seeing so many of you leverage Firebase Studio's AI capabilities to streamline your workflows and speed up your time to release - from creating a procurement platform for the hydrogen economy or empowering people with a personalized fashion stylist to helping Pokémon enthusiasts manage card collections with AI-powered card scanning and identification and bringing architecture to life with striking visualization and human-centered analysis.We’re committed to continuing to ship new features and updates to help you ship professional-quality apps, quickly and easily. Check out these new capabilities in Firebase Studio and share what you build on X and LinkedIn with #FirebaseStudio!",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Firebase-Studio-meta.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \u003csection\u003e\n      \n        \n          \u003cp\u003e\u003ca href=\"https://developers.googleblog.com/en/search/?author=Jeanine+Banks\"\u003eJeanine Banks\u003c/a\u003e\n            \n              \u003cspan\u003eVice President \u0026amp; General Manager\u003c/span\u003e\n            \n            \n              \u003cspan\u003eDeveloper X\u003c/span\u003e\n            \n          \u003c/p\u003e\n        \n\n      \n      \u003c/section\u003e\n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"6egbe\"\u003eAt \u003ca href=\"https://cloudonair.withgoogle.com/events/london-summit-25\"\u003e\u003cb\u003eGoogle Cloud Summit London\u003c/b\u003e\u003c/a\u003e, we shared how Google Cloud is transforming development with AI and unlocking your ability to build the next generation of agentic applications. As part of this, we\u0026#39;re excited to announce significant advancements in \u003ca href=\"https://studio.firebase.google.com/?utm_source=google_for_dev_blog\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY25-Q3-firebasestudio_cloudsummitlondon\u0026amp;utm_content=advancing_agentic_ai_development\u0026amp;utm_term=firebase_studio_marketing\"\u003e\u003cb\u003eFirebase Studio\u003c/b\u003e\u003c/a\u003e, our cloud-based AI workspace where you can create full-stack AI applications, whether you want to \u003cb\u003euse multimodal prompts to generate code or write code directly\u003c/b\u003e. These updates–versatile \u003cb\u003eAgent modes\u003c/b\u003e, foundational support for the \u003cb\u003eModel Context Protocol (MCP),\u003c/b\u003e and\u003cb\u003e Gemini CLI integration\u003c/b\u003e–are designed to redefine AI-assisted development and integrate powerful AI capabilities directly into your workflow.\u003c/p\u003e\u003ch2 data-block-key=\"8c8kz\" id=\"introducing-autonomous-agent-mode:-your-ai-partner-defined-by-you\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eIntroducing autonomous Agent mode: Your AI partner, defined by you\u003c/h2\u003e\u003cp data-block-key=\"ate05\"\u003eThree distinct modes are available now in Firebase Studio for interacting with Gemini, including a new autonomous Agent mode–whether you want to have a conversation, delegate tasks with step-by-step control or let Gemini work independently on your behalf. You can seamlessly toggle between modes to accelerate development tasks thanks to the deep code understanding and powerful reasoning capabilities of \u003ca href=\"https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/\"\u003eGemini 2.5\u003c/a\u003e.\u003c/p\u003e\n\u003c/div\u003e   \n\n\n    \n    \u003cdiv\u003e\n        \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_xvxrYmH.original.png\" alt=\"Agent Mode\"/\u003e\n            \n            \n        \u003c/p\u003e\n    \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"ye3iz\" id=\"ask\"\u003e\u003cb\u003eAsk\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"b8l6v\"\u003eThis mode can be used for discussion and planning with Gemini, and is ideal for brainstorming, planning code, and discussing complex problems collaboratively. The ”\u003cb\u003eAsk\u003c/b\u003e”\u003cb\u003e mode\u003c/b\u003e is purely conversational – no changes will be made to your files.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-_q9d5d4l_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/fs-ask.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"xn2bl\" id=\"agent\"\u003e\u003cb\u003eAgent\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"8lc91\"\u003eIn this mode, Gemini can propose changes to your app, but you are always in the loop. You must approve any proposed changes in “\u003cb\u003eAgent\u003c/b\u003e“ \u003cb\u003emode\u003c/b\u003e before any files are modified. This gives you complete oversight and allows you to easily code review changes before they are integrated into your project.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-iggjzwaq_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/fs-agent_1.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"enwpx\" id=\"agent-(auto-run)\"\u003e\u003cb\u003eAgent (Auto-run)\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"8jbss\"\u003eWhen you use ”\u003cb\u003eAgent (Auto-run)\u003c/b\u003e” \u003cb\u003emode\u003c/b\u003e, Gemini can autonomously reason and generate entire apps or add features to existing apps. For example, it can code changes across multiple files, write tests, fix errors, and refactor components, all from a single prompt. For security, it will always require your permission before deleting files, running terminal commands or using external tools.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-uc9zldbr_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/ai-agent-auto.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"6egbe\"\u003eThe Agent modes can leverage personalized guidance from a variety of project-level rule files to ensure Gemini adheres to your specific design patterns and preferences. It automatically detects and loads instructions from files like \u003ca href=\"https://firebase.google.com/docs/studio/set-up-gemini#create-ai-rules\"\u003e\u003ccode\u003e.idx/airules.md\u003c/code\u003e\u003c/a\u003e, \u003ccode\u003eGEMINI.md\u003c/code\u003e or \u003ccode\u003e.cursorrules\u003c/code\u003e at the project root providing a cohesive and highly customizable experience.\u003c/p\u003e\u003ch2 data-block-key=\"gxce7\" id=\"unlocking-extensibility-with-model-context-protocol-(mcp)\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eUnlocking extensibility with Model Context Protocol (MCP)\u003c/h2\u003e\u003cp data-block-key=\"6d06f\"\u003eAlongside these new Agent modes, we\u0026#39;re previewing \u003ca href=\"https://firebase.google.com/docs/studio/customize-workspace?utm_source=google_for_dev_blog\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY25-Q3-firebasestudio_cloudsummitlondon\u0026amp;utm_content=advancing_agentic_ai_development\u0026amp;utm_term=firebase_studio_marketing#mcp\"\u003efoundational support for the \u003cb\u003eModel Context Protocol (MCP)\u003c/b\u003e\u003c/a\u003e in Firebase Studio. Now you can add MCP servers to your workspace, extending and personalizing your \u003ca href=\"https://firebase.blog/posts/2025/07/supercharge-firebase-studio-with-mcp\"\u003eworkflows with Gemini in Firebase\u003c/a\u003e. For example, you can use the Firebase MCP server to explore your data in Cloud Firestore using natural language while you are building or debugging your application, or use Context7 to get library specific context for Gemini (i.e. try building app with \u003ca href=\"https://context7.com/google-ai-edge/mediapipe/llms.txt?topic=face\"\u003eMediaPipe’s on-device ML\u003c/a\u003e). We want to gather your \u003ca href=\"https://community.firebasestudio.dev/t/mcp-support-in-firebase-studio/16223\"\u003efeedback\u003c/a\u003e as we further integrate the functionality.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-68t8py0m_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/fs-mcp_HSiqpbL.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"mdjfp\" id=\"gemini-cli-firebase-studio\"\u003eGemini CLI Firebase Studio\u003c/h2\u003e\u003cp data-block-key=\"b875v\"\u003eWe recently \u003ca href=\"https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/\"\u003elaunched Gemini CLI\u003c/a\u003e, offering you a powerful, free-to-use tool for a wide range of tasks beyond just code, including content generation and research. It is available with generous usage tiers, advanced AI features, integration with Google Search for real-time context, and an open-source architecture for customization and contributions. And we’re excited to share that now Gemini CLI is directly integrated in Firebase Studio.\u003c/p\u003e\u003cp data-block-key=\"dkgos\"\u003eIf you spend a significant amount of time in the terminal on tasks like code generation, debugging, executing commands, or managing project files, Gemini CLI provides a seamless, AI-powered experience without the need to switch contexts to a separate chat window.\u003c/p\u003e\u003cp data-block-key=\"dokjb\"\u003eThese new updates build on that momentum, extending powerful AI features deeper into Firebase Studio.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-_4vjeqv5_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/fs-gemini-cli.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"rir1o\" id=\"real-world-impact:-firebase-studio-in-action\"\u003eReal-world impact: Firebase Studio in action\u003c/h2\u003e\u003cp data-block-key=\"e516e\"\u003eWe’re already seeing so many of you leverage Firebase Studio\u0026#39;s AI capabilities to streamline your workflows and speed up your time to release - from creating \u003ca href=\"https://www.circularrefining.co.uk/\"\u003ea procurement platform for the hydrogen economy\u003c/a\u003e or empowering people with \u003ca href=\"https://glammeai.web.app/\"\u003ea personalized fashion stylist\u003c/a\u003e to helping Pokémon enthusiasts \u003ca href=\"https://github.com/xavidop/cardex\"\u003emanage card collections with AI-powered card scanning and identification\u003c/a\u003e and bringing architecture to life \u003ca href=\"https://firebase.blog/posts/2025/07/houseid-studio-showcase\"\u003ewith striking visualization and human-centered analysis\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"4s8d5\"\u003eWe’re committed to continuing to ship new features and updates to help \u003ci\u003eyou\u003c/i\u003e ship professional-quality apps, quickly and easily. Check out these new capabilities in Firebase Studio and share what you build on \u003ca href=\"https://x.com/Firebase\"\u003eX\u003c/a\u003e and \u003ca href=\"https://www.linkedin.com/showcase/firebase\"\u003eLinkedIn\u003c/a\u003e with #FirebaseStudio!\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-07-10T00:00:00Z",
  "modifiedTime": null
}
