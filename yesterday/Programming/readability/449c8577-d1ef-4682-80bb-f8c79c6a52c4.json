{
  "id": "449c8577-d1ef-4682-80bb-f8c79c6a52c4",
  "title": "This developer tool is 40 years old: can it be improved?",
  "link": "https://stackoverflow.blog/2024/12/20/this-developer-tool-is-40-years-old-can-it-be-improved/",
  "description": "Would updating a tool few think about make a diff(erence)?",
  "author": "Bill Harding",
  "published": "Fri, 20 Dec 2024 16:29:31 GMT",
  "source": "https://stackoverflow.blog/feed/",
  "categories": [
    "pull-requests",
    "code-review",
    "diff",
    "se-tech",
    "se-stackoverflow"
  ],
  "byline": "Bill Harding",
  "length": 15765,
  "excerpt": "[Ed. note: While we take some time to rest up over the holidays and prepare for next year, we are re-publishing our top ten posts for the year. Please enjoy our favorite work this year and we’ll see you in 2025.]",
  "siteName": "",
  "favicon": "https://stackoverflow.blog/apple-touch-icon.png",
  "text": "[Ed. note: While we take some time to rest up over the holidays and prepare for next year, we are re-publishing our top ten posts for the year. Please enjoy our favorite work this year and we’ll see you in 2025.]In this era of exponential acceleration that AI has brought forth, the average VS Code or Jetbrains developer benefits from a toolkit stacked with modern, state-of-the-art components. From IDEs to extensions to CLIs, if you stop and consider all the tools you use weekly, which would you guess is the oldest? That is, which tool do you interact with regularly (say, an hour per week) that hasn't substantively changed in years?Since IDEs are refreshed every few years, maybe you've guessed that your oldest tool in active use is \"git.\" It was first released nearly 20 years ago, back in 2005. Or maybe you prefer to code with the classic old-school text editors, like Sublime Text (2008) or vim (1991).According to our research at GitClear, the oldest tool most developers are still actively using—more than an hour per week—hasn't changed since before the Berlin Wall came down. In 1986, an unheralded Tucson computer science professor named Eugene Myers published his seminal research paper and the \"Myers Diff Algorithm\" was born. Few developers today know the algorithm by name, but they can recognize the familiar red-and-green byproduct of Myers algorithm, which is the default diff generator of git, and thus, git platforms like GitHub:How did GitHub designate which lines to color red and green? By implementing the formulation of Eugene Myers, who offered what became the canonical solution for representing the difference between the state of a git repo “before” and “after” a developer’s git commit.A path encoding from Myers page 3, which forms the basis for GitHub diffsIs it possible to improve upon this method, or did Professor Myers knock it out of the park? New research we’ve undertaken tests an updated set of \"diff operators\" that extend the usual \"add\" and \"delete\" to include \"move,\" \"update,\" \"find/replace,\" and others. Their goal is to measure whether it's possible to apply a deeper lexicon of diff operators to condense how a commit is represented. Can change be shown more concisely than what was possible nearly 40 years ago?Our work followed tangent lines of investigation: one empirical, one observational. We'll summarize the two sides of the research below. The headline finding should come as welcome news for developers: 30% Less is More: Exploring Strategies to Reduce Pull Request Review Time. The research comes accompanied by examples and videos to substantiate the “30% less code to review in pull requests\" finding.Before we could determine how much time could be saved, we had to establish a baseline: how much time was being spent on code review in the 2020s?According to CodeGrip's 2022 online survey of \"1,000+ CxOs and developers,\" code review is utilized by around 84% of companies. The same survey found that the median developer in 2022 spent two to five hours per week on code review. Thirty percent of respondents report spending more than five hours per week on review. Thus, in a 40-hour work week, more than 10% of the entire week is consumed by code review.Code Review Trends in 2022 - CodegripThe primary correlate of \"code review time\" is \"lines of code to review.\" And the higher an organization’s contributor count rises, the more likely that developers’ burden of \"code to review\" will become 20% or more of their total hours available per week.To understand how GitClear's \"Commit Cruncher\" diff algorithm can generate a more precise diff than Myers, let’s consider a couple specific examples.The Myers diff algorithm classifies all code change lines as binary: either \"add\" or \"delete.\"The Commit Cruncher algorithm tested recognizes three times more types of changed operations: Added, Deleted, Updated, Moved, Find/Replaced, and Copy/Pasted (examples of recognized code operations here). The latter operation (Copy/Paste) featured prominently in GitClear's popular AI Code Quality research from earlier in 2024, which was cited by more than ten developer media sources, including Stack Overflow’s podcast.The extent to which Commit Cruncher reduces lines to read vs. Myers algorithm depends on the content of a given pull request. The more refactoring a pull request includes, the greater the potential savings of “lines to review.” A few examples where Commit Cruncher can express a diff more concisely follow.One example where Myers requires more work by a reviewer is when a code change involves white space, like the change shown earlier in this post:The same diff, through the lens of Commit Cruncher:By recognizing whitespace changes as trivial updates, a diff viewer can focus attention on the subset of lines where meaningful changes occurred.Another example comes from a pull request comparison posted to GitClear’s Youtube channel. It shows a case where a file was renamed and a block of code that had initially been in the body of a React component was extracted to a standalone function. In GitHub’s Myers-based diff presentation, the change is shown as a new, 30+ line, added method:Presentation of a refactored method with Myers diff algorithmThe same diff, processed by Commit Cruncher, is less exciting:Since no change was made to the code itself, only the newly added method definition is highlighted “Less excitement” reviewing pull requests is precisely what the average code reviewer seeks. By eliding the no-op changes to the relocated method, the Commit Cruncher presentation conserves a reviewer’s attention for lines with more substantive content differences.Another line reduction opportunity is presented when lines receive an incremental modification, like this trivial change from a recent React commit:Myers diff presents five lines to review, four of which are incremental updatesThe same diff through a GitClear lens condenses the incremental update to a single line, where the new (or removed) characters are shown inline:Incremental updates expressed more concisely In the GitClear database, containing more than one billion line changes, around 10-15% of those changes are incremental updates like this. These small improvements add up.Commit Cruncher employs another, more subtle difference in how it derives which lines changed compared to Myers. To understand this difference, consider a pull request that includes a set of commits, [A, B, C] being proposed for merge.The Myers diff algorithm works by inspecting two inputs: the repo state before commit A and the state after commit C. The only information that this diff algorithm has available to construct a visual diff is the state of the repo at two points in time. Consider a case where Commit B renames a file, followed by Commit C adding and removing a few lines from the renamed file. A comparison that considers only [A, C] would show on the \"before\" side the pre-rename version of the renamed file as deleted lines. On the \"after\" side, the hundreds or thousands of lines from the renamed file would be presented as if the file had been newly created.In contrast, Commit Cruncher employs the more computationally intensive approach of following each changed line through each commit that it appears within, to build what is labeled a \"Commit Group\":From GitClear Commit Group PDF explainerThere are a few benefits that emerge from doing the added work of traversing each line through its entire commit history.One benefit is that, when hovering on the line, the developer can access a historical record of the commit messages, which often elucidates why a particular line evolved into its final form. From GitClear's video:Another benefit is that, when a line undergoes multiple changes like being moved and having a find/replace applied, Commit Cruncher can still show the reviewer the original location of the multi-updated line. This means less uncertainty about how this line will perform in a production environment (since it was already deployed in the original form).To assess the real-world impact of using the Commit Cruncher diff algorithm vs. classic Myers, GitClear analyzed 12,638 pull requests that it processed during the second half of May 2024. The pull requests’ diffs were processed by GitClear and compared to their GitHub equivalent. The contributing repos were about 25% popular open-source projects (React, VS Code, Chromium, Tensorflow) and roughly 75% SaaS customers who had opted into anonymized data sharing.GitClear used the GitHub API's compare endpoint to capture the count of \"added\" and \"deleted\" lines that GitHub would show for each pull request. It then recorded the count of changed lines per pull request, as derived by Commit Cruncher.Our metric for comparison was the number of green or red highlighted lines in either the classic Myers diff as used on GitHub (and elsewhere) versus the highlighted lines on GitClear (using updated diff algorithm). We lumped add, remove, and others into a single value, as that’s what any code reviewer would see.Here were the 12,638 pull requests, with average and median changed line counts for variously-sized pull requests:The data shows that developers reviewing with GitClear and its \"Commit Cruncher\" algorithm were presented with, on average, 22% to 29% fewer changed lines to review per pull request.The median difference between \"Myers\" and \"Commit Cruncher\" ranges from 27% to 31%, depending on the total magnitude of the change set. This implies that updating git diff processing tools could reduce the volume of lines requiring review by almost a third. A detailed description of the database queries that were used to produce these numbers is offered in the \"Appendix\" section A6.While the raw line counts suggest that Commit Cruncher-processed pull requests will require fewer lines to be reviewed, Lead developers, CTOs, and VPs of engineering may fairly wonder if there are less desirable changes coupled with a new diff processor.To research these questions, 48 developer research participants were recruited randomly from the web platform CodeMentor. Each participant was assigned to review two different pull requests in a programming language familiar to them. Each pair of pull requests alternated which git platform it was shown on. For example, the first participant would review PR #1 on GitHub and PR #2 on GitClear. The second participant would review PR #1 on GitClear and PR #2 on GitHub.The research provides tabular results for these 48 developer interviews, collecting data to evaluate:1) Do reductions in \"lines to review\" actually translate to a corresponding reduction in \"real-world time to review\"?2) Does reviewing pull requests in less time correlate with negative or positive impacts to \"percentage of bugs discovered\"?A study by Bacchelli and Bird that supports the contention that, when reviewing code, most understanding and attention is spent in search of \"Finding Defects\":Developers’ responses in surveys of the amount of code understanding for code review outcomes (Bacchelli and Bird, 2013)Statements from GitClear's survey participants support this interpretation for \"code review motivation\":“The most difficult thing when doing a code review is understanding the reason for the change.”\"Understanding the code takes most of the reviewing time.\"“In a successful code review submission, the author is sure that his peers understand and approve the change.”To shorten the code review process, a tool needs to accelerate the rate at which a developer evolves from \"encountering code\" to \"contextualizing it\" to \"evaluating whether it satisfies the author's goals.\"Our interviews found reductions in each of three pull request programming languages tested:Code Review Duration Aggregated Results GitClear vs GitHubHere's how the aggregated data looks in graph form, with the yellow bars illustrating the absolute difference between the two data points:The most notable difference was for the pull request #25610, with a 42% decrease (13.2 average minutes with GitClear's Commit Cruncher vs. 22.7 minutes with GitHub).GitClear's research found pull request comprehension within the margin of error for GitClear and GitHub reviewers.Question accuracy percentages were less than 5% different. A statistically insignificant benefit was found in favor of Commit Cruncher diffs when evaluated across the entire pool results.The raw data of the evaluation metrics for each individual session was plotted using a scatter chart, comparing question accuracy scores against the code review duration, as seen in the figure below. The code review duration decrease is visually outlined by the increased frequency of blue (GitClear) dots on the left side of the chart.Perhaps the most substantive question that comes to mind while reading this research: how has diff viewing evolved to be more homogenous than any of \"developer IDE,\" \"git platform,\" or \"system OS\"? Compared to the innumerable programming languages that have come and gone in the decades since the Myers algorithm was created, how did so many products converge on a solution developed 40 years ago? We offer two ideas on this puzzler.The first possibility is that most developers don’t even recognize that it’s possible to represent a diff without Myers. Since diffs have looked the same since their career began, nobody thinks to go looking for other options.The second reason is that Myers is a much “cleaner” algorithm than any successor would be. Choosing Myers offers an instantly available, multi-generation-tested means to show a diff. And when it comes to reviewing a diff, getting every line right, every time, is incredibly important.While Commit Cruncher shows significant improvement over Myers in this research, it relies upon a set of iteratively tuned heuristics. None of the large git platforms can afford to imperil user trust as they iterate on a more granular representation of what changed within a commit. Much like all source control providers herded to git once it was proven reliable at enterprise-scale, no single company is likely to evolve their diff tool until they have strong incentives to do so. As future research corroborates that a savings of more than 20% is possible in pull request review time, the current stasis may end.The evidence presented herein raises new questions for the oldest tool still widely used by contemporary developers.The implications of a 28% drop in code review time could be significant. Scale the 2022 CodeGrip code review survey result to a 10-member team and the math works out to about 50 hours per week spent reviewing code. If the combined developer and manager salaries average $150,000, then a 10-developer team invests around $16,000 per month of salary toward code review. This doesn’t include the difficult-to-measure (but familiar to any developer) time needed to context shift into and out of \"code review mode.\"A reduction of the magnitude observed here would mean this 10-developer team could reallocate 40 hours per month for more coding, less reviewing (one hour/week * four weeks/month * 10 developers). Considering that code review is often one of the most unpleasant, high-willpower chores included in a developer's responsibilities, the morale improvement gained by reducing code review time may rival the gains in \"time saved.\"The full text and citations of GitClear's latest research is available to download free: 30% Less is More: Exploring Strategies to Cut Pull Request Review Time. The pull request tool can be trialed at no cost by visiting our Best GitHub Alternative Pull Request Review Tool page, which allows pasting a pull request URL from GitHub to allow a direct, side-by-side comparison of the competing diff algorithms.",
  "image": "https://cdn.stackoverflow.co/images/jo7n4k8s/production/38ad754362725ef6390460beb66d0ac14267f5d3-13396x7384.jpg?w=1200\u0026fm=png\u0026auto=format",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv itemprop=\"articleBody\"\u003e\u003cp\u003e\u003cem\u003e[Ed. note: While we take some time to rest up over the holidays and prepare for next year, we are re-publishing our top ten posts for the year. Please enjoy our favorite work this year and we’ll see you in 2025.]\u003c/em\u003e\u003c/p\u003e\u003cp\u003eIn this era of exponential acceleration that AI has brought forth, the average VS Code or Jetbrains developer benefits from a toolkit stacked with modern, state-of-the-art components. From IDEs to extensions to CLIs, if you stop and consider all the tools you use weekly, which would you guess is the oldest? That is, which tool do you interact with regularly (say, an hour per week) that hasn\u0026#39;t substantively changed in years?\u003c/p\u003e\u003cp\u003eSince IDEs are refreshed every few years, maybe you\u0026#39;ve guessed that your oldest tool in active use is \u0026#34;git.\u0026#34; It was first released nearly 20 years ago, back in 2005. Or maybe you prefer to code with the classic old-school text editors, like Sublime Text (2008) or vim (1991).\u003c/p\u003e\u003cp\u003eAccording to our research at GitClear, the oldest tool most developers are still actively using—\u003cem\u003emore than an hour per week\u003c/em\u003e—\u003cstrong\u003ehasn\u0026#39;t changed since before the Berlin Wall came down\u003c/strong\u003e. In 1986, an unheralded Tucson computer science professor named Eugene Myers \u003ca href=\"http://www.xmailserver.org/diff2.pdf\"\u003epublished his seminal research paper\u003c/a\u003e and the \u0026#34;Myers Diff Algorithm\u0026#34; was born. Few developers today know the algorithm by name, but they can recognize the familiar red-and-green byproduct of Myers algorithm, which is the default diff generator of git, and thus, git platforms like GitHub:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"2024 diff on GitHub; Myers’ work prescribes which color is to be shown as the text background\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/bbaa4ec32d838e102ede59488141481a25ae287d-1600x573.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eHow did GitHub designate which lines to color red and green? By implementing the formulation of Eugene Myers, who offered what became the canonical solution for representing the difference between the state of a git repo “before” and “after” a developer’s git commit.\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"A path encoding from Myers page 3, which forms the basis for GitHub diffs\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/32a1019842f4ca909e45ed958119852999ced3a6-950x986.jpg?auto=format\"/\u003e\u003cfigcaption\u003eA path encoding from Myers page 3, which forms the basis for GitHub diffs\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIs it possible to improve upon this method, or did Professor Myers knock it out of the park? New research we’ve undertaken tests an updated set of \u0026#34;diff operators\u0026#34; that extend the usual \u0026#34;add\u0026#34; and \u0026#34;delete\u0026#34; to include \u0026#34;move,\u0026#34; \u0026#34;update,\u0026#34; \u0026#34;find/replace,\u0026#34; and others. Their goal is to measure whether it\u0026#39;s possible to apply a deeper lexicon of diff operators to condense how a commit is represented. Can change be shown more concisely than what was possible nearly 40 years ago?\u003c/p\u003e\u003cp\u003eOur work followed tangent lines of investigation: one empirical, one observational. We\u0026#39;ll summarize the two sides of the research below. The headline finding should come as welcome news for developers: \u003ca href=\"https://www.gitclear.com/research_studies/pull_request_diff_methods_comparison_faster_review\"\u003e\u003cstrong\u003e30% Less is More: Exploring Strategies to Reduce Pull Request Review Time\u003c/strong\u003e\u003c/a\u003e. The research comes accompanied by \u003ca href=\"https://www.gitclear.com/best_github_alternative_pull_request_review_tool\"\u003eexamples and videos to substantiate the “30% less code to review in pull requests\u003c/a\u003e\u0026#34; finding.\u003c/p\u003e\u003cp\u003eBefore we could determine how much time could be saved, we had to establish a baseline: how much time was being spent on code review in the 2020s?\u003c/p\u003e\u003cp\u003eAccording to \u003ca href=\"https://media.trustradius.com/product-downloadables/DD/D7/XID8MVZTH0JF.pdf\"\u003eCodeGrip\u0026#39;s 2022 online survey\u003c/a\u003e of \u0026#34;1,000+ CxOs and developers,\u0026#34; code review is utilized by around 84% of companies. The same survey found that the median developer in 2022 spent two to five hours per week on code review. Thirty percent of respondents report spending \u003cem\u003emore\u003c/em\u003e than five hours per week on review. Thus, in a 40-hour work week, more than 10% of the entire week is consumed by code review.\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"Graph showing that 50% of developers spend 2-5 hours on code review per week, with 10% spending 5-10 hours and another 10% spending more than 10 hours\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/a40a02587b5752f01c8ffede660611128b5e075e-988x846.jpg?auto=format\"/\u003e\u003cfigcaption\u003eCode Review Trends in 2022 - Codegrip\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe primary correlate of \u0026#34;code review time\u0026#34; is \u0026#34;lines of code to review.\u0026#34; And the higher an organization’s contributor count rises, the more likely that developers’ burden of \u0026#34;code to review\u0026#34; will become 20% or more of their total hours available per week.\u003c/p\u003e\u003cp\u003eTo understand how GitClear\u0026#39;s \u0026#34;Commit Cruncher\u0026#34; diff algorithm can generate a more precise diff than Myers, let’s consider a couple specific examples.\u003c/p\u003e\u003cp\u003eThe Myers diff algorithm classifies all code change lines as binary: either \u0026#34;add\u0026#34; or \u0026#34;delete.\u0026#34;\u003c/p\u003e\u003cp\u003eThe Commit Cruncher algorithm tested recognizes \u003cstrong\u003ethree times more \u003c/strong\u003etypes of changed operations: Added, Deleted, Updated, Moved, Find/Replaced, and Copy/Pasted (examples of \u003ca href=\"https://www.gitclear.com/help/technical/diff_delta_calculation\"\u003erecognized code operations here\u003c/a\u003e). The latter operation (Copy/Paste) featured prominently in GitClear\u0026#39;s \u003ca href=\"https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality\"\u003epopular AI Code Quality research\u003c/a\u003e from earlier in 2024, which was cited by more than ten developer media sources, including Stack Overflow’s \u003ca href=\"https://stackoverflow.blog/2024/03/22/is-ai-making-your-code-worse/\"\u003epodcast\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eThe extent to which Commit Cruncher reduces lines to read vs. Myers algorithm depends on the content of a given pull request. The more refactoring a pull request includes, the greater the potential savings of “lines to review.” A few examples where Commit Cruncher can express a diff more concisely follow.\u003c/p\u003e\u003cp\u003eOne example where Myers requires more work by a reviewer is when a code change involves white space, like the change shown earlier in this post:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"A diff with seven lines highlighted as changed\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/bbaa4ec32d838e102ede59488141481a25ae287d-1600x573.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eThe same diff, through the lens of Commit Cruncher:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"A diff with 2 lines highlighted\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/d3dede5c967a20fab64f0011ab5aa65d8d76dd83-1600x594.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eBy recognizing whitespace changes as trivial updates, a diff viewer can focus attention on the subset of lines where meaningful changes occurred.\u003c/p\u003e\u003cp\u003eAnother example comes from a pull request comparison posted to \u003ca href=\"https://www.youtube.com/watch?v=ZulFo7DijWU\"\u003eGitClear’s Youtube channel\u003c/a\u003e. It shows a case where a file was renamed and a block of code that had initially been in the body of a React component was extracted to a standalone function. In GitHub’s Myers-based diff presentation, the change is shown as a new, 30+ line, added method:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"A diff with a large chunk highlighted as new code\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/03710d07803fd462ae731bf8d5dea02e32421267-1087x1230.jpg?auto=format\"/\u003e\u003cfigcaption\u003ePresentation of a refactored method with Myers diff algorithm\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe same diff, processed by Commit Cruncher, is less exciting:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/cefa89d749d2dc94de98dfa66441803168a36b89-1155x1182.jpg?auto=format\"/\u003e\u003cfigcaption\u003eSince no change was made to the code itself, only the newly added method definition is highlighted\n\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e“Less excitement” reviewing pull requests is precisely what the average code reviewer seeks. By eliding the no-op changes to the relocated method, the Commit Cruncher presentation conserves a reviewer’s attention for lines with more substantive content differences.\u003c/p\u003e\u003cp\u003eAnother line reduction opportunity is presented when lines receive an incremental modification, like this trivial change from a recent React commit:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/beef295664ac464b5632ba7a543c06f02f71847f-848x364.jpg?auto=format\"/\u003e\u003cfigcaption\u003eMyers diff presents five lines to review, four of which are incremental updates\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe same diff through a GitClear lens condenses the incremental update to a single line, where the new (or removed) characters are shown inline:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/e66566139526b25edb1a47de501f193bed99c41a-933x271.jpg?auto=format\"/\u003e\u003cfigcaption\u003eIncremental updates expressed more concisely \n\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn the GitClear database, containing more than one billion line changes, around 10-15% of those changes are incremental updates like this. These small improvements add up.\u003c/p\u003e\u003cp\u003eCommit Cruncher employs another, more subtle difference in how it derives which lines changed compared to Myers. To understand this difference, consider a pull request that includes a set of commits, [A, B, C] being proposed for merge.\u003c/p\u003e\u003cp\u003eThe Myers diff algorithm works by inspecting two inputs: the repo state before commit A and the state after commit C. The only information that this diff algorithm has available to construct a visual diff is the state of the repo at two points in time. Consider a case where Commit B renames a file, followed by Commit C adding and removing a few lines from the renamed file. A comparison that considers only [A, C] would show on the \u0026#34;before\u0026#34; side the pre-rename version of the renamed file as deleted lines. On the \u0026#34;after\u0026#34; side, the hundreds or thousands of lines from the renamed file would be presented as if the file had been newly created.\u003c/p\u003e\u003cp\u003eIn contrast, Commit Cruncher employs the more computationally intensive approach of following each changed line through each commit that it appears within, to build what is labeled a \u0026#34;Commit Group\u0026#34;:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"Describes the diff processes rendered obsolete\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/c894c43c724f6e0b98cbd430f68451e1d09b77e8-1338x733.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eFrom GitClear \u003c/em\u003e\u003ca href=\"https://www.gitclear.com/diff_delta_factors\"\u003e\u003cem\u003eCommit Group PDF explainer\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003eThere are a few benefits that emerge from doing the added work of traversing each line through its entire commit history.\u003c/p\u003e\u003cp\u003eOne benefit is that, when hovering on the line, the developer can access a historical record of the commit messages, which often elucidates why a particular line evolved into its final form. \u003ca href=\"https://youtu.be/ZulFo7DijWU?si=P2eSN4QwB6bf4XvL\u0026amp;t=317\"\u003eFrom GitClear\u0026#39;s video\u003c/a\u003e:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"Hovering on a line processed by Commit Cruncher shows line\u0026#39;s evolution\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/93145329a66648be44f5ab46063a026dd7ad3bc0-1167x486.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eAnother benefit is that, when a line undergoes multiple changes like being moved and having a find/replace applied, Commit Cruncher can still show the reviewer the original location of the multi-updated line. This means less uncertainty about how this line will perform in a production environment (since it was already deployed in the original form).\u003c/p\u003e\u003cp\u003eTo assess the real-world impact of using the Commit Cruncher diff algorithm vs. classic Myers, GitClear analyzed 12,638 pull requests that it processed during the second half of May 2024. The pull requests’ diffs were processed by GitClear and compared to their GitHub equivalent. The contributing repos were about 25% popular open-source projects (\u003ca href=\"https://www.gitclear.com/open_repos/facebook/react/\"\u003eReact\u003c/a\u003e, \u003ca href=\"https://www.gitclear.com/open_repos/Microsoft/vscode/releases\"\u003eVS Code\u003c/a\u003e, \u003ca href=\"https://www.gitclear.com/open_repos/chromium/chromium/releases\"\u003eChromium\u003c/a\u003e, \u003ca href=\"https://www.gitclear.com/open_repos/tensorflow/tensorflow/release/pending_release\"\u003eTensorflow\u003c/a\u003e) and roughly 75% SaaS customers who had opted into anonymized data sharing.\u003c/p\u003e\u003cp\u003eGitClear used the GitHub API\u0026#39;s \u003ca href=\"https://docs.github.com/en/rest/commits/commits?apiVersion=2022-11-28#compare-two-commits\"\u003ecompare endpoint\u003c/a\u003e to capture the count of \u0026#34;added\u0026#34; and \u0026#34;deleted\u0026#34; lines that GitHub would show for each pull request. It then recorded the count of changed lines per pull request, as derived by Commit Cruncher.\u003c/p\u003e\u003cp\u003eOur metric for comparison was the number of green or red highlighted lines in either the classic Myers diff as used on GitHub (and elsewhere) versus the highlighted lines on GitClear (using updated diff algorithm). We lumped add, remove, and others into a single value, as that’s what any code reviewer would see.\u003c/p\u003e\u003cp\u003eHere were the 12,638 pull requests, with \u003cstrong\u003eaverage\u003c/strong\u003e and \u003cstrong\u003emedian \u003c/strong\u003echanged line counts for variously-sized pull requests:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"Commit Cruncher reduces \u0026#34;changed lines to review\u0026#34; across 12,638 pull request samples\n\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/54f6f5a69260d64483d7ff7003e875080d5fc5ae-966x166.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eThe data shows that developers reviewing with GitClear and its \u0026#34;Commit Cruncher\u0026#34; algorithm were presented with, on average, 22% to 29% fewer changed lines to review per pull request.\u003c/p\u003e\u003cp\u003eThe median difference between \u0026#34;Myers\u0026#34; and \u0026#34;Commit Cruncher\u0026#34; ranges from 27% to 31%, depending on the total magnitude of the change set. This implies that updating git diff processing tools could reduce the volume of lines requiring review by almost a third. A detailed description of the database queries that were used to produce these numbers is offered in the \u003ca href=\"https://www.gitclear.com/research_studies/pull_request_diff_methods_comparison_faster_review#A6_-_Database_queries_used\"\u003e\u0026#34;Appendix\u0026#34; section A6\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eWhile the raw line counts suggest that Commit Cruncher-processed pull requests will require fewer lines to be reviewed, Lead developers, CTOs, and VPs of engineering may fairly wonder if there are less desirable changes coupled with a new diff processor.\u003c/p\u003e\u003cp\u003eTo research these questions, 48 developer research participants were recruited randomly from the web platform CodeMentor. Each participant was assigned to review two different pull requests in a programming language familiar to them. Each pair of pull requests alternated which git platform it was shown on. For example, the first participant would review PR #1 on GitHub and PR #2 on GitClear. The second participant would review PR #1 on GitClear and PR #2 on GitHub.\u003c/p\u003e\u003cp\u003eThe research provides tabular results for these 48 developer interviews, collecting data to evaluate:\u003c/p\u003e\u003cp\u003e1) Do reductions in \u0026#34;\u003cstrong\u003elines to review\u003c/strong\u003e\u0026#34; actually translate to a corresponding reduction in \u0026#34;\u003cstrong\u003ereal-world time to review\u003c/strong\u003e\u0026#34;?\u003c/p\u003e\u003cp\u003e2) Does reviewing pull requests in less time correlate with negative or positive impacts to \u0026#34;\u003cstrong\u003epercentage of bugs discovered\u003c/strong\u003e\u0026#34;?\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://sback.it/publications/icse2013.pdf\"\u003eA study by Bacchelli and Bird\u003c/a\u003e that supports the contention that, when reviewing code, most understanding and attention is spent in search of \u0026#34;Finding Defects\u0026#34;:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"Finding defects and alternative solutions require the highest level of understanding of the code\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/04c12fa1b9193d35dd1c4e86bac70e0401033122-876x582.jpg?auto=format\"/\u003e\u003cfigcaption\u003eDevelopers’ responses in surveys of the amount of code understanding for code review outcomes (Bacchelli and Bird, 2013)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eStatements from GitClear\u0026#39;s survey participants support this interpretation for \u0026#34;code review motivation\u0026#34;:\u003c/p\u003e\u003cul\u003e\u003cli\u003e“The most difficult thing when doing a code review is understanding the reason for the change.”\u003c/li\u003e\u003cli\u003e\u0026#34;Understanding the code takes most of the reviewing time.\u0026#34;\u003c/li\u003e\u003cli\u003e“In a successful code review submission, the author is sure that his peers understand and approve the change.”\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo shorten the code review process, a tool needs to accelerate the rate at which a developer evolves from \u0026#34;encountering code\u0026#34; to \u0026#34;contextualizing it\u0026#34; to \u0026#34;evaluating whether it satisfies the author\u0026#39;s goals.\u0026#34;\u003c/p\u003e\u003cp\u003eOur interviews found reductions in each of three pull request programming languages tested:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" alt=\"Median duration percent difference is 36% and the average duration percent difference is 22%\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/506406b5dab5bc426d00b47c90d851224da2dbaa-1310x354.jpg?auto=format\"/\u003e\u003cfigcaption\u003eCode Review Duration Aggregated Results GitClear vs GitHub\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eHere\u0026#39;s how the aggregated data looks in graph form, with the yellow bars illustrating the absolute difference between the two data points:\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/665d5be3e2bfc329b991dc5e87fc57b2bad94d4c-1125x697.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eThe most notable difference was for the pull request #25610, with a 42% decrease (13.2 average minutes with GitClear\u0026#39;s Commit Cruncher vs. 22.7 minutes with GitHub).\u003c/p\u003e\u003cp\u003eGitClear\u0026#39;s research found pull request comprehension within the margin of error for GitClear and GitHub reviewers.\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/fb46714be7667ddc861931ba049841b165869410-1044x646.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eQuestion accuracy percentages were less than 5% different. A statistically insignificant benefit was found in favor of Commit Cruncher diffs when evaluated across the entire pool results.\u003c/p\u003e\u003cp\u003eThe raw data of the evaluation metrics for each individual session was plotted using a scatter chart, comparing question accuracy scores against the code review duration, as seen in the figure below. The code review duration decrease is visually outlined by the increased frequency of blue (GitClear) dots on the left side of the chart.\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/d222e0d2f562192f2cd5c5aa5e606e5ae1f74125-1435x623.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003ePerhaps the most substantive question that comes to mind while reading this research: how has diff viewing evolved to be more homogenous than any of \u0026#34;developer IDE,\u0026#34; \u0026#34;git platform,\u0026#34; or \u0026#34;system OS\u0026#34;? Compared to the innumerable programming languages that have come and gone in the decades since the Myers algorithm was created, how did so many products converge on a solution developed 40 years ago? We offer two ideas on this puzzler.\u003c/p\u003e\u003cp\u003eThe first possibility is that most developers don’t even recognize that it’s \u003cem\u003epossible\u003c/em\u003e to represent a diff without Myers. Since diffs have looked the same since their career began, nobody thinks to go looking for other options.\u003c/p\u003e\u003cp\u003eThe second reason is that Myers is a much “cleaner” algorithm than any successor would be. Choosing Myers offers an instantly available, multi-generation-tested means to show a diff. And when it comes to reviewing a diff, getting every line right, \u003cstrong\u003eevery time\u003c/strong\u003e, is incredibly important.\u003c/p\u003e\u003cp\u003eWhile Commit Cruncher shows significant improvement over Myers in this research, it relies upon a set of iteratively tuned heuristics. None of the large git platforms can afford to imperil user trust as they iterate on a more granular representation of what changed within a commit. Much like all source control providers herded to git once it was proven reliable at enterprise-scale, no single company is likely to evolve their diff tool until they have strong incentives to do so. As future research corroborates that a savings of more than 20% is possible in pull request review time, the current stasis may end.\u003c/p\u003e\u003cp\u003eThe evidence presented herein raises new questions for the oldest tool still widely used by contemporary developers.\u003c/p\u003e\u003cp\u003eThe implications of a 28% drop in code review time could be significant. Scale the \u003ca href=\"https://media.trustradius.com/product-downloadables/DD/D7/XID8MVZTH0JF.pdf\"\u003e2022 CodeGrip code review survey\u003c/a\u003e result to a 10-member team and the math works out to about 50 hours per week spent reviewing code. If the combined developer and manager salaries average $150,000, then a 10-developer team invests around $16,000 per month of salary toward code review. This doesn’t include the difficult-to-measure (but familiar to any developer) time needed to context shift into and out of \u0026#34;code review mode.\u0026#34;\u003c/p\u003e\u003cp\u003eA reduction of the magnitude observed here would mean this 10-developer team could reallocate 40 hours per month for more coding, less reviewing (one hour/week * four weeks/month * 10 developers). Considering that \u003ca href=\"https://stackoverflow.blog/2024/07/05/what-can-devs-do-about-code-review-anxiety/\"\u003ecode review is often one of the most unpleasant, high-willpower chores\u003c/a\u003e included in a developer\u0026#39;s responsibilities, the morale improvement gained by reducing code review time may rival the gains in \u0026#34;time saved.\u0026#34;\u003c/p\u003e\u003cp\u003eThe full text and citations of GitClear\u0026#39;s latest research is available to download free: \u003ca href=\"https://www.gitclear.com/research_studies/pull_request_diff_methods_comparison_faster_review\"\u003e30% Less is More: Exploring Strategies to Cut Pull Request Review Time\u003c/a\u003e. The pull request tool can be trialed at no cost by visiting our \u003ca href=\"https://www.gitclear.com/best_github_alternative_pull_request_review_tool\"\u003eBest GitHub Alternative Pull Request Review Tool\u003c/a\u003e\u003cstrong\u003e \u003c/strong\u003epage\u003cstrong\u003e, \u003c/strong\u003ewhich allows pasting a pull request URL from GitHub to allow a direct, side-by-side comparison of the competing diff algorithms.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "17 min read",
  "publishedTime": null,
  "modifiedTime": null
}
