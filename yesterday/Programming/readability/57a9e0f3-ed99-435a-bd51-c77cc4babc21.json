{
  "id": "57a9e0f3-ed99-435a-bd51-c77cc4babc21",
  "title": "How Do LLMs Benefit Developer Productivity?",
  "link": "https://blog.jetbrains.com/ai/2025/02/how-do-llms-benefit-developer-productivity/",
  "description": "LLMs are everywhere! I am sure you have heard of large language models (LLMs) and may have seen demonstrations of what they can do. You may have even tried to play with some of the popular ones yourself. No matter your opinion of or experience with LLMs, you cannot deny that they are a popular […]",
  "author": "Cheuk Ting Ho",
  "published": "Tue, 18 Feb 2025 13:22:57 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": null,
  "byline": "Cheuk Ting Ho",
  "length": 11168,
  "excerpt": "LLMs are everywhere! I am sure you have heard of large language models (LLMs) and may have seen demonstrations of what they can do. You may have even tried to play with some of the popular ones yourse",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "Supercharge your tools with AI-powered features inside many JetBrains products How Do LLMs Benefit Developer Productivity? LLMs are everywhere! I am sure you have heard of large language models (LLMs) and may have seen demonstrations of what they can do. You may have even tried to play with some of the popular ones yourself. No matter your opinion of or experience with LLMs, you cannot deny that they are a popular topic these days, and the influence of LLMs and other AI assistance is becoming phenomenal.The breakthrough of LLMs is that they allow computers to analyze and understand human language. Before the popularization of LLMs, computers could only receive instructions rigidly, usually via pre-set instructions or a user interface. Sometimes, they also required you to develop certain skills to get the machine to work correctly. However, with LLMs, the user interface becomes more flexible. You can tell the machine to get the job done in the same way you would communicate with another human being. For example, you can now simply ask a smart home device to play some music, and many tasks that seemed impossible for computers have become possible. These tasks require the capability to understand natural language and construct a meaningful response, for example, to chat with users, generate text, or summarize information.  Not limited to natural language, coding assistants are now available that can understand and analyze programming languages, allowing them to help developers write and understand code. One such tool that harvests the power of LLMs and helps developers in their day-to-day work is JetBrains AI Assistant. LLM basics – what are they? Although LLMs seem very powerful, they are not magic. They are the fruit of AI researchers’ labor and are based on math and science. To understand how LLMs work, let’s go through some of the basics.The foundation of LLMs is natural language processing (NLP). Since machines and computers operate in binaries and numbers, we have to convert the natural language to a mathematical format that a machine can process. Researchers in NLP analyze languages and convert sentences into tokens (tokenization), which, in turn, they convert into vectors (embedding). By providing many examples in the form of training data (training), the researchers make it possible for the computer to pick up natural language patterns and contexts (attention) for computation. The amount of data required for training varies depending on the purpose of the model. If the scope of what the model is trying to achieve is narrow, the training set may not need to be as large as it would be for a general-purpose model. For example, a model designed for tasks involving medical terms and concepts will benefit from a smaller but more specific data set.  To train a general-purpose model that can handle various contexts, a larger neural network and training dataset are necessary. Even though these heavier requirements may make training a general-purpose model seem hard, due to decades of storing information on the internet and the advancement of computer processing power, there are now complicated LLMs that are trained with huge amounts of data and can perform well in general tasks.However, for specific tasks like understanding code, we need to reinforce these LLMs by providing code examples for transfer learning. Furthermore, since technology is evolving every day – code can be deprecated relatively quickly, for example – these models also need to be retrained with new knowledge and code examples to stay up to date.All LLMs can hallucinate, which is when they produce results that seem linguistically coherent and grammatically correct but that don’t make sense or even contain bias. In the most extreme cases, the LLMs may provide results that are totally fabricated. Why does this happen? Since LLMs are based in mathematics, the neural network in the model, which is represented as a huge numeric matrix, is used to compute a result in the form of numbers, which are then translated back into languages that are understandable by humans. Most of the time, with a well-trained model, these results reflect what has been trained in the model and provide reliable answers. However, sometimes, the complexity of the models introduces a significant amount of noise via the huge number of weights in the network, leading to hallucinations. The danger of LLM hallucinations is that misleading information is presented to users as facts. At this point, it is the user’s responsibility to double-check and to determine whether to trust what the LLM provided. JetBrains AI as a tool Now that we understand what LLMs are, it should be clear that they LLMs can be great tools in our day-to-day development workflow. Here are a couple of ways that JetBrains AI Assistant can be used to help you in your work. Use prompts to get refactoring suggestions Sometimes, we need to refactor code when a new design comes in, or it becomes necessary to tidy up old code to improve readability as a project grows. This can be a challenging and time-consuming task, especially since it can introduce bugs. JetBrains AI Assistant streamlines this work for you, providing refactoring suggestions to increase the readability of your code. Simply highlight the part of the code you want to refactor and use the keyboard shortcut Alt+Enter (Windows/Linux) or ⌥⏎ (macOS). AI Assistant will then suggest a refactoring for you. The prompt passed to AI Assistant will appear in a dedicated tool window, along with a step-by-step explanation of the suggestion. If you would like AI Assistant to create a new suggestion with another prompt, you can do so here. You can also fine-tune the suggestion if you are not happy with it. For example here, we want to keep the function name to ensure it is consistent throughout the code file, so we simply say “Do not change ‘preduct_upload_file’ naming”. Once you are happy with the suggestion, you can use the Show Diff button to see the suggested refactorings next to the original code. This makes it easy to review all the suggestions at once and finalize the changes. Generate tests with AI Although important, writing tests may not be the most exciting task. Even with the help of tools like code coverage, sometimes tests can be poorly written and unable to capture potential bugs or points of failure. With the help of JetBrains AI, you can focus on reviewing the functionality of suggested unit tests rather than spending energy writing them. To do that, highlight the code (usually a function), right-click on it, and select Generate Unit Tests from the AI Actions menu. You will see the generated unit tests in a new test file, and they can be reviewed and changed at any time. You can also customize the prompt from the Prompt Library in the AI Assistant settings. To access the settings, use the keyboard shortcut Ctrl+Alt+S (Windows/Linux) or ⌘, (macOS). For example, we could specify that we only want to test error cases. After we update the prompt, we’ll see that our tests are only cases with errors. Once you are happy with the generated tests, click Accept all. You can manually change any of the code generated afterward as well. Generate commit messages﻿ JetBrains AI Assistant can also make your life easier by automatically generating commit messages for you. Commit messages are important for documenting and communicating with the wider team regarding changes. It is important to make your commit messages consistent and communicate the changes effectively. When committing your work, simply click on the icon to Generate Commit Message with AI Assistant and a commit message will be generated for you. If you want to customize the style of the message, or even share the prompt you used with the team so the style stays consistent, you can click on the little cog icon at the bottom. At the bottom of the pop-up menu that appears, you will find the Prompt for generation box, where you can type in your own custom prompt to implement your desired style. In this case, we asked AI Assistant to “Only use point form”. After changing the prompt, click the AI Assistant icon to regenerate the commit message. You can see that it then adapts to the new prompt instructions.By asking JetBrains AI Assistant to take care of composing commit messages and applying specific rules for commit message generation, we standardize the style of the commit messages, ensuring consistency within the project. Cautions about data privacy  As you can imagine, the backbone of these LLMs and AI models is the training data. Acquiring huge amounts of data becomes more important for LLM researchers, and thus, data privacy becomes a greater concern. JetBrains AI never uses your data to train any ML models that generate code or text, and you will have full control of your data. For details, you can read the Data Collection and Use Policy﻿ of JetBrains AI. You can review the data sent to external services at any time by searching for “Open AI Assistant Requests Log” in Search Everywhere: You can also control how your data is shared in the Data Sharing options in Settings. Conclusion I hope this article has helped you understand how LLMs work and the benefit of using them in your work with JetBrains AI. The next time you are writing some unit tests, refactoring your code, or committing your work, perhaps you will give AI Assitant a try and see if it fits well into your workflow. It might even become an indispensable tool for you. However, LLMs do not take away our responsibility. We must apply our knowledge and judgment and avoid being misled by occasional hallucinations.  Not only does JetBrains AI Assistant give you suggestions from LLM models, but it also empowers you to customize the prompts you give to the LLMs. This means you can truly use JetBrains AI Assistant as a tool that expands your creativity as a developer, making you and your team more productive. Subscribe to JetBrains AI Blog updates Discover more",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2025/02/as-social_share_blog_1280x720_en-3.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n    \u003cdiv\u003e\n                        \u003ca href=\"https://blog.jetbrains.com/ai/\"\u003e\n                            \u003cimg src=\"https://blog.jetbrains.com/wp-content/uploads/2024/01/JetBrains-AI.svg\" alt=\"Ai logo\"/\u003e\n                                                                                                \n                                                                                    \u003c/a\u003e\n                                                    \u003cp\u003eSupercharge your tools with AI-powered features inside many JetBrains products\u003c/p\u003e\n                                            \u003c/div\u003e\n                            \u003csection data-clarity-region=\"article\"\u003e\n                \u003cdiv\u003e\n                                        \u003ch2 id=\"major-updates\"\u003eHow Do LLMs Benefit Developer Productivity?\u003c/h2\u003e                    \n                    \n\u003cdiv\u003e\u003cp\u003eLLMs are everywhere! I am sure you have heard of large language models (LLMs) and may have seen demonstrations of what they can do. You may have even tried to play with some of the popular ones yourself. No matter your opinion of or experience with LLMs, you cannot deny that they are a popular topic these days, and the influence of LLMs and other AI assistance is becoming phenomenal.\u003c/p\u003e\u003cp\u003eThe breakthrough of LLMs is that they allow computers to analyze and understand human language. Before the popularization of LLMs, computers could only receive instructions rigidly, usually via pre-set instructions or a user interface. Sometimes, they also required you to develop certain skills to get the machine to work correctly. However, with LLMs, the user interface becomes more flexible. You can tell the machine to get the job done in the same way you would communicate with another human being. For example, you can now simply ask a smart home device to play some music, and many tasks that seemed impossible for computers have become possible. These tasks require the capability to understand natural language and construct a meaningful response, for example, to chat with users, generate text, or summarize information. \u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003cp\u003eNot limited to natural language, coding assistants are now available that can understand and analyze programming languages, allowing them to help developers write and understand code. One such tool that harvests the power of LLMs and helps developers in their day-to-day work is JetBrains AI Assistant.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeEG4ycO2-QD4UjUGSD-GKC_sL4D8IjW0NFz3wnW_lc09XZTNHU0YUAYHirdAKlY7OYQRvvRnfKlswWiE7rmdIZi8iqD40XbSiD9WO8XB--ba0A-RmOFEi8Xgj6xmq4eM9HKrtpZ1bjPNZzV8Hn-skveIU8?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003ch2\u003eLLM basics – what are they?\u003c/h2\u003e\n\n\n\n\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003e\u003cbr/\u003e\u003c/strong\u003eAlthough LLMs seem very powerful, they are not magic. They are the fruit of AI researchers’ labor and are based on math and science. To understand how LLMs work, let’s go through some of the basics.\u003c/p\u003e\u003cp\u003eThe foundation of LLMs is natural language processing (NLP). Since machines and computers operate in binaries and numbers, we have to convert the natural language to a mathematical format that a machine can process. Researchers in NLP analyze languages and convert sentences into tokens (tokenization), which, in turn, they convert into vectors (embedding). By providing many examples in the form of training data (training), the researchers make it possible for the computer to pick up natural language patterns and contexts (attention) for computation.\u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf5wFlJO1VAYhQpJxckz5pJXakjFg-g1anZP52c6zIp92xEcC-ibz1HLC5SoUZG2LX21z0V69zTyyPwrRVTiMigj-JXn5jwC22I_tkhjYbAJbDeGkwakm4TzRHt6oaVTvCHcQezdg?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe amount of data required for training varies depending on the purpose of the model. If the scope of what the model is trying to achieve is narrow, the training set may not need to be as large as it would be for a general-purpose model. For example, a model designed for tasks involving medical terms and concepts will benefit from a smaller but more specific data set. \u003c/p\u003e\n\n\n\n\u003cdiv\u003e\u003cp\u003eTo train a general-purpose model that can handle various contexts, a larger neural network and training dataset are necessary. Even though these heavier requirements may make training a general-purpose model seem hard, due to decades of storing information on the internet and the advancement of computer processing power, there are now complicated LLMs that are trained with huge amounts of data and can perform well in general tasks.\u003c/p\u003e\u003cp\u003eHowever, for specific tasks like understanding code, we need to reinforce these LLMs by providing code examples for transfer learning. Furthermore, since technology is evolving every day – code can be deprecated relatively quickly, for example – these models also need to be retrained with new knowledge and code examples to stay up to date.\u003c/p\u003e\u003cp\u003eAll LLMs can hallucinate, which is when they produce results that seem linguistically coherent and grammatically correct but that don’t make sense or even contain bias. In the most extreme cases, the LLMs may provide results that are totally fabricated. Why does this happen? Since LLMs are based in mathematics, the neural network in the model, which is represented as a huge numeric matrix, is used to compute a result in the form of numbers, which are then translated back into languages that are understandable by humans. Most of the time, with a well-trained model, these results reflect what has been trained in the model and provide reliable answers. However, sometimes, the complexity of the models introduces a significant amount of noise via the huge number of weights in the network, leading to hallucinations. The danger of LLM hallucinations is that misleading information is presented to users as facts. At this point, it is the user’s responsibility to double-check and to determine whether to trust what the LLM provided.\u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003ch2\u003eJetBrains AI as a tool\u003c/h2\u003e\n\n\n\n\u003cp\u003eNow that we understand what LLMs are, it should be clear that they LLMs can be great tools in our day-to-day development workflow. Here are a couple of ways that JetBrains AI Assistant can be used to help you in your work.\u003c/p\u003e\n\n\n\n\u003ch3\u003eUse prompts to get refactoring suggestions\u003c/h3\u003e\n\n\n\n\u003cp\u003eSometimes, we need to refactor code when a new design comes in, or it becomes necessary to tidy up old code to improve readability as a project grows. This can be a challenging and time-consuming task, especially since it can introduce bugs. JetBrains AI Assistant streamlines this work for you, providing refactoring suggestions to increase the readability of your code.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdf-jO_fPtOeDiME2ddBhn-0wJF6i2sV8tFENVvIeqrEezOF6nluNims7ZRuEpOvvb6xcejQmt-6dGXZjM1vXvQuP_V7qpvMavGrs0hgcUiHDJmxvndrQ6BCaVzpMvUN5FNtTO1eg?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eSimply highlight the part of the code you want to refactor and use the keyboard shortcut \u003cem\u003eAlt+Enter\u003c/em\u003e (Windows/Linux) or \u003cem\u003e⌥⏎\u003c/em\u003e (macOS). AI Assistant will then suggest a refactoring for you.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe prompt passed to AI Assistant will appear in a dedicated tool window, along with a step-by-step explanation of the suggestion. If you would like AI Assistant to create a new suggestion with another prompt, you can do so here.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeQy2LxRw-4IUn3ZrJj0VLvX0vKSisaVo4naAG68_HaDe3hsKnKIQov240ntnzNcjyanALqB4Vr4K9CFmH_HcNyRDCDXOtxBOFOtMB4mdPCeRxjIEuZuuCV67PdGSkFPJoZONLc8A?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eYou can also fine-tune the suggestion if you are not happy with it. For example here, we want to keep the function name to ensure it is consistent throughout the code file, so we simply say “Do not change ‘preduct_upload_file’ naming”.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcyesgqofGod-CFhwpfyvSTpDxltMu5rYRIPQn7aCLM3K7kSen4RtK85PJ5TSU74swmIaU-JrG68iH5SeIsv9bAkdqjxJ4XSFX0--uULJfJdNc9FONs8gM68Q6oRDpkcHMxbRnWOw?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOnce you are happy with the suggestion, you can use the \u003cem\u003eShow Diff\u003c/em\u003e button to see the suggested refactorings next to the original code. This makes it easy to review all the suggestions at once and finalize the changes.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeI-WVAZjlMwsdtWoeVXZbTlFOZmMnLI6IS7i13b7OyyTQPjzdZRV9feI9IcXNM-9Hv23nkyzvpM6croq52SIadX6Cq4yzWPxDIuexaLq9V7unUoAW9NCzWUJH6xCJh9qPuFQpIvw?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003ch3\u003eGenerate tests with AI\u003c/h3\u003e\n\n\n\n\u003cp\u003eAlthough important, writing tests may not be the most exciting task. Even with the help of tools like code coverage, sometimes tests can be poorly written and unable to capture potential bugs or points of failure. With the help of JetBrains AI, you can focus on reviewing the functionality of suggested unit tests rather than spending energy writing them.\u003c/p\u003e\n\n\n\n\u003cdiv\u003e\u003cp\u003e\u003cimg decoding=\"async\" fetchpriority=\"high\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfRKQqfPUY_T7rnPnPOUsWMfIhH2pWIYsYD5Fc6EJMOPY7RV-EZ0DIQeGeRQOszxar_pKgb7F37-QDdIRrOAq3jPHnhivtq9bqVg714ZOhY-aOYZBLvrQa50pDGDs7wzZA0ChX1zQ?key=8bmC0TcK_AFHRlaxFn-RPw\" width=\"624\" height=\"276\"/\u003e\u003c/p\u003e\u003cp\u003eTo do that, highlight the code (usually a function), right-click on it, and select \u003cem\u003eGenerate Unit Tests\u003c/em\u003e from the \u003cem\u003eAI Actions\u003c/em\u003e menu.\u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003cp\u003eYou will see the generated unit tests in a new test file, and they can be reviewed and changed at any time.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeiZNU497slMpKYvE5DYDv-TDojtZzj6u_zPlq4hetQYgb_oQyGicpB5J1taIrm2DbPvtal_bz_whfR4CpamcQNyhy2CxyizHygETT1aYhT1catUnypdllIeTaOA1RNLczKevz0fg?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdAEHcBQLvvextr_pB1S-G3XVR_yUB1AYRnzS-gm4w3jI6IsIe7EcoE-PTDAkEESUBn28To73_MIMv80O7jjUYhTiwTbQoa3PvPxYCk9jx4aChp0Y2na0TeO9-tjY_BUNm5JoIW?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cbr/\u003eYou can also customize the prompt from the \u003cem\u003ePrompt Library\u003c/em\u003e in the AI Assistant settings. To access the settings, use the keyboard shortcut \u003cem\u003eCtrl+Alt+S\u003c/em\u003e (Windows/Linux) or \u003cem\u003e⌘\u003c/em\u003e, (macOS). For example, we could specify that we only want to test error cases. After we update the prompt, we’ll see that our tests are only cases with errors.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdtYbKU2iPieGVXLL8fgQBOydoTwIk1up-E14S2UbhRTBZ3czCUiSCkgK0ld2CWC2fvZK8agn9Aal23JF7zQAwCDOVV0qYgkz4HWrAX7VOZSjf23mE4KCK0aWFgEpvwZEbqpWWs?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOnce you are happy with the generated tests, click \u003cem\u003eAccept all\u003c/em\u003e. You can manually change any of the code generated afterward as well.\u003c/p\u003e\n\n\n\n\u003ch3\u003eGenerate commit messages﻿\u003c/h3\u003e\n\n\n\n\u003cp\u003eJetBrains AI Assistant can also make your life easier by automatically generating commit messages for you. Commit messages are important for documenting and communicating with the wider team regarding changes. It is important to make your commit messages consistent and communicate the changes effectively.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeff9NcHq4Y3g6Sc67WBZlT02jp61mq9phFvAiT_gmJUM-g7lTtSB2w3v8N0MADdPP_AXOV9OUmJEAkXF-xEpI_J5BWAJWhMLKxd2JkQTLH5F0qfbSJbUeNnsh89TpXKKqClQa4?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWhen committing your work, simply click on the icon to \u003cem\u003eGenerate Commit Message with AI Assistant\u003c/em\u003e and a commit message will be generated for you.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXc4OSkOwkzBeUOyB4OMh80UNx_mQkYx9DQ0mnSSp83IdeTRJIBN4BqFpq3AzRVTk5bGhsYFaTWGHXkPZAyy0VDxjIFkeyz4Ipis0IPhbZJ0Box1veJHJTZuWcb_hN3bim91mY1xQQ?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIf you want to customize the style of the message, or even share the prompt you used with the team so the style stays consistent, you can click on the little cog icon at the bottom. At the bottom of the pop-up menu that appears, you will find the \u003cem\u003ePrompt for generation\u003c/em\u003e box, where you can type in your own custom prompt to implement your desired style. In this case, we asked AI Assistant to “Only use point form”.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfIqZcttORvDZNXZa28wpuSZGQa33O2BMyWU79YTPzFKbgUu58HoxZERdsL3fOi2iUfGdXav3ak7OGIduRSmlbgek4NonZcGurjTvIIQnCXTURUc9xqw968EWsD59DQIU1cafTXpg?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cdiv\u003e\u003cp\u003eAfter changing the prompt, click the AI Assistant icon to regenerate the commit message. You can see that it then adapts to the new prompt instructions.\u003c/p\u003e\u003cp\u003eBy asking JetBrains AI Assistant to take care of composing commit messages and applying specific rules for commit message generation, we standardize the style of the commit messages, ensuring consistency within the project.\u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003ch2\u003eCautions about data privacy \u003c/h2\u003e\n\n\n\n\u003cp\u003eAs you can imagine, the backbone of these LLMs and AI models is the training data. Acquiring huge amounts of data becomes more important for LLM researchers, and thus, data privacy becomes a greater concern. JetBrains AI never uses your data to train any ML models that generate code or text, and you will have full control of your data. For details, you can read the \u003ca href=\"https://www.jetbrains.com/help/ai/data-collection-and-use-policy.html\" target=\"_blank\" rel=\"noopener\"\u003e\u003cem\u003eData Collection and Use Policy\u003c/em\u003e﻿ of JetBrains AI\u003c/a\u003e. You can review the data sent to external services at any time by searching for “Open AI Assistant Requests Log” in \u003cem\u003eSearch Everywhere\u003c/em\u003e:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdxmSYDLs0ajX0iwJ0xNmQAZzVKskUaamtIorlNwbe1G9jXiwxauctFtdxbmxOslhxynIuq-C-7kMraNWqwuQn5H_6uuXutPHAcluneb9L0z-lckzmnXEQYSeiL0gtyGSijoYUf-RjLpvl0hICgPuBHYvd0?key=8bmC0TcK_AFHRlaxFn-RPw\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eYou can also control how your data is shared in the \u003cem\u003eData Sharing\u003c/em\u003e options in \u003cem\u003eSettings\u003c/em\u003e.\u003c/p\u003e\n\n\n\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\n\n\n\u003cp\u003eI hope this article has helped you understand how LLMs work and the benefit of using them in your work with JetBrains AI. The next time you are writing some unit tests, refactoring your code, or committing your work, perhaps you will \u003ca href=\"https://plugins.jetbrains.com/plugin/22282-jetbrains-ai-assistant\" target=\"_blank\" rel=\"noopener\"\u003egive AI Assitant a try\u003c/a\u003e and see if it fits well into your workflow. It might even become an indispensable tool for you.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, LLMs do not take away our responsibility. We must apply our knowledge and judgment and avoid being misled by occasional hallucinations. \u003c/p\u003e\n\n\n\n\u003cp\u003eNot only does JetBrains AI Assistant give you suggestions from LLM models, but it also empowers you to customize the prompts you give to the LLMs. This means you can truly use JetBrains AI Assistant as a tool that expands your creativity as a developer, making you and your team more productive.\u003c/p\u003e\n                    \n                                                                                                                                                                                                                            \u003cdiv\u003e\n                                \u003cdiv\u003e\n                                                                            \u003ch4\u003eSubscribe to JetBrains AI Blog updates\u003c/h4\u003e\n                                                                                                            \n                                \u003c/div\u003e\n                                \n                                \u003cp\u003e\u003cimg src=\"https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg\" alt=\"image description\"/\u003e\n                                                                    \u003c/p\u003e\n                            \u003c/div\u003e\n                                                            \u003c/div\u003e\n                \u003ca href=\"#\"\u003e\u003c/a\u003e\n                \n                \n            \u003c/section\u003e\n                    \u003cdiv\u003e\n                \u003cp\u003e\n                    \u003ch2\u003eDiscover more\u003c/h2\u003e\n                \u003c/p\u003e\n                \n            \u003c/div\u003e\n                \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": null,
  "modifiedTime": null
}
