{
  "id": "a8e28c01-8764-4753-b326-e7c8c211a542",
  "title": "Automate Your React App Deployment With TeamCity",
  "link": "https://blog.jetbrains.com/teamcity/2025/02/automate-your-react-app-deployment-with-teamcity/",
  "description": "This tutorial was brought to you by Kumar Harsh, a software developer and technical author. If you regularly work with React projects, you probably already know how tricky it can be to deploy them smoothly. Issues like manual errors, inconsistent deployment practices, and slow iteration cycles often turn React app deployment into a challenging process […]",
  "author": "Olga Bedrina",
  "published": "Wed, 19 Feb 2025 15:43:45 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": [
    "all-things-web",
    "best-practices",
    "teamcity-2",
    "tutorials",
    "react",
    "tutorial"
  ],
  "byline": "Olga Bedrina",
  "length": 19670,
  "excerpt": "In this tutorial, you'll learn how to configure TeamCity to deploy a React app from a GitHub repository to an Amazon S3 bucket.",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "Powerful CI/CD for DevOps-centric teams All Things Web Best Practices TeamCity TutorialsAutomate Your React App Deployment With TeamCity This tutorial was brought to you by Kumar Harsh, a software developer and technical author. If you regularly work with React projects, you probably already know how tricky it can be to deploy them smoothly. Issues like manual errors, inconsistent deployment practices, and slow iteration cycles often turn React app deployment into a challenging process and a source of frequent headaches. Effective use of automation can help reduce those headaches and significantly improve the transition from code to users. TeamCity, a continuous integration and continuous deployment (CI/CD) platform from JetBrains, is designed to simplify deployment pipelines. It offers features like build automation and optimization, detailed test reporting, and secure credential management. By securely automating your deployment workflow, TeamCity helps reduce errors, improve consistency, and accelerate delivery, allowing your team to focus on building great applications. In this tutorial, you’ll learn how to set up an automated deployment pipeline with TeamCity Pipelines. You’ll learn how to configure TeamCity to deploy a React app from a GitHub repository to an Amazon S3 bucket, making it ready to serve as a static website. Prerequisites Before you get started, here’s what you’ll need to follow along: A GitHub account. An AWS account. The pipeline you’ll create in this tutorial will deploy the final app to an Amazon S3 bucket. Since you only need to use S3, a free AWS account will work. A TeamCity Pipelines account. If you don’t have one, you can sign up for a 14-day free trial. Once you have these ready, start by forking this GitHub repo to your own GitHub account: https://github.com/krharsh17/teamcity-react-test-app The above repo contains a React 18 app created using Vite. The app’s home page displays framework logos and includes a button that tracks how many times it’s clicked: Output of the React app The repo also contains two integration tests in the src/App.test.jsx file that check whether the App component is rendered and if the button and the counter are working. You can enter the following commands in a terminal window at the root of the repo to run the tests for yourself: yarn \u0026\u0026 yarn test Here’s what the output should look like: RUN  v0.34.6 /Users/kumarharsh/Work/Draft/teamcity-react/teamcity-react-test-app  ✓ src/App.test.jsx (2)    ✓ App (2)      ✓ renders      ✓ should increase count by 1  Test Files  1 passed (1)       Tests  2 passed (2)    Start at  23:05:51    Duration  642ms (transform 31ms, setup 0ms, collect 146ms, tests 26ms, environment 284ms, prepare 51ms) ✨  Done in 1.61s. This indicates that the tests ran successfully on your local system. At this point, you’re ready to start building the CI/CD pipeline. Setting up TeamCity Let’s start by creating a new pipeline in TeamCity. Once you’ve signed up for TeamCity Cloud, you should see a loading screen: TeamCity Cloud server starting Once the server is up, here’s what the dashboard should look like: TeamCity Pipelines dashboard Click the blue Create new pipeline button in the middle of the page, then authenticate with your Git platform: Logging in to a VCS provider Authenticate with GitHub once again. TeamCity will then ask you to choose the repo you’d like to deploy in your first pipeline. Type “teamcity-react-test-app” in the search bar: Choosing your forked repo Select the forked repo and click Create: Creating the pipeline This will set up your new pipeline. Here’s what its Edit page should look like: Newly created pipeline At this point, you’re ready to start developing the steps and jobs in the pipeline. Creating a simple, sequential pipeline You’ll first create a straightforward pipeline that installs dependencies, runs tests, creates a build, sets up AWS credentials, and finally pushes the built artifacts to the S3 bucket. Then, you’ll optimize it by splitting it into multiple jobs that can reuse steps and run in parallel as needed. Hover over the name of the job (Job 1) in the right pane and click the pencil icon that pops up to edit the name: Editing the job name Rename the job “Deploy to S3.” Then, click the NODE.JS icon under the Steps section to add a Node.js-based pipeline step: Adding a new step This will open another sidebar that asks for the details of the steps, including the step name, the working directory (which is the repo root by default), and the shell script you’d like to run as part of this step: Editing the step details Enter “Install dependencies” as the step name and yarn for the shell script. Click the blue Done button in the bottom left-hand corner of the sidebar to add the step to the job. Here’s what the job should look like now: Updated job Adding the test and build steps Now, add two more steps to the job with the following details: “Run test”, with the shell script yarn test. “Build”, with the shell script yarn build. Here’s what the job should look like when you’re done adding the two steps: Updated job with three steps At this point, you can try out the pipeline to see if it runs the tests and builds the app correctly by clicking the blue Save and run button in the top right-hand corner of the page. Here’s what the output should look like: Results of the first run You can expand the sections for each of the steps 1 through 3 to learn more about how they ran. Try expanding step 2 to view the test results. You’ll notice results similar to what you received when you ran the tests locally: Test execution logs This indicates that the test and build steps are working correctly. Preparing the S3 bucket for deployment As mentioned earlier, you’ll be deploying the built React app to an Amazon S3 bucket. But before you do that, you’ll need to create a new S3 bucket and configure it to serve a static website. You can find detailed instructions on how to do that in this AWS tutorial. Here’s an overview of the steps: Create a new S3 bucket with a name (for example, myawsbucket-kh) and default settings. On the bucket details page, go to the Properties tab. Scroll down to find the Static website hosting section and click the Edit button:Enabling static website hosting Choose Enable under Static website hosting and specify the Index document as index.html. Click the Save changes button at the bottom of the page when done. Here’s what the Static website hosting section should look like now:Static website hosting enabledYou’ll also find the website endpoint at the bottom of this page. This is where you’ll be able to access the website once it’s deployed. You also need to enable public access to the bucket. To do that, head over to the Permissions tab from the same page and click the Edit button in the Block public access (bucket settings) section:Editing public access settingsOn the resulting page, you need to uncheck the Block all public access option and click the Save changes button in the bottom right-hand corner:Enabling public accessOnce you’ve enabled public access, you can start uploading files to this bucket and access the website at the URL you retrieved earlier. Copy and store the S3 bucket name somewhere safe. You also need to generate an AWS access key ID and secret. Before you do that, it’s best to create a dedicated AWS IAM user for the CI/CD pipeline to avoid exposing your admin user’s privileges unnecessarily. To do that, navigate to the AWS IAM Users page via your AWS console: Users page via the AWS IAM console On this page, click the orange Create user button to create a new user. Feel free to give it any name you like. For permissions, choose Attach policies directly under Permission options and search for and add the AmazonS3FullAccess policy to the user. Here’s what the user should look like on the review page: Reviewing the newly proposed user Click the Create user button in the bottom right-hand corner of the page. Once the user is created, click its name on the Users page to view its details: Viewing the newly created user’s details Here’s what the user details page will look like: User details Click the Security credentials tab and scroll down to find the Access keys section: Finding the access keys section Click the Create access key button. On the page that opens, choose Command line interface (CLI) under the Use case and check the confirmation checkbox at the bottom of the page before clicking the Next button: Creating the access key You can skip adding tags to the access key and click the Create access key button: Skipping tags and creating the access key The next page will display the access key and the secret access key values. Copy them and store them safely. You’ll use them in the next step of the pipeline to upload built artifacts to the S3 bucket through the AWS CLI. You can safely provide your pipeline with the AWS secrets through TeamCity’s secrets. However, the recommended approach to handle infrastructure integration with CI/CD pipelines is to allow administrators to connect and manage cloud platforms while only providing pipelines (and related users) the ability to use those connections as part of the pipeline steps only, with no access to the secret keys or values at all. To learn more about implementing this approach, check out TeamCity’s AWS Connection. Adding the deploy steps You now have everything you need to add the deploy steps. To do that, you’ll need to add two more steps to your TeamCity pipeline as you did before. First, add a step named “Configure AWS credentials.” Set the step type to Script and use the following custom script value: aws configure set aws_access_key_id \"%AWS_ACCESS_KEY_ID%\" aws configure set aws_secret_access_key \"%AWS_SECRET_ACCESS_KEY%\" This step uses the AWS CLI to configure your AWS account credentials by accessing the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY TeamCity secrets. Next, add a step named “Push to S3.” Set its type as Script and add the following custom script value: aws s3 cp dist s3://%AWS_S3_BUCKET_NAME%/ --recursive With the AWS CLI properly configured, this step will upload the contents of the dist directory (generated by the build step) to the S3 bucket, using the bucket name stored in the TeamCity secret AWS_S3_BUCKET_NAME. You can use the AWS CLI directly inside the pipeline because it’s preinstalled on default JetBrains-hosted agents. Here’s a list of all the software resources that you get out of the box when using JetBrains-hosted runners on TeamCity Cloud. This is what the job should look like when you’re done adding the steps: Deploy steps added to the pipeline You’ll notice that the “Deploy to S3” job now shows up in yellow with a warning that says “No compatible agent”. This is because some of the steps in the job rely on pipeline secrets that aren’t defined yet. You can fix that by clicking the Pipeline settings link right above the job and clicking the plus (+) icon to the right of the No Secrets section in the right pane: Adding secrets to the pipeline This will show some text input fields in that section that will allow you to add secret names and values. You need to add the following secrets: AWS_ACCESS_KEY_ID: Your AWS access key. AWS_SECRET_ACCESS_KEY: Your AWS access key secret. AWS_S3_BUCKET_NAME: The name of your S3 bucket. Once you’ve defined and saved these values, you’ll notice the yellow highlight and warning text are gone: Pipeline ready to run You can now click the Save and run button in the top right-hand corner to save and run the updated pipeline. Here’s what the output should look like: Test run of the updated pipeline This means that your app was successfully built and deployed to your S3 bucket. You can check the bucket to see if the files were actually added there: S3 bucket with build artifacts You can also visit the public website URL you received earlier to view the deployed website: Deployed website as a result of the pipeline Since the pipeline was created with a GitHub VCS repository, it’s automatically configured to monitor the main branch for new commits and trigger whenever it detects changes. Optimizing the pipeline You can make some tweaks to optimize this pipeline further. Currently, there are only a small number of tests, which shouldn’t cause a performance bottleneck. However, if you end up having a large number of tests, especially integration tests that might require extensive setup and teardown in some cases, the test step could become quite time-consuming. The pipeline is configured to only proceed to the build and the deploy steps once the tests have been completed successfully. If you’re setting up a pipeline on a production branch that only receives commits after they’ve been approved as part of a PR or another review process earlier, you can consider running the tests and the build in parallel to save some time. If either of the two fails, the deploy step can be skipped since you wouldn’t want to deploy a version that doesn’t satisfy internal tests or if you’re not able to generate a successful build for it. You can use TeamCity’s parallel builds to achieve this. Since this will require you to split the pipeline into multiple jobs, TeamCity can reuse job results to avoid rerunning jobs if the last run was successful and no new changes have been made since then. This approach saves CI/CD minutes when testing the pipeline with the same commit multiple times. Alternatively, you can configure the pipeline to reupload (without rebuilding) the website to the S3 bucket if needed. To implement these optimizations, you’ll first need to split the steps from the “Deploy to S3” job into three jobs. Create build The Create Build job will just install project dependencies and create the build. For that, you need to add two steps to it: a Node.js step called “Install dependencies” with the command yarn and another Node.js step called “Create build” with the command yarn build. Here’s what the job will look like when you’ve added the steps: New build job with two steps You also need to scroll down and configure the artifacts for this job. Since the output of this job will be used by the “Deploy to S3” job to deploy the app to the S3 bucket, you need to click the plus sign icon to the right of the Artifacts section and enter ./dist/* in the input field that pops up: Updated artifacts path in the build job Run tests Now, create another job named “Run Tests” and add two steps: “Install dependencies” (same as before) and another Node step called “Run tests” with the command yarn test. Here’s what the job will look like when you’ve added the steps: New tests job You don’t need to configure any artifacts for this job since it doesn’t generate any output files after running the tests. You could, however, choose to export test results in a file and add another job to the pipeline to upload the results to a test results analysis platform. Deploy to S3 Finally, you need to update the “Deploy to S3” job to run only after the other two jobs have finished running successfully. Since the other steps are now being run as part of the other two jobs, this job only needs to run the “Configure AWS credentials” and “Push to S3” steps. Here’s what the steps list will look like when you’ve deleted the first three steps: New deploy job You need to check both Create Build and Run Tests under Dependencies since the deploy job depends on those two jobs running successfully. Here’s how the job’s details (and the pipeline) will look when you do that: Job dependencies configured Click the dropdown that says Ignore artifacts next to the Create Build checkbox under Dependencies and change its status to Use artifacts: Artifact usage configured for the job Scroll down to the Optimizations section, where you’ll see that the Reuse Job Results toggle is on by default: Reuse job results toggle Switch the toggle to off. Disabling this ensures that, regardless of whether the repository receives a new commit, each pipeline run updates the last successful build artifacts on the S3 bucket. This can help in situations where the contents of the S3 bucket have been manually modified and you need to restore them to the last successful build state. Now, you can click the Save and run button and watch as the pipeline tests and builds your code before deploying it to S3. You can watch as the various steps of the pipeline run in order to build, test, and deploy your React app: Optimized pipeline run in progress You can explore the execution logs of each of the jobs and their steps by clicking the job and then navigating through the logs in the right pane. Once the build completes running, here’s what the page will look like: Successful test results of the optimized pipeline You can now try pushing a new commit to your forked GitHub repo and watch the pipeline get triggered automatically. Within minutes, it will test, build, and deploy your updated React website to the S3 bucket! Conclusion This tutorial explained how to set up an automated deployment pipeline with TeamCity to deploy a React app from GitHub to an Amazon S3 bucket. This process eliminates manual intervention, ensuring your app is deployed faster, more reliably, and with consistent results. Automating your React app deployment not only saves time but also minimizes errors and improves overall development workflows, allowing your team to focus on delivering value to users. With tools like Build Approval, TeamCity allows you to add an extra layer of security by ensuring that only authorized builds are deployed to production. Meanwhile, as you saw in the tutorial, build chains (or pipelines) enable you to manage complex workflows by breaking them into smaller, interdependent tasks, making large projects easier to handle. These features, combined with TeamCity’s comprehensive reporting and automation capabilities, make it a powerful choice for your deployment needs. Make sure to give TeamCity a try for your next React app project! Subscribe to TeamCity Blog updates Discover more",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2025/02/Automate-Your-React-App-Deployment-With-TeamCity-social-1.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n    \u003cdiv\u003e\n                        \u003ca href=\"https://blog.jetbrains.com/teamcity/\"\u003e\n                            \u003cimg src=\"https://blog.jetbrains.com/wp-content/uploads/2019/01/TeamCity-2.svg\" alt=\"Teamcity logo\"/\u003e\n                                                                                                \n                                                                                    \u003c/a\u003e\n                                                    \u003cp\u003ePowerful CI/CD for DevOps-centric teams\u003c/p\u003e\n                                            \u003c/div\u003e\n                            \u003csection data-clarity-region=\"article\"\u003e\n                \u003cdiv\u003e\n                    \t\t\t\t\u003cp\u003e\u003ca href=\"https://blog.jetbrains.com/teamcity/category/all-things-web/\"\u003eAll Things Web\u003c/a\u003e\n\t\t\t\u003ca href=\"https://blog.jetbrains.com/teamcity/category/best-practices/\"\u003eBest Practices\u003c/a\u003e\n\t\t\t\u003ca href=\"https://blog.jetbrains.com/teamcity/category/teamcity-2/\"\u003eTeamCity\u003c/a\u003e\n\t\t\t\u003ca href=\"https://blog.jetbrains.com/teamcity/category/tutorials/\"\u003eTutorials\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"major-updates\"\u003eAutomate Your React App Deployment With TeamCity\u003c/h2\u003e                    \n                    \n\u003cp\u003e\u003cem\u003eThis tutorial was brought to you by \u003ca href=\"https://kumarharsh.me/\" data-type=\"link\" data-id=\"https://kumarharsh.me/\" target=\"_blank\" rel=\"noopener\"\u003eKumar Harsh\u003c/a\u003e, a software developer and technical author.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you regularly work with React projects, you probably already know how tricky it can be to deploy them smoothly. Issues like manual errors, inconsistent deployment practices, and slow iteration cycles often turn React app deployment into a challenging process and a source of frequent headaches. Effective use of automation can help reduce those headaches and significantly improve the transition from code to users.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://www.jetbrains.com/teamcity/\" target=\"_blank\" rel=\"noopener\"\u003eTeamCity\u003c/a\u003e, a continuous integration and continuous deployment (CI/CD) platform from JetBrains, is designed to simplify deployment pipelines. It offers features like build automation and optimization, detailed test reporting, and secure credential management. \u003c/p\u003e\n\n\n\n\u003cp\u003eBy securely automating your deployment workflow, TeamCity helps reduce errors, improve consistency, and accelerate delivery, allowing your team to focus on building great applications.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn this tutorial, you’ll learn how to set up an automated deployment pipeline with \u003ca href=\"https://jetbrains.com/teamcity/pipelines\" data-type=\"link\" data-id=\"https://jetbrains.com/teamcity/pipelines\" target=\"_blank\" rel=\"noopener\"\u003eTeamCity Pipelines\u003c/a\u003e. You’ll learn how to configure TeamCity to deploy a React app from a GitHub repository to an Amazon S3 bucket, making it ready to serve as a static website.\u003c/p\u003e\n\n\n\n\u003ch2\u003e\u003cstrong\u003ePrerequisites\u003c/strong\u003e\u003c/h2\u003e\n\n\n\n\u003cp\u003eBefore you get started, here’s what you’ll need to follow along:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eA GitHub account.\u003c/li\u003e\n\n\n\n\u003cli\u003eAn AWS account. The pipeline you’ll create in this tutorial will deploy the final app to an Amazon S3 bucket. Since you only need to use S3, a \u003ca href=\"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank\u0026amp;all-free-tier.sort-order=asc\u0026amp;awsf.Free%20Tier%20Types=*all\u0026amp;awsf.Free%20Tier%20Categories=*all\" target=\"_blank\" rel=\"noopener\"\u003efree AWS account\u003c/a\u003e will work.\u003c/li\u003e\n\n\n\n\u003cli\u003eA \u003ca href=\"https://jetbrains.com/teamcity/pipelines\" data-type=\"link\" data-id=\"https://jetbrains.com/teamcity/pipelines\" target=\"_blank\" rel=\"noopener\"\u003eTeamCity Pipelines\u003c/a\u003e account. If you don’t have one, you can sign up for a \u003ca href=\"https://www.jetbrains.com/teamcity/download/\" target=\"_blank\" rel=\"noopener\"\u003e14-day free trial\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eOnce you have these ready, start by forking this GitHub repo to your own GitHub account:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://github.com/krharsh17/teamcity-react-test-app\" target=\"_blank\" rel=\"noopener\"\u003e\u003ccode\u003ehttps://github.com/krharsh17/teamcity-react-test-app\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe above repo contains a React 18 app created using \u003ca href=\"https://vite.dev/\" target=\"_blank\" rel=\"noopener\"\u003eVite\u003c/a\u003e. The app’s home page displays framework logos and includes a button that tracks how many times it’s clicked:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" fetchpriority=\"high\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/1_Output-of-the-React-app.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eOutput of the React app\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe repo also contains two integration tests in the \u003ccode\u003esrc/App.test.jsx\u003c/code\u003e file that check whether the \u003ccode\u003eApp\u003c/code\u003e component is rendered and if the button and the counter are working.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can enter the following commands in a terminal window at the root of the repo to run the tests for yourself:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ccode\u003eyarn \u0026amp;\u0026amp; yarn test\u003c/code\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s what the output should look like:\u003c/p\u003e\n\n\n\n\u003cpre\u003eRUN  v0.34.6 /Users/kumarharsh/Work/Draft/teamcity-react/teamcity-react-test-app\n\n ✓ src/App.test.jsx (2)\n\n   ✓ App (2)\n\n     ✓ renders\n\n     ✓ should increase count by 1\n\n Test Files  1 passed (1)\n\n      Tests  2 passed (2)\n\n   Start at  23:05:51\n\n   Duration  642ms (transform 31ms, setup 0ms, collect 146ms, tests 26ms, environment 284ms, prepare 51ms)\n\n✨  Done in 1.61s.\u003c/pre\u003e\n\n\n\n\u003cp\u003eThis indicates that the tests ran successfully on your local system. At this point, you’re ready to start building the CI/CD pipeline.\u003c/p\u003e\n\n\n\n\u003ch2\u003e\u003cstrong\u003eSetting up TeamCity\u003c/strong\u003e\u003c/h2\u003e\n\n\n\n\u003cp\u003eLet’s start by creating a new pipeline in TeamCity. Once you’ve signed up for TeamCity Cloud, you should see a loading screen:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"2980\" height=\"1402\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/2_TeamCity-Cloud-server-starting-1-1.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTeamCity Cloud server starting\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eOnce the server is up, here’s what the dashboard should look like:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"2980\" height=\"1402\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/3_TeamCity-Cloud-dashboard.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTeamCity Pipelines dashboard\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eClick the blue \u003cem\u003eCreate new pipeline\u003c/em\u003e button in the middle of the page, then authenticate with your Git platform:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1402\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/4_Logging-in-to-a-VCS-provider.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eLogging in to a VCS provider\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eAuthenticate with GitHub once again. TeamCity will then ask you to choose the repo you’d like to deploy in your first pipeline. Type “teamcity-react-test-app” in the search bar:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1402\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/5_Choosing-your-forked-repo.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eChoosing your forked repo\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eSelect the forked repo and click \u003cem\u003eCreate\u003c/em\u003e:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/6_Creating-the-pipeline.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eCreating the pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis will set up your new pipeline. Here’s what its \u003cem\u003eEdit\u003c/em\u003e\u003cstrong\u003e \u003c/strong\u003epage should look like:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1402\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/7_Newly-created-pipeline.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eNewly created pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eAt this point, you’re ready to start developing the steps and jobs in the pipeline.\u003c/p\u003e\n\n\n\n\u003ch2\u003e\u003cstrong\u003eCreating a simple, sequential pipeline\u003c/strong\u003e\u003c/h2\u003e\n\n\n\n\u003cp\u003eYou’ll first create a straightforward pipeline that installs dependencies, runs tests, creates a build, sets up AWS credentials, and finally pushes the built artifacts to the S3 bucket. Then, you’ll optimize it by splitting it into multiple jobs that can reuse steps and run in parallel as needed.\u003c/p\u003e\n\n\n\n\u003cp\u003eHover over the name of the job (\u003cstrong\u003eJob 1\u003c/strong\u003e) in the right pane and click the pencil icon that pops up to edit the name:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/8_Editing-the-job-name.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eEditing the job name\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eRename the job “Deploy to S3.” Then, click the \u003cstrong\u003eNODE.JS\u003c/strong\u003e icon under the \u003cstrong\u003eSteps\u003c/strong\u003e section to add a Node.js-based pipeline step:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/9_Adding-a-new-step.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eAdding a new step\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis will open another sidebar that asks for the details of the steps, including the step name, the working directory (which is the repo root by default), and the shell script you’d like to run as part of this step:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/10_Editing-the-step-details.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eEditing the step details\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eEnter “Install dependencies” as the step name and \u003ccode\u003eyarn\u003c/code\u003e for the shell script. Click the blue \u003cstrong\u003eDone\u003c/strong\u003e button in the bottom left-hand corner of the sidebar to add the step to the job. Here’s what the job should look like now:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/11_Updated-job.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eUpdated job\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003ch3\u003e\u003cstrong\u003eAdding the test and build steps\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cp\u003eNow, add two more steps to the job with the following details:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e“Run test”, with the shell script \u003ccode\u003eyarn test\u003c/code\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003e“Build”, with the shell script \u003ccode\u003eyarn build\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eHere’s what the job should look like when you’re done adding the two steps:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/12_Updated-job-with-three-steps.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eUpdated job with three steps\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eAt this point, you can try out the pipeline to see if it runs the tests and builds the app correctly by clicking the blue \u003cstrong\u003eSave and run\u003c/strong\u003e button in the top right-hand corner of the page. Here’s what the output should look like:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/13_Results-of-the-first-run.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eResults of the first run\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can expand the sections for each of the steps 1 through 3 to learn more about how they ran. Try expanding step 2 to view the test results. You’ll notice results similar to what you received when you ran the tests locally:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1470\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/14_Test-execution-logs.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTest execution logs\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis indicates that the test and build steps are working correctly.\u003c/p\u003e\n\n\n\n\u003ch3\u003e\u003cstrong\u003ePreparing the S3 bucket for deployment\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cp\u003eAs mentioned earlier, you’ll be deploying the built React app to an Amazon S3 bucket. But before you do that, you’ll need to create a new S3 bucket and configure it to serve a static website. You can find detailed instructions on how to do that in \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/HostingWebsiteOnS3Setup.html\" target=\"_blank\" rel=\"noopener\"\u003ethis AWS tutorial\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s an overview of the steps:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eCreate a new S3 bucket with a name (for example, \u003ccode\u003emyawsbucket-kh\u003c/code\u003e) and default settings.\u003c/li\u003e\n\n\n\n\u003cli\u003eOn the bucket details page, go to the \u003cstrong\u003eProperties\u003c/strong\u003e tab. Scroll down to find the \u003cstrong\u003eStatic website hosting\u003c/strong\u003e section and click the \u003cstrong\u003eEdit\u003c/strong\u003e button:\u003cbr/\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"624\" height=\"308\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcrz8ajCA1SUQS5GMlJtcuTB-lc6oWDdu_xx_g3ssCO7SegaZuL3XXkQslWUkRXDhdQDw8gVKdCTeFY6oVUiHp1rml6K2c_8eCI7rgBypqfHmr3idYwVKipevKjvhRGxTAUYmY0Fw?key=eGjCvBRhTKrA4HpIyT_bjyV5\" alt=\"Enabling static website hosting\"/\u003e\u003cbr/\u003e\u003cem\u003eEnabling static website hosting\u003c/em\u003e\u003c/li\u003e\n\n\n\n\u003cli\u003eChoose \u003cstrong\u003eEnable\u003c/strong\u003e under \u003cstrong\u003eStatic website hosting\u003c/strong\u003e and specify the \u003cstrong\u003eIndex document\u003c/strong\u003e as index.html. Click the \u003cstrong\u003eSave changes\u003c/strong\u003e button at the bottom of the page when done. Here’s what the \u003cstrong\u003eStatic website hosting\u003c/strong\u003e section should look like now:\u003cbr/\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"624\" height=\"308\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXd2yqvENZLYphG27foOr0HRqtpR4L-Zvu1EpWh-0ufFKBlq-7W_-VG8vFLD-ZnOVY_sZLh1kQKdaNZ0ixyrtNAGE4EzhqGdhAdDLrHQPMluarwymIZvTEaQRXR4ybsz5pBGGS9H?key=eGjCvBRhTKrA4HpIyT_bjyV5\" alt=\"Static website hosting enabled\"/\u003e\u003ca href=\"https://i.imgur.com/5BLVx8V.png\" target=\"_blank\" rel=\"noopener\"\u003e\u003cem\u003e\u003cbr/\u003e\u003c/em\u003e\u003c/a\u003e\u003cem\u003eStatic website hosting enabled\u003c/em\u003e\u003cbr/\u003eYou’ll also find the website endpoint at the bottom of this page. This is where you’ll be able to access the website once it’s deployed.\u003c/li\u003e\n\n\n\n\u003cli\u003eYou also need to enable public access to the bucket. To do that, head over to the \u003cstrong\u003ePermissions\u003c/strong\u003e tab from the same page and click the \u003cstrong\u003eEdit\u003c/strong\u003e button in the \u003cstrong\u003eBlock public access (bucket settings)\u003c/strong\u003e section:\u003cbr/\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"624\" height=\"308\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcLRmeyH5M9aIi_-4_4RNDrIdVu3ZFX0PA5_45uNsRbMTTAyWCK3-ivG4Y3erWcmCCExGT58ZQr0--B8W8dUA0N8PJPmiYgTAZB1H6xzCrDyULj4uUcqSRW_PrYCSudf79SYlIDfg?key=eGjCvBRhTKrA4HpIyT_bjyV5\" alt=\"Editing public access settings\"/\u003e\u003cbr/\u003e\u003cem\u003eEditing public access settings\u003c/em\u003e\u003cp\u003eOn the resulting page, you need to uncheck the \u003cstrong\u003eBlock \u003cem\u003eall\u003c/em\u003e public access\u003c/strong\u003e option and click the \u003cstrong\u003eSave changes\u003c/strong\u003e button in the bottom right-hand corner:\u003cbr/\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"624\" height=\"308\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXf94MBr6MFNcVg3FaLhDAtydktGVUAIO0qZWgzPRArPA1nR69HYbhcuMvRW_Q2KuH8MfqOTMQ-KBBGizCA5ZWgJQfyvS5-gy9n63aeJMz8g7lIrtyX53SaVE6sBqvMmBL_KL_tqgA?key=eGjCvBRhTKrA4HpIyT_bjyV5\" alt=\"Enabling public access\"/\u003e\u003cbr/\u003e\u003cem\u003eEnabling public access\u003c/em\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve enabled public access, you can start uploading files to this bucket and access the website at the URL you retrieved earlier.\u003c/p\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eCopy and store the S3 bucket name somewhere safe. You also need to generate an AWS access key ID and secret. Before you do that, it’s best to create a dedicated AWS IAM user for the CI/CD pipeline to avoid exposing your admin user’s privileges unnecessarily. \u003c/p\u003e\n\n\n\n\u003cp\u003eTo do that, navigate to the \u003ca href=\"https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/users\" target=\"_blank\" rel=\"noopener\"\u003eAWS IAM Users page\u003c/a\u003e via your AWS console:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/16_Users-page-via-the-AWS-IAM-console.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eUsers page via the AWS IAM console\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eOn this page, click the orange \u003cstrong\u003eCreate user\u003c/strong\u003e button to create a new user. Feel free to give it any name you like. For permissions, choose \u003cstrong\u003eAttach policies directly\u003c/strong\u003e under \u003cstrong\u003ePermission options\u003c/strong\u003e and search for and add the \u003ccode\u003eAmazonS3FullAccess\u003c/code\u003e policy to the user. Here’s what the user should look like on the review page:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/17_Reviewing-the-newly-proposed-user.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eReviewing the newly proposed user\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eClick the \u003cstrong\u003eCreate user\u003c/strong\u003e button in the bottom right-hand corner of the page. Once the user is created, click its name on the \u003cstrong\u003eUsers \u003c/strong\u003epage to view its details:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/18_Viewing-the-newly-created-users-details.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eViewing the newly created user’s details\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s what the user details page will look like:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/19_user-details.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eUser details\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eClick the \u003cstrong\u003eSecurity credentials\u003c/strong\u003e tab and scroll down to find the \u003cstrong\u003eAccess keys\u003c/strong\u003e section:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/20_Finding-the-access-keys-section.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eFinding the access keys section\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eClick the \u003cstrong\u003eCreate access key\u003c/strong\u003e button. On the page that opens, choose \u003cstrong\u003eCommand line interface (CLI)\u003c/strong\u003e under the \u003cstrong\u003eUse case\u003c/strong\u003e and check the confirmation checkbox at the bottom of the page before clicking the \u003cstrong\u003eNext\u003c/strong\u003e button:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/21_Creating-the-access-key.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eCreating the access key\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can skip adding tags to the access key and click the \u003cstrong\u003eCreate access key\u003c/strong\u003e button:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/22_Skipping-tags-and-creating-the-access-key.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eSkipping tags and creating the access key\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe next page will display the access key and the secret access key values. Copy them and store them safely. You’ll use them in the next step of the pipeline to upload built artifacts to the S3 bucket through the AWS CLI.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eYou can safely provide your pipeline with the AWS secrets through TeamCity’s secrets. However, the recommended approach to handle infrastructure integration with CI/CD pipelines is to allow administrators to connect and manage cloud platforms while only providing pipelines (and related users) the ability to use those connections as part of the pipeline steps only, with no access to the secret keys or values at all. To learn more about implementing this approach, check out TeamCity’s \u003c/em\u003e\u003ca href=\"https://blog.jetbrains.com/teamcity/2022/12/introducing-aws-connection/\"\u003e\u003cem\u003eAWS Connection\u003c/em\u003e\u003c/a\u003e\u003cem\u003e.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003ch3\u003e\u003cstrong\u003eAdding the deploy steps\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cp\u003eYou now have everything you need to add the deploy steps. To do that, you’ll need to add two more steps to your TeamCity pipeline as you did before.\u003c/p\u003e\n\n\n\n\u003cp\u003eFirst, add a step named “Configure AWS credentials.” Set the step type to \u003cstrong\u003eScript\u003c/strong\u003e and use the following custom script value:\u003c/p\u003e\n\n\n\n\u003cpre\u003eaws configure set aws_access_key_id \u0026#34;%AWS_ACCESS_KEY_ID%\u0026#34;\n\naws configure set aws_secret_access_key \u0026#34;%AWS_SECRET_ACCESS_KEY%\u0026#34;\u003c/pre\u003e\n\n\n\n\u003cp\u003eThis step uses the AWS CLI to configure your AWS account credentials by accessing the \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e and \u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e TeamCity secrets.\u003c/p\u003e\n\n\n\n\u003cp\u003eNext, add a step named “Push to S3.” Set its type as \u003cstrong\u003eScript\u003c/strong\u003e and add the following custom script value:\u003c/p\u003e\n\n\n\n\u003cpre\u003eaws s3 cp dist s3://%AWS_S3_BUCKET_NAME%/ --recursive\u003c/pre\u003e\n\n\n\n\u003cp\u003eWith the AWS CLI properly configured, this step will upload the contents of the dist directory (generated by the build step) to the S3 bucket, using the bucket name stored in the TeamCity secret \u003ccode\u003eAWS_S3_BUCKET_NAME\u003c/code\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eYou can use the AWS CLI directly inside the pipeline because it’s preinstalled on default JetBrains-hosted agents. \u003c/em\u003e\u003ca href=\"https://www.jetbrains.com/help/teamcity/cloud/jetbrains-hosted-agents.html#Agent+Software\" target=\"_blank\" rel=\"noopener\"\u003e\u003cem\u003eHere’s a list of all the software resources\u003c/em\u003e\u003c/a\u003e\u003cem\u003e that you get out of the box when using JetBrains-hosted runners on TeamCity Cloud.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis is what the job should look like when you’re done adding the steps:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/23_Deploy-steps-added-to-the-pipeline.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eDeploy steps added to the pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou’ll notice that the “Deploy to S3” job now shows up in yellow with a warning that says “No compatible agent”. This is because some of the steps in the job rely on pipeline secrets that aren’t defined yet. You can fix that by clicking the \u003cstrong\u003ePipeline settings\u003c/strong\u003e link right above the job and clicking the plus (\u003cstrong\u003e+\u003c/strong\u003e) icon to the right of the \u003cstrong\u003eNo Secrets\u003c/strong\u003e section in the right pane:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/24_Adding-secrets-to-the-pipeline-.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eAdding secrets to the pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis will show some text input fields in that section that will allow you to add secret names and values. You need to add the following secrets:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e: Your AWS access key.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e: Your AWS access key secret.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ccode\u003eAWS_S3_BUCKET_NAME\u003c/code\u003e: The name of your S3 bucket.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eOnce you’ve defined and saved these values, you’ll notice the yellow highlight and warning text are gone:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/25_Pipeline-ready-to-run.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003ePipeline ready to run\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can now click the \u003cstrong\u003eSave and run\u003c/strong\u003e button in the top right-hand corner to save and run the updated pipeline. Here’s what the output should look like:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/26_Test-run-of-the-updated-pipeline.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTest run of the updated pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThis means that your app was successfully built and deployed to your S3 bucket. You can check the bucket to see if the files were actually added there:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/26_S3-bucket-with-build-artifacts-.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eS3 bucket with build artifacts\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can also visit the public website URL you received earlier to view the deployed website:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1580\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/27_Deployed-website-as-a-result-of-the-pipeline.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eDeployed website as a result of the pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eSince the pipeline was created with a GitHub VCS repository, it’s automatically configured to monitor the main branch for new commits and trigger whenever it detects changes.\u003c/p\u003e\n\n\n\n\u003ch2\u003e\u003cstrong\u003eOptimizing the pipeline\u003c/strong\u003e\u003c/h2\u003e\n\n\n\n\u003cp\u003eYou can make some tweaks to optimize this pipeline further. Currently, there are only a small number of tests, which shouldn’t cause a performance bottleneck. However, if you end up having a large number of tests, especially integration tests that might require extensive setup and teardown in some cases, the test step could become quite time-consuming.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe pipeline is configured to only proceed to the build and the deploy steps once the tests have been completed successfully. \u003c/p\u003e\n\n\n\n\u003cp\u003eIf you’re setting up a pipeline on a production branch that only receives commits after they’ve been approved as part of a PR or another review process earlier, you can consider running the tests and the build in parallel to save some time. \u003c/p\u003e\n\n\n\n\u003cp\u003eIf either of the two fails, the deploy step can be skipped since you wouldn’t want to deploy a version that doesn’t satisfy internal tests or if you’re not able to generate a successful build for it.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can use TeamCity’s parallel builds to achieve this. Since this will require you to split the pipeline into multiple jobs, TeamCity can reuse job results to avoid rerunning jobs if the last run was successful and no new changes have been made since then. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis approach saves CI/CD minutes when testing the pipeline with the same commit multiple times. Alternatively, you can configure the pipeline to reupload (without rebuilding) the website to the S3 bucket if needed.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo implement these optimizations, you’ll first need to split the steps from the “Deploy to S3” job into three jobs.\u003c/p\u003e\n\n\n\n\u003ch3\u003e\u003cstrong\u003eCreate build\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cp\u003eThe \u003cstrong\u003eCreate Build\u003c/strong\u003e job will just install project dependencies and create the build. For that, you need to add two steps to it: a Node.js step called “Install dependencies” with the command \u003ccode\u003eyarn\u003c/code\u003e and another Node.js step called “Create build” with the command \u003ccode\u003eyarn build\u003c/code\u003e. Here’s what the job will look like when you’ve added the steps:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/28_New-build-job-with-two-steps-.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eNew build job with two steps\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou also need to scroll down and configure the artifacts for this job. Since the output of this job will be used by the “Deploy to S3” job to deploy the app to the S3 bucket, you need to click the plus sign icon to the right of the \u003cstrong\u003eArtifacts\u003c/strong\u003e section and enter \u003ccode\u003e./dist/*\u003c/code\u003e in the input field that pops up:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/29_Updated-artifacts-path-in-the-build-job-.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eUpdated artifacts path in the build job\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003ch3\u003e\u003cstrong\u003eRun tests\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cp\u003eNow, create another job named “Run Tests” and add two steps: “Install dependencies” (same as before) and another Node step called “Run tests” with the command yarn test. Here’s what the job will look like when you’ve added the steps:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/30_new-tests-job.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://i.imgur.com/4fmND3I.png\" target=\"_blank\" rel=\"noopener\"\u003e\u003cem\u003e\u003cbr/\u003e\u003c/em\u003e\u003c/a\u003e\u003cem\u003eNew tests job\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou don’t need to configure any artifacts for this job since it doesn’t generate any output files after running the tests. You could, however, choose to export test results in a file and add another job to the pipeline to upload the results to a test results analysis platform.\u003c/p\u003e\n\n\n\n\u003ch3\u003e\u003cstrong\u003eDeploy to S3\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cp\u003eFinally, you need to update the “Deploy to S3” job to run only after the other two jobs have finished running successfully. Since the other steps are now being run as part of the other two jobs, this job only needs to run the “Configure AWS credentials” and “Push to S3” steps. \u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s what the steps list will look like when you’ve deleted the first three steps:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/31_new-deploy-job.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eNew deploy job\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou need to check both \u003cstrong\u003eCreate Build\u003c/strong\u003e and \u003cstrong\u003eRun Tests\u003c/strong\u003e under \u003cstrong\u003eDependencies\u003c/strong\u003e since the deploy job depends on those two jobs running successfully. Here’s how the job’s details (and the pipeline) will look when you do that:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/32_Job-dependencies-configured.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eJob dependencies configured\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eClick the dropdown that says \u003cstrong\u003eIgnore artifacts\u003c/strong\u003e next to the \u003cstrong\u003eCreate Build\u003c/strong\u003e checkbox under \u003cstrong\u003eDependencies\u003c/strong\u003e and change its status to \u003cstrong\u003eUse artifacts\u003c/strong\u003e:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/33_Artifact-usage-configured-for-the-job.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eArtifact usage configured for the job\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eScroll down to the \u003cstrong\u003eOptimizations\u003c/strong\u003e section, where you’ll see that the \u003cstrong\u003eReuse Job Results\u003c/strong\u003e toggle is on by default:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/34_Reuse-job-results-toggle.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eReuse job results toggle\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eSwitch the toggle to off. Disabling this ensures that, regardless of whether the repository receives a new commit, each pipeline run updates the last successful build artifacts on the S3 bucket. This can help in situations where the contents of the S3 bucket have been manually modified and you need to restore them to the last successful build state.\u003c/p\u003e\n\n\n\n\u003cp\u003eNow, you can click the \u003cstrong\u003eSave and run\u003c/strong\u003e button and watch as the pipeline tests and builds your code before deploying it to S3.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can watch as the various steps of the pipeline run in order to build, test, and deploy your React app:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/35_Optimized-pipeline-run-in-progress-.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eOptimized pipeline run in progress\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can explore the execution logs of each of the jobs and their steps by clicking the job and then navigating through the logs in the right pane. Once the build completes running, here’s what the page will look like:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"2980\" height=\"1480\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/02/36_Successful-test-results-of-the-optimized-pipeline.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eSuccessful test results of the optimized pipeline\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eYou can now try pushing a new commit to your forked GitHub repo and watch the pipeline get triggered automatically. Within minutes, it will test, build, and deploy your updated React website to the S3 bucket!\u003c/p\u003e\n\n\n\n\u003ch2\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis tutorial explained how to set up an automated deployment pipeline with TeamCity to deploy a React app from GitHub to an Amazon S3 bucket. This process eliminates manual intervention, ensuring your app is deployed faster, more reliably, and with consistent results. \u003c/p\u003e\n\n\n\n\u003cp\u003eAutomating your React app deployment not only saves time but also minimizes errors and improves overall development workflows, allowing your team to focus on delivering value to users.\u003c/p\u003e\n\n\n\n\u003cp\u003eWith tools like \u003ca href=\"https://www.jetbrains.com/help/teamcity/build-approval.html\" target=\"_blank\" rel=\"noopener\"\u003eBuild Approval\u003c/a\u003e, TeamCity allows you to add an extra layer of security by ensuring that only authorized builds are deployed to production. Meanwhile, as you saw in the tutorial, \u003ca href=\"https://www.jetbrains.com/help/teamcity/build-chain.html\" target=\"_blank\" rel=\"noopener\"\u003ebuild chains\u003c/a\u003e (or pipelines) enable you to manage complex workflows by breaking them into smaller, interdependent tasks, making large projects easier to handle. \u003c/p\u003e\n\n\n\n\u003cp\u003eThese features, combined with TeamCity’s comprehensive reporting and automation capabilities, make it a powerful choice for your deployment needs. Make sure to give \u003ca href=\"https://jetbrains.com/teamcity/pipelines\" target=\"_blank\" rel=\"noopener\"\u003eTeamCity\u003c/a\u003e a try for your next React app project!\u003c/p\u003e\n                    \n                                                                                                                                                                                                                            \u003cdiv\u003e\n                                \u003cdiv\u003e\n                                                                            \u003ch4\u003eSubscribe to TeamCity Blog updates\u003c/h4\u003e\n                                                                                                            \n                                \u003c/div\u003e\n                                \n                                \u003cp\u003e\u003cimg src=\"https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg\" alt=\"image description\"/\u003e\n                                                                    \u003c/p\u003e\n                            \u003c/div\u003e\n                                                            \u003c/div\u003e\n                \u003ca href=\"#\"\u003e\u003c/a\u003e\n                \n                \n            \u003c/section\u003e\n                    \u003cdiv\u003e\n                \u003cp\u003e\n                    \u003ch2\u003eDiscover more\u003c/h2\u003e\n                \u003c/p\u003e\n                \n            \u003c/div\u003e\n                \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "21 min read",
  "publishedTime": null,
  "modifiedTime": null
}
