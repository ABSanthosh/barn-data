{
  "id": "d0070eb6-c62a-492a-97ef-86a7f4646153",
  "title": "How to secure your GitHub Actions workflows with CodeQL",
  "link": "https://github.blog/security/application-security/how-to-secure-your-github-actions-workflows-with-codeql/",
  "description": "In the last few months, we secured 75+ GitHub Actions workflows in open source projects, disclosing 90+ different vulnerabilities. Out of this research we produced new support for workflows in CodeQL, empowering you to secure yours. The post How to secure your GitHub Actions workflows with CodeQL appeared first on The GitHub Blog.",
  "author": "Alvaro Munoz",
  "published": "Thu, 09 Jan 2025 17:00:59 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "Application security",
    "Security",
    "CodeQL",
    "GitHub Security Lab"
  ],
  "byline": "Alvaro Munoz",
  "length": 24459,
  "excerpt": "In the last few months, we secured 75+ GitHub Actions workflows in open source projects, disclosing 90+ different vulnerabilities. Out of this research we produced new support for workflows in CodeQL, empowering you to secure yours.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "In the last few months, we secured more than 75 GitHub Actions workflows in open source projects, disclosing more than 90 different vulnerabilities. Out of this research, we produced new support for workflows in CodeQL, empowering you to secure yours. The situation: growing number of insecure workflows If you have read our series about keeping your GitHub Actions and workflows secure, you already have a good understanding of common vulnerabilities in GitHub Actions and how to solve them. Keeping your GitHub Actions and workflows secure Part 1: Preventing pwn requests Keeping your GitHub Actions and workflows secure Part 2: Untrusted input Keeping your GitHub Actions and workflows secure Part 3: How to trust your building blocks Unfortunately, we found that these vulnerabilities are still quite common, mostly because of a lack of awareness of how the moving parts interact with each other and what the impact of these vulnerabilities may be for your organization or repository. To help prevent the introduction of vulnerabilities, identify them in existing workflows, and even fix them using GitHub Copilot Autofix, CodeQL support has been added for GitHub Actions. The new CodeQL packs can be used by code scanning to scan both existing and new workflows. As code scanning and Copilot Autofix are free for OSS repositories, all public GitHub repositories will have access to these new queries, empowering detection and remediation of these vulnerabilities. In the rest of this post, we’ll see What we added to our existing CodeQL support, including actions as a first-class language, taint tracking, bash support; What models and queries we developed; What vulnerabilities and what new patterns we discovered as part of this work. Previous attempt Previously, there was a single CodeQL query capable of identifying simplistic code injections in GitHub workflows. However, this query had several limitations. First, it was bundled with the JavaScript QL packs, meaning users had to enable JavaScript scanning even if they had no JavaScript code in their repositories, which was confusing and misleading. Additionally, the representation of GitHub workflow syntax and grammar was incomplete, making it difficult to express more complex patterns using the existing Abstract Syntax Tree (AST) of GitHub Actions, which is used by static analysis tools such as CodeQL. Most importantly, the CodeQL support for GitHub workflows did not previously include Taint Tracking support and models for non-straightforward sources of untrusted data or dangerous operations. Taint Tracking is key! So what is Taint Tracking and how important is it? Through the previous query for Code Injection, we were able to identify simplistic vulnerabilities such as those cases where a known user-controlled property gets directly interpolated into a Run script: That was a great starting point, but what about cases such as the following? The first step of the path is the download of an artifact. The second and third steps are setting the content of a file from the artifact as the output of the workflow step. In the last step, the value from the previous step is interpolated in an unsafe manner in a Run script leading to a potential code injection. In the case above, the source of untrusted data is not simply a GitHub Event Context access of a known untrusted property (for example, github.event.pull_request.body) but rather the download of an artifact. Should all artifacts be considered untrusted? Certainly not. However, in this instance, where the workflow is triggered by a workflow_run event with no branch filters and where an artifact is downloaded from the triggering workflow (github.event.workflow_run.workflow_id), the artifact should be considered untrusted. When decompressed, it may pollute the Runner’s workspace by writing to files in unexpected locations. Consequently, from that step onward, all files in the workspace should be considered untrusted. This example highlights a non-trivial pattern that we need to express using the new actions AST representation to identify sources of untrusted data. Identifying sources of untrusted data is only the first step towards uncovering more complex injection vulnerabilities. In the example above, it is crucial to understand Bash scripts to determine if they are reading from untrusted files and inserting data into shell variables. It is essential to comprehend how these variables may flow into the output of a step, and, subsequently, how the output flows through different steps, jobs, composite actions, or reusable workflows until they reach a potentially dangerous sink. This understanding is what Taint Tracking and Control Flow will achieve. In summary, as illustrated in the CodeQL alert above, we can now identify non-obvious sources of untrusted data (for example, git or gh commands or third-party actions) and, more importantly, track this untrusted data throughout complex workflows. These workflows involve multiple steps, jobs, actions, and even entire workflows, allowing us to better understand where this data is used and to report potential vulnerabilities effectively. Bash support GitHub’s workflows can execute various scripts, with Bash scripts being among the most common. The new CodeQL packs for GitHub Actions offer basic support for Bash, helping to identify tainted data originating from Bash scripts. For example, commands such as git diff-tree obtain a list of changed files. Tainted data can flow through a script when reading an attacker-controlled file or environment variable into a step’s output or another environment variable. A pertinent example of such a vulnerability could be found in a workflow of Azure CLI repository. In the alert above, we can see how untrusted data, such as a pull request’s title, is assigned to the TITLE environment variable. This variable is then read and processed by several commands, resulting in a new message variable that gets redirected to the special file pointed to by the GITHUB_ENV variable. A malicious actor could craft a title that results in a multiline message, allowing them to inject arbitrary environment variables into subsequent steps. This, in turn, would enable the attacker to exfiltrate secrets used in the workflow. The new CodeQL packs are able to parse Bash scripts. While they don’t yet generate a full AST, they already allow us to understand elements such as assignments, pipelines, and redirections, enabling us to report subtle vulnerabilities like the one mentioned above. Models As explained in “Keeping your GitHub Actions and workflows secure Part 2: Untrusted input,” GitHub’s event context is the most common source of untrusted data. Properties such as github.event.issue.title, github.event.pull_request.head.ref, or github.event.comment.body are typical sources of untrusted data. However, any third-party action may introduce untrusted data. For instance, an action that returns a list of filenames changed in a pull request should be considered a source of untrusted data. Similarly, actions that parse an issue body or comment for a command or structured data should also be treated as sources of untrusted data. The same applies to actions that pass data from one of their inputs to their outputs or into an environment variable, therefore acting as taint steps (summaries). Actions such as actions/github-script, azure/cli, or azure/powershell should be considered sinks for Code Injection, similar to a Run’s step. We have analyzed thousands of popular third-party actions and identified a number of models now incorporated into the analysis: 62 sources 129 summaries 2199 sinks Queries The previous support for GitHub Actions contained a single query for code injection, whereas the new CodeQL packs incorporate 18 new queries, including the Code Injection and Environment Variable Injection queries mentioned above. Execution of Untrusted Code Execution of Untrusted Code (TOCTOU) Artifact Poisoning Code Injection Environment Variable Injection Path Injection Unpinned Action Tag Improper Access Control Excessive Secrets Exposure Secrets In Artifacts Expression is Always True Unmasked Secret Exposure Cache Poisoning (Code Injection, Direct Cache, Untrusted Code) Use of Known Vulnerable Actions Missing Action Permissions Argument Injection (Experimental) Code Execution on Self Hosted Runners (Experimental) Output Clobbering (Experimental) Results For the past few months, we have been testing the new queries on thousands of open source projects to validate their accuracy and performance. The results have been very impressive, allowing us to identify and report vulnerabilities in numerous critical organizations and repositories, such as Microsoft, Azure, GitHub, Eclipse, Jupyter, Adobe, AWS, Cloudflare, Discord, Hibernate, HuggingFace, and Apache. The table below shows all the repositories affected, along with their GitHub stars, to give an idea of the impact that a supply chain attack could have had in these projects: Repository Stars ant-design/ant-design 92,412 Excalidraw/excalidraw 84,021 apache/superset 62,589 withastro/astro 46,604 Stirling-Tools/Stirling-PDF 44,988 geekan/MetaGPT 44,901 Kong/kong 39,221 LAION-AI/Open-Assistant 37,045 appsmithorg/appsmith 34,352 gradio-app/gradio 33,709 DIYgod/RSSHub 33,432 calcom/cal.com 32,282 milvus-io/milvus 30,299 k3s-io/k3s 28,010 discordjs/discord.js 25,390 element-plus/element-plus 24,488 cilium/cilium 20,150 monkeytypegame/monkeytype 15,635 amplication/amplication 15,196 docker-mailserver/docker-mailserver 14,643 jupyterlab/jupyterlab 14,167 openimsdk/open-im-server 14,041 quarkusio/quarkus 13,771 espressif/arduino-esp32 13,609 sympy/sympy 12,967 ionic-team/stencil 12,561 zephyrproject-rtos/zephyr 10,819 qgis/QGIS 10,569 trinodb/trino 10,413 OpenFeign/feign 9,490 marimo-team/marimo 7,583 dream-num/univer 7,021 aws/karpenter-provider-aws 6,782 hibernate/hibernate-orm 5,976 ant-design-blazor/ant-design-blazor 5,809 litestar-org/litestar 5,511 New vulnerability patterns Having triaged and reported numerous alerts, we have identified some common patterns that often lead to vulnerabilities in GitHub workflows: Misuse of pull_request_target trigger The pull_request_target event trigger, while offering powerful automation capabilities in GitHub Actions, harbors a dark side filled with potential security pitfalls. This event trigger, designed to execute workflows within the context of pull request’s base branch, presents special characteristics that severely increase the impact in case of any vulnerability. A workflow activated by pull_request_target and triggered from a fork operates with significant privileges, in contrast to the pull_request event: It is able to read repository and organization secrets. It is allowed to have write permissions. It circumvents the usual safeguards of pull request approvals, allowing workflows to run unimpeded even if approval mechanisms are configured for standard pull_request events. It normally runs in the context of the default branch, which, as we will see, may allow malicious actors to poison the action’s cache and move laterally to other, more privileged workflows even when removing all permissions to the vulnerable workflow. When working with pull_request_triggered workflows, we have to be very careful and pay special attention to the following scenarios: Code execution from untrusted sources: The ability to execute code from forked pull requests is a double-edged sword. A malicious actor can submit a seemingly innocuous pull request that, when triggered by pull_request_target, unleashes havoc. This malicious code, running in the context of the target repository’s environment, could exfiltrate secrets or even tamper with repository contents and releases. The danger lies in the inadvertent checkout and execution of code from untrusted sources. Common mistakes include using the actions/checkout action with a reference to the pull request’s head branch. Time of check to time of use (TOCTOU) attacks. Even with approval requirements in place (such as requiring the pull request to have a specific label that attackers are not able to set on their own), attackers can leverage the element of time to bypass security measures. A malicious actor can submit a seemingly harmless pull request, patiently wait for approval, and then swiftly update the pull request with malicious code before the workflow execution. The workflow, relying on a mutable reference like a branch name, falls prey to this “time of check to time of use” (TOCTOU) attack, unwittingly executing the newly injected malicious code. Confusion surrounding context variables, specifically head.ref and head.sha, can lead to vulnerabilities. head.ref, pointing to the branch, is susceptible to manipulation by attackers. In contrast, head.sha, referencing the specific commit, provides a reliable and immutable pointer to the reviewed and approved code. Using the incorrect variable can create an opening for attackers to inject malicious code after approval. Lurking threats in non-default branches. Vulnerabilities often linger in non-default branches, even after being addressed in the default branch. An attacker can target these vulnerable versions of the workflows residing in non-default branches, exploiting them by submitting pull requests specifically to those branches. Cache poisoning. As a mitigation, developers may strip out all read and write permissions from these workflows when in need to run untrusted code. However, the seemingly innocuous permissions: {} configuration can unexpectedly pave the way for cache poisoning attacks. This attack vector involves injecting malicious content into the cache, which can subsequently affect other workflows relying on the poisoned cache entries. Even if a workflow doesn’t have write access to the repository, it can still poison the cache, leading to potential code execution or data manipulation in other workflows that utilize the compromised cache. If we really need to use this trigger event, there are a few ways to harden the workflows to prevent any abuses: Repository checks. Implementing stringent repository checks is crucial for thwarting attacks originating from forked pull requests. One effective method is to configure workflows to execute only for pull requests originating from the base repository, effectively blocking any attempts from external forks. This can be achieved by using conditions such as github.event.pull_request.head.repo.owner.login == “myorg” to restrict workflow execution. Actor checks. Verifying the permissions of the pull request author is another layer of defense. By restricting workflow execution to trusted actors, such as members of the organization or approved collaborators, the risk of malicious code injection from unauthorized sources can be significantly reduced. Never use a hardcoded list of user names, since the users may lose the permissions with time or the user names may be left abandoned for an attacker to claim. Workflow splitting. The above mitigations may not be useful if we need to run a workflow for forks or arbitrary users. In those cases, splitting workflows into unprivileged and privileged components is a powerful security strategy. Unprivileged workflows, triggered by pull_request events, handle the initial processing of pull requests without access to sensitive secrets or write permissions. Privileged workflows, activated by workflow_run events, are invoked only after the unprivileged workflow has completed its checks. This separation ensures that potentially malicious code from forked pull requests never executes within a privileged context. The unprivileged workflow will generally need to communicate and pass information to the privileged one. This is a crucial security boundary, and, as we will see in the next section, any data coming from the unprivileged workflow should be considered untrusted and potentially dangerous. Security boundaries and workflow_run event The workflow_run event trigger in GitHub Actions is designed to automate tasks based on the execution or completion of another workflow. It may grant write permissions and access to secrets even if the triggering workflow doesn’t have such privileges. While this is beneficial for tasks like labeling pull requests based on test results, it poses significant security risks if not used carefully. The workflow_run trigger poses a risk because it can often be initiated by an attacker. Some maintainers were surprised by this, believing that their triggering workflows, which were run on events such as release, were safe. This assumption was based on the idea that since an attacker couldn’t trigger a new release, they shouldn’t be able to initiate the triggering workflow or the subsequent workflow_run workflow. The reality is that an attacker can submit a pull request that modifies the triggering workflow and even replace the triggering events. Since pull_request workflows run in the context of the pull request’s HEAD branch, the modified workflow will run and, upon completion, will be able to trigger an existing workflow_run workflow. The danger arises from the fact that even if the triggering pull_request workflow is not privileged, the triggered workflow_run workflow will have access to secrets and write-scoped tokens, even if the initial workflow did not have those privileges. This enables privilege escalation attacks, allowing attackers to execute malicious code with elevated permissions within the CI/CD pipeline. Another significant pitfall with the workflow_run event trigger is artifact poisoning. Artifacts are files generated during a workflow run that can be shared with other workflows. Attackers can poison these artifacts by uploading malicious content through a pull request. When a workflow_run workflow downloads and uses these poisoned artifacts, it can lead to arbitrary code execution or other malicious activities within the privileged workflow. The issue is that many workflow_run workflows do not verify the contents of downloaded artifacts before using them, making them vulnerable to various attacks. Securing workflow_run workflows requires a multi-faceted approach. By understanding the inherent risks and implementing the recommended mitigations, developers can leverage the automation benefits of workflow_run while minimizing the potential for security compromises. Effective mitigations Limit workflow scope with branch filters: Specify the branches where workflow_run workflows can be triggered using the branches filter. This helps restrict the scope of potential attacks by preventing them from being triggered on branches from forks. Verify event origin: Incorporate a check like github.event_name != 'pull_request' to prevent workflow_run workflows from being triggered by pull requests from forks. This adds an extra layer of protection by ensuring that the triggering workflow originates from a trusted source. Treat artifacts as untrusted: Treat all downloaded artifacts as potentially malicious and implement rigorous validation checks before using them. Always unzip artifacts to a temporary directory like /tmp to prevent potential file overwrites, that is, the pollution of the workspace. Avoid defining environment variables: Minimize the use of environment variables, especially when handling untrusted data. Environment variables can be vulnerable to injection attacks, potentially allowing attackers to modify their values and execute malicious code. Handle output variables with caution: Exercise caution when defining output variables from artifact’s content, as they can also be vulnerable to manipulation by attackers. Always validate the contents of output variables (for example, that it is a number, not a string) before using them in subsequent steps or other workflows. Non-effective mitigations Repository checks: We found several workflows (for example, AWS Karpenter Provider, or Cloudflare Workers SDK) relying solely on repository checks, such as verifying the repository owner (github.repository_owner == 'myorg'), which is not effective in mitigating workflow_run risks since the workflow always runs in the context of the default branch which belongs to the organization. The issue_comment event trigger in GitHub Actions is a powerful tool for automating workflows based on comments on issues and pull requests. When applied in the context of IssueOps, it can streamline tasks like running commands in response to specific comments. However, this convenience comes with significant security risks that must be carefully considered. TOCTOU vulnerabilities: Similar to the pull_request_target event trigger, workflows using issue_comment can be vulnerable to TOCTOU attacks. If the workflow checks out and executes code from a pull request based on an issue comment, an attacker could exploit the time window between the comment and the workflow execution. An attacker might initially submit a harmless pull request, waiting for an administrator to review and approve the workflow by adding a comment. Once the approval is given, the attacker could quickly update the pull request with malicious code, which would then be executed by the workflow. Bypassing pull request approval mechanisms: The issue_comment event trigger is not subject to the pull request approval mechanisms intended to prevent abuse. Even if the workflows triggered by pull request require approvals, an attacker can trigger an issue_comment workflow by simply adding a comment to the pull request, potentially executing malicious code without any review. Mitigating the risks Shifting to label gates: Instead of relying on issue comments to trigger critical workflows, consider adopting a label gates approach. Label gates use labels to trigger specific actions, allowing for more granular control and better security. Since the labeled activity type for a pull_request trigger contains details about the latest commit SHA of the pull request, there is no need for workflow to resolve a pull request number into the latest commit SHA, as it is the case with issue_comment, and, therefore, there is no window for an attacker to modify the pull request. Remember to use the commit SHA rather than the HEAD reference to prevent TOCTOU vulnerabilities. Ineffective or incomplete mitigations Actor checks: Relying solely on actor checks (verifying the identity or permissions of the commenter) is ineffective. The actor triggering the workflow might not be the same one trying to exploit it, further rendering actor checks unreliable. This is the case for TOCTOU vulnerabilities where an attacker can submit a legitimate pull request and wait for an admin to trigger an IssueOp and then swiftly mutate the pull request by adding a new commit with malicious code on it. Date checks: Comparing timestamps to verify that the last commit occurred before the triggering comment is also unreliable. Currently, GitHub has no reliable way to figure out the date when a commit was pushed to a repository. An attacker can forge commit dates, rendering these checks useless in preventing malicious code execution. Repository checks: Verifying the origin repository is not a useful mitigation for issue_comment event triggers. The issue_comment event always executes within the context of the target repository’s default branch, making repository checks redundant. Wrapping up The new CodeQL support for GitHub Actions is in public preview. The new QL packs allow you to scan your repository for a variety of vulnerabilities in GitHub Actions, helping prevent supply chain attacks in the OSS software we all depend on! If you want to give them a try, take one of the following steps depending on your case: Your repository is newly configured for default setup: Code scanning will automatically attempt to analyze actions if any workflows are present on the default branch. You have nothing to do; keep calm and fix the potential alerts. Your repository is already configured for default setup: You need to edit the Default Setup settings and explicitly enable actions analysis. Your repository is using advanced setup: You just have to add actions to the language matrix. Stay secure! Written by",
  "image": "https://github.blog/wp-content/uploads/2023/12/Security-DarkMode-1.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003eIn the last few months, we secured more than 75 GitHub Actions workflows in open source projects, disclosing more than 90 different vulnerabilities. Out of this research, we produced new support for workflows in CodeQL, empowering you to secure yours.\u003c/p\u003e\n\u003ch2 id=\"the-situation-growing-number-of-insecure-workflows\" id=\"the-situation-growing-number-of-insecure-workflows\"\u003eThe situation: growing number of insecure workflows\u003ca href=\"#the-situation-growing-number-of-insecure-workflows\" aria-label=\"The situation: growing number of insecure workflows\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIf you have read our series about keeping your GitHub Actions and workflows secure, you already have a good understanding of common vulnerabilities in GitHub Actions and how to solve them.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://securitylab.github.com/resources/github-actions-preventing-pwn-requests/\"\u003eKeeping your GitHub Actions and workflows secure Part 1: Preventing pwn requests\u003c/a\u003e  \u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://securitylab.github.com/resources/github-actions-untrusted-input/\"\u003eKeeping your GitHub Actions and workflows secure Part 2: Untrusted input\u003c/a\u003e  \u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://securitylab.github.com/resources/github-actions-building-blocks/\"\u003eKeeping your GitHub Actions and workflows secure Part 3: How to trust your building blocks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUnfortunately, we found that these vulnerabilities are still quite common, mostly because of a lack of awareness of how the moving parts interact with each other and what the impact of these vulnerabilities may be for your organization or repository.\u003c/p\u003e\n\u003cp\u003eTo help prevent the introduction of vulnerabilities, identify them in existing workflows, and even fix them using GitHub Copilot Autofix, \u003ca href=\"https://github.blog/changelog/2024-12-17-find-and-fix-actions-workflows-vulnerabilities-with-codeql-public-preview/\"\u003eCodeQL support has been added for GitHub Actions\u003c/a\u003e. The new CodeQL packs can be used by code scanning to scan both existing and new workflows. As code scanning and Copilot Autofix are free for OSS repositories, all public GitHub repositories will have access to these new queries, empowering detection and remediation of these vulnerabilities.\u003c/p\u003e\n\u003cp\u003eIn the rest of this post, we’ll see\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat we added to our existing CodeQL support, including actions as a first-class language, taint tracking, bash support;  \u003c/li\u003e\n\u003cli\u003eWhat models and queries we developed;  \u003c/li\u003e\n\u003cli\u003eWhat vulnerabilities and what new patterns we discovered as part of this work.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"previous-attempt\" id=\"previous-attempt\"\u003ePrevious attempt\u003ca href=\"#previous-attempt\" aria-label=\"Previous attempt\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePreviously, there was a \u003ca href=\"https://github.com/github/codeql/blob/2cbb0726689e3c6cb213eab2b3fc4b4e7d8119a4/javascript/ql/src/Security/CWE-094/ExpressionInjection.qhelp\"\u003esingle CodeQL query\u003c/a\u003e capable of identifying simplistic code injections in GitHub workflows. However, this query had several limitations. First, it was bundled with the JavaScript QL packs, meaning users had to enable JavaScript scanning even if they had no JavaScript code in their repositories, which was confusing and misleading. Additionally, the representation of GitHub workflow syntax and grammar was incomplete, making it difficult to express more complex patterns using the existing Abstract Syntax Tree (AST) of GitHub Actions, which is used by static analysis tools such as CodeQL. Most importantly, the CodeQL support for GitHub workflows did not previously include Taint Tracking support and models for non-straightforward sources of untrusted data or dangerous operations.\u003c/p\u003e\n\u003ch2 id=\"taint-tracking-is-key\" id=\"taint-tracking-is-key\"\u003eTaint Tracking is key!\u003ca href=\"#taint-tracking-is-key\" aria-label=\"Taint Tracking is key!\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eSo what is Taint Tracking and how important is it?\u003c/p\u003e\n\u003cp\u003eThrough the \u003ca href=\"https://github.com/github/codeql/blob/2cbb0726689e3c6cb213eab2b3fc4b4e7d8119a4/javascript/ql/src/Security/CWE-094/ExpressionInjection.qhelp\"\u003eprevious query for Code Injection\u003c/a\u003e, we were able to identify simplistic vulnerabilities such as those cases where a known user-controlled property gets directly interpolated into a Run script:\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/01/run-script.png?w=674\u0026amp;resize=674%2C57\" alt=\"Code snippet through which a known user-controlled property gets directly interpolated into a Run script\" width=\"674\" height=\"57\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/01/run-script.png?w=674 674w, https://github.blog/wp-content/uploads/2025/01/run-script.png?w=300 300w\" sizes=\"auto, (max-width: 674px) 100vw, 674px\"/\u003e\u003c/p\u003e\n\u003cp\u003eThat was a great starting point, but what about cases such as the following?\u003c/p\u003e\n\u003cp\u003eThe first step of the path is the download of an artifact.\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/01/artifact-download.png?w=1024\u0026amp;resize=1024%2C465\" alt=\"Code snippet representing an artifact download\" width=\"1024\" height=\"465\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/01/artifact-download.png?w=1197 1197w, https://github.blog/wp-content/uploads/2025/01/artifact-download.png?w=300 300w, https://github.blog/wp-content/uploads/2025/01/artifact-download.png?w=768 768w, https://github.blog/wp-content/uploads/2025/01/artifact-download.png?w=1024 1024w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe second and third steps are setting the content of a file from the artifact as the output of the workflow step.\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/01/step-2-and-3.png?w=1024\u0026amp;resize=1024%2C593\" alt=\"Code snippets setting the content of a file from the artifact as the output of the workflow step\" width=\"1024\" height=\"593\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/01/step-2-and-3.png?w=1194 1194w, https://github.blog/wp-content/uploads/2025/01/step-2-and-3.png?w=300 300w, https://github.blog/wp-content/uploads/2025/01/step-2-and-3.png?w=768 768w, https://github.blog/wp-content/uploads/2025/01/step-2-and-3.png?w=1024 1024w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/p\u003e\n\u003cp\u003eIn the last step, the value from the previous step is interpolated in an unsafe manner in a Run script leading to a potential code injection.\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/01/potential-code-injection.png?w=1024\u0026amp;resize=1024%2C303\" alt=\"Code snippet identifying a potential code injection\" width=\"1024\" height=\"303\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/01/potential-code-injection.png?w=1191 1191w, https://github.blog/wp-content/uploads/2025/01/potential-code-injection.png?w=300 300w, https://github.blog/wp-content/uploads/2025/01/potential-code-injection.png?w=768 768w, https://github.blog/wp-content/uploads/2025/01/potential-code-injection.png?w=1024 1024w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/p\u003e\n\u003cp\u003eIn the case above, the source of untrusted data is not simply a GitHub Event Context access of a known untrusted property (for example, \u003ccode\u003egithub.event.pull_request.body\u003c/code\u003e) but rather the download of an artifact. Should all artifacts be considered untrusted? Certainly not. However, in this instance, where the workflow is triggered by a \u003ccode\u003eworkflow_run\u003c/code\u003e event with no branch filters and where an artifact is downloaded from the triggering workflow (\u003ccode\u003egithub.event.workflow_run.workflow_id\u003c/code\u003e), the artifact should be considered untrusted. When decompressed, it may pollute the Runner’s workspace by writing to files in unexpected locations. Consequently, from that step onward, all files in the workspace should be considered untrusted. This example highlights a non-trivial pattern that we need to express using the new actions AST representation to identify sources of untrusted data.\u003c/p\u003e\n\u003cp\u003eIdentifying sources of untrusted data is only the first step towards uncovering more complex injection vulnerabilities. In the example above, it is crucial to understand Bash scripts to determine if they are reading from untrusted files and inserting data into shell variables. It is essential to comprehend how these variables may flow into the output of a step, and, subsequently, how the output flows through different steps, jobs, composite actions, or reusable workflows until they reach a potentially dangerous sink. This understanding is what Taint Tracking and Control Flow will achieve.\u003c/p\u003e\n\u003cp\u003eIn summary, as illustrated in the CodeQL alert above, we can now identify non-obvious sources of untrusted data (for example, \u003ccode\u003egit\u003c/code\u003e or \u003ccode\u003egh\u003c/code\u003e commands or third-party actions) and, more importantly, track this untrusted data throughout complex workflows. These workflows involve multiple steps, jobs, actions, and even entire workflows, allowing us to better understand where this data is used and to report potential vulnerabilities effectively.\u003c/p\u003e\n\u003ch2 id=\"bash-support\" id=\"bash-support\"\u003eBash support\u003ca href=\"#bash-support\" aria-label=\"Bash support\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eGitHub’s workflows can execute various scripts, with Bash scripts being among the most common. The new CodeQL packs for GitHub Actions offer basic support for Bash, helping to identify tainted data originating from Bash scripts. For example, commands such as \u003ccode\u003egit diff-tree\u003c/code\u003e obtain a list of changed files. Tainted data can flow through a script when reading an attacker-controlled file or environment variable into a step’s output or another environment variable. A pertinent example of such a vulnerability could be found in a workflow of Azure CLI repository.\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/01/environment-variabl.png?w=1024\u0026amp;resize=1024%2C326\" alt=\"environment variable built from user-controlled sources\" width=\"1024\" height=\"326\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/01/environment-variabl.png?w=1190 1190w, https://github.blog/wp-content/uploads/2025/01/environment-variabl.png?w=300 300w, https://github.blog/wp-content/uploads/2025/01/environment-variabl.png?w=768 768w, https://github.blog/wp-content/uploads/2025/01/environment-variabl.png?w=1024 1024w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" src=\"https://github.blog/wp-content/uploads/2025/01/step2.png?w=1024\u0026amp;resize=1024%2C457\" alt=\"Code snippet showing how untrusted data, such as a pull request’s title, is assigned to the TITLE environment variable\" width=\"1024\" height=\"457\" loading=\"lazy\" srcset=\"https://github.blog/wp-content/uploads/2025/01/step2.png?w=1193 1193w, https://github.blog/wp-content/uploads/2025/01/step2.png?w=300 300w, https://github.blog/wp-content/uploads/2025/01/step2.png?w=768 768w, https://github.blog/wp-content/uploads/2025/01/step2.png?w=1024 1024w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/p\u003e\n\u003cp\u003eIn the alert above, we can see how untrusted data, such as a pull request’s title, is assigned to the \u003ccode\u003eTITLE\u003c/code\u003e environment variable. This variable is then read and processed by several commands, resulting in a new message variable that gets redirected to the special file pointed to by the \u003ccode\u003eGITHUB_ENV\u003c/code\u003e variable. A malicious actor could craft a title that results in a multiline \u003ccode\u003emessage\u003c/code\u003e, allowing them to inject arbitrary environment variables into subsequent steps. This, in turn, would enable the attacker to exfiltrate secrets used in the workflow.\u003c/p\u003e\n\u003cp\u003eThe new CodeQL packs are able to parse Bash scripts. While they don’t yet generate a full AST, they already allow us to understand elements such as assignments, pipelines, and redirections, enabling us to report subtle vulnerabilities like the one mentioned above.\u003c/p\u003e\n\u003ch2 id=\"models\" id=\"models\"\u003eModels\u003ca href=\"#models\" aria-label=\"Models\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAs explained in “\u003ca href=\"https://securitylab.github.com/resources/github-actions-untrusted-input/\"\u003eKeeping your GitHub Actions and workflows secure Part 2: Untrusted input\u003c/a\u003e,” GitHub’s event context is the most common source of untrusted data. Properties such as \u003ccode\u003egithub.event.issue.title\u003c/code\u003e, \u003ccode\u003egithub.event.pull_request.head.ref\u003c/code\u003e, or \u003ccode\u003egithub.event.comment.body\u003c/code\u003e are typical sources of untrusted data. However, any third-party action may introduce untrusted data. For instance, an action that returns a list of filenames changed in a pull request should be considered a source of untrusted data. Similarly, actions that parse an issue body or comment for a command or structured data should also be treated as sources of untrusted data.\u003c/p\u003e\n\u003cp\u003eThe same applies to actions that pass data from one of their inputs to their outputs or into an environment variable, therefore acting as taint steps (summaries). Actions such as \u003ccode\u003eactions/github-script\u003c/code\u003e, \u003ccode\u003eazure/cli\u003c/code\u003e, or \u003ccode\u003eazure/powershell\u003c/code\u003e should be considered sinks for Code Injection, similar to a Run’s step.\u003c/p\u003e\n\u003cp\u003eWe have analyzed thousands of popular third-party actions and identified a number of models now incorporated into the analysis:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e62 sources  \u003c/li\u003e\n\u003cli\u003e129 summaries  \u003c/li\u003e\n\u003cli\u003e2199 sinks\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"queries\" id=\"queries\"\u003eQueries\u003ca href=\"#queries\" aria-label=\"Queries\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThe previous support for GitHub Actions contained a single query for code injection, whereas the new CodeQL packs incorporate 18 new queries, including the Code Injection and Environment Variable Injection queries mentioned above.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExecution of Untrusted Code  \u003c/li\u003e\n\u003cli\u003eExecution of Untrusted Code (TOCTOU)  \u003c/li\u003e\n\u003cli\u003eArtifact Poisoning  \u003c/li\u003e\n\u003cli\u003eCode Injection  \u003c/li\u003e\n\u003cli\u003eEnvironment Variable Injection  \u003c/li\u003e\n\u003cli\u003ePath Injection  \u003c/li\u003e\n\u003cli\u003eUnpinned Action Tag  \u003c/li\u003e\n\u003cli\u003eImproper Access Control  \u003c/li\u003e\n\u003cli\u003eExcessive Secrets Exposure  \u003c/li\u003e\n\u003cli\u003eSecrets In Artifacts  \u003c/li\u003e\n\u003cli\u003eExpression is Always True  \u003c/li\u003e\n\u003cli\u003eUnmasked Secret Exposure  \u003c/li\u003e\n\u003cli\u003eCache Poisoning (Code Injection, Direct Cache, Untrusted Code)  \u003c/li\u003e\n\u003cli\u003eUse of Known Vulnerable Actions  \u003c/li\u003e\n\u003cli\u003eMissing Action Permissions  \u003c/li\u003e\n\u003cli\u003eArgument Injection (Experimental)  \u003c/li\u003e\n\u003cli\u003eCode Execution on Self Hosted Runners (Experimental)  \u003c/li\u003e\n\u003cli\u003eOutput Clobbering (Experimental)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"results\" id=\"results\"\u003eResults\u003ca href=\"#results\" aria-label=\"Results\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eFor the past few months, we have been testing the new queries on thousands of open source projects to validate their accuracy and performance. The results have been very impressive, allowing us to identify and report vulnerabilities in numerous critical organizations and repositories, such as Microsoft, Azure, GitHub, Eclipse, Jupyter, Adobe, AWS, Cloudflare, Discord, Hibernate, HuggingFace, and Apache.\u003c/p\u003e\n\u003cp\u003eThe table below shows all the repositories affected, along with their GitHub stars, to give an idea of the impact that a supply chain attack could have had in these projects:\u003c/p\u003e\n\u003cdiv\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eRepository\u003c/th\u003e\n\u003cth\u003eStars\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eant-design/ant-design\u003c/td\u003e\n\u003ctd\u003e92,412\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eExcalidraw/excalidraw\u003c/td\u003e\n\u003ctd\u003e84,021\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eapache/superset\u003c/td\u003e\n\u003ctd\u003e62,589\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ewithastro/astro\u003c/td\u003e\n\u003ctd\u003e46,604\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eStirling-Tools/Stirling-PDF\u003c/td\u003e\n\u003ctd\u003e44,988\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egeekan/MetaGPT\u003c/td\u003e\n\u003ctd\u003e44,901\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eKong/kong\u003c/td\u003e\n\u003ctd\u003e39,221\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLAION-AI/Open-Assistant\u003c/td\u003e\n\u003ctd\u003e37,045\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eappsmithorg/appsmith\u003c/td\u003e\n\u003ctd\u003e34,352\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egradio-app/gradio\u003c/td\u003e\n\u003ctd\u003e33,709\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDIYgod/RSSHub\u003c/td\u003e\n\u003ctd\u003e33,432\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecalcom/cal.com\u003c/td\u003e\n\u003ctd\u003e32,282\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emilvus-io/milvus\u003c/td\u003e\n\u003ctd\u003e30,299\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ek3s-io/k3s\u003c/td\u003e\n\u003ctd\u003e28,010\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ediscordjs/discord.js\u003c/td\u003e\n\u003ctd\u003e25,390\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eelement-plus/element-plus\u003c/td\u003e\n\u003ctd\u003e24,488\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecilium/cilium\u003c/td\u003e\n\u003ctd\u003e20,150\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emonkeytypegame/monkeytype\u003c/td\u003e\n\u003ctd\u003e15,635\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eamplication/amplication\u003c/td\u003e\n\u003ctd\u003e15,196\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edocker-mailserver/docker-mailserver\u003c/td\u003e\n\u003ctd\u003e14,643\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ejupyterlab/jupyterlab\u003c/td\u003e\n\u003ctd\u003e14,167\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eopenimsdk/open-im-server\u003c/td\u003e\n\u003ctd\u003e14,041\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003equarkusio/quarkus\u003c/td\u003e\n\u003ctd\u003e13,771\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eespressif/arduino-esp32\u003c/td\u003e\n\u003ctd\u003e13,609\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esympy/sympy\u003c/td\u003e\n\u003ctd\u003e12,967\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eionic-team/stencil\u003c/td\u003e\n\u003ctd\u003e12,561\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ezephyrproject-rtos/zephyr\u003c/td\u003e\n\u003ctd\u003e10,819\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eqgis/QGIS\u003c/td\u003e\n\u003ctd\u003e10,569\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003etrinodb/trino\u003c/td\u003e\n\u003ctd\u003e10,413\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eOpenFeign/feign\u003c/td\u003e\n\u003ctd\u003e9,490\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emarimo-team/marimo\u003c/td\u003e\n\u003ctd\u003e7,583\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edream-num/univer\u003c/td\u003e\n\u003ctd\u003e7,021\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eaws/karpenter-provider-aws\u003c/td\u003e\n\u003ctd\u003e6,782\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ehibernate/hibernate-orm\u003c/td\u003e\n\u003ctd\u003e5,976\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eant-design-blazor/ant-design-blazor\u003c/td\u003e\n\u003ctd\u003e5,809\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003elitestar-org/litestar\u003c/td\u003e\n\u003ctd\u003e5,511\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/div\u003e\n\u003ch2 id=\"new-vulnerability-patterns\" id=\"new-vulnerability-patterns\"\u003eNew vulnerability patterns\u003ca href=\"#new-vulnerability-patterns\" aria-label=\"New vulnerability patterns\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHaving triaged and reported numerous alerts, we have identified some common patterns that often lead to vulnerabilities in GitHub workflows:\u003c/p\u003e\n\u003ch3 id=\"misuse-of-pull_request_target-trigger\" id=\"misuse-of-pull_request_target-trigger\"\u003eMisuse of \u003ccode\u003epull_request_target trigger\u003c/code\u003e\u003ca href=\"#misuse-of-pull_request_target-trigger\" aria-label=\"Misuse of \u0026lt;code\u0026gt;pull_request_target trigger\u0026lt;/code\u0026gt;\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003epull_request_target\u003c/code\u003e event trigger, while offering powerful automation capabilities in GitHub Actions, harbors a dark side filled with potential security pitfalls. This event trigger, designed to execute workflows within the context of pull request’s base branch, presents special characteristics that severely increase the impact in case of any vulnerability. A workflow activated by \u003ccode\u003epull_request_target\u003c/code\u003e and triggered from a fork operates with significant privileges, in contrast to the \u003ccode\u003epull_request\u003c/code\u003e event:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt is able to read repository and organization secrets.  \u003c/li\u003e\n\u003cli\u003eIt is allowed to have write permissions.  \u003c/li\u003e\n\u003cli\u003eIt circumvents the usual safeguards of pull request approvals, allowing workflows to run unimpeded even if approval mechanisms are configured for standard \u003ccode\u003epull_request\u003c/code\u003e events.  \u003c/li\u003e\n\u003cli\u003eIt normally runs in the context of the default branch, which, as we will see, may allow malicious actors to poison the action’s cache and move laterally to other, more privileged workflows even when removing all permissions to the vulnerable workflow.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhen working with \u003ccode\u003epull_request_triggered\u003c/code\u003e workflows, we have to be very careful and pay special attention to the following scenarios:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCode execution from untrusted sources:\u003c/strong\u003e The ability to execute code from forked pull requests is a double-edged sword. A malicious actor can submit a seemingly innocuous pull request that, when triggered by \u003ccode\u003epull_request_target\u003c/code\u003e, unleashes havoc. This malicious code, running in the context of the target repository’s environment, could exfiltrate secrets or even tamper with repository contents and releases. The danger lies in the inadvertent checkout and execution of code from untrusted sources. Common mistakes include using the \u003ccode\u003eactions/checkout\u003c/code\u003e action with a reference to the pull request’s head branch.\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTime of check to time of use (TOCTOU) attacks\u003c/strong\u003e. Even with approval requirements in place (such as requiring the pull request to have a specific label that attackers are not able to set on their own), attackers can leverage the element of time to bypass security measures. A malicious actor can submit a seemingly harmless pull request, patiently wait for approval, and then swiftly update the pull request with malicious code before the workflow execution. The workflow, relying on a mutable reference like a branch name, falls prey to this \u003ca href=\"https://github.com/AdnaneKhan/ActionsTOCTOU\"\u003e“time of check to time of use” (TOCTOU) attack\u003c/a\u003e, unwittingly executing the newly injected malicious code. Confusion surrounding context variables, specifically \u003ccode\u003ehead.ref\u003c/code\u003e and \u003ccode\u003ehead.sha\u003c/code\u003e, can lead to vulnerabilities.  \u003ccode\u003ehead.ref\u003c/code\u003e, pointing to the branch, is susceptible to manipulation by attackers. In contrast, \u003ccode\u003ehead.sha\u003c/code\u003e, referencing the specific commit, provides a reliable and immutable pointer to the reviewed and approved code. Using the incorrect variable can create an opening for attackers to inject malicious code after approval.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eLurking threats in non-default branches\u003c/strong\u003e. Vulnerabilities often linger in non-default branches, even after being addressed in the default branch. An attacker can target these vulnerable versions of the workflows residing in non-default branches, exploiting them by submitting pull requests specifically to those branches.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eCache poisoning\u003c/strong\u003e. As a mitigation, developers may strip out all read and write permissions from these workflows when in need to run untrusted code. However, the seemingly innocuous \u003ccode\u003epermissions: {}\u003c/code\u003e configuration can unexpectedly pave the way for \u003ca href=\"https://adnanthekhan.com/2024/05/06/the-monsters-in-your-build-cache-github-actions-cache-poisoning/\"\u003ecache poisoning attacks\u003c/a\u003e. This attack vector involves injecting malicious content into the cache, which can subsequently affect other workflows relying on the poisoned cache entries. Even if a workflow doesn’t have write access to the repository, it can still poison the cache, leading to potential code execution or data manipulation in other workflows that utilize the compromised cache.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf we really need to use this trigger event, there are a few ways to harden the workflows to prevent any abuses:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eRepository checks\u003c/strong\u003e. Implementing stringent repository checks is crucial for thwarting attacks originating from forked pull requests. One effective method is to configure workflows to execute only for pull requests originating from the base repository, effectively blocking any attempts from external forks. This can be achieved by using conditions such as \u003ccode\u003egithub.event.pull_request.head.repo.owner.login == “myorg”\u003c/code\u003e to restrict workflow execution.\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eActor checks\u003c/strong\u003e. Verifying the permissions of the pull request author is another layer of defense. By restricting workflow execution to trusted actors, such as members of the organization or approved collaborators, the risk of malicious code injection from unauthorized sources can be significantly reduced. Never use a hardcoded list of user names, since the users may lose the permissions with time or the user names may be left abandoned for an attacker to claim.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWorkflow splitting\u003c/strong\u003e. The above mitigations may not be useful if we need to run a workflow for forks or arbitrary users. In those cases, splitting workflows into unprivileged and privileged components is a powerful security strategy. Unprivileged workflows, triggered by \u003ccode\u003epull_request\u003c/code\u003e events, handle the initial processing of pull requests without access to sensitive secrets or write permissions. Privileged workflows, activated by \u003ccode\u003eworkflow_run\u003c/code\u003e events, are invoked only after the unprivileged workflow has completed its checks. This separation ensures that potentially malicious code from forked pull requests never executes within a privileged context. The unprivileged workflow will generally need to communicate and pass information to the privileged one. This is a \u003cstrong\u003ecrucial security boundary\u003c/strong\u003e, and, as we will see in the next section, any data coming from the unprivileged workflow should be considered untrusted and potentially dangerous.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"security-boundaries-and-workflow_run-event\" id=\"security-boundaries-and-workflow_run-event\"\u003eSecurity boundaries and \u003ccode\u003eworkflow_run event\u003c/code\u003e\u003ca href=\"#security-boundaries-and-workflow_run-event\" aria-label=\"Security boundaries and \u0026lt;code\u0026gt;workflow_run event\u0026lt;/code\u0026gt;\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eworkflow_run\u003c/code\u003e event trigger in GitHub Actions is designed to automate tasks based on the execution or completion of another workflow. It may grant write permissions and access to secrets even if the triggering workflow doesn’t have such privileges. While this is beneficial for tasks like labeling pull requests based on test results, it poses significant security risks if not used carefully.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003eworkflow_run\u003c/code\u003e trigger poses a risk because it can often be initiated by an attacker. Some maintainers were surprised by this, believing that their triggering workflows, which were run on events such as \u003ccode\u003erelease\u003c/code\u003e, were safe. This assumption was based on the idea that since an attacker couldn’t trigger a new release, they shouldn’t be able to initiate the triggering workflow or the subsequent \u003ccode\u003eworkflow_run\u003c/code\u003e workflow.\u003c/p\u003e\n\u003cp\u003eThe reality is that an attacker can submit a pull request that modifies the triggering workflow and even replace the triggering events. Since \u003ccode\u003epull_request\u003c/code\u003e workflows run in the context of the pull request’s \u003ccode\u003eHEAD\u003c/code\u003e branch, the modified workflow will run and, upon completion, will be able to trigger an existing \u003ccode\u003eworkflow_run\u003c/code\u003e workflow. The danger arises from the fact that even if the triggering \u003ccode\u003epull_request\u003c/code\u003e workflow is not privileged, the triggered \u003ccode\u003eworkflow_run\u003c/code\u003e workflow will have access to secrets and write-scoped tokens, even if the initial workflow did not have those privileges. This enables privilege escalation attacks, allowing attackers to execute malicious code with elevated permissions within the CI/CD pipeline.\u003c/p\u003e\n\u003cp\u003eAnother significant pitfall with the \u003ccode\u003eworkflow_run\u003c/code\u003e event trigger is artifact poisoning. Artifacts are files generated during a workflow run that can be shared with other workflows. Attackers can poison these artifacts by uploading malicious content through a pull request. When a \u003ccode\u003eworkflow_run\u003c/code\u003e workflow downloads and uses these poisoned artifacts, it can lead to arbitrary code execution or other malicious activities within the privileged workflow. The issue is that many \u003ccode\u003eworkflow_run\u003c/code\u003e workflows do not verify the contents of downloaded artifacts before using them, making them vulnerable to various attacks.\u003c/p\u003e\n\u003cp\u003eSecuring \u003ccode\u003eworkflow_run\u003c/code\u003e workflows requires a multi-faceted approach. By understanding the inherent risks and implementing the recommended mitigations, developers can leverage the automation benefits of \u003ccode\u003eworkflow_run\u003c/code\u003e while minimizing the potential for security compromises.\u003c/p\u003e\n\u003ch4 id=\"effective-mitigations\" id=\"effective-mitigations\"\u003eEffective mitigations\u003ca href=\"#effective-mitigations\" aria-label=\"Effective mitigations\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLimit workflow scope with branch filters:\u003c/strong\u003e Specify the branches where \u003ccode\u003eworkflow_run\u003c/code\u003e workflows can be triggered using the \u003ccode\u003ebranches\u003c/code\u003e filter. This helps restrict the scope of potential attacks by preventing them from being triggered on branches from forks.\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eVerify event origin:\u003c/strong\u003e Incorporate a check like \u003ccode\u003egithub.event_name != \u0026#39;pull_request\u0026#39;\u003c/code\u003e to prevent \u003ccode\u003eworkflow_run\u003c/code\u003e workflows from being triggered by pull requests from forks. This adds an extra layer of protection by ensuring that the triggering workflow originates from a trusted source.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTreat artifacts as untrusted:\u003c/strong\u003e Treat all downloaded artifacts as potentially malicious and implement rigorous validation checks before using them. Always unzip artifacts to a temporary directory like \u003ccode\u003e/tmp\u003c/code\u003e to prevent potential file overwrites, that is, the pollution of the workspace.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAvoid defining environment variables:\u003c/strong\u003e Minimize the use of environment variables, especially when handling untrusted data. Environment variables can be vulnerable to injection attacks, potentially allowing attackers to modify their values and execute malicious code.\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eHandle output variables with caution:\u003c/strong\u003e Exercise caution when defining output variables from artifact’s content, as they can also be vulnerable to manipulation by attackers. Always validate the contents of output variables (for example, that it is a number, not a string) before using them in subsequent steps or other workflows.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"non-effective-mitigations\" id=\"non-effective-mitigations\"\u003eNon-effective mitigations\u003ca href=\"#non-effective-mitigations\" aria-label=\"Non-effective mitigations\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eRepository checks:\u003c/strong\u003e We found several workflows (for example, \u003ca href=\"https://securitylab.github.com/advisories/GHSL-2024-314_AWS_Karpenter_Provider/\"\u003eAWS Karpenter Provider\u003c/a\u003e, or \u003ca href=\"https://securitylab.github.com/advisories/GHSL-2024-252_Cloudflare_workers-sdk/\"\u003eCloudflare Workers SDK\u003c/a\u003e) relying solely on repository checks, such as verifying the repository owner (\u003ccode\u003egithub.repository_owner == \u0026#39;myorg\u0026#39;\u003c/code\u003e), which is not effective in mitigating \u003ccode\u003eworkflow_run\u003c/code\u003e risks since the workflow always runs in the context of the default branch which belongs to the organization.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe \u003ccode\u003eissue_comment\u003c/code\u003e event trigger in GitHub Actions is a powerful tool for automating workflows based on comments on issues and pull requests. When applied in the context of \u003ca href=\"https://issue-ops.github.io/docs/\"\u003eIssueOps\u003c/a\u003e, it can streamline tasks like running commands in response to specific comments. However, this convenience comes with significant security risks that must be carefully considered.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTOCTOU vulnerabilities:\u003c/strong\u003e Similar to the \u003ccode\u003epull_request_target\u003c/code\u003e event trigger, workflows using \u003ccode\u003eissue_comment\u003c/code\u003e can be vulnerable to \u003ca href=\"https://github.com/AdnaneKhan/ActionsTOCTOU\"\u003eTOCTOU attacks\u003c/a\u003e. If the workflow checks out and executes code from a pull request based on an issue comment, an attacker could exploit the time window between the comment and the workflow execution. An attacker might initially submit a harmless pull request, waiting for an administrator to review and approve the workflow by adding a comment. Once the approval is given, the attacker could quickly update the pull request with malicious code, which would then be executed by the workflow.\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eBypassing pull request approval mechanisms:\u003c/strong\u003e The \u003ccode\u003eissue_comment\u003c/code\u003e event trigger is not subject to the pull request approval mechanisms intended to prevent abuse. Even if the workflows triggered by \u003ccode\u003epull request\u003c/code\u003e require approvals, an attacker can trigger an \u003ccode\u003eissue_comment\u003c/code\u003e workflow by simply adding a comment to the pull request, potentially executing malicious code without any review.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"mitigating-the-risks\" id=\"mitigating-the-risks\"\u003eMitigating the risks\u003ca href=\"#mitigating-the-risks\" aria-label=\"Mitigating the risks\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eShifting to label gates:\u003c/strong\u003e Instead of relying on issue comments to trigger critical workflows, consider adopting a label gates approach. Label gates use labels to trigger specific actions, allowing for more granular control and better security. Since the labeled activity type for a \u003ccode\u003epull_request\u003c/code\u003e trigger contains details about the latest commit SHA of the pull request, there is no need for workflow to resolve a pull request number into the latest commit SHA, as it is the case with \u003ccode\u003eissue_comment\u003c/code\u003e, and, therefore, there is no window for an attacker to modify the pull request. Remember to use the commit SHA rather than the HEAD reference to prevent \u003ca href=\"https://github.com/AdnaneKhan/ActionsTOCTOU\"\u003eTOCTOU vulnerabilities\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"ineffective-or-incomplete-mitigations\" id=\"ineffective-or-incomplete-mitigations\"\u003eIneffective or incomplete mitigations\u003ca href=\"#ineffective-or-incomplete-mitigations\" aria-label=\"Ineffective or incomplete mitigations\"\u003e\u003c/a\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eActor checks:\u003c/strong\u003e Relying solely on actor checks (verifying the identity or permissions of the commenter) is ineffective. The actor triggering the workflow might not be the same one trying to exploit it, further rendering actor checks unreliable. This is the case for TOCTOU vulnerabilities where an attacker can submit a legitimate pull request and wait for an admin to trigger an IssueOp and then swiftly mutate the pull request by adding a new commit with malicious code on it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDate checks:\u003c/strong\u003e Comparing timestamps to verify that the last commit occurred before the triggering comment is also unreliable. Currently, GitHub has no reliable way to figure out the date when a commit was pushed to a repository. An attacker can forge commit dates, rendering these checks useless in preventing malicious code execution.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eRepository checks:\u003c/strong\u003e Verifying the origin repository is not a useful mitigation for \u003ccode\u003eissue_comment\u003c/code\u003e event triggers. The \u003ccode\u003eissue_comment\u003c/code\u003e event always executes within the context of the target repository’s default branch, making repository checks redundant.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"wrapping-up\" id=\"wrapping-up\"\u003eWrapping up\u003ca href=\"#wrapping-up\" aria-label=\"Wrapping up\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.blog/changelog/2024-12-17-find-and-fix-actions-workflows-vulnerabilities-with-codeql-public-preview/\"\u003eThe new CodeQL support for GitHub Actions is in public preview\u003c/a\u003e. The new QL packs allow you to scan your repository for a variety of vulnerabilities in GitHub Actions, helping prevent supply chain attacks in the OSS software we all depend on! If you want to give them a try, take one of the following steps depending on your case:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYour repository is newly configured for \u003ca href=\"https://docs.github.com/en/code-security/code-scanning/enabling-code-scanning/configuring-default-setup-for-code-scanning\"\u003edefault setup\u003c/a\u003e: Code scanning will automatically attempt to analyze actions if any workflows are present on the default branch. You have nothing to do; keep calm and fix the potential alerts.  \u003c/li\u003e\n\u003cli\u003eYour repository is already configured for default setup: You need to edit the Default Setup settings and explicitly enable actions analysis.  \u003c/li\u003e\n\u003cli\u003eYour repository is using advanced setup: You just have to add \u003ccode\u003eactions\u003c/code\u003e to the language matrix.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStay secure!\u003c/p\u003e\n\n\t\n\n\t\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tWritten by\t\u003c/h2\u003e\n\t\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/125701?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/125701?v=4\u0026amp;s=200\" alt=\"Alvaro Munoz\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\u003c/div\u003e",
  "readingTime": "26 min read",
  "publishedTime": "2025-01-09T17:00:59Z",
  "modifiedTime": "2025-01-09T21:27:11Z"
}
