{
  "id": "28c1b5a9-20cf-4796-afc2-5bdc19d4bae5",
  "title": "Bringing developer choice to Copilot with Anthropicâ€™s Claude 3.5 Sonnet, Googleâ€™s Gemini 1.5 Pro, and OpenAIâ€™s o1-preview",
  "link": "https://github.blog/news-insights/product-news/bringing-developer-choice-to-copilot/",
  "description": "At GitHub Universe, we announced Anthropicâ€™s Claude 3.5 Sonnet, Googleâ€™s Gemini 1.5 Pro, and OpenAIâ€™s o1-preview and o1-mini are coming to GitHub Copilotâ€”bringing a new level of choice to every developer. The post Bringing developer choice to Copilot with Anthropicâ€™s Claude 3.5 Sonnet, Googleâ€™s Gemini 1.5 Pro, and OpenAIâ€™s o1-preview appeared first on The GitHub Blog.",
  "author": "Thomas Dohmke",
  "published": "Tue, 29 Oct 2024 16:08:30 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "News \u0026 insights",
    "Product",
    "AI",
    "GitHub Copilot"
  ],
  "byline": "Thomas Dohmke",
  "length": 5523,
  "excerpt": "At GitHub Universe, we announced Anthropicâ€™s Claude 3.5 Sonnet, Googleâ€™s Gemini 1.5 Pro, and OpenAIâ€™s o1-preview and o1-mini are coming to GitHub Copilotâ€”bringing a new level of choice to every developer.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "GitHub Copilot has long leveraged different large language models (LLMs) for different use cases. The first public version of Copilot was launched using Codex, an early version of OpenAI GPT-3, specifically fine-tuned for coding tasks. Copilot Chat was launched in 2023 with GPT-3.5 and later GPT-4. Since then, we have updated the base model versions multiple times, using a range from GPT 3.5-turbo to GPT 4o and 4o-mini models for different latency and quality requirements. In the past year, we experienced a boom in high-quality small and large language models that individually excel at different programming tasks. It is clear the next phase of AI code generation will not only be defined by multi-model functionality, but by multi-model choice. GitHub is committed to its ethos as an open developer platform, and ensuring every developer has the agency to build with the models that work best for them. Today at GitHub Universe, we delivered just that. https://github.blog/wp-content/uploads/2024/10/u24_model_picker_1080p.mp4#t=0.001 We are bringing developer choice to GitHub Copilot with Anthropicâ€™s Claude 3.5 Sonnet, Googleâ€™s Gemini 1.5 Pro, and OpenAIâ€™s o1-preview and o1-mini. These new models will be rolling outâ€”first in Copilot Chat, with OpenAI o1-preview and o1-mini available now, Claude 3.5 Sonnet rolling out progressively over the next week, and Googleâ€™s Gemini 1.5 Pro in the coming weeks. From Copilot Workspace to multi-file editing to code review, security autofix, and the CLI, we will bring multi-model choice across many of GitHub Copilotâ€™s surface areas and functions soon. Whether itâ€™s in VS Code or on GitHub.com, individual developers can now decide which models work best for them, while organizations and enterprises have full control over which models they enable for their team. Try multi-model Copilot today. Anthropicâ€™s Claude 3.5 Sonnet Anthropicâ€™s new Claude 3.5 Sonnet excels at coding tasks across the entire software development lifecycleâ€”from initial design to bug fixes, maintenance to optimizations. Claude 3.5 Sonnet demonstrates high proficiency with complex and multi-step coding tasks, handling everything from legacy app updates to code refactoring and feature development. https://github.blog/wp-content/uploads/2024/10/u24_claude_1080_f41df1.mp4#t=0.001 Googleâ€™s Gemini 1.5 Pro The latest Gemini models from Google show high capabilities in coding scenarios. Gemini 1.5 Pro features a two-million-token context window and is natively multi-modalâ€”with the ability to process code, images, audio, video, and text simultaneously. Gemini 1.5 Pro also delivers impressive response times for regular code suggestions, documentation, and explaining code. https://github.blog/wp-content/uploads/2024/10/u24_gemini_pro_1080_7bd088.mp4#t=0.001 OpenAIâ€™s o1-preview and o1-mini OpenAI o1-preview and o1-mini are part of a new series of AI models equipped with more advanced reasoning capabilities than GPT 4o. During our exploration using o1-preview with GitHub Copilot, we found the modelâ€™s reasoning capabilities allow for a deeper understanding of code constraints and edge cases, producing efficient and quality results. https://github.blog/wp-content/uploads/2024/10/u24_o1_1080p.mp4#t=0.001 With GitHub Copilot, the developer is in control. Now you can also control which foundational LLM you use, all with a single login and a single subscription. Try multi-model Copilot today. First glimpse: multi-model choice for GitHub Spark In pursuit of GitHubâ€™s vision to reach 1 billion developers, today at Universe we introduced GitHub Spark: the AI-native tool to build applications entirely in natural language. Sparks are fully functional micro apps that can integrate AI features and external data sources without requiring any management of cloud resources. Utilizing a creativity feedback loop, users start with an initial prompt, see live previews of their app as itâ€™s built, easily see options for each of their requests, and automatically save versions of each iteration so they can compare versions as they go. Hereâ€™s a first glimpse, or spark ðŸ˜€, of GitHub Spark. https://github.blog/wp-content/uploads/2024/10/spark_Jer_v2.mp4#t=0.001 Written by Fascinated by software development since his childhood in Germany, Thomas Dohmke has built a career building tools developers love and accelerating innovations that are changing software development. Currently, Thomas is Chief Executive Officer of GitHub, where he has overseen the launch of the world's first at-scale AI developer tool, GitHub Copilot -- and now, GitHub Copilot X. Before his time at GitHub, Thomas previously co-founded HockeyApp and led the company as CEO through its acquisition by Microsoft in 2014, and holds a PhD in mechanical engineering from University of Glasgow, UK. Related posts Explore more from GitHub Docs Everything you need to master GitHub, all in one place. Go to Docs GitHub Build whatâ€™s next on GitHub, the place for anyone from anywhere to build anything. Start building Customer stories Meet the companies and engineering teams that build with GitHub. Learn more GitHub Universe 2024 Get tickets to the 10th anniversary of our global developer event on AI, DevEx, and security. Get tickets",
  "image": "https://github.blog/wp-content/uploads/2024/10/hero-image-github-universe-2024.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003eGitHub Copilot has long leveraged different large language models (LLMs) for different use cases. The first public version of Copilot was launched using Codex, an early version of OpenAI GPT-3, specifically \u003ca href=\"https://arxiv.org/abs/2107.03374\"\u003efine-tuned for coding tasks\u003c/a\u003e. Copilot Chat was launched in 2023 with GPT-3.5 and later GPT-4. Since then, we have updated the base model versions multiple times, using a range from GPT 3.5-turbo to GPT 4o and 4o-mini models for different latency and quality requirements.\u003c/p\u003e\n\u003cp\u003eIn the past year, we experienced a boom in high-quality small and large language models that individually excel at different programming tasks. It is clear the next phase of AI code generation will not only be defined by multi-model functionality, but by multi-model choice. GitHub is committed to its ethos as an open developer platform, and ensuring every developer has the agency to build with the models that work best for them. Today at GitHub Universe, we delivered just that.\u003c/p\u003e\n\u003cp\u003e\n\u003cvideo id=\"video-80819-1\" width=\"1920\" height=\"1080\" autoplay=\"1\" preload=\"metadata\" controls=\"controls\" playsinline=\"1\" muted=\"1\"\u003e\u003csource type=\"video/mp4\" src=\"https://github.blog/wp-content/uploads/2024/10/u24_model_picker_1080p.mp4#t=0.001\"/\u003e\u003ca href=\"https://github.blog/wp-content/uploads/2024/10/u24_model_picker_1080p.mp4#t=0.001\"\u003ehttps://github.blog/wp-content/uploads/2024/10/u24_model_picker_1080p.mp4#t=0.001\u003c/a\u003e\u003c/video\u003e\u003c/p\u003e\n\u003cp\u003eWe are bringing developer choice to GitHub Copilot with Anthropicâ€™s Claude 3.5 Sonnet, Googleâ€™s Gemini 1.5 Pro, and OpenAIâ€™s o1-preview and o1-mini. These new models will be rolling outâ€”first in Copilot Chat, with OpenAI o1-preview and o1-mini available now, Claude 3.5 Sonnet rolling out progressively over the next week, and Googleâ€™s Gemini 1.5 Pro in the coming weeks. From Copilot Workspace to multi-file editing to code review, security autofix, and the CLI, we will bring multi-model choice across many of GitHub Copilotâ€™s surface areas and functions soon.\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003e\n  Whether itâ€™s in VS Code or on GitHub.com, individual developers can now decide which models work best for them, while organizations and enterprises have full control over which models they enable for their team. \u003ca href=\"https://docs.github.com/copilot/using-github-copilot/using-claude-sonnet-in-github-copilot\"\u003eTry multi-model Copilot today\u003c/a\u003e.\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"anthropics-claude-3-5-sonnet\" id=\"anthropics-claude-3-5-sonnet\"\u003eAnthropicâ€™s Claude 3.5 Sonnet\u003ca href=\"#anthropics-claude-3-5-sonnet\" aria-label=\"Anthropicâ€™s Claude 3.5 Sonnet\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAnthropicâ€™s new \u003ca href=\"https://www.anthropic.com/claude/sonnet\"\u003eClaude 3.5 Sonnet \u003c/a\u003eexcels at coding tasks across the entire software development lifecycleâ€”from initial design to bug fixes, maintenance to optimizations. Claude 3.5 Sonnet demonstrates high proficiency with complex and multi-step coding tasks, handling everything from legacy app updates to code refactoring and feature development.\u003c/p\u003e\n\u003cp\u003e\u003cvideo id=\"video-80819-2\" width=\"1920\" height=\"1080\" preload=\"metadata\" controls=\"controls\"\u003e\u003csource type=\"video/mp4\" src=\"https://github.blog/wp-content/uploads/2024/10/u24_claude_1080_f41df1.mp4#t=0.001\"/\u003e\u003ca href=\"https://github.blog/wp-content/uploads/2024/10/u24_claude_1080_f41df1.mp4#t=0.001\"\u003ehttps://github.blog/wp-content/uploads/2024/10/u24_claude_1080_f41df1.mp4#t=0.001\u003c/a\u003e\u003c/video\u003e\u003c/p\u003e\n\u003ch2 id=\"googles-gemini-1-5-pro\" id=\"googles-gemini-1-5-pro\"\u003eGoogleâ€™s Gemini 1.5 Pro\u003ca href=\"#googles-gemini-1-5-pro\" aria-label=\"Googleâ€™s Gemini 1.5 Pro\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThe latest \u003ca href=\"https://deepmind.google/technologies/gemini/\"\u003eGemini models\u003c/a\u003e from Google show high capabilities in coding scenarios. Gemini 1.5 Pro features a two-million-token context window and is natively multi-modalâ€”with the ability to process code, images, audio, video, and text simultaneously. Gemini 1.5 Pro also delivers impressive response times for regular code suggestions, documentation, and explaining code.\u003c/p\u003e\n\u003cp\u003e\u003cvideo id=\"video-80819-3\" width=\"1920\" height=\"1080\" preload=\"metadata\" controls=\"controls\"\u003e\u003csource type=\"video/mp4\" src=\"https://github.blog/wp-content/uploads/2024/10/u24_gemini_pro_1080_7bd088.mp4#t=0.001\"/\u003e\u003ca href=\"https://github.blog/wp-content/uploads/2024/10/u24_gemini_pro_1080_7bd088.mp4#t=0.001\"\u003ehttps://github.blog/wp-content/uploads/2024/10/u24_gemini_pro_1080_7bd088.mp4#t=0.001\u003c/a\u003e\u003c/video\u003e\u003c/p\u003e\n\u003ch2 id=\"openais-o1-preview-and-o1-mini\" id=\"openais-o1-preview-and-o1-mini\"\u003eOpenAIâ€™s o1-preview and o1-mini\u003ca href=\"#openais-o1-preview-and-o1-mini\" aria-label=\"OpenAIâ€™s o1-preview and o1-mini\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/introducing-openai-o1-preview/\"\u003eOpenAI o1-preview \u003c/a\u003eand o1-mini are part of a new series of AI models equipped with more advanced reasoning capabilities than GPT 4o. During \u003ca href=\"https://github.blog/news-insights/product-news/openai-o1-in-github-copilot/\"\u003eour exploration\u003c/a\u003e using o1-preview with GitHub Copilot, we found the modelâ€™s reasoning capabilities allow for a deeper understanding of code constraints and edge cases, producing efficient and quality results.\u003c/p\u003e\n\u003cp\u003e\u003cvideo id=\"video-80819-4\" width=\"1920\" height=\"1080\" preload=\"metadata\" controls=\"controls\"\u003e\u003csource type=\"video/mp4\" src=\"https://github.blog/wp-content/uploads/2024/10/u24_o1_1080p.mp4#t=0.001\"/\u003e\u003ca href=\"https://github.blog/wp-content/uploads/2024/10/u24_o1_1080p.mp4#t=0.001\"\u003ehttps://github.blog/wp-content/uploads/2024/10/u24_o1_1080p.mp4#t=0.001\u003c/a\u003e\u003c/video\u003e\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003e\n  With GitHub Copilot, the developer is in control. Now you can also control which foundational LLM you use, all with a single login and a single subscription. \u003ca href=\"https://docs.github.com/copilot/using-github-copilot/using-claude-sonnet-in-github-copilot\"\u003eTry multi-model Copilot today\u003c/a\u003e.\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"first-glimpse-multi-model-choice-for-github-spark\" id=\"first-glimpse-multi-model-choice-for-github-spark\"\u003eFirst glimpse: multi-model choice for GitHub Spark\u003ca href=\"#first-glimpse-multi-model-choice-for-github-spark\" aria-label=\"First glimpse: multi-model choice for GitHub Spark\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn pursuit of GitHubâ€™s vision to reach 1 billion developers, today at Universe we introduced GitHub Spark: the AI-native tool to build applications entirely in natural language. Sparks are fully functional micro apps that can integrate AI features and external data sources without requiring any management of cloud resources. Utilizing a creativity feedback loop, users start with an initial prompt, see live previews of their app as itâ€™s built, easily see options for each of their requests, and automatically save versions of each iteration so they can compare versions as they go.\u003c/p\u003e\n\u003cp\u003eHereâ€™s a first glimpse, or spark ðŸ˜€, of \u003ca href=\"http://gh.io/spark-signup\"\u003eGitHub Spark\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cvideo id=\"video-80819-5\" width=\"1920\" height=\"1080\" preload=\"metadata\" controls=\"controls\"\u003e\u003csource type=\"video/mp4\" src=\"https://github.blog/wp-content/uploads/2024/10/spark_Jer_v2.mp4#t=0.001\"/\u003e\u003ca href=\"https://github.blog/wp-content/uploads/2024/10/spark_Jer_v2.mp4#t=0.001\"\u003ehttps://github.blog/wp-content/uploads/2024/10/spark_Jer_v2.mp4#t=0.001\u003c/a\u003e\u003c/video\u003e\u003c/p\u003e\n\n\t\n\n\t\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tWritten by\t\u003c/h2\u003e\n\t\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/70720?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/70720?v=4\u0026amp;s=200\" alt=\"Thomas Dohmke\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\t\t\t\t\n\t\t\t\t\t\u003cp\u003eFascinated by software development since his childhood in Germany, Thomas Dohmke has built a career building tools developers love and accelerating innovations that are changing software development. Currently, Thomas is Chief Executive Officer of GitHub, where he has overseen the launch of the world\u0026#39;s first at-scale AI developer tool, GitHub Copilot -- and now, GitHub Copilot X. Before his time at GitHub, Thomas previously co-founded HockeyApp and led the company as CEO through its acquisition by Microsoft in 2014, and holds a PhD in mechanical engineering from University of Glasgow, UK.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\u003csection\u003e\n\t\u003ch2\u003e\n\t\tRelated posts\t\u003c/h2\u003e\n\t\n\u003c/section\u003e\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tExplore more from GitHub\t\u003c/h2\u003e\n\t\u003cdiv\u003e\n\t\t\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon-Circle.svg\" width=\"44\" height=\"44\" alt=\"Docs\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tDocs\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eEverything you need to master GitHub, all in one place.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Go to Docs; ref_location:bottom recirculation;\" href=\"https://docs.github.com/\" target=\"_blank\" aria-label=\"Go to Docs\"\u003e\n\t\t\t\t\tGo to Docs\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon_95220f.svg\" width=\"44\" height=\"44\" alt=\"GitHub\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tGitHub\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eBuild whatâ€™s next on GitHub, the place for anyone from anywhere to build anything.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Start building; ref_location:bottom recirculation;\" href=\"https://github.blog/developer-skills/github/\" target=\"_blank\" aria-label=\"Start building\"\u003e\n\t\t\t\t\tStart building\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 16 16\" fill=\"none\"\u003e\u003cpath fill=\"currentColor\" d=\"M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z\"\u003e\u003c/path\u003e\u003cpath stroke=\"currentColor\" d=\"M1.75 8H11\" stroke-width=\"1.5\" stroke-linecap=\"round\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon_da43dc.svg\" width=\"44\" height=\"44\" alt=\"Customer stories\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tCustomer stories\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eMeet the companies and engineering teams that build with GitHub.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Learn more; ref_location:bottom recirculation;\" href=\"https://github.com/customer-stories\" target=\"_blank\" aria-label=\"Learn more\"\u003e\n\t\t\t\t\tLearn more\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/04/Icon.svg\" width=\"44\" height=\"44\" alt=\"GitHub Universe 2024\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tGitHub Universe 2024\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eGet tickets to the 10th anniversary of our global developer event on AI, DevEx, and security.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Get tickets; ref_location:bottom recirculation;\" href=\"https://githubuniverse.com/?utm_source=Blog\u0026amp;utm_medium=GitHub\u0026amp;utm_campaign=blog-module\" target=\"_blank\" aria-label=\"Get tickets\"\u003e\n\t\t\t\t\tGet tickets\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\t\u003c/div\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-10-29T16:08:30Z",
  "modifiedTime": null
}
