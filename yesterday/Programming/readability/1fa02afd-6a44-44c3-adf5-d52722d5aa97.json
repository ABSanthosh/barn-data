{
  "id": "1fa02afd-6a44-44c3-adf5-d52722d5aa97",
  "title": "Sequence learning: A paradigm shift for personalized ads recommendations",
  "link": "https://engineering.fb.com/2024/11/19/data-infrastructure/sequence-learning-personalized-ads-recommendations/",
  "description": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system. [...] Read More... The post Sequence learning: A paradigm shift for personalized ads recommendations appeared first on Engineering at Meta.",
  "author": "",
  "published": "Tue, 19 Nov 2024 17:00:43 +0000",
  "source": "https://engineering.fb.com/feed/",
  "categories": [
    "Data Infrastructure",
    "ML Applications",
    "Production Engineering"
  ],
  "byline": "By Sri Reddy, Habiya Beg, Arnold Overwijk, Sean O'Byrne",
  "length": 11011,
  "excerpt": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation mo…",
  "siteName": "Engineering at Meta",
  "favicon": "",
  "text": "AI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by deep learning recommendation models (DLRMs), has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system. Despite training on vast amounts of data, there are limitations to current DLRM-based ads recommendations with manual feature engineering due to the inability of DLRMs to leverage sequential information from people’s experience data. To better capture the experiential behavior, the ads recommendation models have undergone foundational transformations along two dimensions: Event-based learning: learning representations directly from a person’s engagement and conversion events rather than traditional human-engineered features. Learning from sequences: developing new sequence learning architectures to replace traditional DLRM neural network architectures. By incorporating these advancements from the fields of natural language understanding and computer vision, Meta’s next-generation ads recommendation engine addresses the limitations of traditional DLRMs, resulting in more relevant ads for people, higher value for advertisers, and better infrastructure efficiency. These innovations have enabled our ads system to develop a deeper understanding of people’s behavior before and after converting on an ad, enabling us to infer the next set of relevant ads. Since launch, the new ads recommendation system has improved ads prediction accuracy – leading to higher value for advertisers and 2-4% more conversions on select segments. The limits of DLRMs for ads recommendations Meta’s DLRMs for personalized ads rely on a wide array of signals to understand people’s purchase intent and preferences. DLRMs have revolutionized learning from sparse features, which capture a person’s interactions on entities like Facebook pages, which have massive cardinalities often in the billions. The success of DLRMs is founded on their ability to learn generalizable, high dimensional representations, i.e., embeddings from sparse features.  To leverage tens of thousands of such features, various strategies are employed to combine features, transform intermediate representations, and compose the final outputs. Further, sparse features are built by aggregating attributes across a person’s actions over various time windows with different data sources and aggregation schemes.  Some examples of legacy sparse features thus engineered would be: Ads that a person clicked in the last N days → [Ad-id1, Ad-id2, Ad-id3, …, Ad-idN] Facebook pages a person visited in the past M days with a score of how many visits on each page  → [(Page-id1, 45), (Page-id2, 30), (Page-id3, 8), …] Human-engineered sparse features, as described above, have been a cornerstone for personalized recommendations with DLRMs for several years. But this approach has limitations: Loss of sequential information: Sequence information, i.e., the order of a person’s events, can provide valuable insights for better ads recommendations relevant to a person’s behavior. Sparse feature aggregations lose the sequential information in a person’s journeys. Loss of granular information: Fine-grained information like collocation of attributes in the same event is lost as features are aggregated across events. Reliance on human intuition: Human intuition is unlikely to recognize non-intuitive, complex interactions and patterns from vast quantities of data. Redundant feature space: Multiple variants of features get created with different aggregation schemes. Though providing incremental value, overlapping aggregations increase compute and storage costs and make feature management cumbersome. People’s interests evolve over time with continuously evolving and dynamic intents. Such complexities are hard to model with handcrafted features. Modeling these inter-dynamics helps achieve a deeper understanding of a person’s behavior over time for better ad recommendations.  A paradigm shift with learning from sequences for recommendation systems Meta’s new system for ads recommendations uses sequence learning at its core. This necessitated a complete redesign of the ads recommendations system across data storage, feature input formats, and model architecture. The redesign required building a new people-centric infrastructure, training and serving optimization for state-of-the-art sequence learning architectures, and model/system codesign for efficient scaling. Event-based features Event-based features (EBFs) are the building blocks for the new sequence learning models. EBFs – an upgrade to traditional features – standardizes heterogeneous inputs to sequence learning models along three dimensions: Event streams: the data stream for an EBF, e.g. the sequence of recent ads people engaged with or the sequence of pages people liked. Sequence length defines how many recent events are incorporated from each stream and is determined by the importance of each stream. Event Information: captures semantic and contextual information about each event in the stream such as the ad category a person engaged with and the timestamp of the event. Each EBF is a single coherent object that captures all key information about an event. EBFs allow us to incorporate rich information and scale inputs systematically. EBF sequences replace legacy sparse features as the main inputs to the recommendation models. When combined with event models described below, EBFs have ushered in a departure from human-engineered feature aggregations. Sequence modeling with EBFs An event model synthesizes event embeddings from event attributes. It learns embeddings for each attribute and uses linear compression to summarize them into a single event attributed-based embedding. Events are timestamp encoded to capture their recency and temporal order. The event model combines timestamp encoding with the synthesized event attribute-based embedding to produce the final event-level representation – thus translating an EBF sequence into an event embedding sequence. This is akin to how language models use embeddings to represent words. The difference is that EBFs have a vocabulary that is many orders of magnitude larger than a natural language because they come from heterogeneous event streams and encompass millions of entities. The event embeddings from the event model are then fed into the sequence model at the center of the next-generation ads recommendation system. The event sequence model is a person level event summarization model that consumes sequential event embeddings. It utilizes state-of-the-art attention mechanisms to synthesize the event embeddings to a predefined number of  embeddings that are keyed by the ad to be ranked. With techniques like multi-headed attention pooling, the complexity of the self-attention module is reduced from O(N*N) to O(M*N) . M is a tunable parameter and N is the maximum event sequence length. The following figure illustrates the differences between DLRMs with a human-engineered features paradigm (left) and the sequence modeling paradigm with EBFs (right) from a person’s event flow perspective. Scaling the new sequence learning paradigm Following the redesign to shift from sparse feature learning to event-based sequence learning, the next focus was scaling across two domains — scaling the sequence learning architecture and scaling event sequences to be longer and richer. Scaling sequence learning architectures A custom transformer architecture that incorporates complex feature encoding schemes to fully model sequential information was developed to enable faster exploration and adoption of state-of-the-art techniques for recommendation systems. The main challenge with this architectural approach is achieving the performance and efficiency requirements for production. A request to Meta’s ads recommendation system has to rank thousands of ads in a few hundred milliseconds. To scale representation learning for higher fidelity, the existing sum pooling approach was replaced with a new architecture that learned feature interactions from unpooled embeddings. Whereas the prior system based on aggregated features was highly optimized for fixed length embeddings that are pooled by simple methods like averaging, sequence learning introduces new challenges because different people have different event lengths. Longer variable length event sequences, represented by jagged embedding tensors and unpooled embeddings, result in larger compute and communication costs with higher variance. This challenge of growing costs is addressed by adopting hardware codesign innovations for supporting jagged tensors, namely: Native PyTorch capabilities to support Jagged tensors. Kernel-level optimization for processing Jagged tensors on GPUs. A Jagged Flash Attention module to support Flash Attention on Jagged tensors. Scaling with longer, richer sequences Meta’s next-generation recommendation system’s ability to learn directly from event sequences to better understand people’s preferences is further enhanced with longer sequences and richer event attributes. Sequence scaling entailed: Scaling with longer sequences: Increasing sequence lengths gives deeper insights and context about a person’s interests. Techniques like multi-precision quantization and value-based sampling techniques are used to efficiently scale sequence length. Scaling with richer semantics: EBFs enable us to capture richer semantic signals about each event e.g. through multimodal content embeddings. Customized vector quantization techniques are used to efficiently encode the embedding attributes of each event. This yields a more informative representation of the final event embedding. The impact and future of sequence learning The event sequence learning paradigm has been widely adopted across Meta’s ads systems, resulting in gains in ad relevance and performance, more efficient infrastructure, and accelerated research velocity. Coupled with our focus on advanced transformer architectures, event sequence learning has reshaped Meta’s approach to ads recommendation systems.  Going forward, the focus will be on further scaling event sequences by 100X, developing more efficient sequence modeling architectures like linear attention and state space models, key-value (KV) cache optimization, and multimodal enrichment of event sequences. Acknowledgements We would like to thank Neeraj Bhatia, Zhirong Chen, Parshva Doshi, Jonathan Herbach, Yuxi Hu, Abha Jain, Kun Jiang, Santanu Kolay, Boyang Li,  Hong Li, Paolo Massimi, Sandeep Pandey, Dinesh Ramasamy, Ketan Singh, Doris Wang, Rengan Xu, Junjie Yang, and the entire event sequence learning team involved in the development and productionization of the next-generation sequencing learning-based ads recommendation system.",
  "image": "https://engineering.fb.com/wp-content/uploads/2022/11/Eng-Blog-Self-Serve-Hero-Images-DEBUGGING-203-.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n\t\t\u003cp\u003e\u003cspan\u003eAI plays a fundamental role in creating valuable connections between people and advertisers within Meta’s family of apps. Meta’s ad recommendation engine, powered by\u003c/span\u003e \u003ca href=\"https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003edeep learning recommendation models (DLRMs)\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, has been instrumental in delivering personalized ads to people. Key to this success was incorporating thousands of human-engineered signals or features in the DLRM-based recommendation system.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eDespite training on vast amounts of data, there are limitations to current DLRM-based ads recommendations with manual feature engineering due to the inability of DLRMs to leverage sequential information from people’s experience data. To better capture the experiential behavior, the ads recommendation models have undergone foundational transformations along two dimensions:\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cspan\u003eEvent-based learning: learning representations directly from a person’s engagement and conversion events rather than traditional human-engineered features.\u003c/span\u003e\u003c/li\u003e\n\u003cli\u003e\u003cspan\u003eLearning from sequences: developing new sequence learning architectures to replace traditional DLRM neural network architectures.\u003c/span\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cspan\u003eBy incorporating these advancements from the fields of natural language understanding and computer vision, Meta’s next-generation ads recommendation engine addresses the limitations of traditional DLRMs, resulting in more relevant ads for people, higher value for advertisers, and better infrastructure efficiency.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThese innovations have enabled our ads system to develop a deeper understanding of people’s behavior before and after converting on an ad, enabling us to infer the next set of relevant ads. Since launch, the new ads recommendation system has improved ads prediction accuracy – leading to higher value for advertisers and 2-4% more conversions on select segments.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003eThe limits of DLRMs for ads recommendations\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eMeta’s DLRMs for personalized ads rely on a wide array of signals to understand people’s purchase intent and preferences. DLRMs have revolutionized learning from \u003c/span\u003e\u003ca href=\"https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003esparse features\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, which capture a person’s interactions on entities like Facebook pages, which have massive cardinalities often in the billions. The success of DLRMs is founded on their ability to learn generalizable, high dimensional representations, i.e., embeddings from sparse features. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eTo leverage tens of thousands of such features, various strategies are employed to combine features, transform intermediate representations, and compose the final outputs. Further, s\u003c/span\u003e\u003cspan\u003eparse features \u003c/span\u003e\u003cspan\u003eare built by aggregating attributes across a person’s actions over various time windows with different data sources and aggregation schemes. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eSome examples of legacy sparse features thus engineered would be:\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eAds that a person clicked in the last N days → [Ad-id1, Ad-id2, Ad-id3, …, Ad-idN]\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eFacebook pages a person visited in the past M days with a score of how many visits on each page  → [(Page-id1, 45), (Page-id2, 30), (Page-id3, 8), …]\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003eHuman-engineered sparse features, as described above, have been a cornerstone for personalized recommendations with DLRMs for several years. \u003c/span\u003e\u003cspan\u003eBut this approach has limitations:\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eLoss of sequential information: Sequence information, i.e., the order of a person’s events, can provide valuable insights for better ads recommendations relevant to a person’s behavior. Sparse feature aggregations lose the sequential information in a person’s journeys.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eLoss of granular information: Fine-grained information like collocation of attributes in the same event is lost as features are aggregated across events.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eReliance on human intuition: Human intuition is unlikely to recognize non-intuitive, complex interactions and patterns from vast quantities of data.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eRedundant feature space: Multiple variants of features get created with different aggregation schemes. Though providing incremental value, overlapping aggregations increase compute and storage costs and make feature management cumbersome.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan\u003ePeople’s interests evolve over time with continuously evolving and dynamic intents. Such complexities are hard to model with handcrafted features. Modeling these inter-dynamics helps achieve a deeper understanding of a person’s behavior over time for better ad recommendations. \u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003eA paradigm shift with learning from sequences for recommendation systems\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eMeta’s new system for ads recommendations uses sequence learning at its core. This necessitated a complete redesign of the ads recommendations system across data storage, feature input formats, and model architecture. The redesign required building a new people-centric infrastructure, training and serving optimization for state-of-the-art sequence learning architectures, and model/system codesign for efficient scaling.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eEvent-based features\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eEvent-based features (EBFs) are the building blocks for the new sequence learning models. EBFs – an upgrade to traditional features – standardizes heterogeneous inputs to sequence learning models along three dimensions:\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cspan\u003eEvent streams: the data stream for an EBF, e.g. the sequence of recent ads people engaged with or the sequence of pages people liked.\u003c/span\u003e\u003c/li\u003e\n\u003cli\u003e\u003cspan\u003eSequence length defines how many recent events are incorporated from each stream and is determined by the importance of each stream.\u003c/span\u003e\u003c/li\u003e\n\u003cli\u003e\u003cspan\u003eEvent Information: captures semantic and contextual information about each event in the stream such as the ad category a person engaged with and the timestamp of the event.\u003c/span\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cspan\u003eEach EBF is a single coherent object that captures all key information about an event. EBFs\u003c/span\u003e\u003cspan\u003e allow us \u003c/span\u003e\u003cspan\u003eto incorporate rich information and \u003c/span\u003e\u003cspan\u003escale inputs systematically. \u003c/span\u003e\u003cspan\u003eEBF sequences replace legacy sparse features as the main inputs to the recommendation models. When combined with event models described below, EBFs have ushered in a departure from human-engineered feature aggregations.\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eSequence modeling with EBFs\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eAn event model synthesizes event embeddings from event attributes. It learns embeddings for each attribute and uses linear compression to summarize them into a single event attributed-based embedding. Events are timestamp encoded to capture their recency and temporal order. The event model combines timestamp encoding with the synthesized event attribute-based embedding to produce the final event-level representation – thus translating an EBF sequence into an event embedding sequence.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThis is akin to how language models use embeddings to represent words. The difference is that EBFs have a vocabulary that is many orders of magnitude larger than a natural language because they come from heterogeneous event streams and encompass millions of entities.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThe event embeddings from the event model are then fed into the sequence model at the center of the next-generation ads recommendation system. The event sequence model is a person level event summarization model that consumes sequential event embeddings. It utilizes state-of-the-art attention mechanisms \u003c/span\u003e\u003cspan\u003eto\u003c/span\u003e\u003cspan\u003e synthesize the event embeddings to a predefined number of  embeddings that are keyed by the ad to be ranked\u003c/span\u003e\u003cspan\u003e. With techniques like multi-headed attention pooling, the complexity of the self-attention module is reduced from \u003c/span\u003e\u003ci\u003e\u003cspan\u003eO\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e(N*N) to \u003c/span\u003e\u003ci\u003e\u003cspan\u003eO\u003c/span\u003e\u003c/i\u003e\u003cspan\u003e(M*N) . M is a tunable parameter and N is the maximum event sequence length.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThe following figure illustrates the differences between DLRMs with a human-engineered features paradigm (left) and the sequence modeling paradigm with EBFs (right) from a person’s event flow perspective.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg decoding=\"async\" src=\"https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?w=1024\" alt=\"\" width=\"1024\" height=\"899\" srcset=\"https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png 1999w, https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?resize=916,804 916w, https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?resize=768,674 768w, https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?resize=1024,899 1024w, https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?resize=1536,1349 1536w, https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?resize=96,84 96w, https://engineering.fb.com/wp-content/uploads/2024/11/Event-Sequence-Learning-Meta.png?resize=192,169 192w\" sizes=\"(max-width: 992px) 100vw, 62vw\"/\u003e\u003c/p\u003e\n\u003ch2\u003eScaling the new sequence learning paradigm\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eFollowing the redesign to shift from sparse feature learning to event-based sequence learning, the next focus was scaling across two domains — scaling the sequence learning architecture and scaling event sequences to be longer and richer.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003eScaling sequence learning architectures\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eA custom transformer architecture that incorporates complex feature encoding schemes to fully model sequential information was developed to enable faster exploration and adoption of state-of-the-art techniques for recommendation systems. The main challenge with this architectural approach is achieving the performance and efficiency requirements for production. A request to Meta’s ads recommendation system has to rank thousands of ads in a few hundred milliseconds.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eTo scale representation learning for higher fidelity, the existing sum pooling approach\u003c/span\u003e \u003cspan\u003ewas replaced\u003c/span\u003e \u003cspan\u003ewith a new architecture that learned feature interactions from unpooled embeddings.\u003c/span\u003e \u003cspan\u003eWhereas the prior system based on aggregated features was highly optimized for fixed length embeddings that are pooled by simple methods like averaging, sequence learning introduces new challenges because different people have different event lengths. Longer variable length event sequences, represented by jagged embedding tensors and unpooled embeddings, result in larger compute and communication costs with higher variance.\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003cspan\u003eThis challenge of growing costs is addressed by adopting hardware codesign innovations for supporting jagged tensors, namely:\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eNative PyTorch capabilities to support Jagged tensors.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eKernel-level optimization for processing Jagged tensors on GPUs.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cspan\u003eA \u003c/span\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3640457.3688040\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003eJagged Flash Attention \u003c/span\u003e\u003c/a\u003e\u003cspan\u003emodule to support Flash Attention on Jagged tensors.\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eScaling with longer, richer sequences\u003c/h3\u003e\n\u003cp\u003e\u003cspan\u003eMeta’s next-generation recommendation system’s ability to learn directly from event sequences to better understand people’s preferences is further enhanced with longer sequences and richer event attributes.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eSequence scaling entailed:\u003c/span\u003e\u003cspan\u003e\u003cbr/\u003e\n\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eScaling with longer sequences: \u003c/b\u003e\u003cspan\u003eIncreasing sequence lengths gives deeper insights and context about a person’s interests. Techniques like multi-precision quantization and value-based sampling techniques are used to efficiently scale sequence length.\u003c/span\u003e\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cb\u003eScaling with richer semantics\u003c/b\u003e\u003cspan\u003e: EBFs enable us to capture richer semantic signals about each event e.g. through multimodal content embeddings. Customized vector quantization techniques are used to efficiently encode the embedding attributes of each event. This yields a more informative representation of the final event embedding.\u003c/span\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eThe impact and future of sequence learning\u003c/h2\u003e\n\u003cp\u003e\u003cspan\u003eThe event sequence learning paradigm has been widely adopted across Meta’s ads systems, resulting in gains in ad relevance and performance, more efficient infrastructure, and accelerated research velocity. Coupled with our focus on advanced \u003c/span\u003e\u003ca href=\"https://arxiv.org/pdf/2406.05898\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003etransformer architectures\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, event sequence learning has reshaped Meta’s approach to ads recommendation systems. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eGoing forward, the focus will be on further scaling event sequences by 100X, developing more efficient sequence modeling architectures like linear attention and state space models, key-value (KV) cache optimization, and multimodal enrichment of event sequences.\u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003e\u003cspan\u003eAcknowledgements\u003c/span\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ci\u003e\u003cspan\u003eWe would like to thank \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Neeraj Bhatia\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;neerajb@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eNeeraj Bhatia\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, Zhirong Chen, Parshva Doshi, \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Jonathan Herbach\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;jherbach@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eJonathan Herbach\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Yuxi Hu\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;yuxihu@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eYuxi Hu\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, Abha Jain, Kun Jiang, \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Santanu Kolay\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;skolay@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eSantanu Kolay\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, Boyang Li,  Hong Li\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Junjie Yang\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;junjieyang@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003e,\u003c/span\u003e\u003c/i\u003e \u003ci\u003e\u003cspan\u003ePaolo Massimi, \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Sandeep Pandey\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;sppandey@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eSandeep Pandey\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Dinesh Ramasamy\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;dineshr@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eDinesh Ramasamy\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, \u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan data-rich-links=\"{\u0026#34;per_n\u0026#34;:\u0026#34;Ketan Singh\u0026#34;,\u0026#34;per_e\u0026#34;:\u0026#34;ktns@meta.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;person\u0026#34;}\"\u003eKetan Singh\u003c/span\u003e\u003c/i\u003e\u003ci\u003e\u003cspan\u003e, Doris Wang, Rengan Xu, Junjie Yang, and the entire event sequence learning team involved in the development and productionization of the next-generation sequencing learning-based ads recommendation system.\u003c/span\u003e\u003c/i\u003e\u003c/p\u003e\n\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2024-11-19T17:00:43Z",
  "modifiedTime": "2024-11-19T17:12:16Z"
}
