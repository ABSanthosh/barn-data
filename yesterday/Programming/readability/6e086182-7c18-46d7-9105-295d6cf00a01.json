{
  "id": "6e086182-7c18-46d7-9105-295d6cf00a01",
  "title": "InfoQ Dev Summit Munich: How to Optimize Java for the 1BRC",
  "link": "https://www.infoq.com/news/2024/10/optimize-java-1brc/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Java applications passed the 1 Billion Row Challenge (1BRC) in 1.5 seconds. 1BRC creator Gunnar Morling detailed their optimizations at the InfoQ Dev Summit Munich 2024. General optimizations applicable to all Java applications cut the runtime from 290 seconds to 20 seconds. Getting to 1.5 seconds required niche optimizations that most Java applications should forego, except for possibly GraalVM. By Karsten Silz",
  "author": "Karsten Silz",
  "published": "Fri, 11 Oct 2024 04:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Java",
    "InfoQ Dev Summit Munich 2024",
    "Development",
    "news"
  ],
  "byline": "Karsten Silz",
  "length": 6406,
  "excerpt": "Java applications passed the 1 Billion Row Challenge (1BRC) in 1.5 seconds. 1BRC creator Gunnar Morling detailed their optimizations at the InfoQ Dev Summit Munich 2024. General optimizations applicab",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20241001113528/apple-touch-icon.png",
  "text": "Java applications passed the 1 Billion Row Challenge (1BRC) from January 2024 in 1.5 seconds. 1BRC creator Gunnar Morling, Software Engineer at Decodable, detailed how the participants optimized Java at the InfoQ Dev Summit Munich 2024. General optimizations applicable to all Java applications cut the runtime from 290 seconds to 20 seconds using parallel loading/processing and optimized parsing. Getting to 1.5 seconds required niche optimizations that most Java applications should forego, except for possibly GraalVM Native Image compilation. Each of the 1 billion rows has the name of a weather station and a single temperature ranging from -99.9°C to +99.9°C. Participants created that data file with a generator application, which was part of the challenge code. The application had to read that entire file and calculate the minimum, maximum, and average temperatures of the 400 hundred weather stations as quickly as possible. Using external libraries or caching was forbidden. 1BRC measured the official results on a 2019 AMD server processor with 128 GB RAM. The applications only used eight threads. The data file was on a RAM disk. Applications had about 113 GB RAM available, but most used much less. Each submission was tested five times, with the slowest and fastest runs discarded for consistency. Morling wrote the baseline implementation, which took 290 seconds: Collector\u003cMeasurement, MeasurementAggregator, ResultRow\u003e collector = Collector.of(MeasurementAggregator:: new, (a, m) →\u003e { a.min = Math.min(a.min, m. value) ; a.max = Math.max(a.max, m. value); a.sum += m.value; A.count++; }, (aggl, agg2) -\u003e { var res = new MeasurementAggregator(); res.min = Math.min(aggl.min, agg2.min); res.max = Math.max(aggl.max, agg2.max); res.sum = aggl.sum + agg2.sum; res.count = agg1.count + agg2.count; return res; }, agg -\u003e { return new ResultRow(agg.min, round(agg.sum) / agg.count, agg.max); ｝）； Map\u003cString, ResultRow\u003e measurements = new TreeMap\u003c\u003e(Files.Lines(Paths.get(FILE)) .map(l -\u003e new Measurement(l.split(\";\"))) .collect(groupingBy(m →\u003e m.station(), collector))); System.out.println(measurements); The 1BRC is similar to back-end processing that Java often does. That's why its general optimizations are applicable to many Java applications. Parallel processing meant adding a single parallel()call before the map()statement in the fourth line from the bottom. This automatically distributed the following stream operations across the eight CPU cores, cutting the runtime to 71 seconds, a 4x improvement. Parallel loading replaces Files.Lines(Paths.get(FILE)), which turns the file into a Stream\u003cString\u003e sequentially. Instead, eight threads load chunks of the file into custom memory areas with the help of JEP 442, Foreign Function \u0026 Memory API (Third Preview), delivered in Java 21. Note that the Foreign Function \u0026 Memory API was finalized with JEP 454, delivered in Java 22. The final step of the general optimizations was changing the line reading from a string to individual bytes. Together with the parallelization, this achieved the 14.5x improvement from 290 seconds to 20 seconds. The first step of the niche optimizations is \"Single Instruction, Multiple Data (SIMD) Within a Register\" (SWAR) for parsing the data. In SIMD, a processor applies the same command to multiple pieces of data, which is faster than processing it sequentially. SWAR is faster than SIMD because accessing data in CPU registers is much faster than getting it from main memory. Custom map implementations for storing the weather station data provided another performance boost. Because there were only 400 stations, custom hash functions also saved time. Other techniques included using the Unsafe class, superscalar execution, perfect value hashing, the \"spawn trick\" (as characterized by Morling), and using multiple parsing loops. Mechanical sympathy helped: The applications picked a file chunk size so that all chunks for the eight threads fit into the processor cache. And branchless programming ensured that the processor branch predictor had to discard less code. The last two optimizations targeted how the JVM works. Its JIT compiler profiles the interpreted Java bytecode and compiles often-used methods into machine code. Additionally, the JVM creates a class list at startup and initializes the JDK. All that slows down application startup and delays reaching the top speed. The GraalVM Ahead-Of-Time (AOT) compiler Native Image moves compilation and as much initialization work as possible to build time. That produces a native executable which starts at top speed. GraalVM Native Image ships alongside new Java versions. Using GraalVM Native Image comes at the price of some possibly showstopping constraints and a more expensive troubleshooting process. Many application frameworks, such as Helidon, Micronaut, Quarkus, and Spring Boot, support GraalVM Native Image. Some libraries, especially older ones, do not, which may be a showstopper. These constraints were not a factor in the 1BRC, as no external libraries were used. Finally, the JVM garbage collector frees up unused memory. But it also uses CPU time and memory. That is why applications that did not need garbage collection used the \"no-op\" Epsilon garbage collector. The niche optimizations provided a further 13x improvement down to 1.5 seconds. The fastest application with a JIT compiler took 2.367 seconds, the fastest with GraalVM Native Image finished in 1.535 seconds. Co-author of the 1BRC winner and GraalVM Founder and Project Lead Thomas Wuerthinger published his 10 steps of 1BRC optimizations. His baseline solution takes just 125 seconds, compared to Morling's 290 seconds, probably because it runs on a newer 2022 Intel desktop processor. Unsurprisingly, his first step is using GraalVM Native Image. After just two steps, his solution is already down to 5.7 seconds. Morling was positively surprised by the community that quickly formed around 1BRC. They contributed a new server, a test suite, and scripts for configuring the server environment and running the applications. Morling has not thought of a new challenge. About the Author Karsten Silz",
  "image": "https://res.infoq.com/news/2024/10/optimize-java-1brc/en/headerimage/generatedHeaderImage-1728045844447.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eJava applications passed the \u003ca href=\"https://www.infoq.com/news/2024/01/1brc-fast-java-processing\"\u003e1 Billion Row Challenge (1BRC)\u003c/a\u003e from January 2024 in 1.5 seconds. 1BRC creator \u003ca href=\"https://www.linkedin.com/in/gunnar-morling/\"\u003eGunnar Morling\u003c/a\u003e, Software Engineer at Decodable, \u003ca href=\"https://devsummit.infoq.com/presentation/munich2024/1brc-nerd-sniping-java-community\"\u003edetailed\u003c/a\u003e how the participants optimized Java at the InfoQ Dev Summit Munich 2024. General optimizations applicable to all Java applications cut the runtime from 290 seconds to 20 seconds using parallel loading/processing and optimized parsing. Getting to 1.5 seconds required niche optimizations that most Java applications should forego, except for possibly GraalVM Native Image compilation.\u003c/p\u003e\n\n\u003cp\u003eEach of the 1 billion rows has the name of a weather station and a single temperature ranging from -99.9°C to +99.9°C. Participants created that data file with a \u003ca href=\"https://github.com/gunnarmorling/1brc/blob/main/src/main/java/dev/morling/onebrc/CreateMeasurements.java\"\u003egenerator application\u003c/a\u003e, which was part of the challenge code. The application had to read that entire file and calculate the minimum, maximum, and average temperatures of the 400 hundred weather stations as quickly as possible. Using external libraries or caching was forbidden.\u003c/p\u003e\n\n\u003cp\u003e1BRC measured the official results on a 2019 \u003ca href=\"https://www.techpowerup.com/cpu-specs/epyc-7502p.c2260\"\u003eAMD server processor\u003c/a\u003e with 128 GB RAM. The applications only used eight threads. The data file was on a RAM disk. Applications had about 113 GB RAM available, but most used much less. Each submission was tested five times, with the slowest and fastest runs discarded for consistency.\u003c/p\u003e\n\n\u003cp\u003eMorling wrote \u003ca href=\"https://github.com/gunnarmorling/1brc/blob/main/src/main/java/dev/morling/onebrc/CalculateAverage_baseline.java\"\u003ethe baseline implementation\u003c/a\u003e, which took 290 seconds:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003eCollector\u0026lt;Measurement, MeasurementAggregator, ResultRow\u0026gt;\n  collector = Collector.of(MeasurementAggregator:: new,\n    (a, m) →\u0026gt; {\n      a.min = Math.min(a.min, m. value) ;\n      a.max = Math.max(a.max, m. value);\n      a.sum += m.value;\n      A.count++;\n    },\n    (aggl, agg2) -\u0026gt; {\n      var res = new MeasurementAggregator();\n      res.min = Math.min(aggl.min, agg2.min);\n      res.max = Math.max(aggl.max, agg2.max);\n      res.sum = aggl.sum + agg2.sum;\n      res.count = agg1.count + agg2.count;\n      return res;\n    },\n    agg -\u0026gt; {\n      return new ResultRow(agg.min,\n        round(agg.sum) / agg.count, agg.max);\n    ｝）；\n\nMap\u0026lt;String, ResultRow\u0026gt; measurements \n  = new TreeMap\u0026lt;\u0026gt;(Files.Lines(Paths.get(FILE))\n      .map(l -\u0026gt; new Measurement(l.split(\u0026#34;;\u0026#34;)))\n      .collect(groupingBy(m →\u0026gt; m.station(), collector)));\n\nSystem.out.println(measurements);\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe 1BRC is similar to back-end processing that Java often does. That\u0026#39;s why its \u003cstrong\u003egeneral optimizations\u003c/strong\u003e are applicable to many Java applications.\u003c/p\u003e\n\n\u003cp\u003eParallel \u003cstrong\u003eprocessing\u003c/strong\u003e meant adding a single \u003cstrong\u003e\u003ccode\u003eparallel()\u003c/code\u003e\u003c/strong\u003ecall before the \u003cstrong\u003e\u003ccode\u003emap()\u003c/code\u003e\u003c/strong\u003estatement in the fourth line from the bottom. This automatically distributed the following stream operations across the eight CPU cores, cutting the runtime to 71 seconds, a 4x improvement.\u003c/p\u003e\n\n\u003cp\u003eParallel \u003cstrong\u003eloading \u003c/strong\u003ereplaces \u003cstrong\u003e\u003ccode\u003eFiles.Lines(Paths.get(FILE))\u003c/code\u003e,\u003c/strong\u003e which turns the file into a \u003cstrong\u003e\u003ccode\u003eStream\u0026lt;String\u0026gt;\u003c/code\u003e\u003c/strong\u003e sequentially. Instead, eight threads load chunks of the file into custom memory areas with the help of \u003ca href=\"https://openjdk.org/jeps/442\"\u003eJEP 442\u003c/a\u003e, Foreign Function \u0026amp; Memory API (Third Preview), delivered in \u003ca href=\"https://www.infoq.com/news/2023/09/java21-released/\"\u003eJava 21\u003c/a\u003e. Note that the Foreign Function \u0026amp; Memory API was finalized with \u003ca href=\"https://openjdk.org/jeps/454\"\u003eJEP 454\u003c/a\u003e, delivered in \u003ca href=\"https://www.infoq.com/news/2024/03/java22-released/\"\u003eJava 22\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eThe final step of the general optimizations was changing the line reading from a string to individual bytes. Together with the parallelization, this achieved the 14.5x improvement from 290 seconds to 20 seconds.\u003c/p\u003e\n\n\u003cp\u003eThe first step of the \u003cstrong\u003eniche\u003c/strong\u003e optimizations is \u0026#34;Single Instruction, Multiple Data (SIMD) Within a Register\u0026#34; (SWAR) for parsing the data. In SIMD, a processor applies the same command to multiple pieces of data, which is faster than processing it sequentially. SWAR is faster than SIMD because accessing data in CPU registers is much faster than getting it from main memory.\u003c/p\u003e\n\n\u003cp\u003eCustom map implementations for storing the weather station data provided another performance boost. Because there were only 400 stations, custom hash functions also saved time. Other techniques included using the \u003cstrong\u003e\u003ccode\u003e\u003ca href=\"https://github.com/openjdk/jdk/blob/master/src/jdk.unsupported/share/classes/sun/misc/Unsafe.java\"\u003eUnsafe\u003c/a\u003e\u003c/code\u003e\u003c/strong\u003e class, superscalar execution, perfect value hashing, the \u0026#34;spawn trick\u0026#34; (as characterized by Morling), and using multiple parsing loops.\u003c/p\u003e\n\n\u003cp\u003eMechanical sympathy helped: The applications picked a file chunk size so that all chunks for the eight threads fit into the processor cache. And branchless programming ensured that the \u003ca href=\"https://en.wikipedia.org/wiki/Branch_predictor\"\u003eprocessor branch predictor\u003c/a\u003e had to discard less code.\u003c/p\u003e\n\n\u003cp\u003eThe last two optimizations targeted how the JVM works. Its JIT compiler profiles the interpreted Java bytecode and compiles often-used methods into machine code. Additionally, the JVM creates a class list at startup and initializes the JDK. All that slows down application startup and delays reaching the top speed. The GraalVM Ahead-Of-Time (AOT) compiler Native Image moves compilation and as much initialization work as possible to build time. That produces a native executable which starts at top speed. GraalVM Native Image ships \u003ca href=\"https://www.infoq.com/news/2023/07/graalvm-java-17-20/\"\u003ealongside new Java versions\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eUsing GraalVM Native Image comes at the price of \u003ca href=\"https://www.infoq.com/articles/native-java-aligning\"\u003esome possibly showstopping constraints\u003c/a\u003e and a more \u003ca href=\"https://www.infoq.com/articles/native-java-real-world/\"\u003eexpensive troubleshooting process\u003c/a\u003e. Many application frameworks, such as Helidon, Micronaut, Quarkus, and Spring Boot, support GraalVM Native Image. Some libraries, especially older ones, do not, which may be a showstopper. These constraints were not a factor in the 1BRC, as no external libraries were used.\u003c/p\u003e\n\n\u003cp\u003eFinally, the JVM garbage collector frees up unused memory. But it also uses CPU time and memory. That is why applications that did not need garbage collection used the \u0026#34;no-op\u0026#34; Epsilon garbage collector.\u003c/p\u003e\n\n\u003cp\u003eThe niche optimizations provided a further 13x improvement down to 1.5 seconds. The \u003ca href=\"https://github.com/gunnarmorling/1brc/blob/main/README.md#results\"\u003efastest application with a JIT compiler\u003c/a\u003e took 2.367 seconds, the fastest with GraalVM Native Image finished in 1.535 seconds.\u003c/p\u003e\n\n\u003cp\u003eCo-author of the 1BRC winner and GraalVM Founder and Project Lead \u003ca href=\"https://www.linkedin.com/in/thomaswue/\"\u003eThomas Wuerthinger\u003c/a\u003e published his \u003ca href=\"https://github.com/thomaswue/1brc-steps\"\u003e10 steps of 1BRC optimizations\u003c/a\u003e. His baseline solution takes just 125 seconds, compared to Morling\u0026#39;s 290 seconds, probably because it runs on a newer \u003ca href=\"https://www.intel.com/content/www/us/en/products/sku/230496/intel-core-i913900k-processor-36m-cache-up-to-5-80-ghz/specifications.html\"\u003e2022 Intel desktop processor\u003c/a\u003e. Unsurprisingly, his first step is using GraalVM Native Image. After just two steps, his solution is already down to 5.7 seconds.\u003c/p\u003e\n\n\u003cp\u003eMorling was positively surprised by the community that quickly formed around 1BRC. They contributed a new server, a test suite, and scripts for configuring the server environment and running the applications. Morling has not thought of a new challenge.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Karsten-Silz\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eKarsten Silz\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2024-10-11T00:00:00Z",
  "modifiedTime": null
}
