{
  "id": "64114470-a40e-45a9-81b7-d72b426f6503",
  "title": "Simon Willison on the Privacy/Security Risks of Personalized Siri, vis-à-vis Prompt Injection",
  "link": "https://simonwillison.net/2025/Mar/8/delaying-personalized-siri/",
  "description": "",
  "author": "John Gruber",
  "published": "2025-03-08T20:11:03Z",
  "source": "https://daringfireball.net/feeds/main",
  "categories": null,
  "byline": "Simon Willison",
  "length": 1086,
  "excerpt": "Apple told John Gruber (and other Apple press) this about the new \"personalized\" Siri: \u003e It’s going to take us longer than we thought to deliver on these features and …",
  "siteName": "Simon Willison’s Weblog",
  "favicon": "",
  "text": "Apple Is Delaying the ‘More Personalized Siri’ Apple Intelligence Features. Apple told John Gruber (and other Apple press) this about the new \"personalized\" Siri: It’s going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year. I have a hunch that this delay might relate to security. These new Apple Intelligence features involve Siri responding to requests to access information in applications and then perform actions on the user's behalf. This is the worst possible combination for prompt injection attacks! Any time an LLM-based system has access to private data, tools it can call and exposure to potentially malicious instructions (like emails and text messages from untrusted strangers) there's a significant risk that an attacker might subvert those tools and use them to damage or exfiltration a user's data. I published this piece about the risk of prompt injection to personal digital assistants back in November 2023, and nothing has changed since then to make me think this is any less of an open problem.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://daringfireball.net/2025/03/apple_is_delaying_the_more_personalized_siri_apple_intelligence_features\"\u003eApple Is Delaying the ‘More Personalized Siri’ Apple Intelligence Features\u003c/a\u003e\u003c/strong\u003e. Apple told John Gruber (and other Apple press) this about the new \u0026#34;personalized\u0026#34; Siri:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIt’s going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eI have a hunch that this delay might relate to security.\u003c/p\u003e\n\u003cp\u003eThese new Apple Intelligence features involve Siri responding to requests to access information in applications and then perform actions on the user\u0026#39;s behalf.\u003c/p\u003e\n\u003cp\u003eThis is the worst possible combination for \u003ca href=\"https://simonwillison.net/tags/prompt-injection/\"\u003eprompt injection\u003c/a\u003e attacks! Any time an LLM-based system has access to private data, tools it can call and exposure to potentially malicious instructions (like emails and text messages from untrusted strangers) there\u0026#39;s a significant risk that an attacker might subvert those tools and use them to damage or exfiltration a user\u0026#39;s data.\u003c/p\u003e\n\u003cp\u003eI published \u003ca href=\"https://simonwillison.net/2023/Nov/27/prompt-injection-explained/\"\u003ethis piece\u003c/a\u003e about the risk of prompt injection to personal digital assistants back in November 2023, and nothing has changed since then to make me think this is any less of an open problem.\u003c/p\u003e\n\n\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
