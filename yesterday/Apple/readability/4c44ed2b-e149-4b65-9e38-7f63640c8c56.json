{
  "id": "4c44ed2b-e149-4b65-9e38-7f63640c8c56",
  "title": "Gemini 2.0 and LLMs Integrated with Apps",
  "link": "https://www.macstories.net/stories/gemini-2-0-and-llms-integrated-with-apps/",
  "description": "Busy day at Google today: the company rolled out version 2.0 of its Gemini AI assistant (previously announced in December) with a variety of new and updated models to more users. From the Google blog: Today, we’re making the updated Gemini 2.0 Flash generally available via the Gemini API in Google AI Studio and Vertex AI. Developers can […]",
  "author": "Federico Viticci",
  "published": "Thu, 06 Feb 2025 01:34:36 +0000",
  "source": "https://www.macstories.net/feed",
  "categories": [
    "stories",
    "AI",
    "gemini",
    "google"
  ],
  "byline": "Federico Viticci",
  "length": 6592,
  "excerpt": "Busy day at Google today: the company rolled out version 2.0 of its Gemini AI assistant (previously announced in December) with a variety of new and updated models to more users. From the Google blog: Today, we’re making the updated Gemini 2.0 Flash generally available via the Gemini API in Google AI Studio and Vertex AI. Developers can",
  "siteName": "",
  "favicon": "https://www.macstories.net/app/themes/macstories4/images/apple-touch-icon-152x152-precomposed.png",
  "text": "Busy day at Google today: the company rolled out version 2.0 of its Gemini AI assistant (previously announced in December) with a variety of new and updated models to more users. From the Google blog: Today, we’re making the updated Gemini 2.0 Flash generally available via the Gemini API in Google AI Studio and Vertex AI. Developers can now build production applications with 2.0 Flash. We’re also releasing an experimental version of Gemini 2.0 Pro, our best model yet for coding performance and complex prompts. It is available in Google AI Studio and Vertex AI, and in the Gemini app for Gemini Advanced users. We’re releasing a new model, Gemini 2.0 Flash-Lite, our most cost-efficient model yet, in public preview in Google AI Studioand Vertex AI. Finally, 2.0 Flash Thinking Experimental will be available to Gemini app users in the model dropdown on desktop and mobile. Google’s reasoning model (which, similarly to DeepSeek-R1 or OpenAI’s o1/o3 family, can display its “chain of thought” and perform multi-step thinking about a user query) is currently ranked #1 in the popular Chatbot Arena LLM leaderboard. A separate blog post from Google also details the new pricing structure for third-party developers that want to integrate with the Gemini 2.0 API and confirms some of the features coming soon to both Gemini 2.0 Flash and 2.0 Pro, such as image and audio output. Notably, there is also a 2.0 Flash-Lite model that is even cheaper for developers, which I bet we’re going to see soon in utilities like Obsidian Web Clipper, composer fields of social media clients, and more. As part of my ongoing evaluation of assistive AI tools, since Gemini’s initial rollout in December, I’ve been using it in place of ChatGPT, progressively replacing the latter. Today, after the general release of 2.0 Flash, I went ahead and finally swapped ChatGPT for Gemini in my iPhone’s dock. This will probably need to be an in-depth article at some point, but my take so far is that although ChatGPT gets more media buzz and is the more mainstream product1, I think Google is doing more fascinating work with a) their proprietary AI silicon and b) turning LLMs into actual products for personal and professional use that are integrated with their ecosystem. Gemini (rightfully) got a bad rap with its initial release last year, and while it still hallucinates responses (but all LLMs still do), its 2.0 models are more than good enough for the sort of search queries I was asking ChatGPT before. Plus, we pay for Google Workspace at MacStories, and I like that Gemini is directly integrated with the services we use on a daily basis, such as Drive and Gmail. Most of all, I’m very intrigued by Gemini’s support for extensions, which turn conversations with a chatbot into actions that can be performed with other Google apps. For instance, I’ve been enjoying the ability to save research sessions to Google Keep by simply invoking the app and asking Gemini what I wanted to save. I’ve searched YouTube videos with it, looked up places in Google Maps, and – since I’ve been running a platform-agnostic home automation setup in my apartment that natively supports HomeKit, Alexa, and Google Home all at once – even controlled my lights with it. While custom GPTs in ChatGPT seem sort of abandonware now, Gemini’s app integrations are fully functional, integrated across the Google ecosystem, and expanding to third-party services as well.2 Even more impressively, today Google rolled out a preview of a reasoning version of Gemini 2.0 that can integrate with YouTube, Maps, and Search. The idea here is that Gemini can think longer about your request, display its thought process, then do something with apps. So I asked: I want you to find the best YouTube videos with Oasis acoustic performances where Liam is the singer. Only consider performances dated 1994-1996 that took place in Europe. I am not interested in demos, lyrics videos, or other non-live performances. They have to be acoustic sets with Noel playing the guitar and Liam singing. Surely enough, I was presented with some solid results. If Google can figure out how to integrate reasoning capabilities with advanced Gmail searches, that’s going to give services like Shortwave and Superhuman a run for their money. And that’s not to mention all the other apps in Google’s suite that could theoretically receive a similar treatment. However, the Gemini app falls short of ChatGPT and Claude in terms of iOS/iPadOS user experience in several key areas. The app doesn’t support widgets (which Claude has), doesn’t offer any Shortcuts actions (both Claude and ChatGPT have them), doesn’t have a native iPad app (sigh), and I can’t figure out if there’s a deep link to quickly start a new chat on iOS. The photo picker is also bad in that it only lets you attach one image at a time, and the web app doesn’t support native PWA installation on iPhone and iPad. Clearly, there’s a long road ahead for Google to make Gemini a great experience on Apple platforms. And yet, none of these missing features have been dealbreakers for me when Gemini is so fast and I can connect my conversations to the other Google services I already use. This is precisely why I remain convinced that a “Siri LLM” (“Siri Chat” as a product name, perhaps?) with support for conversations integrated and/or deep-linked to native iOS apps may be Apple’s greatest asset…in 2026. Ultimately, I believe that, even though ChatGPT has captured the world’s attention, it is Gemini that will be the ecosystem to beat for Apple. It always comes down to iPhone versus Android after all. Only this time, Apple is the one playing catch-up. Access Extra Content and PerksFounded in 2015, Club MacStories has delivered exclusive content every week for nearly a decade. What started with weekly and monthly email newsletters has blossomed into a family of memberships designed every MacStories fan. Learn more here and from our Club FAQs. Club MacStories: Weekly and monthly newsletters via email and the web that are brimming with apps, tips, automation workflows, longform writing, early access to the MacStories Unwind podcast, periodic giveaways, and more; Club MacStories+: Everything that Club MacStories offers, plus an active Discord community, advanced search and custom RSS features for exploring the Club’s entire back catalog, bonus columns, and dozens of app discounts; Club Premier: All of the above and AppStories+, an extended version of our flagship podcast that’s delivered early, ad-free, and in high-bitrate audio.",
  "image": "https://cdn.macstories.net/thursday-06-feb-2025-02-09-04-1738804149654.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                        \n\u003cp id=\"p2\"\u003eBusy day at Google today: the company rolled out version 2.0 of its Gemini AI assistant (previously \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/\" rel=\"noopener noreferrer\"\u003eannounced\u003c/a\u003e in December) with a variety of new and updated models to more users. From the \u003ca href=\"https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/\" rel=\"noopener noreferrer\"\u003eGoogle blog\u003c/a\u003e:\u003c/p\u003e\n\u003cblockquote id=\"blockquote3\"\u003e\u003cp\u003e\n  Today, we’re making the updated Gemini 2.0 Flash generally available via the Gemini API in \u003ca href=\"https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash\" rel=\"noopener noreferrer\"\u003eGoogle AI Studio\u003c/a\u003e and \u003ca href=\"https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio\" rel=\"noopener noreferrer\"\u003eVertex AI\u003c/a\u003e. Developers can now build production applications with 2.0 Flash.\u003c/p\u003e\n\u003cp\u003e  We’re also releasing an experimental version of Gemini 2.0 Pro, our best model yet for coding performance and complex prompts. It is available in \u003ca href=\"https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-pro-exp-02-05\" rel=\"noopener noreferrer\"\u003eGoogle AI Studio\u003c/a\u003e and \u003ca href=\"https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio\" rel=\"noopener noreferrer\"\u003eVertex AI\u003c/a\u003e, and in the \u003ca href=\"https://gemini.google.com/\" rel=\"noopener noreferrer\"\u003eGemini app\u003c/a\u003e for Gemini Advanced users.\u003c/p\u003e\n\u003cp\u003e  We’re releasing a new model, Gemini 2.0 Flash-Lite, our most cost-efficient model yet, in public preview in \u003ca href=\"https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-lite-preview-02-05\" rel=\"noopener noreferrer\"\u003eGoogle AI Studio\u003c/a\u003eand \u003ca href=\"https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio\" rel=\"noopener noreferrer\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e  Finally, \u003ca href=\"https://blog.google/feed/gemini-app-experimental-models\" rel=\"noopener noreferrer\"\u003e2.0 Flash Thinking Experimental will be available to Gemini app\u003c/a\u003e users in the model dropdown on desktop and mobile.\n\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003cp id=\"p5\"\u003eGoogle’s reasoning model (which, similarly to \u003ca href=\"https://www.deepseek.com/\" rel=\"noopener noreferrer\"\u003eDeepSeek-R1\u003c/a\u003e or OpenAI’s o1/\u003ca href=\"https://openai.com/index/openai-o3-mini/\" rel=\"noopener noreferrer\"\u003eo3\u003c/a\u003e family, can display its “chain of thought” and perform multi-step thinking about a user query) is \u003ca href=\"https://lmarena.ai/?leaderboard\" rel=\"noopener noreferrer\"\u003ecurrently\u003c/a\u003e ranked #1 in the popular Chatbot Arena LLM leaderboard. A \u003ca href=\"https://developers.googleblog.com/en/gemini-2-family-expands/\" rel=\"noopener noreferrer\"\u003eseparate blog post\u003c/a\u003e from Google also details the new pricing structure for third-party developers that want to integrate with the Gemini 2.0 API and confirms some of the features coming soon to both Gemini 2.0 Flash and 2.0 Pro, such as image and audio output. Notably, there is also a 2.0 Flash-Lite model that is even cheaper for developers, which I bet we’re going to see soon in utilities like \u003ca href=\"https://obsidian.md/clipper\" rel=\"noopener noreferrer\"\u003eObsidian Web Clipper\u003c/a\u003e, composer fields of social media clients, and more.\u003c/p\u003e\n\u003cp id=\"p6\"\u003eAs part of my ongoing evaluation of \u003ca href=\"https://appstories.net/episodes/414\" rel=\"noopener noreferrer\"\u003eassistive AI tools\u003c/a\u003e, since Gemini’s initial rollout in December, I’ve been using it in place of ChatGPT, progressively replacing the latter. Today, after the general release of 2.0 Flash, I went ahead and finally swapped ChatGPT for Gemini in my iPhone’s dock.\u003c/p\u003e\n\u003cp id=\"p7\"\u003eThis will probably need to be an in-depth article at some point, but my take so far is that although ChatGPT gets more media buzz and is the more mainstream product\u003csup id=\"fnref-77777-o1-pro\"\u003e\u003ca href=\"#fn-77777-o1-pro\" rel=\"noopener noreferrer\"\u003e1\u003c/a\u003e\u003c/sup\u003e, I think Google is doing more fascinating work with a) their \u003ca href=\"https://cloud.google.com/blog/products/compute/introducing-trillium-6th-gen-tpus\" rel=\"noopener noreferrer\"\u003eproprietary AI silicon\u003c/a\u003e and b) turning LLMs into actual products for personal and professional use that are integrated with their ecosystem. Gemini (rightfully) got a bad rap with its initial release last year, and while it still hallucinates responses (but all LLMs still do), its 2.0 models are more than good enough for the sort of search queries I was asking ChatGPT before. Plus, we pay for Google Workspace at MacStories, and I like that Gemini is directly integrated with the services we use on a daily basis, such as Drive and Gmail.\u003c/p\u003e\n\u003cp id=\"p8\"\u003eMost of all, I’m \u003cem\u003every\u003c/em\u003e intrigued by Gemini’s support for \u003ca href=\"https://support.google.com/gemini/answer/13695044?hl=en\u0026amp;co=GENIE.Platform%3DAndroid\" rel=\"noopener noreferrer\"\u003eextensions\u003c/a\u003e, which turn conversations with a chatbot into actions that can be performed with other Google apps. For instance, I’ve been enjoying the ability to save research sessions to \u003ca href=\"https://keep.google.com/\" rel=\"noopener noreferrer\"\u003eGoogle Keep\u003c/a\u003e by simply invoking the app and asking Gemini what I wanted to save. I’ve searched YouTube videos with it, looked up places in Google Maps, and – since I’ve been running a platform-agnostic home automation setup in my apartment that natively supports HomeKit, Alexa, and Google Home all at once – even controlled my lights with it. While custom GPTs in ChatGPT seem sort of abandonware now, Gemini’s app integrations are fully functional, integrated across the Google ecosystem, and \u003ca href=\"https://www.theverge.com/2024/11/26/24306815/google-gemini-spotify-extension-rollout-android\" rel=\"noopener noreferrer\"\u003eexpanding\u003c/a\u003e to third-party services as well.\u003csup id=\"fnref-77777-geminiTodoist\"\u003e\u003ca href=\"#fn-77777-geminiTodoist\" rel=\"noopener noreferrer\"\u003e2\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003cp id=\"p9\"\u003eEven more impressively, today Google rolled out a preview of a reasoning version of Gemini 2.0 that can integrate with YouTube, Maps, and Search. The idea here is that Gemini can think longer about your request, display its thought process, then do \u003cem\u003esomething\u003c/em\u003e with apps. So I asked:\u003c/p\u003e\n\u003cblockquote id=\"blockquote10\"\u003e\u003cp\u003e\n  I want you to find the best YouTube videos with Oasis acoustic performances where Liam is the singer. Only consider performances dated 1994-1996 that took place in Europe. I am not interested in demos, lyrics videos, or other non-live performances. They have to be acoustic sets with Noel playing the guitar and Liam singing.\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp id=\"p11\"\u003eSurely enough, I was presented with \u003ca href=\"https://bsky.app/profile/viticci.macstories.net/post/3lhgwua7mps2s\" rel=\"noopener noreferrer\"\u003esome solid results\u003c/a\u003e. If Google can figure out how to integrate reasoning capabilities with advanced Gmail searches, that’s going to give services like \u003ca href=\"https://www.shortwave.com/\" rel=\"noopener noreferrer\"\u003eShortwave\u003c/a\u003e and \u003ca href=\"https://superhuman.com/\" rel=\"noopener noreferrer\"\u003eSuperhuman\u003c/a\u003e a run for their money. And that’s not to mention all the other apps in Google’s suite that could theoretically receive a similar treatment.\u003c/p\u003e\n\n\u003cp id=\"p13\"\u003eHowever, the Gemini app falls short of ChatGPT and \u003ca href=\"https://claude.ai/\" rel=\"noopener noreferrer\"\u003eClaude\u003c/a\u003e in terms of iOS/iPadOS user experience in several key areas.\u003c/p\u003e\n\u003cp id=\"p14\"\u003eThe app doesn’t support widgets (which Claude has), doesn’t offer any Shortcuts actions (both Claude and ChatGPT have them), doesn’t have a native iPad app (\u003cem\u003esigh\u003c/em\u003e), and I can’t figure out if there’s a deep link to quickly start a new chat on iOS. The photo picker is also bad in that it only lets you attach one image at a time, and the web app doesn’t support native PWA installation on iPhone and iPad.\u003c/p\u003e\n\u003cp id=\"p15\"\u003eClearly, there’s a long road ahead for Google to make Gemini a great experience on Apple platforms. And yet, none of these missing features have been dealbreakers for me when Gemini is so fast and I can connect my conversations to the other Google services I already use. This is precisely why I remain convinced that a “Siri LLM” (“Siri Chat” as a product name, perhaps?) with support for conversations integrated and/or deep-linked to native iOS apps may be Apple’s greatest asset…in \u003ca href=\"https://www.bloomberg.com/news/articles/2024-11-21/apple-readies-more-conversational-llm-siri-in-bid-to-rival-openai-s-chatgpt\" rel=\"noopener noreferrer\"\u003e2026\u003c/a\u003e.\u003c/p\u003e\n\u003cp id=\"p16\"\u003eUltimately, I believe that, even though ChatGPT has captured the world’s attention, it is Gemini that will be \u003cem\u003ethe\u003c/em\u003e ecosystem to beat for Apple. It always comes down to iPhone versus Android after all. Only \u003ca href=\"https://en.wikipedia.org/wiki/HTC_Dream\" rel=\"noopener noreferrer\"\u003ethis time\u003c/a\u003e, Apple is the one playing catch-up.\u003c/p\u003e\n\n            \u003c/div\u003e\u003cdiv\u003e\n            \u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://www.macstories.net/app/themes/macstories4/images/logo-shape-gold.svg\" alt=\"Club MacStories\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch3\u003eAccess Extra Content and Perks\u003c/h3\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003eFounded in 2015, \u003ca href=\"https://club.macstories.net/plans?utm_source=ms\u0026amp;utm_medium=web-inline\" rel=\"noopener noreferrer\"\u003eClub MacStories\u003c/a\u003e has delivered exclusive content every week for nearly a decade.\u003c/p\u003e\n\u003cp\u003eWhat started with weekly and monthly email newsletters has blossomed into \u003ca href=\"https://club.macstories.net/plans?utm_source=ms\u0026amp;utm_medium=web-inline\" rel=\"noopener noreferrer\"\u003ea family of memberships\u003c/a\u003e designed every MacStories fan.\u003c/p\u003e\n\u003cp\u003eLearn more \u003ca href=\"https://club.macstories.net/plans?utm_source=ms\u0026amp;utm_medium=web-inline\" rel=\"noopener noreferrer\"\u003ehere\u003c/a\u003e and from our \u003ca href=\"https://club.macstories.net/faq\" rel=\"noopener noreferrer\"\u003eClub FAQs\u003c/a\u003e.\u003c/p\u003e\n\u003c/div\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://club.macstories.net/plans/club\" rel=\"noopener noreferrer\"\u003eClub MacStories\u003c/a\u003e\u003c/strong\u003e: Weekly and monthly newsletters via email and the web that are brimming with apps, tips, automation workflows, longform writing, early access to the \u003ca href=\"https://www.macstories.net/unwind/\" rel=\"noopener noreferrer\"\u003eMacStories Unwind podcast\u003c/a\u003e, periodic giveaways, and more;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://club.macstories.net/plans/plus\" rel=\"noopener noreferrer\"\u003eClub MacStories+\u003c/a\u003e\u003c/strong\u003e: Everything that Club MacStories offers, plus an active Discord community, advanced search and custom RSS features for exploring the Club’s entire back catalog, bonus columns, and dozens of app discounts;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://club.macstories.net/plans/premier\" rel=\"noopener noreferrer\"\u003eClub Premier\u003c/a\u003e\u003c/strong\u003e: All of the above \u003cem\u003eand\u003c/em\u003e AppStories+, an extended version of our flagship podcast that’s delivered early, ad-free, and in high-bitrate audio.\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e        \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-02-06T01:34:36-05:00",
  "modifiedTime": null
}
