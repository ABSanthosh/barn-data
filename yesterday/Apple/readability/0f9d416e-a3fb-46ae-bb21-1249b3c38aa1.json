{
  "id": "0f9d416e-a3fb-46ae-bb21-1249b3c38aa1",
  "title": "Apple Previews a Wide Range of Upcoming Accessibility Features to Mark Global Accessibility Awareness Day",
  "link": "https://www.macstories.net/news/apple-previews-a-wide-range-of-upcoming-accessibility-features-to-mark-global-accessibility-awareness-day/",
  "description": "Source: Apple. With Global Accessibility Awareness Day coming up this Thursday, May 15, Apple is back with its annual preview of accessibility features coming to its platforms later in the year. This year marks the 40th anniversary of the creation of the first office within Apple to address accessibility, and there’s no sign of any […]",
  "author": "Jonathan Reed",
  "published": "Tue, 13 May 2025 12:03:55 +0000",
  "source": "https://www.macstories.net/feed",
  "categories": [
    "news",
    "accessibility",
    "app store",
    "apple tv",
    "braille",
    "CarPlay",
    "Live Captions",
    "Live Listen",
    "Magnifier",
    "Nutrition Labels",
    "Personal Voice",
    "System Haptics",
    "Vision Pro",
    "visionOS"
  ],
  "byline": "Jonathan Reed",
  "length": 7071,
  "excerpt": "With Global Accessibility Awareness Day coming up this Thursday, May 15, Apple is back with its annual preview of accessibility features coming to its platforms later in the year. This year marks the 40th anniversary of the creation of the first office within Apple to address accessibility, and there’s no sign of any slowdown in",
  "siteName": "",
  "favicon": "https://www.macstories.net/app/themes/macstories4/images/apple-touch-icon-152x152-precomposed.png",
  "text": "With Global Accessibility Awareness Day coming up this Thursday, May 15, Apple is back with its annual preview of accessibility features coming to its platforms later in the year. This year marks the 40th anniversary of the creation of the first office within Apple to address accessibility, and there’s no sign of any slowdown in the company’s development on this front. While no official release date has been announced for these features, they usually arrive with the new OS updates in the fall. In addition to a new accessibility-focused feature in the App Store, Apple announced a whole raft of system-level features. Let’s take a look. App Store Accessibility Nutrition Labels Launched in December 2020, the App Store’s Privacy Nutrition Labels are part of an app’s listing that inform users what sort of private information is obtained and used by the app. Now, Apple is expanding this approach into accessibility, launching worldwide. In the same way developers create Privacy Nutrition Labels, they can also create labels showing the accessibility features supported by their apps. Features such as VoiceOver, Reduce Motion, captions, and more can be listed, making it easier for those with accessibility needs to choose the right app for them. Developers can also place links to their own accessibility websites in this section. As with Privacy Nutrition Labels, the information displayed in Accessibility Nutrition Labels is chosen by app developers. However, Apple says it will continue monitoring this feature going forward to ensure it works as intended. Magnifier Comes to the Mac Apple’s Magnifier app on the iPhone offers a way to zoom in on objects around you, make text clearer, and identify the distance to objects like doors and people. Later this year, Apple will bring Magnifier to the Mac with some more tricks up its sleeve. By connecting your iPhone to your Mac with Continuity Camera, or by using a USB-compatible camera, your Mac can take images and allow you to manipulate them in ways that make them easier to see. In one provided example, a student in a lecture attached a camera to their MacBook Air using a mount and pointed the camera at the whiteboard. Then, using the Magnifier app, they snapped some pictures of diagrams and notes, adjusted the contrast, changed the colors, and enlarged the text to make the lecture more accessible for them. In the example image above, you can see the student pointing the camera at a textbook to get its content onto their MacBook to read using Desk View. Magnifier on the Mac even allows users to conduct multiple live sessions to follow along in a textbook while reading content on a large screen. Users can save images they capture in groups for use at a later date. Live Listen + Live Captions Live Listen is a feature that was announced in 2014 to allow users with compatible hearing aids to hear people in noisy environments or from across a room by placing an iPhone close to the speaker. AirPods gained this functionality in 2018, and now, Apple is pairing it with Live Captions and bringing the Apple Watch into the mix. Live Captions already captions live conversations on your iPhone, but later this year, you’ll be able to place your phone across the room and send the captions directly to your Apple Watch. You can pause, rewind, start, and stop Live Captions directly from your Apple Watch, which means no more getting up in the middle of a lecture to turn off your iPhone’s microphone. Additionally, Live Captions is adding support for new languages: English (India, Australia, UK, Singapore), Mandarin Chinese (Mainland China), Cantonese (Mainland China, Hong Kong), Spanish (Latin America, Spain), French (France, Canada), Japanese, German (Germany), and Korean. Improved Personal Voice Personal Voice was introduced in 2023 with iOS 17. It allows you to generate a synthetic version of your own voice that can be used to read text. It’s an excellent feature that allows people who are losing the ability to speak to preserve their voices. One big downside of Personal Voice is the time and effort it takes to set it up. Apple has made significant improvements in this area. To train your Personal Voice, you will need to speak only 10 phrases, down from 150. And the results will be available in minutes rather than overnight (or longer, in my case). In addition to these improvements to setup, Personal Voice will sound more natural and be available in Spanish for users in Mexico and the United States. Braille Access For braille users, Braille Access provides a way to connect a braille device to an iPhone, iPad, Mac, or Vision Pro and turn it into a full-featured braille note taker. Users can even use the Live Captions feature with their braille devices to transcribe conversations in real time. visionOS For visionOS, Apple has revealed new capabilities that allow a user to zoom in on areas within their field of view. The company has also committed to letting approved accessibility apps access the Vision Pro’s camera with a new API. With that new access, apps will be able to provide person-to-person assistance and new ways for users to understand their surroundings. Accessibility Reader In a new system-wide feature that will no doubt be used by a wide range of users, Accessibility Reader can transform areas of text in apps, documents, and more in any way you like to make them easier to read. You can quickly adjust spacing, enlarge text, change colors, and more without changing the original formatting of an app or a document. Additional Tidbits Background Sounds can be customized with timers, new Shortcuts actions, and EQ settings. Vehicle Motion Cues make their way to the Mac. Eye Tracking on iPhone and iPad is faster and easier to use, and it now allows users to use either a switch or Dwell Control to select elements. Users can also now “swipe-type” with Switch Control. Assistive Access adds a new Apple TV app, offering users a simplified media player. The Assistive Access API now allows users to build apps for people with intellectual and developmental disabilities. CarPlay supports Large Text and the ability for Sound Recognition to detect crying babies. Music Haptics are more customizable and now available for either the whole track or just vocals. Sound Recognition is now able to recognize names being called. Users can temporarily share their accessibility settings with other iPhones or iPads. In addition to all of these feature announcements, Apple is celebrating GAAD with updates to its Haptics playlists in Apple Music, a special Fitness+ dance workout with Chelsie Hill, a behind-the-scenes look at Apple Original documentary film Deaf President Now! (streaming this Friday on Apple TV+), and spotlights in the App Store, Apple Books, Apple Podcasts, Apple News, and Apple TV. Apple’s announcements for accessibility users always provide a fascinating look into the positive technologies the company is bringing to its platforms. This year is no different, and it’s great to see Apple’s continued commitment to this area.",
  "image": "https://cdn.macstories.net/apple-accessibility-features-app-store-nutrition-labels-1747131462554.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                        \n\u003cp id=\"p2\"\u003eWith \u003ca href=\"https://accessibility.day/\" rel=\"noopener noreferrer\"\u003eGlobal Accessibility Awareness Day\u003c/a\u003e coming up this Thursday, May 15, Apple is back with its annual \u003ca href=\"https://www.apple.com/newsroom/2025/05/apple-unveils-powerful-accessibility-features-coming-later-this-year/?1747137672\" rel=\"noopener noreferrer\"\u003epreview\u003c/a\u003e of accessibility features coming to its platforms later in the year. This year marks the 40th anniversary of the creation of the first office within Apple to address accessibility, and there’s no sign of any slowdown in the company’s development on this front. While no official release date has been announced for these features, they usually arrive with the new OS updates in the fall.\u003c/p\u003e\n\u003cp id=\"p3\"\u003eIn addition to a new accessibility-focused feature in the App Store, Apple announced a whole raft of system-level features. Let’s take a look.\u003c/p\u003e\n\n\u003ch2 id=\"app-store-accessibility-nutrition-labels\"\u003eApp Store Accessibility Nutrition Labels\u003c/h2\u003e\n\u003cp id=\"p5\"\u003eLaunched in December 2020, the App Store’s \u003ca href=\"https://support.apple.com/en-gb/102399\" rel=\"noopener noreferrer\"\u003ePrivacy Nutrition Labels\u003c/a\u003e are part of an app’s listing that inform users what sort of private information is obtained and used by the app. Now, Apple is expanding this approach into accessibility, launching worldwide.\u003c/p\u003e\n\u003cp id=\"p6\"\u003eIn the same way developers create Privacy Nutrition Labels, they can also create labels showing the accessibility features supported by their apps. Features such as \u003ca href=\"https://support.apple.com/en-gb/guide/iphone/iph3e2e415f/ios\" rel=\"noopener noreferrer\"\u003eVoiceOver\u003c/a\u003e, \u003ca href=\"https://support.apple.com/en-gb/111781\" rel=\"noopener noreferrer\"\u003eReduce Motion\u003c/a\u003e, captions, and more can be listed, making it easier for those with accessibility needs to choose the right app for them. Developers can also place links to their own accessibility websites in this section.\u003c/p\u003e\n\u003cp id=\"p7\"\u003eAs with Privacy Nutrition Labels, the information displayed in Accessibility Nutrition Labels is chosen by app developers. However, Apple says it will continue monitoring this feature going forward to ensure it works as intended.\u003c/p\u003e\n\u003ch2 id=\"magnifier-comes-to-the-mac\"\u003eMagnifier Comes to the Mac\u003c/h2\u003e\n\n\u003cp id=\"p9\"\u003eApple’s \u003ca href=\"https://support.apple.com/en-gb/105102\" rel=\"noopener noreferrer\"\u003eMagnifier\u003c/a\u003e app on the iPhone offers a way to zoom in on objects around you, make text clearer, and identify the distance to objects like doors and people. Later this year, Apple will bring Magnifier to the Mac with some more tricks up its sleeve.\u003c/p\u003e\n\u003cp id=\"p10\"\u003eBy connecting your iPhone to your Mac with \u003ca href=\"https://support.apple.com/en-gb/102546\" rel=\"noopener noreferrer\"\u003eContinuity Camera\u003c/a\u003e, or by using a USB-compatible camera, your Mac can take images and allow you to manipulate them in ways that make them easier to see. In one provided example, a student in a lecture attached a camera to their MacBook Air using a mount and pointed the camera at the whiteboard. Then, using the Magnifier app, they snapped some pictures of diagrams and notes, adjusted the contrast, changed the colors, and enlarged the text to make the lecture more accessible for them.\u003c/p\u003e\n\u003cp id=\"p11\"\u003eIn the example image above, you can see the student pointing the camera at a textbook to get its content onto their MacBook to read using \u003ca href=\"https://support.apple.com/en-gb/guide/mac-help/mchl06927be8/mac\" rel=\"noopener noreferrer\"\u003eDesk View\u003c/a\u003e. Magnifier on the Mac even allows users to conduct multiple live sessions to follow along in a textbook while reading content on a large screen. Users can save images they capture in groups for use at a later date.\u003c/p\u003e\n\u003ch2 id=\"live-listen-live-captions\"\u003eLive Listen + Live Captions\u003c/h2\u003e\n\n\u003cp id=\"p13\"\u003e\u003ca href=\"https://support.apple.com/en-gb/102479\" rel=\"noopener noreferrer\"\u003eLive Listen\u003c/a\u003e is a feature that was announced in 2014 to allow users with compatible hearing aids to hear people in noisy environments or from across a room by placing an iPhone close to the speaker. AirPods gained this functionality in 2018, and now, Apple is pairing it with \u003ca href=\"https://support.apple.com/en-gb/guide/iphone/iphe0990f7bb/ios\" rel=\"noopener noreferrer\"\u003eLive Captions\u003c/a\u003e and bringing the Apple Watch into the mix. Live Captions already captions live conversations on your iPhone, but later this year, you’ll be able to place your phone across the room and send the captions directly to your Apple Watch.\u003c/p\u003e\n\u003cp id=\"p14\"\u003eYou can pause, rewind, start, and stop Live Captions directly from your Apple Watch, which means no more getting up in the middle of a lecture to turn off your iPhone’s microphone. Additionally, Live Captions is adding support for new languages: English (India, Australia, UK, Singapore), Mandarin Chinese (Mainland China), Cantonese (Mainland China, Hong Kong), Spanish (Latin America, Spain), French (France, Canada), Japanese, German (Germany), and Korean.\u003c/p\u003e\n\u003ch2 id=\"improved-personal-voice\"\u003eImproved Personal Voice\u003c/h2\u003e\n\u003cp id=\"p15\"\u003e\u003ca href=\"https://www.macstories.net/stories/a-conversation-with-david-niemeijer-of-assistiveware-about-personal-voice-assistive-access-and-developing-apps-for-accessibility/\" rel=\"noopener noreferrer\"\u003ePersonal Voice\u003c/a\u003e was introduced in 2023 with iOS 17. It allows you to generate a synthetic version of your own voice that can be used to read text. It’s an excellent feature that allows people who are losing the ability to speak to preserve their voices. One big downside of Personal Voice is the time and effort it takes to set it up. Apple has made significant improvements in this area.\u003c/p\u003e\n\u003cp id=\"p16\"\u003eTo train your Personal Voice, you will need to speak only 10 phrases, down from 150. And the results will be available in minutes rather than overnight (or longer, in my case). In addition to these improvements to setup, Personal Voice will sound more natural and be available in Spanish for users in Mexico and the United States.\u003c/p\u003e\n\u003ch2 id=\"braille-access\"\u003eBraille Access\u003c/h2\u003e\n\n\u003cp id=\"p18\"\u003eFor braille users, Braille Access provides a way to connect a braille device to an iPhone, iPad, Mac, or Vision Pro and turn it into a full-featured braille note taker. Users can even use the Live Captions feature with their braille devices to transcribe conversations in real time.\u003c/p\u003e\n\u003ch2 id=\"visionos\"\u003evisionOS\u003c/h2\u003e\n\n\u003cp id=\"p20\"\u003eFor visionOS, Apple has revealed new capabilities that allow a user to zoom in on areas within their field of view. The company has also committed to letting approved accessibility apps access the Vision Pro’s camera with a new API. With that new access, apps will be able to provide person-to-person assistance and new ways for users to understand their surroundings.\u003c/p\u003e\n\u003ch2 id=\"accessibility-reader\"\u003eAccessibility Reader\u003c/h2\u003e\n\n\u003cp id=\"p22\"\u003eIn a new system-wide feature that will no doubt be used by a wide range of users, Accessibility Reader can transform areas of text in apps, documents, and more in any way you like to make them easier to read. You can quickly adjust spacing, enlarge text, change colors, and more without changing the original formatting of an app or a document.\u003c/p\u003e\n\u003ch2 id=\"additional-tidbits\"\u003eAdditional Tidbits\u003c/h2\u003e\n\n\u003cul id=\"ul24\"\u003e\u003cli\u003e\u003ca href=\"https://support.apple.com/en-gb/109346\" rel=\"noopener noreferrer\"\u003eBackground Sounds\u003c/a\u003e can be customized with timers, new Shortcuts actions, and EQ settings.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=Ga22EthUCjA\" rel=\"noopener noreferrer\"\u003eVehicle Motion Cues\u003c/a\u003e make their way to the Mac.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://support.apple.com/en-gb/guide/iphone/iph66057d0f6/ios\" rel=\"noopener noreferrer\"\u003eEye Tracking\u003c/a\u003e on iPhone and iPad is faster and easier to use, and it now allows users to use either a switch or Dwell Control to select elements. Users can also now “swipe-type” with Switch Control.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://support.apple.com/en-gb/guide/assistive-access-iphone/welcome/ios\" rel=\"noopener noreferrer\"\u003eAssistive Access\u003c/a\u003e adds a new Apple TV app, offering users a simplified media player. The Assistive Access API now allows users to build apps for people with intellectual and developmental disabilities.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cul id=\"ul26\"\u003e\u003cli\u003eCarPlay supports Large Text and the ability for Sound Recognition to detect crying babies.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://support.apple.com/en-bh/guide/iphone/iphff2ceeb16/ios\" rel=\"noopener noreferrer\"\u003eMusic Haptics\u003c/a\u003e are more customizable and now available for either the whole track or just vocals.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://support.apple.com/en-gb/guide/iphone/iphf2dc33312/ios\" rel=\"noopener noreferrer\"\u003eSound Recognition\u003c/a\u003e is now able to recognize names being called.\u003c/li\u003e\n\u003cli\u003eUsers can temporarily share their accessibility settings with other iPhones or iPads.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp id=\"p27\"\u003eIn addition to all of these feature announcements, Apple is celebrating GAAD with updates to its \u003ca href=\"https://music.apple.com/us/multi-room/6670447147\" rel=\"noopener noreferrer\"\u003eHaptics playlists\u003c/a\u003e in Apple Music, a special Fitness+ \u003ca href=\"https://fitness.apple.com/us/workout/dance-with-ben-feat-dancer-chelsie-hill/1808529158\" rel=\"noopener noreferrer\"\u003edance workout\u003c/a\u003e with Chelsie Hill, a \u003ca href=\"https://youtu.be/6NFRG3Fomjw\" title=\"behind-the-scenes look\" rel=\"noopener noreferrer\"\u003ebehind-the-scenes look\u003c/a\u003e at Apple Original documentary film Deaf President Now! (streaming this Friday on Apple TV+), and spotlights in the App Store, Apple Books, Apple Podcasts, Apple News, and Apple TV.\u003c/p\u003e\n\u003cp id=\"p28\"\u003eApple’s announcements for accessibility users always provide a fascinating look into the positive technologies the company is bringing to its platforms. This year is no different, and it’s great to see Apple’s continued commitment to this area.\u003c/p\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-05-13T12:03:55-04:00",
  "modifiedTime": null
}
