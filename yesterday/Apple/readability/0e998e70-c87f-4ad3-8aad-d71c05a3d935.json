{
  "id": "0e998e70-c87f-4ad3-8aad-d71c05a3d935",
  "title": "How will Apple improve its AI while protecting your privacy?",
  "link": "https://www.macworld.com/article/2686346/how-will-apple-improve-its-ai-while-protecting-your-privacy.html",
  "description": "Macworld With all the problems we’ve heard about Apple Intelligence lately–delayed Siri improvements, bad news notification summaries, unimpressive image generation, and more–you might wonder what Apple is planning to do to right the ship. Obviously new and improved models are important, and so in increased training, but Apple has a particularly hard time of this because its privacy policies are a lot more strict than other companies creating AI products. In a new post on Apple’s Machine Learning Research site, the company explains a technique it will employ to help its AI be more relevant, more often, without training it on your personal data. Ensuring privacy while polling for usage data Differential Privacy is a way to, as Apple puts it, “gain insight into what many Apple users are doing, while helping to preserve the privacy of individual users.” Basically, whenever Apple collects data in a system like this, it first strips out any identifying information (device ID, IP address, and so on) and then slightly alters the data. When millions of users submit results, that “noise” cancels out. That’s the Differential Privacy part: take enough samples with random noise and identifiers removed, and you can’t possibly connect any particular bit of data with a user. It’s a good way to, for example, get a good statistical sample of which emoji are picked most often, or which autocorrect word is used the most after a particular misspelling–collecting data on user preferences without actually being able to trace any particular data point back to any user, even if they wanted to. Apple can generate synthetic text that is representative of common prompts, then use those differential privacy techniques to find out which synthetic samples are selected by users most often. Or to determine which words and phrases are common in Genmoji prompts and which results the users are most likely to pick. The AI system could generate common sentences used in emails, for example, and then send multiple variants out to different users. Then, using differential privacy techniques, Apple can find out which ones are selected most frequently (while having no ability to know what any one individual chose). Apple has been using this technique for years to gather data meant to improve QuickType suggestions, emoji suggestions, lookup hints, and more. As anonymous as it is, it is still opt-in. Apple doesn’t collect this type of data unless you affirmatively enable device analytics. Techniques like this are already being used to improve Genmoji, and in an upcoming update, they’ll be used for Image Generation, Image Wand, Memories Creation, Writing Tools, and Visual Intelligence. A Bloomberg report says the new system will come in a beta update to iOS 18.5, iPadOS 18.5, and macOS 18.5 (the second beta was released today). Of course, this is just data gathering, and it will take weeks or months of data collection and retraining to measurably improve Apple Intelligence features.",
  "author": "",
  "published": "Mon, 14 Apr 2025 22:18:03 +0000",
  "source": "https://www.macworld.com/index.rss",
  "categories": [
    "Apple Inc"
  ],
  "byline": "Author: Jason Cross, Senior Editor, Macworld",
  "length": 3029,
  "excerpt": "Apple uses Differential Privacy to learn trends about how its user base is using AI.",
  "siteName": "Macworld",
  "favicon": "https://www.macworld.com/wp-content/uploads/2021/03/cropped-macworld-favicon.png?w=192",
  "text": "With all the problems we’ve heard about Apple Intelligence lately–delayed Siri improvements, bad news notification summaries, unimpressive image generation, and more–you might wonder what Apple is planning to do to right the ship. Obviously new and improved models are important, and so in increased training, but Apple has a particularly hard time of this because its privacy policies are a lot more strict than other companies creating AI products. In a new post on Apple’s Machine Learning Research site, the company explains a technique it will employ to help its AI be more relevant, more often, without training it on your personal data. Ensuring privacy while polling for usage data Differential Privacy is a way to, as Apple puts it, “gain insight into what many Apple users are doing, while helping to preserve the privacy of individual users.” Basically, whenever Apple collects data in a system like this, it first strips out any identifying information (device ID, IP address, and so on) and then slightly alters the data. When millions of users submit results, that “noise” cancels out. That’s the Differential Privacy part: take enough samples with random noise and identifiers removed, and you can’t possibly connect any particular bit of data with a user. It’s a good way to, for example, get a good statistical sample of which emoji are picked most often, or which autocorrect word is used the most after a particular misspelling–collecting data on user preferences without actually being able to trace any particular data point back to any user, even if they wanted to. Apple can generate synthetic text that is representative of common prompts, then use those differential privacy techniques to find out which synthetic samples are selected by users most often. Or to determine which words and phrases are common in Genmoji prompts and which results the users are most likely to pick. The AI system could generate common sentences used in emails, for example, and then send multiple variants out to different users. Then, using differential privacy techniques, Apple can find out which ones are selected most frequently (while having no ability to know what any one individual chose). Apple has been using this technique for years to gather data meant to improve QuickType suggestions, emoji suggestions, lookup hints, and more. As anonymous as it is, it is still opt-in. Apple doesn’t collect this type of data unless you affirmatively enable device analytics. Techniques like this are already being used to improve Genmoji, and in an upcoming update, they’ll be used for Image Generation, Image Wand, Memories Creation, Writing Tools, and Visual Intelligence. A Bloomberg report says the new system will come in a beta update to iOS 18.5, iPadOS 18.5, and macOS 18.5 (the second beta was released today). Of course, this is just data gathering, and it will take weeks or months of data collection and retraining to measurably improve Apple Intelligence features.",
  "image": "https://www.macworld.com/wp-content/uploads/2025/04/siri-apple-intelligence-graphic.jpg?quality=50\u0026strip=all\u0026w=1024",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"link_wrapped_content\"\u003e\n\n\n\n\n\u003cp\u003eWith all the problems we’ve heard about Apple Intelligence lately–delayed Siri improvements, bad news notification summaries, unimpressive image generation, and more–you might wonder what Apple is planning to do to right the ship.\u003c/p\u003e\n\n\n\n\u003cp\u003eObviously new and improved models are important, and so in increased training, but Apple has a particularly hard time of this because its privacy policies are a lot more strict than other companies creating AI products. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn a new post on \u003ca href=\"https://go.skimresources.com?id=111346X1569486\u0026amp;xs=1\u0026amp;url=https://machinelearning.apple.com/research/differential-privacy-aggregate-trends\u0026amp;xcust=1-1-2686346-1-0-0-0-0\u0026amp;sref=https://www.macworld.com/article/2686346/how-will-apple-improve-its-ai-while-protecting-your-privacy.html\" rel=\"nofollow\" data-subtag=\"1-1-2686346-1-0-0-0-0\" data-domain-name=\"apple\" target=\"_blank\"\u003eApple’s Machine Learning Research\u003c/a\u003e site, the company explains a technique it will employ to help its AI be more relevant, more often, without training it on your personal data.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"ensuring-privacy-while-polling-for-usage-data\"\u003eEnsuring privacy while polling for usage data\u003c/h2\u003e\n\n\n\n\u003cp\u003eDifferential Privacy is a way to, as Apple puts it, “gain insight into what many Apple users are doing, while helping to preserve the privacy of individual users.” \u003c/p\u003e\n\n\t\t\n\t\t\t\n\t\t\t\n\n\n\u003cp\u003eBasically, whenever Apple collects data in a system like this, it first strips out any identifying information (device ID, IP address, and so on) and then \u003cem\u003eslightly alters\u003c/em\u003e the data. When millions of users submit results, that “noise” cancels out. That’s the Differential Privacy part: take enough samples with random noise and identifiers removed, and you can’t possibly connect any particular bit of data with a user.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt’s a good way to, for example, get a good statistical sample of which emoji are picked most often, or which autocorrect word is used the most after a particular misspelling–collecting data on user preferences without actually being able to trace any particular data point back to any user, even if they wanted to.\u003c/p\u003e\n\n\n\n\u003cp\u003eApple can generate synthetic text that is representative of common prompts, then use those differential privacy techniques to find out which synthetic samples are selected by users most often. Or to determine which words and phrases are common in Genmoji prompts and which results the users are most likely to pick.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe AI system could generate common sentences used in emails, for example, and then send multiple variants out to different users. Then, using differential privacy techniques, Apple can find out which ones are selected most frequently (while having no ability to know what any one individual chose).\u003c/p\u003e\n\n\n\n\u003cp\u003eApple has been using this technique for years to gather data meant to improve QuickType suggestions, emoji suggestions, lookup hints, and more. As anonymous as it is, it is still opt-in. Apple doesn’t collect this type of data unless you affirmatively enable device analytics.\u003c/p\u003e\n\n\n\n\u003cp\u003eTechniques like this are already being used to improve Genmoji, and in an upcoming update, they’ll be used for Image Generation, Image Wand, Memories Creation, Writing Tools, and Visual Intelligence. A \u003ca href=\"https://go.skimresources.com?id=111346X1569486\u0026amp;xs=1\u0026amp;url=https://www.bloomberg.com/news/articles/2025-04-14/apple-to-analyze-user-data-on-devices-to-bolster-ai-technology\u0026amp;xcust=1-1-2686346-1-0-0-0-0\u0026amp;sref=https://www.macworld.com/article/2686346/how-will-apple-improve-its-ai-while-protecting-your-privacy.html\" rel=\"nofollow\" data-subtag=\"1-1-2686346-1-0-0-0-0\" data-domain-name=\"bloomberg\" target=\"_blank\"\u003eBloomberg report\u003c/a\u003e says the new system will come in a beta update to iOS 18.5, iPadOS 18.5, and macOS 18.5 (the \u003ca href=\"https://www.macworld.com/article/2656294/ios-18-5-features-release-date-how-to-install.html\"\u003esecond beta was released today\u003c/a\u003e).\u003c/p\u003e\n\n\n\n\u003cp\u003eOf course, this is just data gathering, and it will take weeks or months of data collection and retraining to measurably improve Apple Intelligence features. \u003c/p\u003e\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": null,
  "modifiedTime": null
}
