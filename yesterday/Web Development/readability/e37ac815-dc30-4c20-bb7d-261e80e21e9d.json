{
  "id": "e37ac815-dc30-4c20-bb7d-261e80e21e9d",
  "title": "Automated Visual Regression Testing With Playwright",
  "link": "https://css-tricks.com/automated-visual-regression-testing-with-playwright/",
  "description": "With visual regression testing, we can update a page, take screenshots before and after the fact, and compare the results for unintended changes. In this article, learn how to set up visual regression testing using Playwright. Automated Visual Regression Testing With Playwright originally published on CSS-Tricks, which is part of the DigitalOcean family. You should get the newsletter.",
  "author": "Frederik Dohr",
  "published": "Fri, 28 Mar 2025 15:04:24 +0000",
  "source": "https://css-tricks.com/feed/",
  "categories": [
    "Articles",
    "testing"
  ],
  "byline": "Frederik Dohr",
  "length": 14083,
  "excerpt": "With visual regression testing, we can update a page, take screenshots before and after the fact, and compare the results for unintended changes. In this article, learn how to set up visual regression testing using Playwright.",
  "siteName": "CSS-Tricks",
  "favicon": "https://i0.wp.com/css-tricks.com/wp-content/uploads/2021/07/star.png?fit=180%2C180\u0026ssl=1",
  "text": "Comparing visual artifacts can be a powerful, if fickle, approach to automated testing. Playwright makes this seem simple for websites, but the details might take a little finessing. Recent downtime prompted me to scratch an itch that had been plaguing me for a while: The style sheet of a website I maintain has grown just a little unwieldy as we’ve been adding code while exploring new features. Now that we have a better idea of the requirements, it’s time for internal CSS refactoring to pay down some of our technical debt, taking advantage of modern CSS features (like using CSS nesting for more obvious structure). More importantly, a cleaner foundation should make it easier to introduce that dark mode feature we’re sorely lacking so we can finally respect users’ preferred color scheme. However, being of the apprehensive persuasion, I was reluctant to make large changes for fear of unwittingly introducing bugs. I needed something to guard against visual regressions while refactoring — except that means snapshot testing, which is notoriously slow and brittle. In this context, snapshot testing means taking screenshots to establish a reliable baseline against which we can compare future results. As we’ll see, those artifacts are influenced by a multitude of factors that might not always be fully controllable (e.g. timing, variable hardware resources, or randomized content). We also have to maintain state between test runs, i.e. save those screenshots, which complicates the setup and means our test code alone doesn’t fully describe expectations. Having procrastinated without a more agreeable solution revealing itself, I finally set out to create what I assumed would be a quick spike. After all, this wouldn’t be part of the regular test suite; just a one-off utility for this particular refactoring task. Fortunately, I had vague recollections of past research and quickly rediscovered Playwright’s built-in visual comparison feature. Because I try to select dependencies carefully, I was glad to see that Playwright seems not to rely on many external packages. Setup The recommended setup with npm init playwright@latest does a decent job, but my minimalist taste had me set everything up from scratch instead. This do-it-yourself approach also helped me understand how the different pieces fit together. Given that I expect snapshot testing to only be used on rare occasions, I wanted to isolate everything in a dedicated subdirectory, called test/visual; that will be our working directory from here on out. We’ll start with package.json to declare our dependencies, adding a few helper scripts (spoiler!) while we’re at it: { \"scripts\": { \"test\": \"playwright test\", \"report\": \"playwright show-report\", \"update\": \"playwright test --update-snapshots\", \"reset\": \"rm -r ./playwright-report ./test-results ./viz.test.js-snapshots || true\" }, \"devDependencies\": { \"@playwright/test\": \"^1.49.1\" } } If you don’t want node_modules hidden in some subdirectory but also don’t want to burden the root project with this rarely-used dependency, you might resort to manually invoking npm install --no-save @playwright/test in the root directory when needed. With that in place, npm install downloads Playwright. Afterwards, npx playwright install downloads a range of headless browsers. (We’ll use npm here, but you might prefer a different package manager and task runner.) We define our test environment via playwright.config.js with about a dozen basic Playwright settings: import { defineConfig, devices } from \"@playwright/test\"; let BROWSERS = [\"Desktop Firefox\", \"Desktop Chrome\", \"Desktop Safari\"]; let BASE_URL = \"http://localhost:8000\"; let SERVER = \"cd ../../dist \u0026\u0026 python3 -m http.server\"; let IS_CI = !!process.env.CI; export default defineConfig({ testDir: \"./\", fullyParallel: true, forbidOnly: IS_CI, retries: 2, workers: IS_CI ? 1 : undefined, reporter: \"html\", webServer: { command: SERVER, url: BASE_URL, reuseExistingServer: !IS_CI }, use: { baseURL: BASE_URL, trace: \"on-first-retry\" }, projects: BROWSERS.map(ua =\u003e ({ name: ua.toLowerCase().replaceAll(\" \", \"-\"), use: { ...devices[ua] } })) }); Here we expect our static website to already reside within the root directory’s dist folder and to be served at localhost:8000 (see SERVER; I prefer Python there because it’s widely available). I’ve included multiple browsers for illustration purposes. Still, we might reduce that number to speed things up (thus our simple BROWSERS list, which we then map to Playwright’s more elaborate projects data structure). Similarly, continuous integration is YAGNI for my particular scenario, so that whole IS_CI dance could be discarded. Capture and compare Let’s turn to the actual tests, starting with a minimal sample.test.js file: import { test, expect } from \"@playwright/test\"; test(\"home page\", async ({ page }) =\u003e { await page.goto(\"/\"); await expect(page).toHaveScreenshot(); }); npm test executes this little test suite (based on file-name conventions). The initial run always fails because it first needs to create baseline snapshots against which subsequent runs compare their results. Invoking npm test once more should report a passing test. Changing our site, e.g. by recklessly messing with build artifacts in dist, should make the test fail again. Such failures will offer various options to compare expected and actual visuals: We can also inspect those baseline snapshots directly: Playwright creates a folder for screenshots named after the test file (sample.test.js-snapshots in this case), with file names derived from the respective test’s title (e.g. home-page-desktop-firefox.png). Generating tests Getting back to our original motivation, what we want is a test for every page. Instead of arduously writing and maintaining repetitive tests, we’ll create a simple web crawler for our website and have tests generated automatically; one for each URL we’ve identified. Playwright’s global setup enables us to perform preparatory work before test discovery begins: Determine those URLs and write them to a file. Afterward, we can dynamically generate our tests at runtime. While there are other ways to pass data between the setup and test-discovery phases, having a file on disk makes it easy to modify the list of URLs before test runs (e.g. temporarily ignoring irrelevant pages). Site map The first step is to extend playwright.config.js by inserting globalSetup and exporting two of our configuration values: export let BROWSERS = [\"Desktop Firefox\", \"Desktop Chrome\", \"Desktop Safari\"]; export let BASE_URL = \"http://localhost:8000\"; // etc. export default defineConfig({ // etc. globalSetup: require.resolve(\"./setup.js\") }); Although we’re using ES modules here, we can still rely on CommonJS-specific APIs like require.resolve and __dirname. It appears there’s some Babel transpilation happening in the background, so what’s actually being executed is probably CommonJS? Such nuances sometimes confuse me because it isn’t always obvious what’s being executed where. We can now reuse those exported values within a newly created setup.js, which spins up a headless browser to crawl our site (just because that’s easier here than using a separate HTML parser): import { BASE_URL, BROWSERS } from \"./playwright.config.js\"; import { createSiteMap, readSiteMap } from \"./sitemap.js\"; import playwright from \"@playwright/test\"; export default async function globalSetup(config) { // only create site map if it doesn't already exist try { readSiteMap(); return; } catch(err) {} // launch browser and initiate crawler let browser = playwright.devices[BROWSERS[0]].defaultBrowserType; browser = await playwright[browser].launch(); let page = await browser.newPage(); await createSiteMap(BASE_URL, page); await browser.close(); } This is fairly boring glue code; the actual crawling is happening within sitemap.js: createSiteMap determines URLs and writes them to disk. readSiteMap merely reads any previously created site map from disk. This will be our foundation for dynamically generating tests. (We’ll see later why this needs to be synchronous.) Fortunately, the website in question provides a comprehensive index of all pages, so my crawler only needs to collect unique local URLs from that index page: function extractLocalLinks(baseURL) { let urls = new Set(); let offset = baseURL.length; for(let { href } of document.links) { if(href.startsWith(baseURL)) { let path = href.slice(offset); urls.add(path); } } return Array.from(urls); } Wrapping that in a more boring glue code gives us our sitemap.js: import { readFileSync, writeFileSync } from \"node:fs\"; import { join } from \"node:path\"; let ENTRY_POINT = \"/topics\"; let SITEMAP = join(__dirname, \"./sitemap.json\"); export async function createSiteMap(baseURL, page) { await page.goto(baseURL + ENTRY_POINT); let urls = await page.evaluate(extractLocalLinks, baseURL); let data = JSON.stringify(urls, null, 4); writeFileSync(SITEMAP, data, { encoding: \"utf-8\" }); } export function readSiteMap() { try { var data = readFileSync(SITEMAP, { encoding: \"utf-8\" }); } catch(err) { if(err.code === \"ENOENT\") { throw new Error(\"missing site map\"); } throw err; } return JSON.parse(data); } function extractLocalLinks(baseURL) { // etc. } The interesting bit here is that extractLocalLinks is evaluated within the browser context — thus we can rely on DOM APIs, notably document.links — while the rest is executed within the Playwright environment (i.e. Node). Tests Now that we have our list of URLs, we basically just need a test file with a simple loop to dynamically generate corresponding tests: for(let url of readSiteMap()) { test(`page at ${url}`, async ({ page }) =\u003e { await page.goto(url); await expect(page).toHaveScreenshot(); }); } This is why readSiteMap had to be synchronous above: Playwright doesn’t currently support top-level await within test files. In practice, we’ll want better error reporting for when the site map doesn’t exist yet. Let’s call our actual test file viz.test.js: import { readSiteMap } from \"./sitemap.js\"; import { test, expect } from \"@playwright/test\"; let sitemap = []; try { sitemap = readSiteMap(); } catch(err) { test(\"site map\", ({ page }) =\u003e { throw new Error(\"missing site map\"); }); } for(let url of sitemap) { test(`page at ${url}`, async ({ page }) =\u003e { await page.goto(url); await expect(page).toHaveScreenshot(); }); } Getting here was a bit of a journey, but we’re pretty much done… unless we have to deal with reality, which typically takes a bit more tweaking. Exceptions Because visual testing is inherently flaky, we sometimes need to compensate via special casing. Playwright lets us inject custom CSS, which is often the easiest and most effective approach. Tweaking viz.test.js… // etc. import { join } from \"node:path\"; let OPTIONS = { stylePath: join(__dirname, \"./viz.tweaks.css\") }; // etc. await expect(page).toHaveScreenshot(OPTIONS); // etc. … allows us to define exceptions in viz.tweaks.css: /* suppress state */ main a:visited { color: var(--color-link); } /* suppress randomness */ iframe[src$=\"/articles/signals-reactivity/demo.html\"] { visibility: hidden; } /* suppress flakiness */ body:has(h1 a[href=\"/wip/unicode-symbols/\"]) { main tbody \u003e tr:last-child \u003e td:first-child { font-size: 0; visibility: hidden; } } :has() strikes again! Page vs. viewport At this point, everything seemed hunky-dory to me, until I realized that my tests didn’t actually fail after I had changed some styling. That’s not good! What I hadn’t taken into account is that .toHaveScreenshot only captures the viewport rather than the entire page. We can rectify that by further extending playwright.config.js. export let WIDTH = 800; export let HEIGHT = WIDTH; // etc. projects: BROWSERS.map(ua =\u003e ({ name: ua.toLowerCase().replaceAll(\" \", \"-\"), use: { ...devices[ua], viewport: { width: WIDTH, height: HEIGHT } } })) …and then by adjusting viz.test.js‘s test-generating loop: import { WIDTH, HEIGHT } from \"./playwright.config.js\"; // etc. for(let url of sitemap) { test(`page at ${url}`, async ({ page }) =\u003e { checkSnapshot(url, page); }); } async function checkSnapshot(url, page) { // determine page height with default viewport await page.setViewportSize({ width: WIDTH, height: HEIGHT }); await page.goto(url); await page.waitForLoadState(\"networkidle\"); let height = await page.evaluate(getFullHeight); // resize viewport for before snapshotting await page.setViewportSize({ width: WIDTH, height: Math.ceil(height) }); await page.waitForLoadState(\"networkidle\"); await expect(page).toHaveScreenshot(OPTIONS); } function getFullHeight() { return document.documentElement.getBoundingClientRect().height; } Note that we’ve also introduced a waiting condition, holding until there’s no network traffic for a while in a crude attempt to account for stuff like lazy-loading images. Be aware that capturing the entire page is more resource-intensive and doesn’t always work reliably: You might have to deal with layout shifts or run into timeouts for long or asset-heavy pages. In other words: This risks exacerbating flakiness. Conclusion So much for that quick spike. While it took more effort than expected (I believe that’s called “software development”), this might actually solve my original problem now (not a common feature of software these days). Of course, shaving this yak still leaves me itchy, as I have yet to do the actual work of scratching CSS without breaking anything. Then comes the real challenge: Retrofitting dark mode to an existing website. I just might need more downtime.",
  "image": "https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/playwright-browsers.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n          \n          \n\u003cp\u003eComparing visual artifacts can be a powerful, if fickle, approach to automated testing. \u003ca href=\"https://playwright.dev\" rel=\"noopener\"\u003ePlaywright\u003c/a\u003e makes this seem simple for websites, but the details might take a little finessing.\u003c/p\u003e\n\n\n\n\u003cp\u003eRecent downtime prompted me to scratch an itch that had been plaguing me for a while: The style sheet of a website I maintain has grown just a little unwieldy as we’ve been adding code while exploring new features. Now that we have a better idea of the requirements, it’s time for internal CSS refactoring to pay down some of our \u003ca href=\"https://css-tricks.com/defining-and-dealing-with-technical-debt/\"\u003etechnical debt\u003c/a\u003e, taking advantage of modern CSS features (like using CSS nesting for more obvious structure). More importantly, a cleaner foundation should make it easier to introduce that \u003ca href=\"https://css-tricks.com/a-complete-guide-to-dark-mode-on-the-web/\"\u003edark mode\u003c/a\u003e feature we’re sorely lacking so we can finally respect users’ preferred color scheme.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, being of the apprehensive persuasion, I was reluctant to make large changes for fear of unwittingly introducing bugs. I needed something to guard against visual regressions while refactoring — except that means \u003ca href=\"https://css-tricks.com/testing-for-visual-regressions-with-percy/\"\u003esnapshot testing\u003c/a\u003e, which is notoriously slow and brittle.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn this context, snapshot testing means taking screenshots to establish a reliable baseline against which we can compare future results. As we’ll see, those artifacts are influenced by a multitude of factors that might not always be fully controllable (e.g. timing, variable hardware resources, or randomized content). We also have to maintain state between test runs, i.e. save those screenshots, which complicates the setup and means our test code alone doesn’t fully describe expectations.\u003c/p\u003e\n\n\n\n\u003cp\u003eHaving procrastinated without a more agreeable solution revealing itself, I finally set out to create what I assumed would be a quick spike. After all, this wouldn’t be part of the regular test suite; just a one-off utility for this particular refactoring task.\u003c/p\u003e\n\n\n\n\u003cp\u003eFortunately, I had vague recollections of past research and quickly rediscovered \u003ca href=\"https://playwright.dev/docs/test-snapshots\" rel=\"noopener\"\u003ePlaywright’s built-in visual comparison\u003c/a\u003e feature. Because I try to select dependencies carefully, I was glad to see that Playwright seems not to rely on many external packages.\u003c/p\u003e\n\n\n\u003ch3 id=\"setup\"\u003eSetup\u003c/h3\u003e\n\n\n\u003cp\u003eThe recommended setup with \u003ccode\u003enpm init playwright@latest\u003c/code\u003e does a decent job, but my minimalist taste had me set everything up from scratch instead. This do-it-yourself approach also helped me understand how the different pieces fit together.\u003c/p\u003e\n\n\n\n\u003cp\u003eGiven that I expect snapshot testing to only be used on rare occasions, I wanted to isolate everything in a dedicated subdirectory, called \u003ccode\u003etest/visual\u003c/code\u003e; that will be our working directory from here on out. We’ll start with \u003ccode\u003epackage.json\u003c/code\u003e to declare our dependencies, adding a few helper scripts (spoiler!) while we’re at it:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JSON\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003e{\n  \u0026#34;scripts\u0026#34;: {\n    \u0026#34;test\u0026#34;: \u0026#34;playwright test\u0026#34;,\n    \u0026#34;report\u0026#34;: \u0026#34;playwright show-report\u0026#34;,\n    \u0026#34;update\u0026#34;: \u0026#34;playwright test --update-snapshots\u0026#34;,\n    \u0026#34;reset\u0026#34;: \u0026#34;rm -r ./playwright-report ./test-results ./viz.test.js-snapshots || true\u0026#34;\n  },\n  \u0026#34;devDependencies\u0026#34;: {\n    \u0026#34;@playwright/test\u0026#34;: \u0026#34;^1.49.1\u0026#34;\n  }\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eIf you don’t want \u003ccode\u003enode_modules\u003c/code\u003e hidden in some subdirectory but also don’t want to burden the root project with this rarely-used dependency, you might resort to manually invoking \u003ccode\u003enpm install --no-save @playwright/test\u003c/code\u003e in the root directory when needed.\u003c/p\u003e\n\n\n\n\u003cp\u003eWith that in place, \u003ccode\u003enpm install\u003c/code\u003e downloads Playwright. Afterwards, \u003ccode\u003enpx playwright install\u003c/code\u003e downloads a range of headless browsers. (We’ll use npm here, but you might prefer a different package manager and task runner.)\u003c/p\u003e\n\n\n\n\u003cp\u003eWe define our test environment via \u003ccode\u003eplaywright.config.js\u003c/code\u003e with about a dozen basic \u003ca href=\"https://playwright.dev/docs/test-configuration\" rel=\"noopener\"\u003ePlaywright settings\u003c/a\u003e:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eimport { defineConfig, devices } from \u0026#34;@playwright/test\u0026#34;;\n\nlet BROWSERS = [\u0026#34;Desktop Firefox\u0026#34;, \u0026#34;Desktop Chrome\u0026#34;, \u0026#34;Desktop Safari\u0026#34;];\nlet BASE_URL = \u0026#34;http://localhost:8000\u0026#34;;\nlet SERVER = \u0026#34;cd ../../dist \u0026amp;\u0026amp; python3 -m http.server\u0026#34;;\n\nlet IS_CI = !!process.env.CI;\n\nexport default defineConfig({\n  testDir: \u0026#34;./\u0026#34;,\n  fullyParallel: true,\n  forbidOnly: IS_CI,\n  retries: 2,\n  workers: IS_CI ? 1 : undefined,\n  reporter: \u0026#34;html\u0026#34;,\n  webServer: {\n    command: SERVER,\n    url: BASE_URL,\n    reuseExistingServer: !IS_CI\n  },\n  use: {\n    baseURL: BASE_URL,\n    trace: \u0026#34;on-first-retry\u0026#34;\n  },\n  projects: BROWSERS.map(ua =\u0026gt; ({\n    name: ua.toLowerCase().replaceAll(\u0026#34; \u0026#34;, \u0026#34;-\u0026#34;),\n    use: { ...devices[ua] }\n  }))\n});\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eHere we expect our static website to already reside within the root directory’s \u003ccode\u003edist\u003c/code\u003e folder and to be served at \u003ccode\u003elocalhost:8000\u003c/code\u003e (see \u003ccode\u003eSERVER\u003c/code\u003e; I prefer Python there because it’s \u003ca href=\"https://en.wikipedia.org/wiki/Linux_Standard_Base\" rel=\"noopener\"\u003ewidely available\u003c/a\u003e). I’ve included multiple browsers for illustration purposes. Still, we might reduce that number to speed things up (thus our simple \u003ccode\u003eBROWSERS\u003c/code\u003e list, which we then map to Playwright’s more elaborate \u003ccode\u003eprojects\u003c/code\u003e data structure). Similarly, continuous integration is \u003ca href=\"https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it\" rel=\"noopener\"\u003eYAGNI\u003c/a\u003e for my particular scenario, so that whole \u003ccode\u003eIS_CI\u003c/code\u003e dance could be discarded.\u003c/p\u003e\n\n\n\u003ch3 id=\"capture-and-compare\"\u003eCapture and compare\u003c/h3\u003e\n\n\n\u003cp\u003eLet’s turn to the actual tests, starting with a minimal \u003ccode\u003esample.test.js\u003c/code\u003e file:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eimport { test, expect } from \u0026#34;@playwright/test\u0026#34;;\n\ntest(\u0026#34;home page\u0026#34;, async ({ page }) =\u0026gt; {\n  await page.goto(\u0026#34;/\u0026#34;);\n  await expect(page).toHaveScreenshot();\n});\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003e\u003ccode\u003enpm test\u003c/code\u003e executes this little test suite (based on \u003ca href=\"https://playwright.dev/docs/test-configuration#filtering-tests\" rel=\"noopener\"\u003efile-name conventions\u003c/a\u003e). The initial run always fails because it first needs to create baseline snapshots against which subsequent runs compare their results. Invoking \u003ccode\u003enpm test\u003c/code\u003e once more should report a passing test.\u003c/p\u003e\n\n\n\n\u003cp\u003eChanging our site, e.g. by recklessly messing with build artifacts in \u003ccode\u003edist\u003c/code\u003e, should make the test fail again. Such failures will offer various options to compare expected and actual visuals:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg loading=\"lazy\" data-recalc-dims=\"1\" fetchpriority=\"high\" decoding=\"async\" width=\"1884\" height=\"465\" src=\"https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/visual-regression-error.png?resize=1884%2C465\u0026amp;ssl=1\" alt=\"Failing test with slightly different screenshots side by side\" srcset=\"https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/visual-regression-error.png?w=1884\u0026amp;ssl=1 1884w, https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/visual-regression-error.png?resize=300%2C74\u0026amp;ssl=1 300w, https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/visual-regression-error.png?resize=1024%2C253\u0026amp;ssl=1 1024w, https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/visual-regression-error.png?resize=768%2C190\u0026amp;ssl=1 768w, https://i0.wp.com/css-tricks.com/wp-content/uploads/2025/03/visual-regression-error.png?resize=1536%2C379\u0026amp;ssl=1 1536w\" sizes=\"(min-width: 735px) 864px, 96vw\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWe can also inspect those baseline snapshots directly: Playwright creates a folder for screenshots named after the test file (\u003ccode\u003esample.test.js-snapshots\u003c/code\u003e in this case), with file names derived from the respective test’s title (e.g. \u003ccode\u003ehome-page-desktop-firefox.png\u003c/code\u003e).\u003c/p\u003e\n\n\n\u003ch3 id=\"generating-tests\"\u003eGenerating tests\u003c/h3\u003e\n\n\n\u003cp\u003eGetting back to our original motivation, what we want is a test for every page. Instead of arduously writing and maintaining repetitive tests, we’ll create a simple web crawler for our website and have tests generated automatically; one for each URL we’ve identified.\u003c/p\u003e\n\n\n\n\u003cp\u003ePlaywright’s \u003ca href=\"https://playwright.dev/docs/test-global-setup-teardown\" rel=\"noopener\"\u003eglobal setup\u003c/a\u003e enables us to perform preparatory work before test discovery begins: Determine those URLs and write them to a file. Afterward, we can dynamically generate our tests at runtime.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile there are other ways to pass data between the setup and test-discovery phases, having a file on disk makes it easy to modify the list of URLs before test runs (e.g. temporarily ignoring irrelevant pages).\u003c/p\u003e\n\n\n\u003ch4 id=\"site-map\"\u003eSite map\u003c/h4\u003e\n\n\n\u003cp\u003eThe first step is to extend \u003ccode\u003eplaywright.config.js\u003c/code\u003e by inserting \u003ccode\u003eglobalSetup\u003c/code\u003e and exporting two of our configuration values:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eexport let BROWSERS = [\u0026#34;Desktop Firefox\u0026#34;, \u0026#34;Desktop Chrome\u0026#34;, \u0026#34;Desktop Safari\u0026#34;];\nexport let BASE_URL = \u0026#34;http://localhost:8000\u0026#34;;\n\n// etc.\n\nexport default defineConfig({\n  // etc.\n  globalSetup: require.resolve(\u0026#34;./setup.js\u0026#34;)\n});\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eAlthough we’re using ES modules here, we can still rely on CommonJS-specific APIs like \u003ccode\u003erequire.resolve\u003c/code\u003e and \u003ccode\u003e__dirname\u003c/code\u003e. It appears there’s some Babel transpilation happening in the background, so what’s actually being executed is probably CommonJS? Such nuances sometimes confuse me because it isn’t always obvious what’s being executed where.\u003c/p\u003e\n\n\n\n\u003cp\u003eWe can now reuse those exported values within a newly created \u003ccode\u003esetup.js\u003c/code\u003e, which spins up a headless browser to crawl our site (just because that’s easier here than using a separate HTML parser):\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eimport { BASE_URL, BROWSERS } from \u0026#34;./playwright.config.js\u0026#34;;\nimport { createSiteMap, readSiteMap } from \u0026#34;./sitemap.js\u0026#34;;\nimport playwright from \u0026#34;@playwright/test\u0026#34;;\n\nexport default async function globalSetup(config) {\n  // only create site map if it doesn\u0026#39;t already exist\n  try {\n    readSiteMap();\n    return;\n  } catch(err) {}\n\n  // launch browser and initiate crawler\n  let browser = playwright.devices[BROWSERS[0]].defaultBrowserType;\n  browser = await playwright[browser].launch();\n  let page = await browser.newPage();\n  await createSiteMap(BASE_URL, page);\n  await browser.close();\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eThis is fairly boring glue code; the actual crawling is happening within \u003ccode\u003esitemap.js\u003c/code\u003e:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ecreateSiteMap\u003c/code\u003e determines URLs and writes them to disk.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ccode\u003ereadSiteMap\u003c/code\u003e merely reads any previously created site map from disk. This will be our foundation for dynamically generating tests. (We’ll see later why this needs to be synchronous.)\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eFortunately, the website in question provides a comprehensive index of all pages, so my crawler only needs to collect unique local URLs from that index page:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003efunction extractLocalLinks(baseURL) {\n  let urls = new Set();\n  let offset = baseURL.length;\n  for(let { href } of document.links) {\n    if(href.startsWith(baseURL)) {\n      let path = href.slice(offset);\n      urls.add(path);\n    }\n  }\n  return Array.from(urls);\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eWrapping that in a more boring glue code gives us our \u003ccode\u003esitemap.js\u003c/code\u003e:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eimport { readFileSync, writeFileSync } from \u0026#34;node:fs\u0026#34;;\nimport { join } from \u0026#34;node:path\u0026#34;;\n\nlet ENTRY_POINT = \u0026#34;/topics\u0026#34;;\nlet SITEMAP = join(__dirname, \u0026#34;./sitemap.json\u0026#34;);\n\nexport async function createSiteMap(baseURL, page) {\n  await page.goto(baseURL + ENTRY_POINT);\n  let urls = await page.evaluate(extractLocalLinks, baseURL);\n  let data = JSON.stringify(urls, null, 4);\n  writeFileSync(SITEMAP, data, { encoding: \u0026#34;utf-8\u0026#34; });\n}\n\nexport function readSiteMap() {\n  try {\n    var data = readFileSync(SITEMAP, { encoding: \u0026#34;utf-8\u0026#34; });\n  } catch(err) {\n    if(err.code === \u0026#34;ENOENT\u0026#34;) {\n      throw new Error(\u0026#34;missing site map\u0026#34;);\n    }\n    throw err;\n  }\n  return JSON.parse(data);\n}\n\nfunction extractLocalLinks(baseURL) {\n  // etc.\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eThe interesting bit here is that \u003ccode\u003eextractLocalLinks\u003c/code\u003e is \u003ca href=\"https://playwright.dev/docs/evaluating\" rel=\"noopener\"\u003eevaluated within the browser context\u003c/a\u003e — thus we can rely on DOM APIs, notably \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Document/links\" rel=\"noopener\"\u003e\u003ccode\u003edocument.links\u003c/code\u003e\u003c/a\u003e — while the rest is executed within the Playwright environment (i.e. Node).\u003c/p\u003e\n\n\n\u003ch4 id=\"tests\"\u003eTests\u003c/h4\u003e\n\n\n\u003cp\u003eNow that we have our list of URLs, we basically just need a test file with a simple loop to dynamically generate corresponding tests:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003efor(let url of readSiteMap()) {\n  test(`page at ${url}`, async ({ page }) =\u0026gt; {\n    await page.goto(url);\n    await expect(page).toHaveScreenshot();\n  });\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eThis is why \u003ccode\u003ereadSiteMap\u003c/code\u003e had to be synchronous above: Playwright doesn’t currently support top-level \u003ccode\u003eawait\u003c/code\u003e within test files.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn practice, we’ll want better error reporting for when the site map doesn’t exist yet. Let’s call our actual test file \u003ccode\u003eviz.test.js\u003c/code\u003e:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eimport { readSiteMap } from \u0026#34;./sitemap.js\u0026#34;;\nimport { test, expect } from \u0026#34;@playwright/test\u0026#34;;\n\nlet sitemap = [];\ntry {\n  sitemap = readSiteMap();\n} catch(err) {\n  test(\u0026#34;site map\u0026#34;, ({ page }) =\u0026gt; {\n    throw new Error(\u0026#34;missing site map\u0026#34;);\n  });\n}\n\nfor(let url of sitemap) {\n  test(`page at ${url}`, async ({ page }) =\u0026gt; {\n    await page.goto(url);\n    await expect(page).toHaveScreenshot();\n  });\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eGetting here was a bit of a journey, but we’re pretty much done… unless we have to deal with reality, which typically takes a bit more tweaking.\u003c/p\u003e\n\n\n\u003ch3 id=\"exceptions\"\u003eExceptions\u003c/h3\u003e\n\n\n\u003cp\u003eBecause visual testing is inherently flaky, we sometimes need to compensate via special casing. Playwright lets us inject custom CSS, which is often the easiest and most effective approach. Tweaking \u003ccode\u003eviz.test.js\u003c/code\u003e…\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003e// etc.\nimport { join } from \u0026#34;node:path\u0026#34;;\n\nlet OPTIONS = {\n  stylePath: join(__dirname, \u0026#34;./viz.tweaks.css\u0026#34;)\n};\n\n// etc.\n  await expect(page).toHaveScreenshot(OPTIONS);\n// etc.\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003e… allows us to define exceptions in \u003ccode\u003eviz.tweaks.css\u003c/code\u003e:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"CSS\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003e/* suppress state */\nmain a:visited {\n  color: var(--color-link);\n}\n\n/* suppress randomness */\niframe[src$=\u0026#34;/articles/signals-reactivity/demo.html\u0026#34;] {\n  visibility: hidden;\n}\n\n/* suppress flakiness */\nbody:has(h1 a[href=\u0026#34;/wip/unicode-symbols/\u0026#34;]) {\n  main tbody \u0026gt; tr:last-child \u0026gt; td:first-child {\n    font-size: 0;\n    visibility: hidden;\n  }\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003e\u003ccode\u003e:has()\u003c/code\u003e strikes \u003ca href=\"https://css-tricks.com/more-real-world-uses-for-has/\"\u003eagain\u003c/a\u003e!\u003c/p\u003e\n\n\n\u003ch3 id=\"page-vs-viewport\"\u003ePage vs. viewport\u003c/h3\u003e\n\n\n\u003cp\u003eAt this point, everything seemed hunky-dory to me, until I realized that my tests didn’t actually fail after I had changed some styling. That’s not good! What I hadn’t taken into account is that \u003ccode\u003e.toHaveScreenshot\u003c/code\u003e only captures the viewport rather than the entire page. We can rectify that by further extending \u003ccode\u003eplaywright.config.js\u003c/code\u003e.\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eexport let WIDTH = 800;\nexport let HEIGHT = WIDTH;\n\n// etc.\n\n  projects: BROWSERS.map(ua =\u0026gt; ({\n    name: ua.toLowerCase().replaceAll(\u0026#34; \u0026#34;, \u0026#34;-\u0026#34;),\n    use: {\n      ...devices[ua],\n      viewport: {\n        width: WIDTH,\n        height: HEIGHT\n      }\n    }\n  }))\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003e…and then by adjusting \u003ccode\u003eviz.test.js\u003c/code\u003e‘s test-generating loop:\u003c/p\u003e\n\n\n\n\u003cpre rel=\"JavaScript\" data-line=\"\"\u003e\u003ccode markup=\"tt\"\u003eimport { WIDTH, HEIGHT } from \u0026#34;./playwright.config.js\u0026#34;;\n\n// etc.\n\nfor(let url of sitemap) {\n  test(`page at ${url}`, async ({ page }) =\u0026gt; {\n    checkSnapshot(url, page);\n  });\n}\n\nasync function checkSnapshot(url, page) {\n  // determine page height with default viewport\n  await page.setViewportSize({\n    width: WIDTH,\n    height: HEIGHT\n  });\n  await page.goto(url);\n  await page.waitForLoadState(\u0026#34;networkidle\u0026#34;);\n  let height = await page.evaluate(getFullHeight);\n\n  // resize viewport for before snapshotting\n  await page.setViewportSize({\n    width: WIDTH,\n    height: Math.ceil(height)\n  });\n  await page.waitForLoadState(\u0026#34;networkidle\u0026#34;);\n  await expect(page).toHaveScreenshot(OPTIONS);\n}\n\nfunction getFullHeight() {\n  return document.documentElement.getBoundingClientRect().height;\n}\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eNote that we’ve also introduced a \u003ca href=\"https://playwright.dev/docs/next/api/class-page#page-wait-for-load-state-option-state\" rel=\"noopener\"\u003ewaiting condition\u003c/a\u003e, holding until there’s no network traffic for a while in a crude attempt to account for stuff like lazy-loading images.\u003c/p\u003e\n\n\n\n\u003cp\u003eBe aware that capturing the entire page is more resource-intensive and doesn’t always work reliably: You might have to deal with \u003ca href=\"https://developer.mozilla.org/en-US/docs/Glossary/CLS\" rel=\"noopener\"\u003elayout shifts\u003c/a\u003e or run into timeouts for long or asset-heavy pages. In other words: This risks exacerbating flakiness.\u003c/p\u003e\n\n\n\u003ch3 id=\"conclusion\"\u003eConclusion\u003c/h3\u003e\n\n\n\u003cp\u003eSo much for that quick spike. While it took more effort than expected (I believe that’s called “software development”), this might actually solve my original problem now (not a common feature of software these days). Of course, shaving this yak still leaves me itchy, as I have yet to do the actual work of scratching CSS without breaking anything. Then comes the real challenge: Retrofitting dark mode to an existing website. I just might need more downtime.\u003c/p\u003e\n\n          \n        \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "15 min read",
  "publishedTime": "2025-03-28T09:04:24-06:00",
  "modifiedTime": "2025-03-28T09:04:27-06:00"
}
