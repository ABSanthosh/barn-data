{
  "id": "faa7294e-a3b3-445a-96a5-360720dafb2a",
  "title": "LangChain shows AI agents aren’t human-level yet because they’re overwhelmed by tools",
  "link": "https://venturebeat.com/ai/langchain-shows-ai-agents-arent-human-level-yet-because-theyre-overwhelmed-by-tools/",
  "description": "LangChain evaluated a single AI agent to see if its performance degrades when given more context and tools, essentially overwhelming it.",
  "author": "Emilia David",
  "published": "Tue, 11 Feb 2025 22:53:06 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI agent",
    "ai agent benchmarks",
    "AI agents",
    "AI, ML and Deep Learning",
    "category-/Computers \u0026 Electronics/Programming",
    "category-/Science/Computer Science",
    "enterprise ai",
    "LangChain"
  ],
  "byline": "Emilia David",
  "length": 6580,
  "excerpt": "LangChain evaluated a single AI agent to see if its performance degrades when given more context and tools, essentially overwhelming it.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "February 11, 2025 2:53 PM An AI-generated robot sitting in front of a computer, responding to customer service tickets. Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More As soon as AI agents have showed promise, organizations have had to grapple with figuring out if a single agent was enough, or if they should invest in building out a wider multi-agent network that touches more points in their organization.  Orchestration framework company LangChain sought to get closer to an answer to this question. It subjected an AI agent to several experiments that found single agents do have a limit of context and tools before their performance begins to degrade. These experiments could lead to a better understanding of the architecture needed to maintain agents and multi-agent systems.  In a blog post, LangChain detailed a set of experiments it performed with a single ReAct agent and benchmarked its performance. The main question LangChain hoped to answer was, “At what point does a single ReAct agent become overloaded with instructions and tools, and subsequently sees performance drop?” LangChain chose to use the ReAct agent framework because it is “one of the most basic agentic architectures.” While benchmarking agentic performance can often lead to misleading results, LangChain chose to limit the test to two easily quantifiable tasks of an agent: answering questions and scheduling meetings.  “There are many existing benchmarks for tool-use and tool-calling, but for the purposes of this experiment, we wanted to evaluate a practical agent that we actually use,” LangChain wrote. “This agent is our internal email assistant, which is responsible for two main domains of work — responding to and scheduling meeting requests and supporting customers with their questions.” Parameters of LangChain’s experiment LangChain mainly used pre-built ReAct agents through its LangGraph platform. These agents featured tool-calling large language models (LLMs) that became part of the benchmark test. These LLMs included Anthropic’s Claude 3.5 Sonnet, Meta’s Llama-3.3-70B and a trio of models from OpenAI, GPT-4o, o1 and o3-mini.  The company broke testing down to better assess the performance of email assistant on the two tasks, creating a list of steps for it to follow. It began with the email assistant’s customer support capabilities, which look at how the agent accepts an email from a client and responds with an answer.  LangChain first evaluated the tool calling trajectory, or the tools an agent taps. If the agent followed the correct order, it passed the test. Next, researchers asked the assistant to respond to an email and used an LLM to judge its performance.  For the second work domain, calendar scheduling, LangChain focused on the agent’s ability to follow instructions.  “In other words, the agent needs to remember specific instructions provided, such as exactly when it should schedule meetings with different parties,” the researchers wrote.  Overloading the agent Once they defined parameters, LangChain set to stress out and overwhelm the email assistant agent.  It set 30 tasks each for calendar scheduling and customer support. These were run three times (for a total of 90 runs). The researchers created a calendar scheduling agent and a customer support agent to better evaluate the tasks.  “The calendar scheduling agent only has access to the calendar scheduling domain, and the customer support agent only has access to the customer support domain,” LangChain explained.  The researchers then added more domain tasks and tools to the agents to increase the number of responsibilities. These could range from human resources, to technical quality assurance, to legal and compliance and a host of other areas.  Single-agent instruction degradation After running the evaluations, LangChain found that single agents would often get too overwhelmed when told to do too many things. They began forgetting to call tools or were unable to respond to tasks when given more instructions and contexts.  LangChain found that calendar scheduling agents using GPT-4o “performed worse than Claude-3.5-sonnet, o1 and o3 across the various context sizes, and performance dropped off more sharply than the other models when larger context was provided.” The performance of GPT-4o calendar schedulers fell to 2% when the domains increased to at least seven.  Other models didn’t fare much better. Llama-3.3-70B forgot to call the send_email tool, “so it failed every test case.” Only Claude-3.5-sonnet, o1 and o3-mini all remembered to call the tool, but Claude-3.5-sonnet performed worse than the two other OpenAI models. However, o3-mini’s performance degrades once irrelevant domains are added to the scheduling instructions. The customer support agent can call on more tools, but for this test, LangChain said Claude-3.5-mini performed just as well as o3-mini and o1. It also presented a shallower performance drop when more domains were added. When the context window extends, however, the Claude model performs worse.  GPT-4o also performed the worst among the models tested.  “We saw that as more context was provided, instruction following became worse. Some of our tasks were designed to follow niche specific instructions (e.g., do not perform a certain action for EU-based customers),” LangChain noted. “We found that these instructions would be successfully followed by agents with fewer domains, but as the number of domains increased, these instructions were more often forgotten, and the tasks subsequently failed.” The company said it is exploring how to evaluate multi-agent architectures using the same domain overloading method.  LangChain is already invested in the performance of agents, as it introduced the concept of “ambient agents,” or agents that run in the background and are triggered by specific events. These experiments could make it easier to figure out how best to ensure agentic performance.  Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/04/adobe-firefly-robot-desk-customer-service-agent.jpg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-02-11T22:53:06+00:00\" datetime=\"2025-02-11T22:53:06+00:00\"\u003eFebruary 11, 2025 2:53 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"422\" src=\"https://venturebeat.com/wp-content/uploads/2024/04/adobe-firefly-robot-desk-customer-service-agent.jpg?w=750\" alt=\"An AI-generated robot sitting in front of a computer, responding to customer service tickets.\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eAn AI-generated robot sitting in front of a computer, responding to customer service tickets.\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eAs soon as AI agents have showed promise, organizations have had to grapple with figuring out if a single agent was enough, or if they should invest in building out a wider \u003ca href=\"https://venturebeat.com/ai/why-multi-agent-ai-conquers-complexities-llms-cant/\"\u003emulti-agent network\u003c/a\u003e that touches more points in their organization. \u003c/p\u003e\n\n\n\n\u003cp\u003eOrchestration framework company \u003ca href=\"https://www.langchain.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLangChain\u003c/a\u003e sought to get closer to an answer to this question. It subjected an AI agent to several experiments that found single agents do have a limit of context and tools before \u003ca href=\"https://venturebeat.com/ai/researchers-improved-ai-agent-performance-on-unfamiliar-tasks-using-dungeons-and-dragons/\"\u003etheir performance\u003c/a\u003e begins to degrade. These experiments could lead to a better understanding of the architecture needed to maintain agents and multi-agent systems. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn a \u003ca href=\"https://blog.langchain.dev/react-agent-benchmarking/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eblog post\u003c/a\u003e, LangChain detailed a set of experiments it performed with a single ReAct agent and benchmarked its performance. The main question LangChain hoped to answer was, “At what point does a single ReAct agent become overloaded with instructions and tools, and subsequently sees performance drop?”\u003c/p\u003e\n\n\n\n\u003cp\u003eLangChain chose to use the \u003ca href=\"https://arxiv.org/pdf/2210.03629\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eReAct agent framework \u003c/a\u003ebecause it is “one of the most basic agentic architectures.”\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile benchmarking agentic performance \u003ca href=\"https://venturebeat.com/ai/ai-agent-benchmarks-are-misleading-study-warns/\"\u003ecan often lead to misleading results\u003c/a\u003e, LangChain chose to limit the test to two easily quantifiable tasks of an agent: answering questions and scheduling meetings. \u003c/p\u003e\n\n\n\n\u003cp\u003e“There are many existing benchmarks for tool-use and tool-calling, but for the purposes of this experiment, we wanted to evaluate a practical agent that we actually use,” LangChain wrote. “This agent is our internal email assistant, which is responsible for two main domains of work — responding to and scheduling meeting requests and supporting customers with their questions.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-parameters-of-langchain-s-experiment\"\u003eParameters of LangChain’s experiment\u003c/h2\u003e\n\n\n\n\u003cp\u003eLangChain mainly used pre-built ReAct agents through its LangGraph platform. These agents featured tool-calling large language models (LLMs) that became part of the benchmark test. These LLMs included Anthropic’s Claude 3.5 Sonnet, Meta’s Llama-3.3-70B and a trio of models from OpenAI, GPT-4o, o1 and \u003ca href=\"https://venturebeat.com/ai/openais-surprise-new-o3-powered-deep-research-shows-the-power-of-the-ai-agent-era/\"\u003eo3-mini\u003c/a\u003e. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe company broke testing down to better assess the performance of email assistant on the two tasks, creating a list of steps for it to follow. It began with the email assistant’s customer support capabilities, which look at how the agent accepts an email from a client and responds with an answer. \u003c/p\u003e\n\n\n\n\u003cp\u003eLangChain first evaluated the tool calling trajectory, or the tools an agent taps. If the agent followed the correct order, it passed the test. Next, researchers asked the assistant to respond to an email and used an LLM to judge its performance. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1622\" height=\"1048\" src=\"https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png 1622w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=300,194 300w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=768,496 768w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=800,517 800w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=1536,992 1536w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=400,258 400w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=750,485 750w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=578,373 578w, https://venturebeat.com/wp-content/uploads/2025/02/langchain-benchmark-tooling-screenshot-1.png?resize=930,601 930w\" sizes=\"(max-width: 1622px) 100vw, 1622px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1514\" height=\"1156\" src=\"https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?w=786\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png 1514w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=300,229 300w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=768,586 768w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=786,600 786w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=400,305 400w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=750,573 750w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=578,441 578w, https://venturebeat.com/wp-content/uploads/2025/02/Langchain-benchmark-tooling-screenshot-2.png?resize=930,710 930w\" sizes=\"(max-width: 1514px) 100vw, 1514px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFor the second work domain, calendar scheduling, LangChain focused on the agent’s ability to follow instructions. \u003c/p\u003e\n\n\n\n\u003cp\u003e“In other words, the agent needs to remember specific instructions provided, such as exactly when it should schedule meetings with different parties,” the researchers wrote. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-overloading-the-agent\"\u003eOverloading the agent\u003c/h2\u003e\n\n\n\n\u003cp\u003eOnce they defined parameters, LangChain set to stress out and overwhelm the email assistant agent. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt set 30 tasks each for calendar scheduling and customer support. These were run three times (for a total of 90 runs). The researchers created a calendar scheduling agent and a customer support agent to better evaluate the tasks. \u003c/p\u003e\n\n\n\n\u003cp\u003e“The calendar scheduling agent only has access to the calendar scheduling domain, and the customer support agent only has access to the customer support domain,” LangChain explained. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe researchers then added more domain tasks and tools to the agents to increase the number of responsibilities. These could range from human resources, to technical quality assurance, to legal and compliance and a host of other areas. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-single-agent-instruction-degradation\"\u003eSingle-agent instruction degradation\u003c/h2\u003e\n\n\n\n\u003cp\u003eAfter running the evaluations, LangChain found that single agents would often get too overwhelmed when told to do too many things. They began forgetting to call tools or were unable to respond to tasks when given more instructions and contexts. \u003c/p\u003e\n\n\n\n\u003cp\u003eLangChain found that calendar scheduling agents using GPT-4o “performed worse than Claude-3.5-sonnet, o1 and o3 across the various context sizes, and performance dropped off more sharply than the other models when larger context was provided.” The performance of GPT-4o calendar schedulers fell to 2% when the domains increased to at least seven. \u003c/p\u003e\n\n\n\n\u003cp\u003eOther models didn’t fare much better. Llama-3.3-70B forgot to call the send_email tool, “so it failed every test case.”\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1400\" height=\"832\" src=\"https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09%E2%80%AFPM.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png 1400w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=300,178 300w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=768,456 768w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=800,475 800w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=400,238 400w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=750,446 750w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=578,343 578w, https://venturebeat.com/wp-content/uploads/2025/02/Screenshot-2025-02-11-at-4.42.09 PM.png?resize=930,553 930w\" sizes=\"(max-width: 1400px) 100vw, 1400px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOnly Claude-3.5-sonnet, o1 and o3-mini all remembered to call the tool, but Claude-3.5-sonnet performed worse than the two other OpenAI models. However, o3-mini’s performance degrades once irrelevant domains are added to the scheduling instructions.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe customer support agent can call on more tools, but for this test, LangChain said Claude-3.5-mini performed just as well as o3-mini and o1. It also presented a shallower performance drop when more domains were added. When the context window extends, however, the Claude model performs worse. \u003c/p\u003e\n\n\n\n\u003cp\u003eGPT-4o also performed the worst among the models tested. \u003c/p\u003e\n\n\n\n\u003cp\u003e“We saw that as more context was provided, instruction following became worse. Some of our tasks were designed to follow niche specific instructions (e.g., do not perform a certain action for EU-based customers),” LangChain noted. “We found that these instructions would be successfully followed by agents with fewer domains, but as the number of domains increased, these instructions were more often forgotten, and the tasks subsequently failed.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThe company said it is exploring how to evaluate multi-agent architectures using the same domain overloading method. \u003c/p\u003e\n\n\n\n\u003cp\u003eLangChain is already invested in the performance of agents, as it introduced the \u003ca href=\"https://venturebeat.com/ai/whats-next-for-agentic-ai-langchain-founder-looks-to-ambient-agents/\"\u003econcept of “ambient agents\u003c/a\u003e,” or agents that run in the background and are triggered by specific events. These experiments could make it easier to figure out how best to ensure agentic performance. \u003c/p\u003e\n\n\n\n\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-02-11T22:53:06Z",
  "modifiedTime": "2025-02-11T22:53:46Z"
}
