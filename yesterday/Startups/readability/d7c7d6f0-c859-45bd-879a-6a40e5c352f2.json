{
  "id": "d7c7d6f0-c859-45bd-879a-6a40e5c352f2",
  "title": "Forget the hype — real AI agents solve bounded problems, not open-world fantasies",
  "link": "https://venturebeat.com/ai/forget-the-hype-real-ai-agents-solve-bounded-problems-not-open-world-fantasies/",
  "description": "Event-driven multi-agent systems are a practical architecture for working with imperfect tools in a structured way.",
  "author": "Sean Falconer, Confluent",
  "published": "Sun, 06 Jul 2025 20:15:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI agents",
    "AI, ML and Deep Learning",
    "Generative AI",
    "large language models"
  ],
  "byline": "Sean Falconer, Confluent",
  "length": 13470,
  "excerpt": "Event-driven multi-agent systems are a practical architecture for working with imperfect tools in a structured way.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now Everywhere you look, people are talking about AI agents like they’re just a prompt away from replacing entire departments. The dream is seductive: Autonomous systems that can handle anything you throw at them, no guardrails, no constraints, just give them your AWS credentials and they’ll solve all your problems. But the reality is that’s just not how the world works, especially not in the enterprise, where reliability isn’t optional. Even if an agent is 99% accurate, that’s not always good enough. If it’s optimizing food delivery routes, that means one out of every hundred orders ends up at the wrong address. In a business context, that kind of failure rate isn’t acceptable. It’s expensive, risky and hard to explain to a customer or regulator. In real-world environments like finance, healthcare and operations, the AI systems that actually deliver value don’t look anything like these frontier fantasies. They aren’t improvising in the open world; they’re solving well-defined problems with clear inputs and predictable outcomes. If we keep chasing open-world problems with half-ready technology, we’ll burn time, money and trust. But if we focus on the problems right in front of us, the ones with clear ROI and clear boundaries, we can make AI work today. This article is about cutting through the hype and building AI agents that actually ship, run and help. The problem with the open world hype The tech industry loves a moonshot (and for the record, I do too). Right now, the moonshot is open-world AI — agents that can handle anything, adapt to new situations, learn on the fly and operate with incomplete or ambiguous information. It’s the dream of general intelligence: Systems that can not only reason, but improvise. What makes a problem “open world”? Open-world problems are defined by what we don’t know. More formally, drawing from research defining these complex environments, a fully open world is characterized by two core properties:  Time and space are unbounded: An agent’s past experiences may not apply to new, unseen scenarios. Tasks are unbounded: They aren’t predetermined and can emerge dynamically. In such environments, the AI operates with incomplete information; it cannot assume that what isn’t known to be true is false, it’s simply unknown. The AI is expected to adapt to these unforeseen changes and novel tasks as it navigates the world. This presents an incredibly difficult set of problems for current AI capabilities. Most enterprise problems aren’t like this In contrast, closed-world problems are ones where the scope is known, the rules are clear and the system can assume it has all the relevant data. If something isn’t explicitly true, it can be treated as false. These are the kinds of problems most businesses actually face every day: invoice matching, contract validation, fraud detection, claims processing, inventory forecasting. FeatureOpen worldClosed worldScopeUnboundedWell-definedKnowledgeIncompleteComplete (within domain)AssumptionsUnknown ≠ falseUnknown = falseTasksEmergent, not predefinedFixed, repetitiveTestabilityExtremely hardWell-bounded These aren’t the use cases that typically make headlines, but they’re the ones businesses actually care about solving. The risk of hype and inaction However, the hype is harmful: By setting the bar at open-world general intelligence, we make enterprise AI feel inaccessible. Leaders hear about agents that can do everything, and they freeze, because they don’t know where to start. The problem feels too big, too vague, too risky. It’s like trying to design autonomous vehicles before we’ve even built a working combustion engine. The dream is exciting, but skipping the fundamentals guarantees failure. Solve what’s right in front of you Open-world problems make for great demos and even better funding rounds. But closed-world problems are where the real value is today. They’re solvable, testable and automatable. And they’re sitting inside every enterprise, just waiting for the right system to tackle them. The question isn’t whether AI will solve open-world problems eventually. The question is: What can you actually deploy right now that makes your business faster, smarter and more reliable? What enterprise agents actually look like When people imagine AI agents today, they tend to picture a chat window. A user types a prompt, and the agent responds with a helpful answer (maybe even triggers a tool or two). That’s fine for demos and consumer apps, but it’s not how enterprise AI will actually work in practice. In the enterprise, most useful agents aren’t user-initiated, they’re autonomous. They don’t sit idly waiting for a human to prompt them. They’re long-running processes that react to data as it flows through the business. They make decisions, call services and produce outputs, continuously and asynchronously, without needing to be told when to start. Imagine an agent that monitors new invoices. Every time an invoice lands, it extracts the relevant fields, checks them against open purchase orders, flags mismatches and either routes the invoice for approval or rejection, without anyone asking it to do so. It just listens for the event (“new invoice received”) and goes to work. Or think about customer onboarding. An agent might watch for the moment a new account is created, then kick off a cascade: verify documents, run know-your-customer (KYC) checks, personalize the welcome experience and schedule a follow-up message. The user never knows the agent exists. It just runs. Reliably. In real time. This is what enterprise agents look like: They’re event-driven: Triggered by changes in the system, not user prompts. They’re autonomous: They act without human initiation. They’re continuous: They don’t spin up for a single task and disappear. They’re mostly asynchronous: They work in the background, not in blocking workflows. Agents are microservices that react and emit to events, carry context, use models You don’t build these agents by fine-tuning a giant model. You build them by wiring together existing models, tools and logic. It’s a software engineering problem, not a modeling one. At their core, enterprise agents are just modern microservices with intelligence. You give them access to events, give them the right context and let a language model drive the reasoning. Agent = Event-driven microservice + context data + LLM Done well, that’s a powerful architectural pattern. It’s also a shift in mindset. Building agents isn’t about chasing artificial general intelligence (AGI). It’s about decomposing real problems into smaller steps, then assembling specialized, reliable components that can handle them, just like we’ve always done in good software systems. We’ve solved this kind of problem before If this sounds familiar, it should. We’ve been here before. When monoliths couldn’t scale, we broke them into microservices. When synchronous APIs led to bottlenecks and brittle systems, we turned to event-driven architecture. These were hard-won lessons from decades of building real-world systems. They worked because they brought structure and determinism to complex systems. I worry that we’re starting to forget that history and repeat the same mistakes in how we build AI. Because this isn’t a new problem. It’s the same engineering challenge, just with new components. And right now, enterprise AI needs the same principles that got us here: clear boundaries, loose coupling and systems designed to be reliable from the start. AI models are not deterministic, but your systems can be The problems worth solving in most businesses are closed-world: Problems with known inputs, clear rules and measurable outcomes. But the models we’re using, especially LLMs, are inherently non-deterministic. They’re probabilistic by design. The same input can yield different outputs depending on context, sampling or temperature. That’s fine when you’re answering a prompt. But when you’re running a business process? That unpredictability is a liability. So if you want to build production-grade AI systems, your job is simple: Wrap non-deterministic models in deterministic infrastructure. Build determinism around the model If you know a particular tool should be used for a task, don’t let the model decide, just call the tool. If your workflow can be defined statically, don’t rely on dynamic decision-making, use a deterministic call graph. If the inputs and outputs are predictable, don’t introduce ambiguity by overcomplicating the agent logic. Too many teams are reinventing runtime orchestration with every agent, letting the LLM decide what to do next, even when the steps are known ahead of time. You’re just making your life harder. Where event-driven multi-agent systems shine Event-driven multi-agent systems break the problem into smaller steps. When you assign each one to a purpose-built agent and trigger them with structured events, you end up with a loosely coupled, fully traceable system that works the way enterprise systems are supposed to work: With reliability, accountability and clear control. And because it’s event-driven: Agents don’t need to know about each other. They just respond to events. Work can happen in parallel, speeding up complex flows. Failures are isolated and recoverable via event logs or retries. You can observe, debug and test each component in isolation. Don’t chase magic Closed-world problems don’t require magic. They need solid engineering. And that means combining the flexibility of LLMs with the structure of good software engineering. If something can be made deterministic, make it deterministic. Save the model for the parts that actually require judgment. That’s how you build agents that don’t just look good in demos but actually run, scale and deliver in production. Why testing is so much harder in an open world One of the most overlooked challenges in building agents is testing, but it is absolutely essential for the enterprise. In an open-world context, it’s nearly impossible to do well. The problem space is unbounded so the inputs can be anything, the desired outputs are often ambiguous and even the criteria for success might shift depending on context. How do you write a test suite for a system that can be asked to do almost anything? You can’t. That’s why open-world agents are so hard to validate in practice. You can measure isolated behaviors or benchmark narrow tasks, but you can’t trust the system end-to-end unless you’ve somehow seen it perform across a combinatorially large space of situations, which no one has. In contrast, closed-world problems make testing tractable. The inputs are constrained. The expected outputs are definable. You can write assertions. You can simulate edge cases. You can know what “correct” looks like. And if you go one step further, decomposing your agent’s logic into smaller, well-scoped components using an event-driven architecture, it gets even more tractable. Each agent in the system has a narrow responsibility. Its behavior can be tested independently, its inputs and outputs mocked or replayed, and its performance evaluated in isolation. When the system is modular, and the scope of each module is closed-world, you can build test sets that actually give you confidence. This is the foundation for trust in production AI. Building the right foundation The future of AI in the enterprise doesn’t start with AGI. It starts with automation that works. That means focusing on closed-world problems that are structured, bounded and rich with opportunity for real impact. You don’t need an agent that can do everything. You need a system that can reliably do something: A claim routed correctly. A document parsed accurately. A customer followed up with on time. Those wins add up. They reduce costs, free up time and build trust in AI as a dependable part of the stack. And getting there doesn’t require breakthroughs in prompt engineering or betting on the next model to magically generalize. It requires doing what good engineers have always done: Breaking problems down, building composable systems and wiring components together in ways that are testable and observable. Event-driven multi-agent systems aren’t a silver bullet, they’re just a practical architecture for working with imperfect tools in a structured way. They let you isolate where intelligence is needed, contain where it’s not and build systems that behave predictably even when individual parts don’t. This isn’t about chasing the frontier. It’s about applying basic software engineering to a new class of problems. Sean Falconer is Confluent’s AI entrepreneur in residence. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/07/DDM-engineer.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\u003c/em\u003e \u003cem\u003e\u003ca href=\"https://venturebeat.com/newsletters/\"\u003eSubscribe Now\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eEverywhere you look, people are talking about \u003ca href=\"https://venturebeat.com/ai/launching-your-first-ai-project-with-a-grain-of-rice-weighing-reach-impact-confidence-and-effort-to-create-your-roadmap/\"\u003eAI agents\u003c/a\u003e like they’re just a prompt away from replacing entire departments. The dream is seductive: Autonomous systems that can handle anything you throw at them, no guardrails, no constraints, just give them your AWS credentials and they’ll solve all your problems. But the reality is that’s just not how the world works, especially not in the enterprise, where reliability isn’t optional.\u003c/p\u003e\n\n\n\n\u003cp\u003eEven if an agent is 99% accurate, that’s not always good enough. If it’s optimizing food delivery routes, that means one out of every hundred orders ends up at the wrong address. In a business context, that kind of failure rate isn’t acceptable. It’s expensive, risky and hard to explain to a customer or regulator.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn real-world environments like finance, healthcare and operations, the AI systems that actually deliver value don’t look anything like these \u003ca href=\"https://venturebeat.com/ai/from-ai-agent-hype-to-practicality-why-enterprises-must-consider-fit-over-flash/\"\u003efrontier fantasies\u003c/a\u003e. They aren’t improvising in the open world; they’re solving well-defined problems with clear inputs and predictable outcomes.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf we keep chasing open-world problems with half-ready technology, we’ll burn time, money and trust. But if we focus on the problems right in front of us, the ones with clear \u003ca href=\"https://www.ciodive.com/news/enterprise-AI-ROI-CDW/745933/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eROI and clear boundaries\u003c/a\u003e, we can make AI work today.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis article is about cutting through the hype and building AI agents that actually ship, run and help.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-problem-with-the-open-world-hype\"\u003eThe problem with the open world hype\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe tech industry loves a moonshot (and for the record, I do too). Right now, the moonshot is \u003ca href=\"https://openreview.net/pdf?id=3SBYJI4sv4\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eopen-world AI\u003c/a\u003e — agents that can handle anything, adapt to new situations, learn on the fly and operate with incomplete or ambiguous information. It’s the dream of general intelligence: Systems that can not only reason, but improvise.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-what-makes-a-problem-open-world\"\u003eWhat makes a problem “open world”?\u003c/h3\u003e\n\n\n\n\u003cp\u003eOpen-world problems are defined by what we \u003cem\u003edon’t\u003c/em\u003e know.\u003c/p\u003e\n\n\n\n\u003cp\u003eMore formally, drawing from research defining these \u003ca href=\"https://openreview.net/pdf?id=3SBYJI4sv4\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecomplex environments\u003c/a\u003e, a fully open world is characterized by two core properties: \u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eTime and space are unbounded: An agent’s past experiences may not apply to new, unseen scenarios.\u003c/li\u003e\n\n\n\n\u003cli\u003eTasks are unbounded: They aren’t predetermined and can emerge dynamically.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eIn such environments, the AI operates with incomplete information; it cannot assume that \u003ca href=\"https://www.dataversity.net/introduction-to-open-world-assumption-vs-closed-world-assumption/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewhat isn’t known to be true is false\u003c/a\u003e, it’s simply unknown. The AI is expected to adapt to these unforeseen changes and novel tasks as it navigates the world. This presents an incredibly difficult set of problems for current AI capabilities.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-most-enterprise-problems-aren-t-like-this\"\u003eMost enterprise problems aren’t like this\u003c/h3\u003e\n\n\n\n\u003cp\u003eIn contrast, closed-world problems are ones where the scope is known, the rules are clear and the system can assume it has all the relevant data. If something isn’t explicitly true, \u003ca href=\"https://emeritus.org/in/learn/closed-world-assumption-in-ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eit can be treated as false\u003c/a\u003e. These are the kinds of problems most businesses actually face every day: invoice matching, contract validation, fraud detection, claims processing, inventory forecasting.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cstrong\u003eFeature\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003e\u003cstrong\u003eOpen world\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003e\u003cstrong\u003eClosed world\u003c/strong\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eScope\u003c/td\u003e\u003ctd\u003eUnbounded\u003c/td\u003e\u003ctd\u003eWell-defined\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eKnowledge\u003c/td\u003e\u003ctd\u003eIncomplete\u003c/td\u003e\u003ctd\u003eComplete (within domain)\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eAssumptions\u003c/td\u003e\u003ctd\u003eUnknown ≠ false\u003c/td\u003e\u003ctd\u003eUnknown = false\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eTasks\u003c/td\u003e\u003ctd\u003eEmergent, not predefined\u003c/td\u003e\u003ctd\u003eFixed, repetitive\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eTestability\u003c/td\u003e\u003ctd\u003eExtremely hard\u003c/td\u003e\u003ctd\u003eWell-bounded\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThese aren’t the use cases that typically make headlines, but they’re the ones businesses actually care about solving.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-the-risk-of-hype-and-inaction\"\u003eThe risk of hype and inaction\u003c/h3\u003e\n\n\n\n\u003cp\u003eHowever, the hype is harmful: By setting the bar at open-world general intelligence, we make enterprise AI feel inaccessible. Leaders hear about agents that can do everything, and they freeze, because they don’t know where to start. The problem feels too big, too vague, too risky.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt’s like trying to design autonomous vehicles before we’ve even built a working combustion engine. The dream is exciting, but skipping the fundamentals guarantees failure.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-solve-what-s-right-in-front-of-you\"\u003eSolve what’s right in front of you\u003c/h3\u003e\n\n\n\n\u003cp\u003eOpen-world problems make for great demos and even better funding rounds. But closed-world problems are where the real value is today. They’re solvable, testable and automatable. And they’re sitting inside every enterprise, just waiting for the right system to tackle them.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe question isn’t whether AI will solve open-world problems eventually. The question is: What can you actually deploy right now that makes your business faster, smarter and more reliable?\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-enterprise-agents-actually-look-like\"\u003eWhat enterprise agents actually look like\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhen people imagine \u003ca href=\"https://venturebeat.com/ai/from-fear-to-fluency-why-empathy-is-the-missing-ingredient-in-ai-rollouts/\"\u003eAI agents\u003c/a\u003e today, they tend to picture a chat window. A user types a prompt, and the agent responds with a helpful answer (maybe even triggers a tool or two). That’s fine for demos and consumer apps, but it’s not how enterprise AI will actually work in practice.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn the enterprise, most useful agents aren’t user-initiated, they’re autonomous.\u003c/p\u003e\n\n\n\n\u003cp\u003eThey don’t sit idly waiting for a human to prompt them. They’re long-running processes that react to data as it \u003ca href=\"https://www.automationanywhere.com/rpa/multi-agent-systems\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eflows through the business\u003c/a\u003e. They make decisions, call services and produce outputs, continuously and asynchronously, without needing to be told when to start.\u003c/p\u003e\n\n\n\n\u003cp\u003eImagine an agent that monitors new invoices. Every time an invoice lands, it extracts the relevant fields, checks them against open purchase orders, flags mismatches and either routes the invoice for approval or rejection, without anyone asking it to do so. It just listens for the event (“new invoice received”) and goes to work.\u003c/p\u003e\n\n\n\n\u003cp\u003eOr think about customer onboarding. An agent might watch for the moment a new account is created, then kick off a cascade: verify documents, run know-your-customer (KYC) checks, personalize the welcome experience and schedule a follow-up message. The user never knows the agent exists. It just runs. Reliably. In real time.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis is what enterprise agents look like:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eThey’re event-driven: Triggered by changes in the system, not user prompts.\u003c/li\u003e\n\n\n\n\u003cli\u003eThey’re autonomous: They act without human initiation.\u003c/li\u003e\n\n\n\n\u003cli\u003eThey’re continuous: They don’t spin up for a single task and disappear.\u003c/li\u003e\n\n\n\n\u003cli\u003eThey’re mostly asynchronous: They work in the background, not in blocking workflows.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" height=\"326\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/image1.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/07/image1.png 1999w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=300,122 300w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=768,313 768w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=800,326 800w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=1536,625 1536w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=400,163 400w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=750,305 750w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=578,235 578w, https://venturebeat.com/wp-content/uploads/2025/07/image1.png?resize=930,379 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eAgents are microservices that react and emit to events, carry context, use models\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eYou don’t build these agents by fine-tuning a giant model. You build them by \u003ca href=\"https://www2.deloitte.com/us/en/pages/consulting/articles/ai-agent-architecture-and-multiagent-systems.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewiring together existing models, tools and logic\u003c/a\u003e. It’s a software engineering problem, not a modeling one.\u003c/p\u003e\n\n\n\n\u003cp\u003eAt their core, enterprise agents are just modern microservices with intelligence. You give them access to events, give them the right context and let a language model drive the reasoning.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eAgent = Event-driven microservice + context data + LLM\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eDone well, that’s a powerful architectural pattern. It’s also a shift in mindset. Building agents isn’t about chasing \u003ca href=\"https://venturebeat.com/ai/between-utopia-and-collapse-navigating-ais-murky-middle-future/\"\u003eartificial general intelligence\u003c/a\u003e (AGI). It’s about decomposing real problems into smaller steps, then assembling specialized, reliable components that can handle them, just like we’ve always done in good software systems.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-we-ve-solved-this-kind-of-problem-before\"\u003eWe’ve solved this kind of problem before\u003c/h2\u003e\n\n\n\n\u003cp\u003eIf this sounds familiar, it should. We’ve been here before.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen monoliths couldn’t scale, we broke them into microservices. When synchronous APIs led to bottlenecks and brittle systems, we turned to \u003ca href=\"https://www.techcircle.in/2025/05/06/why-event-driven-design-is-key-to-scalable-multi-agent-ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eevent-driven architecture\u003c/a\u003e. These were hard-won lessons from decades of building real-world systems. They worked because they brought structure and determinism to complex systems.\u003c/p\u003e\n\n\n\n\u003cp\u003eI worry that we’re starting to forget that history and repeat the same mistakes in how we build AI.\u003c/p\u003e\n\n\n\n\u003cp\u003eBecause this isn’t a new problem. It’s the same engineering challenge, just with new components. And right now, enterprise AI needs the same principles that got us here: clear boundaries, loose coupling and systems designed to be reliable from the start.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-ai-models-are-not-deterministic-but-your-systems-can-be\"\u003eAI models are not deterministic, but your systems can be\u003c/h3\u003e\n\n\n\n\u003cp\u003eThe problems worth solving in most businesses are closed-world: Problems with known inputs, clear rules and measurable outcomes. But the models we’re using, especially LLMs, are inherently non-deterministic. They’re probabilistic by design. The same input can yield different outputs depending on context, sampling or temperature.\u003c/p\u003e\n\n\n\n\u003cp\u003eThat’s fine when you’re answering a prompt. But when you’re running a business process? That unpredictability is a liability.\u003c/p\u003e\n\n\n\n\u003cp\u003eSo if you want to build production-grade AI systems, your job is simple: Wrap non-deterministic models in deterministic infrastructure.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-build-determinism-around-the-model\"\u003eBuild determinism around the model\u003c/h3\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eIf you know a particular tool should be used for a task, don’t let the model decide, just call the tool.\u003c/li\u003e\n\n\n\n\u003cli\u003eIf your workflow can be defined statically, don’t rely on dynamic decision-making, use a deterministic call graph.\u003c/li\u003e\n\n\n\n\u003cli\u003eIf the inputs and outputs are predictable, don’t introduce ambiguity by overcomplicating the agent logic.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eToo many teams are reinventing runtime orchestration with every agent, letting the LLM \u003ca href=\"https://venturebeat.com/ai/rethinking-ai-deepseeks-playbook-shakes-up-the-high-spend-high-compute-paradigm/\"\u003edecide what to do next\u003c/a\u003e, even when the steps are known ahead of time. You’re just making your life harder.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-where-event-driven-multi-agent-systems-shine\"\u003eWhere event-driven multi-agent systems shine\u003c/h3\u003e\n\n\n\n\u003cp\u003eEvent-driven multi-agent systems break the problem into smaller steps. When you assign each one to a purpose-built agent and trigger them with structured events, you end up with a loosely coupled, fully traceable system that works the way enterprise systems are supposed to work: With reliability, accountability and clear control.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnd because it’s event-driven:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eAgents don’t need to know about each other. They just respond to events.\u003c/li\u003e\n\n\n\n\u003cli\u003eWork can happen in parallel, speeding up complex flows.\u003c/li\u003e\n\n\n\n\u003cli\u003eFailures are isolated and recoverable via event logs or retries.\u003c/li\u003e\n\n\n\n\u003cli\u003eYou can observe, debug and test each component in isolation.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch3 id=\"h-don-t-chase-magic\"\u003eDon’t chase magic\u003c/h3\u003e\n\n\n\n\u003cp\u003eClosed-world problems don’t require magic. They need solid engineering. And that means combining the flexibility of LLMs with the structure of good software engineering. If something can be made deterministic, make it deterministic. Save the model for the parts that actually require judgment.\u003c/p\u003e\n\n\n\n\u003cp\u003eThat’s how you build agents that don’t just look good in demos but actually run, scale and deliver in production.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-why-testing-is-so-much-harder-in-an-open-world\"\u003eWhy testing is so much harder in an open world\u003c/h2\u003e\n\n\n\n\u003cp\u003eOne of the most overlooked challenges in building agents is testing, but it is absolutely essential for the enterprise.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn an open-world context, it’s nearly impossible to do well. The problem space is unbounded so the inputs can be anything, the desired outputs are often ambiguous and even the criteria for success might shift depending on context.\u003c/p\u003e\n\n\n\n\u003cp\u003eHow do you write a test suite for a system that can be asked to do almost anything? You can’t.\u003c/p\u003e\n\n\n\n\u003cp\u003eThat’s why open-world agents are so hard to validate in practice. You can measure isolated behaviors or benchmark narrow tasks, but you can’t trust the system end-to-end unless you’ve somehow seen it perform across a combinatorially large space of situations, which no one has.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn contrast, closed-world problems make testing tractable. The inputs are constrained. The expected outputs are definable. You can write assertions. You can simulate edge cases. You can know what “correct” looks like.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnd if you go one step further, decomposing your agent’s logic into smaller, well-scoped components using an event-driven architecture, it gets even more tractable. Each agent in the system has a \u003ca href=\"https://www.appsecengineer.com/blog/building-secure-multi-agent-ai-architectures-for-enterprise-secops\" target=\"_blank\" rel=\"noreferrer noopener\"\u003enarrow responsibility\u003c/a\u003e. Its behavior can be tested independently, its inputs and outputs mocked or replayed, and its performance evaluated in isolation.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen the system is modular, and the scope of each module is closed-world, you can build test sets that actually give you confidence.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis is the foundation for trust in production AI.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-building-the-right-foundation\"\u003eBuilding the right foundation\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe future of AI in the enterprise doesn’t start with AGI. It starts with automation that works. That means focusing on closed-world problems that are structured, bounded and rich with opportunity for real impact.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou don’t need an agent that can do everything. You need a system that can reliably do something:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eA claim routed correctly.\u003c/li\u003e\n\n\n\n\u003cli\u003eA document parsed accurately.\u003c/li\u003e\n\n\n\n\u003cli\u003eA customer followed up with on time.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThose wins add up. They reduce costs, free up time and build trust in AI as a dependable part of the stack.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnd getting there doesn’t require breakthroughs in prompt engineering or betting on the next model to magically generalize. It requires doing what good engineers have always done: Breaking problems down, building composable systems and wiring components together in ways that are testable and observable.\u003c/p\u003e\n\n\n\n\u003cp\u003eEvent-driven multi-agent systems aren’t a silver bullet, they’re just a practical architecture for working with imperfect tools in a structured way. They let you isolate where intelligence is needed, contain where it’s not and build systems that behave predictably even when individual parts don’t.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis isn’t about chasing the frontier. It’s about applying basic software engineering to a new class of problems.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eSean Falconer is Confluent’s AI entrepreneur in residence.\u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "15 min read",
  "publishedTime": "2025-07-06T20:15:00Z",
  "modifiedTime": "2025-07-06T19:27:57Z"
}
