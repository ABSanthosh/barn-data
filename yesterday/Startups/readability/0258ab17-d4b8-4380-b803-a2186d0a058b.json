{
  "id": "0258ab17-d4b8-4380-b803-a2186d0a058b",
  "title": "Wayland Apps in WireGuard Docker Containers",
  "link": "https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/",
  "description": "Article URL: https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/ Comments URL: https://news.ycombinator.com/item?id=41874511 Points: 24 # Comments: 5",
  "author": "justinludwig",
  "published": "Thu, 17 Oct 2024 22:36:38 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "by Justin Ludwig",
  "length": 33523,
  "excerpt": "How to use GUI Linux applications with a Docker WireGuard network.",
  "siteName": "Pro Custodibus",
  "favicon": "https://www.procustodibus.com/icon.png",
  "text": "Running WireGuard in a Docker container can be a convenient way to isolate a WireGuard network from the rest of a system. We’ve covered a variety of different patterns for using WireGuard in containers in the past; in this article we’ll dive deep into one particular pattern: using GUI (Graphical User Interface) Linux applications inside Docker containers to access remote sites through WireGuard. We’ll build on the core “Container Network” technique covered previously, where we use a shared network namespace to allow other containers to access the WireGuard network of a dedicated WireGuard container. In this case, we’ll build and run several custom containers with a couple of GUI applications, allowing their GUIs to be used seamlessly as part of the container host’s Wayland display — while still being able to access remote servers through the isolated WireGuard network of the WireGuard container. We’ll work our way up to running a full-fledged Firefox browser with video and audio in a container to access an isolated WireGuard network, but first we’ll cover a number of intermediate steps before we get there: Set up our Docker Projects Set up the WireGuard Network Set up a simple SMB Client Set up an SSH Client with SSH-agent access Set up an RDP Client with Wayland Set up a basic Firefox Client Configure WireGuard Internet Access Update Firefox With Video \u0026 Audio support Add miscellaneous Firefox Extras Docker Projects ~/containers/wg-build/docker-compose.yml, to build the container images ~/containers/wg-network1/docker-compose.yml, to run the containers The first project will contain the Dockerfiles and (other miscellaneous files) that we need to build our custom container images; and the second project will contain the files and settings we use at runtime with our WireGuard network (such as the WireGuard configuration files, and the browser profile and cache content). This will allow us to use the second project as a template for other WireGuard networks that we might want to add in the future; for example, to add a new ~/containers/wg-network-east project to access our Eastern datacenter, and a separate ~/containers/wg-network-west project to access our Western datacenter. WireGuard Network As shown by that guide, on the remote side of the connection (Host β), we’ll set up a WireGuard interface with the following configuration: # /etc/wireguard/wg0.conf # local settings for Host β [Interface] PrivateKey = ABBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBFA= Address = 10.0.0.2/32 ListenPort = 51822 # IP forwarding PreUp = sysctl -w net.ipv4.ip_forward=1 # IP masquerading PreUp = iptables -t mangle -A PREROUTING -i wg0 -j MARK --set-mark 0x30 PreUp = iptables -t nat -A POSTROUTING ! -o wg0 -m mark --mark 0x30 -j MASQUERADE PostDown = iptables -t mangle -D PREROUTING -i wg0 -j MARK --set-mark 0x30 PostDown = iptables -t nat -D POSTROUTING ! -o wg0 -m mark --mark 0x30 -j MASQUERADE # remote settings for Endpoint A [Peer] PublicKey = /TOE4TKtAqVsePRVR+5AA43HkAK5DSntkOCO7nYq5xU= AllowedIPs = 10.0.0.1/32 Start up this WireGuard interface on the remote host as shown in the guide (eg sudo wg-quick up wg0 ). For the local side of the connection (our personal laptop), we’ll use the configuration for Endpoint A from the guide, saving it as ~/containers/wg-network1/wg/wg0.conf: # ~/containers/wg-network1/wg/wg0.conf # local settings for Endpoint A [Interface] PrivateKey = AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEE= Address = 10.0.0.1/32 ListenPort = 51821 # remote settings for Host β [Peer] PublicKey = fE/wdxzl0klVp/IR8UcaoGUMjqaWi3jAd7KzHKFS6Ds= Endpoint = 203.0.113.2:51822 AllowedIPs = 192.168.200.0/24 This WireGuard network will allow the local side of the connection access to the other servers in the 192.168.200.0/24 network address range at Site B. To run this connection in a Docker container, we’ll add a wg service to our runtime compose file at ~/containers/wg-network1/docker-compose.yml: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN volumes: - ./wg:/etc/wireguard Then we’ll start up the wg service: $ cd ~/containers/wg-network1 $ sudo docker compose up wg [+] Running 11/11 ✔ wg Pulled ... [+] Running 1/1 ✔ Container wg-network1-wg-1 Created ... Attaching to wg-1 wg-1 | wg-1 | * /proc is already mounted wg-1 | * /run/lock: creating directory wg-1 | * /run/lock: correcting owner wg-1 | OpenRC 0.54 is starting up Linux 6.5.0-45-generic (x86_64) [DOCKER] wg-1 | wg-1 | * Caching service dependencies ... [ ok ] wg-1 | [#] ip link add wg0 type wireguard wg-1 | [#] wg setconf wg0 /dev/fd/63 wg-1 | [#] ip -4 address add 10.0.0.1/32 dev wg0 wg-1 | [#] ip link set mtu 1420 up dev wg0 wg-1 | [#] ip -4 route add 192.168.200.0/24 dev wg0 wg-1 | * Starting WireGuard interface wg0 ... [ ok ] The WireGuard connection from our local machine to Site B is now up and running inside the wg-network1-wg-1 container. SMB Client As the first step to using this WireGuard connection, we’ll set up a simple SMB client, using the command-line smbclient program. We’ll build an image for this client with the following Dockerfile: # ~/containers/wg-build/smb/Dockerfile FROM alpine:latest RUN apk add --no-cache \\ bash \\ samba-client RUN addgroup al \u0026\u0026 adduser -D -G al al USER al WORKDIR /home/al CMD bash The only thing notable about this image is that it creates and will use a custom user account — with a user ID of 1000, to match the UID of our personal user on the container host — allowing us to avoid any file-ownership annoyances when sharing files between the container and the host. Save this Dockerfile at ~/containers/wg-build/smb/Dockerfile, then add a service for it to our build compose file at ~/containers/wg-build/docker-compose.yml: # ~/containers/wg-build/docker-compose.yml services: smb: build: smb image: my-smb And build the image: $ cd ~/containers/wg-build $ sudo docker compose build smb [+] Building ... =\u003e =\u003e naming to docker.io/library/my-smb =\u003e [build] resolving provenance for metadata file Next, add a service for it to our runtime compose file at ~/containers/wg-network1/docker-compose.yml: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN volumes: - ./wg:/etc/wireguard smb: image: my-smb network_mode: 'service:wg' volumes: - ./smb:/home/al This new smb service will use the my-smb image we just built, and it will share the wg service’s network namespace (so it can use the WireGuard interface) — plus it will mount the container host’s ~/containers/wg-network1/smb/ directory to the home directory of the custom user (al) within the container. Before using this container, create this ~/containers/wg-network1/smb/ mount point on the host: $ cd ~/containers/wg-network1 $ mkdir -p smb And if we had previously shut down the wg service, make sure to start it back up again: $ cd ~/containers/wg-network1 $ sudo docker compose up wg ... Then (in a new terminal) run the smb service: $ cd ~/containers/wg-network1 $ sudo docker compose run smb [+] Running 1/0 ✔ Container wg-network1-wg-1 Running ... 2a04e264f1da:~$ This will bring up a Bash shell in the wg-network1-smb-1 container. In this shell, we can use the SMB client to connect to an SMB server at the remote site through the WireGuard connection provided by the wg service: 2a04e264f1da:~$ smbclient -U justin '\\\\192.168.200.33\\shares' Password for [WORKGROUP\\justin]: Try \"help\" to get a list of possible commands. smb: \\\u003e Or we can just use the WireGuard connection to ping a server at the remote site: 2a04e264f1da:~$ ping -nc1 192.168.200.22 PING 192.168.200.22 (192.168.200.22): 56 data bytes 64 bytes from 192.168.200.22: seq=0 ttl=42 time=68.573 ms --- 192.168.200.22 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 68.573/68.573/68.573 ms SSH Client As the next step, we’ll set up an SSH client in a container that can use this WireGuard network and still have access to the SSH agent on the container host. Having access to the host’s SSH agent will enable us to use any SSH keys stored on the host — or on a smart card attached to the host — that we’ve added to the SSH agent. For this step, we’ll again build a simple image for the client with a custom Dockerfile: # ~/containers/wg-build/ssh/Dockerfile FROM alpine:latest RUN apk add --no-cache \\ bash \\ openssh-client RUN addgroup al \u0026\u0026 adduser -D -G al al \u0026\u0026 \\ mkdir -p /run/user/1000 \u0026\u0026 \\ chmod -R 700 /run/user/1000 \u0026\u0026 \\ chown -R 1000:1000 /run/user/1000 ENV SSH_AUTH_SOCK=/run/user/1000/ssh-agent USER al WORKDIR /home/al CMD bash In this Dockerfile, however, after we create a user account with a UID of 1000 (al), we’ll also set up the standard /run/user/1000/ runtime directory for user-owned socket files — and set the container’s SSH_AUTH_SOCK environment variable to point at a file in that directory. While nothing is in that directory at this point, later on (at runtime) we’ll map the host’s SSH-agent socket file into it at this specific path. Save this Dockerfile at ~/containers/wg-build/ssh/Dockerfile, then add a service for it to our build compose file at ~/containers/wg-build/docker-compose.yml: # ~/containers/wg-build/docker-compose.yml services: smb: build: smb image: my-smb ssh: build: ssh image: my-ssh And build the image: $ cd ~/containers/wg-build $ sudo docker compose build ssh [+] Building ... =\u003e =\u003e naming to docker.io/library/my-ssh =\u003e [build] resolving provenance for metadata file Next, add a service for it to our runtime compose file at ~/containers/wg-network1/docker-compose.yml: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN volumes: - ./wg:/etc/wireguard smb: image: my-smb network_mode: 'service:wg' volumes: - ./smb:/home/al ssh: image: my-ssh network_mode: 'service:wg' volumes: - $SSH_AUTH_SOCK:/run/user/1000/ssh-agent - ./ssh:/home/al This service definition for the ssh service is similar to that of the SMB Client, except that we have added an additional volume. We use this additional volume definition to map our actual SSH-agent socket file on the host to the /run/user/1000/ssh-agent socket file referenced in the my-ssh image’s Dockerfile. Note Run the following command in a terminal on the host to see where the SSH-agent socket file on your host lives: $ echo $SSH_AUTH_SOCK /run/user/1000/gnupg/S.gpg-agent.ssh If this environment variable is empty, you’re probably not running an SSH agent. Mapping the SSH-agent socket file like this enables us to use the SSH agent from the host inside the container. Now we can start up the ssh service. Run the following commands (in a new terminal) to create the ~/containers/wg-network1/ssh/ mount point and start up an ssh container: $ cd ~/containers/wg-network1 $ mkdir -p ssh $ sudo docker compose run ssh [+] Running 1/0 ✔ Container wg-network1-wg-1 Running ... cc574a6ef3af:~$ This will bring up a Bash shell in a new wg-network1-ssh-1 container. If we run the ssh-add -L command in this new container, we should see all the SSH keys that we’ve added to the SSH agent on the host: cc574a6ef3af:~$ ssh-add -L sk-ssh-ed25519@openssh.com AAAAGnNrLXNzaC1lZDI1NTE5QG9wZW5zc2guY29tAAAAIO5k/uLhCT7OLR/S048kPicX6LQ9CUgJugjSjPxGq3XmAAAABHNzaDo= justin@myws And we should be able to use those SSH keys to SSH through WireGuard into any servers at Site B that accept them: cc574a6ef3af:~$ ssh justin@192.168.200.22 Last login: Tue Oct 1 18:07:25 2024 from 192.168.200.33 justin@www:~$ Note that because we’ve mounted the host’s ~/containers/wg-network1/ssh/ directory to the ssh service’s /home/al/ directory, we can use the host’s ~/containers/wg-network1/ssh/.ssh/ subdirectory to configure SSH in the container. For example, if configure the ~/containers/wg-network1/ssh/.ssh/config file like the following: # ~/containers/wg-network1/ssh/.ssh/config Host www-server HostName 192.168.200.22 User justin Then in the ssh container, we can simply run the following command to SSH into the 192.168.200.22 host as the justin user: cc574a6ef3af:~$ ssh www-server Last login: Tue Oct 1 22:10:53 2024 from 192.168.200.2 justin@www:~$ RDP Client Now we’re ready to set up our first GUI app in a Docker container. For this step, we’ll set up Remmina, which provides a GUI for connecting to a remote server over RDP. To enable the Remmina GUI to work, we’ll need to use the same trick that we used above to pass the host’s SSH-agent socket to the SSH Client — but this time we’ll need to pass the host’s Wayland-display socket. Note This guide assumes you’re running Wayland on the host. If you are instead using X11, the same principle applies, but with a few different settings. See the x11docker project wiki for more information. If you’re unsure as to whether or not you’re running Wayland, run the following command on the host: $ echo $WAYLAND_DISPLAY wayland-1 If this environment variable is empty, you’re probably not running Wayland. For this step, we’ll build an image for Remmina (and its RDP plugin) using a custom Dockerfile: # ~/containers/wg-build/rdp/Dockerfile FROM ubuntu:22.04 ARG APT_GET=\"apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\" \\ DEBIAN_FRONTEND=noninteractive \\ DEBIAN_PRIORITY=critical ENV LANG=en_US RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install \\ remmina \\ remmina-plugin-rdp \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* RUN adduser ubuntu \u0026\u0026 \\ mkdir -p /run/user/1000 \u0026\u0026 \\ chmod -R 700 /run/user/1000 \u0026\u0026 \\ chown -R 1000:1000 /run/user/1000 ENV WAYLAND_DISPLAY=wayland-0 \\ XDG_RUNTIME_DIR=/run/user/1000 USER ubuntu WORKDIR /home/ubuntu CMD remmina Like with the Dockerfile from the SSH Client, after we create a user account with a UID of 1000 (this time named ubuntu), we’ll also set up the standard /run/user/1000/ runtime directory for user-owned socket files. In this Dockerfile, however, we’ll set the container’s XDG_RUNTIME_DIR environment variable to point to that directory; and we’ll also set the container’s WAYLAND_DISPLAY environment variable. Together, they’ll signal to programs running in the container that they can use a socket file at /run/user/1000/wayland-0 in the container to connect to Wayland. Note The version of Remmina packaged with Ubuntu 24.04 seems to work only with X11 — so we’re deliberately using Ubuntu 22.04 as the base image for this Dockerfile, as its remmina package works nicely with Wayland. Save this Dockerfile at ~/containers/wg-build/rdp/Dockerfile, then add a service for it to our build compose file at ~/containers/wg-build/docker-compose.yml: # ~/containers/wg-build/docker-compose.yml services: ... ssh: build: ssh image: my-ssh rdp: build: rdp image: my-rdp And build the image: $ cd ~/containers/wg-build $ sudo docker compose build rdp [+] Building ... =\u003e =\u003e naming to docker.io/library/my-rdp =\u003e [build] resolving provenance for metadata file Next, add a service for it to our runtime compose file at ~/containers/wg-network1/docker-compose.yml: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN volumes: - ./wg:/etc/wireguard ... ssh: image: my-ssh network_mode: 'service:wg' volumes: - $SSH_AUTH_SOCK:/run/user/1000/ssh-agent - ./ssh:/home/al rdp: image: my-rdp network_mode: 'service:wg' volumes: - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0 - ./rdp:/home/ubuntu Like the SSH Client, we use the rdp service definition to map a socket file from the host into a container. With the rdp service, however, we’re mapping the Wayland-display socket file; which we map from the host to the container’s /run/user/1000/wayland-0 path. Mapping the Wayland-display socket file like this enables Remmina, running in the container, to interact with our Wayland display, running on the host. If we now run the rdp service in a new terminal, this will start up Remmina, and open up its main window in the host’s Wayland display: $ cd ~/containers/wg-network1 $ mkdir -p rdp $ sudo docker compose run rdp ... Which allows us to use Remmina’s GUI to RDP through WireGuard to a server in Site B: And because we mapped the host’s ~/containers/wg-network1/rdp directory to the home directory of the container’s user, all the container’s Remmina preferences (and cache data) are stored there: $ tree -a ~/containers/wg-network1/rdp /home/justin/containers/wg-network1/rdp ├── .cache │   ├── org.remmina.Remmina │   │   └── latest_news.md │   └── remmina │   ├── group_rdp_shares_192-168-200-33.remmina.state │   └── remmina.pref.state ├── .config │   ├── freerdp │   │   ├── certs │   │   ├── known_hosts2 │   │   └── server │   ├── gtk-3.0 │   └── remmina │   └── remmina.pref └── .local    └── share    ├── recently-used.xbel    └── remmina    └── group_rdp_shares_192-168-200-33.remmina 13 directories, 7 files Firefox Client Now we’re ready to set up Firefox in a Docker container. Just like with the RDP Client above, we’ll pass the host’s Wayland-display socket to the container through a volume mount point, allowing Firefox, running in a container, to use the host’s display. And like with the RDP Client, we’ll also build a Docker image for Firefox with a custom Dockerfile: # ~/containers/wg-build/ff/Dockerfile FROM ubuntu:24.04 ARG APT_GET=\"apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\" \\ DEBIAN_FRONTEND=noninteractive \\ DEBIAN_PRIORITY=critical ENV LANG=en_US RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install ca-certificates COPY conf/packages.mozilla.org.asc /etc/apt/keyrings/packages.mozilla.org.asc COPY conf/mozilla.list /etc/apt/sources.list.d/mozilla.list COPY conf/mozilla-pin /etc/apt/preferences.d/mozilla-pin RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install \\ firefox \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* RUN mkdir -p /run/user/1000 \u0026\u0026 \\ chmod -R 700 /run/user/1000 \u0026\u0026 \\ chown -R 1000:1000 /run/user/1000 ENV WAYLAND_DISPLAY=wayland-0 \\ XDG_RUNTIME_DIR=/run/user/1000 USER ubuntu WORKDIR /home/ubuntu CMD firefox This Dockerfile is quite similar to the one for the RDP Client, differing only in that: We use the latest Ubuntu LTS (24.04) We add the Mozilla repositories We install the firefox package instead of the remmina packages We add the Mozilla repositories to avoid the Snapcraft packages used by default in Ubuntu for Firefox. Save the configuration files needed for the Mozilla repositories in the ~/containers/wg-build/ff/conf/ directory: # ~/containers/wg-build/ff/conf/packages.mozilla.org.asc -----BEGIN PGP PUBLIC KEY BLOCK----- xsBNBGCRt7MBCADkYJHHQQoL6tKrW/LbmfR9ljz7ib2aWno4JO3VKQvLwjyUMPpq /SXXMOnx8jXwgWizpPxQYDRJ0SQXS9ULJ1hXRL/OgMnZAYvYDeV2jBnKsAIEdiG/ e1qm8P4W9qpWJc+hNq7FOT13RzGWRx57SdLWSXo0KeY38r9lvjjOmT/cuOcmjwlD T9XYf/RSO+yJ/AsyMdAr+ZbDeQUd9HYJiPdI04lGaGM02MjDMnx+monc+y54t+Z+ ry1WtQdzoQt9dHlIPlV1tR+xV5DHHsejCZxu9TWzzSlL5wfBBeEz7R/OIzivGJpW QdJzd+2QDXSRg9q2XYWP5ZVtSgjVVJjNlb6ZABEBAAHNVEFydGlmYWN0IFJlZ2lz dHJ5IFJlcG9zaXRvcnkgU2lnbmVyIDxhcnRpZmFjdC1yZWdpc3RyeS1yZXBvc2l0 b3J5LXNpZ25lckBnb29nbGUuY29tPsLAjgQTAQoAOBYhBDW6oLM+nrOW9ZyoOMC6 XObcYxWjBQJgkbezAhsDBQsJCAcCBhUKCQgLAgQWAgMBAh4BAheAAAoJEMC6XObc YxWj+igIAMFh6DrAYMeq9sbZ1ZG6oAMrinUheGQbEqe76nIDQNsZnhDwZ2wWqgVC 7DgOMqlhQmOmzm7M6Nzmq2dvPwq3xC2OeI9fQyzjT72deBTzLP7PJok9PJFOMdLf ILSsUnmMsheQt4DUO0jYAX2KUuWOIXXJaZ319QyoRNBPYa5qz7qXS7wHLOY89IDq fHt6Aud8ER5zhyOyhytcYMeaGC1g1IKWmgewnhEq02FantMJGlmmFi2eA0EPD02G C3742QGqRxLwjWsm5/TpyuU24EYKRGCRm7QdVIo3ugFSetKrn0byOxWGBvtu4fH8 XWvZkRT+u+yzH1s5yFYBqc2JTrrJvRU= =QnvN -----END PGP PUBLIC KEY BLOCK----- # ~/containers/wg-build/ff/conf/mozilla.list deb [signed-by=/etc/apt/keyrings/packages.mozilla.org.asc] https://packages.mozilla.org/apt mozilla main # ~/containers/wg-build/ff/conf/mozilla-pin Package: * Pin: origin packages.mozilla.org Pin-Priority: 1000 And add a service to build the Dockerfile to our build compose file at ~/containers/wg-build/docker-compose.yml: # ~/containers/wg-build/docker-compose.yml services: ... rdp: build: rdp image: my-rdp ff: build: ff image: my-ff Then build the image: $ cd ~/containers/wg-build $ sudo docker compose build ff [+] Building ... =\u003e =\u003e naming to docker.io/library/my-ff =\u003e [build] resolving provenance for metadata file Next, add a service for it to our runtime compose file at ~/containers/wg-network1/docker-compose.yml: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN volumes: - ./wg:/etc/wireguard ... rdp: image: my-rdp network_mode: 'service:wg' volumes: - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0 - ./rdp:/home/ubuntu ff: image: my-ff network_mode: 'service:wg' volumes: - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0 - ./ff:/home/ubuntu The service definition for Firefox is almost exactly the same as the RDP Client — all that’s different is we’re using the my-ff image, and we’re mapping the home folder of container’s ubuntu user to the host’s ff/ directory. If we run the ff service in a new terminal, this will start up Firefox, and open up a new browser window in our Wayland display: $ cd ~/containers/wg-network1 $ mkdir -p ff $ sudo docker compose run ff ... We can then browse any private webservers running in Site B, using the wg service’s WireGuard connection: All the profile settings and other data for this Firefox instance will be stored in the *.default-release/ subdirectory of the host’s ~/containers/wg-network1/ff/.mozilla/firefox/ directory. The prefix for this subdirectory is generated randomly when Firefox creates the profile; in this example, the subdirectory is mrnlwsve.default-release/: $ ls -1 ~/containers/wg-network1/ff/.mozilla/firefox 6wjegbdk.default 'Crash Reports' installs.ini mrnlwsve.default-release 'Pending Pings' profiles.ini WireGuard Internet Access If we want to use the Firefox Client to access any server on the Internet through its WireGuard connection (instead of merely any server in Site B), we need to make a couple of changes to the local side of the WireGuard Network we set up above. First, we need to change the AllowedIPs setting in our local WireGuard configuration at ~/containers/wg-network1/wg/wg0.conf to send all IPv4 traffic (0.0.0.0/0) through the WireGuard connection: # ~/containers/wg-network1/wg/wg0.conf # local settings for Endpoint A [Interface] PrivateKey = AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEE= Address = 10.0.0.1/32 ListenPort = 51821 DNS = 9.9.9.9 # remote settings for Host β [Peer] PublicKey = fE/wdxzl0klVp/IR8UcaoGUMjqaWi3jAd7KzHKFS6Ds= Endpoint = 203.0.113.2:51822 AllowedIPs = 0.0.0.0/0 And if we also want to send all DNS traffic through the WireGuard connection, we’ll also need to add a DNS setting to it, configuring it to use a DNS server available from the remote side of the connection (like the 9.9.9.9 Quad9 DNS server). Next, we need to turn on the net.ipv4.conf.all.src_valid_mark kernel parameter for the wg service (otherwise the WireGuard startup script run inside the container will fail): # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN sysctls: - net.ipv4.conf.all.src_valid_mark=1 volumes: - ./wg:/etc/wireguard ... After making those changes, close all the windows of the GUI apps that are using the wg service’s network namespace, and shut down all the services of the runtime compose file; then start them up again: $ cd ~/containers/wg-network1 $ sudo docker compose down [+] Running 2/2 ✔ Container wg-network1-wg-1 Removed ... ✔ Network wg-network1 Removed ... $ sudo docker compose up -d wg [+] Running 2/2 ✔ Network wg-network1 Created ... ✔ Container wg-network1-wg-1 Created ... $ sudo docker compose run -d ff [+] Running 1/1 ✔ Container wg-network1-wg-1 Running ... The WireGuard container — and all the other containers defined by the ~/containers/wg-network1/docker-compose.yml file to share the same network namespace — will now send all its IPv4 Internet traffic and DNS queries through Host β at the remote site: Tip If you’re having trouble accessing the Internet, make sure you’ve configured the firewall on the remote side of the WireGuard connection (Host β) to masquerade WireGuard traffic, as well as to allow all traffic forwarded from the WireGuard interface to go out through its Internet-facing network interface. Otherwise, if you’re using an iptables-based firewall on the remote host (with firewall rules similar to those shown in the Configure Firewall on Host β section of the WireGuard Point to Site Configuration guide), make sure you include a rule like the following in the host’s FORWARD chain, before any DROP or REJECT rules (where eth0 is the name of the Internet-facing network interface): iptables -A FORWARD -i wg0 -o eth0 -j ACCEPT Or if you’re using an nftables-based firewall on the remote host (with firewall rules similar to those shown in the Point to Site section of the WireGuard Nftables Configuration guide), make sure you include a rule like the following in the host’s forward chain, before any drop or reject rules (where eth0 is the name of the Internet-facing network interface): iifname wg0 oifname eth0 accept Firefox With Video \u0026 Audio If we want our containerized Firefox to play audio — plus be able to transmit audio and video from the host (so that, for example, we can use a videoconferencing webapp) — we need to add a few more packages to our custom Firefox container image, as well as to pass PulseAudio‘s socket to the Firefox container at runtime. First, edit the Dockerfile for the Firefox Client to add the ffmpeg and libpulse0 packages to it; and also to change the mkdir command that creates the /run/user/1000/ directory to simultaneously create the /run/user/1000/pulse/ subdirectory: # ~/containers/wg-build/ff/Dockerfile FROM ubuntu:24.04 ARG APT_GET=\"apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\" \\ DEBIAN_FRONTEND=noninteractive \\ DEBIAN_PRIORITY=critical ENV LANG=en_US RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install ca-certificates COPY conf/packages.mozilla.org.asc /etc/apt/keyrings/packages.mozilla.org.asc COPY conf/mozilla.list /etc/apt/sources.list.d/mozilla.list COPY conf/mozilla-pin /etc/apt/preferences.d/mozilla-pin RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install \\ ffmpeg \\ firefox \\ libpulse0 \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* RUN mkdir -p /run/user/1000/pulse \u0026\u0026 \\ chmod -R 700 /run/user/1000 \u0026\u0026 \\ chown -R 1000:1000 /run/user/1000 ENV WAYLAND_DISPLAY=wayland-0 \\ XDG_RUNTIME_DIR=/run/user/1000 USER ubuntu WORKDIR /home/ubuntu CMD firefox This will add PulseAudio support to the image, as well as to set it up to receive the PulseAudio socket that we will pass from the host to the container’s /run/user/1000/pulse/ directory at runtime. Note The ffmpeg package isn’t actually needed per se for video or audio support — however, it conveniently pulls in a number of common video and audio codecs that may be needed to play the video or audio streams from various websites. Rebuild the ff image with our updates: $ cd ~/containers/wg-build $ sudo docker compose build ff [+] Building ... =\u003e =\u003e naming to docker.io/library/my-ff =\u003e [build] resolving provenance for metadata file Then edit the ff service in our runtime compose file to add another volume mapping; this volume mapping will share the host’s PulseAudio socket with the container: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN sysctls: - net.ipv4.conf.all.src_valid_mark=1 volumes: - ./wg:/etc/wireguard ... ff: image: my-ff network_mode: 'service:wg' volumes: - $XDG_RUNTIME_DIR/pulse/native:/run/user/1000/pulse/native - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0 - ./ff:/home/ubuntu Mapping the PulseAudio socket file like this will allow the container to send sound to the host (through the host’s speakers) — and it will also allow the container to receive sound from the host (through the host’s microphone). Note This assumes you’re running PulseAudio on the host (and using the default PulseAudio configuration). If you’re doing something different, see the x11docker project wiki for other sound options. We don’t actually need to make any changes to the ff service to allow it to display video (it can already send video to the host’s Wayland-display socket). However, if we want to allow the container to receive video from the host’s webcam, we need to map the host’s /dev/video0 device to the same location in the container: # ~/containers/wg-network1/docker-compose.yml services: wg: image: procustodibus/wireguard cap_add: - NET_ADMIN sysctls: - net.ipv4.conf.all.src_valid_mark=1 volumes: - ./wg:/etc/wireguard ... ff: image: my-ff network_mode: 'service:wg' devices: - /dev/video0:/dev/video0 volumes: - $XDG_RUNTIME_DIR/pulse/native:/run/user/1000/pulse/native - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0 - ./ff:/home/ubuntu Now if we close any windows from the ff service that are running, and restart it, we should be able to use videoconferencing webapps in our isolated Firefox instance: $ cd ~/containers/wg-network1 $ sudo docker compose run -d ff [+] Running 1/1 ✔ Container wg-network1-wg-1 Running ... Lastly, here are a couple more environment variables for Firefox that you may find useful to set (either at runtime, or to bake into the container image itself): MOZ_CRASHREPORTER_DISABLE=1 This will suppress Firefox’s crash-reporter dialog when Firefox starts up after a crash. You won’t need this if Firefox never crashes — but if it does, you may end up in a doom loop of crash-reporter dialogs. This environment variable will break the loop. TZ=America/Los_Angeles This will set your timezone to US Pacific time. By default, web pages running in a containerized Firefox instance will not know what timezone the host is using — and will therefore display dates and times in GMT. If you want them to use your local timezone, set it with this environment variable. Also, the only font family built into the Firefox container will be Deja Vu — so you may also want to add some additional fonts to the container image: Noto This family is intended to provide a glyph for every Unicode character (which Firefox can use to avoid displaying “blank boxes” when a web page’s own font stack doesn’t include the glyphs for certain characters on a web page). The fonts-noto-* Debian packages will install it. Microsoft core fonts Many websites include at least one of these fonts in their font stack, expecting that these fonts will be installed on every computer. These fonts can be installed via the ttf-mscorefonts-installer Debian package — however, they won’t be installed unless you first accept a EULA (End User License Agreement). To accept the EULA programmatically, use the debconf-set-selections command to mark the EULA as accepted. And also, you may run across web pages that require WebGL support; the mesa-utils Debian package pulls in the necessary libraries for that. Note This does not actually enable hardware GPU access. To allow the container to access the host’s GPU, you’d also need to 1) map the host’s GPU devices (/dev/dri et al) into the container, 2) add the container’s ubuntu user to the render and video groups, and 3) install the same GPU drivers in the container that the host is using. See the x11docker project wiki for more information. The following version of the Firefox Dockerfile includes all these extras: # ~/containers/wg-build/ff/Dockerfile FROM ubuntu:24.04 ARG APT_GET=\"apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\" \\ DEBIAN_FRONTEND=noninteractive \\ DEBIAN_PRIORITY=critical ENV LANG=en_US RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install ca-certificates COPY conf/packages.mozilla.org.asc /etc/apt/keyrings/packages.mozilla.org.asc COPY conf/mozilla.list /etc/apt/sources.list.d/mozilla.list COPY conf/mozilla-pin /etc/apt/preferences.d/mozilla-pin RUN echo ttf-mscorefonts-installer msttcorefonts/accepted-mscorefonts-eula select true | \\ debconf-set-selections RUN ${APT_GET} update \u0026\u0026 ${APT_GET} install \\ ffmpeg \\ firefox \\ fonts-noto \\ fonts-noto-cjk \\ fonts-noto-color-emoji \\ libpulse0 \\ mesa-utils \\ ttf-mscorefonts-installer \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* RUN mkdir -p /run/user/1000/pulse \u0026\u0026 \\ chmod -R 700 /run/user/1000 \u0026\u0026 \\ chown -R 1000:1000 /run/user/1000 ENV MOZ_CRASHREPORTER_DISABLE=1 \\ TZ=America/Los_Angeles \\ WAYLAND_DISPLAY=wayland-0 \\ XDG_RUNTIME_DIR=/run/user/1000 USER ubuntu WORKDIR /home/ubuntu CMD firefox",
  "image": "https://www.procustodibus.com/app-containers.svg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"app\"\u003e\n        \n\u003carticle\u003e\n  \u003csection\u003e\n    \n    \u003cp\u003eRunning \u003ca href=\"https://www.wireguard.com/\"\u003eWireGuard\u003c/a\u003e in a \u003ca href=\"https://docs.docker.com/\"\u003eDocker\u003c/a\u003e container can be a convenient way to isolate a WireGuard network from the rest of a system. We’ve covered a variety of different patterns for \u003ca href=\"https://www.procustodibus.com/blog/2021/11/wireguard-containers/\"\u003eusing WireGuard in containers\u003c/a\u003e in the past; in this article we’ll dive deep into one particular pattern: using GUI (Graphical User Interface) Linux applications inside Docker containers to access remote sites through WireGuard.\u003c/p\u003e\n\u003cdiv\u003e\n\u003cfigure\u003e\n  \u003cpicture\u003e\n    \u003cimg src=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/app-containers.svg\" width=\"624\" height=\"351\" alt=\"Apps using WireGuard Docker containers\"/\u003e\n  \u003c/picture\u003e\n  \n\u003c/figure\u003e\n\n\u003c/div\u003e\n\u003cp\u003eWe’ll build on the core “\u003ca href=\"https://www.procustodibus.com/blog/2021/11/wireguard-containers/#use-for-container-network\"\u003eContainer Network\u003c/a\u003e” technique covered previously, where we use a shared network namespace to allow other containers to access the WireGuard network of a dedicated WireGuard container. In this case, we’ll build and run several custom containers with a couple of GUI applications, allowing their GUIs to be used seamlessly as part of the container host’s \u003ca href=\"https://wayland.freedesktop.org/\"\u003eWayland\u003c/a\u003e display — while still being able to access remote servers through the isolated WireGuard network of the WireGuard container.\u003c/p\u003e\n\u003cp\u003eWe’ll work our way up to running a full-fledged \u003ca href=\"https://mozilla.org/firefox\"\u003eFirefox\u003c/a\u003e browser with video and audio in a container to access an isolated WireGuard network, but first we’ll cover a number of intermediate steps before we get there:\u003c/p\u003e\n\u003cdiv\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eSet up our \u003ca href=\"#docker-projects\"\u003eDocker Projects\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSet up the \u003ca href=\"#wireguard-network\"\u003eWireGuard Network\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSet up a simple \u003ca href=\"#smb-client\"\u003eSMB Client\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSet up an \u003ca href=\"#ssh-client\"\u003eSSH Client\u003c/a\u003e with SSH-agent access\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSet up an \u003ca href=\"#rdp-client\"\u003eRDP Client\u003c/a\u003e with Wayland\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSet up a basic \u003ca href=\"#firefox-client\"\u003eFirefox Client\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eConfigure \u003ca href=\"#wireguard-internet-access\"\u003eWireGuard Internet Access\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUpdate \u003ca href=\"#firefox-with-video-audio\"\u003eFirefox With Video \u0026amp; Audio\u003c/a\u003e support\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAdd miscellaneous \u003ca href=\"#firefox-extras\"\u003eFirefox Extras\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"docker-projects\"\u003e\u003ca href=\"#docker-projects\"\u003e\u003c/a\u003eDocker Projects\u003c/h2\u003e\n\u003cdiv\u003e\n\n\u003cdiv\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e~/containers/wg-build/docker-compose.yml\u003c/code\u003e, to build the container images\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e, to run the containers\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\u003cp\u003eThe first project will contain the \u003ca href=\"https://docs.docker.com/reference/dockerfile/\"\u003eDockerfiles\u003c/a\u003e and (other miscellaneous files) that we need to build our custom container images; and the second project will contain the files and settings we use at runtime with our WireGuard network (such as the WireGuard configuration files, and the browser profile and cache content).\u003c/p\u003e\n\u003cp\u003eThis will allow us to use the second project as a template for other WireGuard networks that we might want to add in the future; for example, to add a new \u003ccode\u003e~/containers/wg-network-east\u003c/code\u003e project to access our Eastern datacenter, and a separate \u003ccode\u003e~/containers/wg-network-west\u003c/code\u003e project to access our Western datacenter.\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"wireguard-network\"\u003e\u003ca href=\"#wireguard-network\"\u003e\u003c/a\u003eWireGuard Network\u003c/h2\u003e\n\u003cdiv\u003e\n\n\u003cdiv\u003e\n\u003cfigure\u003e\n  \u003cpicture\u003e\n    \u003cimg src=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/app-containers-p2s.svg\" width=\"1091\" height=\"390\" alt=\"WireGuard point-to-site with containers\"/\u003e\n  \u003c/picture\u003e\n  \n\u003c/figure\u003e\n\n\u003c/div\u003e\n\u003cp\u003eAs shown by that guide, on the remote side of the connection (Host β), we’ll set up a WireGuard interface with the following configuration:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# /etc/wireguard/wg0.conf\n\n# local settings for Host β\n[Interface]\nPrivateKey = ABBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBFA=\nAddress = 10.0.0.2/32\nListenPort = 51822\n\n# IP forwarding\nPreUp = sysctl -w net.ipv4.ip_forward=1\n# IP masquerading\nPreUp = iptables -t mangle -A PREROUTING -i wg0 -j MARK --set-mark 0x30\nPreUp = iptables -t nat -A POSTROUTING ! -o wg0 -m mark --mark 0x30 -j MASQUERADE\nPostDown = iptables -t mangle -D PREROUTING -i wg0 -j MARK --set-mark 0x30\nPostDown = iptables -t nat -D POSTROUTING ! -o wg0 -m mark --mark 0x30 -j MASQUERADE\n\n# remote settings for Endpoint A\n[Peer]\nPublicKey = /TOE4TKtAqVsePRVR+5AA43HkAK5DSntkOCO7nYq5xU=\nAllowedIPs = 10.0.0.1/32\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eStart up this WireGuard interface on the remote host as shown in the guide (eg \u003ccode\u003esudo wg-quick up wg0\u003c/code\u003e ).\u003c/p\u003e\n\u003cp\u003eFor the local side of the connection (our personal laptop), we’ll use the configuration for Endpoint A from the guide, saving it as \u003ccode\u003e~/containers/wg-network1/wg/wg0.conf\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-network1/wg/wg0.conf\n\n# local settings for Endpoint A\n[Interface]\nPrivateKey = AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEE=\nAddress = 10.0.0.1/32\nListenPort = 51821\n\n# remote settings for Host β\n[Peer]\nPublicKey = fE/wdxzl0klVp/IR8UcaoGUMjqaWi3jAd7KzHKFS6Ds=\nEndpoint = 203.0.113.2:51822\nAllowedIPs = 192.168.200.0/24\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis WireGuard network will allow the local side of the connection access to the other servers in the \u003ccode\u003e192.168.200.0/24\u003c/code\u003e network address range at Site B.\u003c/p\u003e\n\u003cp\u003eTo run this connection in a Docker container, we’ll add a \u003ccode\u003ewg\u003c/code\u003e service to our runtime compose file at \u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    volumes:\n    - ./wg:/etc/wireguard\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThen we’ll start up the \u003ccode\u003ewg\u003c/code\u003e service:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ sudo docker compose up wg\n[+] Running 11/11\n ✔ wg Pulled ...\n[+] Running 1/1\n ✔ Container wg-network1-wg-1  Created ...\nAttaching to wg-1\nwg-1  |\nwg-1  |  * /proc is already mounted\nwg-1  |  * /run/lock: creating directory\nwg-1  |  * /run/lock: correcting owner\nwg-1  |    OpenRC 0.54 is starting up Linux 6.5.0-45-generic (x86_64) [DOCKER]\nwg-1  |\nwg-1  |  * Caching service dependencies ... [ ok ]\nwg-1  | [#] ip link add wg0 type wireguard\nwg-1  | [#] wg setconf wg0 /dev/fd/63\nwg-1  | [#] ip -4 address add 10.0.0.1/32 dev wg0\nwg-1  | [#] ip link set mtu 1420 up dev wg0\nwg-1  | [#] ip -4 route add 192.168.200.0/24 dev wg0\nwg-1  |  * Starting WireGuard interface wg0 ... [ ok ]\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe WireGuard connection from our local machine to Site B is now up and running inside the \u003ccode\u003ewg-network1-wg-1\u003c/code\u003e container.\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"smb-client\"\u003e\u003ca href=\"#smb-client\"\u003e\u003c/a\u003eSMB Client\u003c/h2\u003e\n\u003cdiv\u003e\n\u003cp\u003eAs the first step to using this WireGuard connection, we’ll set up a simple \u003ca href=\"https://learn.microsoft.com/en-us/windows/win32/fileio/microsoft-smb-protocol-and-cifs-protocol-overview\"\u003eSMB\u003c/a\u003e client, using the command-line \u003ca href=\"https://www.samba.org/samba/docs/current/man-html/smbclient.1.html\"\u003e\u003ccode\u003esmbclient\u003c/code\u003e\u003c/a\u003e program.\u003c/p\u003e\n\u003cp\u003eWe’ll build an image for this client with the following Dockerfile:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"dockerfile\"\u003e# ~/containers/wg-build/smb/Dockerfile\nFROM alpine:latest\n\nRUN apk add --no-cache \\\n    bash \\\n    samba-client\n\nRUN addgroup al \u0026amp;\u0026amp; adduser -D -G al al\n\nUSER al\nWORKDIR /home/al\nCMD bash\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe only thing notable about this image is that it creates and will use a custom user account — with a user ID of \u003ccode\u003e1000\u003c/code\u003e, to match the UID of our personal user on the container host — allowing us to avoid any file-ownership annoyances when sharing files between the container and the host.\u003c/p\u003e\n\u003cp\u003eSave this Dockerfile at \u003ccode\u003e~/containers/wg-build/smb/Dockerfile\u003c/code\u003e, then add a service for it to our build compose file at \u003ccode\u003e~/containers/wg-build/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-build/docker-compose.yml\nservices:\n  smb:\n    build: smb\n    image: my-smb\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd build the image:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-build\n$ sudo docker compose build smb\n[+] Building ...\n =\u0026gt; =\u0026gt; naming to docker.io/library/my-smb\n =\u0026gt; [build] resolving provenance for metadata file\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eNext, add a service for it to our runtime compose file at \u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    volumes:\n    - ./wg:/etc/wireguard\n  \u003cstrong\u003esmb:\n    image: my-smb\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - ./smb:/home/al\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis new \u003ccode\u003esmb\u003c/code\u003e service will use the \u003ccode\u003emy-smb\u003c/code\u003e image we just built, and it will share the \u003ccode\u003ewg\u003c/code\u003e service’s network namespace (so it can use the WireGuard interface) — plus it will mount the container host’s \u003ccode\u003e~/containers/wg-network1/smb/\u003c/code\u003e directory to the home directory of the custom user (\u003ccode\u003eal\u003c/code\u003e) within the container.\u003c/p\u003e\n\u003cp\u003eBefore using this container, create this \u003ccode\u003e~/containers/wg-network1/smb/\u003c/code\u003e mount point on the host:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ mkdir -p smb\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd if we had previously shut down the \u003ccode\u003ewg\u003c/code\u003e service, make sure to start it back up again:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ sudo docker compose up wg\n...\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThen (in a new terminal) run the \u003ccode\u003esmb\u003c/code\u003e service:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ sudo docker compose run smb\n[+] Running 1/0\n ✔ Container wg-network1-wg-1  Running ...\n2a04e264f1da:~$\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis will bring up a \u003ca href=\"https://www.gnu.org/software/bash/\"\u003eBash\u003c/a\u003e shell in the \u003ccode\u003ewg-network1-smb-1\u003c/code\u003e container. In this shell, we can use the SMB client to connect to an SMB server at the remote site through the WireGuard connection provided by the \u003ccode\u003ewg\u003c/code\u003e service:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e2a04e264f1da:~$ smbclient -U justin \u0026#39;\\\\192.168.200.33\\shares\u0026#39;\nPassword for [WORKGROUP\\justin]:\nTry \u0026#34;help\u0026#34; to get a list of possible commands.\nsmb: \\\u0026gt;\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eOr we can just use the WireGuard connection to ping a server at the remote site:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e2a04e264f1da:~$ ping -nc1 192.168.200.22\nPING 192.168.200.22 (192.168.200.22): 56 data bytes\n64 bytes from 192.168.200.22: seq=0 ttl=42 time=68.573 ms\n\n--- 192.168.200.22 ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 68.573/68.573/68.573 ms\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"ssh-client\"\u003e\u003ca href=\"#ssh-client\"\u003e\u003c/a\u003eSSH Client\u003c/h2\u003e\n\u003cdiv\u003e\n\u003cp\u003eAs the next step, we’ll set up an \u003ca href=\"https://man.openbsd.org/ssh.1\"\u003eSSH\u003c/a\u003e client in a container that can use this WireGuard network and still have access to the \u003ca href=\"https://man.openbsd.org/ssh-agent.1\"\u003eSSH agent\u003c/a\u003e on the container host. Having access to the host’s SSH agent will enable us to use any SSH keys stored on the host — or on a smart card attached to the host — that we’ve added to the SSH agent.\u003c/p\u003e\n\u003cp\u003eFor this step, we’ll again build a simple image for the client with a custom Dockerfile:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"dockerfile\"\u003e# ~/containers/wg-build/ssh/Dockerfile\nFROM alpine:latest\n\nRUN apk add --no-cache \\\n    bash \\\n    openssh-client\n\nRUN addgroup al \u0026amp;\u0026amp; adduser -D -G al al \u0026amp;\u0026amp; \\\n    mkdir -p /run/user/1000 \u0026amp;\u0026amp; \\\n    chmod -R 700 /run/user/1000 \u0026amp;\u0026amp; \\\n    chown -R 1000:1000 /run/user/1000\n\nENV SSH_AUTH_SOCK=/run/user/1000/ssh-agent\nUSER al\nWORKDIR /home/al\nCMD bash\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eIn this Dockerfile, however, after we create a user account with a UID of \u003ccode\u003e1000\u003c/code\u003e (\u003ccode\u003eal\u003c/code\u003e), we’ll also set up the standard \u003ccode\u003e/run/user/1000/\u003c/code\u003e runtime directory for user-owned socket files — and set the container’s \u003ccode\u003eSSH_AUTH_SOCK\u003c/code\u003e environment variable to point at a file in that directory. While nothing is in that directory at this point, later on (at runtime) we’ll map the host’s SSH-agent socket file into it at this specific path.\u003c/p\u003e\n\u003cp\u003eSave this Dockerfile at \u003ccode\u003e~/containers/wg-build/ssh/Dockerfile\u003c/code\u003e, then add a service for it to our build compose file at \u003ccode\u003e~/containers/wg-build/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-build/docker-compose.yml\nservices:\n  smb:\n    build: smb\n    image: my-smb\n  \u003cstrong\u003essh:\n    build: ssh\n    image: my-ssh\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd build the image:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-build\n$ sudo docker compose build ssh\n[+] Building ...\n =\u0026gt; =\u0026gt; naming to docker.io/library/my-ssh\n =\u0026gt; [build] resolving provenance for metadata file\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eNext, add a service for it to our runtime compose file at \u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    volumes:\n    - ./wg:/etc/wireguard\n  smb:\n    image: my-smb\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - ./smb:/home/al\n  \u003cstrong\u003essh:\n    image: my-ssh\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - $SSH_AUTH_SOCK:/run/user/1000/ssh-agent\n    - ./ssh:/home/al\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis service definition for the \u003ccode\u003essh\u003c/code\u003e service is similar to that of the \u003ca href=\"#smb-client\"\u003eSMB Client\u003c/a\u003e, except that we have added an additional volume. We use this additional volume definition to map our actual SSH-agent socket file on the host to the \u003ccode\u003e/run/user/1000/ssh-agent\u003c/code\u003e socket file referenced in the \u003ccode\u003emy-ssh\u003c/code\u003e image’s Dockerfile.\u003c/p\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNote\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eRun the following command in a terminal on the host to see where the SSH-agent socket file on your host lives:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e$ echo $SSH_AUTH_SOCK\n/run/user/1000/gnupg/S.gpg-agent.ssh\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eIf this environment variable is empty, you’re probably not running an SSH agent.\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003cp\u003eMapping the SSH-agent socket file like this enables us to use the SSH agent from the host inside the container.\u003c/p\u003e\n\u003cp\u003eNow we can start up the \u003ccode\u003essh\u003c/code\u003e service. Run the following commands (in a new terminal) to create the \u003ccode\u003e~/containers/wg-network1/ssh/\u003c/code\u003e mount point and start up an \u003ccode\u003essh\u003c/code\u003e container:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ mkdir -p ssh\n$ sudo docker compose run ssh\n[+] Running 1/0\n ✔ Container wg-network1-wg-1  Running ...\ncc574a6ef3af:~$\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis will bring up a Bash shell in a new \u003ccode\u003ewg-network1-ssh-1\u003c/code\u003e container. If we run the \u003ccode\u003essh-add -L\u003c/code\u003e command in this new container, we should see all the SSH keys that we’ve added to the SSH agent on the host:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003ecc574a6ef3af:~$ ssh-add -L\nsk-ssh-ed25519@openssh.com AAAAGnNrLXNzaC1lZDI1NTE5QG9wZW5zc2guY29tAAAAIO5k/uLhCT7OLR/S048kPicX6LQ9CUgJugjSjPxGq3XmAAAABHNzaDo= justin@myws\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd we should be able to use those SSH keys to SSH through WireGuard into any servers at Site B that accept them:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003ecc574a6ef3af:~$ ssh justin@192.168.200.22\nLast login: Tue Oct  1 18:07:25 2024 from 192.168.200.33\njustin@www:~$\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eNote that because we’ve mounted the host’s \u003ccode\u003e~/containers/wg-network1/ssh/\u003c/code\u003e directory to the \u003ccode\u003essh\u003c/code\u003e service’s \u003ccode\u003e/home/al/\u003c/code\u003e directory, we can use the host’s  \u003ccode\u003e~/containers/wg-network1/ssh/.ssh/\u003c/code\u003e subdirectory to configure SSH in the container. For example, if configure the \u003ccode\u003e~/containers/wg-network1/ssh/.ssh/config\u003c/code\u003e file like the following:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-network1/ssh/.ssh/config\nHost www-server\n    HostName 192.168.200.22\n    User justin\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThen in the \u003ccode\u003essh\u003c/code\u003e container, we can simply run the following command to SSH into the \u003ccode\u003e192.168.200.22\u003c/code\u003e host as the \u003ccode\u003ejustin\u003c/code\u003e user:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003ecc574a6ef3af:~$ ssh www-server\nLast login: Tue Oct  1 22:10:53 2024 from 192.168.200.2\njustin@www:~$\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"rdp-client\"\u003e\u003ca href=\"#rdp-client\"\u003e\u003c/a\u003eRDP Client\u003c/h2\u003e\n\u003cdiv\u003e\n\u003cp\u003eNow we’re ready to set up our first GUI app in a Docker container. For this step, we’ll set up \u003ca href=\"https://remmina.org/\"\u003eRemmina\u003c/a\u003e, which provides a GUI for connecting to a remote server over \u003ca href=\"https://learn.microsoft.com/en-us/windows/win32/termserv/remote-desktop-protocol\"\u003eRDP\u003c/a\u003e. To enable the Remmina GUI to work, we’ll need to use the same trick that we used above to pass the host’s SSH-agent socket to the \u003ca href=\"#ssh-client\"\u003eSSH Client\u003c/a\u003e — but this time we’ll need to pass the host’s Wayland-display socket.\u003c/p\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNote\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eThis guide assumes you’re running Wayland on the host. If you are instead using \u003ca href=\"https://www.x.org/\"\u003eX11\u003c/a\u003e, the same principle applies, but with a few different settings. See the \u003ca href=\"https://github.com/mviereck/x11docker/wiki/Short-setups-to-provide-X-display-to-container\"\u003ex11docker project wiki\u003c/a\u003e for more information.\u003c/p\u003e\n\u003cp\u003eIf you’re unsure as to whether or not you’re running Wayland, run the following command on the host:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e$ echo $WAYLAND_DISPLAY\nwayland-1\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eIf this environment variable is empty, you’re probably not running Wayland.\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003cp\u003eFor this step, we’ll build an image for Remmina (and its RDP plugin) using a custom Dockerfile:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"dockerfile\"\u003e# ~/containers/wg-build/rdp/Dockerfile\nFROM ubuntu:22.04\n\nARG APT_GET=\u0026#34;apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\u0026#34; \\\n    DEBIAN_FRONTEND=noninteractive \\\n    DEBIAN_PRIORITY=critical\nENV LANG=en_US\n\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install \\\n    remmina \\\n    remmina-plugin-rdp \\\n    \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/*\n\nRUN adduser ubuntu \u0026amp;\u0026amp; \\\n    mkdir -p /run/user/1000 \u0026amp;\u0026amp; \\\n    chmod -R 700 /run/user/1000 \u0026amp;\u0026amp; \\\n    chown -R 1000:1000 /run/user/1000\n\nENV WAYLAND_DISPLAY=wayland-0 \\\n    XDG_RUNTIME_DIR=/run/user/1000\nUSER ubuntu\nWORKDIR /home/ubuntu\nCMD remmina\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eLike with the Dockerfile from the \u003ca href=\"#ssh-client\"\u003eSSH Client\u003c/a\u003e, after we create a user account with a UID of \u003ccode\u003e1000\u003c/code\u003e (this time named \u003ccode\u003eubuntu\u003c/code\u003e), we’ll also set up the standard \u003ccode\u003e/run/user/1000/\u003c/code\u003e runtime directory for user-owned socket files. In this Dockerfile, however, we’ll set the container’s \u003ccode\u003eXDG_RUNTIME_DIR\u003c/code\u003e environment variable to point to that directory; and we’ll also set the container’s \u003ccode\u003eWAYLAND_DISPLAY\u003c/code\u003e environment variable. Together, they’ll signal to programs running in the container that they can use a socket file at \u003ccode\u003e/run/user/1000/wayland-0\u003c/code\u003e in the container to connect to Wayland.\u003c/p\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNote\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\nThe version of Remmina packaged with Ubuntu 24.04 seems to work only with X11 — so we’re deliberately using Ubuntu 22.04 as the base image for this Dockerfile, as its \u003ccode\u003eremmina\u003c/code\u003e package works nicely with Wayland.\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003cp\u003eSave this Dockerfile at \u003ccode\u003e~/containers/wg-build/rdp/Dockerfile\u003c/code\u003e, then add a service for it to our build compose file at \u003ccode\u003e~/containers/wg-build/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-build/docker-compose.yml\nservices:\n...\n  ssh:\n    build: ssh\n    image: my-ssh\n  \u003cstrong\u003erdp:\n    build: rdp\n    image: my-rdp\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd build the image:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-build\n$ sudo docker compose build rdp\n[+] Building ...\n =\u0026gt; =\u0026gt; naming to docker.io/library/my-rdp\n =\u0026gt; [build] resolving provenance for metadata file\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eNext, add a service for it to our runtime compose file at \u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    volumes:\n    - ./wg:/etc/wireguard\n...\n  ssh:\n    image: my-ssh\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - $SSH_AUTH_SOCK:/run/user/1000/ssh-agent\n    - ./ssh:/home/al\n  \u003cstrong\u003erdp:\n    image: my-rdp\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0\n    - ./rdp:/home/ubuntu\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eLike the \u003ca href=\"#ssh-client\"\u003eSSH Client\u003c/a\u003e, we use the \u003ccode\u003erdp\u003c/code\u003e service definition to map a socket file from the host into a container. With the \u003ccode\u003erdp\u003c/code\u003e service, however, we’re mapping the Wayland-display socket file; which we map from the host to the container’s \u003ccode\u003e/run/user/1000/wayland-0\u003c/code\u003e path. Mapping the Wayland-display socket file like this enables Remmina, running in the container, to interact with our Wayland display, running on the host.\u003c/p\u003e\n\u003cp\u003eIf we now run the \u003ccode\u003erdp\u003c/code\u003e service in a new terminal, this will start up Remmina, and open up its main window in the host’s Wayland display:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ mkdir -p rdp\n$ sudo docker compose run rdp\n...\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eWhich allows us to use Remmina’s GUI to RDP through WireGuard to a server in Site B:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cfigure\u003e\n  \u003cpicture\u003e\n    \u003csource srcset=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/remmina-gui_huc8a806a88988ce033bfd062df211af3b_11304_400x250_fit_box_3.png\" width=\"400\" height=\"91\" media=\"(max-width: 768px)\"/\u003e\n    \u003cimg src=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/remmina-gui_huc8a806a88988ce033bfd062df211af3b_11304_800x500_fit_box_3.png\" width=\"741\" height=\"169\" alt=\"Remmina accessing a remote site\"/\u003e\n  \u003c/picture\u003e\n  \n\u003c/figure\u003e\n\n\u003c/div\u003e\n\u003cp\u003eAnd because we mapped the host’s \u003ccode\u003e~/containers/wg-network1/rdp\u003c/code\u003e directory to the home directory of the container’s user, all the container’s Remmina preferences (and cache data) are stored there:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ tree -a ~/containers/wg-network1/rdp\n/home/justin/containers/wg-network1/rdp\n├── .cache\n│   ├── org.remmina.Remmina\n│   │   └── latest_news.md\n│   └── remmina\n│       ├── group_rdp_shares_192-168-200-33.remmina.state\n│       └── remmina.pref.state\n├── .config\n│   ├── freerdp\n│   │   ├── certs\n│   │   ├── known_hosts2\n│   │   └── server\n│   ├── gtk-3.0\n│   └── remmina\n│       └── remmina.pref\n└── .local\n    └── share\n        ├── recently-used.xbel\n        └── remmina\n            └── group_rdp_shares_192-168-200-33.remmina\n\n13 directories, 7 files\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"firefox-client\"\u003e\u003ca href=\"#firefox-client\"\u003e\u003c/a\u003eFirefox Client\u003c/h2\u003e\n\u003cdiv\u003e\n\u003cp\u003eNow we’re ready to set up Firefox in a Docker container. Just like with the \u003ca href=\"#rdp-client\"\u003eRDP Client\u003c/a\u003e above, we’ll pass the host’s Wayland-display socket to the container through a volume mount point, allowing Firefox, running in a container, to use the host’s display.\u003c/p\u003e\n\u003cp\u003eAnd like with the \u003ca href=\"#rdp-client\"\u003eRDP Client\u003c/a\u003e, we’ll also build a Docker image for Firefox with a custom Dockerfile:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"dockerfile\"\u003e# ~/containers/wg-build/ff/Dockerfile\nFROM ubuntu:24.04\n\nARG APT_GET=\u0026#34;apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\u0026#34; \\\n    DEBIAN_FRONTEND=noninteractive \\\n    DEBIAN_PRIORITY=critical\nENV LANG=en_US\n\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install ca-certificates\nCOPY conf/packages.mozilla.org.asc /etc/apt/keyrings/packages.mozilla.org.asc\nCOPY conf/mozilla.list /etc/apt/sources.list.d/mozilla.list\nCOPY conf/mozilla-pin /etc/apt/preferences.d/mozilla-pin\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install \\\n    firefox \\\n    \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/*\n\nRUN mkdir -p /run/user/1000 \u0026amp;\u0026amp; \\\n    chmod -R 700 /run/user/1000 \u0026amp;\u0026amp; \\\n    chown -R 1000:1000 /run/user/1000\n\nENV WAYLAND_DISPLAY=wayland-0 \\\n    XDG_RUNTIME_DIR=/run/user/1000\nUSER ubuntu\nWORKDIR /home/ubuntu\nCMD firefox\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis Dockerfile is quite similar to the one for the \u003ca href=\"#rdp-client\"\u003eRDP Client\u003c/a\u003e, differing only in that:\u003c/p\u003e\n\u003cdiv\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eWe use the latest Ubuntu LTS (24.04)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe \u003ca href=\"https://support.mozilla.org/kb/install-firefox-linux\"\u003eadd the Mozilla repositories\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe install the \u003ccode\u003efirefox\u003c/code\u003e package instead of the \u003ccode\u003eremmina\u003c/code\u003e packages\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e\n\u003cp\u003eWe add the Mozilla repositories to avoid the \u003ca href=\"https://snapcraft.io/\"\u003eSnapcraft\u003c/a\u003e packages used by default in Ubuntu for Firefox. Save the configuration files needed for the Mozilla repositories in the \u003ccode\u003e~/containers/wg-build/ff/conf/\u003c/code\u003e directory:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-build/ff/conf/packages.mozilla.org.asc\n-----BEGIN PGP PUBLIC KEY BLOCK-----\n\nxsBNBGCRt7MBCADkYJHHQQoL6tKrW/LbmfR9ljz7ib2aWno4JO3VKQvLwjyUMPpq\n/SXXMOnx8jXwgWizpPxQYDRJ0SQXS9ULJ1hXRL/OgMnZAYvYDeV2jBnKsAIEdiG/\ne1qm8P4W9qpWJc+hNq7FOT13RzGWRx57SdLWSXo0KeY38r9lvjjOmT/cuOcmjwlD\nT9XYf/RSO+yJ/AsyMdAr+ZbDeQUd9HYJiPdI04lGaGM02MjDMnx+monc+y54t+Z+\nry1WtQdzoQt9dHlIPlV1tR+xV5DHHsejCZxu9TWzzSlL5wfBBeEz7R/OIzivGJpW\nQdJzd+2QDXSRg9q2XYWP5ZVtSgjVVJjNlb6ZABEBAAHNVEFydGlmYWN0IFJlZ2lz\ndHJ5IFJlcG9zaXRvcnkgU2lnbmVyIDxhcnRpZmFjdC1yZWdpc3RyeS1yZXBvc2l0\nb3J5LXNpZ25lckBnb29nbGUuY29tPsLAjgQTAQoAOBYhBDW6oLM+nrOW9ZyoOMC6\nXObcYxWjBQJgkbezAhsDBQsJCAcCBhUKCQgLAgQWAgMBAh4BAheAAAoJEMC6XObc\nYxWj+igIAMFh6DrAYMeq9sbZ1ZG6oAMrinUheGQbEqe76nIDQNsZnhDwZ2wWqgVC\n7DgOMqlhQmOmzm7M6Nzmq2dvPwq3xC2OeI9fQyzjT72deBTzLP7PJok9PJFOMdLf\nILSsUnmMsheQt4DUO0jYAX2KUuWOIXXJaZ319QyoRNBPYa5qz7qXS7wHLOY89IDq\nfHt6Aud8ER5zhyOyhytcYMeaGC1g1IKWmgewnhEq02FantMJGlmmFi2eA0EPD02G\nC3742QGqRxLwjWsm5/TpyuU24EYKRGCRm7QdVIo3ugFSetKrn0byOxWGBvtu4fH8\nXWvZkRT+u+yzH1s5yFYBqc2JTrrJvRU=\n=QnvN\n-----END PGP PUBLIC KEY BLOCK-----\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-build/ff/conf/mozilla.list\ndeb [signed-by=/etc/apt/keyrings/packages.mozilla.org.asc] https://packages.mozilla.org/apt mozilla main\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-build/ff/conf/mozilla-pin\nPackage: *\nPin: origin packages.mozilla.org\nPin-Priority: 1000\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd add a service to build the Dockerfile to our build compose file at \u003ccode\u003e~/containers/wg-build/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-build/docker-compose.yml\nservices:\n...\n  rdp:\n    build: rdp\n    image: my-rdp\n  \u003cstrong\u003eff:\n    build: ff\n    image: my-ff\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThen build the image:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-build\n$ sudo docker compose build ff\n[+] Building ...\n =\u0026gt; =\u0026gt; naming to docker.io/library/my-ff\n =\u0026gt; [build] resolving provenance for metadata file\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eNext, add a service for it to our runtime compose file at \u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    volumes:\n    - ./wg:/etc/wireguard\n...\n  rdp:\n    image: my-rdp\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0\n    - ./rdp:/home/ubuntu\n  \u003cstrong\u003eff:\n    image: my-ff\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0\n    - ./ff:/home/ubuntu\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe service definition for Firefox is almost exactly the same as the \u003ca href=\"#rdp-client\"\u003eRDP Client\u003c/a\u003e — all that’s different is we’re using the \u003ccode\u003emy-ff\u003c/code\u003e image, and we’re mapping the home folder of container’s \u003ccode\u003eubuntu\u003c/code\u003e user to the host’s \u003ccode\u003eff/\u003c/code\u003e directory.\u003c/p\u003e\n\u003cp\u003eIf we run the \u003ccode\u003eff\u003c/code\u003e service in a new terminal, this will start up Firefox, and open up a new browser window in our Wayland display:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ mkdir -p ff\n$ sudo docker compose run ff\n...\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eWe can then browse any private webservers running in Site B, using the \u003ccode\u003ewg\u003c/code\u003e service’s WireGuard connection:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cfigure\u003e\n  \u003cpicture\u003e\n    \u003csource srcset=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/ff-site-b_hu7b506df152df5a710211e65326847bda_19524_400x250_fit_box_3.png\" width=\"400\" height=\"141\" media=\"(max-width: 768px)\"/\u003e\n    \u003cimg src=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/ff-site-b_hu7b506df152df5a710211e65326847bda_19524_800x500_fit_box_3.png\" width=\"632\" height=\"223\" alt=\"Firefox accessing a remote site\"/\u003e\n  \u003c/picture\u003e\n  \n\u003c/figure\u003e\n\n\u003c/div\u003e\n\u003cp\u003eAll the profile settings and other data for this Firefox instance will be stored in the \u003ccode\u003e*.default-release/\u003c/code\u003e subdirectory of the host’s \u003ccode\u003e~/containers/wg-network1/ff/.mozilla/firefox/\u003c/code\u003e directory. The prefix for this subdirectory is generated randomly when Firefox creates the profile; in this example, the subdirectory is \u003ccode\u003emrnlwsve.default-release/\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ ls -1 ~/containers/wg-network1/ff/.mozilla/firefox\n6wjegbdk.default\n\u0026#39;Crash Reports\u0026#39;\ninstalls.ini\nmrnlwsve.default-release\n\u0026#39;Pending Pings\u0026#39;\nprofiles.ini\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"wireguard-internet-access\"\u003e\u003ca href=\"#wireguard-internet-access\"\u003e\u003c/a\u003eWireGuard Internet Access\u003c/h2\u003e\n\u003cdiv\u003e\n\u003cp\u003eIf we want to use the \u003ca href=\"#firefox-client\"\u003eFirefox Client\u003c/a\u003e to access any server on the Internet through its WireGuard connection (instead of merely any server in Site B), we need to make a couple of changes to the local side of the \u003ca href=\"#wireguard-network\"\u003eWireGuard Network\u003c/a\u003e we set up above.\u003c/p\u003e\n\u003cp\u003eFirst, we need to change the \u003ccode\u003eAllowedIPs\u003c/code\u003e setting in our local WireGuard configuration at \u003ccode\u003e~/containers/wg-network1/wg/wg0.conf\u003c/code\u003e to send all IPv4 traffic (\u003ccode\u003e0.0.0.0/0\u003c/code\u003e) through the WireGuard connection:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-network1/wg/wg0.conf\n\n# local settings for Endpoint A\n[Interface]\nPrivateKey = AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEE=\nAddress = 10.0.0.1/32\nListenPort = 51821\n\u003cstrong\u003eDNS = 9.9.9.9\u003c/strong\u003e\n\n# remote settings for Host β\n[Peer]\nPublicKey = fE/wdxzl0klVp/IR8UcaoGUMjqaWi3jAd7KzHKFS6Ds=\nEndpoint = 203.0.113.2:51822\nAllowedIPs = \u003cstrong\u003e0.0.0.0/0\u003c/strong\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd if we also want to send all DNS traffic through the WireGuard connection, we’ll also need to add a \u003ccode\u003eDNS\u003c/code\u003e setting to it, configuring it to use a DNS server available from the remote side of the connection (like the \u003ccode\u003e9.9.9.9\u003c/code\u003e \u003ca href=\"https://quad9.net/\"\u003eQuad9\u003c/a\u003e DNS server).\u003c/p\u003e\n\u003cp\u003eNext, we need to turn on the \u003ccode\u003enet.ipv4.conf.all.src_valid_mark\u003c/code\u003e kernel parameter for the \u003ccode\u003ewg\u003c/code\u003e service (otherwise the WireGuard startup script run inside the container will fail):\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    \u003cstrong\u003esysctls:\n    - net.ipv4.conf.all.src_valid_mark=1\u003c/strong\u003e\n    volumes:\n    - ./wg:/etc/wireguard\n...\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eAfter making those changes, close all the windows of the GUI apps that are using the \u003ccode\u003ewg\u003c/code\u003e service’s network namespace, and shut down all the services of the runtime compose file; then start them up again:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ sudo docker compose down\n[+] Running 2/2\n ✔ Container wg-network1-wg-1  Removed ...\n ✔ Network wg-network1         Removed ...\n$ sudo docker compose up -d wg\n[+] Running 2/2\n ✔ Network wg-network1         Created ...\n ✔ Container wg-network1-wg-1  Created ...\n$ sudo docker compose run -d ff\n[+] Running 1/1\n ✔ Container wg-network1-wg-1  Running ...\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThe WireGuard container — and all the other containers defined by the \u003ccode\u003e~/containers/wg-network1/docker-compose.yml\u003c/code\u003e file to share the same network namespace — will now send all its IPv4 Internet traffic and DNS queries through Host β at the remote site:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cfigure\u003e\n  \u003cpicture\u003e\n    \u003csource srcset=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/ff-ifconfig-me_hue5b4957c71274fc99a69c5e03d7cbe11_42234_400x250_fit_box_3.png\" width=\"400\" height=\"238\" media=\"(max-width: 768px)\"/\u003e\n    \u003cimg src=\"https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/img/ff-ifconfig-me_hue5b4957c71274fc99a69c5e03d7cbe11_42234_800x500_fit_box_3.png\" width=\"632\" height=\"376\" alt=\"Firefox accessing an Internet site\"/\u003e\n  \u003c/picture\u003e\n  \n\u003c/figure\u003e\n\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eTip\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eIf you’re having trouble accessing the Internet, make sure you’ve configured the firewall on the remote side of the WireGuard connection (Host β) to masquerade WireGuard traffic, as well as to allow all traffic forwarded from the WireGuard interface to go out through its Internet-facing network interface.\u003c/p\u003e\n\n\u003cp\u003eOtherwise, if you’re using an \u003ca href=\"https://netfilter.org/projects/iptables/\"\u003eiptables\u003c/a\u003e-based firewall on the remote host (with firewall rules similar to those shown in the \u003ca href=\"https://www.procustodibus.com/blog/2020/11/wireguard-point-to-site-config/#extra-configure-firewall-on-host-b\"\u003eConfigure Firewall on Host β\u003c/a\u003e section of the \u003ca href=\"https://www.procustodibus.com/blog/2020/11/wireguard-point-to-site-config/\"\u003eWireGuard Point to Site Configuration\u003c/a\u003e guide), make sure you include a rule like the following in the host’s \u003ccode\u003eFORWARD\u003c/code\u003e chain, before any \u003ccode\u003eDROP\u003c/code\u003e or \u003ccode\u003eREJECT\u003c/code\u003e rules (where \u003ccode\u003eeth0\u003c/code\u003e is the name of the Internet-facing network interface):\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003eiptables -A FORWARD -i wg0 -o eth0 -j ACCEPT\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eOr if you’re using an \u003ca href=\"https://netfilter.org/projects/nftables/\"\u003enftables\u003c/a\u003e-based firewall on the remote host (with firewall rules similar to those shown in the \u003ca href=\"https://www.procustodibus.com/blog/2021/11/wireguard-nftables/#point-to-site\"\u003ePoint to Site\u003c/a\u003e section of the \u003ca href=\"https://www.procustodibus.com/blog/2021/11/wireguard-nftables/\"\u003eWireGuard Nftables Configuration\u003c/a\u003e guide), make sure you include a rule like the following in the host’s \u003ccode\u003eforward\u003c/code\u003e chain, before any \u003ccode\u003edrop\u003c/code\u003e or \u003ccode\u003ereject\u003c/code\u003e rules (where \u003ccode\u003eeth0\u003c/code\u003e is the name of the Internet-facing network interface):\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003eiifname wg0 oifname eth0 accept\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003ch2 id=\"firefox-with-video-audio\"\u003e\u003ca href=\"#firefox-with-video-audio\"\u003e\u003c/a\u003eFirefox With Video \u0026amp; Audio\u003c/h2\u003e\n\u003cdiv\u003e\n\u003cp\u003eIf we want our containerized Firefox to play audio — plus be able to transmit audio and video from the host (so that, for example, we can use a videoconferencing webapp) — we need to add a few more packages to our custom Firefox container image, as well as to pass \u003ca href=\"https://www.freedesktop.org/wiki/Software/PulseAudio/\"\u003ePulseAudio\u003c/a\u003e‘s socket to the Firefox container at runtime.\u003c/p\u003e\n\u003cp\u003eFirst, edit the Dockerfile for the \u003ca href=\"#firefox-client\"\u003eFirefox Client\u003c/a\u003e to add the \u003ccode\u003effmpeg\u003c/code\u003e and \u003ccode\u003elibpulse0\u003c/code\u003e packages to it; and also to change the \u003ccode\u003emkdir\u003c/code\u003e command that creates the \u003ccode\u003e/run/user/1000/\u003c/code\u003e directory to simultaneously create the \u003ccode\u003e/run/user/1000/pulse/\u003c/code\u003e subdirectory:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-build/ff/Dockerfile\nFROM ubuntu:24.04\n\nARG APT_GET=\u0026#34;apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\u0026#34; \\\n    DEBIAN_FRONTEND=noninteractive \\\n    DEBIAN_PRIORITY=critical\nENV LANG=en_US\n\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install ca-certificates\nCOPY conf/packages.mozilla.org.asc /etc/apt/keyrings/packages.mozilla.org.asc\nCOPY conf/mozilla.list /etc/apt/sources.list.d/mozilla.list\nCOPY conf/mozilla-pin /etc/apt/preferences.d/mozilla-pin\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install \\\n    \u003cstrong\u003effmpeg \\\u003c/strong\u003e\n    firefox \\\n    \u003cstrong\u003elibpulse0 \\\u003c/strong\u003e\n    \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/*\n\nRUN mkdir -p \u003cstrong\u003e/run/user/1000/pulse\u003c/strong\u003e \u0026amp;\u0026amp; \\\n    chmod -R 700 /run/user/1000 \u0026amp;\u0026amp; \\\n    chown -R 1000:1000 /run/user/1000\n\nENV WAYLAND_DISPLAY=wayland-0 \\\n    XDG_RUNTIME_DIR=/run/user/1000\nUSER ubuntu\nWORKDIR /home/ubuntu\nCMD firefox\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThis will add PulseAudio support to the image, as well as to set it up to receive the PulseAudio socket that we will pass from the host to the container’s \u003ccode\u003e/run/user/1000/pulse/\u003c/code\u003e directory at runtime.\u003c/p\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNote\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\nThe \u003ccode\u003effmpeg\u003c/code\u003e package isn’t actually needed per se for video or audio support — however, it conveniently pulls in a number of common video and audio codecs that may be needed to play the video or audio streams from various websites.\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003cp\u003eRebuild the \u003ccode\u003eff\u003c/code\u003e image with our updates:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-build\n$ sudo docker compose build ff\n[+] Building ...\n =\u0026gt; =\u0026gt; naming to docker.io/library/my-ff\n =\u0026gt; [build] resolving provenance for metadata file\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eThen edit the \u003ccode\u003eff\u003c/code\u003e service in our runtime compose file to add another volume mapping; this volume mapping will share the host’s PulseAudio socket with the container:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    sysctls:\n    - net.ipv4.conf.all.src_valid_mark=1\n    volumes:\n    - ./wg:/etc/wireguard\n...\n  ff:\n    image: my-ff\n    network_mode: \u0026#39;service:wg\u0026#39;\n    volumes:\n    \u003cstrong\u003e- $XDG_RUNTIME_DIR/pulse/native:/run/user/1000/pulse/native\u003c/strong\u003e\n    - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0\n    - ./ff:/home/ubuntu\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eMapping the PulseAudio socket file like this will allow the container to send sound to the host (through the host’s speakers) — and it will also allow the container to \u003cem\u003ereceive\u003c/em\u003e sound \u003cem\u003efrom\u003c/em\u003e the host (through the host’s microphone).\u003c/p\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNote\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\nThis assumes you’re running PulseAudio on the host (and using the default PulseAudio configuration). If you’re doing something different, see the \u003ca href=\"https://github.com/mviereck/x11docker/wiki/Container-sound:-ALSA-or-Pulseaudio\"\u003ex11docker project wiki\u003c/a\u003e for other sound options.\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003cp\u003eWe don’t actually need to make any changes to the \u003ccode\u003eff\u003c/code\u003e service to allow it to display video (it can already \u003cem\u003esend\u003c/em\u003e video to the host’s Wayland-display socket). However, if we want to allow the container to \u003cem\u003ereceive\u003c/em\u003e video from the host’s webcam, we need to map the host’s \u003ccode\u003e/dev/video0\u003c/code\u003e device to the same location in the container:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e# ~/containers/wg-network1/docker-compose.yml\nservices:\n  wg:\n    image: procustodibus/wireguard\n    cap_add:\n    - NET_ADMIN\n    sysctls:\n    - net.ipv4.conf.all.src_valid_mark=1\n    volumes:\n    - ./wg:/etc/wireguard\n...\n  ff:\n    image: my-ff\n    network_mode: \u0026#39;service:wg\u0026#39;\n    \u003cstrong\u003edevices:\n    - /dev/video0:/dev/video0\u003c/strong\u003e\n    volumes:\n    - $XDG_RUNTIME_DIR/pulse/native:/run/user/1000/pulse/native\n    - $XDG_RUNTIME_DIR/$WAYLAND_DISPLAY:/run/user/1000/wayland-0\n    - ./ff:/home/ubuntu\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003cp\u003eNow if we close any windows from the \u003ccode\u003eff\u003c/code\u003e service that are running, and restart it, we should be able to use videoconferencing webapps in our isolated Firefox instance:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e$ cd ~/containers/wg-network1\n$ sudo docker compose run -d ff\n[+] Running 1/1\n ✔ Container wg-network1-wg-1  Running ...\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv\u003e\n\u003cp\u003eLastly, here are a couple more environment variables for Firefox that you may find useful to set (either at runtime, or to bake into the container image itself):\u003c/p\u003e\n\u003cdiv\u003e\n\u003cdl\u003e\n\u003cdt\u003e\u003ccode\u003eMOZ_CRASHREPORTER_DISABLE=1\u003c/code\u003e\u003c/dt\u003e\n\u003cdd\u003e\n\u003cp\u003eThis will suppress Firefox’s crash-reporter dialog when Firefox starts up after a crash. You won’t need this if Firefox never crashes — but if it does, you may end up in a doom loop of crash-reporter dialogs. This environment variable will break the loop.\u003c/p\u003e\n\u003c/dd\u003e\n\u003cdt\u003e\u003ccode\u003eTZ=America/Los_Angeles\u003c/code\u003e\u003c/dt\u003e\n\u003cdd\u003e\n\u003cp\u003eThis will set your timezone to US Pacific time. By default, web pages running in a containerized Firefox instance will not know what timezone the host is using — and will therefore display dates and times in \u003ca href=\"https://www.timeanddate.com/time/zones/gmt\"\u003eGMT\u003c/a\u003e. If you want them to use your \u003ca href=\"https://twiki.org/cgi-bin/xtra/tzdatepick.html\"\u003elocal timezone\u003c/a\u003e, set it with this environment variable.\u003c/p\u003e\n\u003c/dd\u003e\n\u003c/dl\u003e\n\u003c/div\u003e\n\u003cp\u003eAlso, the only font family built into the Firefox container will be \u003ca href=\"https://dejavu-fonts.github.io/\"\u003eDeja Vu\u003c/a\u003e — so you may also want to add some additional fonts to the container image:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cdl\u003e\n\u003cdt\u003e\u003ca href=\"https://notofonts.github.io/noto-docs/website/homepage/\"\u003eNoto\u003c/a\u003e\u003c/dt\u003e\n\u003cdd\u003e\n\u003cp\u003eThis family is intended to provide a glyph for every Unicode character (which Firefox can use to avoid displaying “blank boxes” when a web page’s own font stack doesn’t include the glyphs for certain characters on a web page). The \u003ccode\u003efonts-noto-*\u003c/code\u003e Debian packages will install it.\u003c/p\u003e\n\u003c/dd\u003e\n\u003cdt\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Core_fonts_for_the_Web\"\u003eMicrosoft core fonts\u003c/a\u003e\u003c/dt\u003e\n\u003cdd\u003e\n\u003cp\u003eMany websites include at least one of these fonts in their font stack, expecting that these fonts will be installed on every computer. These fonts can be installed via the \u003ccode\u003ettf-mscorefonts-installer\u003c/code\u003e Debian package — however, they won’t be installed unless you first accept a EULA (End User License Agreement). To accept the EULA programmatically, use the \u003ca href=\"https://manpages.debian.org/bookworm/debconf/debconf-set-selections.1.en.html\"\u003e\u003ccode\u003edebconf-set-selections\u003c/code\u003e\u003c/a\u003e command to \u003ca href=\"https://askubuntu.com/a/25614/66329\"\u003emark the EULA as accepted\u003c/a\u003e.\u003c/p\u003e\n\u003c/dd\u003e\n\u003c/dl\u003e\n\u003c/div\u003e\n\u003cp\u003eAnd also, you may run across web pages that require \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API\"\u003eWebGL\u003c/a\u003e support; the \u003ccode\u003emesa-utils\u003c/code\u003e Debian package pulls in the necessary libraries for that.\u003c/p\u003e\n\u003cdiv\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eNote\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\nThis does not actually enable hardware GPU access. To allow the container to access the host’s GPU, you’d also need to 1) map the host’s GPU devices (\u003ccode\u003e/dev/dri\u003c/code\u003e et al) into the container, 2) add the container’s \u003ccode\u003eubuntu\u003c/code\u003e user to the \u003ccode\u003erender\u003c/code\u003e and \u003ccode\u003evideo\u003c/code\u003e groups, and 3) install the same GPU drivers in the container that the host is using. See the \u003ca href=\"https://github.com/mviereck/x11docker/wiki/Hardware-acceleration\"\u003ex11docker project wiki\u003c/a\u003e for more information.\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003cp\u003eThe following version of the Firefox Dockerfile includes all these extras:\u003c/p\u003e\n\u003cdiv\u003e\n\u003cpre\u003e\u003ccode\u003e# ~/containers/wg-build/ff/Dockerfile\nFROM ubuntu:24.04\n\nARG APT_GET=\u0026#34;apt-get -qq -o=Dpkg::Use-Pty=0 --no-install-recommends\u0026#34; \\\n    DEBIAN_FRONTEND=noninteractive \\\n    DEBIAN_PRIORITY=critical\nENV LANG=en_US\n\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install ca-certificates\nCOPY conf/packages.mozilla.org.asc /etc/apt/keyrings/packages.mozilla.org.asc\nCOPY conf/mozilla.list /etc/apt/sources.list.d/mozilla.list\nCOPY conf/mozilla-pin /etc/apt/preferences.d/mozilla-pin\n\u003cstrong\u003eRUN echo ttf-mscorefonts-installer msttcorefonts/accepted-mscorefonts-eula select true | \\\n    debconf-set-selections\u003c/strong\u003e\nRUN ${APT_GET} update \u0026amp;\u0026amp; ${APT_GET} install \\\n    ffmpeg \\\n    firefox \\\n    \u003cstrong\u003efonts-noto \\\n    fonts-noto-cjk \\\n    fonts-noto-color-emoji \\\u003c/strong\u003e\n    libpulse0 \\\n    \u003cstrong\u003emesa-utils \\\n    ttf-mscorefonts-installer \\\u003c/strong\u003e\n    \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/*\n\nRUN mkdir -p /run/user/1000/pulse \u0026amp;\u0026amp; \\\n    chmod -R 700 /run/user/1000 \u0026amp;\u0026amp; \\\n    chown -R 1000:1000 /run/user/1000\n\nENV \u003cstrong\u003eMOZ_CRASHREPORTER_DISABLE=1 \\\n    TZ=America/Los_Angeles \\\u003c/strong\u003e\n    WAYLAND_DISPLAY=wayland-0 \\\n    XDG_RUNTIME_DIR=/run/user/1000\nUSER ubuntu\nWORKDIR /home/ubuntu\nCMD firefox\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\n  \u003c/section\u003e\n  \n\n\u003c/article\u003e\n\n      \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "35 min read",
  "publishedTime": "2024-10-05T00:00:00-07:00",
  "modifiedTime": null
}
