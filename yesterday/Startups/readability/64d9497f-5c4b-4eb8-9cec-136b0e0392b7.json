{
  "id": "64d9497f-5c4b-4eb8-9cec-136b0e0392b7",
  "title": "I trusted an LLM, now I'm on day 4 of an afternoon project",
  "link": "https://nemo.foo/blog/day-4-of-an-afternoon-project",
  "description": "Article URL: https://nemo.foo/blog/day-4-of-an-afternoon-project Comments URL: https://news.ycombinator.com/item?id=42845933 Points: 147 # Comments: 101",
  "author": "nemofoo",
  "published": "Mon, 27 Jan 2025 21:37:59 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "nemo",
  "length": 12197,
  "excerpt": "A quick project spiraled into a marathon of AI missteps, hardware headaches, and hard-earned lessons. Welcome to the story of Deskthang.",
  "siteName": "nemo",
  "favicon": "",
  "text": "TLDR - AI isn’t a co-pilot; it’s a junior dev faking competence. Trust it at your own risk. I’m 4 days into an afternoon project. I was so sure I’d crush this one. I had a good plan and the stoke was high. Let me introduce Deskthang. It’s a thang for your desk. When I work, I want to put my phone in the other room, and only get the important notifications (thangs) in a different way. If my deployment pipeline fails, I want a globe on my desk to turn red and show me a gitlab logo. I do not want to check my phone or email or anywhere a distraction might find me. Quick backstory: I work full time++ doing boring enterprise software dev and rarely get to flex my engineering skills. While my title says engineer, I’d disagree. The Problem I’m Trying to Solve I always try to align multiple interests for a side project. I wanted to pull my electronics hardware box out of storage, I wanted to solve the notifications and focus issue for myself, and I wanted to see how scared I should be about AI taking my job. As they say, I was trying to get a few birds stoned at once. 1. I miss working with hardware. During COVID lock-downs I landed an R\u0026D contract for a IoT Prototype. That R\u0026D job was the most fulfilling work of my career. I worked with a small, scrappy team with some of my best friends. I was 3D printing models, soldering components, writing embedded C, and field-testing with mechanical engineers… Real engineers. We worked hard, often late into the night, and the collaboration felt more like playing StarCraft with the boiz than a 9-to-5. I’ve missed that deeply ever since. Recently, I’ve been inspired recently by @_MaxBlade and DeskHub and wanted to brush the dust off my electronics skills. 2. I hate the UX of MFA (Multi Factor Authentication). I use GitLab heavily for CI/CD with my personal Kubernetes projects. Knowing the status of my pipelines is crucial… broken builds could disrupt all 7 of my users! Logging into GitLab feels like getting stabbed in the spleen. Every time I log in (multiple times a day), I face captchas, authenticator apps, or waiting for email codes, followed by yet another captcha. I’ve tried pipeline notifications through Slack, Discord, and Telegram, but those apps are like productivity black holes. I don’t want my phone near me while working, or to open chat apps that derail my focus. Removing these distractions keeps me locked in. 3. I want to see how good these AI tools are. I want to figure out if AI is going to take my job. I’m skeptical it can replace what I do, but I like testing my assumptions. Sometimes AI surprises me; other times, it’s just a rabbit hole of wasted hours when I avoid doing real thinking. Recently, I used Claude Sonnet 3.5 to brute-force hundreds of React compile errors while upgrading a project from React 15 to 18. I threw package.json updates, deleted node_modules, and burned through a small fortune in AI tokens. To my surprise, we had a passing build by the end of the day. Work has been encouraging us to adopt an AI-first workflow and giving us unlimited tokens. It’s a wild experiment. This happened on a Friday. I wiped the sweat off my brow after a hard day’s prompting, and headed home early to start on my side project… The Plan Unlike me, my wife likes to leave the house and do things. I’ve spent a few years turning my garage into my favorite place to be. My wife and I have a deal where 1 day a month, She takes the kiddo and I am absolved of all responsibilities. I get a full day to lock in and build projects. From her perspective, I order doordash and turn into a degen who is unfit to father. From my perspective, I get to enjoy my favorite place and just tinker or play games or do whatever. These are the days I get to play mad scientist and feel most like myself. I look forward to it every month. My plan was to learn zig, brush off my hardware skills, build this project, write a blog post and make a video about it. Totally achievable. I wanted to wire up a Raspberry Pi Pico, a small 240x240 LCD display and some RGB LEDs. I was going to learn Zig and use it to send image data over USB to the pico which will put an image on the screen and change the LED color. I would set up webhooks from GitLab to call an API in my Kube cluster and setup my host Zig app to poll that same API for changes and send updates to the Pico. I really wanted to transmit the data over USB because I’ve never done that before. I’ve already used Bluetooth, LTE and Wifi and just wanted to do something new. The wiring is simple. Common patterns I was familiar with like SPI (Serial Peripheral Interface) for the display + some RGB leds. The TTY (TeleTYpewriter) serial data port on Linux /dev/ttyACM0 for USB communication with the Pico felt familiar because of how I had setup debug logging in the past. It looked like I had enough example repos collected that I could stitch a solution together. I did a little research each day and felt a little more sure each time. I’ve been using ChatGPT and Claude more and more to do initial research. I was at an AI hype peak and was bold enough to trust it… Since I do full stack web stuff on the daily, the api, webhooks and postgres are out of scope for the degen day. I was scoping the day’s work to Zig -\u003e Pico image transfer. 1. Setup Pico Organize the workspace Find a micro usb cable that supports data and not just charging… really why are they all power only?! Wire up a breadboard with Pico \u0026 display and LED Setup the C SDK for the raspi pico and a repo gitlab, gihub-mirror Push a build and see logs on cat /dev/ttyACM0 2. Setup Pico Display Put something on the screen during the boot loop. youtube link (12 sec) 3. Setup Host Zig Project Setup a host directory in repo Init zig project Send a message and see something on the screen youtube link (9 sec) 4. Image Transfer Yeet the raw rgb image data over USB It’s bidirectional safe right USB CDC is bidirectional safe TTY interface is built on top of USB CDC TTY is bidirectional safe because CDC is (no it’s not… thanks gpt) In the above image you can see the outright lie that broke me… USB CDC has separate TX (Transmit) and RX (Receive) buffers so it’s bidirectional safe. The same is not true for TTY which is bidirectional but less safe with a single buffer for TX and RX data. Timeline of Actuality (AI Woes) After a dozen duds, I found a data capable usb micro cable and everything went smoothly until the image transfer. I used Claude, Cline, and ChatGPT to AI-max my way to a buggy but working implementation. I sent commands from my terminal with Zig over USB to the Pico which read them and changed the screen. This only took a few hours and I was excited that the AI assisted dream was real. It’s not complex but I think it was faster than I could have done alone. I have no experience with zig besides hearing ThePrimeagen yap about it. I haven’t even read the docs. Multiple times, I found myself stopping Cline from starting completely new implementations of already solved issues. I didn’t catch everything though. When Cline blew through my API limits, I added Claude to my harem and ran both in parallel when possible. As I look through the code now, I realize that I’m lousy at multitasking and was gaslighting myself. The Image Transfer Disaster This is where my hubris came into play. In my mind, I pictured sending all the image data in one go, like an S3 upload. I imagined clean, raw data streaming over /dev/ttyACM0. It wasn’t clean. It wasn’t raw. It was chaos. I expected to see: pico - heartbeat zig - start image transfer zig - [240x240 COLOR PIXELS] zig - end image transfer pico - heartbeat What I actually saw looked like this, but worse: pico - heartbeat zig - start ima% pico - heage transfert pico - heartbeat zig - [240x240 COL pico - heartbea OR PIXELtS] pico - heartbeat zig - end image transfer pico - heartbeat It’s just like that interrupting cow knock knock joke. Completely unfunny and day ruining. Key Problems: 1. Buffer Conflicts: /dev/ttyACM0 was the battlefield. The same buffer was used for both logging and image transfer. If a log slipped in during the data stream… well good luck figuring out what the hell just happened. 2. Noise: Some weird corruption was happening. Maybe I wasn’t clearing buffers properly. Maybe the gods of USB communication just hate me. The bottom line? Neither the Pico nor my laptop could trust the data. Each system needed to learn to yield, and I needed to build the round-a-bout to force them to be polite and wait their turn. Packets, Protocols \u0026 State Machines, Oh my… I needed to get serious. So, naturally, I let Claude write some docs: Detailed a packet shape. Documented a checksum verification plan. Described data format for transfer. Denoted how to chunk and rebuild the image. Depicted the state machine transitions. Demonstrated command system. Designed a logging system that doesn’t break incoming commands. After delving down dem docs, I let AI run with the actual implementations. At this point, my “degen hat” came off, and I resumed my dad duties while letting Cursor and Cline play StarCraft with my codebase. This is the dream use case for AI, right? Just let it rip and come back to a perfectly functioning system. Let’s see just how close we get to the sun. Reality Check: AI tools are like interns who know how to Google really fast but don’t understand context. Cursor started changing core implementations for unrelated edits. Cline would randomly rewrite half the system without asking. By the time I noticed, my codebase looked like the aftermath of a spaghetti fight at a junior developer convention. Most of the codebase was actually unreachable. What did I learn? Like Icarus, my codebase is irrecoverable. A tangled heap of wing fragments and melted wax, dripping with half-baked ideas and unsupervised AI chaos. My grand vision of outsourcing grunt work to AI had sent me soaring, but the sun of reality burned away any hope of landing gracefully. Here’s what I’m taking away from this flaming descent. 1. AI is a tool, not a co-pilot AI is great for generating ideas or drafting code, but it doesn’t understand. It’s like giving a junior developer a chainsaw instead of a scalpel—it might finish the job, but you’ll spend twice as long cleaning up the mess. I learned that I need to stay firmly in the driver’s seat when tackling new tech. 2. Friction forces focus Having AI directly in my editor felt like playing with infinite cheat codes. It was too easy to let it run wild and harder to maintain control. Moving forward, I’m introducing deliberate friction. I will be using AI only in web interfaces or as a brainstorming tool. If I have to paste its suggestions into my code manually, I’ll be more mindful of the process and less likely to reach for it. 3. Mistakes teach better than shortcuts When I make mistakes, I learn. Debugging my own failures has always been one of the best ways to understand a new language or concept. Relying on AI to “fix” things for me short-circuited that learning process. As a result, I’m left with no deeper understanding of Zig than when I started. 4. Patience beats hubris Building something new, with unfamiliar tools takes time. The idea that I could fully implement my vision in a single “degen day” was overly optimistic, bordering on foolish. Sometimes, you have to respect the complexity of what you’re trying to achieve. Moving Forward Deskthang has grown from a casual afternoon project into a saga of overconfidence, AI misadventures, and lessons learned the hard way. For now, I’m shelving the AI driven shortcuts and committing to a rewrite on my next no-responsibilities day. I’ve picked up a pen and started writing docs by hand like it’s the stone age. I plan to work through some Advent of Code problems in Zig to actually learn the language before taking another crack at this project. Want to see if Deskthang ever works, or just enjoy the chaos as I fail forward? Subscribe below for a monthly email drop of my latest misadventures and skill issues. Together, we’ll learn how to coexist with AI, relearn the lessons I forget, and hopefully build something worthwhile in the process. LFG 🚀",
  "image": "https://nemo.foo/assets/pfp/color/png/color.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eTLDR - AI isn’t a co-pilot; it’s a junior dev faking competence. Trust it at your own risk.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eI’m 4 days into an afternoon project. I was so sure I’d crush this one. I had a good plan and the stoke was high. Let me introduce \u003cem\u003eDeskthang\u003c/em\u003e. It’s a thang for your desk. When I work, I want to put my phone in the other room, and only get the important notifications (thangs) in a different way. If my deployment pipeline fails, I want a globe on my desk to turn red and show me a gitlab logo. I do not want to check my phone or email or anywhere a distraction might find me.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eQuick backstory: I work full time++ doing boring enterprise software dev and rarely get to flex my engineering skills. While my title says engineer, I’d disagree.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003eThe Problem I’m Trying to Solve\u003c/h2\u003e\n\u003cp\u003eI always try to align multiple interests for a side project. I wanted to pull my electronics hardware box out of storage, I wanted to solve the notifications and focus issue for myself, and I wanted to see how scared I should be about AI taking my job. As they say, I was trying to get a few birds stoned at once.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://nemo.foo/blog-content/deskthang/two_birds_stoned.gif\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch3\u003e1. I miss working with hardware.\u003c/h3\u003e\n\u003cp\u003eDuring COVID lock-downs I landed an R\u0026amp;D contract for a IoT Prototype. That R\u0026amp;D job was the most fulfilling work of my career. I worked with a small, scrappy team with some of my best friends. I was 3D printing models, soldering components, writing embedded C, and field-testing with mechanical engineers… Real engineers. We worked hard, often late into the night, and the collaboration felt more like playing StarCraft with the boiz than a 9-to-5. I’ve missed that deeply ever since. Recently, I’ve been inspired recently by \u003ca href=\"https://x.com/_MaxBlade\"\u003e@_MaxBlade and DeskHub\u003c/a\u003e and wanted to brush the dust off my electronics skills.\u003c/p\u003e\n\u003ch3\u003e2. I hate the UX of MFA (Multi Factor Authentication).\u003c/h3\u003e\n\u003cp\u003eI use GitLab heavily for CI/CD with my personal Kubernetes projects. Knowing the status of my pipelines is crucial… broken builds could disrupt all 7 of my users! Logging into GitLab feels like getting stabbed in the spleen. Every time I log in (multiple times a day), I face captchas, authenticator apps, or waiting for email codes, followed by yet another captcha. I’ve tried pipeline notifications through Slack, Discord, and Telegram, but those apps are like productivity black holes. I don’t want my phone near me while working, or to open chat apps that derail my focus. Removing these distractions keeps me locked in.\u003c/p\u003e\n\u003ch3\u003e3. I want to see how good these AI tools are.\u003c/h3\u003e\n\u003cp\u003eI want to figure out if AI is going to take my job. I’m skeptical it can replace what I do, but I like testing my assumptions. Sometimes AI surprises me; other times, it’s just a rabbit hole of wasted hours when I avoid doing real thinking.\u003c/p\u003e\n\u003cp\u003eRecently, I used Claude Sonnet 3.5 to brute-force hundreds of React compile errors while upgrading a project from React 15 to 18. I threw \u003ccode\u003epackage.json\u003c/code\u003e updates, deleted \u003ccode\u003enode_modules\u003c/code\u003e, and burned through a small fortune in AI tokens. To my surprise, we had a passing build by the end of the day. Work has been encouraging us to adopt an AI-first workflow and giving us unlimited tokens. It’s a wild experiment.\u003c/p\u003e\n\u003cp\u003eThis happened on a Friday. I wiped the sweat off my brow after a hard day’s prompting, and headed home early to start on my side project…\u003c/p\u003e\n\u003ch2\u003eThe Plan\u003c/h2\u003e\n\u003cp\u003eUnlike me, my wife likes to leave the house and do things. I’ve spent a few years turning my garage into my favorite place to be. My wife and I have a deal where 1 day a month, She takes the kiddo and I am absolved of all responsibilities. I get a full day to lock in and build projects. From her perspective, I order doordash and turn into a degen who is unfit to father. From my perspective, I get to enjoy my favorite place and just tinker or play games or do whatever. These are the days I get to play mad scientist and feel most like myself. I look forward to it every month. My plan was to learn zig, brush off my hardware skills, build this project, write a blog post and make a video about it. Totally achievable.\u003c/p\u003e\n\u003cp\u003eI wanted to wire up a Raspberry Pi Pico, a small 240x240 LCD display and some RGB LEDs. I was going to learn Zig and use it to send image data over USB to the pico which will put an image on the screen and change the LED color. I would set up webhooks from GitLab to call an API in my Kube cluster and setup my host Zig app to poll that same API for changes and send updates to the Pico. I really wanted to transmit the data over USB because I’ve never done that before. I’ve already used Bluetooth, LTE and Wifi and just wanted to do something new.\u003c/p\u003e\n\u003cp\u003eThe wiring is simple. Common patterns I was familiar with like \u003ca href=\"https://en.wikipedia.org/wiki/Serial_Peripheral_Interface\"\u003eSPI (Serial Peripheral Interface)\u003c/a\u003e for the display + some RGB leds. The \u003ca href=\"https://itsfoss.com/what-is-tty-in-linux/?utm_source=chatgpt.com\"\u003eTTY (TeleTYpewriter)\u003c/a\u003e serial data port on Linux \u003ccode\u003e/dev/ttyACM0\u003c/code\u003e for USB communication with the Pico felt familiar because of how I had setup debug logging in the past. It looked like I had enough example repos collected that I could stitch a solution together. I did a little research each day and felt a little more sure each time. I’ve been using ChatGPT and Claude more and more to do initial research. I was at an AI hype peak and was bold enough to trust it…\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://nemo.foo/blog-content/deskthang/excalidraw.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003eSince I do full stack web stuff on the daily, the api, webhooks and postgres are out of scope for the degen day. I was scoping the day’s work to Zig -\u0026gt; Pico image transfer.\u003c/p\u003e\n\u003ch3\u003e1. Setup Pico\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOrganize the workspace\u003c/li\u003e\n\u003cli\u003eFind a micro usb cable that supports data and not just charging… really why are they all power only?!\u003c/li\u003e\n\u003cli\u003eWire up a breadboard with Pico \u0026amp; display and LED\u003c/li\u003e\n\u003cli\u003eSetup the C SDK for the raspi pico and a repo \u003ca href=\"https://gitlab.com/nemofoo/deskthang\"\u003egitlab\u003c/a\u003e, \u003ca href=\"https://github.com/nemofoo/deskthang\"\u003egihub-mirror\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003ePush a build and see logs on \u003ccode\u003ecat /dev/ttyACM0\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://nemo.foo/blog-content/deskthang/first_assembly.jpg\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch3\u003e2. Setup Pico Display\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePut something on the screen during the boot loop.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://nemo.foo/blog-content/deskthang/first_test_pattern.jpg\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://youtube.com/shorts/H6b64PJI40o\"\u003eyoutube link (12 sec)\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003e3. Setup Host Zig Project\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSetup a host directory in repo\u003c/li\u003e\n\u003cli\u003eInit zig project\u003c/li\u003e\n\u003cli\u003eSend a message and see something on the screen\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://youtu.be/Y0wkzbwGWJc\"\u003eyoutube link (9 sec)\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003e4. Image Transfer\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eYeet the raw rgb image data over USB\u003c/li\u003e\n\u003cli\u003eIt’s bidirectional safe right\u003c/li\u003e\n\u003cli\u003eUSB CDC is bidirectional safe\n\u003cul\u003e\n\u003cli\u003eTTY interface is built on top of USB CDC\n\u003cul\u003e\n\u003cli\u003eTTY is bidirectional safe because CDC is (no it’s not… thanks gpt)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://nemo.foo/blog-content/deskthang/gptlies.png\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn the above image you can see the outright lie that broke me… USB CDC has separate TX (Transmit) and RX (Receive) buffers so it’s bidirectional safe. The same is not true for TTY which is bidirectional but less safe with a single buffer for TX and RX data.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003eTimeline of Actuality (AI Woes)\u003c/h2\u003e\n\u003cp\u003eAfter a dozen duds, I found a data capable usb micro cable and everything went smoothly until the image transfer. I used Claude, Cline, and ChatGPT to AI-max my way to a buggy but working implementation. I sent commands from my terminal with Zig over USB to the Pico which read them and changed the screen. This only took a few hours and I was excited that the AI assisted dream was real. It’s not complex but I think it was faster than I could have done alone. I have no experience with zig besides hearing ThePrimeagen yap about it. I haven’t even read the docs.\u003c/p\u003e\n\u003cp\u003eMultiple times, I found myself stopping Cline from starting completely new implementations of already solved issues. I didn’t catch everything though. When Cline blew through my API limits, I added Claude to my harem and ran both in parallel when possible.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAs I look through the code now, I realize that I’m lousy at multitasking and was gaslighting myself.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eThe Image Transfer Disaster\u003c/h3\u003e\n\u003cp\u003eThis is where my hubris came into play. In my mind, I pictured sending all the image data in one go, like an S3 upload. I imagined clean, raw data streaming over \u003ccode\u003e/dev/ttyACM0\u003c/code\u003e. It wasn’t clean. It wasn’t raw. It was chaos.\u003c/p\u003e\n\u003cp\u003eI expected to see:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epico - heartbeat\nzig - start image transfer\nzig - [240x240 COLOR PIXELS]\nzig - end image transfer\npico - heartbeat\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhat I actually saw looked like this, but worse:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epico - heartbeat\nzig - start ima%\npico - heage transfert\npico - heartbeat\nzig - [240x240 COL\npico - heartbea\nOR PIXELtS]\npico - heartbeat\nzig - end image transfer\npico - heartbeat\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://youtu.be/jnmqlsdD6oU\"\u003eIt’s just like that interrupting cow knock knock joke.\u003c/a\u003e Completely unfunny and day ruining.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKey Problems:\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Buffer Conflicts:\u003c/strong\u003e \u003ccode\u003e/dev/ttyACM0\u003c/code\u003e was the battlefield. The same buffer was used for both logging and image transfer. If a log slipped in during the data stream… well good luck figuring out what the hell just happened.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. Noise:\u003c/strong\u003e Some weird corruption was happening. Maybe I wasn’t clearing buffers properly. Maybe the gods of USB communication just hate me.\u003c/p\u003e\n\u003cp\u003eThe bottom line? Neither the Pico nor my laptop could trust the data. Each system needed to learn to yield, and I needed to build the round-a-bout to force them to be polite and wait their turn.\u003c/p\u003e\n\u003ch3\u003ePackets, Protocols \u0026amp; State Machines, Oh my…\u003c/h3\u003e\n\u003cp\u003eI needed to get serious. So, naturally, I let Claude write some docs:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDetailed a packet shape.\u003c/li\u003e\n\u003cli\u003eDocumented a checksum verification plan.\u003c/li\u003e\n\u003cli\u003eDescribed data format for transfer.\u003c/li\u003e\n\u003cli\u003eDenoted how to chunk and rebuild the image.\u003c/li\u003e\n\u003cli\u003eDepicted the state machine transitions.\u003c/li\u003e\n\u003cli\u003eDemonstrated command system.\u003c/li\u003e\n\u003cli\u003eDesigned a logging system that doesn’t break incoming commands.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAfter delving down dem docs, I let AI run with the actual implementations. At this point, my “degen hat” came off, and I resumed my dad duties while letting Cursor and Cline play StarCraft with my codebase. This is the dream use case for AI, right? Just let it rip and come back to a perfectly functioning system. Let’s see just how close we get to the sun.\u003c/p\u003e\n\u003cp\u003eReality Check: AI tools are like interns who know how to Google really fast but don’t understand context. Cursor started changing core implementations for unrelated edits. Cline would randomly rewrite half the system without asking. By the time I noticed, my codebase looked like the aftermath of a spaghetti fight at a junior developer convention. Most of the codebase was actually unreachable.\u003c/p\u003e\n\u003ch2\u003eWhat did I learn?\u003c/h2\u003e\n\u003cp\u003eLike Icarus, my codebase is irrecoverable. A tangled heap of wing fragments and melted wax, dripping with half-baked ideas and unsupervised AI chaos. My grand vision of outsourcing grunt work to AI had sent me soaring, but the sun of reality burned away any hope of landing gracefully. Here’s what I’m taking away from this flaming descent.\u003c/p\u003e\n\u003ch3\u003e1. AI is a tool, not a co-pilot\u003c/h3\u003e\n\u003cp\u003eAI is great for generating ideas or drafting code, but it doesn’t understand. It’s like giving a junior developer a chainsaw instead of a scalpel—it might finish the job, but you’ll spend twice as long cleaning up the mess. I learned that I need to stay firmly in the driver’s seat when tackling new tech.\u003c/p\u003e\n\u003ch3\u003e2. Friction forces focus\u003c/h3\u003e\n\u003cp\u003eHaving AI directly in my editor felt like playing with infinite cheat codes. It was too easy to let it run wild and harder to maintain control. Moving forward, I’m introducing deliberate friction. I will be using AI only in web interfaces or as a brainstorming tool. If I have to paste its suggestions into my code manually, I’ll be more mindful of the process and less likely to reach for it.\u003c/p\u003e\n\u003ch3\u003e3. Mistakes teach better than shortcuts\u003c/h3\u003e\n\u003cp\u003eWhen I make mistakes, I learn. Debugging my own failures has always been one of the best ways to understand a new language or concept. Relying on AI to “fix” things for me short-circuited that learning process. As a result, I’m left with no deeper understanding of Zig than when I started.\u003c/p\u003e\n\u003ch3\u003e4. Patience beats hubris\u003c/h3\u003e\n\u003cp\u003eBuilding something new, with unfamiliar tools takes time. The idea that I could fully implement my vision in a single “degen day” was overly optimistic, bordering on foolish. Sometimes, you have to respect the complexity of what you’re trying to achieve.\u003c/p\u003e\n\u003ch2\u003eMoving Forward\u003c/h2\u003e\n\u003cp\u003eDeskthang has grown from a casual afternoon project into a saga of overconfidence, AI misadventures, and lessons learned the hard way. For now, I’m shelving the AI driven shortcuts and committing to a rewrite on my next no-responsibilities day.\u003c/p\u003e\n\u003cp\u003eI’ve picked up a pen and started writing docs by hand like it’s the stone age. I plan to work through some Advent of Code problems in Zig to actually learn the language before taking another crack at this project.\u003c/p\u003e\n\u003cp\u003eWant to see if Deskthang ever works, or just enjoy the chaos as I fail forward? Subscribe below for a monthly email drop of my latest misadventures and skill issues. Together, we’ll learn how to coexist with AI, relearn the lessons I forget, and hopefully build something worthwhile in the process.\u003c/p\u003e\n\u003cp\u003eLFG 🚀\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "14 min read",
  "publishedTime": "2025-01-26T00:00:00Z",
  "modifiedTime": null
}
