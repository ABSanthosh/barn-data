{
  "id": "d33846ee-07e5-4e95-8945-679079925c79",
  "title": "Bus Number – The GitHub plugin my coworkers asked me not to write",
  "link": "https://www.scannedinavian.com/the-github-plugin-my-coworkers-asked-me-not-to-write.html",
  "description": "Article URL: https://www.scannedinavian.com/the-github-plugin-my-coworkers-asked-me-not-to-write.html Comments URL: https://news.ycombinator.com/item?id=42111260 Points: 15 # Comments: 3",
  "author": "todsacerdoti",
  "published": "Mon, 11 Nov 2024 23:11:19 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "",
  "length": 6675,
  "excerpt": "Posted on 2024-11-11",
  "siteName": "",
  "favicon": "",
  "text": "Posted on 2024-11-11 This blog post was written together with \u003cmclare\u003e, who made coooool visualizations like the picture at the end of the post! What’s a Bus Factor or Truck Factor? According to wikipedia: The “bus factor” is the minimum number of team members that have to suddenly disappear from a project before the project stalls due to lack of knowledgeable or competent personnel. Why? In 2015 or so, my employer had layoffs. One of them was the only contributor to part of the codebase that made money for our company. I remembered reading about Truck Number on the original wiki, so I thought it’d be fun to write a github enterprise plugin that calculates who you can’t afford to fire. I enjoy reading research papers, and found this truck factor research paper. I started writing the plugin, and talked five minutes on it at our Thursday afternoon lightning talks. My coworkers said it would immediately hit Goodhart’s Law. They saw this as a way for management to easily calculate who you can fire! What? The original authors calculated how many people had to be hit by a bus for a bunch of popular GitHub projects to stall. This includes the Linux kernel among others. In the first preprint, they said 80 people would have to leave the project for Linux to stop. Last week I mentioned this blog post idea to mclare, and she said we should try to reproduce the results and see if the truck factor has improved in the past ten years. The authors’ github repo is available and still works! Are we able to reproduce the results? The Truck Factor research paper links to a github repository! The data from the paper is available as JSON! Their visualization is backed by a CSV we can scrape! But, we don’t know the date they pulled the data. The README instructions don’t quite work, and we spent an hour figuring out how to execute the pieces. Fortunately, the issues on the github repository told us how to fix the problem. I wanted results, not an afternoon of debugging their use of awk in shell scripts. mclare got the list of github repos out of the first column of their CSV. We needed to clone them all! We had fun learning about gnu parallel to run a bunch of git clone commands at the same time. Gnu Parallel Why does gnu parallel use all the cores when we tell it to use only 8? We only saw eight git clone processes at a time, but a large number of git index-pack processes that maxed out all 32 cores on my laptop. I’m guessing git’s index-pack is a forked subprocess and allows parallel to start another git clone? If you know the answer, send us a message! Ruby Gems in NixOS The Truck Factor code uses linguist to filter out files that are only documentation. Later in the paper the authors say that documentation is the best way to keep your project alive, so I’m not convinced that’s good. In any case, I’m running NixOS and have no experience with Ruby, thus installing Ruby Gems did not fit in the time I had. If you know a good way to install the linguist plugin in a Nix flake, please send me a message! (or even a pull request) But, how did you recalculate the results? We forked the original repository on github, cloned it locally, and puzzled our way through the README. We used mvn package to compile the Java source into a jar, and tried each of the steps on the numpy github repository. Then we were ready to recalculate all the things. mclare downloaded the CSV from the authors’ visualization and we converted the first column into a list of github repositories. I started with a for loop, but mclare switched to gnu parallel, because it’s cool. Also because everything gets done faster. # clone the repositories parallel -j 8 git clone ::: $(cat ../meta/repo_list.txt) # change into the directory so you don't get the awk error cd gittruckfactor/scripts # scrape out all the git commit info for x in ../../repos/*; do ./commit_log_script.sh $x; done; # run the java code that ingests the scraped commit data for x in ../repos/*; do dirname $x \u003e\u003e ../results.txt \u0026\u0026 echo java -jar ./target/gittruckfactor-1.0.jar $x $x \u003e\u003e ../results.txt; done; I have a fast gigabit internet connection at home, it took 17.5 minutes to clone all the repos one at a time. Processing each repo took about the same time, eighteen minutes maybe? Here’s one example output for the linux kernel repository: linux TF = 12 (coverage = 49.98%) TF authors (Developer;Files;Percentage): Linus Torvalds;5712;6.59 Mauro Carvalho Chehab;2479;2.86 Rob Herring;1313;1.51 Thomas Gleixner;1228;1.42 Krzysztof Kozlowski;1222;1.41 Ben Skeggs;1211;1.40 Arnaldo Carvalho de Melo;911;1.05 Greg Kroah-Hartman;852;0.98 David Howells;718;0.83 Ian Rogers;599;0.69 Masahiro Yamada;598;0.69 Takashi Iwai;581;0.67 Problems \u003cmclare\u003e This calculation neglects the review process. As you go up the career ladder, developers should do more review and less hands on keyboard. Further Work does the truck factor calculation take into account git’s co-authored-by and reviewer headers? If not, could it? why is our number for Linux so very different ten years later? The original paper gives a truck factor of 80, we get EIGHT! The original paper uses a Levenshtein distance of one to find and merge developer aliases. I don’t think we did that. Maybe that changes our number? Would this version of the truck factor code still give us 80 if we checkout the Linux kernel repo at mid-2015 ? According to the git history, the algorithm was updated in 2016, could we get new numbers for a later blog post? We could look at some of the 156 citations of this paper and see if someone came up with a better calculation. We could compare popular projects of today to their history. Rust and other recent big names are not mentioned in the 2015 paper. For that matter, we could write a script to find yearly truck numbers for any git repo. Shae wants to figure out how to install Ruby Gems in NixOS so the linguist plugin can filter out which files are only documentation. Conclusion - Bus Factors got scarier. The biggest question we both had was, did it get any better? I’m gonna say no, it’s gotten worse. The 2015 preprint of this paper gave the linux kernel a truck factor of ninety! The full publication gave that same repository a truck number of fifty seven. Without the linguist plugin to filter out documentation and third party libraries, we got a truck factor of twelve for the Linux kernel repository. After mclare installed the plugin on her system, she got a truck factor of eight for the Linux kernel. This is not an improvement. If you want more articles on this subject, send us a message! Visualize! For more visualizations and nifty details, check out mclare’s blog.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"content\"\u003e\n\t    \n\t    \u003cp\u003e\n    Posted on 2024-11-11\n    \n\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://www.scannedinavian.com/images/holastafur.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThis blog post was written together with \u003ca href=\"https://mclare.blog\"\u003e\u0026lt;mclare\u0026gt;\u003c/a\u003e, who made coooool visualizations like the picture at the end of the post!\u003c/p\u003e\n\u003ch2 id=\"whats-a-bus-factor-or-truck-factor\"\u003eWhat’s a Bus Factor or Truck Factor?\u003c/h2\u003e\n\u003cp\u003eAccording to \u003ca href=\"https://en.wikipedia.org/wiki/Bus_factor\"\u003ewikipedia\u003c/a\u003e:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe “bus factor” is the minimum number of team members that have to suddenly disappear from a project before the project stalls due to lack of knowledgeable or competent personnel.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"why\"\u003eWhy?\u003c/h2\u003e\n\u003cp\u003eIn 2015 or so, my employer had layoffs.\nOne of them was the only contributor to part of the codebase that made money for our company.\nI remembered reading about \u003ca href=\"https://wiki.c2.com/?TruckNumber\"\u003eTruck Number\u003c/a\u003e on the original wiki, so I thought it’d be fun to write a github enterprise plugin that calculates who you can’t afford to fire.\nI enjoy reading research papers, and found this \u003ca href=\"http://aserg.labsoft.dcc.ufmg.br/truckfactor/\"\u003etruck factor\u003c/a\u003e research paper.\u003c/p\u003e\n\u003cp\u003eI started writing the plugin, and talked five minutes on it at our Thursday afternoon lightning talks.\nMy coworkers said it would immediately hit \u003ca href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\"\u003eGoodhart’s Law\u003c/a\u003e. They saw this as a way for management to easily calculate who you \u003cstrong\u003ecan\u003c/strong\u003e fire!\u003c/p\u003e\n\u003ch2 id=\"what\"\u003eWhat?\u003c/h2\u003e\n\u003cp\u003eThe original authors calculated how many people had to be hit by a bus for a bunch of popular GitHub projects to stall.\nThis includes the Linux kernel among others. In the first preprint, they said 80 people would have to leave the project for Linux to stop.\u003c/p\u003e\n\u003cp\u003eLast week I mentioned this blog post idea to mclare, and she said we should try to reproduce the results and see if the truck factor has improved in the past ten years.\u003c/p\u003e\n\u003cp\u003eThe authors’ \u003ca href=\"https://github.com/aserg-ufmg/Truck-Factor\"\u003egithub repo\u003c/a\u003e is available and still works!\u003c/p\u003e\n\u003ch2 id=\"are-we-able-to-reproduce-the-results\"\u003eAre we able to reproduce the results?\u003c/h2\u003e\n\u003cp\u003eThe Truck Factor research paper links to a \u003ca href=\"https://github.com/aserg-ufmg/Truck-Factor\"\u003egithub repository\u003c/a\u003e!\nThe data from the paper is available as JSON!\nTheir \u003ca href=\"http://aserg.labsoft.dcc.ufmg.br/truckfactor/target.html\"\u003evisualization\u003c/a\u003e is backed by a CSV we can scrape!\u003c/p\u003e\n\u003cp\u003eBut, we don’t know the \u003cstrong\u003edate\u003c/strong\u003e they pulled the data.\u003c/p\u003e\n\u003cp\u003eThe README instructions don’t quite work, and we spent an hour figuring out how to execute the pieces.\nFortunately, the issues on the github repository told us how to fix the problem. I wanted results, not an afternoon of debugging their use of awk in shell scripts.\nmclare got the list of github repos out of the first column of their CSV. We needed to clone them all!\nWe had fun learning about \u003ca href=\"https://www.gnu.org/software/parallel/\"\u003egnu parallel\u003c/a\u003e to run a bunch of git clone commands at the same time.\u003c/p\u003e\n\u003ch3 id=\"gnu-parallel\"\u003eGnu Parallel\u003c/h3\u003e\n\u003cp\u003eWhy does \u003ca href=\"https://www.gnu.org/software/parallel/\"\u003egnu parallel\u003c/a\u003e use \u003cstrong\u003eall\u003c/strong\u003e the cores when we tell it to use only 8?\nWe only saw eight \u003ccode\u003egit clone\u003c/code\u003e processes at a time, but a large number of \u003ccode\u003egit index-pack\u003c/code\u003e processes that maxed out all 32 cores on my laptop.\nI’m guessing git’s index-pack is a forked subprocess and allows parallel to start another git clone?\nIf you know the answer, send us a message!\u003c/p\u003e\n\u003ch3 id=\"ruby-gems-in-nixos\"\u003eRuby Gems in NixOS\u003c/h3\u003e\n\u003cp\u003eThe Truck Factor code uses \u003ca href=\"https://github.com/github-linguist/linguist\"\u003elinguist\u003c/a\u003e to filter out files that are only documentation. Later in the paper the authors say that documentation is the best way to keep your project alive, so I’m not convinced that’s good.\u003c/p\u003e\n\u003cp\u003eIn any case, I’m running NixOS and have no experience with Ruby, thus installing Ruby Gems did not fit in the time I had.\nIf you know a good way to install the linguist plugin in a Nix flake, please send me a message! (or even a \u003ca href=\"https://github.com/spite-driven-development/Truck-Factor\"\u003epull request\u003c/a\u003e)\u003c/p\u003e\n\u003ch2 id=\"but-how-did-you-recalculate-the-results\"\u003eBut, \u003cstrong\u003ehow\u003c/strong\u003e did you recalculate the results?\u003c/h2\u003e\n\u003cp\u003eWe forked the original repository on github, cloned it locally, and puzzled our way through the README.\nWe used \u003ccode\u003emvn package\u003c/code\u003e to compile the Java source into a jar, and tried each of the steps on the numpy github repository.\nThen we were ready to recalculate all the things.\u003c/p\u003e\n\u003cp\u003emclare downloaded the CSV from the authors’ \u003ca href=\"http://aserg.labsoft.dcc.ufmg.br/truckfactor/target.html\"\u003evisualization\u003c/a\u003e and we converted the first column into a \u003ca href=\"https://github.com/spite-driven-development/Truck-Factor/blob/master/meta/repo_list.txt\"\u003elist of github repositories\u003c/a\u003e.\nI started with a for loop, but mclare switched to gnu parallel, because it’s cool. Also because everything gets done faster.\u003c/p\u003e\n\u003cdiv id=\"cb1\"\u003e\u003cpre\u003e\u003ccode\u003e\u003cspan id=\"cb1-1\"\u003e\u003cspan\u003e# clone the repositories\u003c/span\u003e\u003c/span\u003e\n\u003cspan id=\"cb1-2\"\u003e\u003cspan\u003eparallel\u003c/span\u003e \u003cspan\u003e-j\u003c/span\u003e 8 git clone ::: \u003cspan\u003e$(\u003c/span\u003e\u003cspan\u003ecat\u003c/span\u003e ../meta/repo_list.txt\u003cspan\u003e)\u003c/span\u003e\u003c/span\u003e\n\u003cspan id=\"cb1-3\"\u003e\u003cspan\u003e# change into the directory so you don\u0026#39;t get the awk error\u003c/span\u003e\u003c/span\u003e\n\u003cspan id=\"cb1-4\"\u003e\u003cspan\u003ecd\u003c/span\u003e gittruckfactor/scripts\u003c/span\u003e\n\u003cspan id=\"cb1-5\"\u003e\u003cspan\u003e# scrape out all the git commit info\u003c/span\u003e\u003c/span\u003e\n\u003cspan id=\"cb1-6\"\u003e\u003cspan\u003efor\u003c/span\u003e x \u003cspan\u003ein\u003c/span\u003e ../../repos/\u003cspan\u003e*\u003c/span\u003e\u003cspan\u003e;\u003c/span\u003e \u003cspan\u003edo\u003c/span\u003e \u003cspan\u003e./commit_log_script.sh\u003c/span\u003e \u003cspan\u003e$x\u003c/span\u003e\u003cspan\u003e;\u003c/span\u003e \u003cspan\u003edone\u003c/span\u003e\u003cspan\u003e;\u003c/span\u003e\u003c/span\u003e\n\u003cspan id=\"cb1-7\"\u003e\u003cspan\u003e# run the java code that ingests the scraped commit data\u003c/span\u003e\u003c/span\u003e\n\u003cspan id=\"cb1-8\"\u003e\u003cspan\u003efor\u003c/span\u003e x \u003cspan\u003ein\u003c/span\u003e ../repos/\u003cspan\u003e*\u003c/span\u003e\u003cspan\u003e;\u003c/span\u003e \u003cspan\u003edo\u003c/span\u003e \u003cspan\u003edirname\u003c/span\u003e \u003cspan\u003e$x\u003c/span\u003e \u003cspan\u003e\u0026gt;\u0026gt;\u003c/span\u003e ../results.txt \u003cspan\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan\u003eecho\u003c/span\u003e java \u003cspan\u003e-jar\u003c/span\u003e ./target/gittruckfactor-1.0.jar \u003cspan\u003e$x\u003c/span\u003e \u003cspan\u003e$x\u003c/span\u003e \u003cspan\u003e\u0026gt;\u0026gt;\u003c/span\u003e ../results.txt\u003cspan\u003e;\u003c/span\u003e \u003cspan\u003edone\u003c/span\u003e\u003cspan\u003e;\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eI have a fast gigabit internet connection at home, it took 17.5 minutes to clone all the repos one at a time.\nProcessing each repo took about the same time, eighteen minutes maybe?\u003c/p\u003e\n\u003cp\u003eHere’s one example output for the linux kernel repository:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003elinux\nTF = 12 (coverage = 49.98%)\nTF authors (Developer;Files;Percentage):\nLinus Torvalds;5712;6.59\nMauro Carvalho Chehab;2479;2.86\nRob Herring;1313;1.51\nThomas Gleixner;1228;1.42\nKrzysztof Kozlowski;1222;1.41\nBen Skeggs;1211;1.40\nArnaldo Carvalho de Melo;911;1.05\nGreg Kroah-Hartman;852;0.98\nDavid Howells;718;0.83\nIan Rogers;599;0.69\nMasahiro Yamada;598;0.69\nTakashi Iwai;581;0.67\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"problems\"\u003eProblems\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://mclare.blog\"\u003e\u0026lt;mclare\u0026gt;\u003c/a\u003e This calculation neglects the review process. As you go up the career ladder, developers should do more review and less hands on keyboard.\u003c/p\u003e\n\u003ch2 id=\"further-work\"\u003eFurther Work\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003clabel\u003edoes the truck factor calculation take into account git’s co-authored-by and reviewer headers? If not, could it?\u003c/label\u003e\u003c/li\u003e\n\u003cli\u003e\u003clabel\u003ewhy is our number for Linux so very different ten years later? The original paper gives a truck factor of 80, we get EIGHT!\u003c/label\u003e\n\u003cul\u003e\n\u003cli\u003e\u003clabel\u003eThe original paper uses a \u003ca href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\"\u003eLevenshtein distance\u003c/a\u003e of one to find and merge developer aliases. I don’t think we did that. Maybe that changes our number?\u003c/label\u003e\u003c/li\u003e\n\u003cli\u003e\u003clabel\u003eWould this version of the truck factor code still give us 80 if we checkout the Linux kernel repo at mid-2015 ? According to the git history, the algorithm was updated in 2016, could we get new numbers for a later blog post?\u003c/label\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003clabel\u003eWe could look at some of the \u003ca href=\"https://scholar.google.com/scholar?cluster=5286537198548981618\u0026amp;hl=en\u0026amp;as_sdt=0,22\"\u003e156 citations\u003c/a\u003e of this paper and see if someone came up with a better calculation.\u003c/label\u003e\u003c/li\u003e\n\u003cli\u003e\u003clabel\u003eWe could compare popular projects of today to their history. Rust and other recent big names are not mentioned in the 2015 paper. For that matter, we could write a script to find yearly truck numbers for any git repo.\u003c/label\u003e\u003c/li\u003e\n\u003cli\u003e\u003clabel\u003eShae wants to figure out how to install Ruby Gems in NixOS so the linguist plugin can filter out which files are only documentation.\u003c/label\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"conclusion---bus-factors-got-scarier\"\u003eConclusion - Bus Factors got scarier.\u003c/h2\u003e\n\u003cp\u003eThe biggest question we both had was, did it get any better?\u003c/p\u003e\n\u003cp\u003eI’m gonna say no, it’s gotten worse.\nThe 2015 \u003ca href=\"https://peerj.com/preprints/1233v1.pdf\"\u003epreprint\u003c/a\u003e of this paper gave the linux kernel a truck factor of ninety!\nThe \u003ca href=\"https://arxiv.org/pdf/1604.06766\"\u003efull publication\u003c/a\u003e gave that same repository a truck number of fifty seven.\u003c/p\u003e\n\u003cp\u003eWithout the linguist plugin to filter out documentation and third party libraries, we got a truck factor of twelve for the Linux kernel repository.\nAfter mclare installed the plugin on her system, she got a truck factor of eight for the Linux kernel.\u003c/p\u003e\n\u003cp\u003eThis is not an improvement.\u003c/p\u003e\n\u003cp\u003eIf you want more articles on this subject, send us a message!\u003c/p\u003e\n\u003ch2 id=\"visualize\"\u003eVisualize!\u003c/h2\u003e\n\u003cp\u003eFor more visualizations and nifty details, check out \u003ca href=\"https://mclare.blog\"\u003emclare’s blog\u003c/a\u003e.\n\u003cimg src=\"https://www.scannedinavian.com/images/truck-factor.png\"/\u003e\u003c/p\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": null,
  "modifiedTime": null
}
