{
  "id": "3df8eb8c-0bd9-4ee1-97f1-e3730145ca3c",
  "title": "Midjourney’s surprise: new research on making LLMs write more creatively",
  "link": "https://venturebeat.com/ai/midjourneys-surprise-new-research-on-making-llms-write-more-creatively/",
  "description": "There's still a lot of juice left to be squeezed, cognitively and performance-wise, from classic Transformer-based, text-focused LLMs.",
  "author": "Carl Franzen",
  "published": "Mon, 24 Mar 2025 21:36:24 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI, ML and Deep Learning",
    "Conversational AI",
    "Hugging Face",
    "LLaMA",
    "LLMs",
    "Meta",
    "Midjourney",
    "Mistral AI",
    "NLP"
  ],
  "byline": "Carl Franzen",
  "length": 9492,
  "excerpt": "There's still a lot of juice left to be squeezed, cognitively and performance-wise, from classic Transformer-based, text-focused LLMs.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "March 24, 2025 2:36 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Midjourney is best known as one of the leading AI image generators — with nearly 20 million users on its Discord channel, according to third-party trackers, and presumably more atop that on its website — but its ambitions are beginning to expand. Following the news in late summer 2024 that it was building its own computing and AI hardware, the company this week released a new research paper alongside machine learning experts at New York University (NYU) on training text-based large language models (LLMs) such as Meta’s open source Llama and Mistral’s eponymous source models to write more creatively. The collaboration, documented in a new research paper published on AI code community Hugging Face, introduces two new technieques — Diversified Direct Preference Optimization (DDPO) and Diversified Odds Ratio Preference Optimization (DORPO)— designed to expand the range of possible outputs while maintaining coherence and readability. For a company that is best known for its diffusion AI image generating models, Midjourney’s new approach to rethinking creativity in text-based LLMs shows that it is not limiting its ambitions to visuals, and that, a picture may not actually be worth a thousand words. Could a Midjourney-native LLM or fine-tuned version of an existing LLM be in the cards from the small, bootstrapped startup? I reached out to Midjourney founder David Holz but have yet to hear back. Regardless of a first-party Midjourney LLM offering, the implications of its new research go beyond academic exercises and could be used to help fuel a new wave of LLM training among enterprise AI teams, product developers, and content creators looking to improve AI-generated text. It also shows that despite recent interest and investment among AI model providers in new multimodal and reasoning language models, there’s still a lot of juice left to be squeezed, cognitively and performance-wise, from classic Transformer-based, text-focused LLMs. The problem: AI-generated writing collapses around homogenous outputs In domains like fact-based Q\u0026A or coding assistance, LLMs are expected to generate a single best response. However, creative writing is inherently open-ended, meaning there are many valid responses to a single prompt. For an example provided by the Midjourney researchers, given a prompt like “Write a story about a dog on the moon”, the LLM could explore multiple diverse paths like: An astronaut’s pet dog accidentally left behind after a lunar mission. A dog who finds itself in a futuristic canine space colony. A stranded dog that befriends an alien species. Despite this range of possibilities, instruction-tuned LLMs often converge on similar storylines and themes. This happens because: Post-training techniques prioritize user preference over originality, reinforcing popular but repetitive responses. Instruction tuning often smooths out variation, making models favor “safe” responses over unique ones. Existing diversity-promoting techniques (like temperature tuning) operate only at inference time, rather than being baked into the model’s learning process. This leads to homogenized storytelling, where AI-generated creative writing feels repetitive and lacks surprise or depth. The solution: modifying post-training methods to prioritize diversity To overcome these limitations, the researchers introduced DDPO and DORPO, two extensions of existing preference optimization methods. The core innovation in these approaches is the use of deviation—a measure of how much a response differs from others—to guide training. Here’s how it works: During training, the model is given a writing prompt and multiple possible responses. Each response is compared to others for the same prompt, and a deviation score is calculated. Rare but high-quality responses are weighted more heavily in training, encouraging the model to learn from diverse examples. By incorporating deviation into Direct Preference Optimization (DPO) and Odds Ratio Preference Optimization (ORPO), the model learns to produce high-quality but more varied responses. This method ensures that AI-generated stories do not converge on a single predictable structure, but instead explore a wider range of characters, settings, and themes—just as a human writer might. What Midjourney’s researchers did to achieve this The study involved training LLMs on creative writing tasks using a dataset from the subreddit r/writingPrompts, a Reddit community where users post prompts and respond with short stories. The researchers used two base models for their training: Meta’s Llama-3.1-8B (an 8-billion-parameter model from the Llama 3 series). Mistral-7B-v0.3 (a 7-billion-parameter model from Mistral AI). Then, they took these models through the following processes: Supervised Fine-Tuning (SFT): The models were first fine-tuned using LoRA (Low-Rank Adaptation) to adjust parameters efficiently. Preference Optimization: DPO and ORPO were used as baselines—these standard methods focus on improving response quality based on user preference signals. DDPO and DORPO were then applied, introducing deviation-based weighting to encourage more unique responses. Evaluation: Automatic evaluation: Measured semantic and stylistic diversity using embedding-based techniques. Human evaluation: Judges assessed whether outputs were diverse and engaging compared to GPT-4o and Claude 3.5. Key Training Findings: DDPO significantly outperformed standard DPO in terms of output diversity while maintaining quality. Llama-3.1-8B with DDPO achieved the best balance of quality and diversity, producing responses that were more varied than GPT-4o while maintaining coherence. When dataset size was reduced, DDPO models still maintained diversity, though they required a certain number of diverse training samples to be fully effective. Enterprise implications: what does it mean for those using AI to produce creative responses — such as in marketing copywriting, corporate storytelling, and film/TV/video game scripting? For AI teams managing LLM deployment, enhancing output diversity while maintaining quality is a critical challenge. These findings have significant implications for organizations that rely on AI-generated content in applications such as: Conversational AI and chatbots (ensuring varied and engaging responses). Content marketing and storytelling tools (preventing repetitive AI-generated copy). Game development and narrative design (creating diverse dialogue and branching storylines). For professionals responsible for fine-tuning and deploying models in an enterprise setting, this research provides: A new approach to LLM post-training that enhances creativity without sacrificing quality. A practical alternative to inference-time diversity tuning (such as temperature adjustments) by integrating diversity into the learning process itself. The potential to develop more engaging AI applications, from AI-assisted writing tools to virtual assistants that can adapt their responses dynamically. For those handling AI model orchestration and automation, this research highlights: The importance of tuning models at the training stage, reducing the need for post-processing adjustments at deployment. A way to introduce adaptive storytelling into AI-driven applications, ensuring variability while keeping content quality high. A method for making LLM outputs more human-like, which is crucial for applications requiring interactive storytelling, customer engagement, or dynamic content creation. The future of AI generated creative projects looks bright The success of DDPO and DORPO demonstrates that training LLMs with diversity-focused objectives can yield significant improvements in creative writing. Some ideas include: Integrating deviation-based learning into enterprise AI models to enhance response diversity in customer-facing applications. Exploring how these methods apply to other generative tasks, such as AI-powered poetry, screenwriting, or game storytelling. Developing hybrid training approaches that balance diversity and instruction-following capabilities for AI assistants. For those interested in applying these techniques, the researchers plan to make their code publicly available on this GitHub Repository Whether you are fine-tuning LLMs for business applications or optimizing large-scale AI orchestration, this study provides actionable insights into how models can be more dynamic, engaging, and responsive to creative tasks. By adopting these techniques, AI teams can move beyond rigid, formulaic outputs—building AI systems that are not only smart but also truly imaginative. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/03/cfr0z3n_surreal_image_of_researchers_gathered_around_looking_in_9545941e-3bbf-46e0-ac02-84c6fb6e6f89-1.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-03-24T21:36:24+00:00\" datetime=\"2025-03-24T21:36:24+00:00\"\u003eMarch 24, 2025 2:36 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2025/03/cfr0z3n_surreal_image_of_researchers_gathered_around_looking_in_9545941e-3bbf-46e0-ac02-84c6fb6e6f89-1.png?w=750\" alt=\"People gather to look at a wall popping with surreal distorted light and text shapes in blue with a spot of red\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://www.midjourney.com/home\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMidjourney\u003c/a\u003e is best known as one of the leading AI image generators — with nearly 20 million users on its Discord channel,\u003ca href=\"https://www.demandsage.com/midjourney-statistics/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e according to third-party trackers\u003c/a\u003e, and presumably more atop that on its website — but its ambitions are beginning to expand. \u003c/p\u003e\n\n\n\n\u003cp\u003eFollowing the \u003ca href=\"https://venturebeat.com/ai/midjourney-announces-hardware-team-and-opens-to-applicants/\"\u003enews in late summer 2024\u003c/a\u003e that it was building its own computing and AI hardware, the company this week released a new research paper alongside machine learning experts at New York University (NYU) on training text-based large language models (LLMs) such as Meta’s open source Llama and Mistral’s eponymous source models to write more creatively. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe collaboration, documented in a \u003ca href=\"https://huggingface.co/papers/2503.17126\" target=\"_blank\" rel=\"noreferrer noopener\"\u003enew research paper\u003c/a\u003e published on AI code community Hugging Face, introduces two new technieques — Diversified Direct Preference Optimization (DDPO) and Diversified Odds Ratio Preference Optimization (DORPO)— designed to expand the range of possible outputs while maintaining coherence and readability.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor a company that is best known for its diffusion AI image generating models, Midjourney’s new approach to rethinking creativity in text-based LLMs shows that it is not limiting its ambitions to visuals, and that, a picture may not actually be worth a thousand words. \u003c/p\u003e\n\n\n\n\u003cp\u003eCould a Midjourney-native LLM or fine-tuned version of an existing LLM be in the cards from the small, bootstrapped startup? I reached out to Midjourney founder David Holz but have yet to hear back.\u003c/p\u003e\n\n\n\n\u003cp\u003eRegardless of a first-party Midjourney LLM offering, the implications of its new research go beyond academic exercises and could be used to help fuel a new wave of LLM training among enterprise AI teams, product developers, and content creators looking to improve AI-generated text.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt also shows that despite recent interest and investment among AI model providers in new multimodal and reasoning language models, there’s still a lot of juice left to be squeezed, cognitively and performance-wise, from classic Transformer-based, text-focused LLMs.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-problem-ai-generated-writing-collapses-around-homogenous-outputs\"\u003eThe problem: AI-generated writing collapses around homogenous outputs\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn domains like fact-based Q\u0026amp;A or coding assistance, LLMs are expected to generate a single best response. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, creative writing is inherently open-ended, meaning there are many valid responses to a single prompt.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor an example provided by the Midjourney researchers, given a prompt like \u003cem\u003e“Write a story about a dog on the moon”\u003c/em\u003e, the LLM could explore multiple diverse paths like:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eAn astronaut’s pet dog accidentally left behind after a lunar mission.\u003c/li\u003e\n\n\n\n\u003cli\u003eA dog who finds itself in a futuristic canine space colony.\u003c/li\u003e\n\n\n\n\u003cli\u003eA stranded dog that befriends an alien species.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eDespite this range of possibilities, instruction-tuned LLMs often converge on similar storylines and themes. This happens because:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003ePost-training techniques prioritize user preference over originality, reinforcing popular but repetitive responses.\u003c/li\u003e\n\n\n\n\u003cli\u003eInstruction tuning often smooths out variation, making models favor “safe” responses over unique ones.\u003c/li\u003e\n\n\n\n\u003cli\u003eExisting diversity-promoting techniques (like temperature tuning) operate only at inference time, rather than being baked into the model’s learning process.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eThis leads to homogenized storytelling, where AI-generated creative writing feels repetitive and lacks surprise or depth.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-solution-modifying-post-training-methods-to-prioritize-diversity\"\u003eThe solution: modifying post-training methods to prioritize diversity\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo overcome these limitations, the researchers introduced DDPO and DORPO, two extensions of existing preference optimization methods. The core innovation in these approaches is the use of deviation—a measure of how much a response differs from others—to guide training.\u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s how it works:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eDuring training, the model is given a writing prompt and multiple possible responses.\u003c/li\u003e\n\n\n\n\u003cli\u003eEach response is compared to others for the same prompt, and a deviation score is calculated.\u003c/li\u003e\n\n\n\n\u003cli\u003eRare but high-quality responses are weighted more heavily in training, encouraging the model to learn from diverse examples.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eBy incorporating deviation into Direct Preference Optimization (DPO) and Odds Ratio Preference Optimization (ORPO), the model learns to produce high-quality but more varied responses.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis method ensures that AI-generated stories do not converge on a single predictable structure, but instead explore a wider range of characters, settings, and themes—just as a human writer might.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-midjourney-s-researchers-did-to-achieve-this\"\u003eWhat Midjourney’s researchers did to achieve this\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe study involved training LLMs on creative writing tasks using a dataset from the subreddit r/writingPrompts, a Reddit community where users post prompts and respond with short stories.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe researchers used two base models for their training:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMeta’s Llama-3.1-8B\u003c/strong\u003e (\u003cem\u003ean 8-billion-parameter model from the Llama 3 series\u003c/em\u003e).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eMistral-7B-v0.3\u003c/strong\u003e (\u003cem\u003ea 7-billion-parameter model from Mistral AI\u003c/em\u003e).\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThen, they took these models through the following processes:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eSupervised Fine-Tuning (SFT):\u003c/strong\u003e The models were first fine-tuned using LoRA (Low-Rank Adaptation) to adjust parameters efficiently.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003ePreference Optimization:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDPO and ORPO were used as baselines\u003c/strong\u003e—these standard methods focus on improving response quality based on user preference signals.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eDDPO and DORPO were then applied\u003c/strong\u003e, introducing deviation-based weighting to encourage more unique responses.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eEvaluation:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eAutomatic evaluation: Measured semantic and stylistic diversity using embedding-based techniques.\u003c/li\u003e\n\n\n\n\u003cli\u003eHuman evaluation: Judges assessed whether outputs were diverse and engaging compared to GPT-4o and Claude 3.5.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003ch3 id=\"h-key-training-findings\"\u003e\u003cstrong\u003eKey Training Findings:\u003c/strong\u003e\u003c/h3\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDDPO significantly outperformed standard DPO\u003c/strong\u003e in terms of output diversity while maintaining quality.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eLlama-3.1-8B with DDPO achieved the best balance\u003c/strong\u003e of quality and diversity, producing responses that were \u003cstrong\u003emore varied than GPT-4o\u003c/strong\u003e while maintaining coherence.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eWhen dataset size was reduced\u003c/strong\u003e, DDPO models still maintained diversity, though they required a certain number of diverse training samples to be fully effective.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2 id=\"h-enterprise-implications-what-does-it-mean-for-those-using-ai-to-produce-creative-responses-such-as-in-marketing-copywriting-corporate-storytelling-and-film-tv-video-game-scripting\"\u003eEnterprise implications: what does it mean for those using AI to produce creative responses — such as in marketing copywriting, corporate storytelling, and film/TV/video game scripting?\u003c/h2\u003e\n\n\n\n\u003cp\u003eFor AI teams managing LLM deployment, enhancing output diversity while maintaining quality is a critical challenge. These findings have significant implications for organizations that rely on AI-generated content in applications such as:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eConversational AI and chatbots\u003c/strong\u003e (ensuring varied and engaging responses).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eContent marketing and storytelling tools\u003c/strong\u003e (preventing repetitive AI-generated copy).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eGame development and narrative design\u003c/strong\u003e (creating diverse dialogue and branching storylines).\u003c/li\u003e\n\n\n\n\u003cli\u003e\n\u003c/li\u003e\u003c/ul\u003e\n\n\n\n\u003cp\u003eFor professionals responsible for fine-tuning and deploying models in an enterprise setting, this research provides:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eA new approach to LLM post-training that enhances creativity without sacrificing quality.\u003c/li\u003e\n\n\n\n\u003cli\u003eA practical alternative to inference-time diversity tuning (such as temperature adjustments) by integrating diversity into the learning process itself.\u003c/li\u003e\n\n\n\n\u003cli\u003eThe potential to develop more engaging AI applications, from AI-assisted writing tools to virtual assistants that can adapt their responses dynamically.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eFor those handling AI model orchestration and automation, this research highlights:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eThe importance of tuning models at the training stage, reducing the need for post-processing adjustments at deployment.\u003c/li\u003e\n\n\n\n\u003cli\u003eA way to introduce adaptive storytelling into AI-driven applications, ensuring variability while keeping content quality high.\u003c/li\u003e\n\n\n\n\u003cli\u003eA method for making LLM outputs more human-like, which is crucial for applications requiring interactive storytelling, customer engagement, or dynamic content creation.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2 id=\"h-the-future-of-ai-generated-creative-projects-looks-bright\"\u003eThe future of AI generated creative projects looks bright\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe success of DDPO and DORPO demonstrates that training LLMs with diversity-focused objectives can yield significant improvements in creative writing. Some ideas include:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eIntegrating deviation-based learning into enterprise AI models\u003c/strong\u003e to enhance response diversity in customer-facing applications.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eExploring how these methods apply to other generative tasks\u003c/strong\u003e, such as AI-powered poetry, screenwriting, or game storytelling.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eDeveloping hybrid training approaches\u003c/strong\u003e that balance \u003cstrong\u003ediversity and instruction-following capabilities\u003c/strong\u003e for AI assistants.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eFor those interested in applying these techniques, the researchers plan to make their code publicly available on this \u003ca href=\"https://github.com/mj-storytelling/DiversityTuning\"\u003eGitHub Repository\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWhether you are fine-tuning LLMs for business applications or optimizing large-scale AI orchestration, this study provides actionable insights into how models can be more dynamic, engaging, and responsive to creative tasks.\u003c/p\u003e\n\n\n\n\u003cp\u003eBy adopting these techniques, AI teams can move beyond rigid, formulaic outputs—building AI systems that are not only smart but also truly imaginative.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-03-24T21:36:24Z",
  "modifiedTime": "2025-03-24T21:37:03Z"
}
