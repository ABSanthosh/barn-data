{
  "id": "43d8de31-cda2-473e-b33f-960e2a57beb9",
  "title": "AGI is coming faster than we think — we must get ready now",
  "link": "https://venturebeat.com/ai/agi-is-coming-faster-than-we-think-we-must-get-ready-now/",
  "description": "As we are on the brink of breakthroughs in AGI and superintelligence, we need to assess whether we are truly ready for this transformation.",
  "author": "Gary Grossman, Edelman",
  "published": "Sun, 10 Nov 2024 20:15:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "artificial general intelligence",
    "category-/People \u0026 Society/Subcultures \u0026 Niche Interests",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "NLP",
    "superintelligence"
  ],
  "byline": "Gary Grossman, Edelman",
  "length": 8253,
  "excerpt": "As we are on the brink of breakthroughs in AGI and superintelligence, we need to assess whether we are truly ready for this transformation.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "November 10, 2024 12:15 PM Dall-E 3/Gary Grossman Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Leading figures in AI, including Anthropic’s Dario Amodei and OpenAI’s Sam Altman, suggest that “powerful AI” or even superintelligence could appear within the next two to 10 years, potentially reshaping our world. In his recent essay Machines of Loving Grace, Amodei provides a thoughtful exploration of AI’s potential, suggesting that powerful AI — what others have termed artificial general intelligence (AGI) — could be achieved as early as 2026. Meanwhile, in The Intelligence Age, Altman writes that “it is possible that we will have superintelligence in a few thousand days,” (or by 2034). If they are correct, sometime in the next two to 10 years, the world will dramatically change. As leaders in AI research and development, Amodei and Altman are at the forefront of pushing boundaries for what is possible, making their insights particularly influential as we look to the future. Amodei defines powerful AI as “smarter than a Nobel Prize winner across most relevant fields — biology, programming, math, engineering, writing…” Altman does not explicitly define superintelligence in his essay, although it is understood to be AI systems that surpass human intellectual capabilities across all domains.  Not everyone shares this optimistic timeline, although these less sanguine viewpoints have not dampened enthusiasm among tech leaders. For example, OpenAI co-founder Ilya Sutskever is now a co-founder of Safe Superintelligence (SSI), a startup dedicated to advancing AI with a safety-first approach. When announcing SSI last June, Sutskever said: “We will pursue safe superintelligence in a straight shot, with one focus, one goal and one product.” Speaking about AI advances a year ago when still at OpenAI, he noted: “It’s going to be monumental, earth-shattering. There will be a before and an after.” In his new capacity at SSI, Sutskever has already raised a billion dollars to fund company efforts. These forecasts align with Elon Musk’s estimate that AI will outperform all of humanity by 2029. Musk recently said that AI would be able to do anything any human can do within the next year or two. He added that AI would be able to do what all humans combined can do in a further three years, in 2028 or 2029. These predictions are also consistent with the long-standing view from futurist Ray Kurzweil that AGI would be achieved by 2029. Kurzweil made this prediction as far back as 1995 and wrote about this in this best-selling 2005 book, “The Singularity Is Near.”  Futurist Ray Kurzweil stands by his prediction of AGI by 2029. The imminent transformation As we are on the brink of these potential breakthroughs, we need to assess whether we are truly ready for this transformation. Ready or not, if these predictions are right, a fundamentally new world will soon arrive.  A child born today could enter kindergarten in a world transformed by AGI. Will AI caregivers be far behind? Suddenly, the futuristic vision from Kazuo Ishiguro in “Klara and the Sun” of an android artificial friend for those children when they reach their teenage years does not seem so farfetched. The prospect of AI companions and caregivers suggests a world with profound ethical and societal shifts, one that might challenge our existing frameworks. Beyond companions and caregivers, the implications of these technologies are unprecedented in human history, offering both revolutionary promise and existential risk. The potential upsides that could come from powerful AI are profound. Beyond robotic advances this could include developing cures for cancer and depression to finally achieving fusion energy. Some see this coming epoch as an era of abundance with people having new opportunities for creativity and connection. However, the plausible downsides are equally momentous, from vast unemployment and income inequality to runaway autonomous weapons.  In the near term, MIT Sloan principal research scientist Andrew McAfee sees AI as enhancing rather than replacing human jobs. On a recent Pivot podcast, he argued that AI provides “an army of clerks, colleagues and coaches” available on demand, even as it sometimes takes on “big chunks” of jobs.  But this measured view of AI’s impact may have an end date. Elon Musk said that in the longer term, “probably none of us will have a job.” This stark contrast highlights a crucial point: Whatever seems true about AI’s capabilities and impacts in 2024 may be radically different in the AGI world that could be just several years away. Tempering expectations: Balancing optimism with reality Despite these ambitious forecasts, not everyone agrees that powerful AI is on the near horizon or that its effects will be so straightforward. Deep learning skeptic Gary Marcus has been warning for some time that the current AI technologies are not capable of AGI, arguing that the technology lacks the needed deep reasoning skills. He famously took aim at Musk’s recent prediction of AI soon being smarter than any human and offered $1 million to prove him wrong. Linus Torvalds, creator and lead developer of the Linux operating system, said recently that he thought AI would change the world but currently is “90% marketing and 10% reality.” He suggested that for now, AI may be more hype than substance. Perhaps lending credence to Torvald’s assertion is a new paper from OpenAI that shows their leading frontier large language models (LLM) including GPT-4o and o1 struggling to answer simple questions for which there are factual answers. The paper describes a new “SimpleQA” benchmark “to measure the factuality of language models.” The best performer is o1-preview, but it produced incorrect answers to half of the questions.  Performance of frontier LLMs on new SimpleQA benchmark from OpenAI. Source: Introducing SimpleQA. Looking ahead: Readiness for the AI era Optimistic predictions about the potential of AI contrast with the technology’s present state as shown in benchmarks like SimpleQA. These limitations suggest that while the field is progressing quickly, some significant breakthroughs are needed to achieve true AGI.  Nevertheless, those closest to the developing AI technology foresee rapid advancement. On a recent Hard Fork podcast, OpenAI’s former senior adviser for AGI readiness Miles Brundage said: “I think most people who know what they’re talking about agree [AGI] will go pretty quickly and what does that mean for society is not something that can even necessarily be predicted.” Brundage added: “I think that retirement will come for most people sooner than they think…” Amara’s Law, coined in 1973 by Stanford’s Roy Amara, says that we often overestimate new technology’s short-term impact while underestimating its long-term potential. While AGI’s actual arrival timeline may not match the most aggressive predictions, its eventual emergence, perhaps in only a few years, could reshape society more profoundly than even today’s optimists envision.  However, the gap between current AI capabilities and true AGI is still significant. Given the stakes involved — from revolutionary medical breakthroughs to existential risks — this buffer is valuable. It offers crucial time to develop safety frameworks, adapt our institutions and prepare for a transformation that will fundamentally alter human experience. The question is not only when AGI will arrive, but also whether we will be ready for it when it does. Gary Grossman is EVP of technology practice at Edelman and global lead of the Edelman AI Center of Excellence. DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2024/11/image1-transformed.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-11-10T20:15:00+00:00\" datetime=\"2024-11-10T20:15:00+00:00\"\u003eNovember 10, 2024 12:15 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"429\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image1-transformed.png?w=750\" alt=\"Dall-E 3/Gary Grossman\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eDall-E 3/Gary Grossman\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eLeading figures in AI, including Anthropic’s Dario Amodei and OpenAI’s Sam Altman, suggest that “powerful AI” or even superintelligence could appear within the next two to 10 years, potentially reshaping our world.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn his recent essay \u003ca href=\"https://darioamodei.com/machines-of-loving-grace\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003eMachines of Loving Grace\u003c/em\u003e\u003c/a\u003e, Amodei provides a thoughtful exploration of AI’s potential, suggesting that powerful AI — what others have termed artificial general intelligence (AGI) — could be achieved as early as 2026. Meanwhile, in \u003ca href=\"https://ia.samaltman.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003eThe Intelligence Age\u003c/em\u003e\u003c/a\u003e, Altman writes that “it is possible that we will have superintelligence in a few thousand days,” (or by 2034). If they are correct, sometime in the next two to 10 years, the world will dramatically change.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs leaders in AI research and development, Amodei and Altman are at the forefront of pushing boundaries for what is possible, making their insights particularly influential as we look to the future. Amodei defines \u003ca href=\"https://venturebeat.com/ai/here-are-3-critical-llm-compression-strategies-to-supercharge-ai-performance/\"\u003epowerful AI\u003c/a\u003e as “smarter than a Nobel Prize winner across most relevant fields — biology, programming, math, engineering, writing…” Altman does not explicitly define superintelligence in his essay, although it is understood to be AI systems that surpass human intellectual capabilities across all domains. \u003c/p\u003e\n\n\n\n\u003cp\u003eNot everyone shares this optimistic timeline, although these less sanguine viewpoints have not dampened enthusiasm among tech leaders. For example, OpenAI co-founder Ilya Sutskever is now a co-founder of Safe Superintelligence (SSI), a startup dedicated to advancing AI with a safety-first approach. When \u003ca href=\"https://www.cnbc.com/2024/06/19/openai-co-founder-ilya-sutskever-announces-safe-superintelligence.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eannouncing\u003c/a\u003e SSI last June, Sutskever said: “We will pursue safe superintelligence in a straight shot, with one focus, one goal and one product.” \u003ca href=\"https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSpeaking about AI advances a year ago\u003c/a\u003e when still at OpenAI, he noted: “It’s going to be monumental, earth-shattering. There will be a before and an after.” In his new capacity at SSI, Sutskever has already \u003ca href=\"https://venturebeat.com/ai/ex-openai-co-founders-new-safe-superintelligence-startup-raises-1b-in-three-months/\"\u003eraised a billion dollars\u003c/a\u003e to fund company efforts.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese forecasts align with Elon Musk’s estimate that AI will outperform all of humanity by 2029. Musk \u003ca href=\"https://newatlas.com/ai-humanoids/elon-musk-diamandis-ai-humanity/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003erecently said\u003c/a\u003e that AI would be able to do anything any human can do within the next year or two. He added that AI would be able to do what all humans combined can do in a further three years, in 2028 or 2029. These predictions are also consistent with the long-standing view from futurist Ray Kurzweil that AGI would be achieved by 2029. Kurzweil made this prediction as far back as 1995 and wrote about this in this best-selling 2005 book, “\u003ca href=\"https://www.penguinrandomhouse.com/books/291221/the-singularity-is-near-by-ray-kurzweil/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eThe Singularity Is Near\u003c/a\u003e.” \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cp\u003e\n\u003ciframe title=\"AGI will Happen by 2029 | MOONSHOTS\" width=\"500\" height=\"281\" src=\"https://www.youtube.com/embed/J-faYgAoshI?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\n\u003c/p\u003e\u003cfigcaption\u003e\u003cem\u003eFuturist Ray Kurzweil stands by his prediction of AGI by 2029.\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-the-imminent-transformation\"\u003eThe imminent transformation\u003c/h2\u003e\n\n\n\n\u003cp\u003eAs we are on the brink of these potential breakthroughs, we need to assess whether we are truly ready for this transformation. Ready or not, if these predictions are right, a fundamentally new world will soon arrive. \u003c/p\u003e\n\n\n\n\u003cp\u003eA child born today could enter kindergarten in a world transformed by AGI. Will AI caregivers be far behind? Suddenly, the futuristic vision from Kazuo Ishiguro in “\u003ca href=\"https://www.penguinrandomhouse.com/books/653825/klara-and-the-sun-a-gma-book-club-pick-by-kazuo-ishiguro/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eKlara and the Sun\u003c/a\u003e” of an android artificial friend for those children when they reach their teenage years does not seem so farfetched. The prospect of AI companions and caregivers suggests a world with profound ethical and societal shifts, one that might challenge our existing frameworks.\u003c/p\u003e\n\n\n\n\u003cp\u003eBeyond companions and caregivers, the implications of these technologies are unprecedented in human history, offering both revolutionary promise and existential risk. The potential upsides that could come from \u003ca href=\"https://venturebeat.com/ai/enter-the-whisperverse-how-ai-voice-agents-will-guide-us-through-our-days/\"\u003epowerful AI are profound\u003c/a\u003e. Beyond robotic advances this could include developing cures for cancer and depression to finally achieving fusion energy. Some see this coming epoch as an \u003ca href=\"https://a16z.com/how-ai-will-usher-in-an-era-of-abundance/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eera of abundance\u003c/a\u003e with people having new opportunities for creativity and connection. However, the plausible downsides are equally momentous, from vast unemployment and income inequality to runaway autonomous weapons. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn the near term, MIT Sloan principal research scientist Andrew McAfee sees AI as enhancing rather than replacing human jobs. On a recent \u003ca href=\"https://podcasts.voxmedia.com/show/pivot\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ePivot podcast\u003c/a\u003e, he argued that AI provides “an army of clerks, colleagues and coaches” available on demand, even as it sometimes takes on “big chunks” of jobs. \u003c/p\u003e\n\n\n\n\u003cp\u003eBut this measured view of AI’s impact may have an end date. Elon Musk \u003ca href=\"https://www.cnn.com/2024/05/23/tech/elon-musk-ai-your-job/index.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003esaid\u003c/a\u003e that in the longer term, “probably none of us will have a job.” This stark contrast highlights a crucial point: Whatever seems true about AI’s capabilities and impacts in 2024 may be radically different in the AGI world that could be just several years away.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-tempering-expectations-balancing-optimism-with-reality\"\u003eTempering expectations: Balancing optimism with reality\u003c/h2\u003e\n\n\n\n\u003cp\u003eDespite these ambitious forecasts, not everyone agrees that powerful AI is on the near horizon or that its effects will be so straightforward. Deep learning skeptic Gary Marcus has been warning for some time that the current AI technologies are not capable of AGI, arguing that the technology lacks the needed deep reasoning skills. He famously took aim at Musk’s recent prediction of AI soon being smarter than any human and offered $1 million to prove him wrong.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"691\" height=\"628\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image2_ad0756.png?w=660\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image2_ad0756.png 691w, https://venturebeat.com/wp-content/uploads/2024/11/image2_ad0756.png?resize=300,273 300w, https://venturebeat.com/wp-content/uploads/2024/11/image2_ad0756.png?resize=660,600 660w, https://venturebeat.com/wp-content/uploads/2024/11/image2_ad0756.png?resize=400,364 400w, https://venturebeat.com/wp-content/uploads/2024/11/image2_ad0756.png?resize=578,525 578w\" sizes=\"(max-width: 691px) 100vw, 691px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eLinus Torvalds, creator and lead developer of the Linux operating system, \u003ca href=\"https://www.tomshardware.com/tech-industry/artificial-intelligence/linus-torvalds-reckons-ai-is-90-percent-marketing-and-10-percent-reality\" target=\"_blank\" rel=\"noreferrer noopener\"\u003esaid recently\u003c/a\u003e that he thought AI would change the world but currently is “90% marketing and 10% reality.” He suggested that for now, AI may be more hype than substance.\u003c/p\u003e\n\n\n\n\u003cp\u003ePerhaps lending credence to Torvald’s assertion is a \u003ca href=\"https://openai.com/index/introducing-simpleqa/?utm_source=tldrai\" target=\"_blank\" rel=\"noreferrer noopener\"\u003enew paper\u003c/a\u003e from OpenAI that shows their leading frontier large language models (LLM) including GPT-4o and o1 struggling to answer simple questions for which there are factual answers. The paper describes a new “SimpleQA” benchmark “to measure the factuality of language models.” The best performer is o1-preview, but it produced incorrect answers to half of the questions. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"736\" height=\"750\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image4.png?w=589\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image4.png 736w, https://venturebeat.com/wp-content/uploads/2024/11/image4.png?resize=300,306 300w, https://venturebeat.com/wp-content/uploads/2024/11/image4.png?resize=589,600 589w, https://venturebeat.com/wp-content/uploads/2024/11/image4.png?resize=52,52 52w, https://venturebeat.com/wp-content/uploads/2024/11/image4.png?resize=400,408 400w, https://venturebeat.com/wp-content/uploads/2024/11/image4.png?resize=578,589 578w\" sizes=\"(max-width: 736px) 100vw, 736px\"/\u003e\u003cfigcaption\u003e\u003cem\u003ePerformance of frontier LLMs on new SimpleQA benchmark from OpenAI. Source: \u003ca href=\"https://openai.com/index/introducing-simpleqa/?utm_source=tldrai\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eIntroducing SimpleQA\u003c/a\u003e.\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-looking-ahead-readiness-for-the-ai-era\"\u003eLooking ahead: Readiness for the AI era\u003c/h2\u003e\n\n\n\n\u003cp\u003eOptimistic predictions about the potential of AI contrast with the technology’s present state as shown in benchmarks like SimpleQA. These limitations suggest that while the field is progressing quickly, some significant breakthroughs are needed to achieve true AGI. \u003c/p\u003e\n\n\n\n\u003cp\u003eNevertheless, those closest to the developing AI technology foresee rapid advancement. On a recent \u003ca href=\"https://www.nytimes.com/2024/11/01/podcasts/billionaire-game-theory-we-are-not-ready-for-agi-election-betting-markets-get-weird.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHard Fork podcast\u003c/a\u003e, OpenAI’s former senior adviser for AGI readiness \u003ca href=\"https://www.milesbrundage.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMiles Brundage\u003c/a\u003e said: “I think most people who know what they’re talking about agree [AGI] will go pretty quickly and what does that mean for society is not something that can even necessarily be predicted.” Brundage added: “I think that retirement will come for most people sooner than they think…”\u003c/p\u003e\n\n\n\n\u003cp\u003eAmara’s Law, coined in 1973 by Stanford’s Roy Amara, says that we often overestimate new technology’s short-term impact while underestimating its long-term potential. While AGI’s actual arrival timeline may not match the most aggressive predictions, its eventual emergence, perhaps in only a few years, could reshape society more profoundly than even today’s optimists envision. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, the gap between current AI capabilities and true AGI is still significant. Given the stakes involved — from revolutionary medical breakthroughs to existential risks — this buffer is valuable. It offers crucial time to develop safety frameworks, adapt our institutions and prepare for a transformation that will fundamentally alter human experience. The question is not only when AGI will arrive, but also whether we will be ready for it when it does.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eGary Grossman is EVP of technology practice at \u003ca href=\"https://www.edelman.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eEdelman\u003c/a\u003e and global lead of the Edelman AI Center of Excellence. \u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2024-11-10T20:15:00Z",
  "modifiedTime": "2024-11-11T00:33:39Z"
}
