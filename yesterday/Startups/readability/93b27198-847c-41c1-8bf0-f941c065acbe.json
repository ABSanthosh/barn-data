{
  "id": "93b27198-847c-41c1-8bf0-f941c065acbe",
  "title": "The end of AI scaling may not be nigh: Here’s what’s next",
  "link": "https://venturebeat.com/ai/the-end-of-ai-scaling-may-not-be-nigh-heres-whats-next/",
  "description": "Here's why the AI field is poised for continued breakthroughs through new methodologies and creative engineering.",
  "author": "Gary Grossman, Edelman",
  "published": "Sun, 01 Dec 2024 20:15:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "ai",
    "AI, ML and Deep Learning",
    "category-/Computers \u0026 Electronics",
    "category-/Science",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "NLP",
    "scaling",
    "scaling AI"
  ],
  "byline": "Gary Grossman, Edelman",
  "length": 9312,
  "excerpt": "Here's why the AI field is poised for continued breakthroughs through new methodologies and creative engineering.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "December 1, 2024 12:15 PM Grossman/Dall-E Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More As AI systems achieve superhuman performance in increasingly complex tasks, the industry is grappling with whether bigger models are even possible — or if innovation must take a different path. The general approach to large language model (LLM) development has been that bigger is better, and that performance scales with more data and more computing power. However, recent media discussions have focused on how LLMs are approaching their limits. “Is AI hitting a wall?” The Verge questioned, while Reuters reported that “OpenAI and others seek new path to smarter AI as current methods hit limitations.”  The concern is that scaling, which has driven advances for years, may not extend to the next generation of models. Reporting suggests that the development of frontier models like GPT-5, which push the current limits of AI, may face challenges due to diminishing performance gains during pre-training. The Information reported on these challenges at OpenAI and Bloomberg covered similar news at Google and Anthropic.  This issue has led to concerns that these systems may be subject to the law of diminishing returns — where each added unit of input yields progressively smaller gains. As LLMs grow larger, the costs of getting high-quality training data and scaling infrastructure increase exponentially, reducing the returns on performance improvement in new models. Compounding this challenge is the limited availability of high-quality new data, as much of the accessible information has already been incorporated into existing training datasets.  This does not mean the end of performance gains for AI. It simply means that to sustain progress, further engineering is needed through innovation in model architecture, optimization techniques and data use. Learning from Moore’s Law A similar pattern of diminishing returns appeared in the semiconductor industry. For decades, the industry had benefited from Moore’s Law, which predicted that the number of transistors would double every 18 to 24 months, driving dramatic performance improvements through smaller and more efficient designs. This too eventually hit diminishing returns, beginning somewhere between 2005 and 2007 due to Dennard Scaling — the principle that shrinking transistors also reduces power consumption— having hit its limits which fueled predictions of the death of Moore’s Law. I had a close up view of this issue when I worked with AMD from 2012-2022. This problem did not mean that semiconductors — and by extension computer processors — stopped achieving performance improvements from one generation to the next. It did mean that improvements came more from chiplet designs, high-bandwidth memory, optical switches, more cache memory and accelerated computing architecture rather than the scaling down of transistors. New paths to progress Similar phenomena are already being observed with current LLMs. Multimodal AI models like GPT-4o, Claude 3.5 and Gemini 1.5 have proven the power of integrating text and image understanding, enabling advancements in complex tasks like video analysis and contextual image captioning. More tuning of algorithms for both training and inference will lead to further performance gains. Agent technologies, which enable LLMs to perform tasks autonomously and coordinate seamlessly with other systems, will soon significantly expand their practical applications. Future model breakthroughs might arise from one or more hybrid AI architecture designs combining symbolic reasoning with neural networks. Already, the o1 reasoning model from OpenAI shows the potential for model integration and performance extension. While only now emerging from its early stage of development, quantum computing holds promise for accelerating AI training and inference by addressing current computational bottlenecks. The perceived scaling wall is unlikely to end future gains, as the AI research community has consistently proven its ingenuity in overcoming challenges and unlocking new capabilities and performance advances.  In fact, not everyone agrees that there even is a scaling wall. OpenAI CEO Sam Altman was succinct in his views: “There is no wall.” Source: X https://x.com/sama/status/1856941766915641580  Speaking on the “Diary of a CEO” podcast, ex-Google CEO and co-author of Genesis Eric Schmidt essentially agreed with Altman, saying he does not believe there is a scaling wall — at least there won’t be one over the next five years. “In five years, you’ll have two or three more turns of the crank of these LLMs. Each one of these cranks looks like it’s a factor of two, factor of three, factor of four of capability, so let’s just say turning the crank on all these systems will get 50 times or 100 times more powerful,” he said. Leading AI innovators are still optimistic about the pace of progress, as well as the potential for new methodologies. This optimism is evident in a recent conversation on “Lenny’s Podcast” with OpenAI’s CPO Kevin Weil and Anthropic CPO Mike Krieger. Source: https://www.youtube.com/watch?v=IxkvVZua28k  In this discussion, Krieger described that what OpenAI and Anthropic are working on today “feels like magic,” but acknowledged that in just 12 months, “we’ll look back and say, can you believe we used that garbage? … That’s how fast [AI development] is moving.”  It’s true — it does feel like magic, as I recently experienced when using OpenAI’s Advanced Voice Mode. Speaking with ‘Juniper’ felt entirely natural and seamless, showcasing how AI is evolving to understand and respond with emotion and nuance in real-time conversations. Krieger also discusses the recent o1 model, referring to this as “a new way to scale intelligence, and we feel like we’re just at the very beginning.” He added: “The models are going to get smarter at an accelerating rate.”  These expected advancements suggest that while traditional scaling approaches may or may not face diminishing returns in the near-term, the AI field is poised for continued breakthroughs through new methodologies and creative engineering. Does scaling even matter? While scaling challenges dominate much of the current discourse around LLMs, recent studies suggest that current models are already capable of extraordinary results, raising a provocative question of whether more scaling even matters. A recent study forecasted that ChatGPT would help doctors make diagnoses when presented with complicated patient cases. Conducted with an early version of GPT-4, the study compared ChatGPT’s diagnostic capabilities against those of doctors with and without AI help. A surprising outcome revealed that ChatGPT alone substantially outperformed both groups, including doctors using AI aid. There are several reasons for this, from doctors’ lack of understanding of how to best use the bot to their belief that their knowledge, experience and intuition were inherently superior. This is not the first study that shows bots achieving superior results compared to professionals. VentureBeat reported on a study earlier this year which showed that LLMs can conduct financial statement analysis with accuracy rivaling — and even surpassing — that of professional analysts. Also using GPT-4, another goal was to predict future earnings growth. GPT-4 achieved 60% accuracy in predicting the direction of future earnings, notably higher than the 53 to 57% range of human analyst forecasts. Notably, both these examples are based on models that are already out of date. These outcomes underscore that even without new scaling breakthroughs, existing LLMs are already capable of outperforming experts in complex tasks, challenging assumptions about the necessity of further scaling to achieve impactful results.  Scaling, skilling or both These examples show that current LLMs are already highly capable, but scaling alone may not be the sole path forward for future innovation. But with more scaling possible and other emerging techniques promising to improve performance, Schmidt’s optimism reflects the rapid pace of AI advancement, suggesting that in just five years, models could evolve into polymaths, seamlessly answering complex questions across multiple fields.  Whether through scaling, skilling or entirely new methodologies, the next frontier of AI promises to transform not just the technology itself, but its role in our lives. The challenge ahead is ensuring that progress remains responsible, equitable and impactful for everyone. Gary Grossman is EVP of technology practice at Edelman and global lead of the Edelman AI Center of Excellence. DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2024/11/image1_4b1294.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-12-01T20:15:00+00:00\" datetime=\"2024-12-01T20:15:00+00:00\"\u003eDecember 1, 2024 12:15 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"229\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image1_4b1294.png?w=400\" alt=\"Grossman/Dall-E\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eGrossman/Dall-E\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eAs AI systems achieve \u003ca href=\"https://venturebeat.com/ai/agi-is-coming-faster-than-we-think-we-must-get-ready-now/\"\u003esuperhuman performance\u003c/a\u003e in increasingly complex tasks, the industry is grappling with whether bigger models are even possible — or if innovation must take a different path.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe general approach to large language model (LLM) development has been that bigger is better, and that performance scales with more data and more computing power. However, recent media discussions have focused on how LLMs are approaching their limits. “\u003ca href=\"https://www.theverge.com/2024/11/22/24303470/ai-model-llm-progress-hitting-scaling-wall\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eIs AI hitting a wall?\u003c/a\u003e” \u003cem\u003eThe Verge\u003c/em\u003e questioned, while \u003cem\u003eReuters \u003c/em\u003e\u003ca href=\"https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/?ref=platformer.news\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ereported\u003c/a\u003e that “OpenAI and others seek new path to smarter AI as current methods hit limitations.” \u003c/p\u003e\n\n\n\n\u003cp\u003eThe concern is that scaling, which has driven advances for years, may not extend to the next generation of models. Reporting suggests that the development of frontier models like GPT-5, which push the current limits of AI, may face challenges due to diminishing performance gains during pre-training. \u003ca href=\"https://www.theinformation.com/articles/openai-shifts-strategy-as-rate-of-gpt-ai-improvements-slows\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003eThe Information\u003c/em\u003e\u003c/a\u003e reported on these challenges at OpenAI and \u003ca href=\"https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003eBloomberg\u003c/em\u003e covered\u003c/a\u003e similar news at Google and Anthropic. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis issue has led to concerns that these systems may be subject to the law of diminishing returns — where each added unit of input yields progressively smaller gains. As LLMs grow larger, the costs of getting high-quality training data and scaling infrastructure increase exponentially, reducing the returns on performance improvement in new models. Compounding this challenge is the limited availability of high-quality new data, as much of the accessible information has already been incorporated into existing training datasets. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis does not mean the end of \u003ca href=\"https://venturebeat.com/ai/our-brains-are-vector-databases-heres-why-thats-helpful-when-using-ai/\"\u003eperformance gains for AI\u003c/a\u003e. It simply means that to sustain progress, further engineering is needed through innovation in model architecture, optimization techniques and data use.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-learning-from-moore-s-law\"\u003eLearning from Moore’s Law\u003c/h2\u003e\n\n\n\n\u003cp\u003eA similar pattern of diminishing returns appeared in the semiconductor industry. For decades, the industry had benefited from Moore’s Law, which predicted that the number of transistors would double every 18 to 24 months, driving dramatic performance improvements through smaller and more efficient designs. This too eventually hit diminishing returns, beginning somewhere \u003ca href=\"https://www.nextplatform.com/2019/06/18/dennard-scaling-demise-puts-permanent-dent-in-supercomputing/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ebetween 2005 and 2007\u003c/a\u003e due to \u003ca href=\"https://semiengineering.com/chip-design-shifts-as-fundamental-laws-run-out-of-steam/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eDennard Scaling\u003c/a\u003e — the principle that shrinking transistors also reduces power consumption— having hit its limits which fueled predictions of the \u003ca href=\"https://www.digitaltrends.com/computing/death-of-moores-law-starting-to-stink/#dt-heading-creative-solutions\" target=\"_blank\" rel=\"noreferrer noopener\"\u003edeath of Moore’s Law\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eI had a close up view of this issue when I worked with AMD from 2012-2022. This problem did not mean that semiconductors — and by extension computer processors — stopped achieving performance improvements from one generation to the next. It did mean that improvements came more from chiplet designs, high-bandwidth memory, optical switches, more cache memory and accelerated computing architecture rather than the scaling down of transistors.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-new-paths-to-progress\"\u003eNew paths to progress\u003c/h2\u003e\n\n\n\n\u003cp\u003eSimilar phenomena are already being observed with \u003ca href=\"https://venturebeat.com/ai/getting-started-with-ai-agents-part-1-capturing-processes-roles-and-connections/\"\u003ecurrent LLMs\u003c/a\u003e. Multimodal AI models like GPT-4o, Claude 3.5 and Gemini 1.5 have proven the power of integrating text and image understanding, enabling advancements in complex tasks like video analysis and contextual image captioning. More tuning of algorithms for both training and inference will lead to further performance gains. Agent technologies, which enable LLMs to perform tasks autonomously and coordinate seamlessly with other systems, will soon significantly expand their practical applications.\u003c/p\u003e\n\n\n\n\u003cp\u003eFuture model breakthroughs might arise from one or more hybrid AI architecture designs combining symbolic reasoning with neural networks. Already, the o1 reasoning model from OpenAI shows the potential for model integration and performance extension. While only now emerging from its early stage of development, \u003ca href=\"https://venturebeat.com/security/harvest-now-decrypt-later-why-hackers-are-waiting-for-quantum-computing/\"\u003equantum computing\u003c/a\u003e holds promise for accelerating AI training and inference by addressing current computational bottlenecks.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe perceived scaling wall is unlikely to end future gains, as the AI research community has consistently proven its ingenuity in overcoming challenges and unlocking new capabilities and performance advances. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn fact, not everyone agrees that there even is a scaling wall. OpenAI CEO Sam Altman was succinct in his views: “There is no wall.”\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"874\" height=\"279\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png 874w, https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?resize=300,96 300w, https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?resize=768,245 768w, https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?resize=800,255 800w, https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?resize=400,128 400w, https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?resize=750,239 750w, https://venturebeat.com/wp-content/uploads/2024/11/image3_c2998e.png?resize=578,185 578w\" sizes=\"(max-width: 874px) 100vw, 874px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSource: X \u003ca href=\"https://x.com/sama/status/1856941766915641580\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ehttps://x.com/sama/status/1856941766915641580\u003c/a\u003e \u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eSpeaking on the “\u003ca href=\"https://www.youtube.com/watch?v=2Zg--ouGl7c\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eDiary of a CEO\u003c/a\u003e\u003cem\u003e” \u003c/em\u003epodcast, ex-Google CEO and co-author of \u003ca href=\"https://www.hachettebookgroup.com/titles/henry-a-kissinger/genesis/9781668645093/?lens=little-brown\"\u003e\u003cem\u003eGenesis\u003c/em\u003e\u003c/a\u003e Eric Schmidt essentially agreed with Altman, saying he does not believe there is a scaling wall — at least there won’t be one over the next five years. “In five years, you’ll have two or three more turns of the crank of these LLMs. Each one of these cranks looks like it’s a factor of two, factor of three, factor of four of capability, so let’s just say turning the crank on all these systems will get 50 times or 100 times more powerful,” he said. \u003c/p\u003e\n\n\n\n\u003cp\u003eLeading AI innovators are still optimistic about the pace of progress, as well as the potential for new methodologies. This optimism is evident in a \u003ca href=\"https://www.youtube.com/watch?v=IxkvVZua28k\" target=\"_blank\" rel=\"noreferrer noopener\"\u003erecent conversation\u003c/a\u003e on “\u003ca href=\"https://podcasts.apple.com/us/podcast/lennys-podcast-product-growth-career/id1627920305\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLenny’s Podcast\u003c/a\u003e” with OpenAI’s CPO Kevin Weil and Anthropic CPO Mike Krieger.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"480\" height=\"360\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/image2.jpg\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/image2.jpg 480w, https://venturebeat.com/wp-content/uploads/2024/11/image2.jpg?resize=300,225 300w, https://venturebeat.com/wp-content/uploads/2024/11/image2.jpg?resize=400,300 400w\" sizes=\"(max-width: 480px) 100vw, 480px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSource: \u003ca href=\"https://www.youtube.com/watch?v=IxkvVZua28k\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ehttps://www.youtube.com/watch?v=IxkvVZua28k\u003c/a\u003e \u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIn this discussion, Krieger described that what OpenAI and Anthropic are working on today “feels like magic,” but acknowledged that in just 12 months, “we’ll look back and say, can you believe we used that garbage? … That’s how fast [AI development] is moving.” \u003c/p\u003e\n\n\n\n\u003cp\u003eIt’s true — it does feel like magic, as I recently experienced when using OpenAI’s \u003ca href=\"https://venturebeat.com/ai/openai-finally-brings-humanlike-chatgpt-advanced-voice-mode-to-u-s-plus-team-users/\"\u003eAdvanced Voice Mode\u003c/a\u003e. Speaking with ‘Juniper’ felt entirely natural and seamless, showcasing how AI is evolving to understand and respond with emotion and nuance in real-time conversations.\u003c/p\u003e\n\n\n\n\u003cp\u003eKrieger also discusses the recent o1 model, referring to this as “a new way to scale intelligence, and we feel like we’re just at the very beginning.” He added: “The models are going to get smarter at an accelerating rate.” \u003c/p\u003e\n\n\n\n\u003cp\u003eThese expected advancements suggest that while traditional scaling approaches may or may not face diminishing returns in the near-term, the AI field is poised for continued breakthroughs through new methodologies and creative engineering.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-does-scaling-even-matter\"\u003eDoes scaling even matter?\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile scaling challenges dominate much of the current discourse around LLMs, recent studies suggest that current models are already capable of extraordinary results, raising a provocative question of whether more scaling even matters.\u003c/p\u003e\n\n\n\n\u003cp\u003eA \u003ca href=\"https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html\"\u003erecent study forecasted\u003c/a\u003e that ChatGPT would help doctors make diagnoses when presented with complicated patient cases. Conducted with an early version of GPT-4, the study compared ChatGPT’s diagnostic capabilities against those of doctors with and without AI help. A surprising outcome revealed that ChatGPT alone substantially outperformed both groups, including doctors using AI aid. There are several reasons for this, from doctors’ lack of understanding of how to best use the bot to their belief that their knowledge, experience and intuition were inherently superior.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis is not the first study that shows bots achieving superior results compared to professionals. \u003ca href=\"https://venturebeat.com/ai/the-future-of-financial-analysis-how-gpt-4-is-disrupting-the-industry-according-to-new-research/\"\u003eVentureBeat reported\u003c/a\u003e on a study earlier this year which showed that LLMs can conduct financial statement analysis with accuracy rivaling — and even surpassing — that of professional analysts. Also using GPT-4, another goal was to predict future earnings growth. GPT-4 achieved 60% accuracy in predicting the direction of future earnings, notably higher than the 53 to 57% range of human analyst forecasts.\u003c/p\u003e\n\n\n\n\u003cp\u003eNotably, both these examples are based on models that are already out of date. These outcomes underscore that even without new scaling breakthroughs, existing LLMs are already capable of outperforming experts in complex tasks, challenging assumptions about the necessity of further scaling to achieve impactful results. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-scaling-skilling-or-both\"\u003eScaling, skilling or both\u003c/h2\u003e\n\n\n\n\u003cp\u003eThese examples show that current LLMs are already highly capable, but scaling alone may not be the sole path forward for future innovation. But with more scaling possible and other emerging techniques promising to improve performance, Schmidt’s optimism reflects the rapid pace of AI advancement, suggesting that in just five years, models could evolve into polymaths, seamlessly answering complex questions across multiple fields. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhether through scaling, skilling or entirely new methodologies, the next frontier of AI promises to transform not just the technology itself, but its role in our lives. The challenge ahead is ensuring that progress remains responsible, equitable and impactful for everyone.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eGary Grossman is EVP of technology practice at \u003ca href=\"https://www.edelman.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eEdelman\u003c/a\u003e and global lead of the Edelman AI Center of Excellence.\u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2024-12-01T20:15:00Z",
  "modifiedTime": "2024-11-30T21:35:04Z"
}
