{
  "id": "689209c3-ad06-4667-9ee5-48e6d1e7794f",
  "title": "New open source AI company Deep Cogito releases first models and they’re already topping the charts",
  "link": "https://venturebeat.com/ai/new-open-source-ai-company-deep-cogito-releases-first-models-and-theyre-already-topping-the-charts/",
  "description": "The initial model lineup includes five base sizes: 3 billion, 8 billion, 14 billion, 32 billion, and 70 billion parameters.",
  "author": "Carl Franzen",
  "published": "Tue, 08 Apr 2025 22:01:34 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "ai",
    "AI, ML and Deep Learning",
    "Cogito v1",
    "deep cogito",
    "Google",
    "hybrid models",
    "iterated distillation and amplification (IDA)",
    "large language models",
    "large language models (LLMs)",
    "Large Reasoning Models (LRMs)",
    "LLMs",
    "NLP"
  ],
  "byline": "Carl Franzen",
  "length": 6570,
  "excerpt": "The initial model lineup includes five base sizes: 3 billion, 8 billion, 14 billion, 32 billion, and 70 billion parameters.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "April 8, 2025 3:01 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Deep Cogito, a new AI research startup based in San Francisco, officially emerged from stealth today with Cogito v1, a new line of open source large language models (LLMs) fine-tuned from Meta’s Llama 3.2 and equipped with hybrid reasoning capabilities — the ability to answer quickly and immediately, or “self-reflect” like OpenAI’s “o” series and DeepSeek R1. The company aims to push the boundaries of AI beyond current human-overseer limitations by enabling models to iteratively refine and internalize their own improved reasoning strategies. It’s ultimately on a quest toward developing superintelligence — AI smarter than all humans in all domains — yet the company says that “All models we create will be open sourced.” Deep Cogito’s CEO and co-founder Drishan Arora — a former Senior Software Engineer at Google who says he led the large language model (LLM) modeling for Google’s generative search product —also said in a post on X they are “the strongest open models at their scale – including those from LLaMA, DeepSeek, and Qwen.” The initial model lineup includes five base sizes: 3 billion, 8 billion, 14 billion, 32 billion, and 70 billion parameters, available now on AI code sharing community Hugging Face, Ollama and through application programming interfaces (API) on Fireworks and Together AI. They’re available under the Llama licensing terms which allows for commercial usage — so third-party enterprises could put them to work in paid products — up to 700 million monthly users, at which point they need to obtain a paid license from Meta. The company plans to release even larger models — up to 671 billion parameters — in the coming months. Arora describes the company’s training approach, iterated distillation and amplification (IDA), as a novel alternative to traditional reinforcement learning from human feedback (RLHF) or teacher-model distillation. The core idea behind IDA is to allocate more compute for a model to generate improved solutions, then distill the improved reasoning process into the model’s own parameters — effectively creating a feedback loop for capability growth. Arora likens this approach to Google AlphaGo’s self-play strategy, applied to natural language. The Cogito models are open-source and available for download via Hugging Face and Ollama, or through APIs provided by Fireworks AI and Together AI. Each model supports both a standard mode for direct answers and a reasoning mode, where the model reflects internally before responding. Benchmarks and evaluations The company shared a broad set of evaluation results comparing Cogito models to open-source peers across general knowledge, mathematical reasoning, and multilingual tasks. Highlights include: Cogito 3B (Standard) outperforms LLaMA 3.2 3B on MMLU by 6.7 percentage points (65.4% vs. 58.7%), and on Hellaswag by 18.8 points (81.1% vs. 62.3%). In reasoning mode, Cogito 3B scores 72.6% on MMLU and 84.2% on ARC, exceeding its own standard-mode performance and showing the effect of IDA-based self-reflection. Cogito 8B (Standard) scores 80.5% on MMLU, outperforming LLaMA 3.1 8B by 12.8 points. It also leads by over 11 points on MMLU-Pro and achieves 88.7% on ARC. In reasoning mode, Cogito 8B achieves 83.1% on MMLU and 92.0% on ARC. It surpasses DeepSeek R1 Distill 8B in nearly every category except the MATH benchmark, where Cogito scores significantly lower (60.2% vs. 80.6%). Cogito 14B and 32B models outperform Qwen2.5 counterparts by around 2–3 percentage points on aggregate benchmarks, with Cogito 32B (Reasoning) reaching 90.2% on MMLU and 91.8% on the MATH benchmark. Cogito 70B (Standard) outperforms LLaMA 3.3 70B on MMLU by 6.4 points (91.7% vs. 85.3%) and exceeds LLaMA 4 Scout 109B on aggregate benchmark scores (54.5% vs. 53.3%). Against DeepSeek R1 Distill 70B, Cogito 70B (Reasoning) posts stronger results in general and multilingual benchmarks, with a notable 91.0% on MMLU and 92.7% on MGSM. Cogito models generally show their highest performance in reasoning mode, though some trade-offs emerge — particularly in mathematics. For instance, while Cogito 70B (Standard) matches or slightly exceeds peers in MATH and GSM8K, Cogito 70B (Reasoning) trails DeepSeek R1 in MATH by over five percentage points (83.3% vs. 89.0%). Tool calling built-in In addition to general benchmarks, Deep Cogito evaluated its models on native tool-calling performance — a growing priority for agents and API-integrated systems. Cogito 3B supports four tool-calling tasks natively (simple, parallel, multiple, and parallel-multiple), whereas LLaMA 3.2 3B does not support tool calling. Cogito 3B scores 92.8% on simple tool calls and over 91% on multiple tool calls. Cogito 8B scores over 89% across all tool call types, significantly outperforming LLaMA 3.1 8B, which ranges between 35% and 54%. These improvements are attributed not only to model architecture and training data, but also to task-specific post-training, which many baseline models currently lack. Looking Ahead Deep Cogito plans to release larger-scale models in upcoming months, including mixture-of-expert variants at 109B, 400B, and 671B parameter scales. The company will also continue updating its current model checkpoints with extended training. The company positions its IDA methodology as a long-term path toward scalable self-improvement, removing dependence on human or static teacher models. Arora emphasizes that while performance benchmarks are important, real-world utility and adaptability are the true tests for these models — and that the company is just at the beginning of what it believes is a steep scaling curve. Deep Cogito’s research and infrastructure partnerships include teams from Hugging Face, RunPod, Fireworks AI, Together AI, and Ollama. All released models are open source and available now. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/cfr0z3n_davinci_scientific_diagram_showing_a_human_palm_with_fi_b8a07744-bd15-4aec-8945-46b7fa1a7369.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-04-08T22:01:34+00:00\" datetime=\"2025-04-08T22:01:34+00:00\"\u003eApril 8, 2025 3:01 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/cfr0z3n_davinci_scientific_diagram_showing_a_human_palm_with_fi_b8a07744-bd15-4aec-8945-46b7fa1a7369.png?w=750\" alt=\"Outstretched humanoid hand covered with colorful glowing circuitry\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eDeep Cogito, a new AI research startup based in San Francisco, officially emerged from stealth today with Cogito\u003cem\u003e \u003c/em\u003ev1, a new line of open source large language models (LLMs) fine-tuned from Meta’s Llama 3.2 and equipped with hybrid reasoning capabilities — the ability to answer quickly and immediately, or “self-reflect” like OpenAI’s “o” series and DeepSeek R1. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe company aims to push the boundaries of AI beyond current human-overseer limitations by enabling models to iteratively refine and internalize their own improved reasoning strategies. It’s ultimately on a quest toward developing superintelligence — AI smarter than all humans in all domains — yet the company says that “All models we create will be open sourced.”\u003c/p\u003e\n\n\n\n\u003cp\u003eDeep Cogito’s CEO and co-founder Drishan Arora — a former Senior Software Engineer at Google who says he led the large language model (LLM) modeling for Google’s generative search product —\u003ca href=\"https://x.com/drishanarora/status/1909672495588008312\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ealso said in a post on X \u003c/a\u003ethey are “the strongest open models at their scale – including those from LLaMA, DeepSeek, and Qwen.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThe initial model lineup includes five base sizes: 3 billion, 8 billion, 14 billion, 32 billion, and 70 billion parameters, available now on AI code sharing community \u003ca href=\"https://huggingface.co/collections/deepcogito/cogito-v1-preview-67eb105721081abe4ce2ee53\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHugging Face\u003c/a\u003e, \u003ca href=\"https://ollama.com/library/cogito\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOllama\u003c/a\u003e and through application programming interfaces (API) on \u003ca href=\"https://fireworks.ai/login?redirectURI=%2Fmodels%2Ffireworks%2Fcogito-v1-preview-llama-70b\"\u003eFireworks\u003c/a\u003e and \u003ca href=\"https://www.together.ai/models/cogito-v1-preview-llama-70b\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eTogether AI\u003c/a\u003e. \u003c/p\u003e\n\n\n\n\u003cp\u003eThey’re available under the\u003ca href=\"https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE\"\u003e Llama licensing terms\u003c/a\u003e which allows for commercial usage — so third-party enterprises could put them to work in paid products — up to 700 million monthly users, at which point they need to obtain a paid license from Meta.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe company plans to release even larger models — up to 671 billion parameters — in the coming months.\u003c/p\u003e\n\n\n\n\u003cp\u003eArora describes the company’s training approach, iterated distillation and amplification (IDA), as a novel alternative to traditional reinforcement learning from human feedback (RLHF) or teacher-model distillation. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe core idea behind IDA is to allocate more compute for a model to generate improved solutions, then distill the improved reasoning process into the model’s own parameters — effectively creating a feedback loop for capability growth. Arora likens this approach to Google AlphaGo’s self-play strategy, applied to natural language.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe Cogito models are open-source and available for download via Hugging Face and Ollama, or through APIs provided by Fireworks AI and Together AI. Each model supports both a standard mode for direct answers and a reasoning mode, where the model reflects internally before responding.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-benchmarks-and-evaluations\"\u003eBenchmarks and evaluations\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe company shared a broad set of evaluation results comparing Cogito models to open-source peers across general knowledge, mathematical reasoning, and multilingual tasks. Highlights include:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCogito 3B (Standard)\u003c/strong\u003e outperforms \u003cem\u003eLLaMA 3.2 3B\u003c/em\u003e on MMLU by 6.7 percentage points (65.4% vs. 58.7%), and on Hellaswag by 18.8 points (81.1% vs. 62.3%).\u003c/li\u003e\n\n\n\n\u003cli\u003eIn \u003cstrong\u003ereasoning mode\u003c/strong\u003e, \u003cem\u003eCogito 3B\u003c/em\u003e scores 72.6% on MMLU and 84.2% on ARC, exceeding its own standard-mode performance and showing the effect of IDA-based self-reflection.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eCogito 8B (Standard)\u003c/strong\u003e scores 80.5% on MMLU, outperforming \u003cem\u003eLLaMA 3.1 8B\u003c/em\u003e by 12.8 points. It also leads by over 11 points on MMLU-Pro and achieves 88.7% on ARC.\u003c/li\u003e\n\n\n\n\u003cli\u003eIn \u003cstrong\u003ereasoning mode\u003c/strong\u003e, \u003cem\u003eCogito 8B\u003c/em\u003e achieves 83.1% on MMLU and 92.0% on ARC. It surpasses \u003cem\u003eDeepSeek R1 Distill 8B\u003c/em\u003e in nearly every category except the MATH benchmark, where Cogito scores significantly lower (60.2% vs. 80.6%).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eCogito 14B and 32B\u003c/strong\u003e models outperform \u003cem\u003eQwen2.5\u003c/em\u003e counterparts by around 2–3 percentage points on aggregate benchmarks, with \u003cem\u003eCogito 32B (Reasoning)\u003c/em\u003e reaching 90.2% on MMLU and 91.8% on the MATH benchmark.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eCogito 70B (Standard)\u003c/strong\u003e outperforms \u003cem\u003eLLaMA 3.3 70B\u003c/em\u003e on MMLU by 6.4 points (91.7% vs. 85.3%) and exceeds \u003cem\u003eLLaMA 4 Scout 109B\u003c/em\u003e on aggregate benchmark scores (54.5% vs. 53.3%).\u003c/li\u003e\n\n\n\n\u003cli\u003eAgainst \u003cem\u003eDeepSeek R1 Distill 70B\u003c/em\u003e, \u003cem\u003eCogito 70B (Reasoning)\u003c/em\u003e posts stronger results in general and multilingual benchmarks, with a notable 91.0% on MMLU and 92.7% on MGSM.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eCogito models generally show their highest performance in reasoning mode, though some trade-offs emerge — particularly in mathematics. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor instance, while Cogito 70B (Standard) matches or slightly exceeds peers in MATH and GSM8K, Cogito 70B (Reasoning) trails DeepSeek R1 in MATH by over five percentage points (83.3% vs. 89.0%).\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-tool-calling-built-in\"\u003eTool calling built-in\u003c/h3\u003e\n\n\n\n\u003cp\u003eIn addition to general benchmarks, Deep Cogito evaluated its models on native tool-calling performance — a growing priority for agents and API-integrated systems.\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eCogito 3B supports four tool-calling tasks natively (simple, parallel, multiple, and parallel-multiple), whereas \u003cem\u003eLLaMA 3.2 3B\u003c/em\u003e does not support tool calling.\u003c/li\u003e\n\n\n\n\u003cli\u003eCogito 3B scores 92.8% on simple tool calls and over 91% on multiple tool calls.\u003c/li\u003e\n\n\n\n\u003cli\u003eCogito 8B scores over 89% across all tool call types, significantly outperforming \u003cem\u003eLLaMA 3.1 8B\u003c/em\u003e, which ranges between 35% and 54%.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThese improvements are attributed not only to model architecture and training data, but also to task-specific post-training, which many baseline models currently lack.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-looking-ahead\"\u003eLooking Ahead\u003c/h3\u003e\n\n\n\n\u003cp\u003eDeep Cogito plans to release larger-scale models in upcoming months, including mixture-of-expert variants at 109B, 400B, and 671B parameter scales. The company will also continue updating its current model checkpoints with extended training.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe company positions its IDA methodology as a long-term path toward scalable self-improvement, removing dependence on human or static teacher models. \u003c/p\u003e\n\n\n\n\u003cp\u003eArora emphasizes that while performance benchmarks are important, real-world utility and adaptability are the true tests for these models — and that the company is just at the beginning of what it believes is a steep scaling curve.\u003c/p\u003e\n\n\n\n\u003cp\u003eDeep Cogito’s research and infrastructure partnerships include teams from Hugging Face, RunPod, Fireworks AI, Together AI, and Ollama. All released models are open source and available now.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-04-08T22:01:34Z",
  "modifiedTime": "2025-04-08T22:01:41Z"
}
