{
  "id": "3fd6c916-50e9-48a4-974a-06b2bbb671d8",
  "title": "How (and why) federated learning enhances cybersecurity",
  "link": "https://venturebeat.com/security/how-and-why-federated-learning-enhances-cybersecurity/",
  "description": "Federated learning’s popularity is rapidly increasing because it addresses common development-related security concerns.",
  "author": "Zac Amos, ReHack",
  "published": "Sat, 26 Oct 2024 19:05:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "Security",
    "AI, ML and Deep Learning",
    "category-/Computers \u0026 Electronics/Computer Security",
    "category-/Science/Computer Science",
    "Conversational AI",
    "Data Security and Privacy",
    "federated learning",
    "Network Security and Privacy",
    "NLP",
    "Software Security"
  ],
  "byline": "Zac Amos, ReHack",
  "length": 8169,
  "excerpt": "Federated learning’s popularity is rapidly increasing because it addresses common development-related security concerns.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "October 26, 2024 12:05 PM VentureBeat/Ideogram Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Each year, cyberattacks become more frequent and data breaches become more expensive. Whether companies seek to protect their AI system during development or use their algorithm to improve their security posture, they must alleviate cybersecurity risks. Federated learning might be able to do both. What is federated learning? Federated learning is an approach to AI development in which multiple parties train a single model separately. Each downloads the current primary algorithm from a central cloud server. They train their configuration independently on local servers, uploading it upon completion. This way, they can share data remotely without exposing raw data or model parameters. The centralized algorithm weighs the number of samples it receives from each disparately trained configuration, aggregating them to create a single global model. All information remains on each participant’s local servers or devices — the centralized repository weighs the updates instead of processing raw data. Federated learning’s popularity is rapidly increasing because it addresses common development-related security concerns. It is also highly sought after for its performance advantages. Research shows this technique can improve an image classification model’s accuracy by up to 20% — a substantial increase. Horizontal federated learning There are two types of federated learning. The conventional option is horizontal federated learning. In this approach, data is partitioned across various devices. The datasets share feature spaces but have different samples. This enables edge nodes to collaboratively train a machine learning (ML) model without sharing information. Vertical federated learning In vertical federated learning, the opposite is true — features differ, but samples are the same. Features are distributed vertically across participants, each possessing different attributes about the same set of entities. Since just one party has access to the complete set of sample labels, this approach preserves privacy.  How federated learning strengthens cybersecurity Traditional development is prone to security gaps. Although algorithms must have expansive, relevant datasets to maintain accuracy, involving multiple departments or vendors creates openings for threat actors. They can exploit the lack of visibility and broad attack surface to inject bias, conduct prompt engineering or exfiltrate sensitive training data. When algorithms are deployed in cybersecurity roles, their performance can affect an organization’s security posture. Research shows that model accuracy can suddenly diminish when processing new data. Although AI systems may appear accurate, they may fail when tested elsewhere because they learned to take bogus shortcuts to produce convincing results. Since AI cannot think critically or genuinely consider context, its accuracy diminishes over time. Even though ML models evolve as they absorb new information, their performance will stagnate if their decision-making skills are based on shortcuts. This is where federated learning comes in. Other notable benefits of training a centralized model via disparate updates include privacy and security. Since every participant works independently, no one has to share proprietary or sensitive information to progress training. Moreover, the fewer data transfers there are, the lower the risk of a man-in-the-middle attack (MITM). All updates are encrypted for secure aggregation. Multi-party computation hides them behind various encryption schemes, lowering the chances of a breach or MITM attack. Doing so enhances collaboration while minimizing risk, ultimately improving security posture. One overlooked advantage of federated learning is speed. It has a much lower latency than its centralized counterpart. Since training happens locally instead of on a central server, the algorithm can detect, classify and respond to threats much faster. Minimal delays and rapid data transmissions enable cybersecurity professionals to handle bad actors with ease. Considerations for cybersecurity professionals Before leveraging this training technique, AI engineers and cybersecurity teams should consider several technical, security and operational factors. Resource usage AI development is expensive. Teams building their own model should expect to spend anywhere from $5 million to $200 million upfront, and upwards of $5 million annually for upkeep. The financial commitment is significant even with costs spread out among multiple parties. Business leaders should account for cloud and edge computing costs. Federated learning is also computationally intensive, which may introduce bandwidth, storage space or computing limitations. While the cloud enables on-demand scalability, cybersecurity teams risk vendor lock-in if they are not careful. Strategic hardware and vendor selection is of the utmost importance. Participant trust While disparate training is secure, it lacks transparency, making intentional bias and malicious injection a concern. A consensus mechanism is essential for approving model updates before the centralized algorithm aggregates them. This way, they can minimize threat risk without sacrificing confidentiality or exposing sensitive information. Training data security While this machine learning training technique can improve a firm’s security posture, there is no such thing as 100% secure. Developing a model in the cloud comes with the risk of insider threats, human error and data loss. Redundancy is key. Teams should create backups to prevent disruption and roll back updates, if necessary.  Decision-makers should revisit their training datasets’ sources. In ML communities, heavy borrowing of datasets occurs, raising well-founded concerns about model misalignment. On Papers With Code, more than 50% of task communities use borrowed datasets at least 57.8% of the time. Moreover, 50% of the datasets there come from just 12 universities. Applications of federated learning in cybersecurity Once the primary algorithm aggregates and weighs participants’ updates, it can be reshared for whatever application it was trained for. Cybersecurity teams can use it for threat detection. The advantage here is twofold — while threat actors are left guessing since they cannot easily exfiltrate data, professionals pool insights for highly accurate output. Federated learning is ideal for adjacent applications like threat classification or indicator of compromise detection. The AI’s large dataset size and extensive training build its knowledge base, curating expansive expertise. Cybersecurity professionals can use the model as a unified defense mechanism to protect broad attack surfaces. ML models — especially those that make predictions — are prone to drift over time as concepts evolve or variables become less relevant. With federated learning, teams could periodically update their model with varied features or data samples, resulting in more accurate, timely insights. Leveraging federated learning for cybersecurity Whether companies want to secure their training dataset or leverage AI for threat detection, they should consider using federated learning. This technique could improve accuracy and performance and strengthen their security posture as long as they strategically navigate potential insider threats or breach risks.  Zac Amos is the features editor at ReHack. DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2024/10/a-cinematic-shot-of-a-giant-lock-with-data-inscrib-H0CPCOEcToiwZw4qV8siAg-PpiX9xXfRO6M-RbLJZUhHQ-transformed.jpeg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-10-26T19:05:00+00:00\" datetime=\"2024-10-26T19:05:00+00:00\"\u003eOctober 26, 2024 12:05 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"421\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/a-cinematic-shot-of-a-giant-lock-with-data-inscrib-H0CPCOEcToiwZw4qV8siAg-PpiX9xXfRO6M-RbLJZUhHQ-transformed.jpeg?w=750\" alt=\"VentureBeat/Ideogram\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Ideogram\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eEach year, \u003ca href=\"https://venturebeat.com/security/the-ai-edge-in-cybersecurity-predictive-tools-aim-to-slash-response-times/\"\u003ecyberattacks\u003c/a\u003e become more frequent and data breaches become more expensive. Whether companies seek to protect their AI system during development or use their algorithm to improve their security posture, they must alleviate cybersecurity risks. Federated learning might be able to do both.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-is-federated-learning\"\u003eWhat is federated learning?\u003c/h2\u003e\n\n\n\n\u003cp\u003eFederated learning is an approach to \u003ca href=\"https://venturebeat.com/ai/llms-are-stuck-on-a-problem-from-the-70s-but-are-still-worth-using-heres-why/\"\u003eAI development\u003c/a\u003e in which multiple parties train a single model separately. Each downloads the current primary algorithm from a central cloud server. They train their configuration independently on local servers, uploading it upon completion. This way, they can share data remotely without exposing raw data or model parameters.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe centralized algorithm weighs the number of samples it receives from each disparately trained configuration, aggregating them to create a single global model. All information remains on each participant’s local servers or devices — the centralized repository weighs the updates instead of processing raw data.\u003c/p\u003e\n\n\n\n\u003cp\u003eFederated learning’s popularity is rapidly increasing because it addresses common development-related security concerns. It is also highly sought after for its performance advantages. Research shows this technique can improve an image classification model’s \u003ca href=\"https://www.mdpi.com/1424-8220/23/17/7358\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eaccuracy by up to 20%\u003c/a\u003e — a substantial increase.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-horizontal-federated-learning\"\u003eHorizontal federated learning\u003c/h3\u003e\n\n\n\n\u003cp\u003eThere are two types of federated learning. The conventional option is horizontal federated learning. In this approach, data is partitioned across various devices. The datasets share feature spaces but have different samples. This enables edge nodes to collaboratively train a machine learning (ML) model without sharing information.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-vertical-federated-learning\"\u003eVertical federated learning\u003c/h3\u003e\n\n\n\n\u003cp\u003eIn vertical federated learning, the opposite is true — features differ, but samples are the same. Features are distributed vertically across participants, each possessing different attributes about the same set of entities. Since just one party has access to the complete set of sample labels, this approach preserves privacy. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-how-federated-learning-strengthens-cybersecurity\"\u003eHow federated learning strengthens cybersecurity\u003c/h2\u003e\n\n\n\n\u003cp\u003eTraditional development is prone to security gaps. Although algorithms must have expansive, relevant datasets to maintain accuracy, involving multiple departments or vendors creates openings for threat actors. They can exploit the lack of visibility and broad attack surface to inject bias, conduct prompt engineering or \u003ca href=\"https://venturebeat.com/security/harvest-now-decrypt-later-why-hackers-are-waiting-for-quantum-computing/\"\u003eexfiltrate sensitive training data\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhen algorithms are deployed in cybersecurity roles, their performance can affect an organization’s security posture. Research shows that model accuracy can suddenly diminish when processing new data. Although AI systems may appear accurate, they may fail when tested elsewhere because they learned to take bogus shortcuts to produce convincing results.\u003c/p\u003e\n\n\n\n\u003cp\u003eSince AI cannot think critically or genuinely consider context, its accuracy diminishes over time. Even though ML models evolve as they absorb new information, their performance will stagnate if their decision-making skills are based on shortcuts. This is where federated learning comes in.\u003c/p\u003e\n\n\n\n\u003cp\u003eOther notable benefits of training a centralized model via disparate updates include privacy and security. Since every participant works independently, no one has to share proprietary or sensitive information to progress training. Moreover, the fewer data transfers there are, the lower the risk of a man-in-the-middle attack (MITM).\u003c/p\u003e\n\n\n\n\u003cp\u003eAll updates are encrypted for secure aggregation. Multi-party computation hides them behind various encryption schemes, lowering the chances of a breach or MITM attack. Doing so enhances collaboration while minimizing risk, ultimately improving \u003ca href=\"https://venturebeat.com/security/living-with-trust-issues-the-human-side-of-zero-trust-architecture/\"\u003esecurity posture\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eOne overlooked advantage of federated learning is speed. It has a much lower latency than its centralized counterpart. Since training happens locally instead of on a central server, the algorithm can detect, classify and respond to threats much faster. Minimal delays and rapid data transmissions enable cybersecurity professionals to handle bad actors with ease.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-considerations-for-cybersecurity-professionals\"\u003eConsiderations for cybersecurity professionals\u003c/h2\u003e\n\n\n\n\u003cp\u003eBefore leveraging this training technique, AI engineers and cybersecurity teams should consider several technical, security and operational factors.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-resource-usage\"\u003eResource usage\u003c/h3\u003e\n\n\n\n\u003cp\u003eAI development is expensive. Teams building their own model should expect to spend anywhere from \u003ca href=\"https://quiq.com/blog/ai-security-myths-debunked/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e$5 million to $200 million\u003c/a\u003e upfront, and upwards of $5 million annually for upkeep. The financial commitment is significant even with costs spread out among multiple parties. Business leaders should account for cloud and edge computing costs.\u003c/p\u003e\n\n\n\n\u003cp\u003eFederated learning is also computationally intensive, which may introduce bandwidth, storage space or computing limitations. While the cloud enables on-demand scalability, cybersecurity teams risk vendor lock-in if they are not careful. Strategic hardware and vendor selection is of the utmost importance.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-participant-trust\"\u003eParticipant trust\u003c/h3\u003e\n\n\n\n\u003cp\u003eWhile disparate training is secure, it lacks transparency, making intentional bias and malicious injection a concern. A consensus mechanism is essential for approving model updates before the centralized algorithm aggregates them. This way, they can minimize threat risk without sacrificing confidentiality or exposing sensitive information.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-training-data-security\"\u003eTraining data security\u003c/h3\u003e\n\n\n\n\u003cp\u003eWhile this machine learning training technique can improve a firm’s security posture, there is no such thing as 100% secure. Developing a model in the cloud comes with the risk of insider threats, human error and data loss. Redundancy is key. Teams should create backups to prevent disruption and roll back updates, if necessary. \u003c/p\u003e\n\n\n\n\u003cp\u003eDecision-makers should revisit their training datasets’ sources. In ML communities, heavy borrowing of datasets occurs, raising well-founded concerns about model misalignment. On Papers With Code, more than \u003ca href=\"https://openreview.net/pdf?id=zNQBIBKJRkd\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e50% of task communities\u003c/a\u003e use borrowed datasets at least 57.8% of the time. Moreover, 50% of the datasets there come from just 12 universities.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-applications-of-federated-learning-in-cybersecurity\"\u003eApplications of federated learning in cybersecurity\u003c/h2\u003e\n\n\n\n\u003cp\u003eOnce the primary algorithm aggregates and weighs participants’ updates, it can be reshared for whatever application it was trained for. Cybersecurity teams can use it for threat detection. The advantage here is twofold — while threat actors are left guessing since they cannot easily exfiltrate data, professionals pool insights for highly accurate output.\u003c/p\u003e\n\n\n\n\u003cp\u003eFederated learning is ideal for adjacent applications like threat classification or indicator of compromise detection. The AI’s large dataset size and extensive training build its knowledge base, curating expansive expertise. Cybersecurity professionals can use the model as a unified defense mechanism to protect broad attack surfaces.\u003c/p\u003e\n\n\n\n\u003cp\u003eML models — especially those that make predictions — are prone to drift over time as concepts evolve or variables become less relevant. With federated learning, teams could periodically update their model with varied features or data samples, resulting in more accurate, timely insights.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-leveraging-federated-learning-for-cybersecurity\"\u003eLeveraging federated learning for cybersecurity\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhether companies want to secure their training dataset or leverage AI for threat detection, they should consider using federated learning. This technique could improve accuracy and performance and strengthen their security posture as long as they strategically navigate potential insider threats or breach risks.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e Zac Amos is the features editor at \u003ca href=\"https://rehack.com\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eReHack\u003c/a\u003e. \u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2024-10-26T19:05:00Z",
  "modifiedTime": "2024-10-26T19:15:49Z"
}
