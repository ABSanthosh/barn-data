{
  "id": "d6dd2d1e-e16e-435b-8d8b-c175940a3685",
  "title": "2027 AGI forecast maps a 24-month sprint to human-level AI",
  "link": "https://venturebeat.com/ai/2027-agi-forecast-maps-a-24-month-sprint-to-human-level-ai/",
  "description": "The newly published AI 2027 scenario offers a detailed 2 to 3-year forecast for the future that includes specific technical milestones.",
  "author": "Gary Grossman, Edelman",
  "published": "Sun, 20 Apr 2025 20:15:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "artificial general intelligence",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "NLP"
  ],
  "byline": "Gary Grossman, Edelman",
  "length": 8989,
  "excerpt": "The newly published AI 2027 scenario offers a detailed 2 to 3-year forecast for the future that includes specific technical milestones.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More The distant horizon is always murky, the minute details obscured by sheer distance and atmospheric haze. This is why forecasting the future is so imprecise: We cannot clearly see the outlines of the shapes and events ahead of us. Instead, we take educated guesses.  The newly published AI 2027 scenario, developed by a team of AI researchers and forecasters with experience at institutions like OpenAI and The Center for AI Policy, offers a detailed 2 to 3-year forecast for the future that includes specific technical milestones. Being near-term, it speaks with great clarity about our AI near future. Informed by extensive expert feedback and scenario planning exercises, AI 2027 outlines a quarter-by-quarter progression of anticipated AI capabilities, notably multimodal models achieving advanced reasoning and autonomy. What makes this forecast particularly noteworthy is both its specificity and the credibility of its contributors, who have direct insight into current research pipelines. The most notable prediction is that artificial general intelligence (AGI) will be achieved in 2027, and artificial superintelligence (ASI) will follow months later. AGI matches or exceeds human capabilities across virtually all cognitive tasks, from scientific research to creative endeavors, while demonstrating adaptability, common sense reasoning and self-improvement. ASI goes further, representing systems that dramatically surpass human intelligence, with the ability to solve problems we cannot even comprehend. Like many predictions, these are based on assumptions, not the least of which is that AI models and applications will continue to progress exponentially, as they have for the last several years. As such, it is plausible, but not guaranteed to expect exponential progress, especially as scaling of these models may now be hitting diminishing returns. Not everyone agrees with these predictions. Ali Farhadi, the CEO of the Allen Institute for Artificial Intelligence, told The New York Times: “I’m all for projections and forecasts, but this [AI 2027] forecast doesn’t seem to be grounded in scientific evidence, or the reality of how things are evolving in AI.”  However, there are others who view this evolution as plausible. Anthropic co-founder Jack Clark wrote in his Import AI newsletter that AI 2027 is: “The best treatment yet of what ‘living in an exponential’ might look like.” He added that it is a “technically astute narrative of the next few years of AI development.” This timeline also aligns with that proposed by Anthropic CEO Dario Amodei, who has said that AI that can surpass humans in almost everything will arrive in the next two to three years. And, Google DeepMind said in a new research paper that AGI could plausibly arrive by 2030. The great acceleration: Disruption without precedent This seems like an auspicious time. There have been similar moments like this in history, including the invention of the printing press or the spread of electricity. However, those advances required many years and decades to have a significant impact.  The arrival of AGI feels different, and potentially frightening, especially if it is imminent. AI 2027 describes one scenario that, due to misalignment with human values, superintelligent AI destroys humanity. If they are right, the most consequential risk for humanity may now be within the same planning horizon as your next smartphone upgrade. For its part, the Google DeepMind paper notes that human extinction is a possible outcome from AGI, albeit unlikely in their view.  Opinions change slowly until people are presented with overwhelming evidence. This is one takeaway from Thomas Kuhn’s singular work “The Structure of Scientific Revolutions.” Kuhn reminds us that worldviews do not shift overnight, until, suddenly, they do. And with AI, that shift may already be underway. The future draws near Before the appearance of large language models (LLMs) and ChatGPT, the median timeline projection for AGI was much longer than it is today. The consensus among experts and prediction markets placed the median expected arrival of AGI around the year 2058. Before 2023, Geoffrey Hinton — one of the “Godfathers of AI” and a Turing Award winner — thought AGI was “30 to 50 years or even longer away.” However, progress shown by LLMs led him to change his mind and said it could arrive as soon as 2028. There are numerous implications for humanity if AGI does arrive in the next several years and is followed quickly by ASI. Writing in Fortune, Jeremy Kahn said that if AGI arrives in the next few years “it could indeed lead to large job losses, as many organizations would be tempted to automate roles.” A two-year AGI runway offers an insufficient grace period for individuals and businesses to adapt. Industries such as customer service, content creation, programming and data analysis could face a dramatic upheaval before retraining infrastructure can scale. This pressure will only intensify if a recession occurs in this timeframe, when companies are already looking to reduce payroll costs and often supplant personnel with automation. Cogito, ergo … AI? Even if AGI does not lead to extensive job losses or species extinction, there are other serious ramifications. Ever since the Age of Reason, human existence has been grounded in a belief that we matter because we think.  This belief that thinking defines our existence has deep philosophical roots. It was René Descartes, writing in 1637, who articulated the now-famous phrase: “Je pense, donc je suis” (“I think, therefore I am”). He later translated it into Latin: “Cogito, ergo sum.” In so doing, he proposed that certainty could be found in the act of individual thought. Even if he were deceived by his senses, or misled by others, the very fact that he was thinking proved that he existed. In this view, the self is anchored in cognition. It was a revolutionary idea at the time and gave rise to Enlightenment humanism, the scientific method and, ultimately, modern democracy and individual rights. Humans as thinkers became the central figures of the modern world. Which raises a profound question: If machines can now think, or appear to think, and we outsource our thinking to AI, what does that mean for the modern conception of the self? A recent study reported by 404 Media explores this conundrum. It found that when people rely heavily on generative AI for work, they engage in less critical thinking which, over time, can “result in the deterioration of cognitive faculties that ought to be preserved.”  Where do we go from here? If AGI is coming in the next few years — or soon thereafter — we must rapidly grapple with its implications not just for jobs and safety, but for who we are. And we must do so while also acknowledging its extraordinary potential to accelerate discovery, reduce suffering and extend human capability in unprecedented ways. For example, Amodei has said that “powerful AI” will enable 100 years of biological research and its benefits, including improved healthcare, to be compressed into 5 to 10 years.  The forecasts presented in AI 2027 may or may not be correct, but they are plausible and provocative. And that plausibility should be enough. As humans with agency, and as members of companies, governments and societies, we must act now to prepare for what may be coming.  For businesses, this means investing in both technical AI safety research and organizational resilience, creating roles that integrate AI capabilities while amplifying human strengths. For governments, it requires accelerated development of regulatory frameworks that address both immediate concerns like model evaluation and longer-term existential risks. For individuals, it means embracing continuous learning focused on uniquely human skills including creativity, emotional intelligence and complex judgment, while developing healthy working relationships with AI tools that do not diminish our agency. The time for abstract debate about distant futures has passed; concrete preparation for near-term transformation is urgently needed. Our future will not be written by algorithms alone. It will be shaped by the choices we make, and the values we uphold, starting today. Gary Grossman is EVP of technology practice at Edelman and global lead of the Edelman AI Center of Excellence. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/image1_c6c600.jpg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThe distant horizon is always murky, the minute details obscured by sheer distance and atmospheric haze. This is why forecasting the future is so imprecise: We cannot clearly see the outlines of the shapes and events ahead of us. Instead, we take educated guesses. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe newly published \u003ca href=\"https://ai-2027.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAI 2027\u003c/a\u003e scenario, developed by a team of AI researchers and forecasters with experience at institutions like \u003ca href=\"https://venturebeat.com/ai/windsurf-openais-potential-3b-bet-to-drive-the-vibe-coding-movement/\"\u003eOpenAI\u003c/a\u003e and The Center for AI Policy, offers a detailed 2 to 3-year forecast for the future that includes specific technical milestones. Being near-term, it speaks with great clarity about our AI near future. \u003c/p\u003e\n\n\n\n\u003cp\u003eInformed by extensive expert feedback and scenario planning exercises, AI 2027 outlines a quarter-by-quarter progression of anticipated AI capabilities, notably multimodal models achieving advanced reasoning and autonomy. What makes this forecast particularly noteworthy is both its specificity and the credibility of its contributors, who have direct insight into current research pipelines.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe most notable prediction is that \u003ca href=\"https://venturebeat.com/ai/inching-towards-agi-how-reasoning-and-deep-research-are-expanding-ai-from-statistical-prediction-to-structured-problem-solving/\"\u003eartificial general intelligence\u003c/a\u003e (AGI) will be achieved in 2027, and artificial superintelligence (ASI) will follow months later. AGI matches or exceeds human capabilities across virtually all cognitive tasks, from scientific research to creative endeavors, while demonstrating adaptability, common sense reasoning and self-improvement. ASI goes further, representing systems that dramatically surpass human intelligence, with the ability to solve problems we cannot even comprehend.\u003c/p\u003e\n\n\n\n\u003cp\u003eLike many predictions, these are based on assumptions, not the least of which is that AI models and applications will continue to progress exponentially, as they have for the last several years. As such, it is plausible, but not guaranteed to expect exponential progress, especially as scaling of these models may now be hitting diminishing returns.\u003c/p\u003e\n\n\n\n\u003cp\u003eNot everyone agrees with these predictions. Ali Farhadi, the CEO of the Allen Institute for Artificial Intelligence, told \u003ca href=\"https://www.nytimes.com/2025/04/03/technology/ai-futures-project-ai-2027.html?searchResultPosition=1\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e\u003cem\u003eThe New York Times\u003c/em\u003e\u003c/a\u003e: “I’m all for projections and forecasts, but this [AI 2027] forecast doesn’t seem to be grounded in scientific evidence, or the reality of how things are evolving in AI.” \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, there are others who view this evolution as plausible. Anthropic co-founder Jack Clark wrote in his \u003ca href=\"https://importai.substack.com/p/import-ai-408-multi-code-swe-bench?utm_source=post-email-title\u0026amp;publication_id=1317673\u0026amp;post_id=161266154\u0026amp;utm_campaign=email-post-title\u0026amp;isFreemail=false\u0026amp;r=14wyl2\u0026amp;triedRedirect=true\u0026amp;utm_medium=email\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eImport AI\u003c/a\u003e newsletter that AI 2027 is: “The best treatment yet of what ‘living in an exponential’ might look like.” He added that it is a \u003cem\u003e“\u003c/em\u003etechnically astute narrative of the next few years of AI development.” This timeline also aligns with that proposed by Anthropic CEO Dario Amodei, who has said that AI that can surpass humans in almost everything will arrive in the next two to three years. And, Google DeepMind said in \u003ca href=\"http://chrome-extension/efaidnbmnnnibpcajpcglclefindmkaj/https:/storage.googleapis.com/deepmind-media/DeepMind.com/Blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/An_Approach_to_Technical_AGI_Safety_Apr_2025.pdf\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ea new research paper\u003c/a\u003e that AGI could plausibly arrive by 2030.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-great-acceleration-disruption-without-precedent\"\u003eThe great acceleration: Disruption without precedent\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis seems like an auspicious time. There have been similar moments like this in history, including the invention of the printing press or the spread of electricity. However, those advances required many years and decades to have a significant impact. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe \u003ca href=\"https://venturebeat.com/ai/beyond-arc-agi-gaia-and-the-search-for-a-real-intelligence-benchmark/\"\u003earrival of AGI\u003c/a\u003e feels different, and potentially frightening, especially if it is imminent. AI 2027 describes one scenario that, due to misalignment with human values, superintelligent AI destroys humanity. If they are right, the most consequential risk for humanity may now be within the same planning horizon as your next smartphone upgrade. For its part, the Google DeepMind paper notes that human extinction is a possible outcome from AGI, albeit unlikely in their view. \u003c/p\u003e\n\n\n\n\u003cp\u003eOpinions change slowly until people are presented with overwhelming evidence. This is one takeaway from Thomas Kuhn’s singular work “\u003ca href=\"https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eThe Structure of Scientific Revolutions\u003c/a\u003e.” Kuhn reminds us that worldviews do not shift overnight, until, suddenly, they do. And with AI, that shift may already be underway.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-future-draws-near\"\u003eThe future draws near\u003c/h2\u003e\n\n\n\n\u003cp\u003eBefore the appearance of \u003ca href=\"https://venturebeat.com/ai/mips-to-exaflops-in-just-40-years-compute-power-is-exploding-and-it-will-transform-ai/\"\u003elarge language models\u003c/a\u003e (LLMs) and ChatGPT, the median timeline projection for AGI was much longer than it is today. The consensus among experts and prediction markets placed the median expected arrival of AGI around the year 2058. Before 2023, Geoffrey Hinton — one of the “Godfathers of AI” and a Turing Award winner — \u003ca href=\"https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ethought AGI\u003c/a\u003e was “30 to 50 years or even longer away.” However, progress shown by LLMs led him to change his mind and said it \u003ca href=\"https://x.com/geoffreyhinton/status/1653687894534504451?lang=en\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecould arrive as soon as 2028\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"862\" height=\"318\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/image2.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/04/image2.png 862w, https://venturebeat.com/wp-content/uploads/2025/04/image2.png?resize=300,111 300w, https://venturebeat.com/wp-content/uploads/2025/04/image2.png?resize=768,283 768w, https://venturebeat.com/wp-content/uploads/2025/04/image2.png?resize=800,295 800w, https://venturebeat.com/wp-content/uploads/2025/04/image2.png?resize=400,148 400w, https://venturebeat.com/wp-content/uploads/2025/04/image2.png?resize=750,277 750w, https://venturebeat.com/wp-content/uploads/2025/04/image2.png?resize=578,213 578w\" sizes=\"(max-width: 862px) 100vw, 862px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThere are numerous implications for humanity if AGI does arrive in the next several years and is followed quickly by ASI. Writing in \u003ca href=\"https://fortune.com/2025/04/15/ai-timelines-agi-safety/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eFortune\u003c/a\u003e, Jeremy Kahn said that if AGI arrives in the next few years “it could indeed lead to large job losses, as many organizations would be tempted to automate roles.” \u003c/p\u003e\n\n\n\n\u003cp\u003eA two-year AGI runway offers an insufficient grace period for individuals and businesses to adapt. Industries such as customer service, content creation, programming and data analysis could face a dramatic upheaval before retraining infrastructure can scale. This pressure will only intensify if a \u003ca href=\"https://venturebeat.com/ai/gradually-then-suddenly-is-ai-job-displacement-following-this-pattern/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003erecession\u003c/a\u003e occurs in this timeframe, when companies are already looking to reduce payroll costs and often supplant personnel with automation.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-cogito-ergo-ai\"\u003eCogito, ergo … AI? \u003c/h2\u003e\n\n\n\n\u003cp\u003eEven if AGI does not lead to extensive job losses or species extinction, there are other serious ramifications. Ever since the Age of Reason, human existence has been grounded in a belief that we matter because we think. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis belief that thinking defines our existence has deep philosophical roots. It was René Descartes, writing in 1637, who articulated the now-famous phrase: “Je pense, donc je suis” (“I think, therefore I am”). He later translated it into Latin: \u003cem\u003e“\u003c/em\u003eCogito, ergo sum\u003cem\u003e.”\u003c/em\u003e In so doing, he proposed that certainty could be found in the act of individual thought. Even if he were deceived by his senses, or misled by others, the very fact that he was thinking proved that he existed.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn this view, the self is anchored in cognition. It was a revolutionary idea at the time and gave rise to Enlightenment humanism, the scientific method and, ultimately, modern democracy and individual rights. Humans as thinkers became the central figures of the modern world.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhich raises a profound question: If machines can now think, or appear to think, and we outsource our thinking to AI, what does that mean for the modern conception of the self? A \u003ca href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf\" target=\"_blank\" rel=\"noreferrer noopener\"\u003erecent study\u003c/a\u003e reported by \u003ca href=\"https://www.404media.co/microsoft-study-finds-ai-makes-human-cognition-atrophied-and-unprepared-3/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e404 Media\u003c/a\u003e explores this conundrum. It found that when people rely heavily on generative AI for work, they engage in less critical thinking which, over time, can “result in the deterioration of cognitive faculties that ought to be preserved.” \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-where-do-we-go-from-here\"\u003eWhere do we go from here?\u003c/h2\u003e\n\n\n\n\u003cp\u003eIf AGI is coming in the next few years — or soon thereafter — we must rapidly grapple with its implications not just for jobs and safety, but for who we are. And we must do so while also acknowledging its extraordinary potential to accelerate discovery, reduce suffering and extend human capability in unprecedented ways. For example, Amodei has said that “powerful AI” will enable 100 years of biological research and its benefits, including improved healthcare, to be compressed into 5 to 10 years. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe forecasts presented in AI 2027 may or may not be correct, but they are plausible and provocative. And that plausibility should be enough. As humans with agency, and as members of companies, governments and societies, we must act now to prepare for what may be coming. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor businesses, this means investing in both technical AI safety research and organizational resilience, creating roles that integrate AI capabilities while amplifying human strengths. For governments, it requires accelerated development of regulatory frameworks that address both immediate concerns like model evaluation and longer-term existential risks. For individuals, it means embracing continuous learning focused on uniquely human skills including creativity, emotional intelligence and complex judgment, while developing healthy working relationships with AI tools that do not diminish our agency.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe time for abstract debate about distant futures has passed; concrete preparation for near-term transformation is urgently needed. Our future will not be written by algorithms alone. It will be shaped by the choices we make, and the values we uphold, starting today.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eGary Grossman is EVP of technology practice at \u003ca href=\"https://www.edelman.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eEdelman\u003c/a\u003e and global lead of the Edelman AI Center of Excellence.\u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-04-20T20:15:00Z",
  "modifiedTime": "2025-04-18T22:19:25Z"
}
