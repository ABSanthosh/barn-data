{
  "id": "503cf59c-661f-4861-bbbc-75c50bd82d5f",
  "title": "OpenAI expands Realtime API with new voices and cuts prices for developers",
  "link": "https://venturebeat.com/ai/openai-expands-realtime-api-with-new-voices-and-cuts-prices-for-developers/",
  "description": "OpenAI's voice assistant API offers five new, more natural voices and discounted prices in the newest update.",
  "author": "Emilia David",
  "published": "Wed, 30 Oct 2024 23:25:33 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI-powered speech",
    "AI, ML and Deep Learning",
    "Anthropic",
    "API",
    "audio",
    "category-/Computers \u0026 Electronics/Programming",
    "category-/Science/Computer Science",
    "ChatGPT",
    "claude 3.5 sonnet",
    "Conversational AI",
    "ElevenLabs",
    "enterprises",
    "gpt-4o",
    "OpenAI",
    "Realtime API",
    "Replica Studios",
    "speech recognition",
    "speech-to-speech AI",
    "Text-to-Speech",
    "Voice Engine"
  ],
  "byline": "Emilia David",
  "length": 3892,
  "excerpt": "OpenAI's voice assistant API offers five new, more natural voices and discounted prices in the newest update.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "October 30, 2024 4:25 PM Credit: VentureBeat generated with MidJourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More OpenAI updated its Realtime API today, which is currently in beta. This update adds new voices for speech-to-speech applications to its platform and cuts costs associated with caching prompts.  Beta users of the Realtime API will now have five new voices they can use to build their applications. OpenAI showcased three of the new voices, Ash, Verse and the British-sounding Ballad, in a post on X.  Two Realtime API updates:– You can now build speech-to-speech experiences with five new voices—which are much more expressive and steerable. ???– We're lowering the price by using prompt caching. Cached text inputs are discounted 50% and cached audio inputs are discounted… pic.twitter.com/jLzZDBrR7l— OpenAI Developers (@OpenAIDevs) October 30, 2024 The company said in its API documentation that the native speech-to-speech feature “skip[s] an intermediate text format means low latency and nuanced output,” while the voices are easier to steer and more expressive than its previous voices.  However, OpenAI warns it cannot offer client-side authentication for the API now as it’s still in beta. It also said that there may be issues with processing real-time audio.  “Network conditions heavily affect real-time audio, and delivering audio reliably from a client to a server at scale is challenging when network conditions are unpredictable,” the company shared. OpenAI’s history with AI-powered speech and voices has been controversial. In March, it released Voice Engine, a voice cloning platform to rival ElevenLabs, but it limited access to only a few researchers. In May, after the company demoed its GPT-4o and Voice Mode, it paused using one of the voices, Sky, after the actress Scarlett Johansson spoke out about its similarity to her voice.  The company rolled out ChatGPT Advanced Voice Mode for paying subscribers (those using ChatGPT Plus, Enterprise, Teams and Edu) in the U.S. in September.  Speech-to-speech AI would ideally let enterprises build more real-time responses using a voice. Suppose a customer calls a company’s customer service platform. In that case, the speech-to-speech capability can take the person’s voice, understand what they are asking, and respond using an AI-generated voice with lower latency. Speech-to-speech also lets users generate voice-overs, with a user speaking their lines, but the voice output is not theirs. One platform that offers this is Replica and, of course, ElevenLabs.   OpenAI released the Realtime API this month during its Dev Day. The API aims to speed up the building of voice assistants. Lowering costs Using speech-to-speech features, though, could get expensive.  When Realtime API launched, the pricing structure was at $0.06 per minute of audio input and $0.24 per audio output, which is not cheap. However, the company plans to lower real-time API prices with prompt caching.  Cached text inputs will drop by 50%, and cached audio inputs will be discounted by 80%. OpenAI also announced Prompt Caching during Dev Day and would keep frequently requested contexts and prompts in the model’s memory. This will drop the number of tokens it needs to create to generate responses. Lowering input prices, could encourage more interested developers to connect to the API.  OpenAI is not the only company to roll out Prompt Caching. Anthropic launched prompt caching for Claude 3.5 Sonnet in August.  VB Daily Stay in the know! Get the latest news in your inbox daily By subscribing, you agree to VentureBeat's Terms of Service. Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_texting_chat_bubbles_300a7a07-e34c-403c-84a6-f491f3d23a49.webp?w=986?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-10-30T23:25:33+00:00\" datetime=\"2024-10-30T23:25:33+00:00\"\u003eOctober 30, 2024 4:25 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"421\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_texting_chat_bubbles_300a7a07-e34c-403c-84a6-f491f3d23a49.webp?w=750\" alt=\"Credit: VentureBeat generated with MidJourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat generated with MidJourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://openai.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenAI\u003c/a\u003e updated its Realtime API today, which is currently in beta. This update adds new voices for speech-to-speech applications to its platform and cuts costs associated with caching prompts. \u003c/p\u003e\n\n\n\n\u003cp\u003eBeta users of the Realtime API will now have five new voices they can use to build their applications. OpenAI showcased three of the new voices, Ash, Verse and the British-sounding Ballad, in a post on X. \u003c/p\u003e\n\n\n\n\u003cblockquote\u003e\u003cdiv lang=\"en\" dir=\"ltr\"\u003e\u003cp\u003eTwo Realtime API updates:\u003c/p\u003e\u003cp\u003e– You can now build speech-to-speech experiences with five new voices—which are much more expressive and steerable. ???\u003c/p\u003e\u003cp\u003e– We\u0026#39;re lowering the price by using prompt caching. Cached text inputs are discounted 50% and cached audio inputs are discounted… \u003ca href=\"https://t.co/jLzZDBrR7l\"\u003epic.twitter.com/jLzZDBrR7l\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e— OpenAI Developers (@OpenAIDevs) \u003ca href=\"https://twitter.com/OpenAIDevs/status/1851668229938159853?ref_src=twsrc%5Etfw\"\u003eOctober 30, 2024\u003c/a\u003e\u003c/blockquote\u003e \n\n\n\n\u003cp\u003eThe company said in its \u003ca href=\"https://platform.openai.com/docs/guides/realtime\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAPI documentation\u003c/a\u003e that the native speech-to-speech feature “skip[s] an intermediate text format means low latency and nuanced output,” while the voices are easier to steer and more expressive than its previous voices. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, OpenAI warns it cannot offer client-side authentication for the API now as it’s still in beta. It also said that there may be issues with processing real-time audio. \u003c/p\u003e\n\n\n\n\u003cp\u003e“Network conditions heavily affect real-time audio, and delivering audio reliably from a client to a server at scale is challenging when network conditions are unpredictable,” the company shared.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI’s history with AI-powered speech and voices has been controversial. In March, it \u003ca href=\"https://venturebeat.com/ai/openai-unveils-voice-cloning-ai-model-but-only-for-selected-partners-for-now/\"\u003ereleased Voice Engine\u003c/a\u003e, a voice cloning platform to rival \u003ca href=\"https://elevenlabs.io/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eElevenLabs\u003c/a\u003e, but it limited access to only a few researchers. In May, after the company demoed \u003ca href=\"https://venturebeat.com/ai/openai-announces-new-free-model-gpt-4o-and-chatgpt-for-desktop/\"\u003eits GPT-4o and Voice Mode\u003c/a\u003e, it paused using one of the voices, Sky, after the actress \u003ca href=\"https://venturebeat.com/ai/not-an-imitation-openai-pauses-chatgpt-voice-that-sounded-like-scarlett-johansson/\"\u003eScarlett Johansson spoke out\u003c/a\u003e about its similarity to her voice. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe \u003ca href=\"https://venturebeat.com/ai/openai-finally-brings-humanlike-chatgpt-advanced-voice-mode-to-u-s-plus-team-users/\"\u003ecompany rolled out ChatGPT Advanced Voice Mode\u003c/a\u003e for paying subscribers (those using ChatGPT Plus, Enterprise, Teams and Edu) in the U.S. in September. \u003c/p\u003e\n\n\n\n\u003cp\u003eSpeech-to-speech AI would ideally let enterprises build more real-time responses using a voice. Suppose a customer calls a company’s customer service platform. In that case, the speech-to-speech capability can take the person’s voice, understand what they are asking, and respond using an AI-generated voice with lower latency. Speech-to-speech also lets users generate voice-overs, with a user speaking their lines, but the voice output is not theirs. One platform that offers this is \u003ca href=\"https://www.replicastudios.com/products/speech-to-speech\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eReplica\u003c/a\u003e and, of course, ElevenLabs.  \u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI \u003ca href=\"https://venturebeat.com/ai/openai-devday-2024-4-major-updates-that-will-make-ai-more-accessible-and-affordable/\"\u003ereleased the Realtime API\u003c/a\u003e this month during its Dev Day. The API aims to speed up the building of voice assistants.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-lowering-costs\"\u003eLowering costs\u003c/h2\u003e\n\n\n\n\u003cp\u003eUsing speech-to-speech features, though, could get expensive. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhen Realtime API launched, the pricing structure was at $0.06 per minute of audio input and $0.24 per audio output, which is not cheap. However, the company plans to lower real-time API prices with prompt caching. \u003c/p\u003e\n\n\n\n\u003cp\u003eCached text inputs will drop by 50%, and cached audio inputs will be discounted by 80%.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI also announced Prompt Caching during Dev Day and would keep frequently requested contexts and prompts in the model’s memory. This will drop the number of tokens it needs to create to generate responses. Lowering input prices, could encourage more interested developers to connect to the API. \u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI is not the only company to roll out Prompt Caching. \u003ca href=\"https://www.anthropic.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAnthropic\u003c/a\u003e launched prompt caching for \u003ca href=\"https://venturebeat.com/ai/anthropics-new-claude-prompt-caching-will-save-developers-a-fortune/\"\u003eClaude 3.5 Sonnet in August\u003c/a\u003e. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eVB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eStay in the know! Get the latest news in your inbox daily\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eBy subscribing, you agree to VentureBeat\u0026#39;s \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003eTerms of Service.\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2024-10-30T23:25:33Z",
  "modifiedTime": "2024-10-31T00:01:17Z"
}
