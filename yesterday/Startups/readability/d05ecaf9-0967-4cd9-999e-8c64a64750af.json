{
  "id": "d05ecaf9-0967-4cd9-999e-8c64a64750af",
  "title": "Watch: Google DeepMind CEO and AI Nobel winner Demis Hassabis on CBS’ ’60 Minutes’",
  "link": "https://venturebeat.com/ai/watch-google-deepmind-ceo-and-ai-nobel-winner-demis-hassabis-on-cbs-60-minutes/",
  "description": "The segment ended with a meditation on the future: a world where AI tools could transform almost every human endeavor.",
  "author": "Carl Franzen",
  "published": "Mon, 21 Apr 2025 18:28:35 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "60 Minutes",
    "AI, ML and Deep Learning",
    "cbs",
    "Conversational AI",
    "DeepMind",
    "Demis Hassabis",
    "Google Deepmind",
    "NLP",
    "YouTube"
  ],
  "byline": "Carl Franzen",
  "length": 6006,
  "excerpt": "The segment ended with a meditation on the future: a world where AI tools could transform almost every human endeavor.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More A segment on CBS weekly in-depth TV news program 60 Minutes last night (also shared on YouTube here) offered an inside look at Google’s DeepMind and the vision of its co-founder and Nobel Prize-winning CEO, legendary AI researcher Demis Hassabis. The interview traced DeepMind’s rapid progress in artificial intelligence and its ambition to achieve artificial general intelligence (AGI)—a machine intelligence with human-like versatility and superhuman scale. Hassabis described today’s AI trajectory as being on an “exponential curve of improvement,” fueled by growing interest, talent, and resources entering the field. Two years after a prior 60 Minutes interview heralded the chatbot era, Hassabis and DeepMind are now pursuing more capable systems designed not only to understand language, but also the physical world around them. The interview came after Google’s Cloud Next 2025 conference earlier this month, in which the search giant introduced a host of new AI models and features centered around its Gemini 2.5 multimodal AI model family. Google came out of that conference appearing to have taken a lead compared to other tech companies at providing powerful AI for enterprise use cases at the most affordable price points, surpassing OpenAI. More details on Google DeepMind’s ‘Project Astra’ One of the segment’s focal points was Project Astra, DeepMind’s next-generation chatbot that goes beyond text. Astra is designed to interpret the visual world in real time. In one demo, it identified paintings, inferred emotional states, and created a story around a Hopper painting with the line: “Only the flow of ideas moving onward.” When asked if it was growing bored, Astra replied thoughtfully, revealing a degree of sensitivity to tone and interpersonal nuance. Product manager Bibbo Shu underscored Astra’s unique design: an AI that can “see, hear, and chat about anything”—a marked step toward embodied AI systems. Gemini: Toward actionable AI The broadcast also featured Gemini, DeepMind’s AI system being trained not only to interpret the world but also to act in it—completing tasks like booking tickets and shopping online. Hassabis said Gemini is a step toward AGI: an AI with a human-like ability to navigate and operate in complex environments. The 60 Minutes team tried out a prototype embedded in glasses, demonstrating real-time visual recognition and audio responses. Could it also hint at an upcoming return of the pioneering yet ultimately off-putting early augmented reality glasses known as Google Glass, which debuted in 2012 before being retired in 2015? While specific Gemini model versions like Gemini 2.5 Pro or Flash were not mentioned in the segment, Google’s broader AI ecosystem has recently introduced those models for enterprise use, which may reflect parallel development efforts. These integrations support Google’s growing ambitions in applied AI, though they fall outside the scope of what was directly covered in the interview. AGI as soon as 2030? When asked for a timeline, Hassabis projected AGI could arrive as soon as 2030, with systems that understand their environments “in very nuanced and deep ways.” He suggested that such systems could be seamlessly embedded into everyday life, from wearables to home assistants. The interview also addressed the possibility of self-awareness in AI. Hassabis said current systems are not conscious, but that future models could exhibit signs of self-understanding. Still, he emphasized the philosophical and biological divide: even if machines mimic conscious behavior, they are not made of the same “squishy carbon matter” as humans. Hassabis also predicted major developments in robotics, saying breakthroughs could come in the next few years. The segment featured robots completing tasks with vague instructions—like identifying a green block formed by mixing yellow and blue—suggesting rising reasoning abilities in physical systems. Accomplishments and safety concerns The segment revisited DeepMind’s landmark achievement with AlphaFold, the AI model that predicted the structure of over 200 million proteins. Hassabis and colleague John Jumper were awarded the 2024 Nobel Prize in Chemistry for this work. Hassabis emphasized that this advance could accelerate drug development, potentially shrinking timelines from a decade to just weeks. “I think one day maybe we can cure all disease with the help of AI,” he said. Despite the optimism, Hassabis voiced clear concerns. He cited two major risks: the misuse of AI by bad actors and the growing autonomy of systems beyond human control. He emphasized the importance of building in guardrails and value systems—teaching AI as one might teach a child. He also called for international cooperation, noting that AI’s influence will touch every country and culture. “One of my big worries,” he said, “is that the race for AI dominance could become a race to the bottom for safety.” He stressed the need for leading players and nation-states to coordinate on ethical development and oversight. The segment ended with a meditation on the future: a world where AI tools could transform almost every human endeavor—and eventually reshape how we think about knowledge, consciousness, and even the meaning of life. As Hassabis put it, “We need new great philosophers to come about… to understand the implications of this system.” Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/cfr0z3n_line_art_flat_illustration_messy_graphic_novel_style_do_103e5af2-a524-4a45-8f1b-04f6c5d201f7.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eA segment on CBS weekly in-depth TV news program \u003cem\u003e60 Minutes\u003c/em\u003e last night (\u003ca href=\"https://youtu.be/1XF-NG_35NE?si=WLyi091KeH5tslru\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ealso shared on YouTube here\u003c/a\u003e) offered an inside look at Google’s DeepMind and the vision of its co-founder and \u003ca href=\"https://venturebeat.com/ai/ai-wins-another-nobel-this-time-in-chemistry-google-deepminders-hassabis-and-jumper-awarded-for-alphafold/\"\u003eNobel Prize-winning CEO, legendary AI researcher Demis Hassabis\u003c/a\u003e. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe interview traced DeepMind’s rapid progress in artificial intelligence and its ambition to achieve artificial general intelligence (AGI)—a machine intelligence with human-like versatility and superhuman scale.\u003c/p\u003e\n\n\n\n\u003cp\u003eHassabis described today’s AI trajectory as being on an “exponential curve of improvement,” fueled by growing interest, talent, and resources entering the field. \u003c/p\u003e\n\n\n\n\u003cp\u003eTwo years after a prior \u003cem\u003e60 Minutes\u003c/em\u003e interview heralded the chatbot era, Hassabis and DeepMind are now pursuing more capable systems designed not only to understand language, but also the physical world around them.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe interview came after\u003ca href=\"https://venturebeat.com/ai/google-cloud-next-25-new-ai-chips-and-agent-ecosystem-challenge-microsoft-and-amazon/\"\u003e Google’s Cloud Next 2025 conference earlier this month\u003c/a\u003e, in which the search giant introduced a host of new AI models and features centered around its Gemini 2.5 multimodal AI model family. \u003ca href=\"https://venturebeat.com/ai/from-catch-up-to-catch-us-how-google-quietly-took-the-lead-in-enterprise-ai/\"\u003eGoogle came out of that conference appearing to have taken a lead \u003c/a\u003ecompared to other tech companies at providing powerful AI for enterprise use cases at the most affordable price points, surpassing OpenAI. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-more-details-on-google-deepmind-s-project-astra\"\u003eMore details on Google DeepMind’s ‘Project Astra’\u003c/h2\u003e\n\n\n\n\u003cp\u003eOne of the segment’s focal points was Project Astra, DeepMind’s next-generation chatbot that goes beyond text. Astra is designed to interpret the visual world in real time. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn one demo, it identified paintings, inferred emotional states, and created a story around a Hopper painting with the line: \u003cem\u003e“Only the flow of ideas moving onward.”\u003c/em\u003e \u003c/p\u003e\n\n\n\n\u003cp\u003eWhen asked if it was growing bored, Astra replied thoughtfully, revealing a degree of sensitivity to tone and interpersonal nuance. \u003c/p\u003e\n\n\n\n\u003cp\u003eProduct manager Bibbo Shu underscored Astra’s unique design: an AI that can “see, hear, and chat about anything”—a marked step toward embodied AI systems.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-gemini-toward-actionable-ai\"\u003eGemini: Toward actionable AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe broadcast also featured \u003cstrong\u003eGemini\u003c/strong\u003e, DeepMind’s AI system being trained not only to interpret the world but also to act in it—completing tasks like booking tickets and shopping online. \u003c/p\u003e\n\n\n\n\u003cp\u003eHassabis said Gemini is a step toward AGI: an AI with a human-like ability to navigate and operate in complex environments. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe \u003cem\u003e60 Minutes\u003c/em\u003e team tried out a prototype embedded in glasses, demonstrating real-time visual recognition and audio responses. Could it also hint at an upcoming return of the pioneering yet ultimately off-putting early augmented reality glasses known as Google Glass, \u003ca href=\"https://glassalmanac.com/history-google-glass/\"\u003ewhich debuted in 2012\u003c/a\u003e before \u003ca href=\"https://www.vice.com/en/article/how-glassholes-are-handling-the-end-of-google-glass/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ebeing retired in 2015\u003c/a\u003e? \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile specific Gemini model versions like \u003ca href=\"https://venturebeat.com/ai/from-catch-up-to-catch-us-how-google-quietly-took-the-lead-in-enterprise-ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGemini 2.5 Pro or Flash\u003c/a\u003e were not mentioned in the segment, Google’s broader AI ecosystem has recently introduced those models for enterprise use, which may reflect parallel development efforts. \u003c/p\u003e\n\n\n\n\u003cp\u003eThese integrations support Google’s growing ambitions in applied AI, though they fall outside the scope of what was directly covered in the interview.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-agi-as-soon-as-2030\"\u003eAGI as soon as 2030?\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhen asked for a timeline, Hassabis projected AGI could arrive as soon as 2030, with systems that understand their environments “in very nuanced and deep ways.” He suggested that such systems could be seamlessly embedded into everyday life, from wearables to home assistants.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe interview also addressed the possibility of self-awareness in AI. Hassabis said current systems are not conscious, but that future models could exhibit signs of self-understanding. Still, he emphasized the philosophical and biological divide: even if machines mimic conscious behavior, they are not made of the same “squishy carbon matter” as humans.\u003c/p\u003e\n\n\n\n\u003cp\u003eHassabis also predicted major developments in robotics, saying breakthroughs could come in the next few years. The segment featured robots completing tasks with vague instructions—like identifying a green block formed by mixing yellow and blue—suggesting rising reasoning abilities in physical systems.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-accomplishments-and-safety-concerns\"\u003eAccomplishments and safety concerns\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe segment revisited DeepMind’s landmark achievement with AlphaFold, the AI model that predicted the structure of over 200 million proteins. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://venturebeat.com/ai/ai-wins-another-nobel-this-time-in-chemistry-google-deepminders-hassabis-and-jumper-awarded-for-alphafold/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHassabis and colleague John Jumper were awarded the 2024 Nobel Prize in Chemistry for this work\u003c/a\u003e. Hassabis emphasized that this advance could accelerate drug development, potentially shrinking timelines from a decade to just weeks. “I think one day maybe we can cure all disease with the help of AI,” he said.\u003c/p\u003e\n\n\n\n\u003cp\u003eDespite the optimism, Hassabis voiced clear concerns. He cited two major risks: the misuse of AI by bad actors and the growing autonomy of systems beyond human control. He emphasized the importance of building in guardrails and value systems—teaching AI as one might teach a child. He also called for international cooperation, noting that AI’s influence will touch every country and culture.\u003c/p\u003e\n\n\n\n\u003cp\u003e“One of my big worries,” he said, “is that the race for AI dominance could become a race to the bottom for safety.” He stressed the need for leading players and nation-states to coordinate on ethical development and oversight.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe segment ended with a meditation on the future: a world where AI tools could transform almost every human endeavor—and eventually reshape how we think about knowledge, consciousness, and even the meaning of life. As Hassabis put it, “We need new great philosophers to come about… to understand the implications of this system.”\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-04-21T18:28:35Z",
  "modifiedTime": "2025-04-21T18:28:43Z"
}
