{
  "id": "4de8411b-b97d-4693-89fa-1369c730431f",
  "title": "The open-source AI debate: Why selective transparency poses a serious risk",
  "link": "https://venturebeat.com/ai/the-open-source-ai-debate-why-selective-transparency-poses-a-serious-risk/",
  "description": "It is misleading to call AI open source when no one can look at, experiment with and understand each element that went into creating it.",
  "author": "Jason Corso, University of Michigan, Voxel51",
  "published": "Sat, 22 Mar 2025 20:45:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "Apache Spark",
    "category-/Science/Computer Science",
    "linux",
    "MySQL",
    "Open source",
    "open source AI",
    "php"
  ],
  "byline": "Jason Corso, University of Michigan, Voxel51",
  "length": 7789,
  "excerpt": "It is misleading to call AI open source when no one can look at, experiment with and understand each element that went into creating it.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More As tech giants declare their AI releases open — and even put the word in their names — the once insider term “open source” has burst into the modern zeitgeist. During this precarious time in which one company’s misstep could set back the public’s comfort with AI by a decade or more, the concepts of openness and transparency are being wielded haphazardly, and sometimes dishonestly, to breed trust.  At the same time, with the new White House administration taking a more hands-off approach to tech regulation, the battle lines have been drawn — pitting innovation against regulation and predicting dire consequences if the “wrong” side prevails.  There is, however, a third way that has been tested and proven through other waves of technological change. Grounded in the principles of openness and transparency, true open source collaboration unlocks faster rates of innovation even as it empowers the industry to develop technology that is unbiased, ethical and beneficial to society.  Understanding the power of true open source collaboration Put simply, open-source software features freely available source code that can be viewed, modified, dissected, adopted and shared for commercial and noncommercial purposes — and historically, it has been monumental in breeding innovation. Open-source offerings Linux, Apache, MySQL and PHP, for example, unleashed the internet as we know it.  Now, by democratizing access to AI models, data, parameters and open-source AI tools, the community can once again unleash faster innovation instead of continually recreating the wheel — which is why a recent IBM study of 2,400 IT decision-makers revealed a growing interest in using open-source AI tools to drive ROI. While faster development and innovation were at the top of the list when it came to determining ROI in AI, the research also confirmed that embracing open solutions may correlate to greater financial viability. Instead of short-term gains that favor fewer companies, open-source AI invites the creation of more diverse and tailored applications across industries and domains that might not otherwise have the resources for proprietary models.  Perhaps as importantly, the transparency of open source allows for independent scrutiny and auditing of AI systems’ behaviors and ethics — and when we leverage the existing interest and drive of the masses, they will find the problems and mistakes as they did with the LAION 5B dataset fiasco.  In that case, the crowd rooted out more than 1,000 URLs containing verified child sexual abuse material hidden in the data that fuels generative AI models like Stable Diffusion and Midjourney — which produce images from text and image prompts and are foundational in many online video-generating tools and apps.  While this finding caused an uproar, if that dataset had been closed, as with OpenAI’s Sora or Google’s Gemini, the consequences could have been far worse. It’s hard to imagine the backlash that would ensue if AI’s most exciting video creation tools started churning out disturbing content. Thankfully, the open nature of the LAION 5B dataset empowered the community to motivate its creators to partner with industry watchdogs to find a fix and release ​​RE-LAION 5B — which exemplifies why the transparency of true open-source AI not only benefits users, but the industry and creators who are working to build trust with consumers and the general public.  The danger of open sourcery in AI While source code alone is relatively easy to share, AI systems are far more complicated than software. They rely on system source code, as well as the model parameters, dataset, hyperparameters, training source code, random number generation and software frameworks — and each of these components must work in concert for an AI system to work properly. Amid concerns around safety in AI, it has become commonplace to state that a release is open or open source. For this to be accurate, however, innovators must share all the pieces of the puzzle so that other players can fully understand, analyze and assess the AI system’s properties to ultimately reproduce, modify and extend its capabilities.  Meta, for example, touted Llama 3.1 405B as “the first frontier-level open-source AI model,” but only publicly shared the system’s pre-trained parameters, or weights, and a bit of software. While this allows users to download and use the model at will, key components like the source code and dataset remain closed — which becomes more troubling in the wake of the announcement that Meta will inject AI bot profiles into the ether even as it stops vetting content for accuracy.  To be fair, what is being shared certainly contributes to the community. Open weight models offer flexibility, accessibility, innovation and a level of transparency. DeepSeek’s decision to open source its weights, release its technical reports for R1 and make it free to use, for example, has enabled the AI community to study and verify its methodology and weave it into their work.  It is misleading, however, to call an AI system open source when no one can actually look at, experiment with and understand each piece of the puzzle that went into creating it. This misdirection does more than threaten public trust. Instead of empowering everyone in the community to collaborate, build and advance upon models like Llama X, it forces innovators using such AI systems to blindly trust the components that are not shared. Embracing the challenge before us As self-driving cars take to the streets in major cities and AI systems assist surgeons in the operating room, we are only at the beginning of letting this technology take the proverbial wheel. The promise is immense, as is the potential for error — which is why we need new measures of what it means to be trustworthy in the world of AI. Even as Anka Reuel and colleagues at Stanford University recently attempted to set up a new framework for the AI benchmarks used to assess how well models perform, for example, the review practice the industry and the public rely on is not yet sufficient. Benchmarking fails to account for the fact that datasets at the core of learning systems are constantly changing and that appropriate metrics vary from use case to use case. The field also still lacks a rich mathematical language to describe the capabilities and limitations in contemporary AI.  By sharing entire AI systems to enable openness and transparency instead of relying on insufficient reviews and paying lip service to buzzwords, we can foster greater collaboration and cultivate innovation with safe and ethically developed AI.  While true open-source AI offers a proven framework for achieving these goals, there’s a concerning lack of transparency in the industry. Without bold leadership and cooperation from tech companies to self-govern, this information gap could hurt public trust and acceptance. Embracing openness, transparency and open source is not just a strong business model — it’s also about choosing between an AI future that benefits everyone instead of just the few.  Jason Corso is a professor at the University of Michigan and co-founder of Voxel51. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/03/nuneybits_Abstract_art_of_robot_scientist_vs_robot_businessman_632ad8fb-90de-4747-8bda-2faf5ffcd5be.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eAs tech giants declare their \u003ca href=\"https://venturebeat.com/ai/launching-your-first-ai-project-with-a-grain-of-rice-weighing-reach-impact-confidence-and-effort-to-create-your-roadmap/\"\u003eAI releases\u003c/a\u003e open — and even put the word in their names — the once insider term “open source” has burst into the modern zeitgeist. During this precarious time in which one company’s misstep could set back the public’s comfort with AI by a decade or more, the concepts of openness and transparency are being wielded haphazardly, and sometimes dishonestly, to breed trust. \u003c/p\u003e\n\n\n\n\u003cp\u003eAt the same time, with the new White House administration taking a more hands-off approach to tech regulation, the battle lines have been drawn — pitting innovation against regulation and predicting dire consequences if the “wrong” side prevails. \u003c/p\u003e\n\n\n\n\u003cp\u003eThere is, however, a third way that has been tested and proven through other waves of \u003ca href=\"https://venturebeat.com/ai/the-great-software-rewiring-ai-isnt-just-eating-everything-it-is-everything/\"\u003etechnological change\u003c/a\u003e. Grounded in the principles of openness and transparency, true open source collaboration unlocks faster rates of innovation even as it empowers the industry to develop technology that is unbiased, ethical and beneficial to society. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-understanding-the-power-of-true-open-source-collaboration\"\u003eUnderstanding the power of true open source collaboration\u003c/h2\u003e\n\n\n\n\u003cp\u003ePut simply, open-source software features freely available source code that can be viewed, modified, dissected, adopted and shared for commercial and noncommercial purposes — and historically, it has been monumental in breeding innovation. Open-source offerings Linux, Apache, MySQL and PHP, for example, unleashed the internet as we know it. \u003c/p\u003e\n\n\n\n\u003cp\u003eNow, by democratizing access to AI models, data, parameters and open-source AI tools, the community can once again unleash faster innovation instead of continually recreating the wheel — which is why a recent IBM study of \u003ca href=\"https://newsroom.ibm.com/image/IBM_ROI_of_AI_Report-December_2024.pdf\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e2,400 IT decision-makers\u003c/a\u003e revealed a growing interest in using open-source AI tools to drive ROI. While faster development and innovation were at the top of the list when it came to determining ROI in AI, the research also confirmed that embracing open solutions may correlate to greater financial viability.\u003c/p\u003e\n\n\n\n\u003cp\u003eInstead of short-term gains that favor fewer companies, open-source AI invites the creation of more diverse and tailored applications across industries and domains that might not otherwise have the resources for proprietary models. \u003c/p\u003e\n\n\n\n\u003cp\u003ePerhaps as importantly, the transparency of open source allows for independent scrutiny and auditing of AI systems’ behaviors and ethics — and when we leverage the existing interest and drive of the masses, they will find the problems and mistakes as they did with the \u003ca href=\"https://techcrunch.com/2024/08/30/the-org-behind-the-data-set-used-to-train-stable-diffusion-claims-it-has-removed-csam/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLAION 5B dataset\u003c/a\u003e fiasco. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn that case, the crowd rooted out more than \u003ca href=\"https://cyber.fsi.stanford.edu/news/investigation-finds-ai-image-generation-models-trained-child-abuse\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e1,000 URLs\u003c/a\u003e containing verified child sexual abuse material hidden in the data that fuels generative AI models like Stable Diffusion and Midjourney — which produce images from text and image prompts and are foundational in many online video-generating tools and apps. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile this finding caused an uproar, if that dataset had been closed, as with OpenAI’s Sora or Google’s Gemini, the consequences could have been far worse. It’s hard to imagine the backlash that would ensue if AI’s most exciting video creation tools started churning out disturbing content.\u003c/p\u003e\n\n\n\n\u003cp\u003eThankfully, the open nature of the LAION 5B dataset empowered the community to motivate its creators to partner with industry watchdogs to find a fix and release ​​RE-LAION 5B — which exemplifies why the transparency of true open-source AI not only benefits users, but the industry and creators who are working to build trust with consumers and the general public. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-danger-of-open-sourcery-in-ai\"\u003eThe danger of open sourcery in AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile source code alone is relatively easy to share, \u003ca href=\"https://venturebeat.com/ai/inching-towards-agi-how-reasoning-and-deep-research-are-expanding-ai-from-statistical-prediction-to-structured-problem-solving/\"\u003eAI systems are far more complicated\u003c/a\u003e than software. They rely on system source code, as well as the model parameters, dataset, hyperparameters, training source code, random number generation and software frameworks — and each of these components must work in concert for an AI system to work properly.\u003c/p\u003e\n\n\n\n\u003cp\u003eAmid concerns around safety in AI, it has become commonplace to state that a release is open or open source. For this to be accurate, however, innovators must share all the pieces of the puzzle so that other players can fully understand, analyze and assess the AI system’s properties to ultimately reproduce, modify and extend its capabilities. \u003c/p\u003e\n\n\n\n\u003cp\u003eMeta, for example, \u003ca href=\"https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/#:~:text=We\u0026#39;re%20releasing%20Llama%203.1,3.1%2070B%20and%208B%20models.\" target=\"_blank\" rel=\"noreferrer noopener\"\u003etouted Llama 3.1 405B\u003c/a\u003e as “the first frontier-level open-source AI model,” but only publicly shared the system’s pre-trained parameters, or weights, and a bit of software. While this allows users to download and use the model at will, key components like the source code and dataset remain closed — which becomes more troubling in the wake of \u003ca href=\"https://www.ft.com/content/91183cbb-50f9-464a-9d2e-96063825bfcf?accessToken=zwAGKtJylI4IkdORGDy7UPlGStOdLpYGOCW_zw.MEYCIQD6c_oDOapiyYQRKJvE-z5yzgjbahivq3W2A5LQfpo1iwIhAOpCPXzkaE8uNKgQ0MPL3ZlZ9YoVYjFxqQXsfS66h_5l\u0026amp;sharetype=gift\u0026amp;token=aaca08df-570c-43cc-b86a-9c43d5db9dc9\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ethe announcement that Meta\u003c/a\u003e will inject AI bot profiles into the ether even as it stops vetting content for accuracy. \u003c/p\u003e\n\n\n\n\u003cp\u003eTo be fair, what is being shared certainly contributes to the community. Open weight models offer flexibility, accessibility, innovation and a level of transparency. DeepSeek’s decision to open source its weights, release its technical reports for R1 and make it free to use, for example, has enabled the AI community to study and verify its methodology and weave it into their work. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt is \u003ca href=\"https://medium.com/@jasoncorso/is-open-source-ai-bull-9da010411658\" target=\"_blank\" rel=\"noreferrer noopener\"\u003emisleading\u003c/a\u003e, however, to call an AI system open source when no one can actually look at, experiment with and understand each piece of the puzzle that went into creating it.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis misdirection does more than threaten public trust. Instead of empowering everyone in the community to collaborate, build and advance upon models like Llama X, it forces innovators using such AI systems to blindly trust the components that are not shared.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-embracing-the-challenge-before-us\"\u003eEmbracing the challenge before us\u003c/h2\u003e\n\n\n\n\u003cp\u003eAs self-driving cars take to the streets in major cities and AI systems assist surgeons in the operating room, we are only at the beginning of letting this technology take the proverbial wheel. The promise is immense, as is the potential for error — which is why we need new measures of what it means to be trustworthy in the world of AI.\u003c/p\u003e\n\n\n\n\u003cp\u003eEven as Anka Reuel and colleagues at Stanford University \u003ca href=\"https://hai.stanford.edu/what-makes-good-ai-benchmark\" target=\"_blank\" rel=\"noreferrer noopener\"\u003erecently attempted\u003c/a\u003e to set up a new framework for the AI benchmarks used to assess how well models perform, for example, the review practice the industry and the public rely on is not yet sufficient. Benchmarking fails to account for the fact that datasets at the core of learning systems are constantly changing and that appropriate metrics vary from use case to use case. The field also still lacks a rich mathematical language to describe the capabilities and limitations in contemporary AI. \u003c/p\u003e\n\n\n\n\u003cp\u003eBy sharing entire AI systems to enable openness and transparency instead of relying on insufficient reviews and paying lip service to buzzwords, we can foster greater collaboration and cultivate innovation with safe and ethically developed AI. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile true open-source AI offers a proven framework for achieving these goals, there’s a concerning lack of transparency in the industry. Without bold leadership and cooperation from tech companies to self-govern, this information gap could hurt public trust and acceptance. Embracing openness, transparency and open source is not just a strong business model — it’s also about choosing between an AI future that benefits everyone instead of just the few. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eJason Corso is a professor at the University of Michigan and co-founder of \u003ca href=\"https://voxel51.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eVoxel51\u003c/a\u003e. \u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-03-22T20:45:00Z",
  "modifiedTime": "2025-03-22T20:51:10Z"
}
