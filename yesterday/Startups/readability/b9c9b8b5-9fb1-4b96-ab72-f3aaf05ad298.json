{
  "id": "b9c9b8b5-9fb1-4b96-ab72-f3aaf05ad298",
  "title": "Small models as paralegals: LexisNexis distills models to build AI assistant",
  "link": "https://venturebeat.com/ai/small-models-as-paralegals-lexisnexis-distills-models-to-build-ai-assistant/",
  "description": "LexisNexis fine-tuned Mistral models to build its Protege AI assistant, relying on distilled and small models for its AI platform.",
  "author": "Emilia David",
  "published": "Thu, 20 Mar 2025 23:06:20 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI assistant",
    "AI, ML and Deep Learning",
    "Anthropic",
    "category-/Law \u0026 Government",
    "distilling",
    "Legal AI",
    "Lexis Nexis",
    "LexisNexis",
    "LLMs",
    "Mistral AI",
    "Model Distillation",
    "Protégé",
    "small language models",
    "small language models (SLMs)"
  ],
  "byline": "Emilia David",
  "length": 6373,
  "excerpt": "LexisNexis fine-tuned Mistral models to build its Protege AI assistant, relying on distilled and small models for its AI platform.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "March 20, 2025 4:06 PM Credit: VentureBeat, generated with MidJourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More When legal research company LexisNexis created its AI assistant Protégé, it wanted to figure out the best way to leverage its expertise without deploying a large model.  Protégé aims to help lawyers, associates and paralegals write and proof legal documents and ensure that anything they cite in complaints and briefs is accurate. However, LexisNexis didn’t want a general legal AI assistant; they wanted to build one that learns a firm’s workflow and is more customizable.  LexisNexis saw the opportunity to bring the power of large language models (LLMs) from Anthropic and Mistral and find the best models that answer user questions the best, Jeff Riehl, CTO of LexisNexis Legal and Professional, told VentureBeat. “We use the best model for the specific use case as part of our multi-model approach. We use the model that provides the best result with the fastest response time,” Riehl said. “For some use cases, that will be a small language model like Mistral or we perform distillation to improve performance and reduce cost.” While LLMs still provide value in building AI applications, some organizations turn to using small language models (SLMs) or distilling LLMs to become small versions of the same model.  Distillation, where an LLM “teaches” a smaller model, has become a popular method for many organizations.  Small models often work best for apps like chatbots or simple code completion, which is what LexisNexis wanted to use for Protégé.  This is not the first time LexisNexis built AI applications, even before launching its legal research hub LexisNexis + AI in July 2024. “We have used a lot of AI in the past, which was more around natural language processing, some deep learning and machine learning,” Riehl said. “That really changed in November 2022 when ChatGPT was launched, because prior to that, a lot of the AI capabilities were kind of behind the scenes. But once ChatGPT came out, the generative capabilities, the conversational capabilities of it was very, very intriguing to us.” Small, fine-tuned models and model routing  Riehl said LexisNexis uses different models from most of the major model providers when building its AI platforms. LexisNexis + AI used Claude models from Anthropic, OpenAI’s GPT models and a model from Mistral.  This multimodal approach helped break down each task users wanted to perform on the platform. To do this, LexisNexis had to architect its platform to switch between models.  “We would break down whatever task was being performed into individual components, and then we would identify the best large language model to support that component. One example of that is we will use Mistral to assess the query that the user entered in,” Riehl said.  For Protégé, the company wanted faster response times and models more fine-tuned for legal use cases. So it turned to what Riehl calls “fine-tuned” versions of models, essentially smaller weight versions of LLMs or distilled models.  “You don’t need GPT-4o to do the assessment of a query, so we use it for more sophisticated work, and we switch models out,” he said.  When a user asks Protégé a question about a specific case, the first model it pings is a fine-tuned Mistral “for assessing the query, then determining what the purpose and intent of that query is” before switching to the model best suited to complete the task. Riehl said the next model could be an LLM that generates new queries for the search engine or another model that summarizes results.  Right now, LexisNexis mostly relies on a fine-tuned Mistral model though Riehl said it used a fine-tuned version of Claude “when it first came out; we are not using it in the product today but in other ways.” LexisNexis is also interested in using other OpenAI models especially since the company came out with new reinforcement fine-tuning capabilities last year. LexisNexis is in the process of evaluating OpenAI’s reasoning models including o3 for its platforms.  Riehl added that it may also look at using Gemini models from Google.  LexisNexis backs all of its AI platforms with its own knowledge graph to perform retrieval augmented generation (RAG) capabilities, especially as Protégé could help launch agentic processes later.  The AI legal suite Even before the advent of generative AI, LexisNexis tested the possibility of putting chatbots to work in the legal industry. In 2017, the company tested an AI assistant that would compete with IBM’s Watson-powered Ross and Protégé sits in the company’s LexisNexis + AI platform, which brings together the AI services of LexisNexis.  Protégé helps law firms with tasks that paralegals or associates tend to do. It helps write legal briefs and complaints that are grounded in firms’ documents and data, suggest legal workflow next steps, suggest new prompts to refine searches, draft questions for depositions and discovery, link quotes in filings for accuracy, generate timelines and, of course, summarize complex legal documents.  “We see Protégé as the initial step in personalization and agentic capabilities,” Riehl said. “Think about the different types of lawyers: M\u0026A, litigators, real estate. It’s going to continue to get more and more personalized based on the specific task you do. Our vision is that every legal professional will have a personal assistant to help them do their job based on what they do, not what other lawyers do.” Protégé now competes against other legal research and technology platforms. Thomson Reuters customized OpenAI’s o1-mini-model for its CoCounsel legal assistant. Harvey, which raised $300 million from investors including LexisNexis, also has a legal AI assistant.  Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/03/crimedy7_illustration_of_a_robot_lawyer_in_a_courtroom_comic_st_0f329656-c60d-42b3-b0e9-daa3cdaa1eb6.jpeg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-03-20T23:06:20+00:00\" datetime=\"2025-03-20T23:06:20+00:00\"\u003eMarch 20, 2025 4:06 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2025/03/crimedy7_illustration_of_a_robot_lawyer_in_a_courtroom_comic_st_0f329656-c60d-42b3-b0e9-daa3cdaa1eb6.jpeg?w=750\" alt=\"Credit: VentureBeat, generated with MidJourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat, generated with MidJourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eWhen legal research company \u003ca href=\"https://www.lexisnexis.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLexisNexis\u003c/a\u003e created its AI assistant Protégé, it wanted to figure out the best way to leverage its expertise without deploying a large model. \u003c/p\u003e\n\n\n\n\u003cp\u003eProtégé aims to help lawyers, associates and paralegals write and proof legal documents and ensure that anything they cite in \u003ca href=\"https://venturebeat.com/ai/stanford-study-finds-ai-legal-research-tools-prone-to-hallucinations/\"\u003ecomplaints and briefs is accurate\u003c/a\u003e. However, LexisNexis didn’t want a general legal AI assistant; they wanted to build one that learns a firm’s workflow and is more customizable. \u003c/p\u003e\n\n\n\n\u003cp\u003eLexisNexis saw the opportunity to bring the power of large language models (LLMs) from Anthropic and Mistral and find the best models that answer user questions the best, Jeff Riehl, CTO of LexisNexis Legal and Professional, told VentureBeat.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We use the best model for the specific use case as part of our multi-model approach. We use the model that provides the best result with the fastest response time,” Riehl said. “For some use cases, that will be a small language model like Mistral or we perform distillation to improve performance and reduce cost.”\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile LLMs still provide value in building AI applications, some organizations turn to using small language models (SLMs) or distilling LLMs to become small versions of the same model. \u003c/p\u003e\n\n\n\n\u003cp\u003eDistillation, where an LLM “teaches” a smaller model, has \u003ca href=\"https://venturebeat.com/ai/deepseeks-r1-and-openais-deep-research-just-redefined-ai-rag-distillation-and-custom-models-will-never-be-the-same/\"\u003ebecome a popular method\u003c/a\u003e for many organizations. \u003c/p\u003e\n\n\n\n\u003cp\u003eSmall models often work best for apps like chatbots or simple code completion, which is what LexisNexis wanted to use for Protégé. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis is not the first time LexisNexis built AI applications, even before launching its legal research hub LexisNexis + AI in July 2024.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We have used a lot of AI in the past, which was more around natural language processing, some deep learning and machine learning,” Riehl said. “That really changed in November 2022 when ChatGPT was launched, because prior to that, a lot of the AI capabilities were kind of behind the scenes. But once ChatGPT came out, the generative capabilities, the conversational capabilities of it was very, very intriguing to us.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-small-fine-tuned-models-and-model-routing-nbsp\"\u003eSmall, fine-tuned models and model routing \u003c/h2\u003e\n\n\n\n\u003cp\u003eRiehl said LexisNexis uses different models from most of the major model providers when building its AI platforms. LexisNexis + AI used Claude models from Anthropic, OpenAI’s GPT models and a model from Mistral. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis multimodal approach helped break down each task users wanted to perform on the platform. To do this, LexisNexis had to architect its platform to \u003ca href=\"https://venturebeat.com/ai/why-accenture-and-martian-see-model-routing-as-key-to-enterprise-ai-success/\"\u003eswitch between models\u003c/a\u003e. \u003c/p\u003e\n\n\n\n\u003cp\u003e“We would break down whatever task was being performed into individual components, and then we would identify the best large language model to support that component. One example of that is we will use Mistral to assess the query that the user entered in,” Riehl said. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor Protégé, the company wanted faster response times and models more fine-tuned for legal use cases. So it turned to what Riehl calls “fine-tuned” versions of models, essentially smaller weight versions of LLMs or distilled models. \u003c/p\u003e\n\n\n\n\u003cp\u003e“You don’t need GPT-4o to do the assessment of a query, so we use it for more sophisticated work, and we switch models out,” he said. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhen a user asks Protégé a question about a specific case, the first model it pings is a fine-tuned Mistral “for assessing the query, then determining what the purpose and intent of that query is” before switching to the model best suited to complete the task. Riehl said the next model could be an LLM that generates new queries for the search engine or another model that summarizes results. \u003c/p\u003e\n\n\n\n\u003cp\u003eRight now, LexisNexis mostly relies on a fine-tuned Mistral model though Riehl said it used a fine-tuned version of Claude “when it first came out; we are not using it in the product today but in other ways.” LexisNexis is also interested in using other OpenAI models especially since the company came out with new \u003ca href=\"https://venturebeat.com/ai/openai-releases-new-ai-fine-tuning-tools-vast-majority-of-organizations-will-develop-customized-models/\"\u003ereinforcement fine-tuning capabilities\u003c/a\u003e last year. LexisNexis is in the process of evaluating OpenAI’s reasoning models including o3 for its platforms. \u003c/p\u003e\n\n\n\n\u003cp\u003eRiehl added that it may also look at using Gemini models from Google. \u003c/p\u003e\n\n\n\n\u003cp\u003eLexisNexis backs all of its AI platforms with its own knowledge graph to perform retrieval augmented generation (RAG) capabilities, especially as Protégé could help launch agentic processes later. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-ai-legal-suite\"\u003eThe AI legal suite\u003c/h2\u003e\n\n\n\n\u003cp\u003eEven before the advent of generative AI, LexisNexis tested the possibility of putting chatbots to work in the legal industry. In 2017, the \u003ca href=\"https://venturebeat.com/ai/lexisnexis-is-testing-chatbots-for-lawyers/\"\u003ecompany tested an AI assistant\u003c/a\u003e that would compete with IBM’s Watson-powered Ross and Protégé sits in the company’s LexisNexis + AI platform, which brings together the AI services of LexisNexis. \u003c/p\u003e\n\n\n\n\u003cp\u003eProtégé helps law firms with tasks that paralegals or associates tend to do. It helps write legal briefs and complaints that are grounded in firms’ documents and data, suggest legal workflow next steps, suggest new prompts to refine searches, draft questions for depositions and discovery, link quotes in filings for accuracy, generate timelines and, of course, summarize complex legal documents. \u003c/p\u003e\n\n\n\n\u003cp\u003e“We see Protégé as the initial step in personalization and agentic capabilities,” Riehl said. “Think about the different types of lawyers: M\u0026amp;A, litigators, real estate. It’s going to continue to get more and more personalized based on the specific task you do. Our vision is that every legal professional will have a personal assistant to help them do their job based on what they do, not what other lawyers do.”\u003c/p\u003e\n\n\n\n\u003cp\u003eProtégé now competes against other legal research and technology platforms. Thomson Reuters customized OpenAI’s o1-mini-model for its \u003ca href=\"https://venturebeat.com/ai/thomson-reuters-cocounsel-redefines-legal-ai-with-openais-o1-mini-model/\"\u003eCoCounsel legal assistant\u003c/a\u003e. Harvey, which \u003ca href=\"https://www.harvey.ai/blog/harvey-raises-series-d\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eraised $300 million\u003c/a\u003e from investors including LexisNexis, also has a legal AI assistant. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-03-20T23:06:20Z",
  "modifiedTime": "2025-03-20T23:06:27Z"
}
