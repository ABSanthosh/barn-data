{
  "id": "d82e4ac6-6b98-47cd-8b78-382d6a0f8352",
  "title": "Google’s Gemini 2.5 Flash introduces ‘thinking budgets’ that cut AI costs by 600% when turned down",
  "link": "https://venturebeat.com/ai/googles-gemini-2-5-flash-introduces-thinking-budgets-that-cut-ai-costs-by-600-when-turned-down/",
  "description": "Google's new Gemini 2.5 Flash AI model introduces adjustable \"thinking budgets\" that let businesses pay only for the reasoning power they need, balancing advanced capabilities with cost efficiency.",
  "author": "Michael Nuñez",
  "published": "Thu, 17 Apr 2025 23:27:30 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Data Infrastructure",
    "Enterprise Analytics",
    "Programming \u0026 Development",
    "Security",
    "AI cost",
    "AI cost control",
    "AI market competition",
    "AI model efficiency",
    "AI pricing",
    "AI reasoning tokens",
    "AI thinking budget",
    "AI token pricing",
    "AI, ML and Deep Learning",
    "Business AI solutions",
    "Conversational AI",
    "Data Management",
    "Data Science",
    "Data Security and Privacy",
    "enterprise ai",
    "Enterprise AI pricing",
    "Gemini 2.5 Flash",
    "Gemini vs. ChatGPT",
    "Google Deepmind",
    "Google Gemini 2.5 Flash",
    "NLP",
    "Variable AI pricing"
  ],
  "byline": "Michael Nuñez",
  "length": 8327,
  "excerpt": "Google's new Gemini 2.5 Flash AI model introduces adjustable \"thinking budgets\" that let businesses pay only for the reasoning power they need, balancing advanced capabilities with cost efficiency.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "April 17, 2025 4:27 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Google has launched Gemini 2.5 Flash, a major upgrade to its AI lineup that gives businesses and developers unprecedented control over how much “thinking” their AI performs. The new model, released today in preview through Google AI Studio and Vertex AI, represents a strategic effort to deliver improved reasoning capabilities while maintaining competitive pricing in the increasingly crowded AI market. The model introduces what Google calls a “thinking budget” — a mechanism that allows developers to specify how much computational power should be allocated to reasoning through complex problems before generating a response. This approach aims to address a fundamental tension in today’s AI marketplace: more sophisticated reasoning typically comes at the cost of higher latency and pricing. “We know cost and latency matter for a number of developer use cases, and so we want to offer developers the flexibility to adapt the amount of the thinking the model does, depending on their needs,” said Tulsee Doshi, Product Director for Gemini Models at Google DeepMind, in an exclusive interview with VentureBeat. This flexibility reveals Google’s pragmatic approach to AI deployment as the technology increasingly becomes embedded in business applications where cost predictability is essential. By allowing the thinking capability to be turned on or off, Google has created what it calls its “first fully hybrid reasoning model.” Pay only for the brainpower you need: Inside Google’s new AI pricing model The new pricing structure highlights the cost of reasoning in today’s AI systems. When using Gemini 2.5 Flash, developers pay $0.15 per million tokens for input. Output costs vary dramatically based on reasoning settings: $0.60 per million tokens with thinking turned off, jumping to $3.50 per million tokens with reasoning enabled. This nearly sixfold price difference for reasoned outputs reflects the computational intensity of the “thinking” process, where the model evaluates multiple potential paths and considerations before generating a response. “Customers pay for any thinking and output tokens the model generates,” Doshi told VentureBeat. “In the AI Studio UX, you can see these thoughts before a response. In the API, we currently don’t provide access to the thoughts, but a developer can see how many tokens were generated.” The thinking budget can be adjusted from 0 to 24,576 tokens, operating as a maximum limit rather than a fixed allocation. According to Google, the model intelligently determines how much of this budget to use based on the complexity of the task, preserving resources when elaborate reasoning isn’t necessary. How Gemini 2.5 Flash stacks up: Benchmark results against leading AI models Google claims Gemini 2.5 Flash demonstrates competitive performance across key benchmarks while maintaining a smaller model size than alternatives. On Humanity’s Last Exam, a rigorous test designed to evaluate reasoning and knowledge, 2.5 Flash scored 12.1%, outperforming Anthropic’s Claude 3.7 Sonnet (8.9%) and DeepSeek R1 (8.6%), though falling short of OpenAI’s recently launched o4-mini (14.3%). The model also posted strong results on technical benchmarks like GPQA diamond (78.3%) and AIME mathematics exams (78.0% on 2025 tests and 88.0% on 2024 tests). “Companies should choose 2.5 Flash because it provides the best value for its cost and speed,” Doshi said. “It’s particularly strong relative to competitors on math, multimodal reasoning, long context, and several other key metrics.” Industry analysts note that these benchmarks indicate Google is narrowing the performance gap with competitors while maintaining a pricing advantage — a strategy that may resonate with enterprise customers watching their AI budgets. Smart vs. speedy: When does your AI need to think deeply? The introduction of adjustable reasoning represents a significant evolution in how businesses can deploy AI. With traditional models, users have little visibility into or control over the model’s internal reasoning process. Google’s approach allows developers to optimize for different scenarios. For simple queries like language translation or basic information retrieval, thinking can be disabled for maximum cost efficiency. For complex tasks requiring multi-step reasoning, such as mathematical problem-solving or nuanced analysis, the thinking function can be enabled and fine-tuned. A key innovation is the model’s ability to determine how much reasoning is appropriate based on the query. Google illustrates this with examples: a simple question like “How many provinces does Canada have?” requires minimal reasoning, while a complex engineering question about beam stress calculations would automatically engage deeper thinking processes. “Integrating thinking capabilities into our mainline Gemini models, combined with improvements across the board, has led to higher quality answers,” Doshi said. “These improvements are true across academic benchmarks – including SimpleQA, which measures factuality.” Google’s AI week: Free student access and video generation join the 2.5 Flash launch The release of Gemini 2.5 Flash comes during a week of aggressive moves by Google in the AI space. On Monday, the company rolled out Veo 2 video generation capabilities to Gemini Advanced subscribers, allowing users to create eight-second video clips from text prompts. Today, alongside the 2.5 Flash announcement, Google revealed that all U.S. college students will receive free access to Gemini Advanced until spring 2026 — a move interpreted by analysts as an effort to build loyalty among future knowledge workers. These announcements reflect Google’s multi-pronged strategy to compete in a market dominated by OpenAI’s ChatGPT, which reportedly sees over 800 million weekly users compared to Gemini’s estimated 250-275 million monthly users, according to third-party analyses. The 2.5 Flash model, with its explicit focus on cost efficiency and performance customization, appears designed to appeal particularly to enterprise customers who need to carefully manage AI deployment costs while still accessing advanced capabilities. “We’re super excited to start getting feedback from developers about what they’re building with Gemini Flash 2.5 and how they’re using thinking budgets,” Doshi said. Beyond the preview: What businesses can expect as Gemini 2.5 Flash matures While this release is in preview, the model is already available for developers to start building with, though Google has not specified a timeline for general availability. The company indicates it will continue refining the dynamic thinking capabilities based on developer feedback during this preview phase. For enterprise AI adopters, this release represents an opportunity to experiment with more nuanced approaches to AI deployment, potentially allocating more computational resources to high-stakes tasks while conserving costs on routine applications. The model is also available to consumers through the Gemini app, where it appears as “2.5 Flash (Experimental)” in the model dropdown menu, replacing the previous 2.0 Thinking (Experimental) option. This consumer-facing deployment suggests Google is using the app ecosystem to gather broader feedback on its reasoning architecture. As AI becomes increasingly embedded in business workflows, Google’s approach with customizable reasoning reflects a maturing market where cost optimization and performance tuning are becoming as important as raw capabilities — signaling a new phase in the commercialization of generative AI technologies. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/nuneybits_Vector_art_of_a_retro_computer_on_the_screen_is_a_lig_b7962004-900f-4fdd-8b99-620ed4be1597.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-04-17T23:27:30+00:00\" datetime=\"2025-04-17T23:27:30+00:00\"\u003eApril 17, 2025 4:27 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/nuneybits_Vector_art_of_a_retro_computer_on_the_screen_is_a_lig_b7962004-900f-4fdd-8b99-620ed4be1597.webp?w=750\" alt=\"Credit: VentureBeat made with Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://www.google.com/\"\u003eGoogle\u003c/a\u003e has launched \u003ca href=\"https://developers.googleblog.com/en/start-building-with-gemini-25-flash/\"\u003eGemini 2.5 Flash\u003c/a\u003e, a major upgrade to its AI lineup that gives businesses and developers unprecedented control over how much “thinking” their AI performs. The new model, released today in preview through \u003ca href=\"https://aistudio.google.com/prompts/new_chat\"\u003eGoogle AI Studio\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/vertex-ai?hl=en\"\u003eVertex AI\u003c/a\u003e, represents a strategic effort to deliver improved reasoning capabilities while maintaining competitive pricing in the increasingly crowded AI market.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model introduces what Google calls a “\u003ca href=\"https://developers.googleblog.com/en/start-building-with-gemini-25-flash/\"\u003ethinking budget\u003c/a\u003e” — a mechanism that allows developers to specify how much computational power should be allocated to reasoning through complex problems before generating a response. This approach aims to address a fundamental tension in today’s AI marketplace: more sophisticated reasoning typically comes at the cost of higher latency and pricing.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We know cost and latency matter for a number of developer use cases, and so we want to offer developers the flexibility to adapt the amount of the thinking the model does, depending on their needs,” said Tulsee Doshi, Product Director for Gemini Models at Google DeepMind, in an exclusive interview with VentureBeat.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis flexibility reveals Google’s pragmatic approach to AI deployment as the technology increasingly becomes embedded in business applications where cost predictability is essential. By allowing the thinking capability to be turned on or off, Google has created what it calls its “first fully hybrid reasoning model.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-pay-only-for-the-brainpower-you-need-inside-google-s-new-ai-pricing-model\"\u003ePay only for the brainpower you need: Inside Google’s new AI pricing model\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe new pricing structure highlights the cost of reasoning in today’s AI systems. When using \u003ca href=\"https://developers.googleblog.com/en/start-building-with-gemini-25-flash/\"\u003eGemini 2.5 Flash\u003c/a\u003e, developers pay $0.15 per million tokens for input. Output costs vary dramatically based on reasoning settings: $0.60 per million tokens with thinking turned off, jumping to $3.50 per million tokens with reasoning enabled.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis nearly sixfold price difference for reasoned outputs reflects the computational intensity of the “thinking” process, where the model evaluates multiple potential paths and considerations before generating a response.\u003c/p\u003e\n\n\n\n\u003cp\u003e“Customers pay for any thinking and output tokens the model generates,” Doshi told VentureBeat. “In the AI Studio UX, you can see these thoughts before a response. In the API, we currently don’t provide access to the thoughts, but a developer can see how many tokens were generated.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThe thinking budget can be adjusted from 0 to 24,576 tokens, operating as a maximum limit rather than a fixed allocation. According to Google, the model intelligently determines how much of this budget to use based on the complexity of the task, preserving resources when elaborate reasoning isn’t necessary.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-how-gemini-2-5-flash-stacks-up-benchmark-results-against-leading-ai-models\"\u003eHow Gemini 2.5 Flash stacks up: Benchmark results against leading AI models\u003c/h2\u003e\n\n\n\n\u003cp\u003eGoogle claims \u003ca href=\"https://developers.googleblog.com/en/start-building-with-gemini-25-flash/\"\u003eGemini 2.5 Flash\u003c/a\u003e demonstrates competitive performance across key benchmarks while maintaining a smaller model size than alternatives. On \u003ca href=\"https://agi.safe.ai/\"\u003eHumanity’s Last Exam\u003c/a\u003e, a rigorous test designed to evaluate reasoning and knowledge, 2.5 Flash scored 12.1%, outperforming Anthropic’s \u003ca href=\"https://www.anthropic.com/news/claude-3-7-sonnet\"\u003eClaude 3.7 Sonnet\u003c/a\u003e (8.9%) and \u003ca href=\"https://api-docs.deepseek.com/news/news250120\"\u003eDeepSeek R1\u003c/a\u003e (8.6%), though falling short of OpenAI’s recently launched \u003ca href=\"https://openai.com/index/introducing-o3-and-o4-mini/\"\u003eo4-mini\u003c/a\u003e (14.3%).\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model also posted strong results on technical benchmarks like \u003ca href=\"https://github.com/idavidrein/gpqa\"\u003eGPQA diamond\u003c/a\u003e (78.3%) and \u003ca href=\"https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination?srsltid=AfmBOoqn5oX4M_tpcaMhggWnKpbd1KqjPt2RDum-tvE9CBijsTVaTVQa\"\u003eAIME mathematics exams\u003c/a\u003e (78.0% on 2025 tests and 88.0% on 2024 tests).\u003c/p\u003e\n\n\n\n\u003cp\u003e“Companies should choose 2.5 Flash because it provides the best value for its cost and speed,” Doshi said. “It’s particularly strong relative to competitors on math, multimodal reasoning, long context, and several other key metrics.”\u003c/p\u003e\n\n\n\n\u003cp\u003eIndustry analysts note that these benchmarks indicate Google is narrowing the performance gap with competitors while maintaining a pricing advantage — a strategy that may resonate with enterprise customers watching their AI budgets.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-smart-vs-speedy-when-does-your-ai-need-to-think-deeply\"\u003eSmart vs. speedy: When does your AI need to think deeply?\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe introduction of adjustable reasoning represents a significant evolution in how businesses can deploy AI. With traditional models, users have little visibility into or control over the model’s internal reasoning process.\u003c/p\u003e\n\n\n\n\u003cp\u003eGoogle’s approach allows developers to optimize for different scenarios. For simple queries like language translation or basic information retrieval, thinking can be disabled for maximum cost efficiency. For complex tasks requiring multi-step reasoning, such as mathematical problem-solving or nuanced analysis, the thinking function can be enabled and fine-tuned.\u003c/p\u003e\n\n\n\n\u003cp\u003eA key innovation is the model’s ability to determine how much reasoning is appropriate based on the query. Google illustrates this with examples: a simple question like “How many provinces does Canada have?” requires minimal reasoning, while a complex engineering question about beam stress calculations would automatically engage deeper thinking processes.\u003c/p\u003e\n\n\n\n\u003cp\u003e“Integrating thinking capabilities into our mainline Gemini models, combined with improvements across the board, has led to higher quality answers,” Doshi said. “These improvements are true across academic benchmarks – including SimpleQA, which measures factuality.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-google-s-ai-week-free-student-access-and-video-generation-join-the-2-5-flash-launch\"\u003eGoogle’s AI week: Free student access and video generation join the 2.5 Flash launch\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe release of \u003ca href=\"https://developers.googleblog.com/en/start-building-with-gemini-25-flash/\"\u003eGemini 2.5 Flash\u003c/a\u003e comes during a week of aggressive moves by Google in the AI space. On Monday, the company rolled out \u003ca href=\"https://deepmind.google/technologies/veo/veo-2/\"\u003eVeo 2\u003c/a\u003e video generation capabilities to Gemini Advanced subscribers, allowing users to create eight-second video clips from text prompts. Today, alongside the 2.5 Flash announcement, Google revealed that \u003ca href=\"https://blog.google/products/gemini/google-one-ai-premium-students-free/#:~:text=Sign%20up%20before%20June%2030,each%20tool%20can%20help%20you.\"\u003eall U.S. college students will receive free access to Gemini Advanced until spring 2026\u003c/a\u003e — a move interpreted by analysts as an effort to build loyalty among future knowledge workers.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese announcements reflect Google’s multi-pronged strategy to compete in a market dominated by OpenAI’s ChatGPT, which reportedly sees over \u003ca href=\"https://venturebeat.com/ai/sam-altman-at-ted-2025-inside-the-most-uncomfortable-and-important-ai-interview-of-the-year/\"\u003e800 million weekly users\u003c/a\u003e compared to Gemini’s estimated \u003ca href=\"https://arstechnica.com/ai/2025/04/google-is-gifting-a-year-of-gemini-advanced-to-every-college-student-in-the-us/\"\u003e250-275 million monthly users\u003c/a\u003e, according to third-party analyses.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe 2.5 Flash model, with its explicit focus on cost efficiency and performance customization, appears designed to appeal particularly to enterprise customers who need to carefully manage AI deployment costs while still accessing advanced capabilities.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We’re super excited to start getting feedback from developers about what they’re building with Gemini Flash 2.5 and how they’re using thinking budgets,” Doshi said.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-beyond-the-preview-what-businesses-can-expect-as-gemini-2-5-flash-matures\"\u003eBeyond the preview: What businesses can expect as Gemini 2.5 Flash matures\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile this release is in preview, the model is already available for developers to start building with, though Google has not specified a timeline for general availability. The company indicates it will continue refining the dynamic thinking capabilities based on developer feedback during this preview phase.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor enterprise AI adopters, this release represents an opportunity to experiment with more nuanced approaches to AI deployment, potentially allocating more computational resources to high-stakes tasks while conserving costs on routine applications.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model is also available to consumers through the \u003ca href=\"https://gemini.google.com/app/download\"\u003eGemini app\u003c/a\u003e, where it appears as “2.5 Flash (Experimental)” in the model dropdown menu, replacing the previous 2.0 Thinking (Experimental) option. This consumer-facing deployment suggests Google is using the app ecosystem to gather broader feedback on its reasoning architecture.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs AI becomes increasingly embedded in business workflows, Google’s approach with customizable reasoning reflects a maturing market where cost optimization and performance tuning are becoming as important as raw capabilities — signaling a new phase in the commercialization of generative AI technologies.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-04-17T23:27:30Z",
  "modifiedTime": "2025-04-17T23:29:00Z"
}
