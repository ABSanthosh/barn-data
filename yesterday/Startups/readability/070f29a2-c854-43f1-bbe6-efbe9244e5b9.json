{
  "id": "070f29a2-c854-43f1-bbe6-efbe9244e5b9",
  "title": "New embedding model leaderboard shakeup: Google takes #1 while Alibaba’s open source alternative closes gap",
  "link": "https://venturebeat.com/ai/new-embedding-model-leaderboard-shakeup-google-takes-1-while-alibabas-open-source-alternative-closes-gap/",
  "description": "Google's new Gemini Embedding model now leads the MTEB benchmark. But it is facing fierce competition from closed and open source rivals.",
  "author": "Ben Dickson",
  "published": "Sat, 19 Jul 2025 00:21:39 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI, ML and Deep Learning",
    "API",
    "Cohere",
    "embedding models",
    "Gemini",
    "Gemini API",
    "gemini-embedding-001",
    "Google",
    "large language models",
    "large language models (LLMs)",
    "LLMs",
    "Massive Text Embedding Benchmark (MTEB)",
    "Matryoshka Representation Learning (MRL)",
    "Mistral AI",
    "MLOps",
    "multimodal embedding",
    "OpenAI",
    "Qodo",
    "qwen3",
    "retrieval augmented generation (RAG)",
    "Retrieval-augmented generation (RAG)",
    "Vertex AI"
  ],
  "byline": "Ben Dickson",
  "length": 5831,
  "excerpt": "Google's new Gemini Embedding model now leads the MTEB benchmark. But it is facing fierce competition from closed and open source rivals.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "July 18, 2025 5:21 PM Image credit: VentureBeat with Imagen-4 Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now Google has officially moved its new, high-performance Gemini Embedding model to general availability, currently ranking number one overall on the highly regarded Massive Text Embedding Benchmark (MTEB). The model (gemini-embedding-001) is now a core part of the Gemini API and Vertex AI, enabling developers to build applications such as semantic search and retrieval-augmented generation (RAG). While a number-one ranking is a strong debut, the landscape of embedding models is very competitive. Google’s proprietary model is being challenged directly by powerful open-source alternatives. This sets up a new strategic choice for enterprises: adopt the top-ranked proprietary model or a nearly-as-good open-source challenger that offers more control. What’s under the hood of Google’s Gemini embedding model At their core, embeddings convert text (or other data types) into numerical lists that capture the key features of the input. Data with similar semantic meaning have embedding values that are closer together in this numerical space. This allows for powerful applications that go far beyond simple keyword matching, such as building intelligent retrieval-augmented generation (RAG) systems that feed relevant information to LLMs.  Embeddings can also be applied to other modalities such as images, video and audio. For instance, an e-commerce company might utilize a multimodal embedding model to generate a unified numerical representation for a product that incorporates both textual descriptions and images. The AI Impact Series Returns to San Francisco - August 5 The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation. Secure your spot now - space is limited: https://bit.ly/3GuuPLF For enterprises, embedding models can power more accurate internal search engines, sophisticated document clustering, classification tasks, sentiment analysis and anomaly detection. Embeddings are also becoming an important part of agentic applications, where AI agents must retrieve and match different types of documents and prompts. One of the key features of Gemini Embedding is its built-in flexibility. It has been trained through a technique known as Matryoshka Representation Learning (MRL), which allows developers to get a highly detailed 3072-dimension embedding but also truncate it to smaller sizes like 1536 or 768 while preserving its most relevant features. This flexibility enables an enterprise to strike a balance between model accuracy, performance and storage costs, which is crucial for scaling applications efficiently. Google positions Gemini Embedding as a unified model designed to work effectively “out-of-the-box” across diverse domains like finance, legal and engineering without the need for fine-tuning. This simplifies development for teams that need a general-purpose solution. Supporting over 100 languages and priced competitively at $0.15 per million input tokens, it is designed for broad accessibility. A competitive landscape of proprietary and open-source challengers Source: Google Blog The MTEB leaderboard shows that while Gemini leads, the gap is narrow. It faces established models from OpenAI, whose embedding models are widely used, and specialized challengers like Mistral, which offers a model specifically for code retrieval. The emergence of these specialized models suggests that for certain tasks, a targeted tool may outperform a generalist one. Another key player, Cohere, targets the enterprise directly with its Embed 4 model. While other models compete on general benchmarks, Cohere emphasizes its model’s ability to handle the “noisy real-world data” often found in enterprise documents, such as spelling mistakes, formatting issues, and even scanned handwriting. It also offers deployment on virtual private clouds or on-premises, providing a level of data security that directly appeals to regulated industries such as finance and healthcare. The most direct threat to proprietary dominance comes from the open-source community. Alibaba’s Qwen3-Embedding model ranks just behind Gemini on MTEB and is available under a permissive Apache 2.0 license (available for commercial purposes). For enterprises focused on software development, Qodo’s Qodo-Embed-1-1.5B presents another compelling open-source alternative, designed specifically for code and claiming to outperform larger models on domain-specific benchmarks. For companies already building on Google Cloud and the Gemini family of models, adopting the native embedding model can have several benefits, including seamless integration, a simplified MLOps pipeline, and the assurance of using a top-ranked general-purpose model. However, Gemini is a closed, API-only model. Enterprises that prioritize data sovereignty, cost control, or the ability to run models on their own infrastructure now have a credible, top-tier open-source option in Qwen3-Embedding or can use one of the task-specific embedding models. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/07/Google-embedding-model.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-07-19T00:21:39+00:00\" datetime=\"2025-07-19T00:21:39+00:00\"\u003eJuly 18, 2025 5:21 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"409\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/Google-embedding-model.png?w=750\" alt=\"Google embedding model\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eImage credit: VentureBeat with Imagen-4\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\u003c/em\u003e \u003cem\u003e\u003ca href=\"https://venturebeat.com/newsletters/\"\u003eSubscribe Now\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://www.google.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGoogle\u003c/a\u003e has officially moved its new, high-performance \u003ca href=\"https://developers.googleblog.com/en/gemini-embedding-available-gemini-api/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGemini Embedding model\u003c/a\u003e to general availability, currently ranking number one overall on the highly regarded \u003ca href=\"https://huggingface.co/spaces/mteb/leaderboard\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMassive Text Embedding Benchmark\u003c/a\u003e (MTEB). The model (gemini-embedding-001) is now a core part of the Gemini API and Vertex AI, enabling developers to build applications such as semantic search and retrieval-augmented generation (RAG).\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile a number-one ranking is a strong debut, the landscape of embedding models is very competitive. Google’s proprietary model is being challenged directly by powerful open-source alternatives. This sets up a new strategic choice for enterprises: adopt the top-ranked proprietary model or a nearly-as-good open-source challenger that offers more control.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-s-under-the-hood-of-google-s-gemini-embedding-model\"\u003eWhat’s under the hood of Google’s Gemini embedding model\u003c/h2\u003e\n\n\n\n\u003cp\u003eAt their core, \u003ca href=\"https://venturebeat.com/ai/beyond-chatbots-the-wide-world-of-embeddings/\"\u003eembeddings\u003c/a\u003e convert text (or other data types) into numerical lists that capture the key features of the input. Data with similar semantic meaning have embedding values that are closer together in this numerical space. This allows for powerful applications that go far beyond simple keyword matching, such as building intelligent \u003ca href=\"https://venturebeat.com/ai/new-technique-makes-rag-systems-much-better-at-retrieving-the-right-documents/\"\u003eretrieval-augmented generation\u003c/a\u003e (RAG) systems that feed relevant information to LLMs. \u003c/p\u003e\n\n\n\n\u003cp\u003eEmbeddings can also be applied to other modalities such as images, video and audio. For instance, an e-commerce company might utilize a multimodal embedding model to generate a unified numerical representation for a product that incorporates both textual descriptions and images.\u003c/p\u003e\n\n\n\n\u003cdiv id=\"boilerplate_2803147\"\u003e\n\u003chr/\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eThe AI Impact Series Returns to San Francisco - August 5\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.\u003c/p\u003e\n\n\n\n\u003cp\u003eSecure your spot now - space is limited: \u003ca href=\"https://bit.ly/3GuuPLF\"\u003ehttps://bit.ly/3GuuPLF\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eFor enterprises, embedding models can power more accurate internal search engines, sophisticated document clustering, classification tasks, sentiment analysis and anomaly detection. Embeddings are also becoming an important part of agentic applications, where AI agents must \u003ca href=\"https://venturebeat.com/ai/s3-the-new-rag-framework-that-trains-search-agents-with-minimal-data/\"\u003eretrieve and match\u003c/a\u003e different types of documents and prompts.\u003c/p\u003e\n\n\n\n\u003cp\u003eOne of the key features of Gemini Embedding is its built-in flexibility. It has been trained through a technique known as Matryoshka Representation Learning (MRL), which allows developers to get a highly detailed 3072-dimension embedding but also truncate it to smaller sizes like 1536 or 768 while preserving its most relevant features. This flexibility enables an enterprise to strike a balance between model accuracy, performance and storage costs, which is crucial for scaling applications efficiently.\u003c/p\u003e\n\n\n\n\u003cp\u003eGoogle positions Gemini Embedding as a unified model designed to work effectively “out-of-the-box” across diverse domains like finance, legal and engineering without the need for fine-tuning. This simplifies development for teams that need a general-purpose solution. Supporting over 100 languages and priced competitively at $0.15 per million input tokens, it is designed for broad accessibility.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-competitive-landscape-of-proprietary-and-open-source-challengers\"\u003eA competitive landscape of proprietary and open-source challengers\u003c/h2\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" height=\"450\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?w=800\" alt=\"MTEB rankings\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png 8001w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=300,169 300w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=768,432 768w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=800,450 800w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=1536,864 1536w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=2048,1152 2048w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=400,225 400w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=750,422 750w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=578,325 578w, https://venturebeat.com/wp-content/uploads/2025/07/image_7cf7a0.png?resize=930,523 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSource: Google Blog\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe MTEB leaderboard shows that while Gemini leads, the gap is narrow. It faces established models from OpenAI, whose \u003ca href=\"https://venturebeat.com/ai/openai-launches-new-generation-of-embedding-models-and-other-api-updates/\"\u003eembedding models\u003c/a\u003e are widely used, and specialized challengers like Mistral, which offers a model \u003ca href=\"https://venturebeat.com/ai/mistral-launches-new-code-embedding-model-that-outperforms-openai-and-cohere-in-real-world-retrieval-tasks/\"\u003especifically for code retrieval\u003c/a\u003e. The emergence of these specialized models suggests that for certain tasks, a targeted tool may outperform a generalist one.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnother key player, Cohere, targets the enterprise directly with its \u003ca href=\"https://venturebeat.com/ai/cracking-ais-storage-bottleneck-and-supercharging-inference-at-the-edge/\"\u003eEmbed 4 model\u003c/a\u003e. While other models compete on general benchmarks, Cohere emphasizes its model’s ability to handle the “noisy real-world data” often found in enterprise documents, such as spelling mistakes, formatting issues, and even scanned handwriting. It also offers deployment on virtual private clouds or on-premises, providing a level of data security that directly appeals to regulated industries such as finance and healthcare.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe most direct threat to proprietary dominance comes from the open-source community. Alibaba’s \u003ca href=\"https://huggingface.co/Qwen/Qwen3-Embedding-8B\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eQwen3-Embedding\u003c/a\u003e model ranks just behind Gemini on MTEB and is available under a permissive Apache 2.0 license (available for commercial purposes). For enterprises focused on software development, Qodo’s \u003ca href=\"https://venturebeat.com/programming-development/qodos-open-code-embedding-model-sets-new-enterprise-standard-beating-openai-salesforce/\"\u003eQodo-Embed-1-1.5B\u003c/a\u003e presents another compelling open-source alternative, designed specifically for code and claiming to outperform larger models on domain-specific benchmarks.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor companies already building on Google Cloud and the Gemini family of models, adopting the native embedding model can have several benefits, including seamless integration, a simplified MLOps pipeline, and the assurance of using a top-ranked general-purpose model.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, Gemini is a closed, API-only model. Enterprises that prioritize data sovereignty, cost control, or the ability to run models on their own infrastructure now have a credible, top-tier open-source option in Qwen3-Embedding or can use one of the task-specific embedding models.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-07-19T00:21:39Z",
  "modifiedTime": "2025-07-19T00:21:46Z"
}
