{
  "id": "fa2868dd-ad7f-4c0a-bd75-ceacc64c85b2",
  "title": "Notes on OpenAI O3-Mini",
  "link": "https://simonwillison.net/2025/Jan/31/o3-mini/",
  "description": "Article URL: https://simonwillison.net/2025/Jan/31/o3-mini/ Comments URL: https://news.ycombinator.com/item?id=42894215 Points: 15 # Comments: 1",
  "author": "dtquad",
  "published": "Sat, 01 Feb 2025 00:24:42 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "",
  "length": 2919,
  "excerpt": "OpenAI’s o3-mini is out today. As with other o-series models it’s a slightly difficult one to evaluate—we now need to decide if a prompt is best run using GPT-4o, o1, …",
  "siteName": "",
  "favicon": "",
  "text": "31st January 2025 OpenAI’s o3-mini is out today. As with other o-series models it’s a slightly difficult one to evaluate—we now need to decide if a prompt is best run using GPT-4o, o1, o3-mini or (if we have access) o1 Pro. Confusing matters further, the benchmarks in the o3-mini system card (PDF) aren’t a universal win for o3-mini across all categories. It generally benchmarks higher than GPT-4o and o1 but not across everything. The biggest win for o3-mini is on the Codeforces ELO competitive programming benchmark, which I think is described by this 2nd January 2025 paper, with the following scores: o3-mini (high) 2130 o3-mini (medium) 2036 o1 1891 o3-mini (low) 1831 o1-mini 1650 o1-preview 1258 GPT-4o 900 Weirdly, that GPT-4o score was in an older copy of the System Card PDF which has been replaced by an updated document that doesn’t mention Codeforces ELO scores at all. One note from the System Card that stood out for me concerning intended applications of o3-mini for OpenAI themselves: We also plan to allow users to use o3-mini to search the internet and summarize the results in ChatGPT. We expect o3-mini to be a useful and safe model for doing this, especially given its performance on the jailbreak and instruction hierarchy evals detailed in Section 4 below. This is notable because the existing o1 models on ChatGPT have not yet had access to their web search tool—despite the mixture of search and “reasoning” models having very clear benefits. I released LLM 0.21 with support for the new model, plus its -o reasoning_effort high (or medium or low) option for tweaking the reasoning effort—details in this issue. Note that the new model is currently only available for Tier 3 and higher users, which requires you to have spent at least $100 on the API. o3-mini is priced at $1.10/million input tokens, $4.40/million output tokens—less than half the price of GPT-4o (currently $2.50/$10) and massively cheaper than o1 ($15/60). I tried using it to summarize this conversation about o3-mini on Hacker News, using my hn-summary.sh script. hn-summary.sh 42890627 -o o3-mini Here’s the result—it used 18,936 input tokens and 2,905 output tokens for a total cost of 3.3612 cents. Another characteristic worth noting is o3-mini’s token output limit—the measure of how much text it can output in one go. That’s 100,000 tokens, compared to 16,000 for GPT-4o and just 8,000 for both DeepSeek R1 and Claude 3.5. Invisible “reasoning tokens” come out of the same budget, so it’s likely not possible to have it output the full 100,000. The model accepts up to 200,000 tokens of input, an improvement on GPT-4o’s 128,000. An application where output limits really matter is translation between human languages, where the output can realistically be expected to have a similar length to the input. It will be interesting seeing how well o3-mini works for that, especially given its low price.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-permalink-context=\"/2025/Jan/31/o3-mini/\"\u003e\n\n\u003cp\u003e31st January 2025\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI’s \u003ca href=\"https://openai.com/index/openai-o3-mini/\"\u003eo3-mini is out today\u003c/a\u003e. As with other o-series models it’s a slightly difficult one to evaluate—we now need to decide if a prompt is best run using GPT-4o, o1, o3-mini or (if we have access) o1 Pro.\u003c/p\u003e\n\u003cp\u003eConfusing matters further, the benchmarks in \u003ca href=\"https://openai.com/index/o3-mini-system-card/\"\u003ethe o3-mini system card\u003c/a\u003e (PDF) aren’t a universal win for o3-mini across all categories. It generally benchmarks higher than GPT-4o and o1 but not across everything.\u003c/p\u003e\n\u003cp\u003eThe biggest win for o3-mini is on the Codeforces ELO competitive programming benchmark, which I think is \u003ca href=\"https://arxiv.org/abs/2501.01257\"\u003edescribed by this 2nd January 2025 paper\u003c/a\u003e, with the following scores:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eo3-mini (high) 2130\u003c/li\u003e\n\u003cli\u003eo3-mini (medium) 2036\u003c/li\u003e\n\u003cli\u003eo1 1891\u003c/li\u003e\n\u003cli\u003eo3-mini (low) 1831\u003c/li\u003e\n\u003cli\u003eo1-mini 1650\u003c/li\u003e\n\u003cli\u003eo1-preview 1258\u003c/li\u003e\n\u003cli\u003eGPT-4o 900\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWeirdly, that GPT-4o score was in an older copy of the System Card PDF which has been replaced by an updated document that doesn’t mention Codeforces ELO scores at all.\u003c/p\u003e\n\u003cp\u003eOne note from the System Card that stood out for me concerning intended applications of o3-mini for OpenAI themselves:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWe also plan to allow users to use o3-mini to search the internet and summarize the results in ChatGPT. We expect o3-mini to be a useful and safe model for doing this, especially given its performance on the jailbreak and instruction hierarchy evals detailed in Section 4 below.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThis is notable because the existing o1 models on ChatGPT have not yet had access to their web search tool—despite the mixture of search and “reasoning” models having very clear benefits.\u003c/p\u003e\n\u003cp\u003eI released \u003ca href=\"https://llm.datasette.io/en/stable/changelog.html#v0-21\"\u003eLLM 0.21\u003c/a\u003e with support for the new model, plus its \u003ccode\u003e-o reasoning_effort high\u003c/code\u003e (or \u003ccode\u003emedium\u003c/code\u003e or \u003ccode\u003elow\u003c/code\u003e) option for tweaking the reasoning effort—details \u003ca href=\"https://github.com/simonw/llm/issues/728\"\u003ein this issue\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNote that the new model is currently only available for \u003ca href=\"https://platform.openai.com/docs/guides/rate-limits/usage-tiers#tier-3-rate-limits\"\u003eTier 3\u003c/a\u003e and higher users, which requires you to have spent at least $100 on the API.\u003c/p\u003e\n\u003cp\u003eo3-mini \u003ca href=\"https://openai.com/api/pricing/\"\u003eis priced\u003c/a\u003e at $1.10/million input tokens, $4.40/million output tokens—less than half the price of GPT-4o (currently $2.50/$10) and massively cheaper than o1 ($15/60).\u003c/p\u003e\n\u003cp\u003eI tried using it to summarize \u003ca href=\"https://news.ycombinator.com/item?id=42890627\"\u003ethis conversation about o3-mini on Hacker News\u003c/a\u003e, using \u003ca href=\"https://til.simonwillison.net/llms/claude-hacker-news-themes#user-content-adding-a--m-model-option\"\u003emy hn-summary.sh script\u003c/a\u003e.\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003ehn-summary.sh 42890627 -o o3-mini\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eHere’s \u003ca href=\"https://gist.github.com/simonw/09e5922be0cbb85894cf05e6d75ae050\"\u003ethe result\u003c/a\u003e—it used 18,936 input tokens and 2,905 output tokens for a total cost of 3.3612 cents.\u003c/p\u003e\n\n\u003cp\u003eAnother characteristic worth noting is o3-mini’s token output limit—the measure of how much text it can output in one go.  That’s 100,000 tokens, compared to 16,000 for GPT-4o and just 8,000 for both DeepSeek R1 and Claude 3.5.\u003c/p\u003e\n\n\u003cp\u003eInvisible “reasoning tokens” come out of the same budget, so it’s likely not possible to have it output the full 100,000.\u003c/p\u003e\n\n\u003cp\u003eThe model accepts up to 200,000 tokens of input, an improvement on GPT-4o’s 128,000.\u003c/p\u003e\n\n\u003cp\u003eAn application where output limits really matter is translation between human languages, where the output can realistically be expected to have a similar length to the input. It will be interesting seeing how well o3-mini works for that, especially given its low price.\u003c/p\u003e\n\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": null,
  "modifiedTime": null
}
