{
  "id": "680178e0-579b-4735-b678-046c3327c3a9",
  "title": "Liquid AI is revolutionizing LLMs to work on edge devices like smartphones with new ‘Hyena Edge’ model",
  "link": "https://venturebeat.com/ai/liquid-ai-is-revolutionizing-llms-to-work-on-edge-devices-like-smartphones-with-new-hyena-edge-model/",
  "description": "Hyena Edge’s success positions Liquid AI as one of the emerging players to watch in the evolving AI model landscape.",
  "author": "Carl Franzen",
  "published": "Fri, 25 Apr 2025 22:02:47 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI, ML and Deep Learning",
    "Conversational AI",
    "edge AI",
    "hyena edge",
    "liquid ai",
    "LLMs",
    "MIT",
    "Mobile",
    "NLP",
    "smartphones"
  ],
  "byline": "Carl Franzen",
  "length": 5716,
  "excerpt": "Hyena Edge’s success positions Liquid AI as one of the emerging players to watch in the evolving AI model landscape.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Liquid AI, the Boston-based foundation model startup spun out of the Massachusetts Institute of Technology (MIT), is seeking to move the tech industry beyond its reliance on the Transformer architecture underpinning most popular large language models (LLMs) such as OpenAI’s GPT series and Google’s Gemini family. Yesterday, the company announced “Hyena Edge,” a new convolution-based, multi-hybrid model designed for smartphones and other edge devices in advance of the International Conference on Learning Representations (ICLR) 2025. The conference, one of the premier events for machine learning research, is taking place this year in Vienna, Austria. New convolution-based model promises faster, more memory-efficient AI at the edge Hyena Edge is engineered to outperform strong Transformer baselines on both computational efficiency and language model quality. In real-world tests on a Samsung Galaxy S24 Ultra smartphone, the model delivered lower latency, smaller memory footprint, and better benchmark results compared to a parameter-matched Transformer++ model. A new architecture for a new era of edge AI Unlike most small models designed for mobile deployment — including SmolLM2, the Phi models, and Llama 3.2 1B — Hyena Edge steps away from traditional attention-heavy designs. Instead, it strategically replaces two-thirds of grouped-query attention (GQA) operators with gated convolutions from the Hyena-Y family. The new architecture is the result of Liquid AI’s Synthesis of Tailored Architectures (STAR) framework, which uses evolutionary algorithms to automatically design model backbones and was announced back in December 2024. STAR explores a wide range of operator compositions, rooted in the mathematical theory of linear input-varying systems, to optimize for multiple hardware-specific objectives like latency, memory usage, and quality. Benchmarked directly on consumer hardware To validate Hyena Edge’s real-world readiness, Liquid AI ran tests directly on the Samsung Galaxy S24 Ultra smartphone. Results show that Hyena Edge achieved up to 30% faster prefill and decode latencies compared to its Transformer++ counterpart, with speed advantages increasing at longer sequence lengths. Prefill latencies at short sequence lengths also outpaced the Transformer baseline — a critical performance metric for responsive on-device applications. In terms of memory, Hyena Edge consistently used less RAM during inference across all tested sequence lengths, positioning it as a strong candidate for environments with tight resource constraints. Outperforming Transformers on language benchmarks Hyena Edge was trained on 100 billion tokens and evaluated across standard benchmarks for small language models, including Wikitext, Lambada, PiQA, HellaSwag, Winogrande, ARC-easy, and ARC-challenge. On every benchmark, Hyena Edge either matched or exceeded the performance of the GQA-Transformer++ model, with noticeable improvements in perplexity scores on Wikitext and Lambada, and higher accuracy rates on PiQA, HellaSwag, and Winogrande. These results suggest that the model’s efficiency gains do not come at the cost of predictive quality — a common tradeoff for many edge-optimized architectures. Hyena Edge Evolution: A look at performance and operator trends For those seeking a deeper dive into Hyena Edge’s development process, a recent video walkthrough provides a compelling visual summary of the model’s evolution. The video highlights how key performance metrics — including prefill latency, decode latency, and memory consumption — improved over successive generations of architecture refinement. It also offers a rare behind-the-scenes look at how the internal composition of Hyena Edge shifted during development. Viewers can see dynamic changes in the distribution of operator types, such as Self-Attention (SA) mechanisms, various Hyena variants, and SwiGLU layers. These shifts offer insight into the architectural design principles that helped the model reach its current level of efficiency and accuracy. By visualizing the trade-offs and operator dynamics over time, the video provides valuable context for understanding the architectural breakthroughs underlying Hyena Edge’s performance. Open-source plans and a broader vision Liquid AI said it plans to open-source a series of Liquid foundation models, including Hyena Edge, over the coming months. The company’s goal is to build capable and efficient general-purpose AI systems that can scale from cloud datacenters down to personal edge devices. The debut of Hyena Edge also highlights the growing potential for alternative architectures to challenge Transformers in practical settings. With mobile devices increasingly expected to run sophisticated AI workloads natively, models like Hyena Edge could set a new baseline for what edge-optimized AI can achieve. Hyena Edge’s success — both in raw performance metrics and in showcasing automated architecture design — positions Liquid AI as one of the emerging players to watch in the evolving AI model landscape. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/cfr0z3n_graphic_novel_vector_art_flat_illustration_splash_pag_9dd6886b-a55b-42e5-97c5-1d907b6e1f87_3_5e63ec.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eLiquid AI, the Boston-based foundation model startup spun out of the Massachusetts Institute of Technology (MIT), is seeking to move the tech industry beyond its reliance on the Transformer architecture underpinning most popular large language models (LLMs) such as \u003ca href=\"https://venturebeat.com/security/openais-new-gpt-4-1-models-can-process-a-million-tokens-and-solve-coding-problems-better-than-ever/\"\u003eOpenAI’s GPT\u003c/a\u003e series and \u003ca href=\"https://venturebeat.com/ai/the-new-ai-calculus-googles-80-cost-edge-vs-openais-ecosystem/\"\u003eGoogle’s Gemini\u003c/a\u003e family.\u003c/p\u003e\n\n\n\n\u003cp\u003eYesterday, the company announced “\u003ca href=\"https://www.liquid.ai/research/convolutional-multi-hybrids-for-edge-devices\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHyena Edge\u003c/a\u003e,” a new convolution-based, multi-hybrid model designed for smartphones and other edge devices in advance of the \u003ca href=\"https://iclr.cc/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eInternational Conference on Learning Representations (ICLR) 2025. \u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe conference, one of the premier events for machine learning research, is taking place this year in Vienna, Austria. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-new-convolution-based-model-promises-faster-more-memory-efficient-ai-at-the-edge\"\u003eNew convolution-based model promises faster, more memory-efficient AI at the edge\u003c/h2\u003e\n\n\n\n\u003cp\u003eHyena Edge is engineered to outperform strong Transformer baselines on both computational efficiency and language model quality.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn real-world tests on a Samsung Galaxy S24 Ultra smartphone, the model delivered lower latency, smaller memory footprint, and better benchmark results compared to a parameter-matched Transformer++ model.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-new-architecture-for-a-new-era-of-edge-ai\"\u003eA new architecture for a new era of edge AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eUnlike most small models designed for mobile deployment — including SmolLM2, the Phi models, and Llama 3.2 1B — Hyena Edge steps away from traditional attention-heavy designs. Instead, it strategically replaces two-thirds of grouped-query attention (GQA) operators with gated convolutions from the Hyena-Y family.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe new architecture is the result of Liquid AI’s Synthesis of Tailored Architectures (STAR) framework, which uses evolutionary algorithms to automatically design model backbones and\u003ca href=\"https://venturebeat.com/ai/liquid-ais-new-star-model-architecture-outshines-transformer-efficiency/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e was announced back in December 2024.\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eSTAR explores a wide range of operator compositions, rooted in the mathematical theory of linear input-varying systems, to optimize for multiple hardware-specific objectives like latency, memory usage, and quality.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-benchmarked-directly-on-consumer-hardware\"\u003eBenchmarked directly on consumer hardware\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo validate Hyena Edge’s real-world readiness, Liquid AI ran tests directly on the Samsung Galaxy S24 Ultra smartphone. \u003c/p\u003e\n\n\n\n\u003cp\u003eResults show that Hyena Edge achieved up to 30% faster prefill and decode latencies compared to its Transformer++ counterpart, with speed advantages increasing at longer sequence lengths. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"3300\" height=\"1320\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png 3300w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=300,120 300w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=768,307 768w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=800,320 800w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=1536,614 1536w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=2048,819 2048w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=400,160 400w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=750,300 750w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=578,231 578w, https://venturebeat.com/wp-content/uploads/2025/04/680a7ce39c890004edea492d_architecture_comparison-1.png?resize=930,372 930w\" sizes=\"(max-width: 3300px) 100vw, 3300px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003ePrefill latencies at short sequence lengths also outpaced the Transformer baseline — a critical performance metric for responsive on-device applications.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn terms of memory, Hyena Edge consistently used less RAM during inference across all tested sequence lengths, positioning it as a strong candidate for environments with tight resource constraints.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-outperforming-transformers-on-language-benchmarks\"\u003eOutperforming Transformers on language benchmarks\u003c/h2\u003e\n\n\n\n\u003cp\u003eHyena Edge was trained on 100 billion tokens and evaluated across standard benchmarks for small language models, including Wikitext, Lambada, PiQA, HellaSwag, Winogrande, ARC-easy, and ARC-challenge. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1422\" height=\"592\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04%E2%80%AFPM.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png 1422w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=300,125 300w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=768,320 768w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=800,333 800w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=400,167 400w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=750,312 750w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=578,241 578w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-25-at-5.27.04 PM.png?resize=930,387 930w\" sizes=\"(max-width: 1422px) 100vw, 1422px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOn every benchmark, Hyena Edge either matched or exceeded the performance of the GQA-Transformer++ model, with noticeable improvements in perplexity scores on Wikitext and Lambada, and higher accuracy rates on PiQA, HellaSwag, and Winogrande.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese results suggest that the model’s efficiency gains do not come at the cost of predictive quality — a common tradeoff for many edge-optimized architectures.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-hyena-edge-evolution-a-look-at-performance-and-operator-trends\"\u003eHyena Edge Evolution: A look at performance and operator trends\u003c/h2\u003e\n\n\n\n\u003cp\u003eFor those seeking a deeper dive into Hyena Edge’s development process, a recent \u003ca href=\"https://youtu.be/N5aL1JlupCA?si=qAMAEUDG9AbUgCRF\"\u003evideo walkthrough\u003c/a\u003e provides a compelling visual summary of the model’s evolution. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cp\u003e\n\u003ciframe title=\"Hyena Edge Evolution\" width=\"500\" height=\"281\" src=\"https://www.youtube.com/embed/N5aL1JlupCA?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\n\u003c/p\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe video highlights how key performance metrics — including prefill latency, decode latency, and memory consumption — improved over successive generations of architecture refinement.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt also offers a rare behind-the-scenes look at how the internal composition of Hyena Edge shifted during development. Viewers can see dynamic changes in the distribution of operator types, such as Self-Attention (SA) mechanisms, various Hyena variants, and SwiGLU layers. \u003c/p\u003e\n\n\n\n\u003cp\u003eThese shifts offer insight into the architectural design principles that helped the model reach its current level of efficiency and accuracy.\u003c/p\u003e\n\n\n\n\u003cp\u003eBy visualizing the trade-offs and operator dynamics over time, the video provides valuable context for understanding the architectural breakthroughs underlying Hyena Edge’s performance.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-open-source-plans-and-a-broader-vision\"\u003eOpen-source plans and a broader vision\u003c/h2\u003e\n\n\n\n\u003cp\u003eLiquid AI said it plans to open-source a series of Liquid foundation models, including Hyena Edge, over the coming months. The company’s goal is to build capable and efficient general-purpose AI systems that can scale from cloud datacenters down to personal edge devices.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe debut of Hyena Edge also highlights the growing potential for alternative architectures to challenge Transformers in practical settings. With mobile devices increasingly expected to run sophisticated AI workloads natively, models like Hyena Edge could set a new baseline for what edge-optimized AI can achieve.\u003c/p\u003e\n\n\n\n\u003cp\u003eHyena Edge’s success — both in raw performance metrics and in showcasing automated architecture design — positions Liquid AI as one of the emerging players to watch in the evolving AI model landscape.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-04-25T22:02:47Z",
  "modifiedTime": "2025-04-25T22:03:21Z"
}
