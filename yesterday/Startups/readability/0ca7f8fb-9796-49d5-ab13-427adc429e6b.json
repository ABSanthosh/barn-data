{
  "id": "0ca7f8fb-9796-49d5-ab13-427adc429e6b",
  "title": "GitHub MCP Exploited: Accessing Private Repositories via MCP",
  "link": "https://invariantlabs.ai/blog/mcp-github-vulnerability",
  "description": "Article URL: https://invariantlabs.ai/blog/mcp-github-vulnerability Comments URL: https://news.ycombinator.com/item?id=44102376 Points: 26 # Comments: 2",
  "author": "gokhan",
  "published": "Mon, 26 May 2025 22:53:51 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "Authors: Marco MilantaLuca Beurer-Kellner",
  "length": 10136,
  "excerpt": "We showcase a critical vulnerability with the official GitHub MCP server, allowing attackers to access private repository data. The vulnerability is among the first discovered by Invariant's security analyzer for detecting toxic agent flows.",
  "siteName": "",
  "favicon": "https://invariantlabs.ai/theme/icon/favicon-32x32.png",
  "text": "Invariant has discovered a critical vulnerability affecting the widely-used GitHub MCP integration (14k stars on GitHub). The vulnerability allows an attacker to hijack a user's agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories. The issue is among the first, discovered by Invariant's automated security scanners for detecting so-called Toxic Agent Flows. In such a scenario, an agent is manipulated into performing unintended actions, such as leaking data or executing malicious code. For more information, see below. It is highly relevant to raise awareness about this issue at this time, as the industry is racing to deploy coding agents and IDEs widely, potentially exposing users to similar attacks on critical software development tools. Contents Attack Setup Attack Demonstration Detecting Toxic Agent Flows Mitigations Conclusion Attack Setup In this attack setup, the user is using an MCP client like Claude Desktop with the Github MCP server connected to their account. We assume the user has created two repositories: \u003cuser\u003e/public-repo: A publicly accessible repository, allowing everyone on GitHub to create issues and bug reports. \u003cuser\u003e/private-repo: A private repository, e.g. with proprietary code or private company data. By standard GitHub rules, an attacker can now create a malicious issue on the public repository, containing a prompt injection waiting for the agent to interact. The actual attack triggers as soon as the user and owner of the GitHub account queries their agent with a benign request, such as Have a look at the open issues in \u003cuser\u003e/public-repo, which will lead to the agent fetching the issues from the public repository and getting injected. See below for an illustration of the ensuing flow. As shown here, as soon as the agent encounters the malicious GitHub issue, it can be coerced into pulling private repository data into context, and leaking it in an autonomously-created PR in the public repository, freely accessible to the attacker or anyone else. Toxic Flows We call this use of indirect prompt injection to trigger a malicious tool use sequence, a toxic agent flow. We have found this vulnerability by applying Invariant's security analyzer to GitHub MCP, allowing us to automate the process of discovering the flow in the wild. Attack Demonstration To illustrate more concretely, we implement this attack practically using a set of demo repositories: ukend0464/pacman: A public repository with a simple implementation of a Pacman game (available here) Multiple private repositories containing personal projects and sensitive information about the user. 'About The Author' injection We now place a malicious issue in the public repository, which is accessible to the attacker. The issue contains a payload that will be executed by the agent as soon as it queries the public repository's list of issues. User Interaction To trigger the attack, the user merely prompts Claude 4 Opus with the following request: Claude then uses the GitHub MCP integration to follow the instructions. Throughout this process, Claude Desktop by default requires the user to confirm individual tool calls. However, many users already opt for an “Always Allow” confirmation policy when using agents, and stop monitoring individual actions. Attack Rollout The agent now goes through the list of issues until it finds the attack payload. It willingly pulls private repository data into context, and leaks it into a pull request of the pacman repo, which is freely accessible to the attacker since it is public. The pull request contains the following new information: We thus successfully exfiltrated several pieces of private information about our user ukend0464: information about their private repositories, such as Jupiter Star, their plan to relocate to South America, and even their salary. Below, we include a screenshot of the full chat with the agent, showing its reasoning and tool use sequence in action. Click to see full chat with the agent. Detecting Toxic Agent Flows Unlike previously-discovered tool poisoning attacks with MCP, this vulnerability does not require the MCP tools themselves to be compromised. Instead, the issue emerges even with fully trusted tools, as agents can be exposed to untrusted information when connected to external platforms like GitHub. Understanding, analyzing, and mitigating such issues in agentic systems is a highly complex undertaking that's difficult to perform manually and at scale. To address this challenge, Invariant has developed automated methods for detecting toxic agent flows, enabling organizations to identify and model potential threats before they can be exploited by malicious actors. If you're interested in conducting a comprehensive threat analysis of your agent systems and tools, please contact us at [email protected]. We'll be happy to onboard you to our early access security program. Below is a preview of our security analyzer in action. Preview: Invariant's security analyzer for proactively detecting toxic agent flows. Scope and Mitigations While our experiments focused on Claude Desktop, the vulnerability is not specific to any particular agent or MCP client. It affects any agent that uses the GitHub MCP server, regardless of the underlying model or implementation. Importantly, this is not a flaw in the GitHub MCP server code itself, but rather a fundamental architectural issue that must be addressed at the agent system level. This means that GitHub alone cannot resolve this vulnerability through server-side patches. We thus recommend the following two key mitigation strategies to prevent such attacks and strengthen the security posture of your agent systems. 1. Implement Granular Permission Controls When using MCP integrations like GitHub's, it's critical to limit agent access to only the repositories it needs to interact with—following the principle of least privilege. While traditional token-based permissions offer some protection, they often impose rigid constraints that limit an agent's functionality. For more effective security without sacrificing capability, we recommend implementing dynamic runtime security layers specifically designed for agent systems. Solutions like Invariant Guardrails provide context-aware access control that adapts to your agent's workflow while enforcing security boundaries. To illustrate, here's an example policy that prevents cross-repository information leaks using Invariant Guardrails: raise Violation(\"You can access only one repo per session.\") if: (call_before: ToolCall) -\u003e (call_after: ToolCall) call_before.function.name in (...set of repo actions) call_after.function.name in (...set of repo actions) call_before.function.arguments[\"repo\"] != call_after.function.arguments[\"repo\"] or call_before.function.arguments[\"owner\"] != call_after.function.arguments[\"owner\"] You can find the complete policy here. See the MCP-scan documentation, for more information on how to apply this policy to your MCP deployments. This approach effectively restricts an agent to working with only one repository per session, preventing cross-repository information leakage while maintaining full functionality within authorized boundaries. To experiment more with Guardrails, you can also use the Guardrails Playground to test policies before deploying them. 2. Conduct Continuous Security Monitoring Beyond preventative measures, implement robust monitoring solutions to detect and respond to potential security threats in real time. We recommend deploying specialized security scanners such as Invariant's MCP-scan to continuously audit interactions between agents and MCP systems. The recently introduced proxy mode in MCP-scan significantly simplifies this process by enabling real-time security scanning of MCP connections without requiring modifications to your existing agent infrastructure. Simply route your MCP traffic through the proxy to gain immediate visibility and real-time scanning for potential security violations. Implementing comprehensive monitoring also creates an audit trail that helps identify potential vulnerabilities, detect exploitation attempts, and ensure your agent systems remain protected against emerging attacks. Why Model Alignment Is Not Enough As demonstrated by our findings, even state-of-the-art aligned models are vulnerable to these attacks. In our experiments, we used Claude 4 Opus, a very recent, highly aligned and secure AI model. Despite its robust safety training, the agent was still susceptible to manipulation through relatively simplistic prompt injections. Similarly, many off-the-shelf prompt injection detector defenses, fail to catch this attack. The vulnerability persists because the security of agent systems is fundamentally contextual and environment-dependent. While general model alignment training creates some guardrails, it cannot anticipate the specific security requirements of every deployment scenario or organizational context. Security measures must be implemented at the system level, complementing model-level safeguards. Conclusion In this blog post, we have shown a critical vulnerability affecting the GitHub MCP server, allowing attackers to hijack a user's agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories. The vulnerability is among the first discovered by Invariant's security analyzer for detecting toxic agent flows. While the vulnerability that we uncover is specific to GitHub MCP, similar attacks keep emerging in other settings. For instance, Legit Security recently reported a vulnerability in GitLab Duo. It is crucial to safeguard agent systems and MCP integrations using designated security scanners such as Invariant's MCP-scan and Guardrails to ensure responsible deployment at scale. Work With Us If you are interested in learning more about how to secure your agent systems, please reach out to us at [email protected]. We are happy to onboard you to our early access security program, and help you secure your agent systems.",
  "image": "https://invariantlabs.ai/blog/mcp-github-vulnerability.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n  \u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/mcp-github.svg\"/\u003e\u003c/p\u003e\n\u003cp\u003eInvariant has discovered a critical vulnerability affecting the widely-used \u003ca href=\"https://github.com/github/github-mcp-server\"\u003eGitHub MCP integration\u003c/a\u003e (14k stars on GitHub). The vulnerability allows an attacker to hijack a user\u0026#39;s agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories.\u003c/p\u003e\n\u003cp\u003eThe issue is among the first, discovered by Invariant\u0026#39;s automated security scanners for detecting so-called \u003cem\u003eToxic Agent Flows\u003c/em\u003e. In such a scenario, an agent is manipulated into performing unintended actions, such as leaking data or executing malicious code. For more information, \u003ca href=\"#detecting-toxic-agent-flows\"\u003esee below\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIt is highly relevant to raise awareness about this issue at this time, as the industry is racing to deploy coding agents and IDEs widely, potentially exposing users to similar attacks on critical software development tools.\u003c/p\u003e\n\u003ch2\u003eContents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#attack-setup\"\u003eAttack Setup\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#attack-demonstration\"\u003eAttack Demonstration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#detecting-toxic-agent-flows\"\u003eDetecting Toxic Agent Flows\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mitigations\"\u003eMitigations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"attack-setup\"\u003eAttack Setup\u003c/h2\u003e\n\n\u003cp\u003eIn this attack setup, the user is using an MCP client like Claude Desktop with the \u003ca href=\"https://github.com/github/github-mcp-server\"\u003eGithub MCP server\u003c/a\u003e connected to their account. \u003c/p\u003e\n\u003cp\u003eWe assume the user has created two repositories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003e\u0026lt;user\u0026gt;/public-repo\u003c/code\u003e\u003c/strong\u003e: A publicly accessible repository, allowing everyone on GitHub to create issues and bug reports.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003e\u0026lt;user\u0026gt;/private-repo\u003c/code\u003e\u003c/strong\u003e: A private repository, e.g. with proprietary code or private company data.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy standard GitHub rules, an attacker can now create a malicious issue on the public repository, containing a prompt injection waiting for the agent to interact.\u003c/p\u003e\n\u003cp\u003eThe actual attack triggers as soon as the user and owner of the GitHub account queries their agent with a benign request, such as \u003cem\u003eHave a look at the open issues in \u003ccode\u003e\u0026lt;user\u0026gt;/public-repo\u003c/code\u003e\u003c/em\u003e, which will lead to the agent fetching the issues from the public repository and getting injected.\u003c/p\u003e\n\u003cp\u003eSee below for an illustration of the ensuing flow.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/mcp-github-setup.svg\"/\u003e\u003c/p\u003e\n\u003cp\u003eAs shown here, as soon as the agent encounters the malicious GitHub issue, it can be coerced into pulling private repository data into context, and leaking it in an autonomously-created PR in the public repository, freely accessible to the attacker or anyone else.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eToxic Flows\u003c/strong\u003e We call this use of indirect prompt injection to trigger a malicious tool use sequence, a \u003cem\u003etoxic agent flow\u003c/em\u003e. We have found this vulnerability by applying Invariant\u0026#39;s security analyzer to GitHub MCP, allowing us to automate the process of discovering the flow in the wild.\u003c/p\u003e\n\u003ch2 id=\"attack-demonstration\"\u003eAttack Demonstration\u003c/h2\u003e\n\n\u003cp\u003eTo illustrate more concretely, we implement this attack practically using a set of demo repositories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eukend0464/pacman\u003c/code\u003e: A public repository with a simple implementation of a Pacman game (\u003ca href=\"https://github.com/ukend0464/pacman\"\u003eavailable here\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eMultiple private repositories containing personal projects and sensitive information about the user.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e\u0026#39;About The Author\u0026#39; injection\u003c/strong\u003e We now place a \u003ca href=\"https://github.com/ukend0464/pacman/issues/1\"\u003emalicious issue\u003c/a\u003e in the public repository, which is accessible to the attacker. The issue contains a payload that will be executed by the agent as soon as it queries the public repository\u0026#39;s list of issues.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/mcp-gh-issue.png\" alt=\"A malicious GitHub issue injecting the agent\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eUser Interaction\u003c/strong\u003e To trigger the attack, the user merely prompts \u003ca href=\"https://www.anthropic.com/news/claude-4\"\u003eClaude 4 Opus\u003c/a\u003e with the following request:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/mcp-claude-prompt.png\" alt=\"Claude prompt used to trigger the attack\"/\u003e\u003c/p\u003e\n\u003cp\u003eClaude then uses the GitHub MCP integration to follow the instructions. Throughout this process, Claude Desktop by default requires the user to confirm individual tool calls. However, many users already opt for an “Always Allow” confirmation policy when using agents, and stop monitoring individual actions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAttack Rollout\u003c/strong\u003e The agent now goes through the list of issues until it finds the attack payload. It willingly pulls private repository data into context, and leaks it into a \u003ca href=\"https://github.com/ukend0464/pacman/pull/2\"\u003epull request\u003c/a\u003e of the \u003ccode\u003epacman\u003c/code\u003e repo, which is freely accessible to the attacker since it is public.\u003c/p\u003e\n\u003cp\u003eThe pull request contains the following new information:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/mcp-gh-pr.png\" alt=\"commit where the agent leaks private data\"/\u003e\u003c/p\u003e\n\u003cp\u003eWe thus successfully exfiltrated several pieces of \u003cstrong\u003eprivate information\u003c/strong\u003e about our user \u003ccode\u003eukend0464\u003c/code\u003e: information about their private repositories, such as \u003ccode\u003eJupiter Star\u003c/code\u003e, their plan to relocate to South America, and even their salary.\u003c/p\u003e\n\u003cp\u003eBelow, we include a screenshot of the full chat with the agent, showing its reasoning and tool use sequence in action.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://invariantlabs.ai/images/full-chat.png\" target=\"_blank\"\u003e\n\u003cimg src=\"https://invariantlabs.ai/images/full-chat.png\" alt=\"Full chat with the agent, showing the attack in action\"/\u003e\n\u003cb\u003eClick to see full chat with the agent.\u003c/b\u003e\n\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"detecting-toxic-agent-flows\"\u003eDetecting Toxic Agent Flows\u003c/h2\u003e\n\n\u003cp\u003eUnlike previously-discovered \u003ca href=\"https://invariantlabs.ai/blog/blog/mcp-security-notification-tool-poisoning-attacks.html\"\u003etool poisoning attacks\u003c/a\u003e with MCP, this vulnerability does not require the MCP tools themselves to be compromised. Instead, the issue emerges even with fully trusted tools, as agents can be exposed to untrusted information when connected to external platforms like GitHub.\u003c/p\u003e\n\u003cp\u003eUnderstanding, analyzing, and mitigating such issues in agentic systems is a highly complex undertaking that\u0026#39;s difficult to perform manually and at scale. To address this challenge, Invariant has developed \u003cstrong\u003eautomated methods for detecting toxic agent flows\u003c/strong\u003e, enabling organizations to identify and model potential threats before they can be exploited by malicious actors.\u003c/p\u003e\n\u003cp\u003eIf you\u0026#39;re interested in conducting a comprehensive threat analysis of your agent systems and tools, please contact us at \u003ca href=\"https://invariantlabs.ai/cdn-cgi/l/email-protection#d4b1b5a6b8adb5b7b7b1a7a794bdbaa2b5a6bdb5baa0b8b5b6a7fab5bd\"\u003e\u003cspan data-cfemail=\"d0b5b1a2bca9b1b3b3b5a3a390b9bea6b1a2b9b1bea4bcb1b2a3feb1b9\"\u003e[email protected]\u003c/span\u003e\u003c/a\u003e. We\u0026#39;ll be happy to onboard you to our early access security program. Below is a preview of our security analyzer in action.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cimg src=\"https://invariantlabs.ai/images/toxic-flows-preview.png\" alt=\"Toxic flows preview\"/\u003e\n    \u003cfigcaption\u003ePreview: Invariant\u0026#39;s security analyzer for proactively detecting toxic agent flows.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003ch2 id=\"mitigations\"\u003eScope and Mitigations\u003c/h2\u003e\n\n\u003cp\u003eWhile our experiments focused on Claude Desktop, the vulnerability is not specific to any particular agent or MCP client. It affects any agent that uses the GitHub MCP server, regardless of the underlying model or implementation.\u003c/p\u003e\n\u003cp\u003eImportantly, \u003cstrong\u003ethis is not a flaw in the GitHub MCP server code itself\u003c/strong\u003e, but rather a fundamental architectural issue that must be addressed at the agent system level. This means that GitHub alone cannot resolve this vulnerability through server-side patches.\u003c/p\u003e\n\u003cp\u003eWe thus recommend the following two key mitigation strategies to prevent such attacks and strengthen the security posture of your agent systems.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/flow-grid.svg\" alt=\"Enforce Dataflow Rules\"/\u003e\u003c/p\u003e\n\u003ch4\u003e1. Implement Granular Permission Controls\u003c/h4\u003e\n\u003cp\u003eWhen using MCP integrations like GitHub\u0026#39;s, it\u0026#39;s critical to limit agent access to only the repositories it needs to interact with—following the principle of least privilege. While traditional token-based permissions offer some protection, they often impose rigid constraints that limit an agent\u0026#39;s functionality.\u003c/p\u003e\n\u003cp\u003eFor more effective security without sacrificing capability, we recommend implementing dynamic \u003cstrong\u003eruntime security layers\u003c/strong\u003e specifically designed for agent systems. Solutions like \u003cstrong\u003e\u003ca href=\"https://explorer.invariantlabs.ai/docs/guardrails/\"\u003eInvariant Guardrails\u003c/a\u003e\u003c/strong\u003e provide context-aware access control that adapts to your agent\u0026#39;s workflow while enforcing security boundaries. \u003c/p\u003e\n\u003cp\u003eTo illustrate, here\u0026#39;s an example policy that prevents cross-repository information leaks using Invariant Guardrails:\u003c/p\u003e\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003e\u003c/span\u003e\u003ccode\u003e\u003cspan\u003eraise\u003c/span\u003e \u003cspan\u003eViolation\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003e\u0026#34;You can access only one repo per session.\u0026#34;\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003eif\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\n    \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ecall_before\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003eToolCall\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e-\u0026gt;\u003c/span\u003e \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ecall_after\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003eToolCall\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\n    \u003cspan\u003ecall_before\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efunction\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ename\u003c/span\u003e \u003cspan\u003ein\u003c/span\u003e \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003eset\u003c/span\u003e \u003cspan\u003eof\u003c/span\u003e \u003cspan\u003erepo\u003c/span\u003e \u003cspan\u003eactions\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n    \u003cspan\u003ecall_after\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efunction\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ename\u003c/span\u003e \u003cspan\u003ein\u003c/span\u003e \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003eset\u003c/span\u003e \u003cspan\u003eof\u003c/span\u003e \u003cspan\u003erepo\u003c/span\u003e \u003cspan\u003eactions\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\n    \u003cspan\u003ecall_before\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efunction\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003earguments\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e\u0026#34;repo\u0026#34;\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e \u003cspan\u003e!=\u003c/span\u003e \u003cspan\u003ecall_after\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efunction\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003earguments\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e\u0026#34;repo\u0026#34;\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e \u003cspan\u003eor\u003c/span\u003e\n    \u003cspan\u003ecall_before\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efunction\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003earguments\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e\u0026#34;owner\u0026#34;\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e \u003cspan\u003e!=\u003c/span\u003e \u003cspan\u003ecall_after\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003efunction\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003earguments\u003c/span\u003e\u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e\u0026#34;owner\u0026#34;\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eYou can find the complete policy \u003ca href=\"https://invariantlabs.ai/images/github_policy.txt\"\u003ehere\u003c/a\u003e. See the \u003ca href=\"https://explorer.invariantlabs.ai/docs/mcp-scan/\"\u003eMCP-scan documentation\u003c/a\u003e, for more information on how to apply this policy to your MCP deployments.\u003c/p\u003e\n\u003cp\u003eThis approach effectively restricts an agent to working with only one repository per session, preventing cross-repository information leakage while maintaining full functionality within authorized boundaries.\u003c/p\u003e\n\u003cp\u003eTo experiment more with Guardrails, you can also use the \u003ca href=\"https://explorer.invariantlabs.ai/playground/\"\u003eGuardrails Playground\u003c/a\u003e to test policies before deploying them.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://invariantlabs.ai/images/explorer-icon.svg\" alt=\"Inspect with Explorer\"/\u003e\u003c/p\u003e\n\u003ch4\u003e2. Conduct Continuous Security Monitoring\u003c/h4\u003e\n\u003cp\u003eBeyond preventative measures, implement robust monitoring solutions to detect and respond to potential security threats in real time. We recommend deploying specialized security scanners such as Invariant\u0026#39;s \u003ca href=\"https://explorer.invariantlabs.ai/docs/mcp-scan/\"\u003eMCP-scan\u003c/a\u003e to continuously audit interactions between agents and MCP systems.\u003c/p\u003e\n\u003cp\u003eThe recently introduced \u003ca href=\"https://github.com/invariantlabs-ai/mcp-scan?tab=readme-ov-file#proxy\"\u003eproxy mode in MCP-scan\u003c/a\u003e significantly simplifies this process by enabling real-time security scanning of MCP connections without requiring modifications to your existing agent infrastructure. Simply route your MCP traffic through the proxy to gain immediate visibility and real-time scanning for potential security violations.\u003c/p\u003e\n\u003cp\u003eImplementing comprehensive monitoring also creates an audit trail that helps identify potential vulnerabilities, detect exploitation attempts, and ensure your agent systems remain protected against emerging attacks.\u003c/p\u003e\n\u003ch3\u003eWhy Model Alignment Is Not Enough\u003c/h3\u003e\n\u003cp\u003eAs demonstrated by our findings, even state-of-the-art aligned models are vulnerable to these attacks. In our experiments, we used \u003ca href=\"https://www.anthropic.com/news/claude-4\"\u003eClaude 4 Opus\u003c/a\u003e, a very recent, highly aligned and secure AI model. Despite its robust safety training, the agent was still susceptible to manipulation through relatively simplistic prompt injections. Similarly, many off-the-shelf prompt injection detector defenses, fail to catch this attack.\u003c/p\u003e\n\u003cp\u003eThe vulnerability persists because the security of agent systems is fundamentally contextual and environment-dependent. While general model alignment training creates some guardrails, it cannot anticipate the specific security requirements of every deployment scenario or organizational context. Security measures must be implemented at the system level, complementing model-level safeguards.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\n\u003cp\u003eIn this blog post, we have shown a critical vulnerability affecting the GitHub MCP server, allowing attackers to hijack a user\u0026#39;s agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories. The vulnerability is among the first discovered by Invariant\u0026#39;s security analyzer for detecting toxic agent flows.\u003c/p\u003e\n\u003cp\u003eWhile the vulnerability that we uncover is specific to GitHub MCP, similar attacks keep emerging in other settings. For instance, \u003ca href=\"https://www.legitsecurity.com/\"\u003eLegit Security\u003c/a\u003e recently reported a vulnerability in \u003ca href=\"https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo\"\u003eGitLab Duo\u003c/a\u003e.\n \n\u003c/p\u003e\n\u003cp\u003eIt is crucial to safeguard agent systems and MCP integrations using designated security scanners such as Invariant\u0026#39;s \u003ca href=\"https://invariantlabs.ai/blog/blog/introducing-mcp-scan\"\u003eMCP-scan\u003c/a\u003e and \u003ca href=\"https://explorer.invariantlabs.ai/docs/guardrails/\"\u003eGuardrails\u003c/a\u003e to ensure responsible deployment at scale.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWork With Us\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf you are interested in learning more about how to secure your agent systems, please reach out to us at \u003ca href=\"https://invariantlabs.ai/cdn-cgi/l/email-protection#197c786b7560787a7a7c6a6a5970776f786b7078776d75787b6a377870\"\u003e\u003cspan data-cfemail=\"80e5e1f2ecf9e1e3e3e5f3f3c0e9eef6e1f2e9e1eef4ece1e2f3aee1e9\"\u003e[email protected]\u003c/span\u003e\u003c/a\u003e. We are happy to onboard you to our early access security program, and help you secure your agent systems.\u003c/p\u003e       \n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-05-26T14:00:00+02:00",
  "modifiedTime": "2025-05-26T14:00:00+02:00"
}
