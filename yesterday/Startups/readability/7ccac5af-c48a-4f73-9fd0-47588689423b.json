{
  "id": "7ccac5af-c48a-4f73-9fd0-47588689423b",
  "title": "A look under the hood of transfomers, the engine driving AI model evolution",
  "link": "https://venturebeat.com/ai/a-look-under-the-hood-of-transfomers-the-engine-driving-ai-model-evolution/",
  "description": "How transformers work, why they are so important for the growth of scalable solutions and why they are the backbone of LLMs.",
  "author": "Terrence Alsup, Finastra",
  "published": "Sat, 15 Feb 2025 20:05:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "category-/Computers \u0026 Electronics/Software",
    "category-/Science/Computer Science",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "neural networks",
    "NLP",
    "Transformers"
  ],
  "byline": "Terrence Alsup, Finastra",
  "length": 5940,
  "excerpt": "How transformers work, why they are so important for the growth of scalable solutions and why they are the backbone of LLMs.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "February 15, 2025 12:05 PM VentureBeat/Ideogram Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Today, virtually every cutting-edge AI product and model uses a transformer architecture. Large language models (LLMs) such as GPT-4o, LLaMA, Gemini and Claude are all transformer-based, and other AI applications such as text-to-speech, automatic speech recognition, image generation and text-to-video models have transformers as their underlying technology.   With the hype around AI not likely to slow down anytime soon, it’s time to give transformers their due, which is why I’d like to explain a little about how they work, why they are so important for the growth of scalable solutions and why they are the backbone of LLMs.   Transformers are more than meets the eye  In brief, a transformer is a neural network architecture designed to model sequences of data, making them ideal for tasks such as language translation, sentence completion, automatic speech recognition and more. Transformers have really become the dominant architecture for many of these sequence modeling tasks because the underlying attention-mechanism can be easily parallelized, allowing for massive scale when training and performing inference.   Originally introduced in a 2017 paper, “Attention Is All You Need” from researchers at Google, the transformer was introduced as an encoder-decoder architecture specifically designed for language translation. The following year, Google released bidirectional encoder representations from transformers (BERT), which could be considered one of the first LLMs — although it’s now considered small by today’s standards.  Since then — and especially accelerated with the advent of GPT models from OpenAI — the trend has been to train bigger and bigger models with more data, more parameters and longer context windows.    To facilitate this evolution, there have been many innovations such as: more advanced GPU hardware and better software for multi-GPU training; techniques like quantization and mixture of experts (MoE) for reducing memory consumption; new optimizers for training, like Shampoo and AdamW; techniques for efficiently computing attention, like FlashAttention and KV Caching. The trend will likely continue for the foreseeable future.  The importance of self-attention in transformers Depending on the application, a transformer model follows an encoder-decoder architecture. The encoder component learns a vector representation of data that can then be used for downstream tasks like classification and sentiment analysis. The decoder component takes a vector or latent representation of the text or image and uses it to generate new text, making it useful for tasks like sentence completion and summarization. For this reason, many familiar state-of-the-art models, such the GPT family, are decoder only.    Encoder-decoder models combine both components, making them useful for translation and other sequence-to-sequence tasks. For both encoder and decoder architectures, the core component is the attention layer, as this is what allows a model to retain context from words that appear much earlier in the text.   Attention comes in two flavors: self-attention and cross-attention. Self-attention is used for capturing relationships between words within the same sequence, whereas cross-attention is used for capturing relationships between words across two different sequences. Cross-attention connects encoder and decoder components in a model and during translation. For example, it allows the English word “strawberry” to relate to the French word “fraise.”  Mathematically, both self-attention and cross-attention are different forms of matrix multiplication, which can be done extremely efficiently using a GPU.  Because of the attention layer, transformers can better capture relationships between words separated by long amounts of text, whereas previous models such as recurrent neural networks (RNN) and long short-term memory (LSTM) models lose track of the context of words from earlier in the text.  The future of models  Currently, transformers are the dominant architecture for many use cases that require LLMs and benefit from the most research and development. Although this does not seem likely to change anytime soon, one different class of model that has gained interest recently is state-space models (SSMs) such as Mamba. This highly efficient algorithm can handle very long sequences of data, whereas transformers are limited by a context window.   For me, the most exciting applications of transformer models are multimodal models. OpenAI’s GPT-4o, for instance, is capable of handling text, audio and images — and other providers are starting to follow. Multimodal applications are very diverse, ranging from video captioning to voice cloning to image segmentation (and more). They also present an opportunity to make AI more accessible to those with disabilities. For example, a blind person could be greatly served by the ability to interact through voice and audio components of a multimodal application.   It’s an exciting space with plenty of potential to uncover new use cases. But do remember that, at least for the foreseeable future, are largely underpinned by transformer architecture.  Terrence Alsup is a senior data scientist at Finastra. DataDecisionMakers Welcome to the VentureBeat community! DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation. If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers. You might even consider contributing an article of your own! Read More From DataDecisionMakers",
  "image": "https://venturebeat.com/wp-content/uploads/2025/02/a-3d-render-of-a-vector-illustration-of-_pB9RHAQ4Sx-HNsX4P_Mi2A_K7G5l8EhS4uQBvLexvn0lQ.jpeg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-02-15T20:05:00+00:00\" datetime=\"2025-02-15T20:05:00+00:00\"\u003eFebruary 15, 2025 12:05 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"421\" src=\"https://venturebeat.com/wp-content/uploads/2025/02/a-3d-render-of-a-vector-illustration-of-_pB9RHAQ4Sx-HNsX4P_Mi2A_K7G5l8EhS4uQBvLexvn0lQ.jpeg?w=750\" alt=\"VentureBeat/Ideogram\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Ideogram\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eToday, virtually every cutting-edge AI product and model uses a transformer architecture. \u003ca href=\"https://venturebeat.com/ai/begin-with-problems-sandbox-identify-trustworth-vendors-a-quick-guide-to-getting-started-with-ai/\"\u003eLarge language models\u003c/a\u003e (LLMs) such as GPT-4o, LLaMA, Gemini and Claude are all transformer-based, and other AI applications such as text-to-speech, automatic speech recognition, image generation and text-to-video models have transformers as their underlying technology.  \u003c/p\u003e\n\n\n\n\u003cp\u003eWith the hype around AI not likely to slow down anytime soon, it’s time to give transformers their due, which is why I’d like to explain a little about how they work, why they are so important for the growth of scalable solutions and why they are the backbone of LLMs.  \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-transformers-are-more-than-meets-the-eye\"\u003eTransformers are more than meets the eye \u003c/h2\u003e\n\n\n\n\u003cp\u003eIn brief, a transformer is a neural network architecture designed to model sequences of data, making them ideal for tasks such as language translation, sentence completion, automatic speech recognition and more. Transformers have really become the dominant architecture for many of these sequence modeling tasks because the underlying attention-mechanism can be easily parallelized, allowing for massive scale when \u003ca href=\"https://venturebeat.com/ai/clever-architecture-over-raw-compute-deepseek-shatters-the-bigger-is-better-approach-to-ai-development/\"\u003etraining and performing inference\u003c/a\u003e.  \u003c/p\u003e\n\n\n\n\u003cp\u003eOriginally introduced in a 2017 paper, “\u003ca href=\"https://research.google/pubs/attention-is-all-you-need/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAttention Is All You Need\u003c/a\u003e” from researchers at Google, the transformer was introduced as an encoder-decoder architecture specifically designed for language translation. The following year, Google released bidirectional encoder representations from transformers (BERT), which could be considered one of the first LLMs — although it’s now considered small by today’s standards. \u003c/p\u003e\n\n\n\n\u003cp\u003eSince then — and especially accelerated with the advent of GPT models from \u003ca href=\"https://venturebeat.com/ai/we-asked-openais-o1-about-the-top-ai-trends-in-2025-heres-a-look-into-our-conversation/\"\u003eOpenAI\u003c/a\u003e — the trend has been to train bigger and bigger models with more data, more parameters and longer context windows.   \u003c/p\u003e\n\n\n\n\u003cp\u003eTo facilitate this evolution, there have been many innovations such as: more advanced GPU hardware and better software for multi-GPU training; techniques like quantization and mixture of experts (MoE) for reducing memory consumption; new optimizers for training, like Shampoo and AdamW; techniques for efficiently computing attention, like FlashAttention and KV Caching. The trend will likely continue for the foreseeable future. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-importance-of-self-attention-in-transformers\"\u003eThe importance of self-attention in transformers\u003c/h2\u003e\n\n\n\n\u003cp\u003eDepending on the application, a transformer model follows an encoder-decoder architecture. The encoder component learns a vector representation of data that can then be used for downstream tasks like classification and sentiment analysis. The decoder component takes a vector or latent representation of the text or image and uses it to generate new text, making it useful for tasks like sentence completion and summarization. For this reason, many familiar state-of-the-art models, such the GPT family, are decoder only.   \u003c/p\u003e\n\n\n\n\u003cp\u003eEncoder-decoder models combine both components, making them useful for translation and other sequence-to-sequence tasks. For both encoder and decoder architectures, the core component is the attention layer, as this is what allows a model to retain context from words that appear much earlier in the text.  \u003c/p\u003e\n\n\n\n\u003cp\u003eAttention comes in two flavors: self-attention and cross-attention. Self-attention is used for capturing relationships between words within the same sequence, whereas cross-attention is used for capturing relationships between words across two different sequences. Cross-attention connects encoder and decoder components in a model and during translation. For example, it allows the English word “strawberry” to relate to the French word “fraise.”  Mathematically, both self-attention and cross-attention are different forms of matrix multiplication, which can be done extremely efficiently using a GPU. \u003c/p\u003e\n\n\n\n\u003cp\u003eBecause of the attention layer, transformers can better capture relationships between words separated by long amounts of text, whereas previous models such as recurrent neural networks (RNN) and long short-term memory (LSTM) models lose track of the context of words from earlier in the text. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-future-of-models\"\u003eThe future of models \u003c/h2\u003e\n\n\n\n\u003cp\u003eCurrently, transformers are the dominant architecture for many use cases that require LLMs and benefit from the most research and development. Although this does not seem likely to change anytime soon, one different class of model that has gained interest recently is state-space models (SSMs) such as Mamba. This highly efficient algorithm can handle very long sequences of data, whereas transformers are limited by a context window.  \u003c/p\u003e\n\n\n\n\u003cp\u003eFor me, the most exciting applications of transformer models are multimodal models. OpenAI’s GPT-4o, for instance, is capable of handling text, audio and images — and other providers are starting to follow. Multimodal applications are very diverse, ranging from video captioning to voice cloning to image segmentation (and more). They also present an opportunity to make AI more accessible to those with disabilities. For example, a blind person could be greatly served by the ability to interact through voice and audio components of a multimodal application.  \u003c/p\u003e\n\n\n\n\u003cp\u003eIt’s an exciting space with plenty of potential to uncover new use cases. But do remember that, at least for the foreseeable future, are largely underpinned by transformer architecture. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eTerrence Alsup is a senior data scientist at \u003ca href=\"https://www.finastra.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eFinastra\u003c/a\u003e.\u003cbr/\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2736392\"\u003e\n\u003cp\u003e\u003cstrong\u003eDataDecisionMakers\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWelcome to the VentureBeat community!\u003c/p\u003e\n\n\n\n\u003cp\u003eDataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.\u003c/p\u003e\n\n\n\n\u003cp\u003eYou might even consider \u003ca rel=\"noreferrer noopener\" target=\"_blank\" href=\"https://venturebeat.com/guest-posts/\"\u003econtributing an article\u003c/a\u003e of your own!\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca rel=\"noreferrer noopener\" href=\"https://venturebeat.com/category/DataDecisionMakers/\" target=\"_blank\"\u003eRead More From DataDecisionMakers\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-02-15T20:05:00Z",
  "modifiedTime": "2025-02-15T00:11:32Z"
}
