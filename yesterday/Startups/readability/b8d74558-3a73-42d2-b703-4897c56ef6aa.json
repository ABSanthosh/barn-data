{
  "id": "b8d74558-3a73-42d2-b703-4897c56ef6aa",
  "title": "What If AI Goes Rogue? This Startup Wants to Write the Insurance Policy",
  "link": "https://www.inc.com/tekendra-parmar/what-if-ai-goes-rogue-this-startup-wants-to-write-the-insurance-policy/91219609",
  "description": "With hallucinating chatbots, deepfakes, and algorithmic accidents on the rise, AIUC says the solution to building safer models is pricing the risks.",
  "author": "Tekendra Parmar",
  "published": "Fri, 25 Jul 2025 16:33:18 -0400",
  "source": "https://www.inc.com/rss/",
  "categories": [
    "Startup"
  ],
  "byline": "Tekendra Parmar",
  "length": 3829,
  "excerpt": "With hallucinating chatbots, deepfakes, and algorithmic accidents on the rise, AIUC says the solution to building safer models is pricing the risks.",
  "siteName": "Inc",
  "favicon": "https://www.inc.com/_public/icons/apple-icon.png",
  "text": "An early Anthropic employee has launched an AI insurance firm to help companies deploy artificial intelligence systems while mitigating the catastrophic risks of rogue AI models. The Artificial Intelligence Underwriting Company, which came out of stealth on Wednesday, was launched by co-founders Rune Kvist, formerly of Anthropic; Brandon Wang, a former Thiel fellow; and Rajiv Dattani, a former McKinsey insurance partner. The trio raised $15 million, primarily from former GitHub CEO Nat Friedman through his firm, NFDG. Friedman was responsible for $10 million of that investment, with the remaining third coming from Emergence, Terrain, and angel investors like Benjamin Mann of Anthropic.A top-down approach to AI regulation, Kvist tells Inc., is too slow to keep up with how the technology is evolving. “The EU Act started drafting in 2021. So much has changed since then,” he says. Instead, AIUC is creating both the safety standards and underwriting AI insurance for companies that are implementing the technology. “You wouldn’t rely on Goldman Sachs to say whether their bonds are worthwhile; you look to Standard \u0026 Poor,” he says. This independent perspective, Kvist says, is essential to accurately assessing the safety of AI models and their implementation. For companies that meet AIUC’s safety standards, they partner with some of the largest insurance companies to provide an insurance policy. A retailer, Kvist says, may take out a policy to cover cases in which its AI chatbots go rogue and misinform users about its returns policies. An insurance-based approach, he adds, helps untangle one of the most pressing questions around AI safety: Who is responsible when the machine goes awry?The team, which officially launched in December 2024 and had been operating in stealth until this week, currently consists of five people. But they intend to double headcount over the next year. “We’re trying to keep things tight,” Kvist says. In a paper released earlier this month, Kvist, Dattani and Wang outlined their philosophy for how insurance can help hasten AI progress while managing the risks artificial intelligence poses to society.“We’re navigating a tightrope as Superintelligence nears,” the trio wrote, referring to the advancement of artificial intelligence. “If the west slows down unilaterally, China could dominate the 21st century. If we accelerate recklessly, accidents will halt progress.” AI regulation, however, according to the trio, is moving too slowly and is too much of a patchwork to be effective in mitigating the risks of the technology. Instead, they say “insurers are incentivized to develop and quickly iterate on core safety measures” and therefore could help lead AI regulation efforts. However, AIUC isn’t an alternative to government regulation. Kvist still believes governments should play a key role in regulating larger-scale AI risks, like that posed by deepfakes, AI’s ability to create bioweapons, or other catastrophic risks. “There’s no substitute to government regulation,” says Timnit Gebru, the founder of the Distributed AI Research Institute. “Insurance companies should be more attuned to the risks,” she adds, but Gebru worries that the rapid pace of AI adoption is at odds with reducing AI harms. Kvist estimates enterprise adoption of AI is set to hit $500 billion in the next five years. As it does, the market for insurance providers is set to grow exponentially. “We’re in uncharted territory without a parallel in human history,” he says. “We’re going to need to act with confidence around all the ambiguity and put numbers on the risks. The people you can trust to put numbers on it are those with skin in the game, who pay if we get the numbers wrong.”The final deadline for the 2025 Inc. Power Partner Awards is tonight, July 25, at 11:59 p.m. PT. Apply now.",
  "image": "https://img-cdn.inc.com/image/upload/f_webp,q_auto,c_fit/vip/2025/07/ai-goes-evil-inc-1768777379.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAn early Anthropic employee has launched an AI insurance firm to help companies deploy artificial intelligence systems while mitigating the catastrophic risks of rogue AI models. The Artificial Intelligence Underwriting Company, which came out of stealth on Wednesday, was launched by co-founders Rune Kvist, formerly of \u003ca href=\"https://www.inc.com/ben-sherry/anthropic-just-made-it-easier-to-track-how-your-company-is-using-ai/91214574\"\u003eAnthropic\u003c/a\u003e; Brandon Wang, a former Thiel fellow; and Rajiv Dattani, a former McKinsey insurance partner. \u003c/p\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003eThe trio raised $15 million, primarily from former GitHub CEO Nat Friedman through his firm, NFDG. Friedman was responsible for $10 million of that investment, with the remaining third coming from Emergence, Terrain, and angel investors like Benjamin Mann of Anthropic.\u003c/p\u003e\u003cp\u003eA top-down approach to AI regulation, Kvist tells Inc\u003cem\u003e.\u003c/em\u003e, is too slow to keep up with how the technology is evolving. “The EU Act started drafting in 2021. So much has changed since then,” he says. Instead, AIUC is creating both the safety standards and underwriting AI insurance for companies that are implementing the technology. \u003c/p\u003e\u003cp\u003e“You wouldn’t rely on Goldman Sachs to say whether their bonds are worthwhile; you look to Standard \u0026amp; Poor,” he says. This independent perspective, Kvist says, is essential to accurately assessing the safety of AI models and their implementation. \u003c/p\u003e\u003c/div\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003eFor companies that meet AIUC’s safety standards, they partner with some of the largest insurance companies to provide an insurance policy. A retailer, Kvist says, may take out a policy to cover cases in which its AI chatbots go rogue and misinform users about its returns policies. An insurance-based approach, he adds, helps untangle one of the most pressing questions around AI safety: Who is responsible when the machine goes awry?\u003c/p\u003e\u003cp\u003eThe team, which officially launched in December 2024 and had been operating in stealth until this week, currently consists of five people. But they intend to double headcount over the next year. “We’re trying to keep things tight,” Kvist says. \u003c/p\u003e\u003cp\u003eIn a \u003ca href=\"https://underwriting-superintelligence.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003epaper released\u003c/a\u003e earlier this month, Kvist, Dattani and Wang outlined their philosophy for how insurance can help hasten AI progress while managing the risks artificial intelligence poses to society.\u003c/p\u003e\u003c/div\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003e“We’re navigating a tightrope as Superintelligence nears,” the trio wrote, referring to the \u003ca href=\"https://www.inc.com/kit-eaton/how-ai-superintelligence-could-change-your-business-and-everyone-elses/91209553\"\u003eadvancement of artificial intelligence\u003c/a\u003e. “If the west slows down unilaterally, China could dominate the 21st century. If we accelerate recklessly, accidents will halt progress.” \u003c/p\u003e\u003cp\u003eAI regulation, however, according to the trio, is moving too slowly and is too much of a patchwork to be effective in mitigating the risks of the technology. Instead, they say “insurers are incentivized to develop and quickly iterate on core safety measures” and therefore could help lead AI regulation efforts. \u003c/p\u003e\u003cp\u003eHowever, AIUC isn’t an alternative to government regulation. Kvist still believes governments should play a key role in regulating larger-scale AI risks, like that posed by deepfakes, AI’s ability to create bioweapons, or other catastrophic risks. \u003c/p\u003e\u003c/div\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003e“There’s no substitute to government regulation,” says Timnit Gebru, the founder of the Distributed AI Research Institute. “Insurance companies should be more attuned to the risks,” she adds, but Gebru worries that the rapid pace of AI adoption is at odds with reducing AI harms. \u003c/p\u003e\u003cp\u003eKvist estimates enterprise adoption of AI is set to hit $500 billion in the next five years. As it does, the market for insurance providers is set to grow exponentially. “We’re in uncharted territory without a parallel in human history,” he says. “We’re going to need to act with confidence around all the ambiguity and put numbers on the risks. The people you can trust to put numbers on it are those with skin in the game, who pay if we get the numbers wrong.”\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp\u003e\u003cem\u003eThe final deadline for the 2025 \u003ca href=\"https://incpowerpartners.secure-platform.com/a\"\u003eInc. Power Partner Awards\u003c/a\u003e is tonight, July 25, at 11:59 p.m. PT. \u003ca href=\"https://incpowerpartners.secure-platform.com/a\"\u003eApply now\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-07-25T20:33:18Z",
  "modifiedTime": "2025-07-25T20:33:20Z"
}
