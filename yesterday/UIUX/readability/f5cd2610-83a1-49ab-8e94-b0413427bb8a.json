{
  "id": "f5cd2610-83a1-49ab-8e94-b0413427bb8a",
  "title": "Unmasking The Magic: The Wizard Of Oz Method For UX Research",
  "link": "https://smashingmagazine.com/2025/07/unmasking-magic-wizard-oz-method-ux-research/",
  "description": "The Wizard of Oz method is a proven UX research tool that simulates real interactions to uncover authentic user behavior. Victor Yocco unpacks the core principles of the WOZ method, explores advanced real-world applications, and highlights its unique value, including its relevance in the emerging field of agentic AI.",
  "author": "Victor Yocco",
  "published": "Thu, 10 Jul 2025 10:00:00 GMT",
  "source": "https://www.smashingmagazine.com/feed",
  "categories": null,
  "byline": "About The Author",
  "length": 27519,
  "excerpt": "The Wizard of Oz method is a proven UX research tool that simulates real interactions to uncover authentic user behavior. Victor Yocco unpacks the core principles of the WOZ method, explores advanced real-world applications, and highlights its unique value, including its relevance in the emerging field of agentic AI.",
  "siteName": "Smashing Magazine",
  "favicon": "https://smashingmagazine.com/images/favicon/apple-touch-icon.png",
  "text": "19 min readUX, Design, User ResearchThe Wizard of Oz method is a proven UX research tool that simulates real interactions to uncover authentic user behavior. Victor Yocco explores its fundamentals, advanced techniques, and critical considerations, including its relevance in the emerging field of agentic AI.New technologies and innovative concepts frequently enter the product development lifecycle, promising to revolutionize user experiences. However, even the most ingenious ideas risk failure without a fundamental grasp of user interaction with these new experiences.Consider the plight of the Nintendo Power Glove. Despite being a commercial success (selling over 1 million units), its release in late 1989 was followed by its discontinuation less than a full year later in 1990. The two games created solely for the Power Glove sold poorly, and there was little use for the Glove with Nintendo’s already popular traditional console games.A large part of the failure was due to audience reaction once the product (which allegedly was developed in 8 weeks) was cumbersome and unintuitive. Users found syncing the glove to the moves in specific games to be extremely frustrating, as it required a process of coding the moves into the glove’s preset move buttons and then remembering which buttons would generate which move. With the more modern success of Nintendo’s WII and other movement-based controller consoles and games, we can see the Power Glove was a concept ahead of its time.The Nintendo Power Glove: A Fistful of Frustration. (Image source: ACMI) (Large preview)If Power Glove’s developers wanted to conduct effective research prior to building it out, they would have needed to look beyond traditional methods, such as surveys and interviews, to understand how a user might truly interact with the Glove. How could this have been done without a functional prototype and slowing down the overall development process?Enter the Wizard of Oz method, a potent tool for bridging the chasm between abstract concepts and tangible user understanding, as one potential option. This technique simulates a fully functional system, yet a human operator (“the Wizard”) discreetly orchestrates the experience. This allows researchers to gather authentic user reactions and insights without the prerequisite of a fully built product.The Wizard of Oz (WOZ) method is named in tribute to the similarly named book by Frank L. Baum. In the book, the Wizard is simply a man hidden behind a curtain, manipulating the reality of those who travel the land of Oz. Dorothy, the protagonist, exposes the Wizard for what he is, essentially an illusion or a con who is deceiving those who believe him to be omnipotent. Similarly, WOZ takes technologies that may or may not currently exist and emulates them in a way that should convince a research participant they are using an existing system or tool.WOZ enables the exploration of user needs, validation of nascent concepts, and mitigation of development risks, particularly with complex or emerging technologies.The product team in our above example might have used this method to have users simulate the actions of wearing the glove, programming moves into the glove, and playing games without needing a fully functional system. This could have uncovered the illogical situation of asking laypeople to code their hardware to be responsive to a game, show the frustration one encounters when needing to recode the device when changing out games, and also the cumbersome layout of the controls on the physical device (even if they’d used a cardboard glove with simulated controls drawn in crayon on the appropriate locations.Jeff Kelley credits himself (PDF) with coining the term WOZ method in 1980 to describe the research method he employed in his dissertation. However, Paula Roe credits Don Norman and Allan Munro for using the method as early as 1973 to conduct testing on an airport automated travel assistant. Regardless of who originated the method, both parties agree that it gained prominence when IBM later used it to conduct studies on a speech-to-text tool known as The Listening Typewriter (see Image below).Wizard of Oz testing: The listening typewriter IBM 1984. (Image source: CDS) (Large preview)In this article, I’ll cover the core principles of the WOZ method, explore advanced applications taken from practical experience, and demonstrate its unique value through real-world examples, including its application to the field of agentic AI. UX practitioners can use the WOZ method as another tool to unlock user insights and craft human-centered products and experiences.The Yellow Brick Road: Core Principles And MechanicsThe WOZ method operates on the premise that users believe they are interacting with an autonomous system while a human wizard manages the system’s responses behind the scenes. This individual, often positioned remotely (or off-screen), interprets user inputs and generates outputs that mimic the anticipated functionality of the experience.Cast Of CharactersA successful WOZ study involves several key roles:The UserThe participant who engages with what they perceive as the functional system.The FacilitatorThe researcher who guides the user through predefined tasks and observes their behavior and reactions.The WizardThe individual manipulates the system’s behavior in real-time, providing responses to user inputs.The Observer (Optional)An additional researcher who observes the session without direct interaction, allowing for a secondary perspective on user behavior.Setting The Stage For Believability: Leaving Kansas BehindCreating a convincing illusion is key to the success of a WOZ study. This necessitates careful planning of the research environment and the tasks users will undertake. Consider a study evaluating a new voice command system for smart home devices. The research setup might involve a physical mock-up of a smart speaker and predefined scenarios like “Play my favorite music” or “Dim the living room lights.” The wizard, listening remotely, would then trigger the appropriate responses (e.g., playing a song, verbally confirming the lights are dimmed).Or perhaps it is a screen-based experience testing a new AI-powered chatbot. You have users entering commands into a text box, with another member of the product team providing responses simultaneously using a tool like Figma/Figjam, Miro, Mural, or other cloud-based software that allows multiple users to collaborate simultaneously (the author has no affiliation with any of the mentioned products).The Art Of IllusionMaintaining the illusion of a genuine system requires the following:Timely and Natural ResponsesThe wizard must react to user inputs with minimal delay and in a manner consistent with expected system behavior. Hesitation or unnatural phrasing can break the illusion.Consistent System LogicResponses should adhere to a predefined logic. For instance, if a user asks for the weather in a specific city, the wizard should consistently provide accurate information.Handling the UnexpectedUsers will inevitably deviate from planned paths. The wizard must possess the adaptability to respond plausibly to unforeseen inputs while preserving the perceived functionality.Ethical ConsiderationsTransparency is crucial, even in a method that involves a degree of deception. Participants should always be debriefed after the session, with a clear explanation of the Wizard of Oz technique and the reasons for its use. Data privacy must be maintained as with any study, and participants should feel comfortable and respected throughout the process.Distinguishing The MethodThe WOZ method occupies a unique space within the UX research toolkit:Unlike usability testing, which evaluates existing interfaces, Wizard of Oz explores concepts before significant development.Distinct from A/B testing, which compares variations of a product’s design, WOZ assesses entirely new functionalities that might otherwise lack context if shown to users.Compared to traditional prototyping, which often involves static mockups, WOZ offers a dynamic and interactive experience, enabling observation of real-time user behavior with a simulated system.This method proves particularly valuable when exploring truly novel interactions or complex systems where building a fully functional prototype is premature or resource-intensive. It allows researchers to answer fundamental questions about user needs and expectations before committing significant development efforts.Let’s move beyond the foundational aspects of the WOZ method and explore some more advanced techniques and critical considerations that can elevate its effectiveness.Time Savings: WOZ Versus Crude PrototypingIt’s a fair question to ask whether WOZ is truly a time-saver compared to even cruder prototyping methods like paper prototypes or static digital mockups.While paper prototypes are incredibly fast to create and test for basic flow and layout, they fundamentally lack dynamic responsiveness. Static mockups offer visual fidelity but cannot simulate complex interactions or personalized outputs.The true time-saving advantage of the WOZ emerges when testing novel, complex, or AI-driven concepts. It allows researchers to evaluate genuine user interactions and mental models in a seemingly live environment, collecting rich behavioral data that simpler prototypes cannot. This fidelity in simulating a dynamic experience, even with a human behind the curtain, often reveals critical usability or conceptual flaws far earlier and more comprehensively than purely static representations, ultimately preventing costly reworks down the development pipeline.Additional Techniques And ConsiderationsWhile the core principle of the WOZ method is straightforward, its true power lies in nuanced application and thoughtful execution. Seasoned practitioners may leverage several advanced techniques to extract richer insights and address more complex research questions.Iterative WizardryThe WOZ method isn’t necessarily a one-off endeavor. Employing it in iterative cycles can yield significant benefits. Initial rounds might focus on broad concept validation and identifying fundamental user reactions. Subsequent iterations can then refine the simulated functionality based on previous findings.For instance, after an initial study reveals user confusion with a particular interaction flow, the simulation can be adjusted, and a follow-up study can assess the impact of those changes. This iterative approach allows for a more agile and user-centered exploration of complex experiences.Managing ComplexitySimulating complex systems can be difficult for one wizard. Breaking complex interactions into smaller, manageable steps is crucial. Consider researching a multi-step onboarding process for a new software application. Instead of one person trying to simulate the entire flow, different aspects could be handled sequentially or even by multiple team members coordinating their responses.Clear communication protocols and well-defined responsibilities are essential in such scenarios to maintain a seamless user experience.Measuring Success Beyond ObservationWhile qualitative observation is a cornerstone of the WOZ method, defining clear metrics can add a layer of rigor to the findings. These metrics should match research goals. For example, if the goal is to assess the intuitiveness of a new navigation pattern, you might track the number of times users express confusion or the time it takes them to complete specific tasks.Combining these quantitative measures with qualitative insights provides a more comprehensive understanding of the user experience.Integrating With Other MethodsThe WOZ method isn’t an island. Its effectiveness can be amplified by integrating it with other research techniques. Preceding a WOZ study with user interviews can help establish a deeper understanding of user needs and mental models, informing the design of the simulated experience. Following a WOZ study, surveys can gather broader quantitative feedback on the concepts explored. For example, after observing users interact with a simulated AI-powered scheduling tool, a survey could gauge their overall trust and perceived usefulness of such a system.When Not To Use WOZWOZ, as with all methods, has limitations. A few examples of scenarios where other methods would likely yield more reliable findings would be:Detailed Usability TestingHumans acting as wizards cannot perfectly replicate the exact experience a user will encounter. WOZ is often best in the early stages, where prototypes are rough drafts, and your team is looking for guidance on a solution that is up for consideration. Testing on a more detailed wireframe or prototype would be preferable to WOZ when you have entered the detailed design phase.Evaluating extremely complex systems with unpredictable outputsIf the system’s responses are extremely varied, require sophisticated real-time calculations that exceed human capacity, or are intended to be genuinely unpredictable, a human may struggle to simulate them convincingly and consistently. This can lead to fatigue, errors, or improvisations that don’t reflect the intended system, thereby compromising the validity of the findings.Training And PreparednessThe wizard’s skill is critical to the method’s success. Training the individual(s) who will be simulating the system is essential. This training should cover:Understanding the Research GoalsThe wizard needs to grasp what the research aims to uncover.Consistency in ResponsesMaintaining consistent behavior throughout the sessions is vital for user believability.Anticipating User ActionsWhile improvisation is sometimes necessary, the wizard should be prepared for common user paths and potential deviations.Remaining UnbiasedThe wizard must avoid leading users or injecting their own opinions into the simulation.Handling Unexpected InputsClear protocols for dealing with unforeseen user actions should be established. This might involve having a set of pre-prepared fallback responses or a mechanism for quickly consulting with the facilitator.All of this suggests the need for practice in advance of running the actual session. We shouldn’t forget to have a number of dry runs in which we ask our colleagues or those who are willing to assist to not only participate but also think about possible responses that could stump the wizard or throw things off if the user might provide them during a live session.I suggest having a believable prepared error statement ready to go for when a user throws a curveball. A simple response from the wizard of “I’m sorry, I am unable to perform that task at this time” might be enough to move the session forward while also capturing a potentially unexpected situation your team can address in the final product design.Was This All A Dream? The Art Of The DebriefThe debriefing session following the WOZ interaction is an additional opportunity to gather rich qualitative data. Beyond asking “What did you think?” effective debriefing involves sharing the purpose of the study and the fact that the experience was simulated.Researchers should then conduct psychological probing to understand the reasons behind user behavior and reactions. Asking open-ended questions like “Why did you try that?” or “What were you expecting to happen when you clicked that button?” can reveal valuable insights into user mental models and expectations.Exploring moments of confusion, frustration, or delight in detail can uncover key areas for design improvement. Think about the potential information the Power Gloves’ development team could have uncovered if they’d asked participants what the experience of programming the glove and trying to remember what they’d programmed into which set of keys had been.Case Studies: Real-World ApplicationsThe value of the WOZ method becomes apparent when examining its application in real-world research scenarios. Here is an in-depth review of one scenario and a quick summary of another study involving WOZ, where this technique proved invaluable in shaping user experiences.Unraveling Agentic AI: Understanding User Mental ModelsA significant challenge in the realm of emerging technologies lies in user comprehension. This was particularly evident when our team began exploring the potential of Agentic AI for enterprise HR software.Agentic AI refers to artificial intelligence systems that can autonomously pursue goals by making decisions, taking actions, and adapting to changing environments with minimal human intervention. Unlike generative AI that primarily responds to direct commands or generates content, Agentic AI is designed to understand user intent, independently plan and execute multi-step tasks, and learn from its interactions to improve performance over time. These systems often combine multiple AI models and can reason through complex problems. For designers, this signifies a shift towards creating experiences where AI acts more like a proactive collaborator or assistant, capable of anticipating needs and taking the initiative to help users achieve their objectives rather than solely relying on explicit user instructions for every step.Preliminary research, including surveys and initial interviews, suggested that many HR professionals, while intrigued by the concept of AI assistance, struggled to grasp the potential functionality and practical implications of truly agentic systems — those capable of autonomous action and proactive decision-making. We saw they had no reference point for what agentic AI was, even after we attempted relevant analogies to current examples.Building a fully functional agentic AI prototype at this exploratory stage was impractical. The underlying algorithms and integrations were complex and time-consuming to develop. Moreover, we risked building a solution based on potentially flawed assumptions about user needs and understanding. The WOZ method offered a solution.SetupWe designed a scenario where HR employees interacted with what they believed was an intelligent AI assistant capable of autonomously handling certain tasks. The facilitator presented users with a web interface where they could request assistance with tasks like “draft a personalized onboarding plan for a new marketing hire” or “identify employees who might benefit from proactive well-being resources based on recent activity.”Behind the scenes, a designer acted as the wizard. Based on the user’s request and the (simulated) available data, the designer would craft a response that mimicked the output of an agentic AI. For the onboarding plan, this involved assembling pre-written templates and personalizing them with details provided by the user. For the well-being resource identification, the wizard would select a plausible list of employees based on the general indicators discussed in the scenario.Crucially, the facilitator encouraged users to interact naturally, asking follow-up questions and exploring the system’s perceived capabilities. For instance, a user might ask, “Can the system also schedule the initial team introductions?” The wizard, guided by pre-defined rules and the overall research goals, would respond accordingly, perhaps with a “Yes, I can automatically propose meeting times based on everyone’s calendars” (again, simulated).As recommended, we debriefed participants following each session. We began with transparency, explaining the simulation and that we had another live human posting the responses to the queries based on what the participant was saying. Open-ended questions explored initial reactions and envisioned use. Task-specific probing, like “Why did you expect that?” revealed underlying assumptions. We specifically addressed trust and control (“How much trust…? What level of control…?”). To understand mental models, we asked how users thought the “AI” worked. We also solicited improvement suggestions (“What features…?”).By focusing on the “why” behind user actions and expectations, these debriefings provided rich qualitative data that directly informed subsequent design decisions, particularly around transparency, human oversight, and prioritizing specific, high-value use cases. We also had a research participant who understood agentic AI and could provide additional insight based on that understanding.Key InsightsThis WOZ study yielded several crucial insights into user mental models of agentic AI in an HR context:Overestimation of CapabilitiesSome users initially attributed near-magical abilities to the “AI”, expecting it to understand highly nuanced or ambiguous requests without explicit instruction. This highlighted the need for clear communication about the system’s actual scope and limitations.Trust and ControlA significant theme revolved around trust and control. Users expressed both excitement about the potential time savings and anxiety about relinquishing control over important HR processes. This indicated a need for design solutions that offered transparency into the AI’s decision-making and allowed for human oversight.Value in Proactive AssistanceUsers reacted positively to the AI proactively identifying potential issues (like burnout risk), but they emphasized the importance of the AI providing clear reasoning and allowing human HR professionals to review and approve any suggested actions.Need for Tangible ExamplesAbstract explanations of agentic AI were insufficient. Users gained a much clearer understanding through these simulated interactions with concrete tasks and outcomes.Resulting Design ChangesBased on these findings, we made several key design decisions:Emphasis on TransparencyThe user interface would need to clearly show the AI’s reasoning and the data it used to make decisions.Human Oversight and ReviewBuilt-in approval workflows would be essential for critical actions, ensuring HR professionals retain control.Focus on Specific, High-Value Use CasesInstead of trying to build a general-purpose agent, we prioritized specific use cases where agentic capabilities offered clear and demonstrable benefits.Educational OnboardingThe product onboarding would include clear, tangible examples of the AI’s capabilities in action.Exploring Voice Interaction for In-Car SystemsIn another project, we used the WOZ method to evaluate user interaction with a voice interface for controlling in-car functions. Our research question focused on the naturalness and efficiency of voice commands for tasks like adjusting climate control, navigating to points of interest, and managing media playback.We set up a car cabin simulator with a microphone and speakers. The wizard, located in an adjacent room, listened to the user’s voice commands and triggered the corresponding actions (simulated through visual changes on a display and audio feedback). This allowed us to identify ambiguous commands, areas of user frustration with voice recognition (even though it was human-powered), and preferences for different phrasing and interaction styles before investing in complex speech recognition technology.These examples illustrate the versatility and power of the method in addressing a wide range of UX research questions across diverse product types and technological complexities. By simulating functionality, we can gain invaluable insights into user behavior and expectations early in the design process, leading to more user-centered and ultimately more successful products.The Future of Wizardry: Adapting To Emerging TechnologiesThe WOZ method, far from being a relic of simpler technological times, retains relevance as we navigate increasingly sophisticated and often opaque emerging technologies.The WOZ method’s core strength, the ability to simulate complex functionality with human ingenuity, makes it uniquely suited for exploring user interactions with systems that are still in their nascent stages.WOZ In The Age Of AIConsider the burgeoning field of AI-powered experiences. Researching user interaction with generative AI, for instance, can be effectively done through WOZ. A wizard could curate and present AI-generated content (text, images, code) in response to user prompts, allowing researchers to assess user perceptions of quality, relevance, and trust without needing a fully trained and integrated AI model.Similarly, for personalized recommendation systems, a human could simulate the recommendations based on a user’s stated preferences and observed behavior, gathering valuable feedback on the perceived accuracy and helpfulness of such suggestions before algorithmic development.Even autonomous systems, seemingly the antithesis of human control, can benefit from WOZ studies. By simulating the autonomous behavior in specific scenarios, researchers can explore user comfort levels, identify needs for explainability, and understand how users might want to interact with or override such systems.Virtual And Augmented RealityImmersive environments like virtual and augmented reality present new frontiers for user experience research. WOZ can be particularly powerful here.Imagine testing a novel gesture-based interaction in VR. A researcher tracking the user’s hand movements could trigger corresponding virtual events, allowing for rapid iteration on the intuitiveness and comfort of these interactions without the complexities of fully programmed VR controls. Similarly, in AR, a wizard could remotely trigger the appearance and behavior of virtual objects overlaid onto the real world, gathering user feedback on their placement, relevance, and integration with the physical environment.The Human Factor Remains CentralDespite the rapid advancements in artificial intelligence and immersive technologies, the fundamental principles of human-centered design remain as relevant as ever. Technology should serve human needs and enhance human capabilities.The WOZ method inherently focuses on understanding user reactions and behaviors and acts as a crucial anchor in ensuring that technological progress aligns with human values and expectations.It allows us to inject the “human factor” into the design process of even the most advanced technologies. Doing this may help ensure these innovations are not only technically feasible but also truly usable, desirable, and beneficial.ConclusionThe WOZ method stands as a powerful and versatile tool in the UX researcher’s toolkit. The WOZ method’s ability to bypass limitations of early-stage development and directly elicit user feedback on conceptual experiences offers invaluable advantages. We’ve explored its core mechanics and covered ways of maximizing its impact. We’ve also examined its practical application through real-world case studies, including its crucial role in understanding user interaction with nascent technologies like agentic AI.The strategic implementation of the WOZ method provides a potent means of de-risking product development. By validating assumptions, uncovering unexpected user behaviors, and identifying potential usability challenges early on, teams can avoid costly rework and build products that truly resonate with their intended audience.I encourage all UX practitioners, digital product managers, and those who collaborate with research teams to consider incorporating the WOZ method into their research toolkit. Experiment with its application in diverse scenarios, adapt its techniques to your specific needs and don’t be afraid to have fun with it. Scarecrow costume optional. (yk)",
  "image": "https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/unmasking-magic-wizard-oz-method-ux-research.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article__content\"\u003e\u003cul\u003e\u003cli\u003e19 min read\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://smashingmagazine.com/category/ux\"\u003eUX\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/design\"\u003eDesign\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/user-research\"\u003eUser Research\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003csection aria-label=\"Quick summary\"\u003eThe Wizard of Oz method is a proven UX research tool that simulates real interactions to uncover authentic user behavior. Victor Yocco explores its fundamentals, advanced techniques, and critical considerations, including its relevance in the emerging field of agentic AI.\u003c/section\u003e\u003c/p\u003e\u003cp\u003eNew technologies and innovative concepts frequently enter the product development lifecycle, promising to revolutionize user experiences. However, even the most ingenious ideas risk failure without a fundamental grasp of user interaction with these new experiences.\u003c/p\u003e\u003cp\u003eConsider the plight of the \u003ca href=\"https://en.wikipedia.org/wiki/Power_Glove\"\u003eNintendo Power Glove\u003c/a\u003e. Despite being a commercial success (selling over 1 million units), its release in late 1989 was followed by its discontinuation less than a full year later in 1990. The two games created solely for the Power Glove sold poorly, and there was little use for the Glove with Nintendo’s already popular traditional console games.\u003c/p\u003e\u003cp\u003eA large part of the failure was due to audience reaction once the product (which allegedly was developed in 8 weeks) was \u003cstrong\u003ecumbersome\u003c/strong\u003e and \u003cstrong\u003eunintuitive\u003c/strong\u003e. Users found \u003ca href=\"https://electronics.howstuffworks.com/nintendo-power-glove.htm\"\u003esyncing the glove\u003c/a\u003e to the moves in specific games to be extremely frustrating, as it required a process of coding the moves into the glove’s preset move buttons and then remembering which buttons would generate which move. With the more modern success of Nintendo’s WII and other movement-based controller consoles and games, we can see the Power Glove was a concept ahead of its time.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"539\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg\" sizes=\"100vw\" alt=\"The Nintendo Power Glove\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eThe Nintendo Power Glove: A Fistful of Frustration. (Image source: \u003ca href=\"https://www.acmi.net.au/stories-and-ideas/nintendo-nes-power-glove/\"\u003eACMI\u003c/a\u003e) (\u003ca href=\"https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/1-nintendo-nes-power-glove.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIf Power Glove’s developers wanted to conduct effective research prior to building it out, they would have needed to look beyond traditional methods, such as surveys and interviews, to understand how a user might truly interact with the Glove. How could this have been done without a functional prototype and slowing down the overall development process?\u003c/p\u003e\u003cp\u003eEnter the \u003cstrong\u003eWizard of Oz method\u003c/strong\u003e, a potent tool for bridging the chasm between abstract concepts and tangible user understanding, as one potential option. This technique simulates a fully functional system, yet a human operator (“the Wizard”) discreetly orchestrates the experience. This allows researchers to gather \u003cstrong\u003eauthentic user reactions and insights\u003c/strong\u003e without the prerequisite of a fully built product.\u003c/p\u003e\u003cp\u003eThe Wizard of Oz (WOZ) method is named in tribute to the similarly named book by Frank L. Baum. In the book, the Wizard is simply a man hidden behind a curtain, manipulating the reality of those who travel the land of Oz. Dorothy, the protagonist, exposes the Wizard for what he is, essentially an illusion or a con who is deceiving those who believe him to be omnipotent. Similarly, WOZ takes technologies that may or may not currently exist and emulates them in a way that should convince a research participant they are using an existing system or tool.\u003c/p\u003e\u003cp\u003eWOZ enables the \u003cstrong\u003eexploration of user needs\u003c/strong\u003e, \u003cstrong\u003evalidation of nascent concepts\u003c/strong\u003e, and \u003cstrong\u003emitigation of development risks\u003c/strong\u003e, particularly with complex or emerging technologies.\u003c/p\u003e\u003cp\u003eThe product team in our above example might have used this method to have users simulate the actions of wearing the glove, programming moves into the glove, and playing games without needing a fully functional system. This could have uncovered the illogical situation of asking laypeople to code their hardware to be responsive to a game, show the frustration one encounters when needing to recode the device when changing out games, and also the cumbersome layout of the controls on the physical device (even if they’d used a cardboard glove with simulated controls drawn in crayon on the appropriate locations.\u003c/p\u003e\u003cp\u003eJeff Kelley \u003ca href=\"https://uxpajournal.org/wp-content/uploads/sites/7/pdf/JUS_Kelley_May2018.pdf\"\u003ecredits himself\u003c/a\u003e (PDF) with coining the term WOZ method in 1980 to describe the research method he employed in his dissertation. However, Paula Roe \u003ca href=\"https://www.telefonica.com/en/communication-room/blog/wizard-oz-technique-relation-artificial-intelligence/\"\u003ecredits Don Norman and Allan Munro\u003c/a\u003e for using the method as early as 1973 to conduct testing on an airport automated travel assistant. Regardless of who originated the method, both parties agree that it gained prominence when IBM later used it to conduct studies on a speech-to-text tool known as \u003cem\u003eThe Listening Typewriter\u003c/em\u003e (see Image below).\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"395\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png\" sizes=\"100vw\" alt=\"Wizard of Oz testing: The listening typewriter IBM 1984\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eWizard of Oz testing: The listening typewriter IBM 1984. (Image source: \u003ca href=\"https://blog.cds.co.uk/what-is-wizard-of-oz-testing-and-how-can-it-be-used\"\u003eCDS\u003c/a\u003e) (\u003ca href=\"https://files.smashing.media/articles/unmasking-magic-wizard-oz-method-ux-research/2-wizard-of-oz-testing.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn this article, I’ll cover the core principles of the WOZ method, explore advanced applications taken from practical experience, and demonstrate its unique value through real-world examples, including its application to the field of agentic AI. UX practitioners can use the WOZ method as another tool to \u003cstrong\u003eunlock user insights\u003c/strong\u003e and \u003cstrong\u003ecraft human-centered products and experiences\u003c/strong\u003e.\u003c/p\u003e\u003ch2 id=\"the-yellow-brick-road-core-principles-and-mechanics\"\u003eThe Yellow Brick Road: Core Principles And Mechanics\u003c/h2\u003e\u003cp\u003eThe WOZ method operates on the premise that users believe they are interacting with an autonomous system while a human wizard manages the system’s responses behind the scenes. This individual, often positioned remotely (or off-screen), interprets user inputs and generates outputs that mimic the anticipated functionality of the experience.\u003c/p\u003e\u003ch3 id=\"cast-of-characters\"\u003eCast Of Characters\u003c/h3\u003e\u003cp\u003eA successful WOZ study involves several key roles:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eThe User\u003c/strong\u003e\u003cbr/\u003eThe participant who engages with what they perceive as the functional system.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eThe Facilitator\u003c/strong\u003e\u003cbr/\u003eThe researcher who guides the user through predefined tasks and observes their behavior and reactions.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eThe Wizard\u003c/strong\u003e\u003cbr/\u003eThe individual manipulates the system’s behavior in real-time, providing responses to user inputs.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eThe Observer (Optional)\u003c/strong\u003e\u003cbr/\u003eAn additional researcher who observes the session without direct interaction, allowing for a secondary perspective on user behavior.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"setting-the-stage-for-believability-leaving-kansas-behind\"\u003eSetting The Stage For Believability: Leaving Kansas Behind\u003c/h3\u003e\u003cp\u003eCreating a \u003cstrong\u003econvincing illusion\u003c/strong\u003e is key to the success of a WOZ study. This necessitates careful planning of the research environment and the tasks users will undertake. Consider a study evaluating a new voice command system for smart home devices. The research setup might involve a physical mock-up of a smart speaker and predefined scenarios like \u003cem\u003e“Play my favorite music”\u003c/em\u003e or \u003cem\u003e“Dim the living room lights.”\u003c/em\u003e The wizard, listening remotely, would then trigger the appropriate responses (e.g., playing a song, verbally confirming the lights are dimmed).\u003c/p\u003e\u003cp\u003eOr perhaps it is a screen-based experience testing a new AI-powered chatbot. You have users entering commands into a text box, with another member of the product team providing responses simultaneously using a tool like Figma/Figjam, Miro, Mural, or other cloud-based software that allows multiple users to collaborate simultaneously (the author has no affiliation with any of the mentioned products).\u003c/p\u003e\u003ch4 id=\"the-art-of-illusion\"\u003eThe Art Of Illusion\u003c/h4\u003e\u003cp\u003eMaintaining the illusion of a genuine system requires the following:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eTimely and Natural Responses\u003c/strong\u003e\u003cbr/\u003eThe wizard must react to user inputs with minimal delay and in a manner consistent with expected system behavior. Hesitation or unnatural phrasing can break the illusion.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eConsistent System Logic\u003c/strong\u003e\u003cbr/\u003eResponses should adhere to a predefined logic. For instance, if a user asks for the weather in a specific city, the wizard should consistently provide accurate information.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHandling the Unexpected\u003c/strong\u003e\u003cbr/\u003eUsers will inevitably deviate from planned paths. The wizard must possess the adaptability to respond plausibly to unforeseen inputs while preserving the perceived functionality.\u003c/li\u003e\u003c/ul\u003e\u003ch4 id=\"ethical-considerations\"\u003eEthical Considerations\u003c/h4\u003e\u003cp\u003e\u003cstrong\u003eTransparency is crucial\u003c/strong\u003e, even in a method that involves a degree of deception. Participants should always be debriefed after the session, with a clear explanation of the Wizard of Oz technique and the reasons for its use. \u003cstrong\u003eData privacy\u003c/strong\u003e must be maintained as with any study, and participants should feel comfortable and respected throughout the process.\u003c/p\u003e\u003ch4 id=\"distinguishing-the-method\"\u003eDistinguishing The Method\u003c/h4\u003e\u003cp\u003eThe WOZ method occupies a unique space within the UX research toolkit:\u003c/p\u003e\u003cul\u003e\u003cli\u003eUnlike \u003cstrong\u003eusability testing\u003c/strong\u003e, which evaluates existing interfaces, Wizard of Oz explores concepts before significant development.\u003c/li\u003e\u003cli\u003eDistinct from \u003cstrong\u003eA/B testing\u003c/strong\u003e, which compares variations of a product’s design, WOZ assesses entirely new functionalities that might otherwise lack context if shown to users.\u003c/li\u003e\u003cli\u003eCompared to traditional \u003cstrong\u003eprototyping\u003c/strong\u003e, which often involves static mockups, WOZ offers a dynamic and interactive experience, enabling observation of real-time user behavior with a simulated system.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis method proves particularly valuable when exploring truly \u003cstrong\u003enovel interactions\u003c/strong\u003e or \u003cstrong\u003ecomplex systems\u003c/strong\u003e where building a fully functional prototype is premature or resource-intensive. It allows researchers to answer fundamental questions about user needs and expectations before committing significant development efforts.\u003c/p\u003e\u003cp\u003eLet’s move beyond the foundational aspects of the WOZ method and explore some more advanced techniques and critical considerations that can elevate its effectiveness.\u003c/p\u003e\u003ch4 id=\"time-savings-woz-versus-crude-prototyping\"\u003eTime Savings: WOZ Versus Crude Prototyping\u003c/h4\u003e\u003cp\u003eIt’s a fair question to ask whether WOZ is truly a time-saver compared to even cruder prototyping methods like paper prototypes or static digital mockups.\u003c/p\u003e\u003cp\u003eWhile paper prototypes are incredibly fast to create and test for basic flow and layout, they fundamentally lack dynamic responsiveness. Static mockups offer visual fidelity but cannot simulate complex interactions or personalized outputs.\u003c/p\u003e\u003cp\u003eThe true time-saving advantage of the WOZ emerges when testing novel, complex, or AI-driven concepts. It allows researchers to evaluate \u003cstrong\u003egenuine user interactions and mental models in a seemingly live environment\u003c/strong\u003e, collecting rich behavioral data that simpler prototypes cannot. This fidelity in simulating a \u003cstrong\u003edynamic experience\u003c/strong\u003e, even with a human behind the curtain, often reveals critical usability or conceptual flaws far earlier and more comprehensively than purely static representations, ultimately preventing costly reworks down the development pipeline.\u003c/p\u003e\u003ch3 id=\"additional-techniques-and-considerations\"\u003eAdditional Techniques And Considerations\u003c/h3\u003e\u003cp\u003eWhile the core principle of the WOZ method is straightforward, its true power lies in \u003cstrong\u003enuanced application\u003c/strong\u003e and \u003cstrong\u003ethoughtful execution\u003c/strong\u003e. Seasoned practitioners may leverage several advanced techniques to extract richer insights and address more complex research questions.\u003c/p\u003e\u003ch4 id=\"iterative-wizardry\"\u003eIterative Wizardry\u003c/h4\u003e\u003cp\u003eThe WOZ method isn’t necessarily a one-off endeavor. Employing it in \u003cstrong\u003eiterative cycles\u003c/strong\u003e can yield significant benefits. Initial rounds might focus on broad concept validation and identifying fundamental user reactions. Subsequent iterations can then refine the simulated functionality based on previous findings.\u003c/p\u003e\u003cp\u003eFor instance, after an initial study reveals user confusion with a particular interaction flow, the simulation can be adjusted, and a follow-up study can assess the impact of those changes. This iterative approach allows for a more agile and user-centered exploration of complex experiences.\u003c/p\u003e\u003ch4 id=\"managing-complexity\"\u003eManaging Complexity\u003c/h4\u003e\u003cp\u003eSimulating complex systems can be difficult for one wizard. Breaking complex interactions into smaller, manageable steps is crucial. Consider researching a multi-step onboarding process for a new software application. Instead of one person trying to simulate the entire flow, different aspects could be handled sequentially or even by multiple team members coordinating their responses.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eClear communication protocols\u003c/strong\u003e and \u003cstrong\u003ewell-defined responsibilities\u003c/strong\u003e are essential in such scenarios to maintain a seamless user experience.\u003c/p\u003e\u003ch4 id=\"measuring-success-beyond-observation\"\u003eMeasuring Success Beyond Observation\u003c/h4\u003e\u003cp\u003eWhile qualitative observation is a cornerstone of the WOZ method, defining \u003cstrong\u003eclear metrics\u003c/strong\u003e can add a layer of rigor to the findings. These metrics should match research goals. For example, if the goal is to assess the intuitiveness of a new navigation pattern, you might track the number of times users express confusion or the time it takes them to complete specific tasks.\u003c/p\u003e\u003cp\u003eCombining these quantitative measures with qualitative insights provides a more comprehensive understanding of the user experience.\u003c/p\u003e\u003ch4 id=\"integrating-with-other-methods\"\u003eIntegrating With Other Methods\u003c/h4\u003e\u003cp\u003eThe WOZ method isn’t an island. Its effectiveness can be amplified by integrating it with other research techniques. Preceding a WOZ study with user interviews can help establish a deeper understanding of user needs and mental models, informing the design of the simulated experience. Following a WOZ study, surveys can gather broader quantitative feedback on the concepts explored. For example, after observing users interact with a simulated AI-powered scheduling tool, a survey could gauge their overall trust and perceived usefulness of such a system.\u003c/p\u003e\u003ch4 id=\"when-not-to-use-woz\"\u003eWhen Not To Use WOZ\u003c/h4\u003e\u003cp\u003eWOZ, as with all methods, has limitations. A few examples of scenarios where other methods would likely yield more reliable findings would be:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eDetailed Usability Testing\u003c/strong\u003e\u003cbr/\u003eHumans acting as wizards cannot perfectly replicate the exact experience a user will encounter. WOZ is often best in the \u003cstrong\u003eearly stages\u003c/strong\u003e, where prototypes are rough drafts, and your team is looking for guidance on a solution that is up for consideration. Testing on a more detailed wireframe or prototype would be preferable to WOZ when you have entered the detailed design phase.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEvaluating extremely complex systems with unpredictable outputs\u003c/strong\u003e\u003cbr/\u003eIf the system’s responses are extremely varied, require sophisticated real-time calculations that exceed human capacity, or are intended to be genuinely unpredictable, a human may struggle to simulate them convincingly and consistently. This can lead to fatigue, errors, or improvisations that don’t reflect the intended system, thereby compromising the validity of the findings.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"training-and-preparedness\"\u003eTraining And Preparedness\u003c/h3\u003e\u003cp\u003eThe wizard’s skill is critical to the method’s success. Training the individual(s) who will be simulating the system is essential. This training should cover:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eUnderstanding the Research Goals\u003c/strong\u003e\u003cbr/\u003eThe wizard needs to grasp what the research aims to uncover.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eConsistency in Responses\u003c/strong\u003e\u003cbr/\u003eMaintaining consistent behavior throughout the sessions is vital for user believability.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAnticipating User Actions\u003c/strong\u003e\u003cbr/\u003eWhile improvisation is sometimes necessary, the wizard should be prepared for common user paths and potential deviations.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRemaining Unbiased\u003c/strong\u003e\u003cbr/\u003eThe wizard must avoid leading users or injecting their own opinions into the simulation.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHandling Unexpected Inputs\u003c/strong\u003e\u003cbr/\u003eClear protocols for dealing with unforeseen user actions should be established. This might involve having a set of pre-prepared fallback responses or a mechanism for quickly consulting with the facilitator.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAll of this suggests the need for practice in advance of running the actual session. We shouldn’t forget to have a number of dry runs in which we ask our colleagues or those who are willing to assist to not only participate but also think about possible responses that could stump the wizard or throw things off if the user might provide them during a live session.\u003c/p\u003e\u003cp\u003eI suggest having a believable prepared error statement ready to go for when a user throws a curveball. A simple response from the wizard of \u003cem\u003e“I’m sorry, I am unable to perform that task at this time”\u003c/em\u003e might be enough to move the session forward while also capturing a potentially unexpected situation your team can address in the final product design.\u003c/p\u003e\u003ch3 id=\"was-this-all-a-dream-the-art-of-the-debrief\"\u003eWas This All A Dream? The Art Of The Debrief\u003c/h3\u003e\u003cp\u003eThe debriefing session following the WOZ interaction is an additional opportunity to gather rich qualitative data. Beyond asking \u003cem\u003e“What did you think?”\u003c/em\u003e effective debriefing involves sharing the purpose of the study and the fact that the experience was simulated.\u003c/p\u003e\u003cp\u003eResearchers should then conduct \u003cstrong\u003epsychological probing\u003c/strong\u003e to understand the \u003cem\u003ereasons\u003c/em\u003e behind user behavior and reactions. Asking open-ended questions like \u003cem\u003e“Why did you try that?”\u003c/em\u003e or \u003cem\u003e“What were you expecting to happen when you clicked that button?”\u003c/em\u003e can reveal valuable insights into user mental models and expectations.\u003c/p\u003e\u003cp\u003eExploring moments of confusion, frustration, or delight in detail can uncover key areas for design improvement. Think about the potential information the Power Gloves’ development team could have uncovered if they’d asked participants what the experience of programming the glove and trying to remember what they’d programmed into which set of keys had been.\u003c/p\u003e\u003ch2 id=\"case-studies-real-world-applications\"\u003eCase Studies: Real-World Applications\u003c/h2\u003e\u003cp\u003eThe value of the WOZ method becomes apparent when examining its application in real-world research scenarios. Here is an in-depth review of one scenario and a quick summary of another study involving WOZ, where this technique proved invaluable in shaping user experiences.\u003c/p\u003e\u003ch3 id=\"unraveling-agentic-ai-understanding-user-mental-models\"\u003eUnraveling Agentic AI: Understanding User Mental Models\u003c/h3\u003e\u003cp\u003eA significant challenge in the realm of emerging technologies lies in user comprehension. This was particularly evident when our team began exploring the potential of Agentic AI for enterprise HR software.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.uipath.com/ai/agentic-ai\"\u003eAgentic AI\u003c/a\u003e refers to artificial intelligence systems that can autonomously pursue goals by making decisions, taking actions, and adapting to changing environments with minimal human intervention. \u003ca href=\"https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai\"\u003eUnlike generative AI\u003c/a\u003e that primarily responds to direct commands or generates content, Agentic AI is designed to understand user intent, independently plan and execute multi-step tasks, and learn from its interactions to improve performance over time. These systems often combine multiple AI models and can reason through complex problems. \u003ca href=\"https://www.krasamo.com/ai-ux/\"\u003eFor designers\u003c/a\u003e, this signifies a shift towards creating experiences where AI acts more like a proactive collaborator or assistant, capable of anticipating needs and taking the initiative to help users achieve their objectives rather than solely relying on explicit user instructions for every step.\u003c/p\u003e\u003cp\u003ePreliminary research, including surveys and initial interviews, suggested that many HR professionals, while intrigued by the concept of AI assistance, struggled to grasp the potential functionality and practical implications of truly \u003cem\u003eagentic\u003c/em\u003e systems — those capable of autonomous action and proactive decision-making. We saw they had no reference point for what agentic AI was, even after we attempted relevant analogies to current examples.\u003c/p\u003e\u003cp\u003eBuilding a fully functional agentic AI prototype at this exploratory stage was impractical. The underlying algorithms and integrations were complex and time-consuming to develop. Moreover, we risked building a solution based on potentially flawed assumptions about user needs and understanding. The WOZ method offered a solution.\u003c/p\u003e\u003ch4 id=\"setup\"\u003eSetup\u003c/h4\u003e\u003cp\u003eWe designed a scenario where HR employees interacted with what they believed was an intelligent AI assistant capable of autonomously handling certain tasks. The facilitator presented users with a web interface where they could request assistance with tasks like \u003cem\u003e“draft a personalized onboarding plan for a new marketing hire”\u003c/em\u003e or \u003cem\u003e“identify employees who might benefit from proactive well-being resources based on recent activity.”\u003c/em\u003e\u003c/p\u003e\u003cp\u003eBehind the scenes, a designer acted as the wizard. Based on the user’s request and the (simulated) available data, the designer would craft a response that mimicked the output of an agentic AI. For the onboarding plan, this involved assembling pre-written templates and personalizing them with details provided by the user. For the well-being resource identification, the wizard would select a plausible list of employees based on the general indicators discussed in the scenario.\u003c/p\u003e\u003cp\u003eCrucially, the facilitator encouraged users to \u003cstrong\u003einteract naturally\u003c/strong\u003e, asking \u003cstrong\u003efollow-up questions\u003c/strong\u003e and exploring the system’s perceived capabilities. For instance, a user might ask, \u003cem\u003e“Can the system also schedule the initial team introductions?”\u003c/em\u003e The wizard, guided by pre-defined rules and the overall research goals, would respond accordingly, perhaps with a \u003cem\u003e“Yes, I can automatically propose meeting times based on everyone’s calendars”\u003c/em\u003e (again, simulated).\u003c/p\u003e\u003cp\u003eAs recommended, we debriefed participants following each session. We began with transparency, explaining the simulation and that we had another live human posting the responses to the queries based on what the participant was saying. Open-ended questions explored initial reactions and envisioned use. Task-specific probing, like \u003cem\u003e“Why did you expect that?”\u003c/em\u003e revealed underlying assumptions. We specifically addressed trust and control (\u003cem\u003e“How much trust…? What level of control…?”\u003c/em\u003e). To understand mental models, we asked how users thought the “AI” worked. We also solicited improvement suggestions (\u003cem\u003e“What features…?”\u003c/em\u003e).\u003c/p\u003e\u003cp\u003eBy focusing on the “why” behind user actions and expectations, these debriefings provided rich qualitative data that directly informed subsequent design decisions, particularly around transparency, human oversight, and prioritizing specific, high-value use cases. We also had a research participant who understood agentic AI and could provide additional insight based on that understanding.\u003c/p\u003e\u003ch4 id=\"key-insights\"\u003eKey Insights\u003c/h4\u003e\u003cp\u003eThis WOZ study yielded several crucial insights into user mental models of agentic AI in an HR context:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eOverestimation of Capabilities\u003c/strong\u003e\u003cbr/\u003eSome users initially attributed near-magical abilities to the “AI”, expecting it to understand highly nuanced or ambiguous requests without explicit instruction. This highlighted the need for clear communication about the system’s actual scope and limitations.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eTrust and Control\u003c/strong\u003e\u003cbr/\u003eA significant theme revolved around trust and control. Users expressed both excitement about the potential time savings and anxiety about relinquishing control over important HR processes. This indicated a need for design solutions that offered transparency into the AI’s decision-making and allowed for human oversight.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eValue in Proactive Assistance\u003c/strong\u003e\u003cbr/\u003eUsers reacted positively to the AI proactively identifying potential issues (like burnout risk), but they emphasized the importance of the AI providing clear reasoning and allowing human HR professionals to review and approve any suggested actions.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNeed for Tangible Examples\u003c/strong\u003e\u003cbr/\u003eAbstract explanations of agentic AI were insufficient. Users gained a much clearer understanding through these simulated interactions with concrete tasks and outcomes.\u003c/li\u003e\u003c/ul\u003e\u003ch4 id=\"resulting-design-changes\"\u003eResulting Design Changes\u003c/h4\u003e\u003cp\u003eBased on these findings, we made several key design decisions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eEmphasis on Transparency\u003c/strong\u003e\u003cbr/\u003eThe user interface would need to clearly show the AI’s reasoning and the data it used to make decisions.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHuman Oversight and Review\u003c/strong\u003e\u003cbr/\u003eBuilt-in approval workflows would be essential for critical actions, ensuring HR professionals retain control.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eFocus on Specific, High-Value Use Cases\u003c/strong\u003e\u003cbr/\u003eInstead of trying to build a general-purpose agent, we prioritized specific use cases where agentic capabilities offered clear and demonstrable benefits.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eEducational Onboarding\u003c/strong\u003e\u003cbr/\u003eThe product onboarding would include clear, tangible examples of the AI’s capabilities in action.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"exploring-voice-interaction-for-in-car-systems\"\u003eExploring Voice Interaction for In-Car Systems\u003c/h3\u003e\u003cp\u003eIn another project, we used the WOZ method to evaluate user interaction with a voice interface for controlling in-car functions. Our research question focused on the naturalness and efficiency of voice commands for tasks like adjusting climate control, navigating to points of interest, and managing media playback.\u003c/p\u003e\u003cp\u003eWe set up a car cabin simulator with a microphone and speakers. The wizard, located in an adjacent room, listened to the user’s voice commands and triggered the corresponding actions (simulated through visual changes on a display and audio feedback). This allowed us to identify ambiguous commands, areas of user frustration with voice recognition (even though it was human-powered), and preferences for different phrasing and interaction styles before investing in complex speech recognition technology.\u003c/p\u003e\u003cp\u003eThese examples illustrate the versatility and power of the method in addressing a wide range of UX research questions across diverse product types and technological complexities. By simulating functionality, we can gain invaluable insights into user behavior and expectations early in the design process, leading to more user-centered and ultimately more successful products.\u003c/p\u003e\u003ch2 id=\"the-future-of-wizardry-adapting-to-emerging-technologies\"\u003eThe Future of Wizardry: Adapting To Emerging Technologies\u003c/h2\u003e\u003cp\u003eThe WOZ method, far from being a relic of simpler technological times, retains relevance as we navigate increasingly sophisticated and often opaque emerging technologies.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003ca aria-label=\"Share on Twitter\" href=\"https://twitter.com/share?text=%0aThe%20WOZ%20method%e2%80%99s%20core%20strength,%20the%20ability%20to%20simulate%20complex%20functionality%20with%20human%20ingenuity,%20makes%20it%20uniquely%20suited%20for%20exploring%20user%20interactions%20with%20systems%20that%20are%20still%20in%20their%20nascent%20stages.%0a\u0026amp;url=https://smashingmagazine.com%2f2025%2f07%2funmasking-magic-wizard-oz-method-ux-research%2f\"\u003eThe WOZ method’s core strength, the ability to simulate complex functionality with human ingenuity, makes it uniquely suited for exploring user interactions with systems that are still in their nascent stages.\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cstrong\u003eWOZ In The Age Of AI\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eConsider the burgeoning field of AI-powered experiences. Researching user interaction with generative AI, for instance, can be effectively done through WOZ. A wizard could curate and present AI-generated content (text, images, code) in response to user prompts, allowing researchers to assess user perceptions of quality, relevance, and trust without needing a fully trained and integrated AI model.\u003c/p\u003e\u003cp\u003eSimilarly, for personalized recommendation systems, a human could simulate the recommendations based on a user’s stated preferences and observed behavior, gathering valuable feedback on the perceived accuracy and helpfulness of such suggestions before algorithmic development.\u003c/p\u003e\u003cp\u003eEven autonomous systems, seemingly the antithesis of human control, can benefit from WOZ studies. By simulating the autonomous behavior in specific scenarios, researchers can explore user comfort levels, identify needs for explainability, and understand how users might want to interact with or override such systems.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eVirtual And Augmented Reality\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eImmersive environments like virtual and augmented reality present new frontiers for user experience research. WOZ can be particularly powerful here.\u003c/p\u003e\u003cp\u003eImagine testing a novel gesture-based interaction in VR. A researcher tracking the user’s hand movements could trigger corresponding virtual events, allowing for rapid iteration on the intuitiveness and comfort of these interactions without the complexities of fully programmed VR controls. Similarly, in AR, a wizard could remotely trigger the appearance and behavior of virtual objects overlaid onto the real world, gathering user feedback on their placement, relevance, and integration with the physical environment.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe Human Factor Remains Central\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDespite the rapid advancements in artificial intelligence and immersive technologies, the fundamental principles of human-centered design remain as relevant as ever. Technology should serve human needs and enhance human capabilities.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003ca aria-label=\"Share on Twitter\" href=\"https://twitter.com/share?text=%0aThe%20WOZ%20method%20inherently%20focuses%20on%20understanding%20user%20reactions%20and%20behaviors%20and%20acts%20as%20a%20crucial%20anchor%20in%20ensuring%20that%20technological%20progress%20aligns%20with%20human%20values%20and%20expectations.%0a\u0026amp;url=https://smashingmagazine.com%2f2025%2f07%2funmasking-magic-wizard-oz-method-ux-research%2f\"\u003eThe WOZ method inherently focuses on understanding user reactions and behaviors and acts as a crucial anchor in ensuring that technological progress aligns with human values and expectations.\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eIt allows us to inject the \u003cstrong\u003e“human factor”\u003c/strong\u003e into the design process of even the most advanced technologies. Doing this may help ensure these innovations are not only technically feasible but also truly usable, desirable, and beneficial.\u003c/p\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eThe WOZ method stands as a powerful and versatile tool in the UX researcher’s toolkit. The WOZ method’s ability to bypass limitations of early-stage development and directly elicit user feedback on conceptual experiences offers invaluable advantages. We’ve explored its core mechanics and covered ways of maximizing its impact. We’ve also examined its practical application through real-world case studies, including its crucial role in understanding user interaction with nascent technologies like agentic AI.\u003c/p\u003e\u003cp\u003eThe strategic implementation of the WOZ method provides a \u003cstrong\u003epotent means of de-risking product development\u003c/strong\u003e. By validating assumptions, uncovering unexpected user behaviors, and identifying potential usability challenges early on, teams can avoid costly rework and build products that truly resonate with their intended audience.\u003c/p\u003e\u003cp\u003eI encourage all UX practitioners, digital product managers, and those who collaborate with research teams to consider incorporating the WOZ method into their research toolkit. Experiment with its application in diverse scenarios, adapt its techniques to your specific needs and don’t be afraid to have fun with it. Scarecrow costume optional.\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://www.smashingmagazine.com/images/logo/logo--red.png\" alt=\"Smashing Editorial\" width=\"35\" height=\"46\" loading=\"lazy\" decoding=\"async\"/\u003e\n\u003cspan\u003e(yk)\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "29 min read",
  "publishedTime": "2025-07-10T10:00:00Z",
  "modifiedTime": "2025-07-10T10:00:00Z"
}
