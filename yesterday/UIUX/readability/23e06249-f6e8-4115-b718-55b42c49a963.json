{
  "id": "23e06249-f6e8-4115-b718-55b42c49a963",
  "title": "The end of design certainty",
  "link": "https://uxdesign.cc/the-end-of-design-certainty-65d3ed78336c?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Patrick Morgan",
  "published": "Thu, 20 Feb 2025 00:18:22 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "ux",
    "ui-design",
    "artificial-intelligence",
    "ux-design",
    "ai"
  ],
  "byline": "Patrick Morgan",
  "length": 9498,
  "excerpt": "Anthropic CEO Dario Amodei’s recent podcast with Lex Fridman caught my attention with an observation that keeps replaying in my mind. Even as his team works to understand and interpret AI models, he…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Why AI forces us to embrace emergence instead of clinging to control and understandingMade by Patrick Morgan with MidjourneyAnthropic CEO Dario Amodei’s recent podcast with Lex Fridman caught my attention with an observation that keeps replaying in my mind. Even as his team works to understand and interpret AI models, he acknowledged a surprising truth:There’s no reason why [AI models] should be designed for us to understand them, right? They’re designed to operate, they’re designed to work. Just like the human brain or human biochemistry. They’re not designed for a human to open up the hatch, look inside and understand them.This statement gave me pause. It challenges something deeply ingrained from the last generation of software design: the idea that we must fully understand how something works in order to consider it a valid solution. For years, we’ve doubled down on the belief that ‘data-driven’ design can eliminate uncertainty. The idea is that to make something effective, we first have to deconstruct it, grasp every nuance, and then carefully engineer it into existence.But there’s an irony here: as we’ve become more obsessed with data-driven certainty, we’ve invented systems that operate beyond our ability to fully analyze or predict. AI models demonstrate that sometimes the most powerful solutions emerge from patterns we can observe but not fully explain.AI flips the script. It wasn’t designed for human comprehension — it was designed to work. Understanding, if it comes at all, is often after the fact, something we piece together after we see that the system works. And that realization has forced me to rethink my assumptions about design and invention for this new era.Rethinking “solutions in search of problems”Traditional design wisdom views “solutions in search of problems” as a criticism. It runs counter to everything we’re taught about being problem-focused and user-centered. But as Anthropic’s head of product design Joel Lewenstein observed in a recent Dive Club podcast with Michael Riddering: “I’ve come to see solutions in search of a problem as not a dirty word at all… as long as you just lean into it and state your assumptions, saying ‘look, there’s the germ of something here and we’re going to explore it.’”This isn’t about abandoning user-centered design — it’s about recognizing that with AI, understanding often emerges through exploration. The technology’s capabilities are so novel that even those working on the frontier don’t know what’s possible until they see it.This shift isn’t limited to Anthropic, it’s happening across leading AI companies. Inspired by a recent conversation with Perplexity’s head of design Henry Modisett, Linear CEO Karri Saarinen commented, “At Perplexity they start projects by exploring LLM capabilities with very simple prototypes, even with just a command-line implementation. Only once there’s proof that the idea can work consistently, and that they can bend it to do what they want, do they start designing the experience. Normally, you start with design to explore possibilities, and the tech follows. But in this domain, or this new era of software, LLM/AI is the tool for exploration, and design comes after.”Invention comes before understandingHistorically, software design has followed a structured, step-by-step approach — one where every phase is carefully planned to produce a predictable outcome.Understand the problem deeply.Define a precise solution.Craft an experience that is intentional and predictable.Ship a finished product that behaves exactly as expected.But this isn’t how many of the most transformative inventions have come about. If you look at breakthroughs across history, the process is always messy and often reversed:Have an intent — an idea of what you’re trying to achieve.Experiment, iterate, and push forward without much clarity.Uncover an unexpected breakthrough — it works, but not how you thought.You study the breakthrough, refine it, and later figure out why it works.This pattern of discovery before understanding runs deep. Alexander Fleming didn’t intend to discover penicillin — he noticed something unexpected in his experiment and followed the thread. The steam engine was a product of tinkering; Newcomen and Watt refined working models decades before scientists understood the laws of thermodynamics that made them possible. Early radio pioneers transmitted signals across great distances without fully understanding the physics of electromagnetic waves. And the use of anesthesia in surgery revolutionized medicine long before scientists figured out its precise mechanism of action.AI amplifies this historical patternAI doesn’t just follow this pattern — it speeds it up.Traditional software is deterministic; AI is probabilistic. It doesn’t follow rigid rules — it generates outputs based on patterns and likelihoods we can observe but not fully predict. The technology itself resists complete upfront understanding.The challenge is that many designers, engineers, and product teams are still trying to apply legacy design methodologies to a technology that simply doesn’t work that way. AI doesn’t respect our craving for certainty. It doesn’t wait for us to fully understand it before showing results. And the more we try to force it into rigid, explainable, deterministic workflows, the more we suffocate its potential.Why design struggles to let go — but why it shouldThis has forced me to confront my own biases. I’ve spent a decade designing software, and the instinct to make things fully understood before they exist is deeply ingrained. It’s particularly rooted in the culture of UX design — this idea that we can’t build effectively unless we first have a full grasp of what we’re making.AI challenges this instinct and asks us to revise our beliefs. It requires us to lean into the ambiguity, to design before we fully understand, and to shape the raw materials of generative outputs as useful options emerge. As Lewenstein notes, “You can talk about AI and you can write about AI, but there’s something just so powerful about seeing a working prototype and feeling the dynamic, stochastic nature of it… seeing a website get rendered in real time, iterating on it and seeing it change in front of you — it’s just magical.” Understanding comes through doing, through making something tangible that we can respond to and refine.Confronting this tension reminds me of the Daoist concept of Wu Wei, often translated as “effortless action” or “without force.” It’s the idea that instead of rigidly trying to control every element of a process, we should move with the natural flow of things — guiding and shaping, rather than imposing. Wu Wei isn’t passivity; it’s about working with forces rather than against them. In AI design, this means crafting interactions where users guide and shape outcomes, rather than micromanaging every detail. It’s like how a surfer harnesses a wave’s energy rather than trying to control the ocean.Design must guide, not controlSo what does it look like to design without force? Instead of suppressing the unknown, we embrace it as part of the process.We create affordances, not strict controls: building interfaces that guide behavior rather than dictate it. Instead of trying to expose every parameter, we need interfaces that let users navigate AI while embracing its variability.We prioritize steerability over explainability: giving users meaningful, intuitive ways to shape AI’s behavior without needing to understand its internals. The goal isn’t to make the black box transparent, but to make it controllable at the right level of abstraction.We embrace emergence: designing systems that adapt and evolve, rather than ones that are locked into rigid, pre-defined behaviors. This means creating spaces where unexpected capabilities can surface and be refined through use.This doesn’t mean that understanding is unimportant. But it does mean we should be wary of overprioritizing upfront understanding at the cost of progress. AI is teaching us that function can — and often must — precede full comprehension. And as designers, builders, and creative thinkers, we need to get more comfortable working in that space.If this makes you uncomfortable–good. It means you’re seeing the shift. But if it excites you–well, my friend, you’re right where you need to be.What might become possible if you embrace emergence instead of clinging to control?Embracing the unknownThis shift is much bigger than a throwaway line on a podcast. It’s a reframe for how we approach design and invention in this new age. For decades, the software business has trained us to believe that predictability, explainability, and control are the highest ideals. But many of the most powerful things in the world — our brains, ecosystems, markets, and now AI models — don’t operate that way.If you’re designing with AI, start experimenting before you demand clarity. Try tinkering with the raw materials first, then layering on design afterward — like Perplexity does. Embrace the unknown as a creative tool.As we build in this new era, we need to ask ourselves: what happens when we stop forcing things to fit our desire for immediate understanding? What becomes possible when we embrace discovery as a design principle? And how do we shape these new, emergent systems in ways that are powerful, safe, and genuinely creative?We may not fully understand AI yet. But if history tells us anything, that might be exactly where we need to be.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*RIDmz3TgxhaNmSs8CBSMkQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"ace5\"\u003eWhy AI forces us to embrace emergence instead of clinging to control and understanding\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@itspatmorgan?source=post_page---byline--65d3ed78336c---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Patrick Morgan\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*ZCSPZ40wwJSGiREsYF2qaA.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--65d3ed78336c---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cfigure\u003e\u003cfigcaption\u003eMade by \u003ca href=\"https://patrickmorgan.org/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePatrick Morgan\u003c/a\u003e with \u003ca href=\"https://www.midjourney.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMidjourney\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"5e0a\"\u003eAnthropic CEO Dario Amodei’s recent \u003ca href=\"https://youtu.be/ugvHCXCOmm4?si=LlUHalCGGHfJLZc7\u0026amp;t=1405\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003epodcast with Lex Fridman\u003c/a\u003e caught my attention with an observation that keeps replaying in my mind. Even as his team works to understand and interpret AI models, he acknowledged a surprising truth:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"10d0\"\u003eThere’s no reason why [AI models] should be designed for us to understand them, right? They’re designed to operate, they’re designed to work. Just like the human brain or human biochemistry. They’re not designed for a human to open up the hatch, look inside and understand them.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"34d4\"\u003eThis statement gave me pause. It challenges something deeply ingrained from the last generation of software design: the idea that \u003cem\u003ewe must fully understand how something works in order to consider it a valid solution\u003c/em\u003e. For years, we’ve doubled down on the belief that ‘data-driven’ design can eliminate uncertainty. The idea is that to make something effective, we first have to deconstruct it, grasp every nuance, and then carefully engineer it into existence.\u003c/p\u003e\u003cp id=\"163e\"\u003eBut there’s an irony here: as we’ve become more obsessed with data-driven certainty, we’ve invented systems that operate beyond our ability to fully analyze or predict. AI models demonstrate that sometimes the most powerful solutions emerge from patterns we can observe but not fully explain.\u003c/p\u003e\u003cp id=\"256b\"\u003eAI flips the script. It wasn’t designed for human comprehension — it was designed to work. Understanding, if it comes at all, is often after the fact, something we piece together after we see that the system works. And that realization has forced me to rethink my assumptions about design and invention for this new era.\u003c/p\u003e\u003ch2 id=\"dd58\"\u003eRethinking “solutions in search of problems”\u003c/h2\u003e\u003cp id=\"c5cd\"\u003eTraditional design wisdom views “solutions in search of problems” as a criticism. It runs counter to everything we’re taught about being problem-focused and user-centered. But as Anthropic’s head of product design \u003ca href=\"https://www.linkedin.com/in/joel-lewenstein/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJoel Lewenstein\u003c/a\u003e observed in a recent \u003ca href=\"https://www.dive.club/deep-dives/joel-lewenstein\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDive Club podcast\u003c/a\u003e with \u003ca href=\"https://www.linkedin.com/in/michaelriddering/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMichael Riddering\u003c/a\u003e: “\u003cem\u003eI’ve come to see solutions in search of a problem as not a dirty word at all… as long as you just lean into it and state your assumptions, saying ‘look, there’s the germ of something here and we’re going to explore it.\u003c/em\u003e’”\u003c/p\u003e\u003cp id=\"8de4\"\u003eThis isn’t about abandoning user-centered design — it’s about recognizing that with AI, \u003cstrong\u003eunderstanding often emerges through exploration\u003c/strong\u003e. The technology’s capabilities are so novel that even those working on the frontier don’t know what’s possible until they see it.\u003c/p\u003e\u003cp id=\"0cca\"\u003eThis shift isn’t limited to \u003ca href=\"https://www.anthropic.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAnthropic\u003c/a\u003e, it’s happening across leading AI companies. Inspired by a recent conversation with \u003ca href=\"https://www.perplexity.ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePerplexity\u003c/a\u003e’s head of design \u003ca href=\"https://www.linkedin.com/in/henrymodisett/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHenry Modisett\u003c/a\u003e, \u003ca href=\"https://x.com/karrisaarinen/status/1889734737042002393\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLinear CEO Karri Saarinen commented\u003c/a\u003e, “\u003cem\u003eAt Perplexity they start projects by exploring LLM capabilities with very simple prototypes, even with just a command-line implementation. Only once there’s proof that the idea can work consistently, and that they can bend it to do what they want, do they start designing the experience. Normally, you start with design to explore possibilities, and the tech follows. But in this domain, or this new era of software, LLM/AI is the tool for exploration, and design comes after.\u003c/em\u003e”\u003c/p\u003e\u003ch2 id=\"17e5\"\u003eInvention comes before understanding\u003c/h2\u003e\u003cp id=\"6cfe\"\u003eHistorically, software design has followed a structured, step-by-step approach — one where every phase is carefully planned to produce a predictable outcome.\u003c/p\u003e\u003col\u003e\u003cli id=\"c8bc\"\u003eUnderstand the problem deeply.\u003c/li\u003e\u003cli id=\"f5e8\"\u003eDefine a precise solution.\u003c/li\u003e\u003cli id=\"8159\"\u003eCraft an experience that is intentional and predictable.\u003c/li\u003e\u003cli id=\"52f6\"\u003eShip a finished product that behaves exactly as expected.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"d526\"\u003eBut this isn’t how many of the most transformative inventions have come about. If you look at breakthroughs across history, the process is always messy and often \u003cem\u003ereversed\u003c/em\u003e:\u003c/p\u003e\u003col\u003e\u003cli id=\"5bf2\"\u003eHave an intent — an idea of what you’re trying to achieve.\u003c/li\u003e\u003cli id=\"f35e\"\u003eExperiment, iterate, and push forward without much clarity.\u003c/li\u003e\u003cli id=\"22ab\"\u003eUncover an unexpected breakthrough — it works, but not how you thought.\u003c/li\u003e\u003cli id=\"60bb\"\u003eYou study the breakthrough, refine it, and later figure out why it works.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"7700\"\u003eThis pattern of discovery before understanding runs deep. Alexander Fleming didn’t intend to \u003ca href=\"https://www.prayoga.org.in/post/serendipity-and-the-discovery-of-penicillin\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ediscover penicillin\u003c/a\u003e — he noticed something unexpected in his experiment and followed the thread. The \u003ca href=\"https://study.com/learn/lesson/steam-engine-history-impact.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esteam engine\u003c/a\u003e was a product of tinkering; Newcomen and Watt refined working models decades before scientists understood the laws of thermodynamics that made them possible. Early \u003ca href=\"https://en.wikipedia.org/wiki/History_of_radio\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eradio pioneers\u003c/a\u003e transmitted signals across great distances without fully understanding the physics of electromagnetic waves. And the use of \u003ca href=\"https://www.umhs-sk.org/blog/medical-milestones-discovery-anesthesia-timeline\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eanesthesia in surgery\u003c/a\u003e revolutionized medicine long before scientists figured out its precise mechanism of action.\u003c/p\u003e\u003ch2 id=\"7aa1\"\u003eAI amplifies this historical pattern\u003c/h2\u003e\u003cp id=\"3345\"\u003eAI doesn’t just follow this pattern — it speeds it up.\u003c/p\u003e\u003cp id=\"aa54\"\u003eTraditional software is \u003cstrong\u003edeterministic\u003c/strong\u003e; AI is \u003cstrong\u003eprobabilistic\u003c/strong\u003e. It doesn’t follow rigid rules — it generates outputs based on patterns and likelihoods we can observe but not fully predict. The technology itself resists complete upfront understanding.\u003c/p\u003e\u003cp id=\"e690\"\u003eThe challenge is that many designers, engineers, and product teams are still trying to apply legacy design methodologies to a technology that simply doesn’t work that way. AI doesn’t respect our craving for certainty. It doesn’t wait for us to fully understand it before showing results. And the more we try to force it into rigid, explainable, deterministic workflows, the more we suffocate its potential.\u003c/p\u003e\u003ch2 id=\"707e\"\u003eWhy design struggles to let go — but why it should\u003c/h2\u003e\u003cp id=\"b9d9\"\u003eThis has forced me to confront my own biases. I’ve spent a decade designing software, and the instinct to make things fully understood before they exist is deeply ingrained. It’s particularly rooted in the culture of UX design — this idea that we can’t build effectively unless we first have a full grasp of what we’re making.\u003c/p\u003e\u003cp id=\"b711\"\u003eAI challenges this instinct and asks us to revise our beliefs. It requires us to lean into the ambiguity, to design before we fully understand, and to shape the raw materials of generative outputs as useful options emerge. As \u003ca href=\"https://youtu.be/GgP9LEAY1PA?si=FttIvp2_iHAhpjsh\u0026amp;t=1612\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLewenstein notes\u003c/a\u003e, “\u003cem\u003eYou can talk about AI and you can write about AI, but there’s something just so powerful about seeing a working prototype and feeling the dynamic, stochastic nature of it… seeing a website get rendered in real time, iterating on it and seeing it change in front of you — it’s just magical.\u003c/em\u003e” Understanding comes through doing, through making something tangible that we can respond to and refine.\u003c/p\u003e\u003cp id=\"ddfa\"\u003eConfronting this tension reminds me of the Daoist concept of \u003ca href=\"https://www.merriam-webster.com/dictionary/wu%20wei\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWu Wei\u003c/a\u003e, often translated as “effortless action” or “without force.” It’s the idea that instead of rigidly trying to control every element of a process, we should move with the natural flow of things — guiding and shaping, rather than imposing. Wu Wei isn’t passivity; it’s about working with forces rather than against them. In AI design, this means crafting interactions where users guide and shape outcomes, rather than micromanaging every detail. It’s like how a surfer harnesses a wave’s energy rather than trying to control the ocean.\u003c/p\u003e\u003ch2 id=\"bd24\"\u003eDesign must guide, not control\u003c/h2\u003e\u003cp id=\"a4e3\"\u003eSo what does it look like to \u003cem\u003edesign without force\u003c/em\u003e? Instead of suppressing the unknown, we embrace it as part of the process.\u003c/p\u003e\u003cul\u003e\u003cli id=\"77d4\"\u003e\u003cstrong\u003eWe\u003c/strong\u003e \u003cstrong\u003ecreate affordances, not strict controls\u003c/strong\u003e: building interfaces that guide behavior rather than dictate it. Instead of trying to expose every parameter, we need interfaces that let users navigate AI while embracing its variability.\u003c/li\u003e\u003cli id=\"8b41\"\u003e\u003cstrong\u003eWe\u003c/strong\u003e \u003cstrong\u003eprioritize steerability over explainability\u003c/strong\u003e: giving users meaningful, intuitive ways to shape AI’s behavior without needing to understand its internals. The goal isn’t to make the black box transparent, but to make it controllable at the right level of abstraction.\u003c/li\u003e\u003cli id=\"e84b\"\u003e\u003cstrong\u003eWe\u003c/strong\u003e \u003cstrong\u003eembrace emergence\u003c/strong\u003e: designing systems that adapt and evolve, rather than ones that are locked into rigid, pre-defined behaviors. This means creating spaces where unexpected capabilities can surface and be refined through use.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"3818\"\u003eThis doesn’t mean that understanding is unimportant. But it does mean we should be wary of \u003cem\u003eoverprioritizing\u003c/em\u003e upfront understanding at the cost of progress. AI is teaching us that function can — and often must — precede full comprehension. And as designers, builders, and creative thinkers, we need to get more comfortable working in that space.\u003c/p\u003e\u003cp id=\"944e\"\u003eIf this makes you uncomfortable–good. It means you’re seeing the shift. But if it excites you–well, my friend, you’re right where you need to be.\u003c/p\u003e\u003cp id=\"6aec\"\u003e\u003cem\u003eWhat might become possible if you embrace emergence instead of clinging to control?\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"3f8b\"\u003eEmbracing the unknown\u003c/h2\u003e\u003cp id=\"db14\"\u003eThis shift is much bigger than a throwaway line on a podcast. It’s a reframe for how we approach design and invention in this new age\u003cstrong\u003e.\u003c/strong\u003e For decades, the software business has trained us to believe that predictability, explainability, and control are the highest ideals. But many of the most powerful things in the world — our brains, ecosystems, markets, and now AI models — don’t operate that way.\u003c/p\u003e\u003cp id=\"83c4\"\u003eIf you’re designing with AI, start experimenting before you demand clarity. Try tinkering with the raw materials first, then layering on design afterward — like Perplexity does. Embrace the unknown as a creative tool.\u003c/p\u003e\u003cp id=\"618f\"\u003eAs we build in this new era, we need to ask ourselves: what happens when we stop forcing things to fit our desire for immediate understanding? What becomes possible when we embrace discovery as a design principle? And how do we shape these new, emergent systems in ways that are powerful, safe, and genuinely creative?\u003c/p\u003e\u003cp id=\"ff20\"\u003eWe may not fully understand AI yet. But if history tells us anything, that might be exactly where we need to be.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-02-20T00:18:22.582Z",
  "modifiedTime": null
}
