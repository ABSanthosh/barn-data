{
  "id": "24298b82-2d0f-44b9-a820-34c881d504ba",
  "title": "Design Patterns For AI Interfaces",
  "link": "https://smashingmagazine.com/2025/07/design-patterns-ai-interfaces/",
  "description": "Designing a new AI feature? Where do you even begin? From first steps to design flows and interactions, here‚Äôs a simple, systematic approach to building AI experiences that stick.",
  "author": "Vitaly Friedman",
  "published": "Mon, 14 Jul 2025 15:00:00 GMT",
  "source": "https://www.smashingmagazine.com/feed",
  "categories": null,
  "byline": "About The Author",
  "length": 8713,
  "excerpt": "Designing a new AI feature? Where do you even begin? From first steps to design flows and interactions, here‚Äôs a simple, systematic approach to building AI experiences that stick.",
  "siteName": "Smashing Magazine",
  "favicon": "https://smashingmagazine.com/images/favicon/apple-touch-icon.png",
  "text": "7 min readAI, User Interface, Design PatternsDesigning a new AI feature? Where do you even begin? From first steps to design flows and interactions, here‚Äôs a simple, systematic approach to building AI experiences that stick. More design patterns in our Smart Interface Design Patterns, a friendly video course on UX and design patterns by Vitaly ‚Äî from complex data tables and nested filters to FAQs and error messages.So you need to design a new AI feature for your product. How would you start? How do you design flows and interactions? And how do you ensure that that new feature doesn‚Äôt get abandoned by users after a few runs?In this article, I‚Äôd love to share a very simple but systematic approach to how I think about designing AI experiences. Hopefully, it will help you get a bit more clarity about how to get started.This article is part of our ongoing series on UX. You can find more details on design patterns and UX strategy in Smart Interface Design Patterns¬†üç£ ‚Äî with live UX training coming up soon. Jump to table of contents.The Receding Role of AI ChatOne of the key recent shifts is a slow move away from traditional ‚Äúchat-alike‚Äù AI interfaces. As Luke Wroblewski wrote, when agents can use multiple tools, call other agents and run in the background, users orchestrate AI work more ‚Äî there‚Äôs a lot less chatting back and forth.Messaging UI slowly starts feeling dated, and chat UI fades into background. By Luke Wroblewski. (Large preview)In fact, chatbots are rarely a great experience paradigm ‚Äî mostly because the burden of articulating intent efficiently lies on the user. But in practice, it‚Äôs remarkably difficult to do well and very time-consuming.Chat doesn‚Äôt go away, of course, but it‚Äôs being complemented with task-oriented UIs ‚Äî temperature controls, knobs, sliders, buttons, semantic spreadsheets, infinite canvases ‚Äî with AI providing predefined options, presets, and templates.Agentic AI design patterns, with more task-oriented UIs, rather than chat. By Luke Wroblewski. (Large preview)There, AI emphasizes the work, the plan, the tasks ‚Äî the outcome, instead of the chat input. The results are experiences that truly amplify value for users by sprinkling a bit of AI in places where it delivers real value to real users.To design better AI experiences, we need to study 5 key areas that we need to shape.Input UX: Expressing IntentConversational AI is a very slow way of helping users express and articulate their intent. Usability tests show that users often get lost in editing, reviewing, typing, and re-typing. It‚Äôs painfully slow, often taking 30-60 seconds for input.As it turns out, people have a hard time expressing their intent well. In fact, instead of writing prompts manually, it‚Äôs a good idea to ask AI to write a prompt to feed itself.Flora AI allows you to modify images and videos via nodes. (Large preview)With Flora AI, users can still write prompts, but they visualize their intent with nodes by connecting various sources visually. Instead of elaborately explaining to AI how we need the pipeline to work, we attach nodes and commands on a canvas.With Krea.ai, users can move abstract shapes (on the left) to explain their goal to AI and study the outcome (on the right). (Large preview)With input for AI, being precise is slow and challenging. Instead, we can abstract away the object we want to manipulate, and give AI precise input by moving that abstracted object on a canvas. That‚Äôs what Krea.ai does.In summary, we can minimize the burden of typing prompts manually ‚Äî with AI-generated pre-prompts, prompt extensions, query builders, and also voice input.Output UX: Displaying OutcomesAI output doesn‚Äôt have to be merely plain text or a list of bullet points. It must be helpful to drive people to insights, faster. For example, we could visualize output by creating additional explanations based on the user‚Äôs goal and motivations.Visualizing outcome through style lenses. By Amelia Wattenberger. (Large preview)For example, Amelia Wattenberger visualized AI output for her text editor PenPal by adding style lenses to explore the content from. The output could be visualized in sentence lengths and scales Sad ‚Äî Happy, Concrete ‚Äî Abstract, and so on.Aino.ai, an AI GIS Analyst for urban planning. (Large preview)The outcome could also be visualized on a map, which, of course, is expected for an AI GIS analyst. Also, users can access individual data layers, turn them on and off, and hence explore the data on the map.We can also use forced ranking and prioritizations to suggest best options and avoid choice paralysis ‚Äî even if a user asks for top 10 recommendations. We can think about ways to present results as a data table, or a dashboard, or a visualization on a map, or as a structured JSON file, for example.Refinement UX: Tweaking OutputUsers often need to cherry-pick some bits from the AI output and bring them together in a new place ‚Äî and often they need to expand on one section, synthesize bits from another section, or just refine the outcome to meet their needs.Adobe Firefly suggests options and sliders to adjust the outcome. (Large preview)Refinement is usually the most painful part of the experience, with many fine details being left to users to explain elaborately. But we can use good old-fashioned UI controls like knobs, sliders, buttons, and so on to improve that experience, similar to how Adobe Firefly does it (image above).Presets living on the side in Elicit, an example by Maggie Appleton. (Large preview)We can also use presets, bookmarks, and allow users to highlight specific parts of the outcome that they‚Äôd like to change ‚Äî with contextual prompts acting on highlighted parts of the output, rather than global prompts.Tweaking specific parts of the outcome, on Grammarly. (Large preview)AI Actions: Tasks To CompleteWith AI agents, we can now also allow users to initiate tasks that AI can perform on their behalf, such as scheduling events, planning, and deep research. We could also ask to sort results or filter them in a specific way.Suggesting actions on Elicit, an example by Maggie Appleton. (Large preview)But we can also add features to help users use AI output better ‚Äî e.g., by visualizing it, making it shareable, allowing transformations between formats, or also posting to Slack, Jira, and so on.AI Integration: Where Work HappensMany AI interactions are locked within a specific product, but good AI experiences happen where the actual work happens. It would be quite unusual to expect a dedicated section for Autocomplete, for example, but we do so for AI features.(Large preview)DoveTail AI integrates in plenty of platforms, from Jira and Notion to Slack and Teams, where the actual work happens. (Large preview)The actual boost in productivity comes when users rely on AI as a co-pilot or little helper in the tools they use daily for work. It‚Äôs seamless integrations into Slack, Teams, Jira, GitHub, and so on ‚Äî the tools that people use anyway. Dia Browser and Dovetail are great examples of it in action.Wrapping UpAlong these five areas, we can explore ways to minimize the cost of interaction with a textbox, and allow users to interact with the points of interest directly, by tapping, clicking, selecting, highlighting, and bookmarking.Many products are obsessed with being AI-first. But you might be way better off by being AI-second instead. The difference is that we focus on user needs and sprinkle a bit of AI across customer journeys where it actually adds value.And AI products don‚Äôt have to be AI-only. There is a lot of value in mapping into the mental models that people have adopted over the years, and enhance them with AI, similar to how we do it with browsers‚Äô autofill, rather than leaving users in front of a frightening and omnipresent text box.Useful ResourcesWhere Should AI Sit In Your UI?, by Sharang SharmaShape of AI: Design Patterns, by Emily CampbellAI UX Patterns, by Luke BennisDesign Patterns For Trust With AI, via Sarah GoldAI Guidebook Design Patterns, by GoogleUsable Chat Interfaces to AI Models, by Luke WroblewskiThe Receding Role of AI Chat, by Luke WroblewskiAgent Management Interface Patterns, by Luke WroblewskiDesigning for AI Engineers, by Eve WeinbergMeet ‚ÄúSmart Interface Design Patterns‚ÄùYou can find more details on design patterns and UX in Smart Interface Design Patterns, our 15h-video course with 100s of practical examples from real-life projects ‚Äî with a live UX training later this year. Everything from mega-dropdowns to complex enterprise tables ‚Äî with 5 new segments added every year. Jump to a free preview. Use code BIRDIE to save 15% off.Meet Smart Interface Design Patterns, our video course on interface design \u0026 UX. (yk)",
  "image": "https://files.smashing.media/articles/design-patterns-ai-interfaces/design-patterns-ai-interfaces.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article__content\"\u003e\u003cul\u003e\u003cli\u003e7 min read\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://smashingmagazine.com/category/ai\"\u003eAI\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/user-interface\"\u003eUser Interface\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/design-patterns\"\u003eDesign Patterns\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003csection aria-label=\"Quick summary\"\u003eDesigning a new AI feature? Where do you even begin? From first steps to design flows and interactions, here‚Äôs a simple, systematic approach to building AI experiences that stick. More design patterns in our \u003ca href=\"https://smart-interface-design-patterns.com/\"\u003eSmart Interface Design Patterns\u003c/a\u003e, a \u003cstrong\u003efriendly video course on UX\u003c/strong\u003e and design patterns by Vitaly ‚Äî from complex data tables and nested filters to FAQs and error messages.\u003c/section\u003e\u003c/p\u003e\u003cp\u003eSo you need to \u003cstrong\u003edesign a new AI feature\u003c/strong\u003e for your product. How would you start? How do you design flows and interactions? And how do you ensure that that new feature doesn‚Äôt get abandoned by users after a few runs?\u003c/p\u003e\u003cp\u003eIn this article, I‚Äôd love to share \u003cstrong\u003ea very simple but systematic approach\u003c/strong\u003e to how I think about designing AI experiences. Hopefully, it will help you get a bit more clarity about how to get started.\u003c/p\u003e\u003cp\u003eThis article is \u003cstrong\u003epart of our ongoing series\u003c/strong\u003e on \u003ca href=\"https://smashingmagazine.com/category/ux\"\u003eUX\u003c/a\u003e. You can find more details on \u003cstrong\u003edesign patterns and UX strategy\u003c/strong\u003e in \u003ca href=\"https://smart-interface-design-patterns.com/\"\u003eSmart Interface Design Patterns\u003c/a\u003e¬†üç£ ‚Äî with live UX training coming up soon. \u003ca href=\"https://smart-interface-design-patterns.com\"\u003eJump to table of contents\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"the-receding-role-of-ai-chat\"\u003eThe Receding Role of AI Chat\u003c/h2\u003e\u003cp\u003eOne of the key recent shifts is a slow move away from traditional \u003cstrong\u003e‚Äúchat-alike‚Äù AI interfaces\u003c/strong\u003e. As Luke Wroblewski \u003ca href=\"https://lukew.com/ff/entry.asp?2105\"\u003ewrote\u003c/a\u003e, when agents can use multiple tools, call other agents and run in the background, users \u003cem\u003eorchestrate\u003c/em\u003e AI work more ‚Äî there‚Äôs a lot less chatting back and forth.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://lukew.com/ff/entry.asp?2105\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"610\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg\" sizes=\"100vw\" alt=\"AI Experience Paradigm by Luke Wroblewski\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eMessaging UI \u003ca href=\"https://lukew.com/ff/entry.asp?2105\"\u003eslowly starts feeling dated\u003c/a\u003e, and chat UI fades into background. By Luke Wroblewski. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/1-ai-experience-paradigm.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIn fact, chatbots are \u003cstrong\u003erarely a great experience paradigm\u003c/strong\u003e ‚Äî mostly because the burden of articulating intent efficiently lies on the user. But in practice, it‚Äôs remarkably difficult to do well and very time-consuming.\u003c/p\u003e\u003cp\u003eChat doesn‚Äôt go away, of course, but it‚Äôs being complemented with \u003cstrong\u003etask-oriented UIs\u003c/strong\u003e ‚Äî temperature controls, knobs, sliders, buttons, semantic spreadsheets, infinite canvases ‚Äî with AI providing predefined options, presets, and templates.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://lukew.com/ff/entry.asp?2106\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"707\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg\" sizes=\"100vw\" alt=\"AI Experience Paradigm by Luke Wroblewski\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003ca href=\"https://lukew.com/ff/entry.asp?2106\"\u003eAgentic AI design patterns\u003c/a\u003e, with more task-oriented UIs, rather than chat. By Luke Wroblewski. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/2-agentic-ai-design-patterns.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThere, AI emphasizes the work, the plan, the tasks ‚Äî the outcome, instead of the chat input. The results are experiences that truly \u003cstrong\u003eamplify value for users\u003c/strong\u003e by sprinkling a bit of AI in places where it delivers real value to real users.\u003c/p\u003e\u003cp\u003eTo design better AI experiences, we need to study \u003cstrong\u003e5 key areas\u003c/strong\u003e that we need to shape.\u003c/p\u003e\u003ch2 id=\"input-ux-expressing-intent\"\u003eInput UX: Expressing Intent\u003c/h2\u003e\u003cp\u003e\u003cstrong\u003eConversational AI\u003c/strong\u003e is a \u003cstrong\u003every slow\u003c/strong\u003e way of helping users express and articulate their intent. Usability tests \u003ca href=\"https://www.nngroup.com/articles/accordion-editing-apple-picking/\"\u003eshow\u003c/a\u003e that users often get lost in editing, reviewing, typing, and re-typing. It‚Äôs painfully slow, often taking 30-60 seconds for input.\u003c/p\u003e\u003cp\u003eAs it turns out, people have a hard time expressing their intent well. In fact, instead of writing prompts manually, it‚Äôs a good idea to \u003ca href=\"https://spectrum.ieee.org/prompt-engineering-is-dead\"\u003eask AI to write a prompt\u003c/a\u003e to feed itself.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.florafauna.ai/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"439\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg\" sizes=\"100vw\" alt=\"Illustration: How users can express their intent in AI interfaces.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003ca href=\"https://www.florafauna.ai/\"\u003eFlora AI\u003c/a\u003e allows you to modify images and videos via nodes. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/3-flora-ai.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWith \u003ca href=\"https://www.florafauna.ai/\"\u003eFlora AI\u003c/a\u003e, users can still write prompts, but they \u003cstrong\u003evisualize their intent\u003c/strong\u003e with nodes by connecting various sources visually. Instead of elaborately explaining to AI how we need the pipeline to work, we attach nodes and commands on a canvas.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.krea.ai/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"380\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eWith \u003ca href=\"https://www.krea.ai/\"\u003eKrea.ai\u003c/a\u003e, users can move abstract shapes (on the left) to explain their goal to AI and study the outcome (on the right). (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/4-illustration-output-ux.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWith input for AI, being precise is slow and challenging. Instead, we can \u003cstrong\u003eabstract away\u003c/strong\u003e the object we want to manipulate, and give AI precise input by moving that abstracted object on a canvas. That‚Äôs what \u003ca href=\"https://www.krea.ai/\"\u003eKrea.ai\u003c/a\u003e does.\u003c/p\u003e\u003cp\u003eIn summary, we can \u003cstrong\u003eminimize the burden of typing\u003c/strong\u003e prompts manually ‚Äî with AI-generated pre-prompts, prompt extensions, query builders, and also voice input.\u003c/p\u003e\u003ch2 id=\"output-ux-displaying-outcomes\"\u003eOutput UX: Displaying Outcomes\u003c/h2\u003e\u003cp\u003eAI output doesn‚Äôt have to be merely plain text or a list of bullet points. It must be \u003cstrong\u003ehelpful to drive people to insights\u003c/strong\u003e, faster. For example, we could visualize output by creating additional explanations based on the user‚Äôs goal and motivations.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"516\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eVisualizing outcome through style lenses. By Amelia Wattenberger. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/5-illustration-output-ux.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eFor example, Amelia Wattenberger \u003ca href=\"https://wattenberger.com/thoughts/boo-chatbots\"\u003evisualized AI output\u003c/a\u003e for her text editor PenPal by adding \u003cstrong\u003estyle lenses\u003c/strong\u003e to explore the content from. The output could be visualized in sentence lengths and scales \u003cem\u003eSad ‚Äî Happy\u003c/em\u003e, \u003cem\u003eConcrete ‚Äî Abstract\u003c/em\u003e, and so on.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.aino.world/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"545\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003ca href=\"https://www.aino.world/\"\u003eAino.ai\u003c/a\u003e, an AI GIS Analyst for urban planning. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/6-aino-ai.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe outcome could also be visualized on a map, which, of course, is expected for an \u003ca href=\"https://www.aino.world/\"\u003eAI GIS analyst\u003c/a\u003e. Also, users can \u003cstrong\u003eaccess individual data layers\u003c/strong\u003e, turn them on and off, and hence explore the data on the map.\u003c/p\u003e\u003cp\u003eWe can also use \u003ca href=\"https://www.nngroup.com/articles/accordion-editing-apple-picking/\"\u003eforced ranking\u003c/a\u003e and prioritizations to \u003cstrong\u003esuggest best options\u003c/strong\u003e and avoid choice paralysis ‚Äî even if a user asks for top 10 recommendations. We can think about ways to present results as a data table, or a dashboard, or a visualization on a map, or as a structured JSON file, for example.\u003c/p\u003e\u003ch2 id=\"refinement-ux-tweaking-output\"\u003eRefinement UX: Tweaking Output\u003c/h2\u003e\u003cp\u003eUsers often need to \u003ca href=\"https://www.nngroup.com/articles/accordion-editing-apple-picking/\"\u003echerry-pick\u003c/a\u003e some bits from the AI output and bring them together in a new place ‚Äî and often they need to \u003cstrong\u003eexpand on one section\u003c/strong\u003e, synthesize bits from another section, or just refine the outcome to meet their needs.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.adobe.com/products/firefly.html\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"450\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003ca href=\"https://www.adobe.com/products/firefly.html\"\u003eAdobe Firefly\u003c/a\u003e suggests options and sliders to adjust the outcome. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/7-adobe-firefly.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eRefinement is usually \u003cstrong\u003ethe most painful part of the experience\u003c/strong\u003e, with many fine details being left to users to explain elaborately. But we can use good old-fashioned UI controls like knobs, sliders, buttons, and so on to improve that experience, similar to how Adobe Firefly does it (image above).\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://maggieappleton.com/lm-sketchbook/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"438\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003ePresets living on the side in Elicit, an \u003ca href=\"https://maggieappleton.com/lm-sketchbook/\"\u003eexample\u003c/a\u003e by Maggie Appleton. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/8-illustration-output-ux.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eWe can also use presets, bookmarks, and allow users to \u003cstrong\u003ehighlight specific parts of the outcome\u003c/strong\u003e that they‚Äôd like to change ‚Äî with contextual prompts acting on highlighted parts of the output, rather than global prompts.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://www.grammarly.com/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"329\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eTweaking specific parts of the outcome, on \u003ca href=\"https://www.grammarly.com/\"\u003eGrammarly\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/9-illustration-output-ux.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"ai-actions-tasks-to-complete\"\u003eAI Actions: Tasks To Complete\u003c/h2\u003e\u003cp\u003eWith AI agents, we can now also \u003cstrong\u003eallow users to initiate tasks\u003c/strong\u003e that AI can perform on their behalf, such as scheduling events, planning, and deep research. We could also ask to \u003cstrong\u003esort results or filter them\u003c/strong\u003e in a specific way.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://maggieappleton.com/lm-sketchbook/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"469\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg\" sizes=\"100vw\" alt=\"Illustration of Output UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eSuggesting actions on Elicit, an \u003ca href=\"https://maggieappleton.com/lm-sketchbook/\"\u003eexample\u003c/a\u003e by Maggie Appleton. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/10-illustration-output-ux.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBut we can also add features to help users use AI output better ‚Äî e.g., by visualizing it, making it shareable, allowing \u003cstrong\u003etransformations\u003c/strong\u003e between formats, or also posting to Slack, Jira, and so on.\u003c/p\u003e\u003ch2 id=\"ai-integration-where-work-happens\"\u003eAI Integration: Where Work Happens\u003c/h2\u003e\u003cp\u003eMany AI interactions are locked within a specific product, but good AI experiences happen \u003cstrong\u003ewhere the actual work happens\u003c/strong\u003e. It would be quite unusual to expect a dedicated section for \u003cem\u003eAutocomplete\u003c/em\u003e, for example, but we do so for AI features.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://dovetail.com/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"357\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png\" sizes=\"100vw\" alt=\"Illustration of AI Integration UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e(\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/11-illustration-ai-integration-ux.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003ca href=\"https://dovetail.com/\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"823\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg\" sizes=\"100vw\" alt=\"Illustration of AI Integration UX\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003ca href=\"https://dovetail.com/\"\u003eDoveTail AI\u003c/a\u003e integrates in plenty of platforms, from Jira and Notion to Slack and Teams, where the actual work happens. (\u003ca href=\"https://files.smashing.media/articles/design-patterns-ai-interfaces/12-dovetail.jpg\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eThe actual boost in productivity comes when users rely on AI as a co-pilot or little helper in the \u003cstrong\u003etools they use daily for work\u003c/strong\u003e. It‚Äôs seamless integrations into Slack, Teams, Jira, GitHub, and so on ‚Äî the tools that people use anyway. \u003ca href=\"https://www.diabrowser.com/\"\u003eDia Browser\u003c/a\u003e and \u003ca href=\"https://dovetail.com/\"\u003eDovetail\u003c/a\u003e are great examples of it in action.\u003c/p\u003e\u003ch2 id=\"wrapping-up\"\u003eWrapping Up\u003c/h2\u003e\u003cp\u003eAlong these five areas, we can explore ways to \u003cstrong\u003eminimize the cost of interaction\u003c/strong\u003e with a textbox, and allow users to interact with the points of interest directly, by tapping, clicking, selecting, highlighting, and bookmarking.\u003c/p\u003e\u003cp\u003eMany products are obsessed with being AI-first. But you might be way better off by being \u003cstrong\u003eAI-second\u003c/strong\u003e instead. The difference is that we focus on user needs and sprinkle a bit of AI across customer journeys where it actually adds value.\u003c/p\u003e\u003cp\u003eAnd AI products don‚Äôt have to be AI-only. There is a lot of value in mapping into the mental models that people have adopted over the years, and \u003cstrong\u003eenhance them with AI\u003c/strong\u003e, similar to how we do it with browsers‚Äô autofill, rather than leaving users in front of a frightening and omnipresent text box.\u003c/p\u003e\u003ch2 id=\"useful-resources\"\u003eUseful Resources\u003c/h2\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://uxdesign.cc/where-should-ai-sit-in-your-ui-1710a258390e\"\u003eWhere Should AI Sit In Your UI?\u003c/a\u003e, by Sharang Sharma\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://shapeof.ai/\"\u003eShape of AI: Design Patterns\u003c/a\u003e, by Emily Campbell\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.aiuxpatterns.com/\"\u003eAI UX Patterns\u003c/a\u003e, by Luke Bennis\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://catalogue.projectsbyif.com/\"\u003eDesign Patterns For Trust With AI\u003c/a\u003e, via Sarah Gold\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://pair.withgoogle.com/guidebook/patterns\"\u003eAI Guidebook Design Patterns\u003c/a\u003e, by Google\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://lukew.com/ff/entry.asp?2093\"\u003eUsable Chat Interfaces to AI Models\u003c/a\u003e, by Luke Wroblewski\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://lukew.com/ff/entry.asp?2105\"\u003eThe Receding Role of AI Chat\u003c/a\u003e, by Luke Wroblewski\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://lukew.com/ff/entry.asp?2106\"\u003eAgent Management Interface Patterns\u003c/a\u003e, by Luke Wroblewski\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://uxdesign.cc/designing-for-ai-engineers-what-ui-patterns-and-principles-you-need-to-know-8b16a5b62a61\"\u003eDesigning for AI Engineers\u003c/a\u003e, by Eve Weinberg\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"meet-smart-interface-design-patterns\"\u003eMeet ‚ÄúSmart Interface Design Patterns‚Äù\u003c/h2\u003e\u003cp\u003eYou can find more details on \u003cstrong\u003edesign patterns and UX\u003c/strong\u003e in \u003ca href=\"https://smart-interface-design-patterns.com/\"\u003e\u003cstrong\u003eSmart Interface Design Patterns\u003c/strong\u003e\u003c/a\u003e, our \u003cstrong\u003e15h-video course\u003c/strong\u003e with 100s of practical examples from real-life projects ‚Äî with a live UX training later this year. Everything from mega-dropdowns to complex enterprise tables ‚Äî with 5 new segments added every year. \u003ca href=\"https://www.youtube.com/watch?v=jhZ3el3n-u0\"\u003eJump to a free preview\u003c/a\u003e. Use code \u003ca href=\"https://smart-interface-design-patterns.com\"\u003e\u003cstrong\u003eBIRDIE\u003c/strong\u003e\u003c/a\u003e to \u003cstrong\u003esave 15%\u003c/strong\u003e off.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://smart-interface-design-patterns.com/\"\u003e\u003cimg decoding=\"async\" fetchpriority=\"low\" width=\"950\" height=\"492\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg\" sizes=\"100vw\" alt=\"Smart Interface Design Patterns\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eMeet \u003ca href=\"https://smart-interface-design-patterns.com/\"\u003eSmart Interface Design Patterns\u003c/a\u003e, our video course on interface design \u0026amp; UX.\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003e\u003cimg src=\"https://www.smashingmagazine.com/images/logo/logo--red.png\" alt=\"Smashing Editorial\" width=\"35\" height=\"46\" loading=\"lazy\" decoding=\"async\"/\u003e\n\u003cspan\u003e(yk)\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-07-14T15:00:00Z",
  "modifiedTime": "2025-07-14T15:00:00Z"
}
