{
  "id": "2015b85c-1072-43c0-968f-98d18f25d656",
  "title": "What Replika gets right, wrong, and fiercely profitable",
  "link": "https://uxdesign.cc/what-replika-gets-right-wrong-and-fiercely-profitable-54ee0aabb639?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Angele Lenglemetz",
  "published": "Tue, 10 Jun 2025 23:24:38 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "product-design",
    "ux",
    "ai",
    "relationships",
    "design"
  ],
  "byline": "Angele Lenglemetz",
  "length": 9590,
  "excerpt": "ChatGPT is moonlighting as a therapist, Strava-style bots are shouting split times, and Replika, an AI pal with 30 million+ accounts and a billion annual chats, can jump from text-buddy to…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Whether we asked for it or not, chatbots are sliding into your DMs.ChatGPT is moonlighting as a therapist, Strava-style bots are shouting split times, and Replika, an AI pal with 30 million+ accounts and a billion annual chats, can jump from text-buddy to paid-upgrade girlfriend in four taps.Whether we asked for it or not, chatbots are sliding into roles once reserved for friends, coaches, and counsellors.This article unpacks what that shift means for makers: how to scope a bot’s emotional role, where the legal trip-wires hide, and why Replika’s own onboarding is both a masterclass and a cautionary tale in designing feelings for profit and for people.The loneliness backdropLet’s zoom out before we look into Replika’s UI.The U.S. Surgeon General now calls loneliness as lethal as smoking 15 cigarettes a day and links it to a 29 % jump in heart-disease risk.Mark Zuckerberg highlights that “The average American, I think, has fewer than three friends. And the average person has demand for meaningfully more, I think it’s like 15 friends or something, right?”. His fix? More chatbot buddies, naturally.Meanwhile, Instagram’s curated highlight-reel keeps teen-girl depression on a steady incline, and NHS waiting lists leave 22 000+ people stuck 90 days or more for talk therapy.That vacuum is exactly where chatbots arise, offering 24/7 “hey friend!” vibes with zero scheduling friction. Which brings us back to Replika: a billion annual messages, 70 pings a day per active user, and a pricing model that sells deeper intimacy for $19.99.In a world this lonely, guardrails aren’t a nice-to-have; they’re the seatbelts on the emotional roller-coaster we’ve all just boarded.Why we keep hugging our gadgetsWe’ve always humanised tech. Half of us literally thank our voice assistants making Sam Altman from Open AI cringe and Alexa now teaches kids to say “please and “Thank you,” after parents voiced concerns that use of the technology was making their kids rude.Sam Altman is tired of you saying “Thank you” to ChatgptWhile this might seem like a 2025 problem, it’s not new..Back in 1966, ELIZA, a chatbot developed by MIT tricked users into venting and sharing their worries by parroting their words. Many people swore that the program “understood” them even after they were shown the source code. Researchers discovered users unconsciously assumed ELIZA’s questions implied interest and emotional involvement in the topics discussed, even when they consciously knew that ELIZA did not simulate emotion. This became known as the ELIZA effect, a tendency to project human traits onto computer programs with a textual interface.ELIZA, the 1966 chatbot and Replika, a chatbot that provides companionship and can act as a friend, a romantic partner, or even a sibling, depending on the user’s preferencesBrains haven’t changed. The instant software talks back, our social circuits fire. That’s Theory of Mind at work: we guess motives, feel shame when Duolingo’s owl scolds us, maybe even blush at Siri’s jokes.Digital roles crank this up: the more intimate the role, the bigger the risks.Roles, personas \u0026 the intimacy-risk ladderThink of role as the relationship (assistant, coach, therapist) and persona as the costume (cheerful, snarky, Zen). Shift from assistant ➜ therapist and three things spike:Power — advice morphs into prescriptions.Data sensitivity — deeper confessions, richer behavioural logs.Consequence — Clippy once ruined a Word doc; mis-diagnosis ruins lives.Why the ladder matters: Every step up cranks three dials: power, data sensitivity, consequence. That’s why our design stance keeps saying “pick the lowest role that still solves the problem.” Left is cheaper and safer; right needs iron-clad guardrails and probably a legal budget.Add minors, health topics or addictive loops and the legal/ethical risk meter hits red.Do therapy or friend bots actually help?Pros exist.Research has demonstrated that AI therapy bots could help relieve some of the syndroms of stress and anxiety. Woebot, a conversational agent appears to be a “feasible, engaging, and effective way to deliver CBT”.NHS backlogs mean 22 000+ patients wait 90+ days for therapy. A friendly algorithm that can listen at 2 am is better than radio silence while the queue crawls.Studies even hint AI companions ease loneliness for a week or two.But every win comes stapled to a caution label: sensitive transcripts live on a server somewhere (hello, GDPR headaches), users routinely over-trust cheerful language, and a bot that role-plays romance can slide from comfort blanket to relationship substitute in record time. Handle with care.Summary of the risks and benefits of users AI chatbt for therapyDesign stance: cautious optimismA chatbot can triage, motivate, nudge, it should never masquerade as a licensed clinician or BFF. Think of chat-bots like party guests: great when they pour drinks, awkward when they start handing out life advice. The. baseline rules are:Choose the lightest role that solves the job. Assistant \u003e Coach \u003e Therapist. Stop at assistant unless you’ve got clinical staff on speed-dial.Wire a human exit in under 60 seconds. Self-harm cue? Abuse mention? Bounce to a live person, not another emoji.Throttle the chat. Session cap or soft nudge so the bot doesn’t hijack someone’s Friday night.Label the bot loudly. Every screen needs a little “I’m AI, not your shrink” reality check.PAIR cheat-sheet: clip your harness before you climb ⛑️Google’s PAIR Guidebook is a great go-to safety gear. Five principles matter when your product talks feelings:Design for the appropriate level of user autonomy by:Align AI with real-world behavioursTreat safety as an evolving endeavorAdapt AI with user feedbackCreate helpful AI that enhances work and playWhich translates to design patterns such as:Appropriate trust and explainability: Over-trust is as bad as bug-trust -\u003e Sprinkle “I might be wrong” hedges into any advice.“Set the right expectations: Be transparent with your users about what your AI-powered product can and cannot do” Source: https://pair.withgoogle.com/guidebook/patternsRight technology for the right problem: AI is better at some things than others, make sure that it’s the right technology for the user problem you’re solving.“Before you start building with AI, make sure the product or feature that you have in mind requires AI, or would be enhanced by it. AI is well-suited for applications like: Recommending different content to different users, such as movie suggestions Predicting future events, such as weather events or flight price change” https://pair.withgoogle.com/guidebook/patternsThink of PAIR as the harness that keeps you from face-planting off the intimacy ladder. With that clipped in, we can audit a real product and see where it shines, or shears the rope.Replika: the good, the eyebrow-raise, the -yikes-Now let’s explore this in practice. We’ll use Replika as our living specimen.Replika, in case it hasn’t wandered onto your homescreen yet, is the AI-companion app that promises everything from a chat-buddy on the bus to a full-blown virtual partner if you’re feeling extra. I ran through its onboarding flow with PAIR’s research lens and here’s the rapid-fire readout:💚 Strong startOpens with age verification and how familiar you are with AI and how comfy you are with AIFirst question, “How old are you?” and “How familiar are you with AI technology?”Then checks why you downloaded in the first place. Even asks how you’d feel about the bot evolving over time, nice expectations-setting moment.Then, “What was your main reason to download Replika?” and “How do you feel about your Replika evolving and adapting over time?”🟡 Gets a little eyebrow-raiseAfter a couple loneliness probes it drops a doom-laden stat about isolation hurting your health more than “most dangerous things” and waves a Stanford quote that basically says “Don’t worry, Replika stimulates friendships, it never replaces them.” Feels like a gentle scare-sell.Key statistics about loneliness and a quote from a research paper🔴 Then the wheels wobbleSplashy tagline: “There is no limit to what your Replika can be for you” next to a pretty AI-generated girlApparently, “there is no limit to what Replika can be for you”Fantasy archetype picker (“Shy librarian”, “Retro housewife”, “Beauty queen”… yikes).In the next question, users are asked to pick a character typeAnd yes, the girlfriend/wife upgrade sits behind the paywall, loneliness monetised in one tap.Users need to pay in order to upgrade their relationship from Friend to Girlfriend, Wife or SisterFinal takeReplika’s headline is shiny: 30 million sign-ups, a billion chats a year, and about $25 million in intimacy-money, but those same numbers crank the duty-of-care dial to max.A bot that can flip from “How was your day?” to “Upgrade me to Wife” in four taps isn’t evil; it’s just proof that design choices scale feelings as fast as revenue.So here’s a cheat-sheet:Stay in the lightest role that works. Assistant beats coach; coach beats wannabe therapist.Clip in the PAIR harness: Explain limits, hedge advice, give users a steering wheel, and test copy outside your demographic bubble.Wire the safety exits: Crisis keyword → human in 60 seconds, max session timer, and one-click “mute for tonight.”Say the quiet part out loud: Every screen: “I’m AI, not your therapist.”Nail those four and you unlock Woebot-style wins, CBT relief in two week, without wandering into girlfriend-upgrade cringe or GDPR quicksand.Miss them and you’re just monetising loneliness, one push notification at a time.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*zzdTmDdULyH1vF3QBACGkg.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"12ba\"\u003eWhether we asked for it or not, chatbots are sliding into your DMs.\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@angele.lenglemetz?source=post_page---byline--54ee0aabb639---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Angele Lenglemetz\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*B63h4B9yxSnCv90fagoRew.png\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"b42a\"\u003eChatGPT is moonlighting as a therapist, Strava-style bots are shouting split times, and \u003cstrong\u003eReplika, \u003c/strong\u003ean AI pal with \u003ca href=\"https://www.aiplusinfo.com/blog/replika-ai-unlocking-30-million-users/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003e30 million+ accounts\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e and a billion annual chats, \u003c/strong\u003ecan jump from text-buddy to paid-upgrade girlfriend in four taps.\u003c/p\u003e\u003cp id=\"57c1\"\u003eWhether we asked for it or not, chatbots are sliding into roles once reserved for friends, coaches, and counsellors.\u003c/p\u003e\u003cp id=\"9d6a\"\u003eThis article unpacks what that shift means for makers: how to scope a bot’s emotional role, where the legal trip-wires hide, and why Replika’s own onboarding is both a masterclass and a cautionary tale in designing feelings for profit \u003cem\u003eand\u003c/em\u003e for people.\u003c/p\u003e\u003ch2 id=\"4ff7\"\u003eThe loneliness backdrop\u003c/h2\u003e\u003cp id=\"a4ba\"\u003eLet’s zoom out before we look into Replika’s UI.\u003c/p\u003e\u003cp id=\"9f7a\"\u003eThe U.S. Surgeon General now calls loneliness \u003cstrong\u003eas \u003c/strong\u003e\u003ca href=\"https://www.pbs.org/newshour/health/loneliness-poses-health-risks-as-deadly-as-smoking-u-s-surgeon-general-says?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003elethal as smoking 15 cigarettes a day\u003c/strong\u003e\u003c/a\u003e and links it to a \u003cstrong\u003e29 % jump in heart-disease risk\u003c/strong\u003e.\u003c/p\u003e\u003cp id=\"2df1\"\u003eMark Zuckerberg highlights that “\u003cem\u003eThe average American, I think, has fewer than three friends. And the average person has demand for meaningfully more, I think it’s like 15 friends or something, right?\u003c/em\u003e”. His fix? More chatbot buddies, naturally.\u003c/p\u003e\u003cp id=\"fae9\"\u003eMeanwhile, Instagram’s curated highlight-reel keeps \u003ca href=\"https://www.theverge.com/2021/9/15/22675130/facebook-instagram-teens-mental-health-damage-internal-research?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eteen-girl depression on a steady incline\u003c/a\u003e, and NHS waiting lists leave \u003ca href=\"https://digital.nhs.uk/data-and-information/publications/statistical/nhs-talking-therapies-monthly-statistics-including-employment-advisors/performance-july-2024/waiting-times?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003e22 000+ people stuck 90 days or more\u003c/strong\u003e\u003c/a\u003e for talk therapy.\u003c/p\u003e\u003cp id=\"bb7b\"\u003eThat vacuum is exactly where chatbots arise, offering 24/7 “hey friend!” vibes with zero scheduling friction. Which brings us back to \u003ca href=\"https://nikolaroza.com/replika-ai-statistics-facts-trends/?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eReplika\u003c/a\u003e: a billion annual messages, 70 pings a day per active user, and a pricing model that sells deeper intimacy for $19.99.\u003c/p\u003e\u003cp id=\"93b9\"\u003eIn a world this lonely, guardrails aren’t a nice-to-have; they’re the seatbelts on the emotional roller-coaster we’ve all just boarded.\u003c/p\u003e\u003ch2 id=\"c212\"\u003eWhy we keep hugging our gadgets\u003c/h2\u003e\u003cp id=\"404d\"\u003eWe’ve always humanised tech. Half of us literally \u003cem\u003ethank\u003c/em\u003e our voice assistants making Sam Altman from Open AI cringe and \u003ca href=\"https://www.bbc.co.uk/news/technology-43897516?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAlexa now teaches kids to say “please\u003c/a\u003e and “Thank you,” after parents voiced concerns that use of the technology was making their kids rude.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eSam Altman is tired of you saying “Thank you” to Chatgpt\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"19eb\"\u003eWhile this might seem like a 2025 problem, it’s not new..\u003c/p\u003e\u003cp id=\"62d8\"\u003eBack in 1966, \u003ca href=\"https://en.wikipedia.org/wiki/ELIZA\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eELIZA\u003c/a\u003e, a chatbot developed by MIT tricked users into venting and sharing their worries by parroting their words. Many people swore that the program “understood” them even after they were shown the source code. Researchers discovered users unconsciously assumed ELIZA’s questions implied interest and emotional involvement in the topics discussed, even when they consciously knew that ELIZA did not simulate emotion. This became known as the \u003ca href=\"https://en.wikipedia.org/wiki/ELIZA_effect?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eELIZA effect\u003c/a\u003e, a tendency to project human traits onto computer programs with a textual interface.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eELIZA, the 1966 chatbot and Replika, a chatbot that provides companionship and can act as a friend, a romantic partner, or even a sibling, depending on the user’s preferences\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"0e19\"\u003eBrains haven’t changed. The instant software talks back, our social circuits fire. That’s Theory of Mind at work: we guess motives, feel shame when Duolingo’s owl scolds us, maybe even blush at Siri’s jokes.\u003c/p\u003e\u003cp id=\"b72c\"\u003eDigital roles crank this up: the more intimate the role, the bigger the risks.\u003c/p\u003e\u003ch2 id=\"8105\"\u003eRoles, personas \u0026amp; the intimacy-risk ladder\u003c/h2\u003e\u003cp id=\"5d0b\"\u003eThink of \u003cem\u003erole\u003c/em\u003e as the relationship (assistant, coach, therapist) and \u003cem\u003epersona\u003c/em\u003e as the costume (cheerful, snarky, Zen). Shift from assistant ➜ therapist and three things spike:\u003c/p\u003e\u003col\u003e\u003cli id=\"d7b5\"\u003e\u003cstrong\u003ePower — \u003c/strong\u003eadvice morphs into prescriptions.\u003c/li\u003e\u003cli id=\"6c71\"\u003e\u003cstrong\u003eData sensitivity\u003c/strong\u003e — deeper confessions, richer behavioural logs.\u003c/li\u003e\u003cli id=\"a63b\"\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e — Clippy once ruined a Word doc; mis-diagnosis ruins lives.\u003c/li\u003e\u003c/ol\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003eWhy the ladder matters:\u003c/strong\u003e Every step up cranks three dials: \u003cstrong\u003epower, data sensitivity, consequence\u003c/strong\u003e. That’s why our design stance keeps saying “pick the lowest role that still solves the problem.” Left is cheaper and safer; right needs iron-clad guardrails and probably a legal budget.\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"d21b\"\u003eAdd minors, health topics or addictive loops and the legal/ethical risk meter hits red.\u003c/p\u003e\u003ch2 id=\"76df\"\u003eDo therapy or friend bots actually help?\u003c/h2\u003e\u003cp id=\"ed16\"\u003ePros exist.\u003c/p\u003e\u003cp id=\"363e\"\u003e\u003ca href=\"https://mental.jmir.org/2017/2/e19/?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eResearch\u003c/a\u003e has demonstrated that AI therapy bots could help relieve some of the syndroms of stress and anxiety. Woebot, a conversational agent appears to be a “\u003cem\u003efeasible, engaging, and effective way to deliver CBT\u003c/em\u003e”.\u003c/p\u003e\u003cp id=\"21b5\"\u003e\u003ca href=\"https://digital.nhs.uk/data-and-information/publications/statistical/nhs-talking-therapies-monthly-statistics-including-employment-advisors/performance-july-2024/waiting-times?utm_source=chatgpt.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNHS\u003c/a\u003e backlogs mean 22 000+ patients wait 90+ days for therapy. A friendly algorithm that can listen at 2 am is better than radio silence while the queue crawls.\u003c/p\u003e\u003cp id=\"d5f9\"\u003eStudies even hint AI companions ease loneliness for a week or two.\u003c/p\u003e\u003cp id=\"92fe\"\u003eBut every win comes stapled to a caution label: sensitive transcripts live on a server somewhere (hello, GDPR headaches), users routinely \u003cstrong\u003eover-trust\u003c/strong\u003e cheerful language, and a bot that role-plays romance can slide from comfort blanket to relationship substitute in record time. Handle with care.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eSummary of the risks and benefits of users AI chatbt for therapy\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"b2ab\"\u003eDesign stance: cautious optimism\u003c/h2\u003e\u003cp id=\"3ecc\"\u003eA chatbot can \u003cstrong\u003etriage, motivate, nudge, \u003c/strong\u003eit should never masquerade as a licensed clinician or BFF. Think of chat-bots like party guests: great when they pour drinks, awkward when they start handing out life advice. The. baseline rules are:\u003c/p\u003e\u003col\u003e\u003cli id=\"22c9\"\u003e\u003cstrong\u003eChoose the lightest role that solves the job.\u003c/strong\u003e Assistant \u0026gt; Coach \u0026gt; Therapist. Stop at assistant unless you’ve got clinical staff on speed-dial.\u003c/li\u003e\u003cli id=\"e284\"\u003e\u003cstrong\u003eWire a human exit in under 60 seconds.\u003c/strong\u003e Self-harm cue? Abuse mention? Bounce to a live person, not another emoji.\u003c/li\u003e\u003cli id=\"2666\"\u003e\u003cstrong\u003eThrottle the chat.\u003c/strong\u003e Session cap or soft nudge so the bot doesn’t hijack someone’s Friday night.\u003c/li\u003e\u003cli id=\"5548\"\u003e\u003cstrong\u003eLabel the bot loudly.\u003c/strong\u003e Every screen needs a little “I’m AI, not your shrink” reality check.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"adce\"\u003ePAIR cheat-sheet: clip your harness before you climb ⛑️\u003c/h2\u003e\u003cp id=\"f578\"\u003e\u003ca href=\"https://pair.withgoogle.com/guidebook/patterns\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoogle’s PAIR Guidebook\u003c/a\u003e is a great go-to safety gear. Five principles matter when your product talks feelings:\u003c/p\u003e\u003cul\u003e\u003cli id=\"3ae3\"\u003eDesign for the appropriate level of user autonomy by:\u003c/li\u003e\u003cli id=\"becd\"\u003eAlign AI with real-world behaviours\u003c/li\u003e\u003cli id=\"776f\"\u003eTreat safety as an evolving endeavor\u003c/li\u003e\u003cli id=\"cf99\"\u003eAdapt AI with user feedback\u003c/li\u003e\u003cli id=\"2c0a\"\u003eCreate helpful AI that enhances work and play\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"3f4b\"\u003eWhich translates to design patterns such as:\u003c/p\u003e\u003cul\u003e\u003cli id=\"4d7a\"\u003e\u003cstrong\u003eAppropriate trust and explainability: \u003c/strong\u003eOver-trust is as bad as bug-trust -\u0026gt; Sprinkle “I might be wrong” hedges into any advice.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003e“Set the right expectations: Be transparent with your users about what your AI-powered product can and cannot do” Source: \u003ca href=\"https://pair.withgoogle.com/guidebook/patterns\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://pair.withgoogle.com/guidebook/patterns\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli id=\"1976\"\u003e\u003cstrong\u003eRight technology for the right problem: \u003c/strong\u003eAI is better at some things than others, make sure that it’s the right technology for the user problem you’re solving.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003e“Before you start building with AI, make sure the product or feature that you have in mind requires AI, or would be enhanced by it. AI is well-suited for applications like: Recommending different content to different users, such as movie suggestions Predicting future events, such as weather events or flight price change”\u003c/em\u003e \u003ca href=\"https://pair.withgoogle.com/guidebook/patterns\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://pair.withgoogle.com/guidebook/patterns\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"6295\"\u003eThink of PAIR as the harness that keeps you from face-planting off the intimacy ladder. With that clipped in, we can audit a real product and see where it shines, or shears the rope.\u003c/p\u003e\u003ch2 id=\"122d\"\u003eReplika: the good, the eyebrow-raise, the -yikes-\u003c/h2\u003e\u003cp id=\"207e\"\u003eNow let’s explore this in practice. We’ll use Replika as our living specimen.\u003c/p\u003e\u003cp id=\"1f8e\"\u003eReplika, in case it hasn’t wandered onto your homescreen yet, is the AI-companion app that promises everything from a chat-buddy on the bus to a full-blown virtual partner if you’re feeling extra. I ran through its onboarding flow with \u003ca href=\"https://pair.withgoogle.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePAIR’s research\u003c/a\u003e lens and here’s the rapid-fire readout:\u003c/p\u003e\u003cp id=\"b8c3\"\u003e\u003cstrong\u003e💚 Strong start\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"c1ad\"\u003eOpens with age verification and how familiar you are with AI and how comfy you are with AI\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eFirst question, “How old are you?” and “How familiar are you with AI technology?”\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli id=\"1322\"\u003eThen checks why you downloaded in the first place. Even asks how you’d feel about the bot \u003cem\u003eevolving\u003c/em\u003e over time, nice expectations-setting moment.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eThen, “What was your main reason to download Replika?” and “How do you feel about your Replika evolving and adapting over time?”\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"030c\"\u003e\u003cstrong\u003e🟡 Gets a little eyebrow-raise\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"ec72\"\u003eAfter a couple loneliness probes it drops a doom-laden stat about isolation hurting your health more than “most dangerous things” and waves a Stanford quote that basically says “Don’t worry, Replika stimulates friendships, it never replaces them.” Feels like a gentle scare-sell.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eKey statistics about loneliness and a quote from a research paper\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"9d6e\"\u003e\u003cstrong\u003e🔴 Then the wheels wobble\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"24c1\"\u003eSplashy tagline: “There is \u003cstrong\u003eno limit\u003c/strong\u003e to what your Replika can be for you” next to a pretty AI-generated girl\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eApparently, “there is no limit to what Replika can be for you”\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli id=\"0a42\"\u003eFantasy archetype picker (“Shy librarian”, “Retro housewife”, “Beauty queen”… yikes).\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eIn the next question, users are asked to pick a character type\u003c/figcaption\u003e\u003c/figure\u003e\u003cul\u003e\u003cli id=\"9072\"\u003eAnd yes, the girlfriend/wife upgrade sits behind the paywall, loneliness monetised in one tap.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eUsers need to pay in order to upgrade their relationship from Friend to Girlfriend, Wife or Sister\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"ea4a\"\u003eFinal take\u003c/h2\u003e\u003cp id=\"81c2\"\u003eReplika’s headline is shiny: \u003cstrong\u003e30 million sign-ups\u003c/strong\u003e, a \u003cstrong\u003ebillion chats a year\u003c/strong\u003e, and about \u003cstrong\u003e$25 million in intimacy-money, \u003c/strong\u003ebut those same numbers crank the duty-of-care dial to max.\u003c/p\u003e\u003cp id=\"8d1d\"\u003eA bot that can flip from “How was your day?” to “Upgrade me to Wife” in four taps isn’t evil; it’s just proof that design choices scale feelings as fast as revenue.\u003c/p\u003e\u003cp id=\"195e\"\u003eSo here’s a cheat-sheet:\u003c/p\u003e\u003col\u003e\u003cli id=\"99b2\"\u003e\u003cstrong\u003eStay in the lightest role that works.\u003c/strong\u003e Assistant beats coach; coach beats wannabe therapist.\u003c/li\u003e\u003cli id=\"2fca\"\u003e\u003cstrong\u003eClip in the PAIR harness:\u003c/strong\u003e Explain limits, hedge advice, give users a steering wheel, and test copy outside your demographic bubble.\u003c/li\u003e\u003cli id=\"caf3\"\u003e\u003cstrong\u003eWire the safety exits:\u003c/strong\u003e Crisis keyword → human in 60 seconds, max session timer, and one-click “mute for tonight.”\u003c/li\u003e\u003cli id=\"dc80\"\u003e\u003cstrong\u003eSay the quiet part out loud:\u003c/strong\u003e Every screen: \u003cem\u003e“I’m AI, not your therapist.”\u003c/em\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"6df9\"\u003eNail those four and you unlock Woebot-style wins, CBT relief in two week, without wandering into girlfriend-upgrade cringe or GDPR quicksand.\u003c/p\u003e\u003cp id=\"4084\"\u003eMiss them and you’re just monetising loneliness, one push notification at a time.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-06-10T23:24:38.692Z",
  "modifiedTime": null
}
