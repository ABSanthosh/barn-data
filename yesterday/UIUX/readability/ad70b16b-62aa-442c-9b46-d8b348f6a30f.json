{
  "id": "ad70b16b-62aa-442c-9b46-d8b348f6a30f",
  "title": "Human flourishing in the Age of AI",
  "link": "https://uxdesign.cc/human-flourishing-in-the-age-of-ai-b456b1de31c7?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Josh LaMar",
  "published": "Sat, 11 Jan 2025 10:44:19 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "ux",
    "technology",
    "flourishing",
    "ai",
    "culture"
  ],
  "byline": "Josh LaMar",
  "length": 33644,
  "excerpt": "The explosion of AI over the past two years, particularly generative AI and large language models (LLMs), has reshaped much of how we work and think about technology. For user researcher and…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "TECHNOLOGY \u0026 CULTUREChallenges, strategies, \u0026 opportunities.Credit: MarketoonistThe explosion of AI over the past two years, particularly generative AI and large language models (LLMs), has reshaped much of how we work and think about technology. For user researcher and designers, AI’s impact can be grouped into three broad areas:Generative AI product development: The topics and challenges explored in research and design projects as we seek to best implement AI into new products and services.Internal processes: Systems and workflows within the workplace leveraging AI to enhance efficiency and insight as we work together to build AI-leveraged products and services.Personal practices and training: Individual use of AI to augment skills and productivity.While AI offers immense potential to accelerate and enhance product design, it’s critical to approach it with a balanced perspective. Alongside its benefits, AI presents potential harms and negative impacts that demand careful consideration.As this transition is happening, many of us are asking ourselves how we can approach AI in a human-centered way. Some of the key questions to guide responsible AI integration include:How can organizations advocate for the development of AI technologies that prioritize human well-being in their products and services?What strategies ensure AI can be leveraged responsibly while centering human needs during research, analysis, design, and the software development process?How can authentic human experiences be validated within a landscape increasingly shaped by artificial content?What day-to-day practices can researchers and designers adopt to maintain a balanced, human-centered approach to AI?And most importantly:How can researchers and designers learn, grow, and adapt while AI technology is evolving faster and faster?In this article, I will attempt to answer these questions by revisiting foundational concepts of human flourishing, reflecting on organizational values, and synthesizing diverse perspectives from professional communities and academic literature.The goal is to help us all develop best practices for AI use that align with both ethical standards and business goals.And keep the human centered in the loop.A human-first approachAdopting a human-first approach provides a strong foundation for ethical and effective AI use. At its core, this philosophy emphasizes serving and empowering people through empathy, authenticity, and a commitment to collective well-being.I think of Human-First as humans serving humans. Every decision, every interaction is grounded in empathy, authenticity, and the acknowledgment of our collective humanity. We take care of ourselves and keep the health of others in mind. We create space when needed.Taking the core concepts of human flourishing as identified by academics and applied practitioners, (See Appendix, below, for complete list of frameworks) practitioners and organizations that embrace a human-first mindset define their values around these core principles:Purpose and Contribution: Supporting work that feels meaningful and impactful.Personal Growth and Agency: Encouraging self-determination and skill development.Holistic Well-Being: Addressing physical, mental, social, and other dimensions of health.Ethical Living: Ensuring actions align with moral values and promote harmony.A holistic view of human flourishing considers the individual, structural, systemic, and environmental levels to create sustainable, people-centered solutions.Interdisciplinary and cross-cultural frameworks (e.g., the Social Ecological Framework, The Ecology of Wellbeing, \u0026 Measuring Flourishing | Harvard), can be applied to aide us in decision-making.By rooting AI practices in these values, researchers, designers, and organizations can better navigate challenges to human flourishing in research and design. This foundation sets the stage for addressing specific AI-related concerns while advancing the shared goal of creating technologies that truly serve humanity.It is in this context that we next identify AI-related challenges to human flourishing in the context of UX Research and Design.AI challenges to human flourishing and lessons learnedThe more I experiment with AI tools while also conducting research and consulting with companies building generative AI-based tools, the more I can see the limitations of how AI can detract from human flourishing.While societal concerns surrounding AI are vast and complex, (See AI Risks in Appendix, below), this discussion focuses on challenges most relevant to day-to-day experience of user experience (UX) and design research work.Through personal (and team) experience and reviewing articles and perspectives, we have identified four key characteristics of AI as particularly threatening to human flourishing:1. OversimplificationAI’s limited ability to detect and adapt to complex, changing contexts can lead to oversimplification of human behavior and realities, culturally or situationally inappropriate insights and output, and perpetuation of systemic inequities and injustices.Frequent users of AI tools have likely had an experience with AI output that isn’t quite what you were looking for. In those moments, it feels like AI isn’t gleaning the intent behind your question. Sometimes even the most well-crafted prompt isn’t enough to overcome this barrier.AI models often struggle to fully understand and adapt to contextual nuances, particularly in complex or dynamic environments where human interpretation is key. It falls short in fully grasping the subtleties of human communication, including tone, cultural references, and implied meanings, as well as sussing out potential motivations or explanations for human behavior and phenomena (What Are the Limitations of AI in Understanding Context in Text? — Space Coast Daily \u0026 The Context Problem in Artificial Intelligence — Communications of the ACM).As it relies on predefined rules and training data, it can fail to factor in social, cultural, systemic, and environmental influences out of purview.These characteristics limit AI’s responsible utilization in research across contexts, cultures, and in novel situations, and when completing tasks that require high-stakes or creative problem-solving.Research and design often involve making sense of a complex interplay of user and contextual factors that combine to drive behavior or shape an experience — and it seems that AI tools are not yet advanced enough to appropriately capture and process this complexity.Not all generative AI tools are the same and having awareness about each product’s context windows ensures we’re realistic about to what extent the tool can help us center humanness in research and design (What is a context window?).2. Propensity to generalizeAI’s tendency to summarize and generalize poses a risk to the representation of diverse human experiences and inclusivity. While AI excels at processing large datasets to identify common patterns and deliver efficient summaries, this strength can become a limitation when it oversimplifies nuanced perspectives or excludes less common experiences.For example, AI-powered search engines highlight the most popular answers but may exclude context-specific insights, leading to incomplete or biased conclusions (The AI Summarization Dilemma: When Good Enough Isn’t Enough: Center for Advancing Safety of Machine Intelligence — Northwestern University \u0026 AI’s dark secret: It’s rolling back progress on equality | Context).Similarly, relying solely on AI for research analysis can result in a surface-level understanding of the average. AI analysis may lead to the full spectrum of participant responses not being considered, ignoring minority perspectives, and creating exclusive products or experiences.There are times in analysis where you want to understand the broad themes — but there are also times where it's important to understand individual nuances.These limitations are particularly dangerous when researching diverse populations or designing solutions that require high degrees of sensitivity and nuance. Indeed, as we’ve experimented with AI tools for research and analysis, we have found outputs to be inadequate and potentially misleading, and we find ourselves needing to reintegrate human subtleties and dive deeper into oversimplified insights.3. Lack of transparencyAI tools’ lack of transparency and data privacy guardrails can infringe on our basic human right to privacy and decrease our sense of agency to choose our relationship with technology.Despite efforts to improve transparency and develop privacy-centric AI, using AI often still feels like working with a “black box” — with users still missing deep understanding of how AI processes their data and clear, succinct explanations of privacy practices (We Must Fix the Lack of Transparency Around the Data Used to Train Foundation Models · Special Issue 5: Grappling With the Generative AI Revolution \u0026 Transparency is sorely lacking amid growing AI interest | ZDNET).This has implications as we use AI to collect and analyze data from people and as we try to develop AI-powered products that promote consent, agency, and empowerment.As researchers and designers, we have a duty to protect personally identifiable information (PII) of research participants and the intellectual property of our clients.We have a responsibility to ensure that our research participants have the power to consent to how their data is used and to our consumers to create products and experiences that do not lead to privacy breaches and data exploitation. In our experience, when using popular AI tools to their full functionality, we cannot guarantee those protections will be upheld.4. AI isn't aware of its' own biasAI’s tendency to reproduce bias and generate inaccurate output can exacerbate existing social inequalities and creates threats to informed decision-making.For example, the UK passport photo checker showed bias towards women and darker-skinned people:https://www.bbc.co.uk/news/technology-54349538.ampThe tendency for AI tools to perpetuate and exacerbate human biases present in their training data is probably the most commonly discussed threat of AI, so we won’t discuss this issue in depth here (Battling Bias in AI).Bias can lead to discriminatory experiences for research participants, skewed insights, narrowed scope of potential design directions, and designs that cater to hegemonic identities and majority user groups.Hallucinations: Beyond biased output, there is the potential for hallucinations which produce nonexistent or inaccurate outputs (When AI Gets It Wrong: Addressing AI Hallucinations and Bias — MIT Sloan Teaching \u0026 Learning Technologies). This misinformation could affect research and product decisions in major ways.In another example, Air Canada's chatbot lied to a passenger about bereavement fares but the customer later won the case:The passenger claimed to have been misled on the airline’s rules for bereavement fares when the chatbot hallucinated an answer inconsistent with airline policy. The Tribunal in Canada’s small claims court found the passenger was right and awarded them $812.02 in damages and court fees… the court found Air Canada failed to explain why the passenger should not trust information provided on its website by its chatbot. Source: ForbesWhile being aware that generative AI products can produced biased or inaccurate information is a good first step, we feel there is still unmet need for transparency and diversification of training datasets and extensive training on critical evaluation of AI output. AI must be leveraged judiciously and always in service of human-centered needs.Addressing threats to human flourishingAs we advance our use of AI, we must remain committed to prioritizing the human experience and fostering the well-being of our colleagues, research participants, clients, and the customers who use the products we help create.Technology should contribute to the well-being, growth, and fulfillment of people and their communities.Addressing the four challenges discussed above, here are four strategies to combat the limitations.Strategy #1: AI as a complement, not a replacementAI has proven to be a powerful tool in research, but its greatest potential lies in complementing, not replacing, human expertise. Understanding where AI excels and where humans bring unique value allows us to strike the right balance.Where AI shines:Processing large data sets: AI’s computational power allows it to analyze vast amounts of data far faster than humans, making it an indispensable tool for pattern recognition and large-scale analysis.Generating initial ideas: AI is excellent at sparking brainstorming by presenting diverse, unbiased possibilities, which can help overcome creative blocks.Recognizing patterns: AI’s pattern-recognition capabilities are unmatched for identifying trends and correlations across datasets.Where humans shine:Empathy and connection: These are foundational to qualitative research. Building trust, reading body language, and engaging authentically are uniquely human abilities that technology cannot replicate.Understanding complex contexts: Humans excel at synthesizing subtle, multifaceted information that may not fit neatly into patterns.Ethical and contextual judgment: Humans bring cultural and moral considerations into decision-making, ensuring sensitivity and appropriateness.Unique insights: The creativity and contextual understanding required for truly novel insights remain human strengths.Striking the right balanceData collection: AI can enhance efficiency in data collection when used intentionally. For example, it can assist with participant screening during recruitment, but researcher oversight ensures quality and appropriateness. Human moderation remains indispensable for creating connection, fostering empathy, and understanding participants deeply.While AI moderation is effective for executing qualitative research quickly and at scale (Accelerating Research with AI), it cannot replicate the depth of human engagement.Data analysis: In analysis, AI can be valuable for identifying major themes and aiding qualitative data coding, providing researchers with a head start. Transcriptions alone are a great start. When it comes to summaries, most tools I've tried are ok at this, but the future promise is there.Examples of Transcription \u0026 Summaries from Dovetail. Source: NN/gHowever, interpreting participant behavior, understanding nuances in communication, and recognizing diverse perspectives still greatly rely on human expertise. AI serves as a tool for initial synthesis and as a point of comparison, but humans are indispensable in making sense of the human experience.Data generation: Using AI to generate qualitative data, such as having AI simulate human responses, can jeopardize the integrity of research by misrepresenting authentic experiences.That said, there are cases where AI-generated responses can enhance research outcomes. For instance, immersive AI avatars have been used effectively in healthcare provider (HCP) market research to elevate engagement and provide richer insights, offering a viable alternative in specific contexts (How we elevated HCP market research engagement and insights using AI avatars for an immersive experience — Research Partnership).Source: ResearchPartnershipBy leveraging AI as a complement to human expertise, we can enhance efficiency and scalability without compromising the depth and integrity of research. The key is intentionality — using AI where it excels while relying on human strengths to truly understand and connect with people.Strategy #2: Contextually and culturally-aware implementationHuman diversity is central to effective cross-cultural research and design, and understanding the differences between individuals, their daily contexts, and broader sociocultural environments is key to generating meaningful insights. This same principle applies to the thoughtful integration of AI into practices and workflows.AI implementation should be deliberate and context-sensitive, with careful consideration of when and how AI is the right tool for the task. Context plays a pivotal role in determining whether AI enhances or detracts from the goals of a given project. Tailoring AI strategies to align with cultural nuances, environmental factors, and user needs ensures that technology complements, rather than complicates, the work at hand. For example:Building rapport: If establishing trust and encouraging participants to open up about sensitive topics is essential, AI may not be the best fit.Anonymity preferences: In contrast, participants may prefer the perceived neutrality and anonymity of an AI moderator when discussing highly personal or taboo subjects.Cultural perceptions: In Western Europe, heightened concerns about AI and data privacy influence how AI is received and used, requiring careful consideration of tools and methods (Will the EU AI Act work? Lessons learned from past legislative initiatives, future challenges | IAPP \u0026 How concerned are Europeans about their personal data online? | European Union Agency for Fundamental Rights).Social dynamics: In Brazil, where authentic social connections are highly valued, human-to-human interaction may be preferred for meaningful engagement (How to Apply Cultural Knowledge in Your Brazilian Localization Strategy).Research goals: For tactical questions or high-level sentiment analysis, AI can effectively identify trends and major pain points. For deeper explorations of complex motivations or mental models, human-led research is often more appropriate.When implementing AI, it’s essential to stay well-informed about the tool’s capabilities and limitations, including its context windows and potential blind spots. Organizations designing AI products should prioritize localization and enhanced context sensitivity to ensure these tools address diverse human needs effectively.By thoughtfully balancing human expertise with AI-driven methods, it’s possible to create solutions that honor cultural uniqueness while leveraging technology to deepen understanding and foster meaningful connections.Strategy #3: Privacy and consent practicesEffective AI implementation requires balancing innovation with robust privacy and consent practices. Popular AI platforms often retain data input to train their tools, raising concerns about confidentiality and data security.Zoom subtly updated their terms of service in March, 2023, leading to a backlash and then backpedaling and clarification in August:Thread source on XTo address these risks, organizations should establish clear policies to safeguard sensitive information, including personally identifiable information (PII) and proprietary data (Can GPT-4o Be Trusted With Your Private Data? | WIRED). These should be shared openly and in advance. Practices like anonymization and secure data storage can help minimize risks from the outset. For organizations seeking greater control, developing proprietary AI models is an option worth exploring.Transparency is a cornerstone of effective privacy and consent practices. Providing research participants with detailed information about AI use in consent forms and participation materials enables them to make fully informed decisions about how their data is handled. Encouraging team members to share questions or concerns about AI tools fosters a culture of open dialogue and ethical accountability, ensuring that privacy practices stay aligned with both internal values and external expectations.Additionally, applying user experience (UX) and human-centered design principles to AI technologies can make privacy and security features more transparent, accessible, and empowering. This ensures that consent goes beyond a checkbox to become a meaningful and informed part of the user experience (The AI Consent Conundrum: Do We Truly Understand What We Agree To? | by Neria Sebastien, EdD | Medium).By adopting these strategies, organizations can align their AI practices with both ethical standards and user expectations, creating tools and systems that promote trust and human flourishing.Strategy #4: Ongoing AI training \u0026 discussionAs AI evolves rapidly, staying informed, critically evaluating its capabilities, and understanding its impact are essential for leveraging its full potential. A team-based approach to AI training encourages shared learning and open discussions about its possibilities and limitations. This not only helps refine policies and address concerns but also fosters innovation as the technology progresses.Effective AI strategies involve tackling key topics such as maintaining non-disclosure and data privacy requirements while using AI, reviewing outputs to identify and mitigate bias or misinformation, and finding ways to enhance efficiency and effectiveness. These conversations are vital for ensuring that AI is used responsibly and productively.A human-first philosophy should guide these efforts.Organizations should regularly assess AI’s impact not only on participants, consumers, and clients but also on internal teams.The aim is to ensure AI supports meaningful work — allowing people to build new skills, refine creative and critical thinking, and stay engaged in tasks that are both purposeful and impactful. AI should empower teams to feel more efficient and effective while safeguarding their sense of purpose (Finding Meaningful Work in the Age of AI | LinkedIn).AI training and policies must remain flexible and adaptable. As technology evolves or reveals limitations, organizations should be prepared to recalibrate their approach, ensuring that human values remain at the center of innovation. By embracing this mindset, businesses can harness AI’s potential while ensuring it serves people first.AI and opportunities to promote flourishingWhile this article has primarily focused on the ways AI challenges human flourishing and the strategies we, as researchers and designers, use to mitigate these risks, it’s equally important to recognize AI’s potential to promote flourishing.When developed and applied with the specific aim of enhancing human lives, AI can paradoxically address even those areas where it poses the greatest risks, transforming them into opportunities for growth and well-being. Here are a few ways we’re excited about AI contributing to human flourishing:Inclusive and accessible products: AI has the power to make products more inclusive and accessible by collaborating with diverse users and understanding their needs. When designed thoughtfully, AI can personalize experiences to adapt to individual abilities, preferences, and identities (How Artificial General Intelligence Could Redefine Accessibility).For instance, AI-powered voice assistants can be trained to recognize diverse speech patterns, accents, and variations, breaking down communication barriers and fostering a sense of belonging for all users (Voice-activated Devices: AI’s Epic Role in Speech Recognition).Automating low-level tasks and assisting with complex ones: AI can strategically automate repetitive and unfulfilling tasks, freeing people to focus on creative, meaningful, or strategic activities. By reducing human error and alleviating mental and physical stress, AI helps protect our sense of purpose and enhances productivity (The Ultimate Guide To Using (or Avoiding) AI At Work).Conversely, AI can also act as a creative assistant for more complex, cognitively demanding tasks, such as brainstorming, design, writing, and art creation. By broadening our thinking and inspiring new possibilities, AI supports higher-level cognitive work and innovation (Creativity was another of ChatGPT’s conquests. Here’s why it’s more computable than we think. | by Paul Pallaghy, PhD | Medium).Insights for positive behavior change: AI-powered analytics can identify patterns in behavior and generate actionable insights to encourage positive changes. For example, these insights can help improve products designed for health and education, empowering individuals to achieve their goals more effectively and efficiently.How are Machine Learning and Artificial Intelligence Used in Digital Behavior Change Interventions? A Scoping Review — Mayo Clinic Proceedings: Digital HealthCSRWire — A Bridge to Success: Using AI To Raise the Bar in Special EducationEnhanced data privacy and security: AI has the potential to improve data privacy and security through advanced capabilities such as anomaly detection, encryption, and access control management. Technologies like differential privacy and federated learning allow for valuable insights to be drawn from data while maintaining safeguards to protect sensitive information. These tools, when implemented conscientiously, can create systems that prioritize the privacy and security of research participants and clients.Generative AI \u0026 Data Security: 5 Ways to Boost Cybersecurity | BigIDAre Data Privacy And Generative AI Mutually Exclusive?What is federated learning? — IBM ResearchHowever, it’s important to acknowledge the inherent risks and challenges. The data-hungry nature of AI training often incentivizes excessive data collection, which can conflict with privacy objectives. Additionally, the complexity of AI systems sometimes makes it difficult to ensure that privacy protections are upheld consistently across applications. As a result, the risks associated with AI’s use in privacy-sensitive contexts often outweigh the potential benefits unless organizations approach implementation with exceptional care and transparency.This dual perspective highlights the need for cautious optimism. While AI can enhance privacy in theory, realizing these benefits in practice requires prioritizing ethical design, robust regulation, and a commitment to limiting data use to what is strictly necessary. By balancing these considerations, organizations can mitigate risks and responsibly explore AI’s potential for improving data security.Checking bias: AI can act as a “gut check” or an additional data point to help illuminate biases or blind spots in human decision-making when it is developed to be inclusive and address bias from the start. When trained on diverse datasets, AI tools can provide thoughtful recommendations, offering value in contexts ranging from product development to broader decision-making processes.Can the Bias in Algorithms Help Us See Our Own? | The Brink | Boston UniversityHow AI can end bias | SAPBridging cultural divides: While AI still has a long way to go in context sensitivity, its capabilities in real-time language translation and diverse content promotion are already helping bridge cultural and community barriers. For example, AI can enable more inclusive international research and create richer digital experiences that celebrate global diversity.By intentionally designing AI to prioritize accessibility, security, and cultural sensitivity, we can harness its immense potential to foster connection, creativity, and well-being, ultimately driving human flourishing in ways that matter most.Bridging Cultural Divides: AI in Global Content Strategy | by Phan Nython | MediumThe Role of AI in Bridging Cultural Gaps within Remote TeamsBuild Cross-Cultural Bridges, Not Barriers, With AIConcluding thoughts \u0026 next stepsAI is a moving target, evolving rapidly in ways that challenge and inspire. As researchers, designers, and technologists, we have a unique responsibility to approach AI critically — assessing how it both promotes and threatens human flourishing. With regulation, governance, and accountability structures still taking shape, our vigilance and ethical commitment are more important than ever.To ensure AI enhances rather than detracts from human flourishing, here are a few actionable steps:Apply a human-first lens: Continuously evaluate how AI tools align with values like inclusivity, transparency, and ethical responsibility.Balance AI with human expertise: Leverage AI’s strengths while retaining the depth, empathy, and nuance that only humans can bring. You may have heard of this as keeping a, \"Human in the loop.\"Foster open dialogue: Share learnings and raise concerns within your teams and professional communities to shape better practices collectively.Explore the resources and appendix: Dig deeper into the resources referenced throughout this article and the extensive Appendix that follows to expand your understanding and spark new ideas.Advocate for responsible AI: Push for thoughtful regulation and design that centers human well-being at every level.Engage in conversation: Talk to your colleagues and friends. Talk to your manager. Talk to your clients. You can even talk to me. Whether you’re seeking practical insights, curious about integrating these strategies, or just exploring the topic in a collaborative way… conversing with others will bring these ideas to the forefront and keep us all moving forward in a human-centered way.As researchers and designers shaping the products billions of people use daily, we hold the power to keep humans at the heart of this technology.By being intentional, we can ensure AI evolves into a force that uplifts and empowers, rather than one that diminishes or divides.Huge thank you to my colleagues Katie Trocin and LaToya Tufts for the lit review, content development, editing, and discussion that lead to the creation of this article.Josh LaMar is the Co-Founder and CEO of Amplinate, an international agency focusing on cross-cultural Research \u0026 Design, based in the USA, France, Brazil, and India. As the Chief Strategy Officer of JoshLaMar Consult, he helps Entrepreneurs grow their business through ethical competitive advantage.Appendix: References and ResourcesHuman Flourishing FrameworksSocial Ecological FrameworkThe Ecology of WellbeingMeasuring Flourishing | HarvardAuthentic Happiness | PennPhilosophies of HappinessOn the promotion of human flourishing | PNASRethinking flourishing: Critical insights and qualitative perspectives from the U.S. Midwest — PMC (nih.gov)Measures of Community Well-Being: a Template (springer.com)Flourish: A Visionary New Understanding of Happiness and Well-beingRadically Human Technology: Enhancing Connection and Wellbeing (Or Finding your Ikigai Kairos ) | by Nichol Bradford | Transformative Technology | MediumTHE 17 GOALS | Sustainable Development (un.org)Universal Declaration of Human Rights — Amnesty InternationalAyurveda’s Edge Over Western Psychology (bwwellbeingworld.com)AI RisksAI Risks that Could Lead to Catastrophe | CAIS (safe.ai)The AI Risk Repository (mit.edu)Limitations of AIWhat Are the Limitations of AI in Understanding Context in Text? — Space Coast DailyThe Context Problem in Artificial Intelligence — Communications of the ACMWhat is a context window?The AI Summarization Dilemma: When Good Enough Isn’t Enough: Center for Advancing Safety of Machine Intelligence — Northwestern UniversityAI’s dark secret: It’s rolling back progress on equality | ContextWe Must Fix the Lack of Transparency Around the Data Used to Train Foundation Models · Special Issue 5: Grappling With the Generative AI RevolutionTransparency is sorely lacking amid growing AI interest | ZDNETBias in AIBattling Bias in AIWhen AI Gets It Wrong: Addressing AI Hallucinations and Bias — MIT Sloan Teaching \u0026 Learning TechnologiesThere’s More to AI Bias Than Biased Data, NIST Report Highlights | NISTEliminating Algorithmic Bias Is Just the Beginning of Equitable AI (hbr.org)Can the Bias in Algorithms Help Us See Our Own? | The Brink | Boston UniversityHow AI can end bias | SAPStrategy 1: ComplementAccelerating Research with AI | NN/gHow we elevated HCP market research engagement and insights using AI avatars for an immersive experience — Research PartnershipStrategy 2: Contextually AwareWill the EU AI Act work? Lessons learned from past legislative initiatives, future challenges | IAPPHow concerned are Europeans about their personal data online? | European Union Agency for Fundamental RightsHow to Apply Cultural Knowledge in Your Brazilian Localization StrategyStrategy 3: Privacy \u0026 ConsentCan GPT-4o Be Trusted With Your Private Data? | WIREDThe AI Consent Conundrum: Do We Truly Understand What We Agree To? | by Neria Sebastien, EdD | MediumStrategy 4: Ongoing TrainingFinding Meaningful Work in the Age of AI | LinkedInOpportunitiesHow Artificial General Intelligence Could Redefine AccessibilityVoice-activated Devices: AI’s Epic Role in Speech RecognitionThe Ultimate Guide To Using (or Avoiding) AI At WorkCreativity was another of ChatGPT’s conquests. Here’s why it’s more computable than we think. | by Paul Pallaghy, PhD | MediumHow are Machine Learning and Artificial Intelligence Used in Digital Behavior Change Interventions? A Scoping Review — Mayo Clinic Proceedings: Digital HealthCSRWire — A Bridge to Success: Using AI To Raise the Bar in Special EducationGenerative AI \u0026 Data Security: 5 Ways to Boost Cybersecurity | BigIDAre Data Privacy And Generative AI Mutually Exclusive?What is federated learning? — IBM ResearchCan the Bias in Algorithms Help Us See Our Own? | The Brink | Boston UniversityHow AI can end bias | SAPBridging Cultural Divides: AI in Global Content Strategy | by Phan Nython | MediumThe Role of AI in Bridging Cultural Gaps within Remote TeamsBuild Cross-Cultural Bridges, Not Barriers, With AIAI Failures9 AI fails (and how they could have been prevented)12 famous AI disasters16 biggest AI Fails17 Screenshots Of AI Fails That Range From Hilarious To Mildly Terrifyingr/aifails | Reddit",
  "image": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*Jnd0VPa-zfq55uxi",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"2d31\" aria-label=\"kicker paragraph\"\u003eTECHNOLOGY \u0026amp; CULTURE\u003c/h2\u003e\u003cdiv\u003e\u003ch2 id=\"73a2\"\u003eChallenges, strategies, \u0026amp; opportunities.\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@joshlamar?source=post_page---byline--b456b1de31c7--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Josh LaMar\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*t3S5vjW_kad0OgZTsigYLQ.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--b456b1de31c7--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cfigure\u003e\u003cfigcaption\u003eCredit: \u003ca href=\"https://x.com/marketoonist\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMarketoonist\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"5fa2\"\u003e\u003cspan\u003eT\u003c/span\u003ehe explosion of AI over the past two years, particularly generative AI and large language models (LLMs), has reshaped much of how we work and think about technology. For user researcher and designers, AI’s impact can be grouped into three broad areas:\u003c/p\u003e\u003col\u003e\u003cli id=\"fbf6\"\u003e\u003cstrong\u003eGenerative AI product development\u003c/strong\u003e: The topics and challenges explored in research and design projects as we seek to best implement AI into new products and services.\u003c/li\u003e\u003cli id=\"5409\"\u003e\u003cstrong\u003eInternal processes\u003c/strong\u003e: Systems and workflows within the workplace leveraging AI to enhance efficiency and insight as we work together to build AI-leveraged products and services.\u003c/li\u003e\u003cli id=\"3fe9\"\u003e\u003cstrong\u003ePersonal practices and training\u003c/strong\u003e: Individual use of AI to augment skills and productivity.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"2112\"\u003eWhile AI offers immense potential to accelerate and enhance product design, it’s critical to approach it with a balanced perspective. Alongside its benefits, AI presents potential harms and negative impacts that demand careful consideration.\u003c/p\u003e\u003cp id=\"d988\"\u003eAs this transition is happening, many of us are asking ourselves how we can approach AI in a human-centered way. Some of the key questions to guide responsible AI integration include:\u003c/p\u003e\u003cul\u003e\u003cli id=\"d7b8\"\u003eHow can organizations advocate for the development of AI technologies that prioritize human well-being in their products and services?\u003c/li\u003e\u003cli id=\"caa8\"\u003eWhat strategies ensure AI can be leveraged responsibly while centering human needs during research, analysis, design, and the software development process?\u003c/li\u003e\u003cli id=\"ea0d\"\u003eHow can authentic human experiences be validated within a landscape increasingly shaped by artificial content?\u003c/li\u003e\u003cli id=\"fb1e\"\u003eWhat day-to-day practices can researchers and designers adopt to maintain a balanced, human-centered approach to AI?\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"46a9\"\u003eAnd most importantly:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"408f\"\u003eHow can researchers and designers learn, grow, and adapt while AI technology is evolving faster and faster?\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"307c\"\u003eIn this article, I will attempt to answer these questions by revisiting foundational concepts of human flourishing, reflecting on organizational values, and synthesizing diverse perspectives from professional communities and academic literature.\u003c/p\u003e\u003cp id=\"5011\"\u003eThe goal is to help us all develop best practices for AI use that align with both ethical standards and business goals.\u003c/p\u003e\u003cp id=\"7081\"\u003eAnd keep the human \u003cem\u003ecentered\u003c/em\u003e in the loop.\u003c/p\u003e\u003ch2 id=\"e448\"\u003e\u003cstrong\u003eA human-first approach\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"db34\"\u003eAdopting a human-first approach provides a strong foundation for ethical and effective AI use. At its core, this philosophy emphasizes serving and empowering people through empathy, authenticity, and a commitment to collective well-being.\u003c/p\u003e\u003cp id=\"b8b9\"\u003eI think of Human-First as humans serving humans. Every decision, every interaction is grounded in empathy, authenticity, and the acknowledgment of our collective humanity. We take care of ourselves and keep the health of others in mind. We create space when needed.\u003c/p\u003e\u003cp id=\"8ce1\"\u003eTaking the core concepts of human flourishing as identified by academics and applied practitioners, (See Appendix, below, for complete list of frameworks) practitioners and organizations that embrace a human-first mindset define their values around these core principles:\u003c/p\u003e\u003cul\u003e\u003cli id=\"29aa\"\u003e\u003cstrong\u003ePurpose and Contribution\u003c/strong\u003e: Supporting work that feels meaningful and impactful.\u003c/li\u003e\u003cli id=\"6dc5\"\u003e\u003cstrong\u003ePersonal Growth and Agency\u003c/strong\u003e: Encouraging self-determination and skill development.\u003c/li\u003e\u003cli id=\"0b87\"\u003e\u003cstrong\u003eHolistic Well-Being\u003c/strong\u003e: Addressing physical, mental, social, and other dimensions of health.\u003c/li\u003e\u003cli id=\"4367\"\u003e\u003cstrong\u003eEthical Living\u003c/strong\u003e: Ensuring actions align with moral values and promote harmony.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"6eac\"\u003eA holistic view of human flourishing considers the individual, structural, systemic, and environmental levels to create sustainable, people-centered solutions.\u003c/p\u003e\u003cp id=\"01db\"\u003eInterdisciplinary and cross-cultural frameworks (e.g., the \u003ca href=\"https://www.researchgate.net/figure/Social-ecological-framework-for-measuring-human-flourishing-reproduced-with-permission_fig1_233828994\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSocial Ecological Framework\u003c/a\u003e, \u003ca href=\"https://www.flourishproject.net/uploads/1/8/4/9/1849450/introducing_the_flourish_model__optimized_.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Ecology of Wellbeing\u003c/a\u003e, \u0026amp; \u003ca href=\"https://hfh.fas.harvard.edu/measuring-flourishing\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMeasuring Flourishing | Harvard\u003c/a\u003e), can be applied to aide us in decision-making.\u003c/p\u003e\u003cp id=\"2284\"\u003eBy rooting AI practices in these values, researchers, designers, and organizations can better navigate challenges to human flourishing in research and design. This foundation sets the stage for addressing specific AI-related concerns while advancing the shared goal of creating technologies that truly serve humanity.\u003c/p\u003e\u003cp id=\"9b63\"\u003eIt is in this context that we next identify AI-related challenges to human flourishing in the context of UX Research and Design.\u003c/p\u003e\u003ch2 id=\"8d2f\"\u003eAI challenges to human flourishing and lessons learned\u003c/h2\u003e\u003cp id=\"cdd3\"\u003eThe more I experiment with AI tools while also conducting research and consulting with companies building generative AI-based tools, the more I can see the limitations of how AI can detract from human flourishing.\u003c/p\u003e\u003cp id=\"4a9a\"\u003eWhile societal concerns surrounding AI are vast and complex, (See AI Risks in Appendix, below), this discussion focuses on challenges most relevant to day-to-day experience of user experience (UX) and design research work.\u003c/p\u003e\u003cp id=\"35a3\"\u003eThrough personal (and team) experience and reviewing articles and perspectives, we have identified four key characteristics of AI as particularly threatening to human flourishing:\u003c/p\u003e\u003ch2 id=\"d703\"\u003e1. Oversimplification\u003c/h2\u003e\u003cp id=\"f2ea\"\u003eAI’s limited ability to detect and adapt to complex, changing contexts can lead to oversimplification of human behavior and realities, culturally or situationally inappropriate insights and output, and \u003cstrong\u003eperpetuation of systemic inequities\u003c/strong\u003e and injustices.\u003c/p\u003e\u003cp id=\"ee7d\"\u003eFrequent users of AI tools have likely had an experience with AI output that isn’t quite what you were looking for. In those moments, it feels like AI isn’t gleaning the intent behind your question. Sometimes even the most well-crafted prompt isn’t enough to overcome this barrier.\u003c/p\u003e\u003cp id=\"43b5\"\u003eAI models often struggle to fully understand and adapt to contextual nuances, particularly in complex or dynamic environments where human interpretation is key. It falls short in fully grasping the subtleties of human communication, including tone, cultural references, and implied meanings, as well as sussing out potential motivations or explanations for human behavior and phenomena (\u003ca href=\"https://spacecoastdaily.com/2024/02/what-are-the-limitations-of-ai-in-understanding-context-in-text/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhat Are the Limitations of AI in Understanding Context in Text? — Space Coast Daily\u003c/a\u003e \u0026amp; \u003ca href=\"https://cacm.acm.org/opinion/the-context-problem-in-artificial-intelligence/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Context Problem in Artificial Intelligence — Communications of the ACM\u003c/a\u003e).\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"e38a\"\u003eAs it relies on predefined rules and training data, it can fail to factor in social, cultural, systemic, and environmental influences out of purview.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"1da1\"\u003eThese characteristics limit AI’s responsible utilization in research across contexts, cultures, and in novel situations, and when completing tasks that require high-stakes or creative problem-solving.\u003c/p\u003e\u003cp id=\"8fce\"\u003eResearch and design often involve making sense of a complex interplay of user and contextual factors that combine to drive behavior or shape an experience — and it seems that AI tools are not yet advanced enough to appropriately capture and process this complexity.\u003c/p\u003e\u003cp id=\"af54\"\u003eNot all generative AI tools are the same and having awareness about each product’s context windows ensures we’re realistic about to what extent the tool can help us center humanness in research and design (\u003ca href=\"https://www.techtarget.com/whatis/definition/context-window\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhat is a context window?\u003c/a\u003e).\u003c/p\u003e\u003ch2 id=\"ef95\"\u003e2. Propensity to generalize\u003c/h2\u003e\u003cp id=\"ccfb\"\u003eAI’s tendency to summarize and generalize poses a risk to the representation of diverse human experiences and inclusivity. While AI excels at processing large datasets to identify common patterns and deliver efficient summaries, this strength can become a limitation when it oversimplifies nuanced perspectives or excludes less common experiences.\u003c/p\u003e\u003cp id=\"24ab\"\u003eFor example, AI-powered search engines highlight the most popular answers but may exclude context-specific insights, leading to incomplete or biased conclusions (\u003ca href=\"https://casmi.northwestern.edu/news/articles/2024/the-ai-summarization-dilemma-when-good-enough-isnt-enough.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe AI Summarization Dilemma: When Good Enough Isn’t Enough: Center for Advancing Safety of Machine Intelligence — Northwestern University\u003c/a\u003e \u0026amp; \u003ca href=\"https://www.context.news/ai/opinion/ais-dark-secret-its-rolling-back-progress-on-equality\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAI’s dark secret: It’s rolling back progress on equality | Context\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"786b\"\u003eSimilarly, relying solely on AI for research analysis can result in a surface-level understanding of the average. AI analysis may lead to the full spectrum of participant responses not being considered, ignoring minority perspectives, and creating exclusive products or experiences.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"d609\"\u003eThere are times in analysis where you want to understand the broad themes — but there are also times where it\u0026#39;s important to understand individual nuances.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"e5b5\"\u003eThese limitations are particularly dangerous when researching diverse populations or designing solutions that require high degrees of sensitivity and nuance. Indeed, as we’ve experimented with AI tools for research and analysis, we have found outputs to be inadequate and potentially misleading, and we find ourselves needing to reintegrate human subtleties and dive deeper into oversimplified insights.\u003c/p\u003e\u003ch2 id=\"e15e\"\u003e3. Lack of transparency\u003c/h2\u003e\u003cp id=\"3968\"\u003eAI tools’ lack of transparency and data privacy guardrails can infringe on our basic human right to privacy and decrease our sense of agency to choose our relationship with technology.\u003c/p\u003e\u003cp id=\"6bcc\"\u003eDespite efforts to improve transparency and develop privacy-centric AI, using AI often still feels like working with a “black box” — with users still missing deep understanding of how AI processes their data and clear, succinct explanations of privacy practices (\u003ca href=\"https://hdsr.mitpress.mit.edu/pub/xau9dza3/release/2\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWe Must Fix the Lack of Transparency Around the Data Used to Train Foundation Models · Special Issue 5: Grappling With the Generative AI Revolution\u003c/a\u003e \u0026amp; \u003ca href=\"https://www.zdnet.com/article/transparency-is-sorely-lacking-amid-growing-ai-interest/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTransparency is sorely lacking amid growing AI interest | ZDNET\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"741b\"\u003eThis has implications as we use AI to collect and analyze data from people and as we try to develop AI-powered products that promote consent, agency, and empowerment.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"f1d8\"\u003eAs researchers and designers, we have a duty to protect personally identifiable information (PII) of research participants and the intellectual property of our clients.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"7d7a\"\u003eWe have a responsibility to ensure that our research participants have the power to consent to how their data is used and to our consumers to create products and experiences that do not lead to privacy breaches and data exploitation. In our experience, when using popular AI tools to their full functionality, we cannot guarantee those protections will be upheld.\u003c/p\u003e\u003ch2 id=\"eaeb\"\u003e4. AI isn\u0026#39;t aware of its\u0026#39; own bias\u003c/h2\u003e\u003cp id=\"0091\"\u003eAI’s tendency to reproduce bias and generate inaccurate output can exacerbate existing social inequalities and creates threats to informed decision-making.\u003c/p\u003e\u003cp id=\"f767\"\u003eFor example, the UK passport photo checker showed bias towards women and darker-skinned people:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://www.bbc.co.uk/news/technology-54349538.amp\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://www.bbc.co.uk/news/technology-54349538.amp\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"a156\"\u003eThe tendency for AI tools to perpetuate and exacerbate human biases present in their training data is probably the most commonly discussed threat of AI, so we won’t discuss this issue in depth here (\u003ca href=\"https://stories.camden.rutgers.edu/battling-bias-in-ai/index.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBattling Bias in AI\u003c/a\u003e).\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"d960\"\u003eBias can lead to discriminatory experiences for research participants, skewed insights, narrowed scope of potential design directions, and designs that cater to hegemonic identities and majority user groups.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"7f73\"\u003e\u003cstrong\u003eHallucinations: \u003c/strong\u003eBeyond biased output, there is the potential for hallucinations which produce nonexistent or inaccurate outputs (\u003ca href=\"https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhen AI Gets It Wrong: Addressing AI Hallucinations and Bias — MIT Sloan Teaching \u0026amp; Learning Technologies\u003c/a\u003e). This misinformation could affect research and product decisions in major ways.\u003c/p\u003e\u003cp id=\"d2a8\"\u003eIn another example, Air Canada\u0026#39;s chatbot lied to a passenger about bereavement fares but the customer later won the case:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"edb0\"\u003eThe passenger claimed to have been misled on the airline’s rules for bereavement fares when the chatbot hallucinated an answer inconsistent with airline policy. The Tribunal in Canada’s small claims court found the passenger was right and awarded them $812.02 in damages and court fees… the court found Air Canada failed to explain why the passenger should not trust information provided on its website by its chatbot. \u003ca href=\"https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSource: Forbes\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"61f1\"\u003eWhile being aware that generative AI products can produced biased or inaccurate information is a good first step, we feel there is still unmet need for transparency and diversification of training datasets and extensive training on critical evaluation of AI output. AI must be leveraged judiciously and always in service of human-centered needs.\u003c/p\u003e\u003ch2 id=\"34c4\"\u003eAddressing threats to human flourishing\u003c/h2\u003e\u003cp id=\"fe2f\"\u003eAs we advance our use of AI, we must remain committed to prioritizing the human experience and fostering the well-being of our colleagues, research participants, clients, and the customers who use the products we help create.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"71cc\"\u003eTechnology should contribute to the well-being, growth, and fulfillment of people and their communities.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"bace\"\u003eAddressing the four challenges discussed above, here are four strategies to combat the limitations.\u003c/p\u003e\u003ch2 id=\"2c65\"\u003eStrategy #1: AI as a complement, not a replacement\u003c/h2\u003e\u003cp id=\"2d85\"\u003eAI has proven to be a powerful tool in research, but its greatest potential lies in complementing, not replacing, human expertise. Understanding where AI excels and where humans bring unique value allows us to strike the right balance.\u003c/p\u003e\u003cp id=\"d79c\"\u003e\u003cstrong\u003eWhere AI shines:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"b3c5\"\u003e\u003cstrong\u003eProcessing large data sets\u003c/strong\u003e: AI’s computational power allows it to analyze vast amounts of data far faster than humans, making it an indispensable tool for pattern recognition and large-scale analysis.\u003c/li\u003e\u003cli id=\"beb7\"\u003e\u003cstrong\u003eGenerating initial ideas\u003c/strong\u003e: AI is excellent at sparking brainstorming by presenting diverse, unbiased possibilities, which can help overcome creative blocks.\u003c/li\u003e\u003cli id=\"0e32\"\u003e\u003cstrong\u003eRecognizing patterns\u003c/strong\u003e: AI’s pattern-recognition capabilities are unmatched for identifying trends and correlations across datasets.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"8d45\"\u003e\u003cstrong\u003eWhere humans shine:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"3531\"\u003e\u003cstrong\u003eEmpathy and connection\u003c/strong\u003e: These are foundational to qualitative research. Building trust, reading body language, and engaging authentically are uniquely human abilities that technology cannot replicate.\u003c/li\u003e\u003cli id=\"067f\"\u003e\u003cstrong\u003eUnderstanding complex contexts\u003c/strong\u003e: Humans excel at synthesizing subtle, multifaceted information that may not fit neatly into patterns.\u003c/li\u003e\u003cli id=\"91fb\"\u003e\u003cstrong\u003eEthical and contextual judgment\u003c/strong\u003e: Humans bring cultural and moral considerations into decision-making, ensuring sensitivity and appropriateness.\u003c/li\u003e\u003cli id=\"a39c\"\u003e\u003cstrong\u003eUnique insights\u003c/strong\u003e: The creativity and contextual understanding required for truly novel insights remain human strengths.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"fc16\"\u003e\u003cstrong\u003eStriking the right balance\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"50a3\"\u003e\u003cstrong\u003eData collection: \u003c/strong\u003eAI can enhance efficiency in data collection when used intentionally. For example, it can assist with participant screening during recruitment, but researcher oversight ensures quality and appropriateness. Human moderation remains indispensable for creating connection, fostering empathy, and understanding participants deeply.\u003c/p\u003e\u003cp id=\"3904\"\u003eWhile AI moderation is effective for executing qualitative research quickly and at scale (\u003ca href=\"https://www.nngroup.com/articles/research-with-ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAccelerating Research with AI\u003c/a\u003e), it cannot replicate the depth of human engagement.\u003c/p\u003e\u003cp id=\"c7cf\"\u003e\u003cstrong\u003eData analysis: \u003c/strong\u003eIn analysis, AI can be valuable for identifying major themes and aiding qualitative data coding, providing researchers with a head start. Transcriptions alone are a great start. When it comes to summaries, most tools I\u0026#39;ve tried are ok at this, but the future promise is there.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eExamples of Transcription \u0026amp; Summaries from Dovetail. \u003ca href=\"https://www.nngroup.com/articles/research-with-ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSource: NN/g\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"21b7\"\u003eHowever, interpreting participant behavior, understanding nuances in communication, and recognizing diverse perspectives still greatly rely on human expertise. AI serves as a tool for initial synthesis and as a point of comparison, but humans are indispensable in making sense of the human experience.\u003c/p\u003e\u003cp id=\"9dbc\"\u003e\u003cstrong\u003eData generation: \u003c/strong\u003eUsing AI to generate qualitative data, such as having AI simulate human responses, can jeopardize the integrity of research by misrepresenting authentic experiences.\u003c/p\u003e\u003cp id=\"4440\"\u003eThat said, there are cases where AI-generated responses can enhance research outcomes. For instance, immersive AI avatars have been used effectively in healthcare provider (HCP) market research to elevate engagement and provide richer insights, offering a viable alternative in specific contexts (\u003ca href=\"https://www.researchpartnership.com/insights/how-we-elevated-hcp-market-research-engagement-and-insights-using-ai-avatars-for-an-immersive-experience/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow we elevated HCP market research engagement and insights using AI avatars for an immersive experience — Research Partnership\u003c/a\u003e).\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eSource: \u003ca href=\"https://www.researchpartnership.com/insights/how-we-elevated-hcp-market-research-engagement-and-insights-using-ai-avatars-for-an-immersive-experience/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eResearchPartnership\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"5636\"\u003eBy leveraging AI as a complement to human expertise, we can enhance efficiency and scalability without compromising the depth and integrity of research. The key is intentionality — using AI where it excels while relying on human strengths to truly understand and connect with people.\u003c/p\u003e\u003ch2 id=\"7aeb\"\u003eStrategy #2: Contextually and culturally-aware implementation\u003c/h2\u003e\u003cp id=\"fa29\"\u003eHuman diversity is central to effective cross-cultural research and design, and understanding the differences between individuals, their daily contexts, and broader sociocultural environments is key to generating meaningful insights. This same principle applies to the thoughtful integration of AI into practices and workflows.\u003c/p\u003e\u003cp id=\"5639\"\u003eAI implementation should be deliberate and context-sensitive, with careful consideration of when and how AI is the right tool for the task. Context plays a pivotal role in determining whether AI enhances or detracts from the goals of a given project. Tailoring AI strategies to align with cultural nuances, environmental factors, and user needs ensures that technology complements, rather than complicates, the work at hand. For example:\u003c/p\u003e\u003cul\u003e\u003cli id=\"4688\"\u003e\u003cstrong\u003eBuilding rapport\u003c/strong\u003e: If establishing trust and encouraging participants to open up about sensitive topics is essential, AI may not be the best fit.\u003c/li\u003e\u003cli id=\"81c0\"\u003e\u003cstrong\u003eAnonymity preferences\u003c/strong\u003e: In contrast, participants may prefer the perceived neutrality and anonymity of an AI moderator when discussing highly personal or taboo subjects.\u003c/li\u003e\u003cli id=\"0984\"\u003e\u003cstrong\u003eCultural perceptions\u003c/strong\u003e: In Western Europe, heightened concerns about AI and data privacy influence how AI is received and used, requiring careful consideration of tools and methods (\u003ca href=\"https://iapp.org/news/a/will-the-eu-ai-act-work-lessons-learned-from-past-legislative-initiatives-future-challenges\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWill the EU AI Act work? Lessons learned from past legislative initiatives, future challenges | IAPP\u003c/a\u003e \u0026amp; \u003ca href=\"https://fra.europa.eu/en/news/2020/how-concerned-are-europeans-about-their-personal-data-online\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow concerned are Europeans about their personal data online? | European Union Agency for Fundamental Rights\u003c/a\u003e).\u003c/li\u003e\u003cli id=\"3016\"\u003e\u003cstrong\u003eSocial dynamics\u003c/strong\u003e: In Brazil, where authentic social connections are highly valued, human-to-human interaction may be preferred for meaningful engagement (\u003ca href=\"https://www.unitedlanguagegroup.com/blog/localization-strategy-guide-brazil\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow to Apply Cultural Knowledge in Your Brazilian Localization Strategy\u003c/a\u003e).\u003c/li\u003e\u003cli id=\"8bd2\"\u003e\u003cstrong\u003eResearch goals\u003c/strong\u003e: For tactical questions or high-level sentiment analysis, AI can effectively identify trends and major pain points. For deeper explorations of complex motivations or mental models, human-led research is often more appropriate.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"7bd3\"\u003eWhen implementing AI, it’s essential to stay well-informed about the tool’s capabilities and limitations, including its context windows and potential blind spots. Organizations designing AI products should prioritize localization and enhanced context sensitivity to ensure these tools address diverse human needs effectively.\u003c/p\u003e\u003cp id=\"0aac\"\u003eBy thoughtfully balancing human expertise with AI-driven methods, it’s possible to create solutions that honor cultural uniqueness while leveraging technology to deepen understanding and foster meaningful connections.\u003c/p\u003e\u003ch2 id=\"3251\"\u003eStrategy #3: Privacy and consent practices\u003c/h2\u003e\u003cp id=\"1e20\"\u003eEffective AI implementation requires balancing innovation with robust privacy and consent practices. Popular AI platforms often retain data input to train their tools, raising concerns about confidentiality and data security.\u003c/p\u003e\u003cp id=\"b91b\"\u003eZoom \u003ca href=\"https://www.rollingstone.com/culture/culture-news/zoom-ai-personl-data-1234802844/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esubtly updated their terms of service\u003c/a\u003e in March, 2023, leading to a backlash and then \u003ca href=\"https://www.theverge.com/2023/8/11/23828649/zoom-communications-like-data-train-ai-artificial-intelligence-models\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ebackpedaling and clarification\u003c/a\u003e in August:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://x.com/Zoom/status/1688624797066895361?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1688624797066895361%7Ctwgr%5Efd282dc7b71ba65727f4d82c8f89e1f715b81a75%7Ctwcon%5Es1_\u0026amp;ref_url=https%3A%2F%2Fwww.rollingstone.com%2Fculture%2Fculture-news%2Fzoom-ai-personl-data-1234802844%2F\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThread source on X\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"55dc\"\u003eTo address these risks, organizations should establish clear policies to safeguard sensitive information, including personally identifiable information (PII) and proprietary data (\u003ca href=\"https://www.wired.com/story/can-chatgpt-4o-be-trusted-with-your-private-data/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCan GPT-4o Be Trusted With Your Private Data? | WIRED\u003c/a\u003e). These should be shared openly and in advance. Practices like anonymization and secure data storage can help minimize risks from the outset. For organizations seeking greater control, developing proprietary AI models is an option worth exploring.\u003c/p\u003e\u003cp id=\"c1c3\"\u003eTransparency is a cornerstone of effective privacy and consent practices. Providing research participants with detailed information about AI use in consent forms and participation materials enables them to make fully informed decisions about how their data is handled. Encouraging team members to share questions or concerns about AI tools fosters a culture of open dialogue and ethical accountability, ensuring that privacy practices stay aligned with both internal values and external expectations.\u003c/p\u003e\u003cp id=\"a5fc\"\u003eAdditionally, applying user experience (UX) and human-centered design principles to AI technologies can make privacy and security features more transparent, accessible, and empowering. This ensures that consent goes beyond a checkbox to become a meaningful and informed part of the user experience (\u003ca href=\"https://medium.com/@neriasebastien/the-ai-consent-conundrum-do-we-truly-understand-what-we-agree-to-295201df823e\" rel=\"noopener\"\u003eThe AI Consent Conundrum: Do We Truly Understand What We Agree To? | by Neria Sebastien, EdD | Medium\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"f5d4\"\u003eBy adopting these strategies, organizations can align their AI practices with both ethical standards and user expectations, creating tools and systems that promote trust and human flourishing.\u003c/p\u003e\u003ch2 id=\"6d3f\"\u003eStrategy #4: Ongoing AI training \u0026amp; discussion\u003c/h2\u003e\u003cp id=\"a3bd\"\u003eAs AI evolves rapidly, staying informed, critically evaluating its capabilities, and understanding its impact are essential for leveraging its full potential. A team-based approach to AI training encourages shared learning and open discussions about its possibilities and limitations. This not only helps refine policies and address concerns but also fosters innovation as the technology progresses.\u003c/p\u003e\u003cp id=\"9dbe\"\u003eEffective AI strategies involve tackling key topics such as maintaining non-disclosure and data privacy requirements while using AI, reviewing outputs to identify and mitigate bias or misinformation, and finding ways to enhance efficiency and effectiveness. These conversations are vital for ensuring that AI is used responsibly and productively.\u003c/p\u003e\u003cp id=\"5c96\"\u003eA human-first philosophy should guide these efforts.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"fb9c\"\u003eOrganizations should regularly assess AI’s impact not only on participants, consumers, and clients but also on internal teams.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"ea4a\"\u003eThe aim is to ensure AI supports meaningful work — allowing people to build new skills, refine creative and critical thinking, and stay engaged in tasks that are both purposeful and impactful. AI should empower teams to feel more efficient and effective while safeguarding their sense of purpose (\u003ca href=\"https://www.linkedin.com/pulse/finding-meaningful-work-age-ai-stephanie-roberto-5hsnc/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFinding Meaningful Work in the Age of AI | LinkedIn\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"df82\"\u003eAI training and policies must remain flexible and adaptable. As technology evolves or reveals limitations, organizations should be prepared to recalibrate their approach, ensuring that human values remain at the center of innovation. By embracing this mindset, businesses can harness AI’s potential while ensuring it serves people first.\u003c/p\u003e\u003ch2 id=\"829f\"\u003eAI and opportunities to promote flourishing\u003c/h2\u003e\u003cp id=\"668d\"\u003eWhile this article has primarily focused on the ways AI challenges human flourishing and the strategies we, as researchers and designers, use to mitigate these risks, it’s equally important to recognize AI’s potential to promote flourishing.\u003c/p\u003e\u003cp id=\"6a73\"\u003eWhen developed and applied with the specific aim of enhancing human lives, AI can paradoxically address even those areas where it poses the greatest risks, transforming them into opportunities for growth and well-being. Here are a few ways we’re excited about AI contributing to human flourishing:\u003c/p\u003e\u003cp id=\"8195\"\u003e\u003cstrong\u003eInclusive and accessible products: \u003c/strong\u003eAI has the power to make products more inclusive and accessible by collaborating with diverse users and understanding their needs. When designed thoughtfully, AI can personalize experiences to adapt to individual abilities, preferences, and identities (\u003ca href=\"https://www.forbes.com/councils/forbesbusinesscouncil/2024/02/02/how-artificial-general-intelligence-could-redefine-accessibility/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow Artificial General Intelligence Could Redefine Accessibility\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"0639\"\u003eFor instance, AI-powered voice assistants can be trained to recognize diverse speech patterns, accents, and variations, breaking down communication barriers and fostering a sense of belonging for all users (\u003ca href=\"https://waywithwords.net/resource/voice-activated-devices-ai-speech/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eVoice-activated Devices: AI’s Epic Role in Speech Recognition\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"849b\"\u003e\u003cstrong\u003eAutomating low-level tasks and assisting with complex ones: \u003c/strong\u003eAI can strategically automate repetitive and unfulfilling tasks, freeing people to focus on creative, meaningful, or strategic activities. By reducing human error and alleviating mental and physical stress, AI helps protect our sense of purpose and enhances productivity (\u003ca href=\"https://stealthesethoughts.com/2024/11/26/the-ultimate-guide-to-using-or-avoiding-ai-at-work/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Ultimate Guide To Using (or Avoiding) AI At Work\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"bc5e\"\u003eConversely, AI can also act as a creative assistant for more complex, cognitively demanding tasks, such as brainstorming, design, writing, and art creation. By broadening our thinking and inspiring new possibilities, AI supports higher-level cognitive work and innovation (\u003ca href=\"https://medium.com/@paul.k.pallaghy/creativity-was-another-of-chatgpts-conquests-here-s-why-it-s-more-computable-than-we-think-fb1e9b382ab2\" rel=\"noopener\"\u003eCreativity was another of ChatGPT’s conquests. Here’s why it’s more computable than we think. | by Paul Pallaghy, PhD | Medium\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"6cc6\"\u003e\u003cstrong\u003eInsights for positive behavior change: \u003c/strong\u003eAI-powered analytics can identify patterns in behavior and generate actionable insights to encourage positive changes. For example, these insights can help improve products designed for health and education, empowering individuals to achieve their goals more effectively and efficiently.\u003c/p\u003e\u003cul\u003e\u003cli id=\"a010\"\u003e\u003ca href=\"https://www.mcpdigitalhealth.org/article/S2949-7612(24)00042-7/fulltext\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow are Machine Learning and Artificial Intelligence Used in Digital Behavior Change Interventions? A Scoping Review — Mayo Clinic Proceedings: Digital Health\u003c/a\u003e\u003c/li\u003e\u003cli id=\"9d0e\"\u003e\u003ca href=\"https://www.csrwire.com/press_releases/800456-bridge-success-using-ai-raise-bar-special-education\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCSRWire — A Bridge to Success: Using AI To Raise the Bar in Special Education\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"9a8c\"\u003e\u003cstrong\u003eEnhanced data privacy and security: \u003c/strong\u003eAI has the potential to improve data privacy and security through advanced capabilities such as anomaly detection, encryption, and access control management. Technologies like differential privacy and federated learning allow for valuable insights to be drawn from data while maintaining safeguards to protect sensitive information. These tools, when implemented conscientiously, can create systems that prioritize the privacy and security of research participants and clients.\u003c/p\u003e\u003cul\u003e\u003cli id=\"b687\"\u003e\u003ca href=\"https://bigid.com/blog/5-ways-generative-ai-empowers-data-security/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGenerative AI \u0026amp; Data Security: 5 Ways to Boost Cybersecurity | BigID\u003c/a\u003e\u003c/li\u003e\u003cli id=\"0b3d\"\u003e\u003ca href=\"https://www.forbes.com/councils/forbestechcouncil/2024/04/22/are-data-privacy-and-generative-ai-mutually-exclusive/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAre Data Privacy And Generative AI Mutually Exclusive?\u003c/a\u003e\u003c/li\u003e\u003cli id=\"1792\"\u003e\u003ca href=\"https://research.ibm.com/blog/what-is-federated-learning\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhat is federated learning? — IBM Research\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"1b89\"\u003eHowever, it’s important to acknowledge the inherent risks and challenges. The data-hungry nature of AI training often incentivizes excessive data collection, which can conflict with privacy objectives. Additionally, the complexity of AI systems sometimes makes it difficult to ensure that privacy protections are upheld consistently across applications. As a result, the risks associated with AI’s use in privacy-sensitive contexts often outweigh the potential benefits unless organizations approach implementation with exceptional care and transparency.\u003c/p\u003e\u003cp id=\"3b2f\"\u003eThis dual perspective highlights the need for cautious optimism. While AI can enhance privacy in theory, realizing these benefits in practice requires prioritizing ethical design, robust regulation, and a commitment to limiting data use to what is strictly necessary. By balancing these considerations, organizations can mitigate risks and responsibly explore AI’s potential for improving data security.\u003c/p\u003e\u003cp id=\"848e\"\u003e\u003cstrong\u003eChecking bias: \u003c/strong\u003eAI can act as a “gut check” or an additional data point to help illuminate biases or blind spots in human decision-making when it is developed to be inclusive and address bias from the start. When trained on diverse datasets, AI tools can provide thoughtful recommendations, offering value in contexts ranging from product development to broader decision-making processes.\u003c/p\u003e\u003cul\u003e\u003cli id=\"2098\"\u003e\u003ca href=\"https://www.bu.edu/articles/2024/can-the-bias-in-algorithms-help-us-see-our-own/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCan the Bias in Algorithms Help Us See Our Own? | The Brink | Boston University\u003c/a\u003e\u003c/li\u003e\u003cli id=\"d7ac\"\u003e\u003ca href=\"https://www.sap.com/resources/how-ai-can-end-bias\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow AI can end bias | SAP\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"ae18\"\u003e\u003cstrong\u003eBridging cultural divides: \u003c/strong\u003eWhile AI still has a long way to go in context sensitivity, its capabilities in real-time language translation and diverse content promotion are already helping bridge cultural and community barriers. For example, AI can enable more inclusive international research and create richer digital experiences that celebrate global diversity.\u003c/p\u003e\u003cp id=\"4d5e\"\u003eBy intentionally designing AI to prioritize accessibility, security, and cultural sensitivity, we can harness its immense potential to foster connection, creativity, and well-being, ultimately driving human flourishing in ways that matter most.\u003c/p\u003e\u003cul\u003e\u003cli id=\"bc14\"\u003e\u003ca href=\"https://medium.com/@Phannuman/bridging-cultural-divides-ai-in-global-content-strategy-aafbf861d3dd\" rel=\"noopener\"\u003eBridging Cultural Divides: AI in Global Content Strategy | by Phan Nython | Medium\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b859\"\u003e\u003ca href=\"https://vorecol.com/blogs/blog-the-role-of-ai-in-bridging-cultural-gaps-within-remote-teams-173326\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Role of AI in Bridging Cultural Gaps within Remote Teams\u003c/a\u003e\u003c/li\u003e\u003cli id=\"59db\"\u003e\u003ca href=\"https://www.forbes.com/councils/forbescommunicationscouncil/2019/07/31/build-cross-cultural-bridges-not-barriers-with-ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBuild Cross-Cultural Bridges, Not Barriers, With AI\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"0cad\"\u003eConcluding thoughts \u0026amp; next steps\u003c/h2\u003e\u003cp id=\"1ad7\"\u003eAI is a moving target, evolving rapidly in ways that challenge and inspire. As researchers, designers, and technologists, we have a unique responsibility to approach AI critically — assessing how it both promotes and threatens human flourishing. With regulation, governance, and accountability structures still taking shape, our vigilance and ethical commitment are more important than ever.\u003c/p\u003e\u003cp id=\"ef5c\"\u003eTo ensure AI enhances rather than detracts from human flourishing, here are a few actionable steps:\u003c/p\u003e\u003col\u003e\u003cli id=\"b2ef\"\u003e\u003cstrong\u003eApply a human-first lens\u003c/strong\u003e: Continuously evaluate how AI tools align with values like inclusivity, transparency, and ethical responsibility.\u003c/li\u003e\u003cli id=\"e82c\"\u003e\u003cstrong\u003eBalance AI with human expertise\u003c/strong\u003e: Leverage AI’s strengths while retaining the depth, empathy, and nuance that only humans can bring. You may have heard of this as keeping a, \u0026#34;Human in the loop.\u0026#34;\u003c/li\u003e\u003cli id=\"12d4\"\u003e\u003cstrong\u003eFoster open dialogue\u003c/strong\u003e: Share learnings and raise concerns within your teams and professional communities to shape better practices collectively.\u003c/li\u003e\u003cli id=\"0e39\"\u003e\u003cstrong\u003eExplore the resources and appendix\u003c/strong\u003e: Dig deeper into the resources referenced throughout this article and the extensive Appendix that follows to expand your understanding and spark new ideas.\u003c/li\u003e\u003cli id=\"d0f7\"\u003e\u003cstrong\u003eAdvocate for responsible AI\u003c/strong\u003e: Push for thoughtful regulation and design that centers human well-being at every level.\u003c/li\u003e\u003cli id=\"f446\"\u003e\u003cstrong\u003eEngage in conversation\u003c/strong\u003e: Talk to your colleagues and friends. Talk to your manager. Talk to your clients. You can even talk to me. Whether you’re seeking practical insights, curious about integrating these strategies, or just exploring the topic in a collaborative way… conversing with others will bring these ideas to the forefront and keep us all moving forward in a human-centered way.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"c9bb\"\u003eAs researchers and designers shaping the products billions of people use daily, we hold the power to keep humans at the heart of this technology.\u003c/p\u003e\u003cp id=\"ad6a\"\u003eBy being intentional, we can ensure AI evolves into a force that uplifts and empowers, rather than one that diminishes or divides.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"9ac4\"\u003eHuge thank you to my colleagues \u003cstrong\u003eKatie Trocin\u003c/strong\u003e and \u003cstrong\u003eLaToya Tufts\u003c/strong\u003e for the lit review, content development, editing, and discussion that lead to the creation of this article.\u003c/p\u003e\u003cp id=\"290b\"\u003e\u003cstrong\u003eJosh LaMar\u003c/strong\u003e is the Co-Founder and CEO of \u003ca href=\"https://amplinate.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAmplinate\u003c/a\u003e, an international agency focusing on cross-cultural Research \u0026amp; Design, based in the USA, France, Brazil, and India. As the Chief Strategy Officer of \u003ca href=\"https://www.joshlamar.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJoshLaMar Consult\u003c/a\u003e, he helps Entrepreneurs grow their business through ethical competitive advantage.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2 id=\"5687\"\u003eAppendix: References and Resources\u003c/h2\u003e\u003ch2 id=\"2af7\"\u003eHuman Flourishing Frameworks\u003c/h2\u003e\u003cul\u003e\u003cli id=\"e1f8\"\u003e\u003ca href=\"https://www.researchgate.net/figure/Social-ecological-framework-for-measuring-human-flourishing-reproduced-with-permission_fig1_233828994\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSocial Ecological Framework\u003c/a\u003e\u003c/li\u003e\u003cli id=\"d8ac\"\u003e\u003ca href=\"https://www.flourishproject.net/uploads/1/8/4/9/1849450/introducing_the_flourish_model__optimized_.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Ecology of Wellbeing\u003c/a\u003e\u003c/li\u003e\u003cli id=\"6a5b\"\u003e\u003ca href=\"https://hfh.fas.harvard.edu/measuring-flourishing\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMeasuring Flourishing | Harvard\u003c/a\u003e\u003c/li\u003e\u003cli id=\"3300\"\u003e\u003ca href=\"https://www.authentichappiness.sas.upenn.edu/newsletters/flourishnewsletters/newtheory\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAuthentic Happiness | Penn\u003c/a\u003e\u003c/li\u003e\u003cli id=\"a7c5\"\u003e\u003ca href=\"https://www.jstor.org/stable/10.7312/lobe18410\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePhilosophies of Happiness\u003c/a\u003e\u003c/li\u003e\u003cli id=\"7ea1\"\u003e\u003ca href=\"https://www.pnas.org/doi/abs/10.1073/pnas.1702996114\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eOn the promotion of human flourishing | PNAS\u003c/a\u003e\u003c/li\u003e\u003cli id=\"2a2b\"\u003e\u003ca href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8694651/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eRethinking flourishing: Critical insights and qualitative perspectives from the U.S. Midwest — PMC (nih.gov)\u003c/a\u003e\u003c/li\u003e\u003cli id=\"ae09\"\u003e\u003ca href=\"https://link.springer.com/content/pdf/10.1007/s42413-019-00036-8.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMeasures of Community Well-Being: a Template (springer.com)\u003c/a\u003e\u003c/li\u003e\u003cli id=\"31ad\"\u003e\u003ca href=\"https://www.cis.org.au/wp-content/uploads/2015/04/images/stories/policy-magazine/2011-spring/27-3-11-winton-bates.pdf\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFlourish: A Visionary New Understanding of Happiness and Well-being\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b2e3\"\u003e\u003ca href=\"https://medium.com/transformative-technology/radically-human-technology-enhancing-connection-and-wellbeing-or-finding-your-ikigai-kairos-e656fd0f4836\" rel=\"noopener\"\u003eRadically Human Technology: Enhancing Connection and Wellbeing (Or Finding your Ikigai Kairos ) | by Nichol Bradford | Transformative Technology | Medium\u003c/a\u003e\u003c/li\u003e\u003cli id=\"6c8a\"\u003e\u003ca href=\"https://sdgs.un.org/goals\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTHE 17 GOALS | Sustainable Development (un.org)\u003c/a\u003e\u003c/li\u003e\u003cli id=\"9f8c\"\u003e\u003ca href=\"https://www.amnesty.org/en/what-we-do/universal-declaration-of-human-rights/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUniversal Declaration of Human Rights — Amnesty International\u003c/a\u003e\u003c/li\u003e\u003cli id=\"13f9\"\u003e\u003ca href=\"https://bwwellbeingworld.com/article/ayurvedas-edge-over-western-psychology-445546\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAyurveda’s Edge Over Western Psychology (bwwellbeingworld.com)\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"0c3b\"\u003eAI Risks\u003c/h2\u003e\u003cul\u003e\u003cli id=\"8ecc\"\u003e\u003ca href=\"https://www.safe.ai/ai-risk\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAI Risks that Could Lead to Catastrophe | CAIS (safe.ai)\u003c/a\u003e\u003c/li\u003e\u003cli id=\"7e9c\"\u003e\u003ca href=\"https://airisk.mit.edu/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe AI Risk Repository (mit.edu)\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"0a1f\"\u003eLimitations of AI\u003c/h2\u003e\u003cul\u003e\u003cli id=\"3089\"\u003e\u003ca href=\"https://spacecoastdaily.com/2024/02/what-are-the-limitations-of-ai-in-understanding-context-in-text/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhat Are the Limitations of AI in Understanding Context in Text? — Space Coast Daily\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b561\"\u003e\u003ca href=\"https://cacm.acm.org/opinion/the-context-problem-in-artificial-intelligence/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Context Problem in Artificial Intelligence — Communications of the ACM\u003c/a\u003e\u003c/li\u003e\u003cli id=\"ed69\"\u003e\u003ca href=\"https://www.techtarget.com/whatis/definition/context-window\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhat is a context window?\u003c/a\u003e\u003c/li\u003e\u003cli id=\"15c0\"\u003e\u003ca href=\"https://casmi.northwestern.edu/news/articles/2024/the-ai-summarization-dilemma-when-good-enough-isnt-enough.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe AI Summarization Dilemma: When Good Enough Isn’t Enough: Center for Advancing Safety of Machine Intelligence — Northwestern University\u003c/a\u003e\u003c/li\u003e\u003cli id=\"63b0\"\u003e\u003ca href=\"https://www.context.news/ai/opinion/ais-dark-secret-its-rolling-back-progress-on-equality\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAI’s dark secret: It’s rolling back progress on equality | Context\u003c/a\u003e\u003c/li\u003e\u003cli id=\"e1ac\"\u003e\u003ca href=\"https://hdsr.mitpress.mit.edu/pub/xau9dza3/release/2\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWe Must Fix the Lack of Transparency Around the Data Used to Train Foundation Models · Special Issue 5: Grappling With the Generative AI Revolution\u003c/a\u003e\u003c/li\u003e\u003cli id=\"1789\"\u003e\u003ca href=\"https://www.zdnet.com/article/transparency-is-sorely-lacking-amid-growing-ai-interest/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTransparency is sorely lacking amid growing AI interest | ZDNET\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"ff49\"\u003eBias in AI\u003c/h2\u003e\u003cul\u003e\u003cli id=\"bcef\"\u003e\u003ca href=\"https://stories.camden.rutgers.edu/battling-bias-in-ai/index.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBattling Bias in AI\u003c/a\u003e\u003c/li\u003e\u003cli id=\"8a81\"\u003e\u003ca href=\"https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhen AI Gets It Wrong: Addressing AI Hallucinations and Bias — MIT Sloan Teaching \u0026amp; Learning Technologies\u003c/a\u003e\u003c/li\u003e\u003cli id=\"033d\"\u003e\u003ca href=\"https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThere’s More to AI Bias Than Biased Data, NIST Report Highlights | NIST\u003c/a\u003e\u003c/li\u003e\u003cli id=\"1e2a\"\u003e\u003ca href=\"https://hbr.org/2023/09/eliminating-algorithmic-bias-is-just-the-beginning-of-equitable-ai\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eEliminating Algorithmic Bias Is Just the Beginning of Equitable AI (hbr.org)\u003c/a\u003e\u003c/li\u003e\u003cli id=\"eca7\"\u003e\u003ca href=\"https://www.bu.edu/articles/2024/can-the-bias-in-algorithms-help-us-see-our-own/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCan the Bias in Algorithms Help Us See Our Own? | The Brink | Boston University\u003c/a\u003e\u003c/li\u003e\u003cli id=\"724a\"\u003e\u003ca href=\"https://www.sap.com/resources/how-ai-can-end-bias\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow AI can end bias | SAP\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"fd59\"\u003eStrategy 1: Complement\u003c/h2\u003e\u003cul\u003e\u003cli id=\"bb14\"\u003e\u003ca href=\"https://www.nngroup.com/articles/research-with-ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAccelerating Research with AI | NN/\u003c/a\u003eg\u003c/li\u003e\u003cli id=\"cada\"\u003e\u003ca href=\"https://www.researchpartnership.com/insights/how-we-elevated-hcp-market-research-engagement-and-insights-using-ai-avatars-for-an-immersive-experience/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow we elevated HCP market research engagement and insights using AI avatars for an immersive experience — Research Partnership\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"c180\"\u003eStrategy 2: Contextually Aware\u003c/h2\u003e\u003cul\u003e\u003cli id=\"2a54\"\u003e\u003ca href=\"https://iapp.org/news/a/will-the-eu-ai-act-work-lessons-learned-from-past-legislative-initiatives-future-challenges\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWill the EU AI Act work? Lessons learned from past legislative initiatives, future challenges | IAPP\u003c/a\u003e\u003c/li\u003e\u003cli id=\"2cfc\"\u003e\u003ca href=\"https://fra.europa.eu/en/news/2020/how-concerned-are-europeans-about-their-personal-data-online\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow concerned are Europeans about their personal data online? | European Union Agency for Fundamental Rights\u003c/a\u003e\u003c/li\u003e\u003cli id=\"0210\"\u003e\u003ca href=\"https://www.unitedlanguagegroup.com/blog/localization-strategy-guide-brazil\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow to Apply Cultural Knowledge in Your Brazilian Localization Strategy\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"e5f9\"\u003eStrategy 3: Privacy \u0026amp; Consent\u003c/h2\u003e\u003cul\u003e\u003cli id=\"1138\"\u003e\u003ca href=\"https://www.wired.com/story/can-chatgpt-4o-be-trusted-with-your-private-data/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCan GPT-4o Be Trusted With Your Private Data? | WIRED\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b8cc\"\u003e\u003ca href=\"https://medium.com/@neriasebastien/the-ai-consent-conundrum-do-we-truly-understand-what-we-agree-to-295201df823e\" rel=\"noopener\"\u003eThe AI Consent Conundrum: Do We Truly Understand What We Agree To? | by Neria Sebastien, EdD | Medium\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"fbfa\"\u003eStrategy 4: Ongoing Training\u003c/h2\u003e\u003cul\u003e\u003cli id=\"525d\"\u003e\u003ca href=\"https://www.linkedin.com/pulse/finding-meaningful-work-age-ai-stephanie-roberto-5hsnc/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFinding Meaningful Work in the Age of AI | LinkedIn\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"227e\"\u003eOpportunities\u003c/h2\u003e\u003cul\u003e\u003cli id=\"119b\"\u003e\u003ca href=\"https://www.forbes.com/councils/forbesbusinesscouncil/2024/02/02/how-artificial-general-intelligence-could-redefine-accessibility/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow Artificial General Intelligence Could Redefine Accessibility\u003c/a\u003e\u003c/li\u003e\u003cli id=\"cfc4\"\u003e\u003ca href=\"https://waywithwords.net/resource/voice-activated-devices-ai-speech/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eVoice-activated Devices: AI’s Epic Role in Speech Recognition\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b152\"\u003e\u003ca href=\"https://stealthesethoughts.com/2024/11/26/the-ultimate-guide-to-using-or-avoiding-ai-at-work/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Ultimate Guide To Using (or Avoiding) AI At Work\u003c/a\u003e\u003c/li\u003e\u003cli id=\"f40a\"\u003e\u003ca href=\"https://medium.com/@paul.k.pallaghy/creativity-was-another-of-chatgpts-conquests-here-s-why-it-s-more-computable-than-we-think-fb1e9b382ab2\" rel=\"noopener\"\u003eCreativity was another of ChatGPT’s conquests. Here’s why it’s more computable than we think. | by Paul Pallaghy, PhD | Medium\u003c/a\u003e\u003c/li\u003e\u003cli id=\"fcdd\"\u003e\u003ca href=\"https://www.mcpdigitalhealth.org/article/S2949-7612(24)00042-7/fulltext\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow are Machine Learning and Artificial Intelligence Used in Digital Behavior Change Interventions? A Scoping Review — Mayo Clinic Proceedings: Digital Health\u003c/a\u003e\u003c/li\u003e\u003cli id=\"d111\"\u003e\u003ca href=\"https://www.csrwire.com/press_releases/800456-bridge-success-using-ai-raise-bar-special-education\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCSRWire — A Bridge to Success: Using AI To Raise the Bar in Special Education\u003c/a\u003e\u003c/li\u003e\u003cli id=\"7edb\"\u003e\u003ca href=\"https://bigid.com/blog/5-ways-generative-ai-empowers-data-security/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGenerative AI \u0026amp; Data Security: 5 Ways to Boost Cybersecurity | BigID\u003c/a\u003e\u003c/li\u003e\u003cli id=\"e634\"\u003e\u003ca href=\"https://www.forbes.com/councils/forbestechcouncil/2024/04/22/are-data-privacy-and-generative-ai-mutually-exclusive/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAre Data Privacy And Generative AI Mutually Exclusive?\u003c/a\u003e\u003c/li\u003e\u003cli id=\"17da\"\u003e\u003ca href=\"https://research.ibm.com/blog/what-is-federated-learning\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWhat is federated learning? — IBM Research\u003c/a\u003e\u003c/li\u003e\u003cli id=\"9d15\"\u003e\u003ca href=\"https://www.bu.edu/articles/2024/can-the-bias-in-algorithms-help-us-see-our-own/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCan the Bias in Algorithms Help Us See Our Own? | The Brink | Boston University\u003c/a\u003e\u003c/li\u003e\u003cli id=\"b8c3\"\u003e\u003ca href=\"https://www.sap.com/resources/how-ai-can-end-bias\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow AI can end bias | SAP\u003c/a\u003e\u003c/li\u003e\u003cli id=\"5311\"\u003e\u003ca href=\"https://medium.com/@Phannuman/bridging-cultural-divides-ai-in-global-content-strategy-aafbf861d3dd\" rel=\"noopener\"\u003eBridging Cultural Divides: AI in Global Content Strategy | by Phan Nython | Medium\u003c/a\u003e\u003c/li\u003e\u003cli id=\"6c7f\"\u003e\u003ca href=\"https://vorecol.com/blogs/blog-the-role-of-ai-in-bridging-cultural-gaps-within-remote-teams-173326\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe Role of AI in Bridging Cultural Gaps within Remote Teams\u003c/a\u003e\u003c/li\u003e\u003cli id=\"ad99\"\u003e\u003ca href=\"https://www.forbes.com/councils/forbescommunicationscouncil/2019/07/31/build-cross-cultural-bridges-not-barriers-with-ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBuild Cross-Cultural Bridges, Not Barriers, With AI\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"5b20\"\u003eAI Failures\u003c/h2\u003e\u003cul\u003e\u003cli id=\"87f0\"\u003e\u003ca href=\"https://www.ataccama.com/blog/ai-fails-how-to-prevent\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e9 AI fails (and how they could have been prevented)\u003c/a\u003e\u003c/li\u003e\u003cli id=\"ad06\"\u003e\u003ca href=\"https://www.cio.com/article/190888/5-famous-analytics-and-ai-disasters.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e12 famous AI disasters\u003c/a\u003e\u003c/li\u003e\u003cli id=\"1280\"\u003e\u003ca href=\"https://www.webopedia.com/technology/biggest-ai-fails/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e16 biggest AI Fails\u003c/a\u003e\u003c/li\u003e\u003cli id=\"3dc6\"\u003e\u003ca href=\"https://www.buzzfeed.com/carleysuthers/weird-and-wrong-ai-responses\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e17 Screenshots Of AI Fails That Range From Hilarious To Mildly Terrifying\u003c/a\u003e\u003c/li\u003e\u003cli id=\"cba4\"\u003e\u003ca href=\"https://www.reddit.com/r/aifails/?share_id=hReMOQSjW3iHAAuJ9gTp7\u0026amp;utm_content=1\u0026amp;utm_medium=ios_app\u0026amp;utm_name=ioscss\u0026amp;utm_source=share\u0026amp;utm_term=1\u0026amp;rdt=54908\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003er/aifails | Reddit\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "35 min read",
  "publishedTime": "2025-01-11T10:44:19.142Z",
  "modifiedTime": null
}
