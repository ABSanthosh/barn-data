{
  "id": "97a0aba8-0c82-4e20-9ecc-aa872a62c8e3",
  "title": "11 lessons from a year of using AI in my daily work",
  "link": "https://uxdesign.cc/11-lessons-from-a-year-of-using-ai-in-my-daily-work-f03c18c7f861?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Jan Takacs",
  "published": "Thu, 24 Jul 2025 11:19:13 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "product-design",
    "ai",
    "learning",
    "ux",
    "design"
  ],
  "byline": "Jan Takacs",
  "length": 9927,
  "excerpt": "AI is everywhere, and it doesn’t seem to be slowing down. Rather than watching from the sidelines, I believe it’s better to dive in and learn by doing. The following are my personal reflections from…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "From hype to habit.Zoom image will be displayedPhoto: Julius Drost/Unsplash, Illustration: Jan TakacsAI is everywhere, and it doesn’t seem to be slowing down. Rather than watching from the sidelines, I believe it’s better to dive in and learn by doing. The following are my personal reflections from the past year or so of using tools like ChatGPT, Claude, Gemini, and others in real, everyday work. What has worked, what hasn’t, and what I have learned along the way with all the good and the bad.So, without any complicated or sophisticated introduction, let’s take a look at the major themes and takeaways that stuck with me after making AI part of my daily work life. No filters. Here we go.‍1. Context windows are huge and using them well has been a difference-maker for me. I get the best results when I have one conversation for each project. Sometimes it feels like LLMs are easy to confuse, and this way, I keep it efficient and don’t have to repeat myself as much.Plus, the context windows are really massive now, allowing me to work on a project for weeks (or even months) while still using a single chat window. That way, the LLM already has all the previous information, knowledge, and context, which makes the workflow faster, more tailored, and more effective. When I want to start something new, however small, I just start fresh with a new chat and a clean slate.‍2. I find myself constantly impressed by how great LLMs are for text-based work, but not so happy with other outputs just yet. Co-writing, critiques, ideation or even research. Anything text-based often works like magic. It almost feels like you’re shaping texts like Dumbledore shapes that big-ball water spell in the Order of the Phoenix. It does seem like this is where LLMs truly shine.On the other hand, as someone who has been in the creative business for more than 20 years, I’m often disappointed by the other outputs, such as images, sounds or video. They just need too much of extra work, refinements, and time – even to get to a quality I consider ‘decent’. That’s where I see myself shifting back to the ‘traditional’ way of making them (such as stock footage/photos manipulation), as that way I can get to the quality I want faster.Zoom image will be displayedShaping any text with LLMs often feels like magic. The first comparison that comes to mind is Dumbledore shaping his water-sphere spell to keep Voldemort at bay. Photo: Warner Bros, Illustration: Jan Takacs‍3. I did say it before, but it still proves to be true every single day: Communication is the ultimate skill. Clear communication is not just key for working with people, but it’s also how you get the most out of AI. Whether it’s with text, voice, or visuals, the better I express what I need, the better results I get. It’s a skill that keeps proving itself essential.Not only for our standard (and yes, still the most important) human-to-human interactions but also for the interactions with LLMs: it seems to me that great communication is key to unlocking the technology’s potential.Hence, if there are a few top skills I see as invaluable going forward, communication is one of them for sure. If not the top skill.‍4. Even when I do multilingual work, the English-first approach still wins regarding output quality. What I found out is that even when my final output is in Czech or another language, I do all the thinking, writing, and refinements in English first, before ultimately translating the final outputs to the language I want. This way I get consistently good results.Funnily enough, even the LLMs themselves are telling me that it’s the better approach. Simply because their core training is done in English and that they’re more efficient doing the work in the same language, rather than doing the entire work, e.g. in Czech or Spanish all the way. So it does seem that people with great proficiency in English have an edge here, at least for now.‍5. The way I approach research changed dramatically over the past year, and it’s hard to imagine moving back. A lot of my work in product and design is insight-driven and research-based, and I’m surprised how fast LLMs turbocharged some of the core activities I do often, such as desktop research, information and data synthesis, product and concept ideation, UX benchmarking, critiques, and more.Yes, it’s a tight line to walk because AI-supported (or even AI-led) research has a lot of drawbacks (and biases!), but I can comfortably say that learning how to use AI intentionally helps me move faster, explore more, and sharpen ideas way quicker than before. Removing it entirely now would feel like a major step backwards.‍6. Vibe coding is a great way to grow technically. And while it’s still not quite ready for prime time (especially in enterprise), it shows real promise as the next potential paradigm for designing and creating digital products.Prototyping with AI is great fun and perfect for exploration and learning. I’m a fan because I believe that successful designers (or people in general?) of the future need to be a lot more technical, and I see this as an accelerator of that trend. It has already helped me understand some engineering principles better.But for serious product work, especially in enterprise, it’s just not ready from my observations for production yet. Taking UI to a fully working code and product takes a lot of things to get right: debugging, security, iterations, documentation, understanding the code, etc. So, I see this as an evolution for sure, but would tone down the narrative that either engineers or designers are being replaced by AI (or by each other) in the near future.‍7. Great input = great output. When I emphasize the quality of inputs, I get great outputs. Otherwise, it’s often lots of fluff. When I’m disappointed by the results I’m getting from GPT, Claude or Gemini, it’s frequently because of the poor instructions or prompts I gave. Over the past year, I figured out that if I want high-quality results, I need to provide rich, detailed context or even upload a solid work-in-progress.And often, I see that the best results are pretty much when there’s almost a 1:1 ratio between input and output. Meaning the context I’m putting in is quite substantial. The easiest recipe for bland, generic, and often useless outputs seems to be short, vague instructions.Zoom image will be displayedIt’s critical to stay mentally sharp and not ‘outsource’ too much to AI. Early research indicates that over‑relying on AI can dull our mental sharpness — with potentially serious consequences for our future outlook. Photo‍8. The fundamentals of working with AI matter most, as the core tech hasn’t changed much in years, despite the hype. There’s a lot of hype about new AI releases on a weekly and monthly basis, and AI companies seem to position every release as something new and transformative.But every time I collaborate or talk to senior data science individuals or AI-related experts, they all agree on one thing – the underlying, core transformer technology hasn’t changed much in the past few years (with all its pros and cons).This means it’s really a great idea to get good with the basics and foundations and ignore the bombastic PR headlines. A new, better LLM model is unlikely to change how well you can leverage AI – the essentials matter a lot more.‍9. More and more, I find myself talking to AI rather than typing, as the model quality continues to improve. Lately, I find myself talking to AI a lot. Sometimes, perhaps even more than typing. It’s often comfortable, quick, and, with the latest voice models, surprisingly engaging. It allows me to convey thoughts, ideas, and requirements easily, and it continues to change how I think about tools and interfaces. Especially in terms of ideation for future product opportunities. There is a caveat, though…‍10. I run into some interface-related issues daily, and it’s clear to me now that the chat interface is holding us back. Lots of new AI-powered products get plenty of hate because they’re just “GPT-wrappers.” But the more I use the simple chat-like interfaces such as GPT, Claude, or Gemini, the more I’m convinced that the “wrapper” layer and the UX built on top of the LLMs will be the deciding factor for many of the successful products in the future.The basic chat interface is alright, but it often crashes, recalling lost content or context is difficult, it requires me to do a lot of frustrating heavy lifting constantly, and it’s hard to pause or steer the token generation.The pain is most obvious when it comes to longer voice communication and chat-voice transitions. There’s just so much left to desire.‍11. The more I use AI, the more I worry about staying mentally sharp and how much it matters. The more I rely on AI, the more I worry about over-relying on it. Sometimes I catch myself going to GPT even for easy tasks, even when I feel like I shouldn’t.It’s not difficult to imagine that if I’m not careful, I could start outsourcing the very skills I used to take pride in – structuring and synthesizing thoughts, writing, solving problems from scratch, and more.On top of that, I believe that to get the best from AI, it’s necessary to stay sharp, read and learn more, think deeper, explore further, and resist the temptation to offload too much. Because once those brain muscles weaken, I imagine they will be very hard to rebuild.If you’re on your own AI journey, one thing’s clear – learning by doing still rules the game. The pressure we all feel to keep up can actually be a useful push to get hands-on, experiment, and figure out what really adds value.But in the rush to integrate AI into everything, it’s worth remembering: just because we can use AI doesn’t always mean we should. The balance between what we do ourselves and what we hand over to machines doesn’t just affect the work – it shapes how we think.And that’s something worth protecting.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*tqB3QC4rRHOHnxL0E-HCNw.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"a7d2\"\u003eFrom hype to habit.\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\" role=\"tooltip\"\u003e\u003ca href=\"https://medium.com/@jantakacs?source=post_page---byline--f03c18c7f861---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Jan Takacs\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*-Gs2_Nw6Oj9k0pfvyqnANQ.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cdiv role=\"button\" tabindex=\"0\"\u003e\u003cp\u003e\u003cspan\u003eZoom image will be displayed\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003cfigcaption\u003ePhoto: Julius Drost/Unsplash, Illustration: Jan Takacs\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"a089\"\u003eAI is everywhere, and it doesn’t seem to be slowing down. Rather than watching from the sidelines, I believe it’s better to dive in and learn by doing. The following are my personal reflections from the past year or so of using tools like ChatGPT, Claude, Gemini, and others in real, everyday work. What has worked, what hasn’t, and what I have learned along the way with all the good and the bad.\u003c/p\u003e\u003cp id=\"c701\"\u003eSo, without any complicated or sophisticated introduction, let’s take a look at the major themes and takeaways that stuck with me after making AI part of my daily work life. No filters. Here we go.\u003c/p\u003e\u003cp id=\"38d0\"\u003e‍\u003cbr/\u003e1. \u003ca href=\"https://www.ibm.com/think/topics/context-window\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eContext windows\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e are huge and using them well has been a difference-maker for me.\u003c/strong\u003e I get the best results when I have one conversation for each project. Sometimes it feels like LLMs are easy to confuse, and this way, I keep it efficient and don’t have to repeat myself as much.\u003c/p\u003e\u003cp id=\"d1e8\"\u003ePlus, the context windows are really \u003ca href=\"https://explodingtopics.com/blog/list-of-llms\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003emassive\u003c/a\u003e now, allowing me to work on a project for weeks (or even months) while still using a single chat window. That way, the LLM already has all the previous information, knowledge, and context, which makes the workflow faster, more tailored, and more effective. When I want to start something new, however small, I just start fresh with a new chat and a clean slate.\u003c/p\u003e\u003cp id=\"ec44\"\u003e‍\u003cbr/\u003e2. \u003cstrong\u003eI find myself constantly impressed by how great LLMs are for text-based work, but not so happy with other outputs just yet. \u003c/strong\u003eCo-writing, critiques, ideation or even research. Anything text-based often works like magic. It almost feels like you’re shaping texts like Dumbledore shapes that \u003ca href=\"https://www.youtube.com/watch?v=SBWkAHAjXWo\u0026amp;pp=ygUdZHVtYmxlZG9yZSB2cyB2b2xkZW1vcnQgZmlnaHQ%3D\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ebig-ball water spell\u003c/a\u003e in the Order of the Phoenix. It does seem like this is where LLMs truly shine.\u003c/p\u003e\u003cp id=\"51db\"\u003eOn the other hand, as someone who has been in the creative business for more than 20 years, I’m often disappointed by the other outputs, such as images, sounds or video. They just need too much of extra work, refinements, and time – even to get to a quality I consider ‘decent’. That’s where I see myself shifting back to the ‘traditional’ way of making them (such as stock footage/photos manipulation), as that way I can get to the quality I want faster.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cdiv role=\"button\" tabindex=\"0\"\u003e\u003cp\u003e\u003cspan\u003eZoom image will be displayed\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003cfigcaption\u003e\u003cstrong\u003eShaping any text with LLMs often feels like magic. \u003c/strong\u003eThe first comparison that comes to mind is Dumbledore shaping his water-sphere spell to keep Voldemort at bay. Photo: Warner Bros, Illustration: Jan Takacs\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"c03c\"\u003e‍3. \u003cstrong\u003eI did say it before, but it still proves to be true every single day: Communication is the ultimate skill.\u003c/strong\u003e Clear communication is not just key for working with people, but it’s also how you get the most out of AI. Whether it’s with text, voice, or visuals, the better I express what I need, the better results I get. It’s a skill that keeps proving itself essential.\u003c/p\u003e\u003cp id=\"a3cd\"\u003eNot only for our standard (and yes, still the most important) human-to-human interactions but also for the interactions with LLMs: it seems to me that great communication is key to unlocking the technology’s potential.\u003c/p\u003e\u003cp id=\"fe63\"\u003eHence, if there are a few top skills I see as invaluable going forward, communication is one of them for sure. If not the top skill.\u003c/p\u003e\u003cp id=\"0add\"\u003e‍\u003cbr/\u003e4. \u003cstrong\u003eEven when I do multilingual work, the English-first approach still wins regarding output quality.\u003c/strong\u003e What I found out is that even when my final output is in Czech or another language, I do all the thinking, writing, and refinements in English first, before ultimately translating the final outputs to the language I want. This way I get consistently good results.\u003c/p\u003e\u003cp id=\"8f71\"\u003eFunnily enough, even the LLMs themselves are telling me that it’s the better approach. Simply because their core training is done in English and that they’re more efficient doing the work in the same language, rather than doing the entire work, e.g. in Czech or Spanish all the way. So it does seem that people with great proficiency in English have an edge here, at least for now.\u003c/p\u003e\u003cp id=\"0c59\"\u003e‍\u003cbr/\u003e5. \u003cstrong\u003eThe way I approach research changed dramatically over the past year, and it’s hard to imagine moving back.\u003c/strong\u003e A lot of my work in product and design is insight-driven and research-based, and I’m surprised how fast LLMs turbocharged some of the core activities I do often, such as desktop research, information and data synthesis, product and concept ideation, UX benchmarking, critiques, and more.\u003c/p\u003e\u003cp id=\"27e1\"\u003eYes, it’s a tight line to walk because AI-supported (or even AI-led) research has a lot of drawbacks (and biases!), but I can comfortably say that learning how to use AI intentionally helps me move faster, explore more, and sharpen ideas way quicker than before. Removing it entirely now would feel like a major step backwards.\u003c/p\u003e\u003cp id=\"751d\"\u003e‍\u003cbr/\u003e6. \u003ca href=\"https://en.wikipedia.org/wiki/Vibe_coding\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eVibe coding\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e is a great way to grow technically. And while it’s still not quite ready for prime time (especially in enterprise), it shows real promise as the next potential paradigm for designing and creating digital products.\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"be1a\"\u003ePrototyping with AI is great fun and perfect for exploration and learning. I’m a fan because I believe that successful designers (or people in general?) of the future need to be a lot more technical, and I see this as an accelerator of that trend. It has already helped me understand some engineering principles better.\u003c/p\u003e\u003cp id=\"2fd6\"\u003eBut for serious product work, especially in enterprise, it’s just not ready from my observations for production yet. Taking UI to a fully working code and product takes a lot of things to get right: debugging, security, iterations, documentation, understanding the code, etc. So, I see this as an evolution for sure, but would tone down the narrative that either engineers or designers are being replaced by AI (or by each other) in the near future.\u003c/p\u003e\u003cp id=\"13d7\"\u003e‍\u003cbr/\u003e7. \u003cstrong\u003eGreat input = great output. When I emphasize the quality of inputs, I get great outputs. Otherwise, it’s often lots of fluff. \u003c/strong\u003eWhen I’m disappointed by the results I’m getting from GPT, Claude or Gemini, it’s frequently because of the poor instructions or prompts I gave. Over the past year, I figured out that if I want high-quality results, I need to provide rich, detailed context or even upload a solid work-in-progress.\u003c/p\u003e\u003cp id=\"b240\"\u003eAnd often, I see that the best results are pretty much when there’s almost a 1:1 ratio between input and output. Meaning the context I’m putting in is quite substantial. The easiest recipe for bland, generic, and often useless outputs seems to be short, vague instructions.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cdiv role=\"button\" tabindex=\"0\"\u003e\u003cp\u003e\u003cspan\u003eZoom image will be displayed\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003cfigcaption\u003e\u003cstrong\u003eIt’s critical to stay mentally sharp and not ‘outsource’ too much to AI. \u003c/strong\u003eEarly research \u003ca href=\"https://tech.co/news/another-study-ai-making-us-dumb\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eindicates\u003c/a\u003e that over‑relying on AI can dull our mental sharpness — with potentially serious consequences for our future outlook. Photo\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"1cd6\"\u003e‍8. \u003cstrong\u003eThe fundamentals of working with AI matter most, as the core tech \u003c/strong\u003e\u003ca href=\"https://toloka.ai/blog/history-of-llms/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003ehasn’t changed\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e much in years, despite the hype.\u003c/strong\u003e There’s a lot of hype about new AI releases on a weekly and monthly basis, and AI companies seem to position every release as something new and transformative.\u003c/p\u003e\u003cp id=\"0940\"\u003eBut every time I collaborate or talk to senior data science individuals or AI-related experts, they all agree on one thing – the underlying, core transformer technology hasn’t changed much in the past few years (with all its pros and cons).\u003c/p\u003e\u003cp id=\"6a87\"\u003eThis means it’s really a great idea to get good with the basics and foundations and ignore the bombastic PR headlines. A new, better LLM model is unlikely to change how well you can leverage AI – the essentials matter a lot more.\u003c/p\u003e\u003cp id=\"978e\"\u003e‍\u003cbr/\u003e9. \u003cstrong\u003eMore and more, I find myself talking to AI rather than typing, as the model quality \u003c/strong\u003e\u003ca href=\"https://elevenlabs.io/blog/eleven-v3\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003econtinues to improve\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e.\u003c/strong\u003e Lately, I find myself talking to AI a lot. Sometimes, perhaps even more than typing. It’s often comfortable, quick, and, with the latest voice models, surprisingly engaging. It allows me to convey thoughts, ideas, and requirements easily, and it continues to change how I think about tools and interfaces. Especially in terms of ideation for future product opportunities. There is a caveat, though…\u003c/p\u003e\u003cp id=\"93db\"\u003e‍\u003cbr/\u003e10. \u003cstrong\u003eI run into some interface-related issues daily, and it’s clear to me now that the chat interface is holding us back. \u003c/strong\u003eLots of new AI-powered products get plenty of hate because they’re just “GPT-wrappers.” But the more I use the simple chat-like interfaces such as GPT, Claude, or Gemini, the more I’m convinced that the “wrapper” layer and the UX built on top of the LLMs will be the deciding factor for many of the successful products in the future.\u003c/p\u003e\u003cp id=\"9aee\"\u003eThe basic chat interface is alright, but it often crashes, recalling lost content or context is difficult, it requires me to do a lot of frustrating heavy lifting constantly, and it’s hard to pause or steer the token generation.\u003c/p\u003e\u003cp id=\"f47d\"\u003eThe pain is most obvious when it comes to longer voice communication and chat-voice transitions. There’s just so much left to desire.\u003c/p\u003e\u003cp id=\"a2d6\"\u003e‍\u003cbr/\u003e11. \u003cstrong\u003eThe more I use AI, the more I worry about staying mentally sharp and how much it matters.\u003c/strong\u003e The more I rely on AI, the more I worry about over-relying on it. Sometimes I catch myself going to GPT even for easy tasks, even when I feel like I shouldn’t.\u003c/p\u003e\u003cp id=\"5c15\"\u003eIt’s not difficult to imagine that if I’m not careful, I could start outsourcing the very skills I used to take pride in – structuring and synthesizing thoughts, writing, solving problems from scratch, and more.\u003c/p\u003e\u003cp id=\"a033\"\u003eOn top of that, I believe that to get the best from AI, it’s necessary to stay sharp, read and learn more, think deeper, explore further, and resist the temptation to offload too much. Because once those brain muscles weaken, I imagine they will be \u003ca href=\"https://www.media.mit.edu/articles/a-i-s-effects-on-the-brain/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003every hard to rebuild\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"e19e\"\u003eIf you’re on your own AI journey, one thing’s clear – learning by doing still rules the game. The pressure we all feel to keep up can actually be a useful push to get hands-on, experiment, and figure out what really adds value.\u003c/p\u003e\u003cp id=\"0fbd\"\u003eBut in the rush to integrate AI into everything, it’s worth remembering: \u003cstrong\u003ejust because we can use AI doesn’t always mean we should\u003c/strong\u003e. The balance between what we do ourselves and what we hand over to machines doesn’t just affect the work – it shapes how we think.\u003c/p\u003e\u003cp id=\"4898\"\u003eAnd that’s something worth \u003ca href=\"https://fortune.com/2025/03/20/ai-affects-critical-thinking/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eprotecting\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/article\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-07-24T11:19:13.091Z",
  "modifiedTime": null
}
