{
  "id": "85099cf2-4128-49d3-85e0-da0d26a433bb",
  "title": "Benchmarking Koin vs. Dagger Hilt in Modern Android Development (2024)",
  "link": "https://proandroiddev.com/benchmarking-koin-vs-dagger-hilt-in-modern-android-development-2024-ff7bb40470df?source=rss----c72404660798---4",
  "description": "",
  "author": "Arnaud Giuliani",
  "published": "Wed, 27 Nov 2024 02:00:21 GMT",
  "source": "https://proandroiddev.com/feed",
  "categories": [
    "performance",
    "android",
    "dependency-injection",
    "koin",
    "benchmark"
  ],
  "byline": "Arnaud Giuliani",
  "length": 6049,
  "excerpt": "When choosing a dependency injection framework for Android and Kotlin development, performance is often a key consideration. This article explores the performance of Koin in its latest version‚Ä¶",
  "siteName": "ProAndroidDev",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*A8VytPZQhvUf_MG6hm_Dlw.png",
  "text": "Service Locator or Dependency Injection? Koin can do both!Before diving into the benchmarks, let‚Äôs address a common question about Koin: Is it a Service Locator or a Dependency Injection (DI) framework? The answer is both.A Service Locator retrieves dependencies dynamically through a centralized registry.Dependency Injection provides dependencies explicitly at instantiation, enhancing testability and maintainability.Koin bridges these two approaches, offering dynamic retrieval via get() or inject() while also supporting DI features like constructor injection and scoping.Koin‚Äôs dynamic behavior is influenced by Android‚Äôs lifecycle, which historically made constructor injection challenging. While modern Android features now support constructor injection, Koin remains flexible, letting developers choose the best approach for their needs.At its core, Koin is a DI framework. It avoids reflection overhead, uses a Kotlin DSL for dependency graphs, and supports scoped lifecycles. However, its ability to function as a Service Locator adds versatility, particularly for simpler or legacy projects.This is a summary, but this Koin project documentation page has more details if you need to go deeper.Why choose Koin?Simple and Developer-Friendly: Koin‚Äôs clean DSL, no compile-time overhead, minimal setup, and easy testing let you focus on building your apps.Scales with Your App: from small apps to complex projects, Koin scales effortlessly to meet your needs.Evolving Compile-Time Safety: With features like module validation (Verify API), Koin Annotations (KSP for configuration safety), and the upcoming Koin IDE Plugin, Koin simplifies coding while boosting safety.Ready for Kotlin Multiplatform: Koin seamlessly manages dependencies across iOS, Android, Desktop, and Web, making it the go-to DI framework for cross-platform development.Perfect for Compose Multiplatform: Koin integrates effortlessly with Compose Multiplatform, supporting shared logic and DI for UI components ‚Äî even ViewModel.If you‚Äôre curious about Koin‚Äôs internals and design, let me know ‚Äî I‚Äôd be happy to explore that in a future article. For now, let‚Äôs dive into the benchmarks! üòÅTracking PerformancesTracking the performance of components over sessions is trickier than it initially seems. While tools like Baseline Profiles Macrobenchmark and similar deep-dive tools offer great analysis, they don‚Äôt allow me to easily extract benchmark values for custom use. Alternatively, connected dev platforms like Firebase Crashlytics or Kotzilla Platform offer convenient solutions to capture and analyze performance metrics.My goal here is to stay simple and lightweight: I want to measure how long it takes to create a specific component, like building a ViewModel instance using dependency injection. I don‚Äôt need a complex framework for this task, but I‚Äôm OK with manually instrumenting my code as long as it‚Äôs straightforward and lightweight.To achieve this, I wrote a few functions to capture function call time from DI frameworks (All is in Measure.kt file). This utility leverages Kotlin‚Äôs measureTimedValue function, an elegant and efficient way to measure code execution times, making it an excellent fit for lightweight, manual instrumentation. By extending the Android Context, I created an easy way to log the duration of any function call (or dependency injection operation) directly to a log file.inline fun \u003creified T\u003e Context.measureTimeLazy(tag : String, code : () -\u003e Lazy\u003cT\u003e) : Lazy\u003cT\u003e{ val result = measureTimedValue(code) val timeInMs = result.duration.inWholeMicroseconds / 1000.0 logBenchmark(tag,timeInMs) return result.value}In the end, we are storing all results in a local file (function logBenchmark). This file will be extracted, to allow average times calculation.Now in AndroidNow, let‚Äôs see how these tracking functions are applied in our real-world scenario. For this benchmark, we‚Äôll measure the performance of the following components: MainActivityViewModel, ForYouViewModel, and startup time.These ViewModels are the first two used in the application, making them ideal candidates for assessing the performance of DI frameworks during the app‚Äôs initial loading phase.In the Koin implementation, the performance tracking for these components is instrumented as follows (MainActivity \u0026 ForYouScreen links):MainActivityForYouScreenA note here: we are using the latest Koin AndroidX Startup feature to help improve startup time.For the Hilt implementation, tracking is similarly applied (MainActivity \u0026 ForYouScreen links):MainActivityForYouScreenTo capture the startup time, we use the onWindowFocusChanged function in MainActivity. This measures the time it takes for the app to render its first frame after gaining focus, giving a clear picture of the app‚Äôs startup performance. We track time from the Application class until the first Activity:MainActivityExecution, Extraction, And ResultsTo capture performance metrics automatically, we run the benchmark.sh shell script. This script automates a sequence of app install, start, wait a few seconds, and stop actions to simulate realistic usage patterns. After all runs, it extracts the benchmark_log.txt file containing all recorded times. This is 25 iterations of running the Nia application's start, wait and stop (demo release build).Using the collected data, the stats.py Python script processes the log to compute key statistics: minimum, maximum, and average times for each benchmarked component.On your terminal, you can just run the command: benchmark.sh ; python3 stats.py (from the /app folder).The best is to run it on a real Android device. On my OnePlus Nord (Android 12), I got the following results:Same OnePlus Nord results in tableIn this benchmark, in addition to average, minimum, and maximum, we show the ‚Äústandard error‚Äù: it measures the reliability of the average, indicating how much it may vary from the true population mean. Smaller values mean more stable and precise results. It helps also compare stability results between Koin and Dagger Hilt.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*h5ULv-tGdDA3yD2c685lFQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"4883\"\u003eService Locator or Dependency Injection? Koin can do both!\u003c/h2\u003e\u003cp id=\"3562\"\u003eBefore diving into the benchmarks, let‚Äôs address a common question about Koin: Is it a Service Locator or a Dependency Injection (DI) framework? The answer i\u003cstrong\u003es both.\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"20ac\"\u003eA \u003cstrong\u003eService Locator\u003c/strong\u003e retrieves dependencies dynamically through a centralized registry.\u003c/li\u003e\u003cli id=\"269b\"\u003e\u003cstrong\u003eDependency Injection\u003c/strong\u003e provides dependencies explicitly at instantiation, enhancing testability and maintainability.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"9e90\"\u003eKoin bridges these two approaches, offering dynamic retrieval via \u003ccode\u003eget()\u003c/code\u003e or \u003ccode\u003einject()\u003c/code\u003e while also supporting DI features like constructor injection and scoping.\u003c/p\u003e\u003cp id=\"6078\"\u003eKoin‚Äôs dynamic behavior is influenced by Android‚Äôs lifecycle, which historically made constructor injection challenging. While modern Android features now support constructor injection, Koin remains flexible, letting developers choose the best approach for their needs.\u003c/p\u003e\u003cp id=\"bb09\"\u003eAt its core, \u003cstrong\u003eKoin is a DI framework\u003c/strong\u003e. It avoids reflection overhead, uses a Kotlin DSL for dependency graphs, and supports scoped lifecycles. However, its ability to function as a Service Locator adds versatility, particularly for simpler or legacy projects.\u003c/p\u003e\u003cp id=\"f51b\"\u003eThis is a summary, but this Koin project \u003ca href=\"https://insert-koin.io/docs/setup/why/#koin-a-dependency-injection-framework\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edocumentation page\u003c/a\u003e has more details if you need to go deeper.\u003c/p\u003e\u003ch2 id=\"4aae\"\u003eWhy choose Koin?\u003c/h2\u003e\u003cul\u003e\u003cli id=\"0f97\"\u003e\u003cstrong\u003eSimple and Developer-Friendly: \u003c/strong\u003eKoin‚Äôs clean DSL, no compile-time overhead, minimal setup, and easy testing let you focus on building your apps.\u003c/li\u003e\u003cli id=\"8f0e\"\u003e\u003cstrong\u003eScales with Your App: f\u003c/strong\u003erom small apps to complex projects, Koin scales effortlessly to meet your needs.\u003c/li\u003e\u003cli id=\"0a6b\"\u003e\u003cstrong\u003eEvolving Compile-Time Safety: \u003c/strong\u003eWith features like module validation (\u003cstrong\u003eVerify API\u003c/strong\u003e), \u003cstrong\u003eKoin Annotations\u003c/strong\u003e (KSP for configuration safety), and the upcoming \u003cstrong\u003eKoin IDE Plugin\u003c/strong\u003e, Koin simplifies coding while boosting safety.\u003c/li\u003e\u003cli id=\"67be\"\u003e\u003cstrong\u003eReady for Kotlin Multiplatform: \u003c/strong\u003eKoin seamlessly manages dependencies across iOS, Android, Desktop, and Web, making it the go-to DI framework for cross-platform development.\u003c/li\u003e\u003cli id=\"7d59\"\u003e\u003cstrong\u003ePerfect for Compose Multiplatform: \u003c/strong\u003eKoin integrates effortlessly with Compose Multiplatform, supporting shared logic and DI for UI components ‚Äî even \u003cstrong\u003eViewModel\u003c/strong\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"a843\"\u003eIf you‚Äôre curious about Koin‚Äôs internals and design, let me know ‚Äî I‚Äôd be happy to explore that in a future article. For now, let‚Äôs dive into the benchmarks! üòÅ\u003c/p\u003e\u003ch2 id=\"67eb\"\u003eTracking Performances\u003c/h2\u003e\u003cp id=\"c623\"\u003eTracking the performance of components over sessions is trickier than it initially seems. While tools like \u003ca href=\"https://developer.android.com/topic/performance/baselineprofiles/measure-baselineprofile\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eBaseline Profiles Macrobenchmark\u003c/strong\u003e\u003c/a\u003e and similar deep-dive tools offer great analysis, they don‚Äôt allow me to easily extract benchmark values for custom use. Alternatively, connected dev platforms like \u003cstrong\u003eFirebase Crashlytics or \u003c/strong\u003e\u003ca href=\"https://kotzilla.io/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eKotzilla Platform\u003c/strong\u003e\u003c/a\u003e offer convenient solutions to capture and analyze performance metrics.\u003c/p\u003e\u003cp id=\"7175\"\u003eMy goal here is to \u003cstrong\u003estay simple and lightweight\u003c/strong\u003e: I want to \u003cstrong\u003emeasure how long it takes to create a specific component\u003c/strong\u003e, like building a ViewModel instance using dependency injection. I don‚Äôt need a complex framework for this task, but I‚Äôm OK with manually instrumenting my code as long as it‚Äôs straightforward and lightweight.\u003c/p\u003e\u003cp id=\"7f6e\"\u003eTo achieve this, I wrote a few functions to capture function call time from DI frameworks (All is in \u003ccode\u003e\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_koin/core/data/src/main/kotlin/com/google/samples/apps/nowinandroid/core/data/Measure.kt\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eMeasure.kt\u003c/strong\u003e\u003c/a\u003e\u003c/code\u003e file). This utility leverages \u003cstrong\u003eKotlin‚Äôs \u003c/strong\u003e\u003ccode\u003e\u003cstrong\u003emeasureTimedValue\u003c/strong\u003e\u003c/code\u003e\u003cstrong\u003e \u003c/strong\u003efunction, an elegant and efficient way to measure code execution times, making it an excellent fit for lightweight, manual instrumentation. By extending the Android \u003ccode\u003eContext\u003c/code\u003e, I created an easy way to log the duration of any function call (or dependency injection operation) directly to a log file.\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"ea9d\"\u003einline fun \u0026lt;reified T\u0026gt; Context.measureTimeLazy(tag : String, code : () -\u0026gt; Lazy\u0026lt;T\u0026gt;) : Lazy\u0026lt;T\u0026gt;{\u003cbr/\u003e    val result = measureTimedValue(code)\u003cbr/\u003e    val timeInMs = result.duration.inWholeMicroseconds / 1000.0\u003cbr/\u003e    logBenchmark(tag,timeInMs)\u003cbr/\u003e    return result.value\u003cbr/\u003e}\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"049b\"\u003eIn the end, \u003cstrong\u003ewe are storing all results in a local file\u003c/strong\u003e (function \u003ccode\u003e\u003cstrong\u003elogBenchmark\u003c/strong\u003e\u003c/code\u003e). This file will be extracted, to allow average times calculation.\u003c/p\u003e\u003ch2 id=\"a68e\"\u003eNow in Android\u003c/h2\u003e\u003cp id=\"5067\"\u003eNow, let‚Äôs see how these tracking functions are applied in our real-world scenario. For this benchmark, we‚Äôll measure the performance of the following components: \u003cstrong\u003eMainActivityViewModel\u003c/strong\u003e, \u003cstrong\u003eForYouViewModel\u003c/strong\u003e, and \u003cstrong\u003estartup time\u003c/strong\u003e.\u003c/p\u003e\u003cp id=\"6454\"\u003eThese ViewModels are the first two used in the application, making them ideal candidates for assessing the performance of DI frameworks during the app‚Äôs initial loading phase.\u003c/p\u003e\u003cp id=\"7efb\"\u003eIn the \u003cstrong\u003eKoin implementation\u003c/strong\u003e, the performance tracking for these components is instrumented as follows (\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_koin/app/src/main/kotlin/com/google/samples/apps/nowinandroid/MainActivity.kt#L77\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMainActivity\u003c/a\u003e \u0026amp; \u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_koin/feature/foryou/src/main/kotlin/com/google/samples/apps/nowinandroid/feature/foryou/ForYouScreen.kt#L113\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eForYouScreen\u003c/a\u003e links):\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_koin/app/src/main/kotlin/com/google/samples/apps/nowinandroid/MainActivity.kt#L77\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMainActivity\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_koin/feature/foryou/src/main/kotlin/com/google/samples/apps/nowinandroid/feature/foryou/ForYouScreen.kt#L113\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eForYouScreen\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"78e9\"\u003eA note here: we are using the latest \u003ca href=\"https://insert-koin.io/docs/reference/koin-android/start#start-koin-with-androidx-startup-401\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKoin AndroidX Startup\u003c/a\u003e feature to help improve startup time.\u003c/p\u003e\u003cp id=\"3e23\"\u003eFor the \u003cstrong\u003eHilt implementation\u003c/strong\u003e, tracking is similarly applied (\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_hilt/app/src/main/kotlin/com/google/samples/apps/nowinandroid/MainActivity.kt#L80\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMainActivity\u003c/a\u003e \u0026amp; \u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_hilt/feature/foryou/src/main/kotlin/com/google/samples/apps/nowinandroid/feature/foryou/ForYouScreen.kt#L113\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eForYouScreen\u003c/a\u003e links):\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_hilt/app/src/main/kotlin/com/google/samples/apps/nowinandroid/MainActivity.kt#L80\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMainActivity\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_hilt/feature/foryou/src/main/kotlin/com/google/samples/apps/nowinandroid/feature/foryou/ForYouScreen.kt#L113\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eForYouScreen\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"861d\"\u003eTo capture the \u003cstrong\u003estartup time\u003c/strong\u003e, we use the \u003ccode\u003eonWindowFocusChanged\u003c/code\u003e function in \u003cstrong\u003eMainActivity\u003c/strong\u003e. This measures the time it takes for the app to render its first frame after gaining focus, giving a clear picture of the app‚Äôs startup performance. We track time from the \u003cstrong\u003eApplication\u003c/strong\u003e class until the first Activity:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://github.com/InsertKoinIO/nowinandroid/blob/perfs_hilt/app/src/main/kotlin/com/google/samples/apps/nowinandroid/MainActivity.kt#L80\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMainActivity\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"101e\"\u003eExecution, Extraction, And Results\u003c/h2\u003e\u003cp id=\"36aa\"\u003eTo capture performance metrics automatically, we run the \u003ccode\u003e\u003cstrong\u003ebenchmark.sh\u003c/strong\u003e\u003c/code\u003e shell script. This script automates a sequence of app install, start, wait a few seconds, and stop actions to simulate realistic usage patterns. After all runs, it extracts the \u003ccode\u003e\u003cstrong\u003ebenchmark_log.txt\u003c/strong\u003e\u003c/code\u003e file containing all recorded times. This is 25 iterations of running the Nia application\u0026#39;s start, wait and stop (demo release build).\u003c/p\u003e\u003cp id=\"0853\"\u003eUsing the collected data, the \u003ccode\u003e\u003cstrong\u003estats.py\u003c/strong\u003e\u003c/code\u003e Python script processes the log to compute key statistics: minimum, maximum, and average times for each benchmarked component.\u003c/p\u003e\u003cp id=\"8ae9\"\u003e\u003cstrong\u003eOn your terminal\u003c/strong\u003e, you can just run the command: \u003ccode\u003e\u003cstrong\u003ebenchmark.sh ; python3 stats.py\u003c/strong\u003e\u003c/code\u003e\u003cstrong\u003e (\u003c/strong\u003efrom the /app folder).\u003c/p\u003e\u003cp id=\"0892\"\u003eThe best is to run it on a real Android device. On my OnePlus Nord (Android 12), I got the following results:\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003eSame OnePlus Nord \u003ca href=\"https://gist.github.com/arnaudgiuliani/9e05451d111373eaf570c7f3a4465ad2\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eresults\u003c/a\u003e in table\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"8d37\"\u003eIn this benchmark, in addition to average, minimum, and maximum, we show the ‚Äú\u003cstrong\u003estandard error‚Äù: \u003c/strong\u003eit\u003cstrong\u003e \u003c/strong\u003emeasures the \u003cstrong\u003ereliability of the average\u003c/strong\u003e, indicating how much it may vary from the true population mean. Smaller values mean more stable and precise results. It helps also compare stability results between Koin and Dagger Hilt.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2024-11-27T02:00:21.762Z",
  "modifiedTime": null
}
