{
  "id": "39244a05-44e6-472a-8958-f043b6a61f52",
  "title": "Tap to focus: Mastering CameraX Transformations in Jetpack Compose",
  "link": "https://medium.com/androiddevelopers/tap-to-focus-mastering-camerax-transformations-in-jetpack-compose-440853280a6e?source=rss----95b274b437c2---4",
  "description": "",
  "author": "Jolanda Verhoef",
  "published": "Thu, 09 Jan 2025 17:04:14 GMT",
  "source": "https://medium.com/feed/androiddevelopers",
  "categories": [
    "android",
    "kotlin",
    "programming",
    "mobile-app-development",
    "jetpack-compose"
  ],
  "byline": "Jolanda Verhoef",
  "length": 10090,
  "excerpt": "This blog post is a part of Camera and Media Spotlight Week. Weâ€™re providing resources â€” blog posts, videos, sample code, and more â€” all designed to help you uplevel the media experiences in yourâ€¦",
  "siteName": "Android Developers",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "Part 2 of Unlocking the Power of CameraX in Jetpack ComposeThis blog post is a part of Camera and Media Spotlight Week. Weâ€™re providing resources â€” blog posts, videos, sample code, and more â€” all designed to help you uplevel the media experiences in your app.To learn more about what Spotlight Week has to offer and how it can benefit you, be sure to read our overview blog post.Welcome back! In the first post of this series, we built a basic camera preview using the new camera-compose artifact. We covered permission handling and basic integration, and now itâ€™s time to get more interactive!ðŸ§± Part 1: Building a basic camera preview using the new camera-compose artifact. Weâ€™ll cover permission handling and basic integration.ðŸ‘† Part 2 (this post): Using the Compose gesture system, graphics, and coroutines to implement a visual tap-to-focus.ðŸ”Ž Part 3: Exploring how to overlay Compose UI elements on top of your camera preview for a richer user experience.ðŸ“‚ Part 4: Using adaptive APIs and the Compose animation framework to smoothly animate to and from tabletop mode on foldable phones.In this post, weâ€™ll dive into implementing the tap-to-focus feature. This involves understanding how to translate Compose touch events to camera sensor coordinates, and adding a visual indicator to show the user where the camera is focusing.Thereâ€™s an open feature request for a higher level composable that will contain more out-of-the-box functionality (like tap-to-focus and zooming). Please upvote the feature if you need this!Add tap-to-focus functionality to the view modelFirst, letâ€™s modify the CameraPreviewViewModel to handle tap-to-focus logic. We need to adapt our existing code in two ways:We hold on to a SurfaceOrientedMeteringPointFactory, that is able to translate the tap coordinates coming from the UI into a MeteringPoint.We hold on to a CameraControl, that can be used to interact with the camera. Once we have the correct MeteringPoint, we pass it to that camera control to be used as the reference point for auto-focusing.class CameraPreviewViewModel : ViewModel() { .. private var surfaceMeteringPointFactory: SurfaceOrientedMeteringPointFactory? = null private var cameraControl: CameraControl? = null private val cameraPreviewUseCase = Preview.Builder().build().apply { setSurfaceProvider { newSurfaceRequest -\u003e _surfaceRequest.update { newSurfaceRequest } surfaceMeteringPointFactory = SurfaceOrientedMeteringPointFactory( newSurfaceRequest.resolution.width.toFloat(), newSurfaceRequest.resolution.height.toFloat() ) } } suspend fun bindToCamera(appContext: Context, lifecycleOwner: LifecycleOwner) { val processCameraProvider = ProcessCameraProvider.awaitInstance(appContext) val camera = processCameraProvider.bindToLifecycle( lifecycleOwner, DEFAULT_BACK_CAMERA, cameraPreviewUseCase ) cameraControl = camera.cameraControl // Cancellation signals we're done with the camera try { awaitCancellation() } finally { processCameraProvider.unbindAll() cameraControl = null } } fun tapToFocus(tapCoords: Offset) { val point = surfaceMeteringPointFactory?.createPoint(tapCoords.x, tapCoords.y) if (point != null) { val meteringAction = FocusMeteringAction.Builder(point).build() cameraControl?.startFocusAndMetering(meteringAction) } }}We create a SurfaceOrientedMeteringPointFactory when the SurfaceRequest is available, using the surfaceâ€™s resolution. This factory translates the tapped coordinates on the surface to a focus metering point.We assign the cameraControl attached to the Camera when we bind to the cameraâ€™s lifecycle. We then reset it to null when the lifecycle ends.The tapToFocus function takes an Offset representing the tap location in sensor coordinates, translates it to a MeteringPoint using the factory, and then uses the CameraX cameraControl to initiate the focus and metering action.Note: We could improve the interaction between UI and CameraControl somewhat by using a more sophisticated coroutines setup, but this is outside the scope of this blog post. If youâ€™re interested in learning more about such an implementation, check out the Jetpack Camera App sample, which implements camera interactions through the CameraXCameraUseCase.Transform gesture from display to sensor coordinatesNow, letâ€™s update the CameraPreviewContent composable to handle touch events and pass those events to the view model. To do that, weâ€™ll use the pointerInput modifier and the detectTapGestures extension function:@Composablefun CameraPreviewContent(..) { .. surfaceRequest?.let { request -\u003e val coordinateTransformer = remember { MutableCoordinateTransformer() } CameraXViewfinder( surfaceRequest = request, coordinateTransformer = coordinateTransformer, modifier = modifier.pointerInput(Unit) { detectTapGestures { tapCoords -\u003e with(coordinateTransformer) { viewModel.tapToFocus(tapCoords.transform()) } } } ) }}We use the pointerInput modifier and detectTapGestures to listen for tap events on the CameraXViewfinder.We create a MutableCoordinateTransformer, which is provided by the camera-compose library, to transform the tap coordinates from the layoutâ€™s coordinate system to the sensorâ€™s coordinate system. This transformation is non-trivial! The physical sensor is often rotated relative to the screen, and additional scaling and cropping is done to make the image fit the container itâ€™s in. We pass the mutable transformer instance into the CameraXViewfinder. Internally, the viewfinder sets the transformation matrix of the transformer. This transformation matrix is capable of transforming local window coordinates into sensor coordinates.Inside the detectTapGestures block, we use the coordinateTransformer to transform the tap coordinates before passing them to the tapToFocus function of our view model.As weâ€™re using typical Compose gesture handling, we unlock any sort of gesture recognition. So if you want to focus after the user triple-taps, or swipes up and down, nothing is holding you back! This is an example of the power of the new CameraX Compose APIs. They are built from the ground up, in an open way, so that you can extend and build whatever you need on top of them. Compare this to the old CameraController that had tap-to-focus built in â€” thatâ€™s great if tap-to-focus is what you need, but it didnâ€™t give you any opportunity to customize the behavior.Visual indicator when tapping to focusTo provide visual feedback to the user, weâ€™ll add a small white circle that briefly appears at the tap location. Weâ€™ll use Compose animation APIs to fade it in and out:@Composablefun CameraPreviewContent( viewModel: CameraPreviewViewModel, modifier: Modifier = Modifier, lifecycleOwner: LifecycleOwner = LocalLifecycleOwner.current) { val surfaceRequest by viewModel.surfaceRequest.collectAsStateWithLifecycle() val context = LocalContext.current LaunchedEffect(lifecycleOwner) { viewModel.bindToCamera(context.applicationContext, lifecycleOwner) } var autofocusRequest by remember { mutableStateOf(UUID.randomUUID() to Offset.Unspecified) } val autofocusRequestId = autofocusRequest.first // Show the autofocus indicator if the offset is specified val showAutofocusIndicator = autofocusRequest.second.isSpecified // Cache the initial coords for each autofocus request val autofocusCoords = remember(autofocusRequestId) { autofocusRequest.second } // Queue hiding the request for each unique autofocus tap if (showAutofocusIndicator) { LaunchedEffect(autofocusRequestId) { delay(1000) // Clear the offset to finish the request and hide the indicator autofocusRequest = autofocusRequestId to Offset.Unspecified } } surfaceRequest?.let { request -\u003e val coordinateTransformer = remember { MutableCoordinateTransformer() } CameraXViewfinder( surfaceRequest = request, coordinateTransformer = coordinateTransformer, modifier = modifier.pointerInput(viewModel, coordinateTransformer) { detectTapGestures { tapCoords -\u003e with(coordinateTransformer) { viewModel.tapToFocus(tapCoords.transform()) } autofocusRequest = UUID.randomUUID() to tapCoords } } ) AnimatedVisibility( visible = showAutofocusIndicator, enter = fadeIn(), exit = fadeOut(), modifier = Modifier .offset { autofocusCoords.takeOrElse { Offset.Zero } .round() } .offset((-24).dp, (-24).dp) ) { Spacer(Modifier.border(2.dp, Color.White, CircleShape).size(48.dp)) } }}We use the mutable state autofocusRequest to manage the visibility state of the focus box and the tap coordinates.A LaunchedEffect is used to trigger the animation. When the autofocusRequest is updated, we briefly show the autofocus box and hide it after a delay.We use AnimatedVisibility to show the focus box with a fade-in and fade-out animation.The focus box is a simple Spacer with a white border in a circular shape, positioned using offset modifiers.In this sample, we chose a simple white circle fading in and out, but the sky is the limit and you can create any UI using the powerful Compose components and animation system. Confetti, anyone? ðŸŽŠResultOur camera preview now responds to touch events! Tapping on the preview triggers a focus action in the camera and shows a visual indicator where you tapped. You can find the full code snippet here and a version using the Konfetti library here.In the next post, weâ€™ll explore how to overlay Compose UI elements on top of your camera preview for a fancy spotlight effect. Stay tuned!",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*k-WDMPkp9zsnxyyQ6v1VMA.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"0ed5\"\u003ePart 2 of Unlocking the Power of CameraX in Jetpack Compose\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca rel=\"noopener follow\" href=\"https://medium.com/@lojanda?source=post_page---byline--440853280a6e--------------------------------\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Jolanda Verhoef\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*XXxKnGkW5RkuVemStEYjdw.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/androiddevelopers?source=post_page---byline--440853280a6e--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Android Developers\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*4Tg6pPzer7cIarYaszIKaQ.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"50c3\"\u003e\u003cem\u003eThis blog post is a part of Camera and Media Spotlight Week. Weâ€™re providing resources â€” blog posts, videos, sample code, and more â€” all designed to help you uplevel the media experiences in your app.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"863d\"\u003e\u003cem\u003eTo learn more about what Spotlight Week has to offer and how it can benefit you, be sure to \u003c/em\u003e\u003ca href=\"https://android-developers.googleblog.com/2025/01/spotlight-week-android-camera-and-media.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eread our overview blog post\u003c/em\u003e\u003c/a\u003e\u003cem\u003e.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"12ea\"\u003eWelcome back! In \u003ca rel=\"noopener\" href=\"https://medium.com/androiddevelopers/getting-started-with-camerax-in-jetpack-compose-781c722ca0c4\"\u003ethe first post of this series\u003c/a\u003e, we built a basic camera preview using the new \u003ccode\u003e\u003ca href=\"https://developer.android.com/jetpack/androidx/releases/camera#1.5.0-alpha01\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecamera-compose\u003c/a\u003e\u003c/code\u003e artifact. We covered permission handling and basic integration, and now itâ€™s time to get more interactive!\u003c/p\u003e\u003cul\u003e\u003cli id=\"0918\"\u003eðŸ§±\u003cstrong\u003e \u003c/strong\u003e\u003ca rel=\"noopener\" href=\"https://medium.com/androiddevelopers/getting-started-with-camerax-in-jetpack-compose-781c722ca0c4\"\u003e\u003cstrong\u003ePart 1\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e:\u003c/strong\u003e Building a basic camera preview using the new camera-compose artifact. Weâ€™ll cover permission handling and basic integration.\u003c/li\u003e\u003cli id=\"7694\"\u003eðŸ‘† \u003cstrong\u003ePart 2 (this post): \u003c/strong\u003eUsing the Compose gesture system, graphics, and coroutines to implement a visual tap-to-focus.\u003c/li\u003e\u003cli id=\"3834\"\u003eðŸ”Ž \u003cstrong\u003ePart 3:\u003c/strong\u003e Exploring how to overlay Compose UI elements on top of your camera preview for a richer user experience.\u003c/li\u003e\u003cli id=\"57e8\"\u003eðŸ“‚ \u003cstrong\u003ePart 4: \u003c/strong\u003eUsing adaptive APIs and the Compose animation framework to smoothly animate to and from tabletop mode on foldable phones.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"ac22\"\u003eIn this post, weâ€™ll dive into implementing the tap-to-focus feature. This involves understanding how to translate Compose touch events to camera sensor coordinates, and adding a visual indicator to show the user where the camera is focusing.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"1310\"\u003e\u003cem\u003eThereâ€™s an \u003c/em\u003e\u003ca href=\"https://issuetracker.google.com/383692145\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eopen feature request\u003c/em\u003e\u003c/a\u003e\u003cem\u003e for a higher level composable that will contain more out-of-the-box functionality (like tap-to-focus and zooming). Please upvote the feature if you need this!\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"0921\"\u003eAdd tap-to-focus functionality to the view model\u003c/h2\u003e\u003cp id=\"7657\"\u003eFirst, letâ€™s modify the \u003ccode\u003eCameraPreviewViewModel\u003c/code\u003e to handle tap-to-focus logic. We need to adapt our existing code in two ways:\u003c/p\u003e\u003cul\u003e\u003cli id=\"9818\"\u003eWe hold on to a \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/androidx/camera/core/SurfaceOrientedMeteringPointFactory\\\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSurfaceOrientedMeteringPointFactory\u003c/a\u003e\u003c/code\u003e, that is able to translate the tap coordinates coming from the UI into a \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/androidx/camera/core/MeteringPoint\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMeteringPoint\u003c/a\u003e\u003c/code\u003e.\u003c/li\u003e\u003cli id=\"39a3\"\u003eWe hold on to a \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/androidx/camera/core/CameraControl\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCameraControl\u003c/a\u003e\u003c/code\u003e, that can be used to interact with the camera. Once we have the correct \u003ccode\u003eMeteringPoint\u003c/code\u003e, we pass it to that camera control to be used as the reference point for auto-focusing.\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003cspan id=\"5e9c\"\u003eclass CameraPreviewViewModel : ViewModel() {\u003cbr/\u003e    ..\u003cbr/\u003e    private var surfaceMeteringPointFactory: SurfaceOrientedMeteringPointFactory? = null\u003cbr/\u003e    private var cameraControl: CameraControl? = null\u003cp\u003e    private val cameraPreviewUseCase = Preview.Builder().build().apply {\u003cbr/\u003e        setSurfaceProvider { newSurfaceRequest -\u0026gt;\u003cbr/\u003e            _surfaceRequest.update { newSurfaceRequest }\u003cbr/\u003e            surfaceMeteringPointFactory = SurfaceOrientedMeteringPointFactory(\u003cbr/\u003e                newSurfaceRequest.resolution.width.toFloat(),\u003cbr/\u003e                newSurfaceRequest.resolution.height.toFloat()\u003cbr/\u003e            )\u003cbr/\u003e        }\u003cbr/\u003e    }\u003c/p\u003e\u003cp\u003e    suspend fun bindToCamera(appContext: Context, lifecycleOwner: LifecycleOwner) {\u003cbr/\u003e        val processCameraProvider = ProcessCameraProvider.awaitInstance(appContext)\u003cbr/\u003e        val camera = processCameraProvider.bindToLifecycle(\u003cbr/\u003e            lifecycleOwner, DEFAULT_BACK_CAMERA, cameraPreviewUseCase\u003cbr/\u003e        )\u003cbr/\u003e        cameraControl = camera.cameraControl\u003c/p\u003e\u003cp\u003e        // Cancellation signals we\u0026#39;re done with the camera\u003cbr/\u003e        try { awaitCancellation() } finally {\u003cbr/\u003e            processCameraProvider.unbindAll()\u003cbr/\u003e            cameraControl = null\u003cbr/\u003e        }\u003cbr/\u003e    }\u003c/p\u003e\u003cp\u003e    fun tapToFocus(tapCoords: Offset) {\u003cbr/\u003e        val point = surfaceMeteringPointFactory?.createPoint(tapCoords.x, tapCoords.y)\u003cbr/\u003e        if (point != null) {\u003cbr/\u003e            val meteringAction = FocusMeteringAction.Builder(point).build()\u003cbr/\u003e            cameraControl?.startFocusAndMetering(meteringAction)\u003cbr/\u003e        }\u003cbr/\u003e    }\u003cbr/\u003e}\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cul\u003e\u003cli id=\"d350\"\u003eWe create a \u003ccode\u003eSurfaceOrientedMeteringPointFactory\u003c/code\u003e when the \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/androidx/camera/core/SurfaceRequest\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSurfaceRequest\u003c/a\u003e\u003c/code\u003e is available, using the surfaceâ€™s resolution. This factory translates the tapped coordinates on the surface to a focus metering point.\u003c/li\u003e\u003cli id=\"16f3\"\u003eWe assign the \u003ccode\u003ecameraControl\u003c/code\u003e attached to the \u003ccode\u003eCamera\u003c/code\u003e when we bind to the cameraâ€™s lifecycle. We then reset it to null when the lifecycle ends.\u003c/li\u003e\u003cli id=\"425c\"\u003eThe \u003ccode\u003etapToFocus\u003c/code\u003e function takes an \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/kotlin/androidx/compose/ui/geometry/Offset\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eOffset\u003c/a\u003e\u003c/code\u003e representing the tap location in sensor coordinates, translates it to a \u003ccode\u003eMeteringPoint\u003c/code\u003e using the factory, and then uses the CameraX \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/androidx/camera/core/CameraControl\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecameraControl\u003c/a\u003e\u003c/code\u003e to initiate the focus and metering action.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"9e73\"\u003e\u003cem\u003eNote: We could improve the interaction between UI and CameraControl somewhat by using a more sophisticated coroutines setup, but this is outside the scope of this blog post. If youâ€™re interested in learning more about such an implementation, check out the \u003c/em\u003e\u003ca href=\"https://github.com/google/jetpack-camera-app\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eJetpack Camera App sample\u003c/em\u003e\u003c/a\u003e\u003cem\u003e, which implements camera interactions through the \u003c/em\u003e\u003ca href=\"https://github.com/google/jetpack-camera-app/blob/41f953fde14bca11fed9534d074a9f5f67e8eaac/core/camera/src/main/java/com/google/jetpackcamera/core/camera/CameraXCameraUseCase.kt#L108\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eCameraXCameraUseCase\u003c/em\u003e\u003c/a\u003e\u003cem\u003e.\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"ff0d\"\u003eTransform gesture from display to sensor coordinates\u003c/h2\u003e\u003cp id=\"3df6\"\u003eNow, letâ€™s update the \u003ccode\u003eCameraPreviewContent\u003c/code\u003e composable to handle touch events and pass those events to the view model. To do that, weâ€™ll use the \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/kotlin/androidx/compose/ui/input/pointer/package-summary#(androidx.compose.ui.Modifier).pointerInput(kotlin.Any,kotlin.Any,kotlin.coroutines.SuspendFunction1)\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003epointerInput\u003c/a\u003e\u003c/code\u003e modifier and the \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/kotlin/androidx/compose/foundation/gestures/package-summary#(androidx.compose.ui.input.pointer.PointerInputScope).detectTapGestures(kotlin.Function1,kotlin.Function1,kotlin.coroutines.SuspendFunction2,kotlin.Function1)\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edetectTapGestures\u003c/a\u003e\u003c/code\u003e extension function:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"66c6\"\u003e@Composable\u003cbr/\u003efun CameraPreviewContent(..) {\u003cbr/\u003e    ..\u003cp\u003e    surfaceRequest?.let { request -\u0026gt;\u003cbr/\u003e        val coordinateTransformer = remember { MutableCoordinateTransformer() }\u003cbr/\u003e        CameraXViewfinder(\u003cbr/\u003e            surfaceRequest = request,\u003cbr/\u003e            coordinateTransformer = coordinateTransformer,\u003cbr/\u003e            modifier = modifier.pointerInput(Unit) {\u003cbr/\u003e                detectTapGestures { tapCoords -\u0026gt;\u003cbr/\u003e                    with(coordinateTransformer) {\u003cbr/\u003e                        viewModel.tapToFocus(tapCoords.transform()) \u003cbr/\u003e                    }\u003cbr/\u003e                }\u003cbr/\u003e            }\u003cbr/\u003e        )\u003cbr/\u003e    }\u003cbr/\u003e}\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cul\u003e\u003cli id=\"eb95\"\u003eWe use the \u003ccode\u003epointerInput\u003c/code\u003e modifier and \u003ccode\u003edetectTapGestures\u003c/code\u003e to listen for tap events on the \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/kotlin/androidx/camera/compose/package-summary#CameraXViewfinder(androidx.camera.core.SurfaceRequest,androidx.compose.ui.Modifier,androidx.camera.viewfinder.surface.ImplementationMode,androidx.camera.viewfinder.compose.MutableCoordinateTransformer)\\\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCameraXViewfinder\u003c/a\u003e\u003c/code\u003e.\u003c/li\u003e\u003cli id=\"d623\"\u003eWe create a \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/kotlin/androidx/camera/viewfinder/compose/MutableCoordinateTransformer\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMutableCoordinateTransformer\u003c/a\u003e\u003c/code\u003e, which is provided by the \u003ccode\u003ecamera-compose\u003c/code\u003e library, to transform the tap coordinates from the layoutâ€™s coordinate system to the sensorâ€™s coordinate system. \u003cstrong\u003eThis transformation is non-trivial!\u003c/strong\u003e The physical sensor is often rotated relative to the screen, and additional scaling and cropping is done to make the image fit the container itâ€™s in. We pass the mutable transformer instance into the \u003ccode\u003eCameraXViewfinder\u003c/code\u003e. Internally, the viewfinder sets the transformation matrix of the transformer. This transformation matrix is capable of transforming local window coordinates into sensor coordinates.\u003c/li\u003e\u003cli id=\"d4d1\"\u003eInside the \u003ccode\u003edetectTapGestures\u003c/code\u003e block, we use the \u003ccode\u003ecoordinateTransformer\u003c/code\u003e to transform the tap coordinates before passing them to the \u003ccode\u003etapToFocus\u003c/code\u003e function of our view model.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"25c7\"\u003eAs weâ€™re using typical Compose gesture handling, \u003cstrong\u003ewe unlock any sort of gesture recognition\u003c/strong\u003e. So if you want to focus after the user triple-taps, or swipes up and down, nothing is holding you back! This is an example of the power of the new CameraX Compose APIs. They are built from the ground up, in an open way, so that you can extend and build whatever you need on top of them. Compare this to the old \u003ccode\u003e\u003ca href=\"https://developer.android.com/reference/androidx/camera/view/CameraController\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCameraController\u003c/a\u003e\u003c/code\u003e that had tap-to-focus built in â€” thatâ€™s great if tap-to-focus is what you need, but it didnâ€™t give you any opportunity to customize the behavior.\u003c/p\u003e\u003ch2 id=\"2e91\"\u003eVisual indicator when tapping to focus\u003c/h2\u003e\u003cp id=\"5629\"\u003eTo provide visual feedback to the user, weâ€™ll add a small white circle that briefly appears at the tap location. Weâ€™ll use Compose animation APIs to fade it in and out:\u003c/p\u003e\u003cpre\u003e\u003cspan id=\"00fa\"\u003e@Composable\u003cbr/\u003efun CameraPreviewContent(\u003cbr/\u003e    viewModel: CameraPreviewViewModel,\u003cbr/\u003e    modifier: Modifier = Modifier,\u003cbr/\u003e    lifecycleOwner: LifecycleOwner = LocalLifecycleOwner.current\u003cbr/\u003e) {\u003cbr/\u003e    val surfaceRequest by viewModel.surfaceRequest.collectAsStateWithLifecycle()\u003cbr/\u003e    val context = LocalContext.current\u003cbr/\u003e    LaunchedEffect(lifecycleOwner) {\u003cbr/\u003e        viewModel.bindToCamera(context.applicationContext, lifecycleOwner)\u003cbr/\u003e    }\u003cp\u003e    var autofocusRequest by remember { mutableStateOf(UUID.randomUUID() to Offset.Unspecified) }\u003c/p\u003e\u003cp\u003e    val autofocusRequestId = autofocusRequest.first\u003cbr/\u003e    // Show the autofocus indicator if the offset is specified\u003cbr/\u003e    val showAutofocusIndicator = autofocusRequest.second.isSpecified\u003cbr/\u003e    // Cache the initial coords for each autofocus request\u003cbr/\u003e    val autofocusCoords = remember(autofocusRequestId) { autofocusRequest.second }\u003c/p\u003e\u003cp\u003e    // Queue hiding the request for each unique autofocus tap\u003cbr/\u003e    if (showAutofocusIndicator) {\u003cbr/\u003e        LaunchedEffect(autofocusRequestId) {\u003cbr/\u003e            delay(1000)\u003cbr/\u003e            // Clear the offset to finish the request and hide the indicator\u003cbr/\u003e            autofocusRequest = autofocusRequestId to Offset.Unspecified\u003cbr/\u003e        }\u003cbr/\u003e    }\u003c/p\u003e\u003cp\u003e    surfaceRequest?.let { request -\u0026gt;\u003cbr/\u003e        val coordinateTransformer = remember { MutableCoordinateTransformer() }\u003cbr/\u003e        CameraXViewfinder(\u003cbr/\u003e            surfaceRequest = request,\u003cbr/\u003e            coordinateTransformer = coordinateTransformer,\u003cbr/\u003e            modifier = modifier.pointerInput(viewModel, coordinateTransformer) {\u003cbr/\u003e                detectTapGestures { tapCoords -\u0026gt;\u003cbr/\u003e                    with(coordinateTransformer) {\u003cbr/\u003e                        viewModel.tapToFocus(tapCoords.transform())\u003cbr/\u003e                    }\u003cbr/\u003e                    autofocusRequest = UUID.randomUUID() to tapCoords\u003cbr/\u003e                }\u003cbr/\u003e            }\u003cbr/\u003e        )\u003c/p\u003e\u003cp\u003e        AnimatedVisibility(\u003cbr/\u003e            visible = showAutofocusIndicator,\u003cbr/\u003e            enter = fadeIn(),\u003cbr/\u003e            exit = fadeOut(),\u003cbr/\u003e            modifier = Modifier\u003cbr/\u003e                .offset { autofocusCoords.takeOrElse { Offset.Zero } .round() }\u003cbr/\u003e                .offset((-24).dp, (-24).dp)\u003cbr/\u003e        ) {\u003cbr/\u003e            Spacer(Modifier.border(2.dp, Color.White, CircleShape).size(48.dp))\u003cbr/\u003e        }\u003cbr/\u003e    }\u003cbr/\u003e}\u003c/p\u003e\u003c/span\u003e\u003c/pre\u003e\u003cul\u003e\u003cli id=\"d654\"\u003eWe use the mutable state \u003ccode\u003eautofocusRequest\u003c/code\u003e to manage the visibility state of the focus box and the tap coordinates.\u003c/li\u003e\u003cli id=\"a72f\"\u003eA \u003ccode\u003eLaunchedEffect\u003c/code\u003e is used to trigger the animation. When the \u003ccode\u003eautofocusRequest\u003c/code\u003e is updated, we briefly show the autofocus box and hide it after a delay.\u003c/li\u003e\u003cli id=\"d94c\"\u003eWe use \u003ccode\u003eAnimatedVisibility\u003c/code\u003e to show the focus box with a fade-in and fade-out animation.\u003c/li\u003e\u003cli id=\"c478\"\u003eThe focus box is a simple \u003ccode\u003eSpacer\u003c/code\u003e with a white border in a circular shape, positioned using offset modifiers.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"e11e\"\u003eIn this sample, we chose a simple white circle fading in and out, but the sky is the limit and you can create any UI using the powerful Compose components and animation system. Confetti, anyone? ðŸŽŠ\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"d4d9\"\u003eResult\u003c/h2\u003e\u003cp id=\"2f36\"\u003eOur camera preview now responds to touch events! Tapping on the preview triggers a focus action in the camera and shows a visual indicator where you tapped. You can find the full code snippet \u003ca href=\"https://gist.github.com/JolandaVerhoef/74d4696b804736c698450bd34b5c9ff8#file-2_1_tap_to_focus-kt\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehere\u003c/a\u003e and a version using the \u003ca href=\"https://github.com/DanielMartinus/Konfetti\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKonfetti\u003c/a\u003e library \u003ca href=\"https://gist.github.com/JolandaVerhoef/74d4696b804736c698450bd34b5c9ff8#file-2_2_tap_to_focus_konfetti-kt\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp id=\"18a0\"\u003eIn the next post, weâ€™ll explore how to overlay Compose UI elements on top of your camera preview for a fancy spotlight effect. Stay tuned!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-01-09T17:04:14.28Z",
  "modifiedTime": null
}
