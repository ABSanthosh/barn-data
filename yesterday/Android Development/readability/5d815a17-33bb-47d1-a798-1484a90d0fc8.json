{
  "id": "5d815a17-33bb-47d1-a798-1484a90d0fc8",
  "title": "QuickTrim | Creating Transcription based video Trimmer with Media3 Transformer",
  "link": "https://proandroiddev.com/quicktrim-creating-transcription-based-video-trimmer-with-media3-transformer-fe7e1e610905?source=rss----c72404660798---4",
  "description": "",
  "author": "Nikhil Mandlik",
  "published": "Sat, 21 Jun 2025 19:28:57 GMT",
  "source": "https://proandroiddev.com/feed",
  "categories": [
    "androiddev",
    "android-app-development",
    "jetpack-compose",
    "media3",
    "android"
  ],
  "byline": "Nikhil Mandlik",
  "length": 2737,
  "excerpt": "With transcription APIs that support word alignment, we can trim exact words or sentences from a video. This lets users remove filler words, bad takes, or silences easily. The result is a clean and‚Ä¶",
  "siteName": "ProAndroidDev",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*A8VytPZQhvUf_MG6hm_Dlw.png",
  "text": "With transcription APIs that support word alignment, we can trim exact words or sentences from a video. This lets users remove filler words, bad takes, or silences easily. The result is a clean and polished video. This blog explains how I built QuickTrim using Media3 Transformer and ElevenLabs APIs.QuickTrim Android | Transcription Based Video TrimmerHigh Level OverviewThe core idea is to extract audio from a video, convert it into a transcript using a speech-to-text API, allow user to trim the video based on words or segments in the transcript. and Export the edited media sequenceüîä Step 1: Audio Extraction:Most transcription APIs require only audio input. The EditedMediaItem.setRemoveVideo(true) method is used to strip the video and retain only the audio, which is then saved in the cache directory.üìÉ Step 2: Generating TranscriptOnce audio extraction is complete, the file is sent to the ElevenLabs Speech-to-Text API, which returns a transcription with word-level timestamps. The API also supports additional output formats such as:SegmentedJson (sentence-level breakdown)SRT (subtitle format)In this application, the segmented JSON format is used. More details can be found in the official ElevenLabs documentation.API Interface for calling speech-to-text endpoint:üé• Step 3: Removing Filler Words and Segments with Real-Time PreviewOnce the transcription is generated, users can remove specific words or segments by toggling them in the transcript. After each update, a real-time preview of the trimmed video is played. Since Media3 does not support direct preview of Composition objects, an alternative approach is used. Instead of building a new composition on every change, the application computes keep intervals‚Äîthe sections of the video that remain. Clipped MediaItems are then created for each interval and passed to ExoPlayer as a list using setMediaItems(), enabling seamless playback of the edited sequence in real time.Real-time preview is generated on each edit as follows:‚è≥ Step 4: Exporting Edited MediaOnce editing is finalized, the final trimmed video is exported through the following steps:Compute Keep Intervals: Identify portions of the video to retain based on removed segments like filler words or silences.Build Clipped MediaItems: Create a MediaItem for each keep interval using clipping configurations for the corresponding start and end times.Compose Edited Sequence: Wrap the clipped items into an EditedMediaItemSequence and include it in a Composition.Start Export: Pass the Composition to Transformer, which muxes and encodes the result into a .mp4 file.üöÄ Wrapping UpThanks for Reading! For low-level implementation details, refer to the GitHub repository or drop a question in the comments üòÑ.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*BgZ_EK7cLAxXoonvoLfcPQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@nikhil.here?source=post_page---byline--fe7e1e610905---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Nikhil Mandlik\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*phVGVUHy5uG9cSGfQX12QQ.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp id=\"beb0\"\u003eWith transcription APIs that support word alignment, we can trim exact words or sentences from a video. This lets users remove filler words, bad takes, or silences easily. The result is a clean and polished video. This blog explains how I built \u003ca href=\"https://github.com/nikhil-here/quicktrim-android\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eQuickTrim\u003c/a\u003e using \u003ca href=\"https://developer.android.com/media/media3/transformer\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMedia3 Transformer\u003c/a\u003e and \u003ca href=\"https://elevenlabs.io/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eElevenLabs APIs.\u003c/a\u003e\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eQuickTrim Android | Transcription Based Video Trimmer\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"b228\"\u003eHigh Level Overview\u003c/h2\u003e\u003cp id=\"dc5b\"\u003eThe core idea is to extract audio from a video, convert it into a transcript using a speech-to-text API, allow user to trim the video based on words or segments in the transcript. and Export the edited media sequence\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"fd78\"\u003e\u003cstrong\u003eüîä Step 1: Audio Extraction:\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"eae8\"\u003eMost transcription APIs require only audio input. The \u003ccode\u003eEditedMediaItem.setRemoveVideo(true)\u003c/code\u003e method is used to strip the video and retain only the audio, which is then saved in the cache directory.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"0dd2\"\u003eüìÉ Step 2: Generating Transcript\u003c/h2\u003e\u003cp id=\"35df\"\u003eOnce audio extraction is complete, the file is sent to the ElevenLabs Speech-to-Text API, which returns a transcription with word-level timestamps. The API also supports additional output formats such as:\u003c/p\u003e\u003cul\u003e\u003cli id=\"582b\"\u003eSegmentedJson (sentence-level breakdown)\u003c/li\u003e\u003cli id=\"5136\"\u003eSRT (subtitle format)\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"3aab\"\u003eIn this application, the segmented JSON format is used. More details can be found in the official \u003ca href=\"https://elevenlabs.io/docs/api-reference/speech-to-text/convert\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eElevenLabs documentation\u003c/a\u003e.\u003c/p\u003e\u003cp id=\"6e9f\"\u003eAPI Interface for calling speech-to-text endpoint:\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"c140\"\u003eüé• Step 3: Removing Filler Words and Segments with Real-Time Preview\u003c/h2\u003e\u003cp id=\"8a52\"\u003eOnce the transcription is generated, users can remove specific words or segments by toggling them in the transcript. After each update, a real-time preview of the trimmed video is played. Since Media3 does not support direct preview of \u003ccode\u003eComposition\u003c/code\u003e objects, an alternative approach is used. Instead of building a new composition on every change, the application computes \u003ccode\u003ekeep intervals\u003c/code\u003e‚Äîthe sections of the video that remain. Clipped \u003ccode\u003eMediaItem\u003c/code\u003es are then created for each interval and passed to ExoPlayer as a list using \u003ccode\u003esetMediaItems()\u003c/code\u003e, enabling seamless playback of the edited sequence in real time.\u003c/p\u003e\u003cp id=\"8caf\"\u003eReal-time preview is generated on each edit as follows:\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"581a\"\u003e‚è≥ Step 4: Exporting Edited Media\u003c/h2\u003e\u003cp id=\"a07a\"\u003eOnce editing is finalized, the final trimmed video is exported through the following steps:\u003c/p\u003e\u003col\u003e\u003cli id=\"d81e\"\u003e\u003cstrong\u003eCompute Keep Intervals\u003c/strong\u003e: Identify portions of the video to retain based on removed segments like filler words or silences.\u003c/li\u003e\u003cli id=\"9b49\"\u003e\u003cstrong\u003eBuild Clipped MediaItems\u003c/strong\u003e: Create a \u003ccode\u003eMediaItem\u003c/code\u003e for each keep interval using clipping configurations for the corresponding start and end times.\u003c/li\u003e\u003cli id=\"8f3b\"\u003e\u003cstrong\u003eCompose Edited Sequence\u003c/strong\u003e: Wrap the clipped items into an \u003ccode\u003eEditedMediaItemSequence\u003c/code\u003e and include it in a \u003ccode\u003eComposition\u003c/code\u003e.\u003c/li\u003e\u003cli id=\"eb27\"\u003e\u003cstrong\u003eStart Export\u003c/strong\u003e: Pass the \u003ccode\u003eComposition\u003c/code\u003e to \u003ccode\u003eTransformer\u003c/code\u003e, which muxes and encodes the result into a \u003ccode\u003e.mp4\u003c/code\u003e file.\u003c/li\u003e\u003c/ol\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"5184\"\u003eüöÄ Wrapping Up\u003c/h2\u003e\u003cp id=\"e37a\"\u003eThanks for Reading! For low-level implementation details, refer to the GitHub repository or drop a question in the comments üòÑ.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-06-21T19:28:57.302Z",
  "modifiedTime": null
}
