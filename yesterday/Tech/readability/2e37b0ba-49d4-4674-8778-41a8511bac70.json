{
  "id": "2e37b0ba-49d4-4674-8778-41a8511bac70",
  "title": "Gen AI's Accuracy Problems Aren't Going Away Anytime Soon, Researchers Say",
  "link": "https://www.cnet.com/tech/services-and-software/gen-ais-accuracy-problems-arent-going-away-anytime-soon-researchers-say/#ftag=CAD590a51e",
  "description": "Artificial intelligence needs to get a lot more reliable if it's going to catch up with the hype cycle.",
  "author": "Jon Reed",
  "published": "Fri, 21 Mar 2025 22:23:00 +0000",
  "source": "https://www.cnet.com/rss/news/",
  "categories": null,
  "byline": "Jon Reed",
  "length": 9655,
  "excerpt": "Artificial intelligence needs to get a lot more reliable if it's going to catch up with the hype cycle.",
  "siteName": "CNET",
  "favicon": "https://www.cnet.com/favicon-480.png",
  "text": "Artificial intelligence needs to get a lot more reliable if it's going to catch up with the hype cycle. Jon Reed is a senior editor overseeing coverage for CNET's home, energy and utilities category. Jon has over a decade of experience of writing and reporting as a statehouse reporter in Columbus, Ohio, a crime reporter in Birmingham, Alabama, and as an mortgage and housing market editor for TIME's former personal finance brand, NextAdvisor. Jon now leads coverage and strategy on CNET's Energy category and aims to help readers take charge of their home's energy usage and costs. Jon has first-hand experience testing home energy products such as portable power stations, home battery solutions and smart thermostats. Jon has showcased his expertise live on TV for news networks and his written work is often cited in major publications such as This Week in CleanTech, NASDAQ and MorningBrew's newsletter. When not asking people questions about energy, he can usually be found half asleep trying to read a long history book while surrounded by multiple cats. You can reach Jon at joreed@cnet.com Expertise Energy, Solar Power, Renewable Energy, Climate Issues, Virtual Power Plants, Grid Infrastructure, Electric Vehicles, Plug-in Hybrids, Energy-Savings Tips, Smart Thermostats, Portable Power Stations, Home Battery Solutions, EV Charging Infrastructure, Home Generative AI chatbots are known to make a lot of mistakes. Let's hope you didn't follow Google's AI suggestion to add glue to your pizza recipe or eat a rock or two a day for your health. These errors are known as hallucinations: essentially, things the model makes up. Will this technology get better? Even researchers who study AI aren't optimistic that'll happen soon.That's one of the findings by a panel of two dozen artificial intelligence experts released this month by the Association for the Advancement of Artificial Intelligence. The group also surveyed more than 400 of the association's members.  In contrast to the hype you may see about developers being just years (or months, depending on who you ask) away from improving AI, this panel of academics and industry experts seems more guarded about how quickly these tools will advance. That includes not just getting facts right and avoiding bizarre mistakes. The reliability of AI tools needs to increase dramatically if developers are going to produce a model that can meet or surpass human intelligence, commonly known as artificial general intelligence. Researchers seem to believe improvements at that scale are unlikely to happen soon.\"We tend to be a little bit cautious and not believe something until it actually works,\" Vincent Conitzer, a professor of computer science at Carnegie Mellon University and one of the panelists, told me.Artificial intelligence has developed rapidly in recent yearsThe report's goal, AAAI president Francesca Rossi wrote in its introduction, is to support research in artificial intelligence that produces technology that helps people. Issues of trust and reliability are serious, not just in providing accurate information but in avoiding bias and ensuring a future AI doesn't cause severe unintended consequences. \"We all need to work together to advance AI in a responsible way, to make sure that technological progress supports the progress of humanity and is aligned to human values,\" she wrote. The acceleration of AI, especially since OpenAI launched ChatGPT in 2022, has been remarkable, Conitzer said. \"In some ways that's been stunning, and many of these techniques work much better than most of us ever thought that they would,\" he said.There are some areas of AI research where \"the hype does have merit,\" John Thickstun, assistant professor of computer science at Cornell University, told me. That's especially true in math or science, where users can check a model's results. \"This technology is amazing,\" Thickstun said. \"I've been working in this field for over a decade, and it's shocked me how good it's become and how fast it's become good.\"Despite those improvements, there are still significant issues that merit research and consideration, experts said.Will chatbots start to get their facts straight?Despite some progress in improving the trustworthiness of the information that comes from generative AI models, much more work needs to be done. A recent report from Columbia Journalism Review found chatbots were unlikely to decline to answer questions they couldn't answer accurately, confident about the wrong information they provided and made up (and provided fabricated links to) sources to back up those wrong assertions. Improving reliability and accuracy \"is arguably the biggest area of AI research today,\" the AAAI report said.Researchers noted three main ways to boost the accuracy of AI systems: fine-tuning, such as reinforcing learning with human feedback; retrieval-augmented generation, in which the system gathers specific documents and pulls its answer from those; and chain-of-thought, where prompts break down the question into smaller steps that the AI model can check for hallucinations.Will those things make your chatbot responses more accurate soon? Not likely: \"Factuality is far from solved,\" the report said. About 60% of those surveyed indicated doubts that factuality or trustworthiness concerns would be solved soon. In the generative AI industry, there has been optimism that scaling up existing models will make them more accurate and reduce hallucinations. \"I think that hope was always a little bit overly optimistic,\" Thickstun said. \"Over the last couple of years, I haven't seen any evidence that really accurate, highly factual language models are around the corner.\"Despite the fallibility of large language models such as Anthropic's Claude or Meta's Llama, users can mistakenly assume they're more accurate because they present answers with confidence, Conitzer said. \"If we see somebody responding confidently or words that sound confident, we take it that the person really knows what they're talking about,\" he said. \"An AI system, it might just claim to be very confident about something that's completely nonsense.\"Lessons for the AI userAwareness of generative AI's limitations is vital to using it properly. Thickstun's advice for users of models such as ChatGPT and Google's Gemini is simple: \"You have to check the results.\"General large language models do a poor job of consistently retrieving factual information, he said. If you ask it for something, you should probably follow up by looking up the answer in a search engine (and not relying on the AI summary of the search results). By the time you do that, you might have been better off doing that in the first place.Thickstun said the way he uses AI models most is to automate tasks that he could do anyway and that he can check the accuracy, such as formatting tables of information or writing code. \"The broader principle is that I find these models are most useful for automating work that you already know how to do,\" he said.Read more: 5 Ways to Stay Smart When Using Gen AI, Explained by Computer Science ProfessorsIs artificial general intelligence around the corner?One priority of the AI development industry is an apparent race to create what's often called artificial general intelligence, or AGI. This is a model that is generally capable of a human level of thought or better. The report's survey found strong opinions on the race for AGI. Notably, more than three-quarters (76%) of respondents said scaling up current AI techniques such as large language models was unlikely to produce AGI. A significant majority of researchers doubt the current march toward AGI will work.A similarly large majority believe systems capable of artificial general intelligence should be publicly owned if they're developed by private entities (82%). That aligns with concerns about the ethics and potential downsides of creating a system that can outthink humans. Most researchers (70%) said they oppose stopping AGI research until safety and control systems are developed. \"These answers seem to suggest a preference for continued exploration of the topic, within some safeguards,\" the report said.The conversation around AGI is complicated, Thickstun said. In some sense, we've already created systems that have a form of general intelligence. Large language models such as OpenAI's ChatGPT are capable of doing a variety of human activities, in contrast to older AI models that could only do one thing, such as play chess. The question is whether it can do many things consistently at a human level.\"I think we're very far away from this,\" Thickstun said.He said these models lack a built-in concept of truth and the ability to handle truly open-ended creative tasks. \"I don't see the path to making them operate robustly in a human environment using the current technology,\" he said. \"I think there are many research advances in the way of getting there.\"Conitzer said the definition of what exactly constitutes AGI is tricky: Often, people mean something that can do most tasks better than a human but some say it's just something capable of doing a range of tasks. \"A stricter definition is something that would really make us completely redundant,\" he said. While researchers are skeptical that AGI is around the corner, Conitzer cautioned that AI researchers didn't necessarily expect the dramatic technological improvement we've all seen in the past few years. \"We did not see coming how quickly things have changed recently,\" he said, \"and so you might wonder whether we're going to see it coming if it continues to go faster.\"",
  "image": "https://www.cnet.com/a/img/resize/0c4afc7e6b8833ce4a380a2b6bfc6877e1c5189a/hub/2025/03/21/025cc5d8-a551-42aa-ac72-908bddf25784/gettyimages-2204318121.jpg?auto=webp\u0026fit=crop\u0026height=675\u0026width=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e \u003cp\u003e\n    Artificial intelligence needs to get a lot more reliable if it\u0026#39;s going to catch up with the hype cycle.\n  \u003c/p\u003e \u003cdiv data-cy=\"globalAuthorImage\"\u003e\u003cdiv\u003e\u003cpicture\u003e \u003cimg src=\"https://www.cnet.com/a/img/resize/98841d2f30db19ca0642b7ae9d0d51b37561f48a/hub/2023/01/10/931ff7fd-78aa-4bd4-b424-379816356ccf/jonreed.jpg?auto=webp\u0026amp;fit=crop\u0026amp;height=96\u0026amp;width=96\" alt=\"Headshot of Jon Reed\" height=\"96\" width=\"96\"/\u003e\u003c/picture\u003e\u003c/div\u003e \u003cdiv section=\"authorCard\" id=\"author-card-0\"\u003e \u003cp\u003eJon Reed is a senior editor overseeing coverage for CNET\u0026#39;s home, energy and utilities category. Jon has over a decade of experience of writing and reporting as a statehouse reporter in Columbus, Ohio, a crime reporter in Birmingham, Alabama, and as an mortgage and housing market editor for TIME\u0026#39;s former personal finance brand, NextAdvisor. \n\nJon now leads coverage and strategy on CNET\u0026#39;s Energy category and aims to help readers take charge of their home\u0026#39;s energy usage and costs. Jon has first-hand experience testing home energy products such as portable power stations, home battery solutions and smart thermostats. Jon has showcased his expertise live on TV for news networks and his written work is often cited in major publications such as This Week in CleanTech, NASDAQ and MorningBrew\u0026#39;s newsletter. \n\nWhen not asking people questions about energy, he can usually be found half asleep trying to read a long history book while surrounded by multiple cats.\n\nYou can reach Jon at joreed@cnet.com\u003c/p\u003e \u003cp\u003e\u003cspan\u003eExpertise\u003c/span\u003e \u003cspan\u003eEnergy, Solar Power, Renewable Energy, Climate Issues, Virtual Power Plants, Grid Infrastructure, Electric Vehicles, Plug-in Hybrids, Energy-Savings Tips, Smart Thermostats, Portable Power Stations, Home Battery Solutions, EV Charging Infrastructure, Home\u003c/span\u003e  \u003c/p\u003e  \u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv id=\"article-12192307-a6a9-4f2f-81e2-c2b57258bfdc\"\u003e\u003carticle\u003e\u003cp\u003e\u003ca href=\"https://www.cnet.com/tech/services-and-software/generative-ai-what-you-need-to-know-about-the-tech-behind-chatgpt/\" target=\"_self\"\u003eGenerative AI chatbots\u003c/a\u003e are known to make a lot of mistakes. Let\u0026#39;s hope you didn\u0026#39;t follow Google\u0026#39;s AI suggestion to \u003ca href=\"https://www.cnet.com/tech/services-and-software/glue-in-pizza-eat-rocks-googles-ai-search-is-mocked-for-bizarre-answers/\" target=\"_self\"\u003eadd glue to your pizza recipe\u003c/a\u003e or eat a rock or two a day for your health. \u003c/p\u003e\u003cp\u003eThese errors are known as \u003ca href=\"https://www.cnet.com/tech/hallucinations-why-ai-makes-stuff-up-and-whats-being-done-about-it/\" target=\"_self\"\u003ehallucinations\u003c/a\u003e: essentially, things the model makes up. Will this technology get better? Even researchers who study \u003ca href=\"https://www.cnet.com/tech/services-and-software/best-ai-chatbots/\" target=\"_self\"\u003eAI\u003c/a\u003e aren\u0026#39;t optimistic that\u0026#39;ll happen soon.\u003c/p\u003e\u003cp\u003eThat\u0026#39;s one of the findings by a panel of \u003ca href=\"https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-Digital-3.7.25.pdf\" rel=\"noopener nofollow\" target=\"_blank\" title=\"(opens in a new window)\"\u003etwo dozen artificial intelligence experts\u003c/a\u003e released this month by the Association for the Advancement of Artificial Intelligence. The group also surveyed more than 400 of the association\u0026#39;s members. \u003c/p\u003e\u003cfigure\u003e\u003ca rel=\"\" href=\"https://www.cnet.com/ai-atlas/\" target=\"_blank\"\u003e \u003cdiv\u003e\u003cpicture\u003e\u003csource media=\"(max-width: 767px)\" srcset=\"https://www.cnet.com/a/img/resize/6bd4587def86e9b1261141196ef1cac4f6209007/hub/2024/04/16/660f9254-c869-4a08-9ba6-93c16106b001/ai-atlas-tag.png?auto=webp\u0026amp;width=768\" alt=\"AI Atlas\"/\u003e\u003csource media=\"(max-width: 1023px)\" srcset=\"https://www.cnet.com/a/img/resize/6bd4587def86e9b1261141196ef1cac4f6209007/hub/2024/04/16/660f9254-c869-4a08-9ba6-93c16106b001/ai-atlas-tag.png?auto=webp\u0026amp;width=768\" alt=\"AI Atlas\"/\u003e\u003csource media=\"(max-width: 1440px)\" srcset=\"https://www.cnet.com/a/img/resize/6bd4587def86e9b1261141196ef1cac4f6209007/hub/2024/04/16/660f9254-c869-4a08-9ba6-93c16106b001/ai-atlas-tag.png?auto=webp\u0026amp;width=768\" alt=\"AI Atlas\"/\u003e \u003cimg src=\"\" alt=\"AI Atlas\" height=\"268.29694323144105\" width=\"768\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e  \u003c/a\u003e \u003c/figure\u003e\u003cp\u003eIn contrast to the hype you may see about developers being just years (or months, depending on who you ask) away from improving AI, this panel of academics and industry experts seems more guarded about how quickly these tools will advance. That includes not just getting facts right and avoiding bizarre mistakes. The reliability of AI tools needs to increase dramatically if developers are going to produce a model that can \u003ca href=\"https://www.cnet.com/tech/theres-ai-and-then-theres-agi-what-you-need-to-know-to-tell-the-difference/\" target=\"_self\"\u003emeet or surpass human intelligence\u003c/a\u003e, commonly known as artificial general intelligence. Researchers seem to believe improvements at that scale are unlikely to happen soon.\u003c/p\u003e\u003cp\u003e\u0026#34;We tend to be a little bit cautious and not believe something until it actually works,\u0026#34; \u003ca href=\"https://www.cs.cmu.edu/~conitzer/\" rel=\"noopener nofollow\" target=\"_blank\" title=\"(opens in a new window)\"\u003eVincent Conitzer\u003c/a\u003e, a professor of computer science at Carnegie Mellon University and one of the panelists, told me.\u003c/p\u003e\u003ch2\u003eArtificial intelligence has developed rapidly in recent years\u003c/h2\u003e\u003cp\u003eThe report\u0026#39;s goal, AAAI president Francesca Rossi wrote in its introduction, is to support research in artificial intelligence that produces technology that helps people. Issues of trust and reliability are serious, not just in providing accurate information but in avoiding bias and ensuring a future AI doesn\u0026#39;t cause severe unintended consequences. \u0026#34;We all need to work together to advance AI in a responsible way, to make sure that technological progress supports the progress of humanity and is aligned to human values,\u0026#34; she wrote. \u003c/p\u003e\u003cp\u003eThe acceleration of AI, especially since OpenAI launched \u003ca href=\"https://www.cnet.com/tech/services-and-software/chatgpt-4-review-a-smarter-ai-chatbot-but-itll-cost-you/\" target=\"_self\"\u003eChatGPT\u003c/a\u003e in 2022, has been remarkable, Conitzer said. \u0026#34;In some ways that\u0026#39;s been stunning, and many of these techniques work much better than most of us ever thought that they would,\u0026#34; he said.\u003c/p\u003e\u003cp\u003eThere are some areas of AI research where \u0026#34;the hype does have merit,\u0026#34; \u003ca href=\"https://johnthickstun.com/\" rel=\"noopener nofollow\" target=\"_blank\" title=\"(opens in a new window)\"\u003eJohn Thickstun\u003c/a\u003e, assistant professor of computer science at Cornell University, told me. That\u0026#39;s especially true in math or science, where users can check a model\u0026#39;s results. \u003c/p\u003e\u003cp\u003e\u0026#34;This technology is amazing,\u0026#34; Thickstun said. \u0026#34;I\u0026#39;ve been working in this field for over a decade, and it\u0026#39;s shocked me how good it\u0026#39;s become and how fast it\u0026#39;s become good.\u0026#34;\u003c/p\u003e\u003cp\u003eDespite those improvements, there are still significant issues that merit research and consideration, experts said.\u003c/p\u003e\u003ch2\u003eWill chatbots start to get their facts straight?\u003c/h2\u003e\u003cp\u003eDespite some progress in improving the trustworthiness of the information that comes from generative AI models, much more work needs to be done. A recent \u003ca href=\"https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php\" rel=\"noopener nofollow\" target=\"_blank\" title=\"(opens in a new window)\"\u003ereport from Columbia Journalism Review\u003c/a\u003e found chatbots were unlikely to decline to answer questions they couldn\u0026#39;t answer accurately, confident about the wrong information they provided and made up (and provided fabricated links to) sources to back up those wrong assertions. \u003c/p\u003e\u003cp\u003eImproving reliability and accuracy \u0026#34;is arguably the biggest area of AI research today,\u0026#34; the AAAI report said.\u003c/p\u003e\u003cp\u003eResearchers noted three main ways to boost the accuracy of AI systems: fine-tuning, such as reinforcing learning with human feedback; retrieval-augmented generation, in which the system gathers specific documents and pulls its answer from those; and chain-of-thought, where prompts break down the question into smaller steps that the AI model can check for hallucinations.\u003c/p\u003e\u003cp\u003eWill those things make your chatbot responses more accurate soon? Not likely: \u0026#34;Factuality is far from solved,\u0026#34; the report said. About 60% of those surveyed indicated doubts that factuality or trustworthiness concerns would be solved soon. \u003c/p\u003e\u003cp\u003eIn the generative AI industry, there has been optimism that scaling up existing models will make them more accurate and reduce hallucinations. \u003c/p\u003e\u003cp\u003e\u0026#34;I think that hope was always a little bit overly optimistic,\u0026#34; Thickstun said. \u0026#34;Over the last couple of years, I haven\u0026#39;t seen any evidence that really accurate, highly factual language models are around the corner.\u0026#34;\u003c/p\u003e\u003cp\u003eDespite the fallibility of large language models such as \u003ca href=\"https://www.cnet.com/tech/services-and-software/claude-ai-review-the-most-conversational-ai-engine/\" target=\"_self\"\u003eAnthropic\u0026#39;s Claude\u003c/a\u003e or \u003ca href=\"https://www.cnet.com/tech/services-and-software/what-is-meta-ai-everything-you-should-know-about-the-social-network-giants-ai-tools/\" target=\"_self\"\u003eMeta\u0026#39;s Llama\u003c/a\u003e, users can mistakenly assume they\u0026#39;re more accurate because they present answers with confidence, Conitzer said. \u003c/p\u003e\u003cp\u003e\u0026#34;If we see somebody responding confidently or words that sound confident, we take it that the person really knows what they\u0026#39;re talking about,\u0026#34; he said. \u0026#34;An AI system, it might just claim to be very confident about something that\u0026#39;s completely nonsense.\u0026#34;\u003c/p\u003e\u003ch2\u003eLessons for the AI user\u003c/h2\u003e\u003cp\u003eAwareness of generative AI\u0026#39;s limitations is vital to using it properly. Thickstun\u0026#39;s advice for users of models such as ChatGPT and \u003ca href=\"https://www.cnet.com/tech/services-and-software/what-is-gemini-everything-you-should-know-about-googles-ai-tool/\" target=\"_self\"\u003eGoogle\u0026#39;s Gemini\u003c/a\u003e is simple: \u0026#34;You have to check the results.\u0026#34;\u003c/p\u003e\u003cp\u003eGeneral large language models do a poor job of consistently retrieving factual information, he said. If you ask it for something, you should probably follow up by looking up the answer in a search engine (and not relying on the AI summary of the search results). By the time you do that, you might have been better off doing that in the first place.\u003c/p\u003e\u003cp\u003eThickstun said the way he uses AI models most is to automate tasks that he could do anyway and that he can check the accuracy, such as formatting tables of information or writing code. \u0026#34;The broader principle is that I find these models are most useful for automating work that you already know how to do,\u0026#34; he said.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRead more:\u003c/strong\u003e \u003ca href=\"https://www.cnet.com/tech/services-and-software/5-ways-to-stay-smart-when-using-gen-ai-explained-by-computer-science-professors/\" target=\"_self\"\u003e5 Ways to Stay Smart When Using Gen AI, Explained by Computer Science Professors\u003c/a\u003e\u003c/p\u003e\u003ch2\u003eIs artificial general intelligence around the corner?\u003c/h2\u003e\u003cp\u003eOne priority of the AI development industry is an apparent race to create what\u0026#39;s often called artificial general intelligence, or AGI. This is a model that is generally capable of a human level of thought or better. \u003c/p\u003e\u003cp\u003eThe report\u0026#39;s survey found strong opinions on the race for AGI. Notably, more than three-quarters (76%) of respondents said scaling up current AI techniques such as large language models was unlikely to produce AGI. A significant majority of researchers doubt the current march toward AGI will work.\u003c/p\u003e\u003cp\u003eA similarly large majority believe systems capable of artificial general intelligence should be publicly owned if they\u0026#39;re developed by private entities (82%). That aligns with concerns about the ethics and potential downsides of creating a system that can outthink humans. Most researchers (70%) said they oppose stopping AGI research until safety and control systems are developed. \u0026#34;These answers seem to suggest a preference for continued exploration of the topic, within some safeguards,\u0026#34; the report said.\u003c/p\u003e\u003cp\u003eThe conversation around AGI is complicated, Thickstun said. In some sense, we\u0026#39;ve already created systems that have a form of general intelligence. Large language models such as OpenAI\u0026#39;s ChatGPT are capable of doing a variety of human activities, in contrast to older AI models that could only do one thing, such as play chess. The question is whether it can do many things consistently at a human level.\u003c/p\u003e\u003cp\u003e\u0026#34;I think we\u0026#39;re very far away from this,\u0026#34; Thickstun said.\u003c/p\u003e\u003cp\u003eHe said these models lack a built-in concept of truth and the ability to handle truly open-ended creative tasks. \u0026#34;I don\u0026#39;t see the path to making them operate robustly in a human environment using the current technology,\u0026#34; he said. \u0026#34;I think there are many research advances in the way of getting there.\u0026#34;\u003c/p\u003e\u003cp\u003eConitzer said the definition of what exactly constitutes AGI is tricky: Often, people mean something that can do most tasks better than a human but some say it\u0026#39;s just something capable of doing a range of tasks. \u0026#34;A stricter definition is something that would really make us completely redundant,\u0026#34; he said. \u003c/p\u003e\u003cp\u003eWhile researchers are skeptical that \u003ca href=\"https://blog.samaltman.com/three-observations\" rel=\"noopener nofollow\" target=\"_blank\" title=\"(opens in a new window)\"\u003eAGI is around the corner\u003c/a\u003e, Conitzer cautioned that AI researchers didn\u0026#39;t necessarily expect the dramatic technological improvement we\u0026#39;ve all seen in the past few years. \u003c/p\u003e\u003cp\u003e\u0026#34;We did not see coming how quickly things have changed recently,\u0026#34; he said, \u0026#34;and so you might wonder whether we\u0026#39;re going to see it coming if it continues to go faster.\u0026#34;\u003c/p\u003e\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-03-21T22:23:58Z",
  "modifiedTime": null
}
