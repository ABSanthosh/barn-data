{
  "id": "151d49bb-77a1-49da-b32c-1f1b39fe883c",
  "title": "Generative AI Doesn't Have a Coherent Understanding of the World, MIT Researchers Find",
  "link": "https://slashdot.org/story/24/11/10/1911204/generative-ai-doesnt-have-a-coherent-understanding-of-the-world-mit-researchers-find?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "Long-time Slashdot reader Geoffrey.landis writes: Despite its impressive output, a recent study from MIT suggests generative AI doesn't have a coherent understanding of the world. While the best-performing large language models have surprising capabilities that make it seem like the models are implicitly learning some general truths about the world, that isn't necessarily the case. The recent paper showed that Large Language Models and game-playing AI implicitly model the world, but the models are flawed and incomplete. An example study showed that a popular type of generative AI model accurately provided turn-by-turn driving directions in New York City, without having formed an accurate internal map of the city. Though the model can still navigate effectively, when the researchers closed some streets and added detours, its performance plummeted. And when they dug deeper, the researchers found that the New York maps the model implicitly generated had many nonexistent streets curving between the grid and connecting far away intersections. Read more of this story at Slashdot.",
  "author": "EditorDavid",
  "published": "2024-11-10T22:34:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "ai"
  ],
  "byline": "",
  "length": 1056,
  "excerpt": "Long-time Slashdot reader Geoffrey.landis writes: Despite its impressive output, a recent study from MIT suggests generative AI doesn't have a coherent understanding of the world. While the best-performing large language models have surprising capabilities that make it seem like the models are impli...",
  "siteName": "",
  "favicon": "",
  "text": "Long-time Slashdot reader Geoffrey.landis writes: Despite its impressive output, a recent study from MIT suggests generative AI doesn't have a coherent understanding of the world. While the best-performing large language models have surprising capabilities that make it seem like the models are implicitly learning some general truths about the world, that isn't necessarily the case. The recent paper showed that Large Language Models and game-playing AI implicitly model the world, but the models are flawed and incomplete. An example study showed that a popular type of generative AI model accurately provided turn-by-turn driving directions in New York City, without having formed an accurate internal map of the city. Though the model can still navigate effectively, when the researchers closed some streets and added detours, its performance plummeted. And when they dug deeper, the researchers found that the New York maps the model implicitly generated had many nonexistent streets curving between the grid and connecting far away intersections.",
  "image": "https://a.fsdn.com/sd/topics/ai_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-175445003\"\u003e\n\t\n\t\t\n\t\n\n\t\n\t\t\n\t\t\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tLong-time Slashdot reader \u003ca href=\"https://slashdot.org/~Geoffrey.landis\"\u003eGeoffrey.landis\u003c/a\u003e writes: \u003ci\u003eDespite its impressive output, a \u003ca href=\"https://news.mit.edu/2024/generative-ai-lacks-coherent-world-understanding-1105\"\u003erecent study from MIT\u003c/a\u003e suggests generative AI doesn\u0026#39;t have a coherent understanding of the world. While the best-performing large language models have surprising capabilities that make it seem like the models are implicitly learning some general truths about the world, that isn\u0026#39;t necessarily the case. The \u003ca href=\"https://arxiv.org/pdf/2406.03689\"\u003erecent paper\u003c/a\u003e showed that Large Language Models and game-playing AI implicitly model the world, but the models are flawed and incomplete. \u003cp\u003e \n\nAn example study showed that a popular type of generative AI model accurately provided turn-by-turn driving directions in New York City, without having formed an accurate internal map of the city. Though the model can still navigate effectively, when the researchers closed some streets and added detours, its performance plummeted. And when they dug deeper, the researchers found that the New York maps the model implicitly generated had many nonexistent streets curving between the grid and connecting far away intersections.\u003c/p\u003e\u003c/i\u003e\u003cbr/\u003e\n\t\t \t\n\t\t\u003c/p\u003e\n\n\t\t\n\n\t\t\n\n\t\t\n\t\t\t\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
