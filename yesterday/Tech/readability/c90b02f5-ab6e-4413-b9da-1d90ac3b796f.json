{
  "id": "c90b02f5-ab6e-4413-b9da-1d90ac3b796f",
  "title": "Can You Run the Llama 2 LLM on DOS?",
  "link": "https://tech.slashdot.org/story/25/04/21/0026255/can-you-run-the-llama-2-llm-on-dos?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "Slashdot reader yeokm1 is the Singapore-based embedded security researcher whose side projects include installing Linux on a 1993 PC and building a ChatGPT client for MS-DOS. He's now sharing his latest project — installing Llama 2 on DOS: Conventional wisdom states that running LLMs locally will require computers with high performance specifications especially GPUs with lots of VRAM. But is this actually true? Thanks to an open-source llama2.c project [original created by Andrej Karpathy], I ported it to work so vintage machines running DOS can actually inference with Llama 2 LLM models. Of course there are severe limitations but the results will surprise you. \"Everything is open sourced with the executable available here,\" according to the blog post. (They even addressed an early \"gotcha\" with DOS filenames being limited to eight characters.) \"As expected, the more modern the system, the faster the inference speed...\" it adds. \"Still, I'm amazed what can still be accomplished with vintage systems.\" Read more of this story at Slashdot.",
  "author": "EditorDavid",
  "published": "2025-04-21T00:34:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "ai"
  ],
  "byline": "",
  "length": 1027,
  "excerpt": "Slashdot reader yeokm1 is the Singapore-based embedded security researcher whose side projects include installing Linux on a 1993 PC and building a ChatGPT client for MS-DOS. He's now sharing his latest project — installing Llama 2 on DOS: Conventional wisdom states that running LLMs local...",
  "siteName": "",
  "favicon": "",
  "text": "Slashdot reader yeokm1 is the Singapore-based embedded security researcher whose side projects include installing Linux on a 1993 PC and building a ChatGPT client for MS-DOS. He's now sharing his latest project — installing Llama 2 on DOS: Conventional wisdom states that running LLMs locally will require computers with high performance specifications especially GPUs with lots of VRAM. But is this actually true? Thanks to an open-source llama2.c project [original created by Andrej Karpathy], I ported it to work so vintage machines running DOS can actually inference with Llama 2 LLM models. Of course there are severe limitations but the results will surprise you. \"Everything is open sourced with the executable available here,\" according to the blog post. (They even addressed an early \"gotcha\" with DOS filenames being limited to eight characters.) \"As expected, the more modern the system, the faster the inference speed...\" it adds. \"Still, I'm amazed what can still be accomplished with vintage systems.\"",
  "image": "https://a.fsdn.com/sd/topics/ai_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-177073317\"\u003e\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tSlashdot reader \u003ca href=\"https://www.slashdot.org/~yeokm1\"\u003eyeokm1\u003c/a\u003e is the Singapore-based embedded security researcher whose side projects include \u003ca href=\"https://linux.slashdot.org/story/18/01/07/228222/can-you-install-linux-on-a-1993-pc\"\u003einstalling Linux on a 1993 PC\u003c/a\u003e and \u003ca href=\"https://slashdot.org/story/23/03/26/1811249/developer-builds-a-chatgpt-client-for-ms-dos\"\u003ebuilding a ChatGPT client for MS-DOS\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e \n\nHe\u0026#39;s now sharing his latest project — \u003ca href=\"https://yeokhengmeng.com/2025/04/llama2-llm-on-dos/\"\u003einstalling Llama 2 on DOS\u003c/a\u003e:\n\n\u003ci\u003e\nConventional wisdom states that running LLMs locally will require computers with high performance specifications especially GPUs with lots of VRAM. But is this actually true?\u003cp\u003e \nThanks to an open-source llama2.c project [original created by \u003ca href=\"https://news.slashdot.org/story/24/07/16/2039236/former-tesla-openai-exec-andrej-karpathy-founds-ai-native-education-startup\"\u003eAndrej Karpathy\u003c/a\u003e], I ported it to work so vintage machines running DOS can actually inference with Llama 2 LLM models. Of course there are severe limitations but the results will surprise you.\n\u003c/p\u003e\u003c/i\u003e \u003cbr/\u003e\n\n\u0026#34;Everything is open sourced with \u003ca href=\"https://github.com/yeokm1/dosllam2\"\u003ethe executable available here\u003c/a\u003e,\u0026#34; according to the \u003ca href=\"https://yeokhengmeng.com/2025/04/llama2-llm-on-dos/\"\u003eblog post\u003c/a\u003e.  (They even addressed an early \u0026#34;gotcha\u0026#34; with DOS filenames being limited to eight characters.)\u003c/p\u003e\u003cp\u003e \n\n\u0026#34;As expected, the more modern the system, the faster the inference speed...\u0026#34; it adds.  \u0026#34;Still, I\u0026#39;m amazed what can still be accomplished with vintage systems.\u0026#34;\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
