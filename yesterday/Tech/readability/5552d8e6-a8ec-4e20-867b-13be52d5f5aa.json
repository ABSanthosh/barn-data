{
  "id": "5552d8e6-a8ec-4e20-867b-13be52d5f5aa",
  "title": "Deploying Containers on NixOS: A Guide",
  "link": "https://bkiran.com/blog/deploying-containers-nixos",
  "description": "Comments",
  "author": "",
  "published": "Wed, 04 Dec 2024 23:34:39 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "Burak Kiran Brown boy from the block",
  "length": 7011,
  "excerpt": "Let's make managing infrastructure on your own machine less cumbersome. Simplify it with NixOS and containers.",
  "siteName": "Integrand",
  "favicon": "",
  "text": "Managing infrastructure on your own machine can be cumbersome and scary. Much of the rhetoric out there would have you believe that it’s not possible or very dangerous to run and manage your own server. There have been some great advances with tools like containers(Docker and Podman) and NixOS that makes this easier than ever. Why Bother with NixOS? Most of my background is in DevOps and infrastructure. I set out to find the easiest way to manage multiple websites and applications on my own servers. Installing and managing Kubernetes seemed like a nightmare, and deploying with Docker Compose felt neither elegant nor easy enough to justify using it. Then I came across NixOS. I found a way to adapt it to meet my needs for managing different application containers on a single machine—or even across a fleet. NixOS is a Linux distribution that offers a unique approach: immutable and declarative builds. This allows you to define the state of a machine in a single configuration file, which, as an infrastructure professional, is something I really like. This approach fits me because of how I think about software. I love being able to see everything running on a machine in one place, defined declaratively. It enables you to create a configuration for your machine and seamlessly apply it to the host. Containers, Containers I have considerable experience running containers in production environments, usually on Kubernetes. Becuase of this, I prefer to package my software as a container. Many of my workflows are built around the useage of containers. For me, containers are simply a means to get things up and running in production quickly. While I can easily get a Docker image of my software packaged, how can I get it running on NixOS? 1. Setting up Virtualization and Podman There is an option in NixOS called vitualization. This allows for all different types of virtualization but we want to virtualize at the OS level(how Docker and Podman works). So here we’re going to pick one to use and and enable it. I’m using Podman but you can choose Docker if you like. virtualisation = { podman = { enable = true; }; }; 2. Adding Our Container Okay so now that our virtualization is turned on, we want to start a container. We do that by defining a option in virtualisation called oci-containers.containers. For each container we want to run, we create and entry here. There are a few options that I always use: image: Defines the container image we want to run. environment: Define environment variables that you want to be exposed within the container. entrypoint: Define a command to run on container startup(if needed). virtualisation = { podman = { enable = true; }; oci-containers.containers = { my-appication = { image = \"myregistry.com/myApplication:latest\"; entrypoint = \"/root/main\"; environment = { DEV_MODE = \"false\"; }; }; }; }; 3. Private Registry, No Problem Your container may not actually work at the previous step because it’s behind a private registry. It’s good practice to put your containers behind one and if you do, you need a way to authenticate. This is done using the login configuration. virtualisation = { podman = { enable = true; }; oci-containers.containers = { my-appication = { login = { registry = \"https://myregistry.com\"; username = \"myRegistryUsername\"; passwordFile = \"/root/registry-password.txt\"; }; image = \"myregistry.com/myApplication:latest\"; entrypoint = \"/root/main\"; environment = { DEV_MODE = \"false\"; }; }; }; }; 4. Opening it Up to the Outside For things like web servers, we need a way to expose our container to the outside world. This is achieved using ports on both the host and the container. First, we add the ports configuration to our container setup. At this point, our container is accessible to the machine itself. To make it accessible from outside the machine, we specify the following configuration: networking.firewall.interfaces.ens4.allowedTCPPorts. The complete configuration will look like this: networking.firewall.interfaces.ens4.allowedTCPPorts = [ 8090 ]; virtualisation = { podman = { enable = true; }; oci-containers.containers = { my-appication = { login = { registry = \"https://myregistry.com\"; username = \"myRegistryUsername\"; passwordFile = \"/root/registry-password.txt\"; }; image = \"myregistry.com/myApplication:latest\"; ports = [\"8090:8000\"]; entrypoint = \"/root/main\"; environment = { DEV_MODE = \"false\"; }; }; }; }; Interacting With Your Running Container Containers are started as systemd processes. You can use systemd commands interact and debug each running container. Also since our virutaulization is enabled, we can use our Podman and Docker commands. Here are my favorite tools for debugging my running services. Systemd processes are named podmain-{container-name}.service so in our example it would be podman-my-appication.service Starting, Stoping and Statuses To get the current status of the application and last lines of logs we want to use the status command. This is useful for doing a quick check on if anything failed or just getting the last lines of logs. systemctl status {service} Let’s say you want to start and stop a process. We can use the respective start and stop commands. systemctl start {service} systemctl stop {service} The Process Journal systemctl is a useful command but it does not show us all the logs. To be able to view all the logs of a systemd serice, we need to use the journalctl. journalctl -u {service} -b Container Commands To get a list of all the running podman services. Often times I use this command to get the container ID. podman ps We can get more granular and specify the service name to get the ID of the container podman ps -aqf \"name={service}\" Often times, I’ll jump into the contain to run some one off command or dig through internals to find an issue that I could not find on the logs exposed to the systemd service. We’ll do that with the exec command and use a shell that’s avaliable in your container(in this example im using sh). podman exec -it {container-id} /bin/sh What are You Waiting For? NixOS has some great attributes, especially if you’re willing to invest the time to learn and understand its configuration language. It’s the easiest Linux distribution I’ve used that allows me to go from configuration to working container orchestration seamlessly while not loosing sight that we’re running on Linux infrastructure. This also makes continuous deployment much simpler—we’ll explore that in future posts.",
  "image": "https://bkiran.com/static/images/profile/burak.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n        \u003cp\u003eManaging infrastructure on your own machine can be cumbersome and scary. Much of the rhetoric out there would have you believe that it’s not possible or very dangerous to run and manage your own server. There have been some great advances with tools like containers(Docker and Podman) and NixOS that makes this easier than ever.\u003c/p\u003e\n\n\u003ch2 id=\"why-bother-with-nixos\"\u003eWhy Bother with NixOS?\u003c/h2\u003e\n\n\u003cp\u003eMost of my background is in DevOps and infrastructure. I set out to find the easiest way to manage multiple websites and applications on my own servers. Installing and managing Kubernetes seemed like a nightmare, and deploying with Docker Compose felt neither elegant nor easy enough to justify using it.\u003c/p\u003e\n\n\u003cp\u003eThen I came across NixOS. I found a way to adapt it to meet my needs for managing different application containers on a single machine—or even across a fleet. NixOS is a Linux distribution that offers a unique approach: immutable and declarative builds. This allows you to define the state of a machine in a single configuration file, which, as an infrastructure professional, is something I really like.\u003c/p\u003e\n\n\u003cp\u003eThis approach fits me because of how I think about software. I love being able to see everything running on a machine in one place, defined declaratively. It enables you to create a configuration for your machine and seamlessly apply it to the host.\u003c/p\u003e\n\n\u003ch2 id=\"containers-containers\"\u003eContainers, Containers\u003c/h2\u003e\n\n\u003cp\u003eI have considerable experience running containers in production environments, usually on Kubernetes. Becuase of this, I prefer to package my software as a container. Many of my  workflows are built around the useage of containers.\u003c/p\u003e\n\n\u003cp\u003eFor me, containers are simply a means to get things up and running in production quickly. While I can easily get a Docker image of my software packaged, how can I get it running on NixOS?\u003c/p\u003e\n\n\u003ch4 id=\"1-setting-up-virtualization-and-podman\"\u003e1. Setting up Virtualization and Podman\u003c/h4\u003e\n\n\u003cp\u003eThere is an option in NixOS called vitualization. This allows for all different types of virtualization but we want to virtualize at the OS level(how Docker and Podman works). So here we’re going to pick one to use and and enable it. I’m using Podman but you can choose Docker if you like.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e  virtualisation = {\n    podman = {\n      enable = true;\n    };\n  };\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch4 id=\"2-adding-our-container\"\u003e2. Adding Our Container\u003c/h4\u003e\n\n\u003cp\u003eOkay so now that our virtualization is turned on, we want to start a container. We do that by defining a option in \u003ccode\u003evirtualisation\u003c/code\u003e called \u003ccode\u003eoci-containers.containers\u003c/code\u003e. For each container we want to run, we create and entry here. There are a few options that I always use:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eimage\u003c/strong\u003e: Defines the container image we want to run.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eenvironment\u003c/strong\u003e: Define environment variables that you want to be exposed within the container.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eentrypoint\u003c/strong\u003e: Define a command to run on container startup(if needed).\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cpre\u003e\u003ccode\u003e  virtualisation = {\n      podman = {\n        enable = true;\n      };\n      oci-containers.containers = {\n        my-appication = {\n          image = \u0026#34;myregistry.com/myApplication:latest\u0026#34;;\n          entrypoint = \u0026#34;/root/main\u0026#34;;\n          environment = {\n              DEV_MODE = \u0026#34;false\u0026#34;;\n          };\n        };\n      };\n  };\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch4 id=\"3-private-registry-no-problem\"\u003e3. Private Registry, No Problem\u003c/h4\u003e\n\n\u003cp\u003eYour container may not actually work at the previous step because it’s behind a private registry. It’s good practice to put your containers behind one and if you do, you need a way to authenticate. This is done using the \u003ccode\u003elogin\u003c/code\u003e configuration.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e  virtualisation = {\n      podman = {\n        enable = true;\n      };\n      oci-containers.containers = {\n        my-appication = {\n          login = {\n              registry = \u0026#34;https://myregistry.com\u0026#34;;\n              username = \u0026#34;myRegistryUsername\u0026#34;;\n              passwordFile = \u0026#34;/root/registry-password.txt\u0026#34;;\n          };\n          image = \u0026#34;myregistry.com/myApplication:latest\u0026#34;;\n          entrypoint = \u0026#34;/root/main\u0026#34;;\n          environment = {\n              DEV_MODE = \u0026#34;false\u0026#34;;\n          };\n        };\n      };\n  };\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch4 id=\"4-opening-it-up-to-the-outside\"\u003e4. Opening it Up to the Outside\u003c/h4\u003e\n\n\u003cp\u003eFor things like web servers, we need a way to expose our container to the outside world. This is achieved using ports on both the host and the container. First, we add the \u003ccode\u003eports\u003c/code\u003e configuration to our container setup. At this point, our container is accessible to the machine itself. To make it accessible from outside the machine, we specify the following configuration: \u003ccode\u003enetworking.firewall.interfaces.ens4.allowedTCPPorts\u003c/code\u003e. The complete configuration will look like this:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e  networking.firewall.interfaces.ens4.allowedTCPPorts = [\n    8090\n  ];\n\n  virtualisation = {\n      podman = {\n        enable = true;\n      };\n      oci-containers.containers = {\n        my-appication = {\n          login = {\n              registry = \u0026#34;https://myregistry.com\u0026#34;;\n              username = \u0026#34;myRegistryUsername\u0026#34;;\n              passwordFile = \u0026#34;/root/registry-password.txt\u0026#34;;\n          };\n          image = \u0026#34;myregistry.com/myApplication:latest\u0026#34;;\n          ports = [\u0026#34;8090:8000\u0026#34;];\n          entrypoint = \u0026#34;/root/main\u0026#34;;\n          environment = {\n              DEV_MODE = \u0026#34;false\u0026#34;;\n          };\n        };\n      };\n  };\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch2 id=\"interacting-with-your-running-container\"\u003eInteracting With Your Running Container\u003c/h2\u003e\n\n\u003cp\u003eContainers are started as systemd processes. You can use systemd commands interact and debug each running container. Also since our virutaulization is enabled, we can use our Podman and Docker commands.\u003c/p\u003e\n\n\u003cp\u003eHere are my favorite tools for debugging my running services. Systemd processes are named \u003ccode\u003epodmain-{container-name}.service\u003c/code\u003e so in our example it would be \u003ccode\u003epodman-my-appication.service\u003c/code\u003e\u003c/p\u003e\n\n\u003ch3 id=\"starting-stoping-and-statuses\"\u003eStarting, Stoping and Statuses\u003c/h3\u003e\n\n\u003cp\u003eTo get the current status of the application and last lines of logs we want to use the \u003ccode\u003estatus\u003c/code\u003e command. This is useful for doing a quick check on if anything failed or just getting the last lines of logs.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003esystemctl status {service}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eLet’s say you want to start and stop a process. We can use the respective \u003ccode\u003estart\u003c/code\u003e and \u003ccode\u003estop\u003c/code\u003e commands.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003esystemctl start {service}\nsystemctl stop {service}\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"the-process-journal\"\u003eThe Process Journal\u003c/h3\u003e\n\n\u003cp\u003e\u003ccode\u003esystemctl\u003c/code\u003e is a useful command but it does not show us all the logs. To be able to view all the logs of a systemd serice, we need to use the \u003ccode\u003ejournalctl\u003c/code\u003e.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003ejournalctl -u {service} -b\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3 id=\"container-commands\"\u003eContainer Commands\u003c/h3\u003e\n\n\u003cp\u003eTo get a list of all the running podman services. Often times I use this command to get the container ID.\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003epodman ps\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eWe can get more granular and specify the service name to get the ID of the container\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003epodman ps -aqf \u0026#34;name={service}\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eOften times, I’ll jump into the contain to run some one off command or dig through internals to find an issue that I could not find on the logs exposed to the systemd service. We’ll do that with the \u003ccode\u003eexec\u003c/code\u003e command and use a shell that’s avaliable in your container(in this example im using \u003ccode\u003esh\u003c/code\u003e).\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003epodman exec -it {container-id} /bin/sh\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch2 id=\"what-are-you-waiting-for\"\u003eWhat are You Waiting For?\u003c/h2\u003e\n\n\u003cp\u003eNixOS has some great attributes, especially if you’re willing to invest the time to learn and understand its configuration language. It’s the easiest Linux distribution I’ve used that allows me to go from configuration to working container orchestration seamlessly while not loosing sight that we’re running on Linux infrastructure. This also makes continuous deployment much simpler—we’ll explore that in future posts.\u003c/p\u003e\n\n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": null,
  "modifiedTime": null
}
