{
  "id": "646ff48d-9973-41b6-af87-57c868a45b59",
  "title": "Google Beam Hands-On: The Most Lifelike 3D Video Calling That Didn’t Totally Blow Me Away",
  "link": "https://gizmodo.com/google-beam-hands-on-the-most-lifelike-3d-video-calling-that-didnt-totally-blow-me-away-2000605706",
  "description": "Google has made something really impressive, but it's not exactly perfect—yet.",
  "author": "Raymond Wong",
  "published": "Wed, 21 May 2025 23:40:24 +0000",
  "source": "https://gizmodo.com/rss",
  "categories": [
    "Gadgets",
    "Google",
    "Google I/O",
    "video calling"
  ],
  "byline": "Raymond Wong",
  "length": 4075,
  "excerpt": "Google has made something really impressive, but it's not exactly perfect—yet.",
  "siteName": "Gizmodo",
  "favicon": "https://gizmodo.com/apple-touch-icon.png",
  "text": "After Android XR smart glasses, I was most excited to try out Google Beam, a shrunken and commercialized version of Project Starline 3D video calling booth that Google has been plugging away at over the past couple of years. Seemingly everyone who has tried Project Starline has told me how mind-blowing it is to video call with someone inside of what’s essentially a glasses-free 3D TV, and feel like they’re really sitting in front of them. I finally got the opportunity to try the technology at Google I/O 2025—it’s impressive, but it’s far from some perfect replication of the person you’re talking with. Let me just repeat myself so there’s no confusion: that Google can replicate a person from a bunch of 2D videos that are then stitched together into 3D using a custom AI neural network is nothing short of wizardry. The 3D person inside of the screen really feels as if they’re sitting across the table. In my demo, which was actually using the older Project Starline setup and not the more compact one HP is making, a friendly guy named Jerome, who said he was being streamed from Seattle, Wash. to my screen in Mountain View, Calif., reached out to hand me an apple that was in his hand, and I instinctively tried to grab it. A few beats later, when he told me the demo was over, we high-fived—I, again, did it without much thought. All the while, during our 1-2 minute convo, we made eye contact, smiled, and laughed, as if we were together IRL. It was all very… normal. Ridiculously short as my demo was, the limitations of the current version of 3D video calling technology were immediately obvious as soon as I sat down in front of the TV “booth.” When Jerome appeared on the screen, I could see that the 3D render of him was jittering very slightly. The entire time, I could see the slightly horizontal jitters as he moved around. The closest thing I can compare it to is like slightly jittery TV scanlines—but it was something that I noticed right away and became fixated on. Another limitation is the camera tracking and viewing angle—it only really works looking at it dead center. Whenever I shifted my chair to the left or right, Jerome’s picture darkened and became distorted. Even with an 8K resolution, the light field display still looked grainy. I also noticed that if you try to “look around” the other person’s body, there’s nothing there. It’s just… empty particle-like space. That makes sense because Beam/Starline’s cameras are only capturing the front and parts of a person’s sides, not back angles. If you’ve ever seen the back of a person’s portrait mode photo (see below), you’ll know there’s just no captured data back there. This is too cool: iPhone Portrait mode…exploded into depth layers pic.twitter.com/oA8FicilWG — Ray Wong (@raywongy) November 22, 2018 I’m also suspicious as hell about how well Beam works in less-than-optimal lighting. The room I was in had nicely diffused lighting. I suspect that the image quality might be greatly degraded with dimmer lighting. There would probably be some real noticeable image noise. I should also note that my chat with Jerome was actually my second demo. My first demo was with a guy named Ryan. The experience was equally as brief, but Starline crashed and his image froze, and I had to be transferred to Jerome. Prototypes! Sure, Zoom calls can freeze up too, but you know what doesn’t freeze up? Real-life conversations in person. Because these units were Project Starline ones—the cameras and speaker modules were attached to the sides of the screen instead of built into them—there’s no way to know whether Google Beam is a more polished product or not. I really expected to have my mind blown like everyone else, but because it felt so natural, the whole experience didn’t quite make me freak out. And I’m known for freaking out when some new technology seems amazing. Maybe that’s a blessing in disguise—there’s no shock factor (not for me, at least), which means the Beam/Starline technology has done its job (mostly) getting out of the way to allow for genuine communication.",
  "image": "https://gizmodo.com/app/uploads/2025/05/googlebeam.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n              \n              \n              \u003cp\u003eAfter \u003ca href=\"http://Google Beam\"\u003eAndroid XR smart glasses\u003c/a\u003e, I was most excited to try out \u003ca href=\"https://gizmodo.com/googles-freaky-realistic-3d-video-calling-booth-is-finally-a-real-product-but-you-wont-be-able-to-buy-it-2000604521\"\u003eGoogle Beam\u003c/a\u003e, a shrunken and commercialized version of \u003ca href=\"https://gizmodo.com/project-starline-hands-on-3d-hologram-webcam-video-chat-1850429422\"\u003eProject Starline 3D\u003c/a\u003e video calling booth that Google has been plugging away at over the past couple of years. Seemingly everyone who has tried Project Starline has told me how mind-blowing it is to video call with someone inside of what’s essentially a glasses-free 3D TV, and feel like they’re really sitting in front of them. I finally got the opportunity to try the technology at \u003ca href=\"https://gizmodo.com/live-updates-from-google-i-o-2025-%f0%9f%94%b4-2000603531\"\u003eGoogle I/O 2025\u003c/a\u003e—it’s impressive, but it’s far from some perfect replication of the person you’re talking with.\u003c/p\u003e \u003cp\u003eLet me just repeat myself so there’s no confusion: that Google can replicate a person from a bunch of 2D videos that are then stitched together into 3D using a custom AI neural network is nothing short of wizardry. The 3D person inside of the screen really feels as if they’re sitting across the table. In my demo, which was actually using the older Project Starline setup and not the more compact one HP is making, a friendly guy named Jerome, who said he was being streamed from Seattle, Wash. to my screen in Mountain View, Calif., reached out to hand me an apple that was in his hand, and I instinctively tried to grab it. A few beats later, when he told me the demo was over, we high-fived—I, again, did it without much thought. All the while, during our 1-2 minute convo, we made eye contact, smiled, and laughed, as if we were together IRL. It was all very… normal.\u003c/p\u003e \u003cp\u003eRidiculously short as my demo was, the limitations of the current version of 3D video calling technology were immediately obvious as soon as I sat down in front of the TV “booth.” When Jerome appeared on the screen, I could see that the 3D render of him was jittering very slightly. The entire time, I could see the slightly horizontal jitters as he moved around. The closest thing I can compare it to is like slightly jittery TV scanlines—but it was something that I noticed right away and became fixated on.\u003c/p\u003e\n\n \u003cp\u003eAnother limitation is the camera tracking and viewing angle—it only really works looking at it dead center. Whenever I shifted my chair to the left or right, Jerome’s picture darkened and became distorted. Even with an 8K resolution, the light field display still looked grainy. I also noticed that if you try to “look around” the other person’s body, there’s nothing there. It’s just… empty particle-like space. That makes sense because Beam/Starline’s cameras are only capturing the front and parts of a person’s sides, not back angles. If you’ve ever seen the back of a person’s portrait mode photo (see below), you’ll know there’s just no captured data back there.\u003c/p\u003e \u003cblockquote data-width=\"500\" data-dnt=\"true\"\u003e \u003cp lang=\"en\" dir=\"ltr\"\u003eThis is too cool: iPhone Portrait mode…exploded into depth layers \u003ca href=\"https://t.co/oA8FicilWG\"\u003epic.twitter.com/oA8FicilWG\u003c/a\u003e\u003c/p\u003e \u003cp\u003e— Ray Wong (@raywongy) \u003ca href=\"https://twitter.com/raywongy/status/1065595586034970625?ref_src=twsrc%5Etfw\"\u003eNovember 22, 2018\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e  \u003cp\u003eI’m also suspicious as hell about how well Beam works in less-than-optimal lighting. The room I was in had nicely diffused lighting. I suspect that the image quality might be greatly degraded with dimmer lighting. There would probably be some real noticeable image noise.\u003c/p\u003e \u003cp\u003eI should also note that my chat with Jerome was actually my second demo. My first demo was with a guy named Ryan. The experience was equally as brief, but Starline crashed and his image froze, and I had to be transferred to Jerome. Prototypes! Sure, Zoom calls can freeze up too, but you know what doesn’t freeze up? Real-life conversations in person.\u003c/p\u003e\n\n \u003cp\u003eBecause these units were Project Starline ones—the cameras and speaker modules were attached to the sides of the screen instead of built into them—there’s no way to know whether Google Beam is a more polished product or not.\u003c/p\u003e \u003cp\u003eI really expected to have my mind blown like everyone else, but because it felt so natural, the whole experience didn’t quite make me freak out. And I’m known for freaking out when some new technology seems amazing. Maybe that’s a blessing in disguise—there’s no shock factor (not for me, at least), which means the Beam/Starline technology has done its job (mostly) getting out of the way to allow for genuine communication.\u003c/p\u003e\n                          \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-05-21T23:40:24Z",
  "modifiedTime": "2025-05-22T00:54:29Z"
}
