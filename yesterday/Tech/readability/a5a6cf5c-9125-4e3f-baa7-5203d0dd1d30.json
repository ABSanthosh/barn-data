{
  "id": "a5a6cf5c-9125-4e3f-baa7-5203d0dd1d30",
  "title": "How we built Pixel’s Add Me feature for easier group photos",
  "link": "https://blog.google/products/pixel/how-google-built-pixel-add-me/",
  "description": "Learn how Google teams built the Pixel 9 series’ Add Me feature, which uses AI for easier group photos.",
  "author": "Molly McHugh-JohnsonContributorThe Keyword",
  "published": "Mon, 27 Jan 2025 20:40:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Pixel",
    "Google AR \u0026 VR",
    "AI"
  ],
  "byline": "Molly McHugh-Johnson",
  "length": 6666,
  "excerpt": "Learn how Google teams built the Pixel 9 series’ Add Me feature, which uses AI for easier group photos.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20250121-1756",
  "text": "Jan 27, 2025 [[read-time]] min read Say cheese, and Add Me please! General summary The Pixel Add Me feature lets you combine two photos taken in the same scene, so everyone, including the photographer, is in the picture. The feature was inspired by the common problem of photographers being left out of group photos. It uses augmented reality to guide users in aligning the two images, and relies on machine learning models powered by Pixel's TPU for fast processing. Summaries were generated by Google AI. Generative AI is experimental. Bullet points Pixel's Add Me feature lets you combine two photos to include everyone in the shot. The feature was inspired by the struggle of photographers to be in group photos. Add Me uses augmented reality to guide users in aligning photos for a seamless blend. The feature relies on machine learning models powered by Pixel's TPU for fast processing. Add Me has become popular for capturing special moments and creating fun \"twinning\" photos. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! Maayan Rossmann is her family’s de facto photographer, which means she’s missing from a lot of photos. “In Israel, there’s ‘Family Day,’ where kids bring in a family photo at school,” the Pixel camera product manager says. “And it was always hard for me to find one that I was in!”This experience, of course, isn’t specific to parents; there’s always someone who volunteers to take the pic, or dash for the camera timer or contort their arm to get everyone in the shot. But the plight of the parent behind the lens is a big part of what inspired Pixel’s Add Me feature. Launched at Made by Google in August, Add Me allows you to combine two pictures taken during the same session and in the same scene so everyone — including the person who took the original shot — is in the photo. With Add Me, you’ll get a photo with everyone who was there — without having to pack a tripod or ask a stranger for help. Software engineer Adi Zicher had only been on the Creative Camera team for about three weeks in August 2022 before pitching the idea. During a brainstorm session, Adi brought up that someone is always left out of group shots. This resonated with everyone, especially the parents (who, given their day jobs, are often the group photographer).Development was already underway for the Pixel 8 series, so a feature that addressed this problem wouldn’t be ready in time. But Adi could still chip away at it for the future. “I had a year of working on it solo, and popping into hackathons and stuff, trying to get people to work on it with me,” Adi explains. Towards the end of that year, a mockup of the feature was available, which was also around the time Maayan joined the project. “Maayan took care of making this a reality!” Adi says. Maayan and Adi using the Add Me feature. Making Add Me a reality required collaboration between the Pixel Camera, Creative Camera and Google XR teams. (The Google XR team works on Android XR and ARCore, platforms for building augmented and virtual reality experiences.) To blend an image, Add Me uses augmented reality (AR) to show the second photographer an overlay of the first image so they can accurately frame the new photo to match the composition of the first one. Since aligning the two images is crucial to get the best result, the team explored a few methods to get the perfect shot. They eventually realized augmented reality was the most useful way to visually guide the user, so they turned to the Google XR team.“We on the XR team have always wanted to do more and enable helpful features in the Camera app,” says XR software engineer Ryan DuToit. The team saw the vision for Add Me and recognized how useful it would be for personal photography.Still, developing an interface where the AR feature was self-explanatory — so even those unfamiliar with the technology could use it — wasn’t easy, and took ample experimentation. Plus, the XR team had a busy 2024, Ryan explains, pointing to the recent Android XR launch. “Collaborating with another team on another project was challenging — but we did it, and I’m very proud of it,” he says.Add Me was a fairly complicated technical feat: It uses various machine learning models, which are powered by Pixel’s TPU and the Tensor G4 chip to run on device. “If it weren’t for the TPU, I don’t think we would have been able to converge to a reasonable latency,” Adi says. If they’d had to run these ML models on a GPU or CPU, the feature wouldn’t have been able to display the images from the first shot and then later the blended shot quickly enough. Add Me launched with our Pixel 9 phones and quickly became a popular feature, especially during moments when people tend to gather. \"When I look at the photos Googlers share with us, it strikes me how often they use Add Me to capture those special moments with loved ones — family gatherings, vacations, holidays,” Adi says.And then there’s the whole “twinning with yourself” thing. With Add Me, you can have someone take two photos of you to blend together into interesting, Sci-Fi-esque “twinning” photographs. It’s something the team experimented with a lot — but not for the cool effect. Adi twinning, thanks to Add Me. “We’d take photos duplicating ourselves just because that was easy for testing,” Adi says. But the twinning craze took over the Sandbox demo at Made by Google. “It was one of the first things that people tried with it!” she says.So whether you want to get in the next family photo or take one with the person you know best — yourself — Add Me can be the perfect tool.",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/01-27_Pixel9AddMe_SocialShare.width-1300.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n  }\"\u003e\n  \n  \u003cdiv\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eJan 27, 2025\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          Say cheese, and Add Me please!\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n  \n  \u003cdiv data-component=\"uni-ai-generated-summary\" data-analytics-module=\"{\n    \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n    \u0026#34;module_name\u0026#34;: \u0026#34;ai_summary\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;CTA\u0026#34;\n  }\"\u003e\n      \n        \u003cdiv data-summary-id=\"ai_summary_1\"\u003e\n          \u003ch2\u003eGeneral summary\u003c/h2\u003e\n          \u003cp\u003eThe Pixel Add Me feature lets you combine two photos taken in the same scene, so everyone, including the photographer, is in the picture. The feature was inspired by the common problem of photographers being left out of group photos.  It uses augmented reality to guide users in aligning the two images, and relies on machine learning models powered by Pixel\u0026#39;s TPU for fast processing.\u003c/p\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n      \n        \u003cdiv data-summary-id=\"ai_summary_2\"\u003e\n          \u003ch2\u003eBullet points\u003c/h2\u003e\n          \u003cul\u003e\n\u003cli\u003ePixel\u0026#39;s Add Me feature lets you combine two photos to include everyone in the shot.\u003c/li\u003e\n\u003cli\u003eThe feature was inspired by the struggle of photographers to be in group photos.\u003c/li\u003e\n\u003cli\u003eAdd Me uses augmented reality to guide users in aligning photos for a seamless blend.\u003c/li\u003e\n\u003cli\u003eThe feature relies on machine learning models powered by Pixel\u0026#39;s TPU for fast processing.\u003c/li\u003e\n\u003cli\u003eAdd Me has become popular for capturing special moments and creating fun \u0026#34;twinning\u0026#34; photos.\u003c/li\u003e\n\u003c/ul\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n      \n\n      \n      \u003cdiv\u003e\n        \u003ch4\u003e\n          Explore other styles:\n        \u003c/h4\u003e\n        \n      \u003c/div\u003e\n      \n\n      \u003c/div\u003e\n\u003c/div\u003e\n\n    \n\n    \n      \u003cdiv\u003e\n      \u003cp\u003e\n        \u003cvideo autoplay=\"\" muted=\"\" loop=\"\" playsinline=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/01-27_Pixel9AddMe_Hero.mp4\" title=\"Two people sitting on a yellow table and bench. A white vertical line swipes over the photo, and a third person appears\" poster=\"\n            \n              https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/01-27_Pixel9AddMe_Thumbnail.png\n            \"\u003e\n          Sorry, your browser doesn\u0026#39;t support embedded videos, but don\u0026#39;t worry, you can\n            \u003ca href=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/01-27_Pixel9AddMe_Hero.mp4\"\u003edownload it\u003c/a\u003e\n            and watch it with your favorite video player!\n        \u003c/video\u003e\n      \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\n\n\u003cgoogle-read-aloud-player data-analytics-module=\"{\n        \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n        \u0026#34;module_name\u0026#34;: \u0026#34;ai_audio\u0026#34;,\n        \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n    }\" data-call-to-action-text=\"Listen to article\" data-date-modified=\"2025-01-27T21:14:39.774639+00:00\" data-progress-bar-style=\"half-wave\" data-api-key=\"AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac\" data-article-style=\"style9\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-layout-style=\"style1\" data-highlight-mode=\"word-over-paragraph\" data-highlight-text-color=\"#000000\" data-highlight-word-background=\"#8AB4F8\" data-highlight-paragraph-background=\"#D2E3FC\" data-background=\"linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)\" data-foreground-color=\"#202124\" data-font=\"600 16px Google Sans, sans-serif\" data-box-shadow=\"0px 1px 3px 1px rgba(60, 64, 67, 0.15)\"\u003e\n\u003c/google-read-aloud-player\u003e\n\n\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"sdiog\"\u003eMaayan Rossmann is her family’s de facto photographer, which means she’s missing from a lot of photos. “In Israel, there’s ‘Family Day,’ where kids bring in a family photo at school,” the Pixel camera product manager says. “And it was always hard for me to find one that I was in!”\u003c/p\u003e\u003cp data-block-key=\"8hdi8\"\u003eThis experience, of course, isn’t specific to parents; there’s always someone who volunteers to take the pic, or dash for the camera timer or contort their arm to get everyone in the shot. But the plight of the parent behind the lens is a big part of what inspired \u003ca href=\"https://store.google.com/intl/en/ideas/articles/pixel-add-me/\"\u003ePixel’s Add Me feature\u003c/a\u003e. Launched at \u003ca href=\"https://blog.google/products/pixel/google-pixel-9-ai-camera-features/\"\u003eMade by Google in August\u003c/a\u003e, Add Me allows you to combine two pictures taken during the same session and in the same scene so everyone — including the person who took the original shot — is in the photo.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"A GIF that shows how Add Me works. First, you take a photo of the group. Then trade places with someone to take a photo with you in it. AR guides the second photographer to frame the photo to match the composition of the first one. Pixel then merges both images so everyone is in a single photo.\" external-image=\"\" or-mp4-video-title=\"Add Me Keyword asset\" or-mp4-video-url=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Add_Me_Keyword_blog.mp4\" section-header=\"How we built Pixel’s Add Me feature for easier group photos\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n    \u003cdiv slot=\"caption-slot\"\u003e\n      \u003cp data-block-key=\"ifi07\"\u003eWith Add Me, you’ll get a photo with everyone who was there — without having to pack a tripod or ask a stranger for help.\u003c/p\u003e\n    \u003c/div\u003e\n  \n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"sdiog\"\u003eSoftware engineer Adi Zicher had only been on the Creative Camera team for about three weeks in August 2022 before pitching the idea. During a brainstorm session, Adi brought up that someone is always left out of group shots. This resonated with everyone, especially the parents (who, given their day jobs, are often the group photographer).\u003c/p\u003e\u003cp data-block-key=\"6ekl7\"\u003eDevelopment was already underway for the Pixel 8 series, so a feature that addressed this problem wouldn’t be ready in time. But Adi could still chip away at it for the future. “I had a year of working on it solo, and popping into hackathons and stuff, trying to get people to work on it with me,” Adi explains. Towards the end of that year, a mockup of the feature was available, which was also around the time Maayan joined the project. “Maayan took care of making this a reality!” Adi says.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"Animation showing one person sitting on a couch. A vertical white line swipes over the image, and a second person appears.\" external-image=\"\" or-mp4-video-title=\"Add Me Keyword asset\" or-mp4-video-url=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Add_Me_Keyword_inline.mp4\" section-header=\"How we built Pixel’s Add Me feature for easier group photos\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n    \u003cdiv slot=\"caption-slot\"\u003e\n      \u003cp data-block-key=\"ifi07\"\u003eMaayan and Adi using the Add Me feature.\u003c/p\u003e\n    \u003c/div\u003e\n  \n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"sdiog\"\u003eMaking Add Me a reality required collaboration between the Pixel Camera, Creative Camera and Google XR teams. (The Google XR team works on Android XR and ARCore, platforms for building augmented and virtual reality experiences.) To blend an image, Add Me uses augmented reality (AR) to show the second photographer an overlay of the first image so they can accurately frame the new photo to match the composition of the first one. Since aligning the two images is crucial to get the best result, the team explored a few methods to get the perfect shot. They eventually realized augmented reality was the most useful way to visually guide the user, so they turned to the Google XR team.\u003c/p\u003e\u003cp data-block-key=\"ej5e8\"\u003e“We on the XR team have always wanted to do more and enable helpful features in the Camera app,” says XR software engineer Ryan DuToit. The team saw the vision for Add Me and recognized how useful it would be for personal photography.\u003c/p\u003e\u003cp data-block-key=\"2isjp\"\u003eStill, developing an interface where the AR feature was self-explanatory — so even those unfamiliar with the technology could use it — wasn’t easy, and took ample experimentation. Plus, the XR team had a busy 2024, Ryan explains, pointing to the \u003ca href=\"https://blog.google/products/android/android-xr/\"\u003erecent Android XR launch\u003c/a\u003e. “Collaborating with another team on another project was challenging — but we did it, and I’m very proud of it,” he says.\u003c/p\u003e\u003cp data-block-key=\"c6tcs\"\u003eAdd Me was a fairly complicated technical feat: It uses various machine learning models, which are powered by Pixel’s TPU and the Tensor G4 chip to \u003ca href=\"https://blog.google/technology/ai/on-device-processing/\"\u003erun on device\u003c/a\u003e. “If it weren’t for the TPU, I don’t think we would have been able to converge to a reasonable latency,” Adi says. If they’d had to run these ML models on a GPU or CPU, the feature wouldn’t have been able to display the images from the first shot and then later the blended shot quickly enough.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n\u003cuni-related-content-tout title=\"What\u0026#39;s the difference between a CPU, GPU and TPU?\" cta=\"See more\" summary=\"Learn more from a Google expert about CPUs, GPUs and TPUs — and Google latest TPU, Trillium.\" hideimage=\"False\" eyebrow=\"Related Article\" fullurl=\"https://blog.google/technology/ai/difference-cpu-gpu-tpu-trillium/\" pagetype=\"articlepage\" isarticlepage=\"\" data-ga4-related-article=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;article_lead_click\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;Ask a Techspert: What\\u0027s the difference between a CPU, GPU and TPU?\u0026#34;,\n  \u0026#34;link_type\u0026#34;: \u0026#34;internal\u0026#34;,\n  \u0026#34;full_url\u0026#34;: \u0026#34;https://blog.google/technology/ai/difference-cpu-gpu-tpu-trillium/\u0026#34;,\n  \u0026#34;title\u0026#34;: \u0026#34;Ask a Techspert: What\\u0027s the difference between a CPU, GPU and TPU?\u0026#34;,\n  \u0026#34;author\u0026#34; : \u0026#34;Molly McHugh-Johnson\u0026#34;,\n  \u0026#34;slug\u0026#34;: \u0026#34;difference-cpu-gpu-tpu-trillium\u0026#34;,\n  \u0026#34;position\u0026#34;: \u0026#34;1 of 1\u0026#34;,\n  \u0026#34;click_location\u0026#34;: \u0026#34;undefined\u0026#34;,\n  \u0026#34;primary_tag\u0026#34;: \u0026#34;Topics - AI\u0026#34;,\n  \u0026#34;secondary_tags\u0026#34;: \u0026#34;Google Cloud,Ask a Techspert\u0026#34;,\n  \u0026#34;published_date\u0026#34;: \u0026#34;2024-10-30|19:00\u0026#34;,\n  \u0026#34;hero_media_type\u0026#34;: \u0026#34;image\u0026#34;,\n  \u0026#34;days_since_published\u0026#34;: \u0026#34;90\u0026#34;,\n  \u0026#34;content_category\u0026#34;: \u0026#34;Editorial feature\u0026#34;,\n  \u0026#34;word_count\u0026#34;: \u0026#34;888\u0026#34;,\n  \u0026#34;has_audio\u0026#34;: \u0026#34;no\u0026#34;,\n  \u0026#34;has_video\u0026#34;: \u0026#34;no\u0026#34;,\n  \u0026#34;has_image\u0026#34;: \u0026#34;no\u0026#34;,\n  \u0026#34;has_carousel\u0026#34;: \u0026#34;no\u0026#34;\n}\"\u003e\n  \n    \u003cdiv slot=\"rct-image-slot\"\u003e\n      \n    \u003cfigure\u003e\n        \u003cpicture\u003e\n            \n\n\n    \n\n    \n        \u003csource media=\"(max-resolution: 1.5dppx)\" sizes=\"300px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ink_TheDifferenceBetweenCPUGPUTPU.width-300.format-webp.webp 300w\"/\u003e\n    \n        \u003csource media=\"(min-resolution: 1.5dppx)\" sizes=\"600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ink_TheDifferenceBetweenCPUGPUTPU.width-600.format-webp.webp 600w\"/\u003e\n    \n\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ink_TheDifferenceBetweenCPUGPUTPU.width-600.format-webp.webp\" alt=\"Three squares illustrate different computer processors. Blue: a classic CPU with a grid of contact points. Green: a GPU with a simple line symbolizing parallel processing. Yellow: a TPU with intricate circuitry for machine learning.\" sizes=\" 300px,  600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ink_TheDifferenceBetweenCPUGPUTPU.width-300.format-webp.webp 300w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ink_TheDifferenceBetweenCPUGPUTPU.width-600.format-webp.webp 600w\" data-target=\"image\" loading=\"lazy\"/\u003e\n    \n\n\n        \u003c/picture\u003e\n    \u003c/figure\u003e\n\n\n    \u003c/div\u003e\n  \n\u003c/uni-related-content-tout\u003e\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"sdiog\"\u003eAdd Me launched with our Pixel 9 phones and quickly became a popular feature, especially during moments when people tend to gather. \u0026#34;When I look at the photos Googlers share with us, it strikes me how often they use Add Me to capture those special moments with loved ones — family gatherings, vacations, holidays,” Adi says.\u003c/p\u003e\u003cp data-block-key=\"aam5e\"\u003eAnd then there’s the whole “twinning with yourself” thing. With Add Me, you can have someone take two photos of you to blend together into interesting, Sci-Fi-esque “twinning” photographs. It’s something the team experimented with a lot — but not for the cool effect.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\u003cuni-image-full-width alignment=\"full\" alt-text=\"A woman in a black jacket stands on the side of a cliff next to a suspension bridge. Another image of the woman is on the bridge.\" external-image=\"\" or-mp4-video-title=\"\" or-mp4-video-url=\"\" section-header=\"How we built Pixel’s Add Me feature for easier group photos\" custom-class=\"image-full-width--constrained-width uni-component-spacing\"\u003e\n  \n    \u003cdiv slot=\"caption-slot\"\u003e\n      \u003cp data-block-key=\"ifi07\"\u003eAdi twinning, thanks to Add Me.\u003c/p\u003e\n    \u003c/div\u003e\n  \n  \n    \u003cp\u003e\u003cimg alt=\"A woman in a black jacket stands on the side of a cliff next to a suspension bridge. Another image of the woman is on the bridge.\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Twinning.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n            \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Twinning.width-500.format-webp.webp\u0026#34;,\n            \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Twinning.width-1000.format-webp.webp\u0026#34;\n          }\"/\u003e\n    \u003c/p\u003e\n  \n\u003c/uni-image-full-width\u003e\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Pixel’s Add Me feature for easier group photos\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"sdiog\"\u003e“We’d take photos duplicating ourselves just because that was easy for testing,” Adi says. But the twinning craze took over the Sandbox demo at Made by Google. “It was one of the first things that people tried with it!” she says.\u003c/p\u003e\u003cp data-block-key=\"cgk1\"\u003eSo whether you want to get in the next family photo or take one with the person you know best — yourself — Add Me can be the perfect tool.\u003c/p\u003e\u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-01-27T20:40:00Z",
  "modifiedTime": null
}
