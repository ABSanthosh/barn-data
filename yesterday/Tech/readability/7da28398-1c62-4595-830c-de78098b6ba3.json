{
  "id": "7da28398-1c62-4595-830c-de78098b6ba3",
  "title": "Human versus autonomous car race ends before it begins",
  "link": "https://arstechnica.com/cars/2024/12/man-vs-ai-race-scrapped-after-ai-car-crashes-into-wall-on-warm-up-lap/",
  "description": "A2RL admits that this is a hard problem, and that's refreshing.",
  "author": "Roberto Baldwin",
  "published": "Sun, 22 Dec 2024 12:05:50 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "Cars",
    "A2RL",
    "autonomous cars",
    "Racing"
  ],
  "byline": "Ars Contributors",
  "length": 11970,
  "excerpt": "A2RL recently traveled to Japan to pit its AI-driven car against former F1 driver Daniil Kvyat but it didn’t go so great.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "A2RL admits that this is a hard problem, and that's refreshing. A2RL chose the Super Formula chassis to install its autonomous driving tech. Recently, an A2RL car went to Suzuka in Japan to try and race against a human-driven version. Credit: Roberto Baldwin A2RL chose the Super Formula chassis to install its autonomous driving tech. Recently, an A2RL car went to Suzuka in Japan to try and race against a human-driven version. Credit: Roberto Baldwin TOKYO—Racing is hard. It's hard on the teams, it's hard on the owner's bank account, it's hard on the cars, and it's especially hard on the drivers. Driving at the edge for a few hours in a vehicle cockpit that's only slightly wider than your frame can take a toll. The A2RL (Abu Dhabi Autonomous Racing League) removes one of those elements from its vehicles but, in doing so, creates a whole new list of complexities. Say goodbye to the human driver and hello to 95 kilograms of computers and a whole suite of sensors. That setup was poised to be part of a demonstration \"race\" against former F1 driver Daniil Kvyat at Suzuka Circuit in Japan during the Super Formula season finale. But again, racing is hard, and replacing humans doesn't change that. The people who run and participate in A2RL are aware of this, and while many organizations have made it a sport of overselling AI, A2RL is up-front about the limitations of the current state of the technology. One example of the technology's current shortcomings: The vehicles can't swerve back and forth to warm up the tires. The A2RL team and former F1 racer Daniil Kvyat (center) smile for the media at Suzuka. Credit: Roberto Baldwin Giovanni Pau, Team Principal of TII Racing, stated during a press briefing regarding the AI system built for racing, \"We don't have human intuition. So basically, that is one of the main challenges to drive this type of car. It's impossible today to do a correct grip estimation. A thing my friend Daniil (Kvyat) can do in a nanosecond.\" Technology Innovation Institute (TII) develops the hardware and software stack for all the vehicles. Hardware-wise, the eight teams receive the same technology. When it comes to software, the teams need to build out their own system on TII's software stack to get the vehicles to navigate the tracks. Not quite learning but not quite not learning In April, four teams raced on the track in Abu Dhabi. As we've noted before, how the vehicles navigate the tracks and world around them isn't actually AI. It's programmed responses to an environment; these vehicles are not learning on their own. Frankly, most of what is called \"AI\" in the real world is also not AI. Vehicles driven by the systems still need years of research to come close to the effectiveness of a human beyond the wheel. Kvyat has been working with A2RL since the beginning. In that time, the former F1 driver has been helping engineers understand how to bring the vehicle closer to their limit. The speed continues to increase as the development progresses. Initially, the vehicles were three to five minutes slower than Kvyat around a lap; now, they are about eight seconds behind. That's a lifetime in a real human-to-human race, but an impressive amount of development for vehicles with 90 kg of computer hardware crammed into the cockpit of a super formula car. Credit: Roberto Baldwin Currently, the vehicles are capable of recreating 90–95 percent of the speed of a human driver, according to Pau. Those capabilities are reduced when a human driver is also on the track, particularly for safety reasons. When asked by Ars what his biggest concern was being on the track with a vehicle that doesn't have a human behind the wheel, Kvyat said he has to \"try to follow the car first to see what line it chooses and to understand where it is safe to race it. Some places here [at Suzuka] are quite narrow—on the contrary from the Abu Dhabi track—and there are a lot of long corners. So I really need to be alert and give respect and space to the AI car,\" Kvyat said. Kvyat also noted that the AI car is traveling at a more respectable speed, so he really needs to know what's going on. The predictability of a human driver both on a track and in the real world is one of the issues surrounding AI. As we drive, walk, or bike around a city, we rely on eye contact from drivers, and there are certain behavioral expectations. It's the behavioral outliers that cause issues. Examples include things like running a stop sign, weaving into a lane already occupied by another vehicle, or stopping in the middle of the road for no discernible reason. On the track, an autonomous vehicle might choose to deviate from the racing line around a corner because of a signal input that a human driver would ignore or fold into their driving based on their real-world experience. The context of the rest of a lived life is just as important as what's learned on the track. Life and racing are hard and chaotic. The “race” On the Saturday of the race weekend, a demonstration of two A2RL vehicles raced around the circuit. The vehicles were moving quickly down the straight. The corners, though? We were told that they were still a bit tricky for the vehicles to navigate. Down in the pits, the team watched a bank of monitors. Sensor data came in from the vehicles—zeros and ones representing the track translated into a sea of graphs. To help parse the data quickly, the system shows a green flag when everything is going well and red flags when the values are out of whack with what's supposed to happen. In addition to how the vehicle is moving, information about fuel consumption, brake wear, and tire temperature is shared with the team. All of this data lets the team know how hard it is pushing the vehicle. If everything looks good, the team can push the vehicle to go a little quicker, to push a little harder for a better lap time. Humans elsewhere in the pits will soon tell their human drivers the same thing. Push harder, be quicker; the car can handle it. The data coming in predicts what will happen in the next few seconds. Hopefully. The individual teams will try to find the optimal line, just like the human team, but it doesn't always follow what humans have done before on a track. They work to create an optimal line for the autonomous car instead of just copying what humans are doing. This team has been at Suzuka for weeks ahead of this race. The HD map they bought from a third party was off by meters. In that time the team had to remap the track for the vehicles and teach them how to drive on a circuit that's narrower than the track at Abu Dhabi. The car is outfitted with Sony 4K cameras, radars, lidar, high-definition GPS, and other sensors. The electric steering can handle up to five Gs. The hydraulic brakes on each wheel could be triggered individually, but currently, they are not, according to Pau. However, Pau did note that enabling this function would open up new possibilities, especially in cornering. On the grid at Suzuka. Credit: Roberto Baldwin Pau took a moment while walking us around the vehicle to point to the laser that measures the external temperature of the tire. That, along with the ability to track the tire's pressure, are key to ensuring the vehicle stays on the track. The next morning, the main event was gearing up. Man versus machine. A modern-day John Henry tale without the drama of the song about a steel-driving man. We all knew Kvyat would win. A2RL was very up-front that the system is not nearly as quick as a human. At least not yet. But it had decided to bring the race to Japan, a country known to be on the cutting edge of technology. The \"race\" was to be held ahead of the season finale of the Super Formula season. It was cooler that morning than the previous day. The cars were pushed out to the grid. Kvyat was stationed behind the driverless vehicle. The time between leaving the pits and the race starting felt longer than the day before. The tires were cooling off. The A2RL vehicle took off approximately 22 seconds ahead of Kvyat, but the race ended before the practice lap was completed. Cameras missed the event, but the A2RL car lost traction and ended up tail-first into a wall. A rather anti-climatic end to weeks of work by the team. In the pits, people gathered around the monitors trying to determine exactly what went wrong. Khurram Hassan, commercial director of A2RL, told Ars that the cold tires on the cold track caused a loss of traction. A press release sent out later in the day noted that one of the rear tires suddenly lost pressure, causing the vehicle to lose traction and slide into the wall. The cameras missed the spin, but caught the aftermath. Roberto Baldwin Hassan reminded us that the vehicle does not know how to swerve back and forth yet to warm up its tires. But more importantly, he said that the gap between simulation and the real world is very real. \"You could do things on a computer screen, but this is so important. Because you have to be on the track,\" Hassan said. The reality is that reality is chaos and always changing. When a company notes that it's doing millions of miles of simulated testing, it's vital to remember that a computer-generated world does not equal the one we inhabit. Reality and intelligence A2RL doesn't want to replace human-to-human racing. It understands the emotional attachment humans have to watching other humans compete. It also realizes that as these vehicles improve, what the teams learn will not be directly pulled from the track and put on self-driving cars. But by pushing these vehicles to the limit and letting AI determine the best course of action to keep from slamming into a wall or other vehicle, that information could be used in the future as a safety feature in vehicles—a way to keep a collision from happening used in conjunction with other safety features. The day before the human versus AI race, Super Formula had its penultimate race of the season. During that race, two cars left the pits only to have one of their rear wheels come off. Also, another two cars collided with each another. Racing is hard, and accidents happen. For A2RL, failure is always an option. It may break the hearts of everyone in the pits that have prepped for weeks for an event, but it's important to remember that it's a controlled environment. A2RL seems to understand and talks about the complications of aiming for an AI-powered vehicle. It would be nice if those companies testing on our streets did the same. 102 Comments",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1152x648-1734453248.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n            \u003carticle data-id=\"2067206\"\u003e\n  \n  \u003cheader\u003e\n  \u003cdiv\u003e\n    \n\n    \n\n    \u003cp\u003e\n      A2RL admits that this is a hard problem, and that\u0026#39;s refreshing.\n    \u003c/p\u003e\n\n    \n\n    \u003cdiv\u003e\n            \u003cp\u003e\u003ca data-pswp-width=\"2500\" data-pswp-height=\"1667\" data-pswp-srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12.jpg 2500w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-640x427.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1024x683.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-768x512.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1536x1024.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-2048x1366.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-980x653.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1440x960.jpg 1440w\" data-cropped=\"false\" href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12.jpg\" target=\"_blank\"\u003e\n              \u003cimg width=\"2500\" height=\"1667\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12.jpg\" alt=\"A pair of open-wheel race cars parked on the main straight at Suzuka in Japan\" loading=\"eager\" decoding=\"async\" fetchpriority=\"high\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12.jpg 2500w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-640x427.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1024x683.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-768x512.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1536x1024.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-2048x1366.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-980x653.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-1440x960.jpg 1440w\" sizes=\"(max-width: 2500px) 100vw, 2500px\"/\u003e\n            \u003c/a\u003e\u003c/p\u003e\u003cdiv id=\"caption-2067209\"\u003e\n    \n    \u003cp\u003e\n      A2RL chose the Super Formula chassis to install its autonomous driving tech. Recently, an A2RL car went to Suzuka in Japan to try and race against a human-driven version.\n\n              \u003cspan\u003e\n          Credit:\n\n          \n          Roberto Baldwin\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n          \u003c/div\u003e\n\n    \u003cdiv\u003e\n    \n    \u003cp\u003e\n      A2RL chose the Super Formula chassis to install its autonomous driving tech. Recently, an A2RL car went to Suzuka in Japan to try and race against a human-driven version.\n\n              \u003cspan\u003e\n          Credit:\n\n          \n          Roberto Baldwin\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/header\u003e\n\n\n  \n\n  \n      \n    \n    \u003cdiv\u003e\n                      \n                      \n          \n\n\u003cp\u003eTOKYO—Racing is hard. It\u0026#39;s hard on the teams, it\u0026#39;s hard on the owner\u0026#39;s bank account, it\u0026#39;s hard on the cars, and it\u0026#39;s especially hard on the drivers. Driving at the edge for a few hours in a vehicle cockpit that\u0026#39;s only slightly wider than your frame can take a toll.\u003c/p\u003e\n\u003cp\u003eThe A2RL (Abu Dhabi Autonomous Racing League) removes one of those elements from its vehicles but, in doing so, creates a whole new list of complexities. Say goodbye to the human driver and hello to 95 kilograms of computers and a whole suite of sensors. That setup was poised to be part of a demonstration \u0026#34;race\u0026#34; against former F1 driver Daniil Kvyat at Suzuka Circuit in Japan during the Super Formula season finale.\u003c/p\u003e\n\u003cp\u003eBut again, racing is hard, and replacing humans doesn\u0026#39;t change that. The people who run and participate in A2RL are aware of this, and while many organizations have made it a sport of overselling AI, A2RL is up-front about the limitations of the current state of the technology. One example of the technology\u0026#39;s current shortcomings: The vehicles can\u0026#39;t swerve back and forth to warm up the tires.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"2500\" height=\"1667\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15.jpg\" alt=\"A team of people stand in front of a racing car and pose for a photograph\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15.jpg 2500w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-640x427.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-1024x683.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-768x512.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-1536x1024.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-2048x1366.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-980x653.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-15-1440x960.jpg 1440w\" sizes=\"auto, (max-width: 2500px) 100vw, 2500px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      The A2RL team and former F1 racer Daniil Kvyat (center) smile for the media at Suzuka.\n\n              \u003cspan\u003e\n          Credit:\n\n          \n          Roberto Baldwin\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eGiovanni Pau, Team Principal of TII Racing, stated during a press briefing regarding the AI system built for racing, \u0026#34;We don\u0026#39;t have human intuition. So basically, that is one of the main challenges to drive this type of car. It\u0026#39;s impossible today to do a correct grip estimation. A thing my friend Daniil (Kvyat) can do in a nanosecond.\u0026#34;\u003c/p\u003e\n\u003cp\u003eTechnology Innovation Institute (TII) develops the hardware and software stack for all the vehicles. Hardware-wise, the eight teams receive the same technology. When it comes to software, the teams need to build out their own system on TII\u0026#39;s software stack to get the vehicles to navigate the tracks.\u003c/p\u003e\n\u003ch2\u003eNot quite learning but not quite not learning\u003c/h2\u003e\n\u003cp\u003eIn April, four teams raced on the track in Abu Dhabi. \u003ca href=\"https://arstechnica.com/cars/2024/05/driverless-racing-is-real-terrible-and-strangely-exciting/\"\u003eAs we\u0026#39;ve noted before\u003c/a\u003e, how the vehicles navigate the tracks and world around them isn\u0026#39;t actually AI. It\u0026#39;s programmed responses to an environment; these vehicles are not learning on their own. Frankly, most of what is called \u0026#34;AI\u0026#34; in the real world is also not AI.\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eVehicles driven by the systems still need years of research to come close to the effectiveness of a human beyond the wheel. Kvyat has been working with A2RL since the beginning. In that time, the former F1 driver has been helping engineers understand how to bring the vehicle closer to their limit.\u003c/p\u003e\n\u003cp\u003eThe speed continues to increase as the development progresses. Initially, the vehicles were three to five minutes slower than Kvyat around a lap; now, they are about eight seconds behind. That\u0026#39;s a lifetime in a real human-to-human race, but an impressive amount of development for vehicles with 90 kg of computer hardware crammed into the cockpit of a super formula car.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"2500\" height=\"1667\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3.jpg\" alt=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3.jpg 2500w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-640x427.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-1024x683.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-768x512.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-1536x1024.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-2048x1366.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-980x653.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-3-1440x960.jpg 1440w\" sizes=\"auto, (max-width: 2500px) 100vw, 2500px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\u003cspan\u003e\n          Credit:\n\n          \n          Roberto Baldwin\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eCurrently, the vehicles are capable of recreating 90–95 percent of the speed of a human driver, according to Pau. Those capabilities are reduced when a human driver is also on the track, particularly for safety reasons. When asked by Ars what his biggest concern was being on the track with a vehicle that doesn\u0026#39;t have a human behind the wheel, Kvyat said he has to \u0026#34;try to follow the car first to see what line it chooses and to understand where it is safe to race it. Some places here [at Suzuka] are quite narrow—on the contrary from the Abu Dhabi track—and there are a lot of long corners. So I really need to be alert and give respect and space to the AI car,\u0026#34; Kvyat said.\u003c/p\u003e\n\u003cp\u003eKvyat also noted that the AI car is traveling at a more respectable speed, so he really needs to know what\u0026#39;s going on.\u003c/p\u003e\n\u003cp\u003eThe predictability of a human driver both on a track and in the real world is one of the issues surrounding AI. As we drive, walk, or bike around a city, we rely on eye contact from drivers, and there are certain behavioral expectations. It\u0026#39;s the behavioral outliers that cause issues. Examples include things like running a stop sign, weaving into a lane already occupied by another vehicle, or stopping in the middle of the road for no discernible reason. On the track, an autonomous vehicle might choose to deviate from the racing line around a corner because of a signal input that a human driver would ignore or fold into their driving based on their real-world experience. The context of the rest of a lived life is just as important as what\u0026#39;s learned on the track. Life and racing are hard and chaotic.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\n\u003ch2\u003eThe “race”\u003c/h2\u003e\n\u003cp\u003eOn the Saturday of the race weekend, a demonstration of two A2RL vehicles raced around the circuit. The vehicles were moving quickly down the straight. The corners, though? We were told that they were still a bit tricky for the vehicles to navigate.\u003c/p\u003e\n\u003cp\u003eDown in the pits, the team watched a bank of monitors. Sensor data came in from the vehicles—zeros and ones representing the track translated into a sea of graphs. To help parse the data quickly, the system shows a green flag when everything is going well and red flags when the values are out of whack with what\u0026#39;s supposed to happen. In addition to how the vehicle is moving, information about fuel consumption, brake wear, and tire temperature is shared with the team.\u003c/p\u003e\n\n\n\u003cp\u003eAll of this data lets the team know how hard it is pushing the vehicle. If everything looks good, the team can push the vehicle to go a little quicker, to push a little harder for a better lap time. Humans elsewhere in the pits will soon tell their human drivers the same thing. Push harder, be quicker; the car can handle it. The data coming in predicts what will happen in the next few seconds.\u003c/p\u003e\n\u003cp\u003eHopefully.\u003c/p\u003e\n\u003cp\u003eThe individual teams will try to find the optimal line, just like the human team, but it doesn\u0026#39;t always follow what humans have done before on a track. They work to create an optimal line for the autonomous car instead of just copying what humans are doing.\u003c/p\u003e\n\u003cp\u003eThis team has been at Suzuka for weeks ahead of this race. The HD map they bought from a third party was off by meters. In that time the team had to remap the track for the vehicles and teach them how to drive on a circuit that\u0026#39;s narrower than the track at Abu Dhabi.\u003c/p\u003e\n\u003cp\u003eThe car is outfitted with Sony 4K cameras, radars, lidar, high-definition GPS, and other sensors. The electric steering can handle up to five Gs. The hydraulic brakes on each wheel could be triggered individually, but currently, they are not, according to Pau. However, Pau did note that enabling this function would open up new possibilities, especially in cornering.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"2500\" height=\"1667\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4.jpg\" alt=\"A pair of racing cars on the grid at Suzuka before the start of a race. Photographers and engineers are fussing over the car\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4.jpg 2500w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-640x427.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-1024x683.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-768x512.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-1536x1024.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-2048x1366.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-980x653.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-4-1440x960.jpg 1440w\" sizes=\"auto, (max-width: 2500px) 100vw, 2500px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      On the grid at Suzuka.\n\n              \u003cspan\u003e\n          Credit:\n\n          \n          Roberto Baldwin\n\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003ePau took a moment while walking us around the vehicle to point to the laser that measures the external temperature of the tire. That, along with the ability to track the tire\u0026#39;s pressure, are key to ensuring the vehicle stays on the track.\u003c/p\u003e\n\u003cp\u003eThe next morning, the main event was gearing up. Man versus machine. A modern-day John Henry tale without the drama of the song about a steel-driving man. We all knew Kvyat would win. A2RL was very up-front that the system is not nearly as quick as a human. At least not yet. But it had decided to bring the race to Japan, a country known to be on the cutting edge of technology. The \u0026#34;race\u0026#34; was to be held ahead of the season finale of the Super Formula season.\u003c/p\u003e\n\u003cp\u003eIt was cooler that morning than the previous day. The cars were pushed out to the grid. Kvyat was stationed behind the driverless vehicle. The time between leaving the pits and the race starting felt longer than the day before. The tires were cooling off.\u003c/p\u003e\n\u003cp\u003eThe A2RL vehicle took off approximately 22 seconds ahead of Kvyat, but the race ended before the practice lap was completed. Cameras missed the event, but the A2RL car lost traction and ended up tail-first into a wall. A rather anti-climatic end to weeks of work by the team. In the pits, people gathered around the monitors trying to determine exactly what went wrong.\u003c/p\u003e\n\u003cp\u003eKhurram Hassan, commercial director of A2RL, told Ars that the cold tires on the cold track caused a loss of traction. A press release sent out later in the day noted that one of the rear tires suddenly lost pressure, causing the vehicle to lose traction and slide into the wall.\u003c/p\u003e\n\u003cdiv\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 40\"\u003e\u003cdefs\u003e\u003cclipPath id=\"arrow-blocks-right_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v40H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#arrow-blocks-right_svg__a)\"\u003e\u003cpath d=\"M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\n\n    \u003cp\u003e\u003cspan\u003eThe cameras missed the spin, but caught the aftermath.\u003c/span\u003e\n                    \u003cspan\u003e\n                      Roberto Baldwin\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n\n\u003cp\u003eHassan reminded us that the vehicle does not know how to swerve back and forth yet to warm up its tires. But more importantly, he said that the gap between simulation and the real world is very real. \u0026#34;You could do things on a computer screen, but this is so important. Because you have to be on the track,\u0026#34; Hassan said.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n\n        \n        \u003cdiv\u003e\n          \n          \n\u003cp\u003eThe reality is that reality is chaos and always changing. When a company notes that it\u0026#39;s doing millions of miles of simulated testing, it\u0026#39;s vital to remember that a computer-generated world does not equal the one we inhabit.\u003c/p\u003e\n\u003ch2\u003eReality and intelligence\u003c/h2\u003e\n\u003cp\u003eA2RL doesn\u0026#39;t want to replace human-to-human racing. It understands the emotional attachment humans have to watching other humans compete. It also realizes that as these vehicles improve, what the teams learn will not be directly pulled from the track and put on self-driving cars. But by pushing these vehicles to the limit and letting AI determine the best course of action to keep from slamming into a wall or other vehicle, that information could be used in the future as a safety feature in vehicles—a way to keep a collision from happening used in conjunction with other safety features.\u003c/p\u003e\n\u003cp\u003eThe day before the human versus AI race, Super Formula had its penultimate race of the season. During that race, two cars left the pits only to have one of their rear wheels come off. Also, another two cars collided with each another. Racing is hard, and accidents happen.\u003c/p\u003e\n\u003cp\u003eFor A2RL, failure is always an option. It may break the hearts of everyone in the pits that have prepped for weeks for an event, but it\u0026#39;s important to remember that it\u0026#39;s a controlled environment. A2RL seems to understand and talks about the complications of aiming for an AI-powered vehicle. It would be nice if those companies testing on our streets did the same.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\n\n                  \n          \n\n\n\n\n\n\n\n\n  \u003cp\u003e\n    \u003ca href=\"https://arstechnica.com/cars/2024/12/man-vs-ai-race-scrapped-after-ai-car-crashes-into-wall-on-warm-up-lap/#comments\" title=\"102 comments\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 80 80\"\u003e\u003cdefs\u003e\u003cclipPath id=\"bubble-zero_svg__a\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"bubble-zero_svg__b\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#bubble-zero_svg__a)\"\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#bubble-zero_svg__b)\"\u003e\u003cpath d=\"M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40\"\u003e\u003c/path\u003e\u003cpath d=\"M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n    102 Comments\n  \u003c/a\u003e\n      \u003c/p\u003e\n              \u003c/div\u003e\n  \u003c/article\u003e\n\n\n  \n\n\n  \n\n\n  \u003cdiv\u003e\n    \u003cheader\u003e\n      \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 26\"\u003e\u003cdefs\u003e\u003cclipPath id=\"most-read_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"most-read_svg__b\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#most-read_svg__a)\"\u003e\u003cg fill=\"none\" clip-path=\"url(#most-read_svg__b)\"\u003e\u003cpath fill=\"currentColor\" d=\"M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1\"\u003e\u003c/path\u003e\u003cpath fill=\"#ff4e00\" d=\"M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n      \n    \u003c/header\u003e\n    \u003col\u003e\n              \u003cli\u003e\n                      \u003ca href=\"https://arstechnica.com/cars/2024/12/man-vs-ai-race-scrapped-after-ai-car-crashes-into-wall-on-warm-up-lap/\"\u003e\n              \u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-768x432-1734453248.jpg\" alt=\"Listing image for first story in Most Read: Human versus autonomous car race ends before it begins\" decoding=\"async\" loading=\"lazy\"/\u003e\n            \u003c/a\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                  \u003c/ol\u003e\n\u003c/div\u003e\n\n\n  \n\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2024-12-22T12:05:50Z",
  "modifiedTime": "2024-12-22T12:16:31Z"
}
