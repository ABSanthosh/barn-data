{
  "id": "af66c250-1789-4a29-b97c-eada03dbe234",
  "title": "LIMO: Less Is More for Reasoning",
  "link": "https://arxiv.org/abs/2502.03387",
  "description": "Comments",
  "author": "",
  "published": "Sun, 09 Feb 2025 16:33:28 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "[Submitted on 5 Feb 2025]",
  "length": 2023,
  "excerpt": "We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (\u003e100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models' 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as \"cognitive templates\" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at https://github.com/GAIR-NLP/LIMO.",
  "siteName": "arXiv.org",
  "favicon": "https://arxiv.org/static/browse/0.3.4/images/icons/apple-touch-icon.png",
  "text": "View PDF HTML (experimental) Abstract:We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (\u003e100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models' 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as \"cognitive templates\" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at this https URL. Submission history From: Zhen Huang [view email] [v1] Wed, 5 Feb 2025 17:23:45 UTC (8,774 KB)",
  "image": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"content-inner\"\u003e\n    \n    \n                \n    \u003cp\u003e\u003ca href=\"https://arxiv.org/pdf/2502.03387\"\u003eView PDF\u003c/a\u003e\n    \u003ca href=\"https://arxiv.org/html/2502.03387v1\"\u003eHTML (experimental)\u003c/a\u003e\u003c/p\u003e\u003cblockquote\u003e\n            \u003cspan\u003eAbstract:\u003c/span\u003eWe present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (\u0026gt;100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models\u0026#39; 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model\u0026#39;s encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as \u0026#34;cognitive templates\u0026#34; that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at \u003ca href=\"https://github.com/GAIR-NLP/LIMO\" rel=\"external noopener nofollow\"\u003ethis https URL\u003c/a\u003e.\n    \u003c/blockquote\u003e\n\n    \n    \n  \u003c/div\u003e\u003cdiv\u003e\n      \u003ch2\u003eSubmission history\u003c/h2\u003e\u003cp\u003e From: Zhen Huang [\u003ca href=\"https://arxiv.org/show-email/43e4049b/2502.03387\" rel=\"nofollow\"\u003eview email\u003c/a\u003e]      \u003cbr/\u003e    \u003cstrong\u003e[v1]\u003c/strong\u003e\n        Wed, 5 Feb 2025 17:23:45 UTC (8,774 KB)\u003cbr/\u003e\n\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
