{
  "id": "ede6ad26-e66b-4b52-909a-2b25a704d8dd",
  "title": "Google’s legislative proposal for keeping kids safe online",
  "link": "https://blog.google/outreach-initiatives/public-policy/google-legislative-proposal-for-keeping-kids-safe-online/",
  "description": "Legislation would share kids' information without parental consent or rules on how it's used; we have a better way to keep kids safe.",
  "author": "Kareem GhanemDirectorPublic Policy",
  "published": "Wed, 12 Mar 2025 19:00:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Public Policy",
    "Families",
    "Safety \u0026 Security",
    "Google Play"
  ],
  "byline": "Kareem Ghanem",
  "length": 5153,
  "excerpt": "Legislation would share kids' information without parental consent or rules on how it's used; we have a better way to keep kids safe.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20250306-1741",
  "text": "Mar 12, 2025 [[read-time]] min read Legislation pushed by Meta would share kids' information with millions of developers without parental consent or rules on how it's used; we have a better way. Everyone wants to protect kids and teens online, and make sure they engage with age-appropriate content, but how it’s done matters. There are a variety of fast-moving legislative proposals being pushed by Meta and other companies in an effort to offload their own responsibilities to keep kids safe to app stores. These proposals introduce new risks to the privacy of minors, without actually addressing the harms that are inspiring lawmakers to act. Google is proposing a more comprehensive legislative framework that shares responsibility between app stores and developers, and protects children’s privacy and the decision rights of parents.Where current legislative proposals fall shortOne example of concerning legislation is Utah’s App Store Accountability Act. The bill requires app stores to share if a user is a kid or teenager with all app developers (effectively millions of individual companies) without parental consent or rules on how the information is used. That raises real privacy and safety risks, like the potential for bad actors to sell the data or use it for other nefarious purposes.This level of data sharing isn’t necessary — a weather app doesn’t need to know if a user is a kid. By contrast, a social media app does need to make significant decisions about age-appropriate content and features. As written, however, the bill helps social media companies avoid that responsibility despite the fact that apps are just one of many ways that kids can access these platforms. And by requiring app stores to obtain parental consent for every single app download, it dictates how parents supervise their kids and potentially cuts teens off from digital services like educational or navigation apps.A legislative framework that better protects kidsBy contrast, we are focused on solutions that require appropriate user consent and minimize data exposure. Our legislative framework, which we’ll share with lawmakers as we continue to engage on this issue, has app stores securely provide industry standard age assurances only to developers who actually need them — and ensures that information is used responsibly. Here are more details:Privacy-preserving age signal shared only with consent: Some legislation, including the Utah bill, require app stores to send age information to all developers without permission from the user or their parents. In our proposal, only developers who create apps that may be risky for minors would request industry standard age signals from app stores, and the information is only shared with permission from a user (or their parent). By just sharing with developers who need the information to deliver age-appropriate experiences, and only sharing the minimum amount of data needed to provide an age signal, it reduces the risk of sensitive information being shared broadly.Appropriate safety measures within apps: Under our proposal, an age signal helps a developer understand whether a user is an adult or a minor — the developer is then responsible for applying the appropriate safety and privacy protections. For example, an app developer might filter out certain types of content, introduce take a break reminders, or offer different privacy settings when they know a user might be a minor. Because developers know their apps best, they are best positioned to determine when and where an age-gate might be beneficial to their users, and that may evolve over time, which is another reason why a one-size-fits-all approach won’t adequately protect kids.Responsible use of age signals: Some legislative proposals create new child safety risks because they establish no guardrails against developers misusing an age signal. Our proposal helps to ensure that any age signals are used responsibly, with clear consequences for developers who violate users’ trust. For example, it protects against a developer improperly accessing or sharing the age signal.No ads personalization to minors: Alongside any age assurance proposal, we support banning personalized advertisements targeting users under 18 as an industry standard. At Google, this is a practice we’ve long disallowed. It’s time for other companies to follow suit.Centralized parental controls: Recognizing that parents sometimes feel overwhelmed by parental controls across different apps, our proposal would provide for a centralized dashboard for parents to manage their children’s online activities across different apps in one place and for developers to easily integrate with.Google has demonstrated our commitment to doing our part to keep kids safe online. We’re ready to build on this work and will continue engaging with lawmakers and developers on how to move this legislative framework for age assurance forward.",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SocialShare_6_1.width-1300.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"jump-content\" tabindex=\"-1\"\u003e\n            \n\n    \n    \n\n    \u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;Google’s legislative proposal for keeping kids safe online\u0026#34;\n  }\"\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eMar 12, 2025\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          Legislation pushed by Meta would share kids\u0026#39; information with millions of developers without parental consent or rules on how it\u0026#39;s used; we have a better way.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n      \n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\n\n\u003cgoogle-read-aloud-player data-analytics-module=\"{\n        \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n        \u0026#34;module_name\u0026#34;: \u0026#34;ai_audio\u0026#34;,\n        \u0026#34;section_header\u0026#34;: \u0026#34;Google’s legislative proposal for keeping kids safe online\u0026#34;\n    }\" data-call-to-action-text=\"Listen to article\" data-date-modified=\"2025-03-12T19:01:08.006305+00:00\" data-progress-bar-style=\"half-wave\" data-api-key=\"AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac\" data-article-style=\"style9\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-layout-style=\"style1\" data-highlight-mode=\"word-over-paragraph\" data-highlight-text-color=\"#000000\" data-highlight-word-background=\"#8AB4F8\" data-highlight-paragraph-background=\"#D2E3FC\" data-background=\"linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)\" data-foreground-color=\"#202124\" data-font=\"600 16px Google Sans, sans-serif\" data-box-shadow=\"0px 1px 3px 1px rgba(60, 64, 67, 0.15)\"\u003e\n\u003c/google-read-aloud-player\u003e\n\n\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;Google’s legislative proposal for keeping kids safe online\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"ra3zb\"\u003eEveryone wants to protect kids and teens online, and make sure they engage with age-appropriate content, but how it’s done matters. There are a variety of fast-moving legislative proposals being pushed by Meta and other companies in an effort to offload their own responsibilities to keep kids safe to app stores. These proposals introduce new risks to the privacy of minors, without actually addressing the harms that are inspiring lawmakers to act. Google is proposing a more comprehensive legislative framework that shares responsibility between app stores and developers, and protects children’s privacy and the decision rights of parents.\u003c/p\u003e\u003ch3 data-block-key=\"151l2\"\u003eWhere current legislative proposals fall short\u003c/h3\u003e\u003cp data-block-key=\"77gmu\"\u003eOne example of concerning legislation is Utah’s App Store Accountability Act. The bill requires app stores to share if a user is a kid or teenager with all app developers (effectively millions of individual companies) without parental consent or rules on how the information is used. That raises real privacy and safety risks, like the potential for bad actors to sell the data or use it for other nefarious purposes.\u003c/p\u003e\u003cp data-block-key=\"bklqh\"\u003eThis level of data sharing isn’t necessary — a weather app doesn’t need to know if a user is a kid. By contrast, a social media app does need to make significant decisions about age-appropriate content and features. As written, however, the bill helps social media companies avoid that responsibility despite the fact that apps are just one of many ways that kids can access these platforms. And by requiring app stores to obtain parental consent for every single app download, it dictates how parents supervise their kids and potentially cuts teens off from digital services like educational or navigation apps.\u003c/p\u003e\u003ch3 data-block-key=\"ff53k\"\u003eA legislative framework that better protects kids\u003c/h3\u003e\u003cp data-block-key=\"kuca\"\u003eBy contrast, we are focused on solutions that require appropriate user consent and minimize data exposure. Our legislative framework, which we’ll share with lawmakers as we continue to engage on this issue, has app stores securely provide industry standard age assurances only to developers who actually need them — and ensures that information is used responsibly. Here are more details:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"95f56\"\u003e\u003cb\u003ePrivacy-preserving age signal shared\u003c/b\u003e \u003cb\u003e\u003ci\u003eonly\u003c/i\u003e\u003c/b\u003e\u003cb\u003e with consent:\u003c/b\u003e Some legislation, including the Utah bill, require app stores to send age information to all developers without permission from the user or their parents. In our proposal, only developers who create apps that may be risky for minors would request industry standard age signals from app stores, and the information is only shared with permission from a user (or their parent). By just sharing with developers who need the information to deliver age-appropriate experiences, and only sharing the minimum amount of data needed to provide an age signal, it reduces the risk of sensitive information being shared broadly.\u003c/li\u003e\u003cli data-block-key=\"af6su\"\u003e\u003cb\u003eAppropriate safety measures within apps:\u003c/b\u003e Under our proposal, an age signal helps a developer understand whether a user is an adult or a minor — the developer is then responsible for applying the appropriate safety and privacy protections. For example, an app developer might filter out certain types of content, introduce take a break reminders, or offer different privacy settings when they know a user might be a minor. Because developers know their apps best, they are best positioned to determine when and where an age-gate might be beneficial to their users, and that may evolve over time, which is another reason why a one-size-fits-all approach won’t adequately protect kids.\u003c/li\u003e\u003cli data-block-key=\"9f2vr\"\u003e\u003cb\u003eResponsible use of age signals:\u003c/b\u003e Some legislative proposals create new child safety risks because they establish no guardrails against developers misusing an age signal. Our proposal helps to ensure that any age signals are used responsibly, with clear consequences for developers who violate users’ trust. For example, it protects against a developer improperly accessing or sharing the age signal.\u003c/li\u003e\u003cli data-block-key=\"7reo8\"\u003e\u003cb\u003eNo ads personalization to minors:\u003c/b\u003e Alongside any age assurance proposal, we support banning personalized advertisements targeting users under 18 as an industry standard. At Google, this is a practice we’ve long disallowed. It’s time for other companies to follow suit.\u003c/li\u003e\u003cli data-block-key=\"46rs9\"\u003e\u003cb\u003eCentralized parental controls:\u003c/b\u003e Recognizing that parents sometimes feel overwhelmed by parental controls across different apps, our proposal would provide for a centralized dashboard for parents to manage their children’s online activities across different apps in one place and for developers to easily integrate with.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"nj2g\"\u003eGoogle has \u003ca href=\"https://blog.google/technology/families/google-new-built-in-protections-kids-teens/\"\u003edemonstrated\u003c/a\u003e our commitment to doing our part to keep kids safe online. We’re ready to build on this work and will continue engaging with lawmakers and developers on how to move this legislative framework for age assurance forward.\u003c/p\u003e\u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\n  \n\n\n\n\n\n  \n\n  \n\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-03-12T19:00:00Z",
  "modifiedTime": null
}
