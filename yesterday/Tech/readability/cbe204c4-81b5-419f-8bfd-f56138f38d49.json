{
  "id": "cbe204c4-81b5-419f-8bfd-f56138f38d49",
  "title": "A Short Introduction to Automotive Lidar Technology",
  "link": "https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar",
  "description": "Comments",
  "author": "",
  "published": "Mon, 25 Nov 2024 20:12:27 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "Vik's Newsletter",
  "length": 16288,
  "excerpt": "A guide to the operating principles, techniques and technology in lidar systems for self driving cars.",
  "siteName": "Vik's Newsletter",
  "favicon": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7ac9a28-8847-46e2-a70a-5b20d487d559%2Fapple-touch-icon-1024x1024.png",
  "text": "Ubiquitous adoption of lidar in self driving cars needs one major thing: lower cost. Lidar has proven to be a capable technology for level 4 autonomous driving, and is already used in self driving taxis by Waymo and Cruise. But the spinning lidar domes on top of these cars cost thousands of dollars, and that number needs to drop by at least an order of magnitude.There are over 140 startups in the lidar space looking to make that happen and more.In this post, we will cover the basics of automotive lidar technology:Lidar for autonomous vehiclesWavelength of operationPhotodetectorsRanging techniquesMechanical lidarScanning systemsMEMS mirrorsSolid-state lidarFlash lidarOptical phased arraysReferencesRead time: 12 minsThe post may be too long for email. Please read it online.Lidar stands for Light Detection and Ranging and is a method where infrared laser light is used to measure the distance to a remote object. This technology is not new. For years, it has been used for imaging vegetation, urban terrain, hidden archeological sites, building construction and recently, in augmented reality. Its particular superpower is that it can generate high resolution images of its surroundings much better than radar can. While lidar and radar are fundamentally similar in operation, the use of shorter wavelengths (lasers) compared to radar (microwaves) gives it the ability to generate highly detailed images.In last week’s article, we looked at the camera versus lidar debate for self driving cars. If you missed that, you can read it below.Since 2020, lidar has become especially relevant as the “eyes” of autonomous vehicles. Its ability to rapidly generate precise 3D images of the surroundings is critical in making accurate distance estimations for self driving. The downside of lidar is cost. Laser sources, detectors and associated electronics and mechanics are expensive. The rise of solid-state lidar technologies may still offer a competitive price point for widespread adoption of lidar in self driving cars. The next sections will explain the inner workings of lidar technology.Lidar systems are predominantly designed to operate in one of two wavelengths that are in the infrared region (750 nanometers to 15 micrometers) of the electromagnetic spectrum, but outside visible range (380 to 700 nanometers).905 nm (near infrared, or NIR)1550 nm (short wave infrared, or SWIR)The choice of wavelength in a lidar system depends on the output power of laser sources, sensitivity of detectors and the interference from natural and artificial light sources in the same spectrum.Sunlight is one of the dominant sources of interference which has a lot of energy in the infrared region of the spectrum. A measure of sunlight’s impact is called the solar photon flux, which is the amount of sunlight hitting the earth at any given wavelength.Impact of sunlight at ground level versus wavelength. Source: OusterThere are some noticeable dips at 905, 940 and 1550 nm due to absorption by water vapor in the upper atmosphere, which conveniently reduces interference in systems at ground level. Unfortunately, the same effect absorbs radiation in foggy and rainy road conditions. The proximity of the 905 nm wavelength to the visible range causes two other concerns:905 nm laser wavelengths are easily absorbed by the retina causing damage from prolonged exposure. As a result, there are strict standards for lidar eye safety that must be adhered to.There are plenty of interference sources near visible light, both from the sun and from vehicle headlamps that degrade the system performance.However, at shorter wavelengths, photodetectors are generally more sensitive and laser sources are more powerful and inexpensive. Ouster, for example, has actually adopted 850 nm for its lidar technology despite high solar photon flux due to better visibility in damp conditions, improved source and detector performance, with patented approaches to rejecting environmental interference.1550 nm wavelength mitigates some problems; lower interference from solar radiation, and lower eye safety concerns because this wavelength only penetrates up to the cornea, thus protecting the retina. Better eye safety implies that more power can be used at 1550 nm for longer periods of time, providing longer detection range. The downside of 1550 nm wavelength is that the high absorption by water vapor makes it difficult to use in wet conditions.The choice of wavelength also depends on the capabilities and economics of photodetectors.Avalanche photodiodes (APDs) are the most commonly used detectors in lidar. They are specially engineered PN semiconductor junctions that utilize the photoelectric effect to generate electron-hole pairs in response to incident photons. They generate a current proportional to the number of photos incident, which depends on the amount of reverse bias on the diode. APDs are most often built with Silicon (Si), Germanium (Ge), and Indium Gallium Arsenide (InGaAs), but each of them respond differently to infrared wavelengths. Silicon APDs respond well to NIR and are inexpensive to manufacture, while InGaAs works well for SWIR wavelengths but are more expensive.Responsivity curves for various infrared sensor APDs. Source: PhluxA popular detector used in lidar systems is the single-photon avalanche diode (SPAD). SPADs are especially interesting as photodetectors. Unlike traditional avalanche photodiodes (APDs) which generate a signal proportional to the amount of light, SPADs generate a near binary response to the arrival of a photon by operating in “Geiger-mode” where the photodiode is heavily reverse-biased. The avalanche breakdown effect in the diode generates massive amounts of current when incident even with a single photon. With this, the timing of photon arrivals can be determined to pico-second (trillionth of a second) accuracies which allows accurate distance measurements using these sensors. An added benefit is that SPADs can be implemented in a CMOS process making them low cost. This also allows massive amounts of signal processing to be integrated right next to the detector array.Especially at 905 nm, silicon photomultipliers (SiPMs) have largely replaced Si APDs. SiPMs are arrays of microcells comprising of a SPAD with a quenching resistor to self-limit the flow of avalanche current. SiPMs provide very high photoelectric gain and are capable of detecting the precise number of incident photons depending on output current levels.The detection of object distance using lidar is called ranging, and there are two popular approaches that are often used.Much like how sonar echo-location or pulsed doppler radar works, ToF sensing using lidar involves emitting laser bursts and measuring the time taken to detect the reflected signal. The total time elapsed from signal emission to reception is called the round-trip delay. Since the actual time to the object is half the round-trip delay, the distance is calculated using the speed of light in the propagating medium.ToF lidar ranging. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdfThe smallest distance that can be measured using ToF depends on the resolution of the timing electronics. A nearby object might have a short round-trip delay that the detector might not resolve. Hence the minimum depth of such radars are usually limited to a few centimeters.The largest distance that can be measured depends on the transmitted power, detector sensitivity and free space path loss. If the reflected signal is indistinguishable from background noise, then the distance to the object cannot be resolved. Commercial dToF systems have a maximum range of 100-200 meters.Most lidar systems today use dToF ranging methods due to simplicity. A slightly different temporal detection approach is to use continuous wave signals, and detect the phase shift of the reflected wave. This method is called indirect ToF (iToF), or more specifically amplitude modulated continuous wave (AMCW). It is less sensitive to timing drift and better suited to short distance measurements.AMCW lidar ranging. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdfWhile ToF uses pulsed or continuous wave signals of a fixed wavelength, there are benefits to modulating it. Lidars that use the modulation of the wavelength or frequency of the transmitted pulse are called FMCW lidars. While many sources online claim that FMCW lidar is new technology, it is not. It has been around since the 1960s and the concept is widely used in automotive radar technology.FMCW LiDAR. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdfEach burst of frequency modulated signal is called a “chirp”, and the reflected signal received after a time delay has an instantaneous frequency difference between transmitted and reflected pulses. This “beat” frequency can be downconverted using a mixer and used to compute both distance and velocity of the object. I have explained before how this works for radar, and the same principles apply to lidar. FMCW lidar systems are complex to implement due to the need for a frequency tunable laser source for modulation and additional electronics needed to extract information from the transmitted and received signals. But they do give lower interference from nearby lidar systems because the frequencies are different at any point in time. Also, FMCW lidar requires lower peak power from a laser compared to ToF which has implications in eye safety requirements especially at 905 nm.A mechanical lidar has an infrared laser that is mounted on a brushless DC motor that rotates the sensor thus providing it a 360° field of view (FOV) in the horizontal direction and eliminating any blindspots. The FOV in the vertical direction is still limited to about 90-95°. An example of a mechanical scanning lidar sensor is Waymo’s Laser Bear Honeycomb, which is often seen mounted on top of its self driving fleet of cars. The motors and its associated precision moving parts add to the bill of materials, and are subject to wear and tear from repeated use. As a result, scanning lidar systems are bulky and expensive.Waymo’s Jaguar iPace with a scanning Lidar sensor. Source: WaymoInstead of moving the laser source and sensor around like in mechanical scanning, another approach is to reflect the laser light off a movable micro-electromechanical (MEMS) mirror. By oscillating the MEMS mirror back and forth at a fixed rate, the lidar can be scanned across 3D space. MEMS mirrors can be made to move with electrostatic (only electric field), electromagnetic (electric and magnetic field), or electrothermal (with heat) actuation mechanisms. Below is a nice demonstration of the concept; video credits: TTP. A trade-off in MEMS mirror design is weight versus scanning rate; a heavy mirror will have low scanning rate. While the video above shows 1D scanning, 2D MEMS mirrors have also been implemented where the mirrors have a slow and fast axis. The mirrors move quickly along one direction allowing fast raster scanning, while moving slower in the perpendicular direction to only produce a static positional shift for a new rapid scan.Arguably, the greatest benefit is the fact that MEMS mirrors can be fabricated using back-end-of-line processes in a legacy CMOS foundry and are considered a mature technology. This enables low-cost implementations of scanning lidar technology.Instead of scanning 3D space, think of flash lidar as a photographic capture that illuminates the space in front of it. Flash lidar consists of a vertical-cavity surface-emitting laser (VCSEL) as laser source that is diffused to illuminate a target. The reflected signals are detected with an SiPM array. These lidar flashes are taken at rates up to 30 frames per second providing a real-time rendering of 3D space. By the nature of how it works, flash lidar has a reduced FOV compared to a rotating mechanical lidar scanner.The resolution of flash lidar is limited by how many pixels fit into a given area, much like a digital camera. Compared to the scanning type, flash lidar has lower signal-to-noise ratio (SNR) because the limited optical laser power needs to be distributed to all pixels in the array. The detection sensitivity is also limited by background noise in the environment at the same wavelength as the laser. SNR is the ultimate limiting factor in the detection range of flash lidar with sensing distances up to 100 meters and centimeter-scale resolutions being reported in literature.Some companies have adopted a multi-beam approach to flash lidar, illuminating only those parts of the environment where the detector is looking for information. This allows greater optical power to be directed at fewer, but more relevant pixels in the array, enhancing SNR. It is a combination of scanning and flash lidar, with the advantages of both.Overall, the lack of moving parts means that the system is much more reliable, immune to vibration effects, and has increased data capture rate.The most recent approach still in the research phase is to use silicon photonics to implement scanning lidar on a chip. The idea is borrowed from phased array antennas which allow scanning of the radiated beam by adjusting the phase shift of each signal fed to an antenna array. Phase shifts are implemented either with integrated optical waveguides, or by using integrated heaters to slow light through the mechanism of thermo-optic coupling. Depending on the phase shift, the direction of the radiated wavefront can be scanned in 3D space. I have explained this in a previous article.Now, the same approach is being utilized to steer infrared lasers by implementing phase shifts to integrated optical modulators in a photonics platform. The benefits of OPA are greatly increased scanning speeds due to electronic control and no moving parts. The cost and reliability benefits from a purely integrated approach on 300-mm diameter silicon wafers is also attractive.The use of optical frequencies presents its own challenges in the context of phased arrays:Thermal management: The heat generated from many on chip laser sources must be dissipated effectively.Proximity of elements: Phased arrays require elements spaced half a wavelength apart. At 1550 nm laser wavelength, that means each laser source needs to be spaced under a micron apart.Scanning angle: In phased arrays, the best quality beam is at “boresight” or right in front of the array. As the beam is scanned away from the center, say beyond 60°, grating lobes degrade the beam width. Analog Photonics is a spin off from MIT, founded by Prof. Michael Watts, that is working on commercializing OPA technology and is worth keeping an eye on.EETimes: What’s the Direction for Automotive LiDAR: 905 nm or 1550 nm?Texas Instruments: An introduction to automotive lidarOnsemi: Introduction to the Silicon PhotomultiplierAeye: Time of Flight vs. FMCW LiDAR: A side-by-side comparisonIEEE Spectrum: Lidar on a chip puts self driving cars in the fast lanePhlux: The role of infrared sensors in light detection and ranging - lidarN. Li et al., “A Progress Review on Solid‐State LiDAR and Nanophotonics‐Based LiDAR Sensors,” Laser \u0026 Photonics Reviews, vol. 16, no. 11, p. 2100511, Nov. 2022, doi: 10.1002/lpor.202100511.D. Wang, C. Watkins, and H. Xie, “MEMS Mirrors for LiDAR: A Review,” Micromachines, vol. 11, no. 5, p. 456, Apr. 2020, doi: 10.3390/mi11050456.If you like this post, please click ❤️ on Substack, subscribe to the publication, and tell someone if you like it. 🙏🏽 If you enjoyed this issue, reply to the email and let me know your thoughts, or leave a comment on this post.Leave a commentJoin a Discord community of professionals, enthusiasts and students, and get in on the discussion.Join DiscordThe views, thoughts, and opinions expressed in this newsletter are solely mine; they do not reflect the views or positions of my employer or any entities I am affiliated with. The content provided is for informational purposes only and does not constitute professional or investment advice.",
  "image": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc68959f4-8bfc-412e-ae61-9027a0d864ad_1456x1048.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle\u003e\u003cdiv dir=\"auto\"\u003e\u003cp\u003eUbiquitous adoption of lidar in self driving cars needs one major thing: lower cost. \u003c/p\u003e\u003cp\u003e\u003cspan\u003eLidar has proven to be a capable technology for \u003c/span\u003e\u003ca href=\"https://www.sae.org/blog/sae-j3016-update\" rel=\"\"\u003elevel 4\u003c/a\u003e\u003cspan\u003e autonomous driving, and is already used in self driving taxis by Waymo and Cruise. But the spinning lidar domes on top of these cars cost thousands of dollars, and that number needs to drop by at least an order of magnitude.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eThere are \u003c/span\u003e\u003ca href=\"https://tracxn.com/d/companies/lidar/__S0h0aWT4FqieGUvRDUJ0Jly7aZjCfw3Yk5P2sJUm04Y/competitors#competitive-landscape\" rel=\"\"\u003eover 140 startups\u003c/a\u003e\u003cspan\u003e in the lidar space looking to make that happen and more.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eIn this post, we will cover the basics of automotive lidar technology:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eLidar for autonomous vehicles\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eWavelength of operation\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003ePhotodetectors\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRanging techniques\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eMechanical lidar\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eScanning systems\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eMEMS mirrors\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSolid-state lidar\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eFlash lidar\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eOptical phased arrays\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eReferences\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eRead time\u003c/strong\u003e\u003cspan\u003e: 12 mins\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThe post may be too long for email. Please read it online.\u003c/em\u003e\u003c/p\u003e\u003cp\u003eLidar stands for Light Detection and Ranging and is a method where infrared laser light is used to measure the distance to a remote object. This technology is not new. For years, it has been used for imaging vegetation, urban terrain, hidden archeological sites, building construction and recently, in augmented reality. Its particular superpower is that it can generate high resolution images of its surroundings much better than radar can. While lidar and radar are fundamentally similar in operation, the use of shorter wavelengths (lasers) compared to radar (microwaves) gives it the ability to generate highly detailed images.\u003c/p\u003e\u003cp\u003eIn last week’s article, we looked at the camera versus lidar debate for self driving cars. If you missed that, you can read it below.\u003c/p\u003e\u003cdiv data-component-name=\"DigestPostEmbed\"\u003e\u003ca href=\"https://www.viksnewsletter.com/p/teslas-big-bet-cameras-over-lidar\" target=\"_blank\" rel=\"noopener\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa10835d4-e008-4f1b-8763-fc1da126c6e2_1456x1048.png\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa10835d4-e008-4f1b-8763-fc1da126c6e2_1456x1048.png\" sizes=\"100vw\" alt=\"Tesla’s Big Bet: Cameras over LiDAR for Self Driving Cars\" width=\"140\" height=\"140\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp\u003eSince 2020, lidar has become especially relevant as the “eyes” of autonomous vehicles. Its ability to rapidly generate precise 3D images of the surroundings is critical in making accurate distance estimations for self driving. The downside of lidar is cost. Laser sources, detectors and associated electronics and mechanics are expensive. The rise of solid-state lidar technologies may still offer a competitive price point for widespread adoption of lidar in self driving cars. \u003c/p\u003e\u003cp\u003eThe next sections will explain the inner workings of lidar technology.\u003c/p\u003e\u003cp\u003eLidar systems are predominantly designed to operate in one of two wavelengths that are in the infrared region (750 nanometers to 15 micrometers) of the electromagnetic spectrum, but outside visible range (380 to 700 nanometers).\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e905 nm (near infrared, or NIR)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e1550 nm (short wave infrared, or SWIR)\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThe choice of wavelength in a lidar system depends on the output power of laser sources, sensitivity of detectors and the interference from natural and artificial light sources in the same spectrum.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eSunlight is one of the dominant sources of interference which has a lot of energy in the infrared region of the spectrum. A measure of sunlight’s impact is called the \u003c/span\u003e\u003cem\u003esolar photon flux\u003c/em\u003e\u003cspan\u003e, which is the amount of sunlight hitting the earth at any given wavelength.\u003c/span\u003e\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003ca target=\"_blank\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png\" data-component-name=\"Image2ToDOM\" rel=\"\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1456w\" sizes=\"100vw\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png\" width=\"1110\" height=\"524\" data-attrs=\"{\u0026#34;src\u0026#34;:\u0026#34;https://substack-post-media.s3.amazonaws.com/public/images/5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png\u0026#34;,\u0026#34;srcNoWatermark\u0026#34;:null,\u0026#34;fullscreen\u0026#34;:null,\u0026#34;imageSize\u0026#34;:null,\u0026#34;height\u0026#34;:524,\u0026#34;width\u0026#34;:1110,\u0026#34;resizeWidth\u0026#34;:null,\u0026#34;bytes\u0026#34;:346506,\u0026#34;alt\u0026#34;:null,\u0026#34;title\u0026#34;:null,\u0026#34;type\u0026#34;:\u0026#34;image/png\u0026#34;,\u0026#34;href\u0026#34;:null,\u0026#34;belowTheFold\u0026#34;:true,\u0026#34;topImage\u0026#34;:false,\u0026#34;internalRedirect\u0026#34;:null,\u0026#34;isProcessing\u0026#34;:false}\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fc614d4-eb17-4411-bb8c-1a9be3ad80a5_1110x524.png 1456w\" sizes=\"100vw\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003cspan\u003eImpact of sunlight at ground level versus wavelength. Source: \u003c/span\u003e\u003ca href=\"https://ouster.com/insights/blog/how-multi-beam-flash-lidar-works\" rel=\"\"\u003eOuster\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThere are some noticeable dips at 905, 940 and 1550 nm due to absorption by water vapor in the upper atmosphere, which conveniently reduces interference in systems at ground level. Unfortunately, the same effect absorbs radiation in foggy and rainy road conditions. The proximity of the 905 nm wavelength to the visible range causes two other concerns:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e905 nm laser wavelengths are easily absorbed by the retina causing damage from prolonged exposure. As a result, there are strict standards for lidar eye safety that must be adhered to.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThere are plenty of interference sources near visible light, both from the sun and from vehicle headlamps that degrade the system performance.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003cspan\u003eHowever, at shorter wavelengths, photodetectors are generally more sensitive and laser sources are more powerful and inexpensive. \u003c/span\u003e\u003ca href=\"https://ouster.com\" rel=\"\"\u003eOuster\u003c/a\u003e\u003cspan\u003e, for example, has actually adopted 850 nm for its lidar technology despite high solar photon flux due to better visibility in damp conditions, improved source and detector performance, with patented approaches to rejecting environmental interference.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e1550 nm wavelength mitigates some problems; lower interference from solar radiation, and lower eye safety concerns because this wavelength only penetrates up to the cornea, thus protecting the retina. Better eye safety implies that more power can be used at 1550 nm for longer periods of time, providing longer detection range. The downside of 1550 nm wavelength is that the high absorption by water vapor makes it difficult to use in wet conditions.\u003c/p\u003e\u003cp\u003eThe choice of wavelength also depends on the capabilities and economics of photodetectors.\u003c/p\u003e\u003cp\u003eAvalanche photodiodes (APDs) are the most commonly used detectors in lidar. They are specially engineered PN semiconductor junctions that utilize the photoelectric effect to generate electron-hole pairs in response to incident photons. They generate a current proportional to the number of photos incident, which depends on the amount of reverse bias on the diode. \u003c/p\u003e\u003cp\u003eAPDs are most often built with Silicon (Si), Germanium (Ge), and Indium Gallium Arsenide (InGaAs), but each of them respond differently to infrared wavelengths. Silicon APDs respond well to NIR and are inexpensive to manufacture, while InGaAs works well for SWIR wavelengths but are more expensive.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003ca target=\"_blank\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp\" data-component-name=\"Image2ToDOM\" rel=\"\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1456w\" sizes=\"100vw\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp\" width=\"610\" height=\"431.575\" data-attrs=\"{\u0026#34;src\u0026#34;:\u0026#34;https://substack-post-media.s3.amazonaws.com/public/images/f0292f4a-da98-4104-898b-009a3d06305c_800x566.webp\u0026#34;,\u0026#34;srcNoWatermark\u0026#34;:null,\u0026#34;fullscreen\u0026#34;:null,\u0026#34;imageSize\u0026#34;:null,\u0026#34;height\u0026#34;:566,\u0026#34;width\u0026#34;:800,\u0026#34;resizeWidth\u0026#34;:610,\u0026#34;bytes\u0026#34;:null,\u0026#34;alt\u0026#34;:\u0026#34;APD response curves\u0026#34;,\u0026#34;title\u0026#34;:null,\u0026#34;type\u0026#34;:null,\u0026#34;href\u0026#34;:null,\u0026#34;belowTheFold\u0026#34;:true,\u0026#34;topImage\u0026#34;:false,\u0026#34;internalRedirect\u0026#34;:null,\u0026#34;isProcessing\u0026#34;:false}\" alt=\"APD response curves\" title=\"APD response curves\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0292f4a-da98-4104-898b-009a3d06305c_800x566.webp 1456w\" sizes=\"100vw\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003cspan\u003eResponsivity curves for various infrared sensor APDs. Source: \u003c/span\u003e\u003ca href=\"https://phluxtechnology.com/latest/the-role-of-infrared-sensors-in-light-detection-and-ranging-lidar\" rel=\"\"\u003ePhlux\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eA popular detector used in lidar systems is the single-photon avalanche diode (SPAD). SPADs are especially interesting as photodetectors. Unlike traditional avalanche photodiodes (APDs) which generate a signal proportional to the amount of light, SPADs generate a near binary response to the arrival of a photon by operating in “Geiger-mode” where the photodiode is heavily reverse-biased. \u003c/p\u003e\u003cp\u003eThe avalanche breakdown effect in the diode generates massive amounts of current  when incident even with a single photon. With this, the timing of photon arrivals can be determined to pico-second (trillionth of a second) accuracies which allows accurate distance measurements using these sensors. An added benefit is that SPADs can be implemented in a CMOS process making them low cost. This also allows massive amounts of signal processing to be integrated right next to the detector array.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eEspecially at 905 nm, silicon photomultipliers (SiPMs) have largely replaced Si APDs. SiPMs are arrays of microcells comprising of a SPAD with a \u003c/span\u003e\u003cem\u003equenching \u003c/em\u003e\u003cspan\u003eresistor to self-limit the flow of avalanche current. SiPMs provide very high photoelectric gain and are capable of detecting the precise number of incident photons depending on output current levels.\u003c/span\u003e\u003c/p\u003e\u003cp\u003eThe detection of object distance using lidar is called ranging, and there are two popular approaches that are often used.\u003c/p\u003e\u003cp\u003eMuch like how sonar echo-location or pulsed doppler radar works, ToF sensing using lidar involves emitting laser bursts and measuring the time taken to detect the reflected signal. The total time elapsed from signal emission to reception is called the round-trip delay. Since the actual time to the object is half the round-trip delay, the distance is calculated using the speed of light in the propagating medium.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003ca target=\"_blank\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png\" data-component-name=\"Image2ToDOM\" rel=\"\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1456w\" sizes=\"100vw\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png\" width=\"552\" height=\"284.1017612524462\" data-attrs=\"{\u0026#34;src\u0026#34;:\u0026#34;https://substack-post-media.s3.amazonaws.com/public/images/44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png\u0026#34;,\u0026#34;srcNoWatermark\u0026#34;:null,\u0026#34;fullscreen\u0026#34;:null,\u0026#34;imageSize\u0026#34;:null,\u0026#34;height\u0026#34;:526,\u0026#34;width\u0026#34;:1022,\u0026#34;resizeWidth\u0026#34;:552,\u0026#34;bytes\u0026#34;:307963,\u0026#34;alt\u0026#34;:null,\u0026#34;title\u0026#34;:null,\u0026#34;type\u0026#34;:\u0026#34;image/png\u0026#34;,\u0026#34;href\u0026#34;:null,\u0026#34;belowTheFold\u0026#34;:true,\u0026#34;topImage\u0026#34;:false,\u0026#34;internalRedirect\u0026#34;:null,\u0026#34;isProcessing\u0026#34;:false}\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44af7fa1-46af-4473-bc07-a693fa4f1cfd_1022x526.png 1456w\" sizes=\"100vw\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003cfigcaption\u003eToF lidar ranging. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdf\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe smallest distance that can be measured using ToF depends on the resolution of the timing electronics. A nearby object might have a short round-trip delay that the detector might not resolve. Hence the minimum depth of such radars are usually limited to a few centimeters.\u003c/p\u003e\u003cp\u003eThe largest distance that can be measured depends on the transmitted power, detector sensitivity and free space path loss. If the reflected signal is indistinguishable from background noise, then the distance to the object cannot be resolved. Commercial dToF systems have a maximum range of 100-200 meters.\u003c/p\u003e\u003cp\u003eMost lidar systems today use dToF ranging methods due to simplicity. A slightly different temporal detection approach is to use continuous wave signals, and detect the phase shift of the reflected wave. This method is called indirect ToF (iToF), or more specifically amplitude modulated continuous wave (AMCW). It is less sensitive to timing drift and better suited to short distance measurements.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003ca target=\"_blank\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png\" data-component-name=\"Image2ToDOM\" rel=\"\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1456w\" sizes=\"100vw\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png\" width=\"526\" height=\"273.293542074364\" data-attrs=\"{\u0026#34;src\u0026#34;:\u0026#34;https://substack-post-media.s3.amazonaws.com/public/images/93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png\u0026#34;,\u0026#34;srcNoWatermark\u0026#34;:null,\u0026#34;fullscreen\u0026#34;:null,\u0026#34;imageSize\u0026#34;:null,\u0026#34;height\u0026#34;:531,\u0026#34;width\u0026#34;:1022,\u0026#34;resizeWidth\u0026#34;:526,\u0026#34;bytes\u0026#34;:350913,\u0026#34;alt\u0026#34;:null,\u0026#34;title\u0026#34;:null,\u0026#34;type\u0026#34;:\u0026#34;image/png\u0026#34;,\u0026#34;href\u0026#34;:null,\u0026#34;belowTheFold\u0026#34;:true,\u0026#34;topImage\u0026#34;:false,\u0026#34;internalRedirect\u0026#34;:null,\u0026#34;isProcessing\u0026#34;:false}\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93cf1c08-bb87-4655-b18d-e981140811b6_1022x531.png 1456w\" sizes=\"100vw\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003cfigcaption\u003eAMCW lidar ranging. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdf\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eWhile ToF uses pulsed or continuous wave signals of a fixed wavelength, there are benefits to modulating it. Lidars that use the modulation of the wavelength or frequency of the transmitted pulse are called FMCW lidars. While many sources online claim that FMCW lidar is new technology, it is not. It has been around since the 1960s and the concept is widely used in automotive radar technology.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003ca target=\"_blank\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png\" data-component-name=\"Image2ToDOM\" rel=\"\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1456w\" sizes=\"100vw\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png\" width=\"564\" height=\"290.27788649706457\" data-attrs=\"{\u0026#34;src\u0026#34;:\u0026#34;https://substack-post-media.s3.amazonaws.com/public/images/05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png\u0026#34;,\u0026#34;srcNoWatermark\u0026#34;:null,\u0026#34;fullscreen\u0026#34;:null,\u0026#34;imageSize\u0026#34;:null,\u0026#34;height\u0026#34;:526,\u0026#34;width\u0026#34;:1022,\u0026#34;resizeWidth\u0026#34;:564,\u0026#34;bytes\u0026#34;:339118,\u0026#34;alt\u0026#34;:null,\u0026#34;title\u0026#34;:null,\u0026#34;type\u0026#34;:\u0026#34;image/png\u0026#34;,\u0026#34;href\u0026#34;:null,\u0026#34;belowTheFold\u0026#34;:true,\u0026#34;topImage\u0026#34;:false,\u0026#34;internalRedirect\u0026#34;:null,\u0026#34;isProcessing\u0026#34;:false}\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05020a5f-e089-46ba-bdf8-cf12e6d4517d_1022x526.png 1456w\" sizes=\"100vw\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003cfigcaption\u003eFMCW LiDAR. Credit: Philip Sandborn, Berkeley Technical Report UCB/EECS-2019-148: https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-148.pdf\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003eEach burst of frequency modulated signal is called a “chirp”, and the reflected signal received after a time delay has an instantaneous frequency difference between transmitted and reflected pulses. This “beat” frequency can be downconverted using a mixer and used to compute \u003c/span\u003e\u003cem\u003eboth\u003c/em\u003e\u003cspan\u003e distance and velocity of the object. I have explained before how this works for radar, and the same principles apply to lidar. \u003c/span\u003e\u003c/p\u003e\u003cdiv data-component-name=\"DigestPostEmbed\"\u003e\u003ca href=\"https://www.viksnewsletter.com/p/how-automotive-radar-uses-chirp-signals\" target=\"_blank\" rel=\"noopener\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e2dc2a5-7b48-4d51-95e2-14a2c310e184_1092x786.gif\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e2dc2a5-7b48-4d51-95e2-14a2c310e184_1092x786.gif\" sizes=\"100vw\" alt=\"How Automotive Radar uses Chirp Signals for Sensing\" width=\"140\" height=\"140\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv data-component-name=\"DigestPostEmbed\"\u003e\u003ca href=\"https://www.viksnewsletter.com/p/how-automotive-radar-measures-velocity\" target=\"_blank\" rel=\"noopener\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05261946-b4bd-4db6-83c8-d78ecff6ce5a_1092x786.gif\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05261946-b4bd-4db6-83c8-d78ecff6ce5a_1092x786.gif\" sizes=\"100vw\" alt=\"How Automotive Radar Measures the Velocity of Objects\" width=\"140\" height=\"140\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp\u003eFMCW lidar systems are complex to implement due to the need for a frequency tunable laser source for modulation and additional electronics needed to extract information from the transmitted and received signals. But they do give lower interference from nearby lidar systems because the frequencies are different at any point in time. Also, FMCW lidar requires lower peak power from a laser compared to ToF which has implications in eye safety requirements especially at 905 nm.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eA mechanical lidar has an infrared laser that is mounted on a brushless DC motor that rotates the sensor thus providing it a 360° field of view (FOV) in the horizontal direction and eliminating any blindspots. The FOV in the vertical direction is still limited to about 90-95°. An example of a mechanical scanning lidar sensor is Waymo’s \u003c/span\u003e\u003ca href=\"https://waymo.com/blog/2019/03/bringing-3d-perimeter-lidar-to-partners/\" rel=\"\"\u003eLaser Bear Honeycomb\u003c/a\u003e\u003cspan\u003e, which is often seen mounted on top of its self driving fleet of cars. The motors and its associated precision moving parts add to the bill of materials, and are subject to wear and tear from repeated use. As a result, scanning lidar systems are bulky and expensive.\u003c/span\u003e\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003ca target=\"_blank\" href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic\" data-component-name=\"Image2ToDOM\" rel=\"\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1456w\" sizes=\"100vw\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic\" width=\"562\" height=\"322.93537015276144\" data-attrs=\"{\u0026#34;src\u0026#34;:\u0026#34;https://substack-post-media.s3.amazonaws.com/public/images/42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic\u0026#34;,\u0026#34;srcNoWatermark\u0026#34;:null,\u0026#34;fullscreen\u0026#34;:null,\u0026#34;imageSize\u0026#34;:null,\u0026#34;height\u0026#34;:489,\u0026#34;width\u0026#34;:851,\u0026#34;resizeWidth\u0026#34;:562,\u0026#34;bytes\u0026#34;:28913,\u0026#34;alt\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;title\u0026#34;:null,\u0026#34;type\u0026#34;:\u0026#34;image/heic\u0026#34;,\u0026#34;href\u0026#34;:null,\u0026#34;belowTheFold\u0026#34;:true,\u0026#34;topImage\u0026#34;:false,\u0026#34;internalRedirect\u0026#34;:null,\u0026#34;isProcessing\u0026#34;:false}\" alt=\"\" title=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42188af9-55a4-4bd4-bb89-25506272e386_851x489.heic 1456w\" sizes=\"100vw\" loading=\"lazy\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003cfigcaption\u003eWaymo’s Jaguar iPace with a scanning Lidar sensor. Source: Waymo\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003eInstead of moving the laser source and sensor around like in mechanical scanning, another approach is to reflect the laser light off a movable micro-electromechanical (MEMS) mirror. By oscillating the MEMS mirror back and forth at a fixed rate, the lidar can be scanned across 3D space. MEMS mirrors can be made to move with electrostatic (only electric field), electromagnetic (electric and magnetic field), or electrothermal (with heat) actuation mechanisms. Below is a nice demonstration of the concept; video credits: \u003c/span\u003e\u003ca href=\"https://www.ttp.com/insights/building-the-perfect-mems-mirror-for-next-generation-lidar-what-have-we-learned/\" rel=\"\"\u003eTTP\u003c/a\u003e\u003cspan\u003e. \u003c/span\u003e\u003c/p\u003e\u003cp\u003eA trade-off in MEMS mirror design is weight versus scanning rate; a heavy mirror will have low scanning rate. While the video above shows 1D scanning, 2D MEMS mirrors have also been implemented where the mirrors have a slow and fast axis. The mirrors move quickly along one direction allowing fast raster scanning, while moving slower in the perpendicular direction to only produce a static positional shift for a new rapid scan.\u003c/p\u003e\u003cp\u003eArguably, the greatest benefit is the fact that MEMS mirrors can be fabricated using back-end-of-line processes in a legacy CMOS foundry and are considered a mature technology. This enables low-cost implementations of scanning lidar technology.\u003c/p\u003e\u003cp\u003eInstead of scanning 3D space, think of flash lidar as a photographic capture that illuminates the space in front of it. Flash lidar consists of a vertical-cavity surface-emitting laser (VCSEL) as laser source that is diffused to illuminate a target. The reflected signals are detected with an SiPM array. These lidar flashes are taken at rates up to 30 frames per second providing a real-time rendering of 3D space. By the nature of how it works, flash lidar has a reduced FOV compared to a rotating mechanical lidar scanner.\u003c/p\u003e\u003cp\u003eThe resolution of flash lidar is limited by how many pixels fit into a given area, much like a digital camera. Compared to the scanning type, flash lidar has lower signal-to-noise ratio (SNR) because the limited optical laser power needs to be distributed to all pixels in the array. The detection sensitivity is also limited by background noise in the environment at the same wavelength as the laser. SNR is the ultimate limiting factor in the detection range of flash lidar with sensing distances up to 100 meters and centimeter-scale resolutions being reported in literature.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eSome companies have adopted a \u003c/span\u003e\u003cem\u003emulti-beam \u003c/em\u003e\u003cspan\u003eapproach to flash lidar, illuminating only those parts of the environment where the detector is looking for information. This allows greater optical power to be directed at fewer, but more relevant pixels in the array, enhancing SNR. It is a combination of scanning and flash lidar, with the advantages of both.\u003c/span\u003e\u003c/p\u003e\u003cp\u003eOverall, the lack of moving parts means that the system is much more reliable, immune to vibration effects, and has increased data capture rate.\u003c/p\u003e\u003cp\u003eThe most recent approach still in the research phase is to use silicon photonics to implement scanning lidar on a chip. The idea is borrowed from phased array antennas which allow scanning of the radiated beam by adjusting the phase shift of each signal fed to an antenna array. Phase shifts are implemented either with integrated optical waveguides, or by using integrated heaters to slow light through the mechanism of thermo-optic coupling. Depending on the phase shift, the direction of the radiated wavefront can be scanned in 3D space. I have explained this in a previous article.\u003c/p\u003e\u003cdiv data-component-name=\"DigestPostEmbed\"\u003e\u003ca href=\"https://www.viksnewsletter.com/p/basics-of-phased-array-antennas-and\" target=\"_blank\" rel=\"noopener\"\u003e\u003cdiv\u003e\u003cpicture\u003e\u003csource type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10cc2e24-476f-4f04-998d-ce32e7573756_1456x1048.png\"/\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10cc2e24-476f-4f04-998d-ce32e7573756_1456x1048.png\" sizes=\"100vw\" alt=\"How does a Phased Array Antenna work? Types of Beamforming Architectures\" width=\"140\" height=\"140\"/\u003e\u003c/picture\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp\u003eNow, the same approach is being utilized to steer infrared lasers by implementing phase shifts to integrated optical modulators in a photonics platform. The benefits of OPA are greatly increased scanning speeds due to electronic control and no moving parts. The cost and reliability benefits from a purely integrated approach on 300-mm diameter silicon wafers is also attractive.\u003c/p\u003e\u003cp\u003eThe use of optical frequencies presents its own challenges in the context of phased arrays:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eThermal management\u003c/strong\u003e\u003cspan\u003e: The heat generated from many on chip laser sources must be dissipated effectively.\u003c/span\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eProximity of elements\u003c/strong\u003e\u003cspan\u003e: Phased arrays require elements spaced half a wavelength apart. At 1550 nm laser wavelength, that means each laser source needs to be spaced under a micron apart.\u003c/span\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eScanning angle\u003c/strong\u003e\u003cspan\u003e: In phased arrays, the best quality beam is at “boresight” or right in front of the array. As the beam is scanned away from the center, say beyond 60°, grating lobes degrade the beam width. \u003c/span\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003ca href=\"https://www.analogphotonics.com/home/\" rel=\"\"\u003eAnalog Photonics\u003c/a\u003e\u003cspan\u003e is a spin off from MIT, founded by Prof. Michael Watts, that is working on commercializing OPA technology and is worth keeping an eye on.\u003c/span\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eEETimes: \u003c/span\u003e\u003ca href=\"https://www.eetimes.com/whats-the-direction-for-automotive-lidar-905-nm-or-1550-nm/\" rel=\"\"\u003eWhat’s the Direction for Automotive LiDAR: 905 nm or 1550 nm?\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eTexas Instruments: \u003c/span\u003e\u003ca href=\"https://www.ti.com/lit/wp/slyy150b/slyy150b.pdf?ts=1703269882036\" rel=\"\"\u003eAn introduction to automotive lidar\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eOnsemi: \u003c/span\u003e\u003ca href=\"https://www.onsemi.com/pub/Collateral/AND9770-D.PDF\" rel=\"\"\u003eIntroduction to the Silicon Photomultiplier\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eAeye: \u003c/span\u003e\u003ca href=\"https://www.aeye.ai/resources/white-papers/time-of-flight-vs-fmcw-lidar-a-side-by-side-comparison/\" rel=\"\"\u003eTime of Flight vs. FMCW LiDAR: A side-by-side comparison\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eIEEE Spectrum: \u003c/span\u003e\u003ca href=\"https://spectrum.ieee.org/lidar-on-a-chip\" rel=\"\"\u003eLidar on a chip puts self driving cars in the fast lane\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003ePhlux: \u003c/span\u003e\u003ca href=\"https://phluxtechnology.com/latest/the-role-of-infrared-sensors-in-light-detection-and-ranging-lidar\" rel=\"\"\u003eThe role of infrared sensors in light detection and ranging - lidar\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eN. Li \u003c/span\u003e\u003cem\u003eet al.\u003c/em\u003e\u003cspan\u003e, “A Progress Review on Solid‐State LiDAR and Nanophotonics‐Based LiDAR Sensors,” \u003c/span\u003e\u003cem\u003eLaser \u0026amp; Photonics Reviews\u003c/em\u003e\u003cspan\u003e, vol. 16, no. 11, p. 2100511, Nov. 2022, doi: \u003c/span\u003e\u003ca href=\"https://doi.org/10.1002/lpor.202100511\" rel=\"\"\u003e10.1002/lpor.202100511\u003c/a\u003e\u003cspan\u003e.\u003c/span\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cspan\u003eD. Wang, C. Watkins, and H. Xie, “MEMS Mirrors for LiDAR: A Review,” \u003c/span\u003e\u003cem\u003eMicromachines\u003c/em\u003e\u003cspan\u003e, vol. 11, no. 5, p. 456, Apr. 2020, doi: \u003c/span\u003e\u003ca href=\"https://doi.org/10.3390/mi11050456\" rel=\"\"\u003e10.3390/mi11050456\u003c/a\u003e\u003cspan\u003e.\u003c/span\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf you like this post, please click ❤️ on Substack, subscribe to the publication, and tell someone if you like it. 🙏🏽 \u003c/p\u003e\u003cp\u003e\u003cspan\u003eIf you enjoyed this issue, \u003c/span\u003e\u003cstrong\u003ereply to the email\u003c/strong\u003e\u003cspan\u003e and let me know your thoughts, or leave a comment on this post.\u003c/span\u003e\u003c/p\u003e\u003cp data-attrs=\"{\u0026#34;url\u0026#34;:\u0026#34;https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar/comments\u0026#34;,\u0026#34;text\u0026#34;:\u0026#34;Leave a comment\u0026#34;,\u0026#34;action\u0026#34;:null,\u0026#34;class\u0026#34;:null}\" data-component-name=\"ButtonCreateButton\"\u003e\u003ca href=\"https://www.viksnewsletter.com/p/short-intro-to-automotive-lidar/comments\" rel=\"\"\u003e\u003cspan\u003eLeave a comment\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003eJoin a Discord community of professionals, enthusiasts and students, and get in on the discussion.\u003c/p\u003e\u003cp data-attrs=\"{\u0026#34;url\u0026#34;:\u0026#34;https://discord.gg/e6ysnA9c7q\u0026#34;,\u0026#34;text\u0026#34;:\u0026#34;Join Discord\u0026#34;,\u0026#34;action\u0026#34;:null,\u0026#34;class\u0026#34;:null}\" data-component-name=\"ButtonCreateButton\"\u003e\u003ca href=\"https://discord.gg/e6ysnA9c7q\" rel=\"\"\u003e\u003cspan\u003eJoin Discord\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThe views, thoughts, and opinions expressed in this newsletter are solely mine; they do not reflect the views or positions of my employer or any entities I am affiliated with. The content provided is for informational purposes only and does not constitute professional or investment advice.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "17 min read",
  "publishedTime": "2024-11-24T18:29:48Z",
  "modifiedTime": null
}
