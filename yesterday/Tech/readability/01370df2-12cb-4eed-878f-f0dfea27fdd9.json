{
  "id": "01370df2-12cb-4eed-878f-f0dfea27fdd9",
  "title": "Differentiable Logic Cellular Automata",
  "link": "https://google-research.github.io/self-organising-systems/difflogic-ca/?hn",
  "description": "Comments",
  "author": "",
  "published": "Thu, 06 Mar 2025 23:43:37 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "",
  "length": 40071,
  "excerpt": "We use Differentiable Logic Gate Networks to create end-to-end differentiable, self-organizing discrete cellular automata powered by recurrent circuits, capable of playing the Game of Life as well as producing patterns à la Neural Cellular Automata.",
  "siteName": "",
  "favicon": "https://google-research.github.io/self-organising-systems/difflogic-ca/images/notaorb_180.png?b",
  "text": "From Game of Life to pattern generation with learned recurrent circuitsAFFILIATIONS:Google, Paradigms of Intelligence TeamImagine trying to reverse-engineer the complex, often unexpected patterns and behaviors that emerge from simple rules. This challenge has inspired researchers and enthusiasts that work with cellular automata for decades. In cellular automata, we generally approach things from the bottom-up. We choose local rules, then investigate the resulting emergent patterns. What if we could create systems that, given some complex desired pattern, can, in a fully differentiable fashion, learn the local rules that generate it, while preserving the inherent discrete nature of cellular automata? This is what we'll explore with you today.Zoomed view of learned circuit\"G\" being generated by learned circuitPrior work has explored learning transition rules using non-differentiable techniques, demonstrating the feasibility of evolving local rules for specific computation. Likewise prior exploration of making one-dimensional cellular automata differentiable exist. We propose a novel, fully end-to-end differentiable approach, combining two interesting concepts from the world of artificial intelligence: Neural Cellular Automata (NCA) and Differentiable Logic Gates Networks . NCA exhibit the ability to learn arbitrary patterns and behaviors, however, they do not inherently operate within a discrete state space. This makes interpretability more challenging, and leaves them stuck in a regime where current hardware must perform costly matrix multiplications to gradually update their continuous internal states. Differentiable Logic Gates Networks, meanwhile, have been used to discover combinatorial logic circuits, blending discrete states with differentiable training signals. But they haven't yet been shown to work in recurrent settings. NCA, as it were, are recurrent in both space, and time. Sounds intriguing, right?Zooming out, we believe the integration of differentiable logic gates and neural cellular automata is a potential step towards programmable matter - Computronium - a theoretical physical substance capable of performing arbitrary computation. Toffoli and Margolus pioneered this direction with CAM-8, a cellular automata based computing architecture , in theory capable of immense, horizontally scalable computation. However, they faced a fundamental challenge: actually crafting the local rules needed to achieve a desired macroscopic computation, with Amato et al. noting that “other researchers [...] still worry about the difficulty of finding local rules that correspond to real natural systems” . What if we could directly learn these local rules, and create models that combine binary logic, the flexibility of neural networks, and the local processing of cellular automata? We believe our prototypes offer a glimpse into the future of computing: learnable, local, and discrete.This article will walk you through implementing cellular automata using differentiable logic gates, and demonstrate some key results along the way.We're faced with two fundamental questions. ❓Can a Differentiable Logic CA learn at all? To answer this, we'll start by attacking Conway's Game of Life - perhaps the most iconic cellular automata, having captivated researchers for decades. While this first experiment might seem overly simplistic (functionally equivalent to learning a truth table), it will prove the basic learning capability of our setup. The more profound question follows: ❓Can recurrent-in-space and recurrent-in-time circuits learn complex patterns similar to those generated by traditional NCAs? While both Differentiable Logic Gate Networks and Neural Cellular Automata (NCAs) have demonstrated trainability, effectively training circuits that exhibit both temporal and spatial recurrence of NCA, within the framework of differentiable logic, remains unexplored. The second experiment will demonstrate the model's ability to learn recurrent circuits that generate complex patterns similar to the ones generated by traditional NCA. Recap - Neural Cellular AutomataAt the heart of this project lies Neural Cellular Automata (NCA), a synthesis of classical cellular automata with modern deep learning techniques. This powerful paradigm, pioneered by Mordvintsev et al. , represents a fundamental shift in how we think about computational systems that can grow, adapt, and self-organize.Traditional cellular automata have long captivated researchers with their ability to generate complex behaviors from simple, local rules. Neural Cellular Automata take this concept further by making these rules learnable through gradient descent. Instead of hand-designing update rules, the system discovers them automatically, opening up entirely new possibilities for self-organizing computational systems.What makes this approach particularly elegant is how it preserves the core principles of cellular automata - locality, parallelism, and state-based computation - while introducing the adaptability of neural networks. In the following sections, we will summarize the main concepts from the “Growing Neural Cellular Automata” work , which presents a Neural Cellular Automata developed for morphogenesis. If you are already familiar with it, feel free to skip it.The Structure: A 2D Grid of Intelligent CellsAt the heart of the system is a 2D grid, much like classic cellular automata. Each cell contains an n-dimensional vector of information which is called the cell's state (or channels) and for the specific case of Growing-NCA it is composed by these elements:RGB Colors (3 channels): These represent the visible properties of the cell, essentially its color.Alpha (α) Channel (1 channel): This indicates cell vitality. If the alpha value is greater than 0.1, the cell is considered “alive.”Hidden Channels (n minus 4 channels): These allow cells to communicate more complex information about their environment, making interactions richer and more dynamic.But the magic doesn’t stop here. What really sets this system apart is how the cells interact and evolve through a two-stage process.The Two-Stage Update Mechanism: Perception and UpdateThe Perception StageIn the first stage, each cell perceives its environment. Think of it as a cell sensing the world around it. To do this, it uses Sobel filters, mathematical tools designed to numerically approximate spatial gradients - \"changes across its surroundings\". The filters are applied channel-wise, and the result is termed the perception vector, which combines the cell’s current state with the information it gathers about its environment. A bit like how biological cells use chemical gradients to sense and react to their surroundings.The Update StageNext, the neural network steps in. Each cell uses its perception vector as input to a neural network, which performs identical operations on every cell in the grid. Using around ~8,000 parameters, the neural network determines how each cell should change based on the information it has gathered. It’s here that the system evolves, with the cells adapting and responding to environmental changes.Learning process for Growing NCA, image by Mordvintsev et al. The Power of DifferentiabilityWhat makes this system truly powerful is its differentiability. Every operation, from perceiving the environment to updating its state, is fully differentiable. This means we can optimize the entire system through gradient descent, just like how neural networks learn from data. As a result, the system isn’t statically pre-defined with some arbitrary rules — it can actually learn to grow specific patterns or behaviors, making it a powerful tool for modeling complex systems.NCA Growing process, credit to While the individual components of the system (like Sobel filters and neural networks) are relatively simple, their combination creates something much more sophisticated. It’s a balance between simplicity and complexity, much like biological systems in nature, where local interactions lead to the emergence of surprising, intricate behaviors.This approach doesn’t just push the boundaries of what cellular automata can do, it opens up a world of possibilities for learning, growth, and pattern formation through local interactions alone. Whether you’re a researcher, a developer, or simply someone fascinated by the intersection of AI and complexity, there’s a lot to explore here. Other applications of Neural Cellular Automata include Image Segmentation , Image classification and many more. Recap - Differentiable Logic Gate NetworksWhat if we could take the basic building blocks of computation (logic gates like AND, OR, and XOR) and combine them in a learned fashion, to solve some task ? That's exactly what Deep Differentiable Logic Gate Networks (DLGNs) achieve, merging the efficiency of digital circuits with the power of machine learning. This approach, developed by Petersen et al. , opens up exciting possibilities, especially in resource-constrained environments like edge computing and embedded systems. Convolution Differentiable Logic Gate Network, image by Petersen et al.How Do Deep Differentiable Logic Gate Networks Work?Logic Gates as NeuronsAt their core, DLGNs use logic gates as their building blocks, instead of the traditional artificial neurons found in neural networks. Each node in this case is a logic gate, and instead of performing weighted sums and matrix multiplications, each gate performs simple operations like AND, OR, XOR, etc.The Architecture: The architecture of a DLGN is surprisingly simple:The network is composed of layers of gates. Each gate takes inputs from two gates in the previous layer, resulting in a naturally sparse network.The connections between gates are fixed; they are randomly initialized but do not change during training. The learning process determines what each gate does, not the connections between gates.During inference, each gate performs one simple binary operation (think AND or OR) based on the operation it learned. The Learning Process: Making Discrete Operations DifferentiableInstead of learning weights as traditional neural networks do, this network learns which logic operation each gate should perform. During training, each node solves a classification task to identify the correct gate to use in order to minimize the objective function.The challenge is that logic gates are inherently discrete and non-differentiable, making them unsuitable for gradient-based learning. So how do we make them learn? Through two key tricks:Continuous Logic OperationsDuring training, each logic operation is replaced by a continuous relaxation, which is a differentiable version that operates on continuous values between 0 and 1. For example, instead of a hard AND gate that only accepts 0 or 1, we use a soft AND gate that can handle values between 0 and 1 as inputs, and passes a continuous mix of the two inputs as its output. These continuous relaxations (listed below) allow us to train the network using gradient descent.Probabilistic Gate SelectionEach gate maintains a probability distribution over the 16 possible binary operations for two inputs. This distribution is represented by a 16-dimensional parameter vector, which is then transformed into a probability distribution using softmax. The values of the 16-dimensional vector are modified during the training process: over time, the gate learns to prefer one operation over others.IndexOperationContinuous RelaxationSymbol0FALSE01ANDa * b2A AND (NOT B)a - a*b3Aa4(NOT A) AND Bb - a*b5Bb6XORa + b - 2a*b7ORa + b - a*b8NOR1 - (a + b - a*b)9XNOR1 - (a + b - 2a*b)10NOT B1 - b11A OR (NOT B)1 - b + a*b12NOT A1 - a13(NOT A) OR B1 - a + a*b14NAND1 - a*b15TRUE1During training, the network uses the continuous relaxations of the logic operations, but once the network is trained, we switch to pure binary operations for lightning-fast inference.Sketch illustrating the training of a single GateTo facilitate training stability, the initial distribution of gates is biased toward the pass-through gate.Training: Learning the GatesThe training process follows a standard forward-backward pass:Forward PassThe input values propagate through the network.Each gate, given two inputs, computes the results of all 16 possible logic operations using their continuous relaxations.These results are weighted according to the gate’s probability distribution, and the weighted sum becomes the output of the gate.Backward PassThe network computes the gradients with respect to the probability distributions, which are then updated using gradient descent.Over time, each gate’s distribution becomes more squeezed and spontaneously converge on one operation, whether it’s AND, OR, XOR, or another.Inference: The Magic of Binary OperationsOnce training is complete, we can freeze the network. This means that each gate settles on its most probable operation, and the continuous versions of the logic operations are discarded. What’s left is a pure logic circuit that operates on binary values (0 or 1).This final form is incredibly efficient. When it’s time to deploy, the network runs using only binary operations, making it exceptionally fast on any hardware.Differentiable Logic Cellular AutomataThe integration of differentiable logic gate networks with neural cellular automata provides a solution for handling discrete states while maintaining differentiability. Let's explore this system in depth, examining how it differs from traditional Neural Cellular Automata, while highlighting their common principles and understanding the fundamental role of differentiable logic gates. We'll borrow the terminology of NCA stages, highlighting where our model differs.The Structure: A 2D Grid of binary, intelligent cellsAs with NCA, the system is built around a 2D grid of cells, where each cell's state is represented by an n-dimensional binary vector This binary state vector acts as the cell's working memory, storing information from previous iterations. Throughout this article, cell state and channels will be used interchangeably.The Two-Stage Update Mechanism: Perception and UpdateThe Perception StageIn cellular automata systems, each cell must be aware of its environment. While traditional NCA use Sobel filters to model this perception, DiffLogic CA takes a different approach, following . Each kernel is a distinct circuit, where connections are fixed with a particular structure, but the gates are learned. The kernels are computed channel-wise. Each circuit employs four layers whose connections are designed to compute interactions between the central cell and its neighboring cells as in the figure on the right. The output dimension is the number of kernels multiplied by the number of channels. Alternative approaches involve kernels with multiple bits of output per channel, rather than only one, improving convergence in some cases.Each kernel operates channel-wise and computes the interaction between the central cell and its neighbors, emulating the CA's interaction within the Moore neighborhood. This 3x3 patch shows a state dimension of 3. The circuit is wired to process interactions between the central cell and its surrounding cells. The first layer has 8 gates, with each gate taking the central cell as its first input and a neighboring cell as its second input.The Update StageThe update mechanism follows the NCA paradigm, but employs a Differentiable Logic Network to compute each cell's new state. The network's connections can be either randomly initialized or specifically structured to ensure all inputs are included in the computation. The updated state is determined by applying a Differentiable Logic Gate Network to the concatenation of the cell's previous memory (represented in gray), and the information received from its neighbors (represented in orange). In standard NCA, at this point, one would incrementally update the state, treating the whole system like an ODE. With DiffLogic CAs, we output the new state directly. A representation of the update step given a cell state of dimension 4 and 2 kernels.In summary: the perception phase uses a logic gate network to process the binary neighborhood states, replacing traditional convolution filter-based operations, and the update rule is implemented as another logic gate network that takes the perception output and current state as inputs, and outputs the next binary state of the cell.Schematic representation of a 4x4 DiffLogic CA grid. At each time step, each cell reads and processes the information stored in its neighboring cells' states and then updates its own stateThe diagram above schematically represents a 4x4 DiffLogic CA grid, each of the small squares is a tiny computer with a dual-memory system. We visualize these two registers as gray and orange, respectively. Every cell in our grid performs a two-step process, which we will later see can be either performed synchronously, or in some cases asynchronously: Step 1: The Perception PhaseFirst, every cell in our grid becomes a data gatherer. They examine their neighbors' gray registers, process what they observe, and store their results in their orange registers.Step 2: The Update PhaseRight after that, each cell becomes a decision maker. Using the information stored in both its registers (the original gray one and the newly filled orange one), the cell calculates its new state. This new state gets written to the gray register, while the orange register is cleared, ready for the next round of perception.The system behaves like a network of tiny, independent computers that communicate with their neighbors and make decisions based on their observations. Each cell is a miniature processor in a vast, interconnected grid, working together to perform complex computations through these simple local interactions. By combining local connections with distributed processing, we've built something that can tackle tasks exploiting the emergence of collective behavior. We again find strong kinship with the the work Programmable Matter and Computronium by Toffoli and Margolus, who proposed the CAM-8 , a computer architecture based on cellular automata which is similar to the system above where each cell uses a DRAM chips for state variables and an SRAM for processing.Cam-8 architecture and image from from Margolus et al.Experiment 1: Learning Game of LifeConway's Game of Life is a fascinating mathematical simulation that demonstrates how complex patterns can emerge from simple rules. Created by mathematician John Conway in 1970, this game isn't played in the traditional sense - it's a cellular automaton where cells on a grid live or die based on just four basic rules. Despite its simplicity, the Game of Life can produce amazing behaviors, from stable structures to dynamic patterns that seem to take on a life of their own.Simulation of Conway's Game of LifeThe rules of the game are elegantly simple, focusing on how each cell interacts with its eight neighboring cells:Birth: A dead cell (whose current value is 0) with exactly three living neighbors springs to life in the next generation, as if by reproduction.Survival: A living cell (whose current value is 1) with either two or three living neighbors survives to the next generation, representing a balanced environment.Underpopulation: A living cell with fewer than two living neighbors dies from isolation in the next generation.Overpopulation: A living cell with more than three living neighbors dies from overcrowding in the next generation.These four rules, applied simultaneously to every cell in the grid at each step, create a dance of patterns. From these basic interactions emerge complex behaviors: stable structures that never change, oscillators that pulse in regular patterns, and even gliders that appear to move across the grid. It's this emergence of complexity from simplicity that has made the Game of Life a powerful metaphor for self-organization in natural systems, from biological evolution to the formation of galaxies.Given its binary and dynamic nature, Game of Life is a good sanity check of the DiffLogic CA. State and ParametersGiven that we know the rules are independent of previous state iterations, we consider a cell state consisting of 1 bit, meaning the system is essentially memory-less. The model architecture includes 16 perception circuit-kernels, each of them with the same structure of nodes [8, 4, 2, 1]. The update network instead has 23 layers: first 16 layers have 128 nodes each, and the subsequent layers have [64, 32, 16, 8, 4, 2, 1] nodes, respectively.Loss functionThe loss function is computed by summing the squared differences between the predicted grid and the ground truth grid.∑i,jN(yi,j−y~i,j)2\\sum_{i,j}^N(y_{i,j} - \\tilde{y}_{i,j})^2 Training DatasetThe model was trained on 3x3 periodic grids for a single time step. Given that each cell in the Game of Life interacts with its eight neighbors, and its next state is determined by its current state and the states of its neighbors, there are 512 possible unique configurations for a 3x3 grid. To train the model, we constructed a grid including all 512 possible grid configurations. Learning the next state of grid correctly implies learning the complete Game of Life rule set. The trained parameters were subsequently used to simulate the model's behavior on larger grids.ResultsOn the left, you can observe the loss plot comparing the two representations of logic gates. The soft loss computes the output of the gates using their continuous approximation as explained in the previous section, while the hard loss selects only the most probable gate and uses its discrete output. Both losses fully converge, indicating that we were able to generate a circuit that perfectly simulates the Game of Life.Using hard inference (selecting most probable gates), the simulation on the right displays the learned circuit's performance on a larger grid. The emergent patterns capture the structures from Conway's Game of Life: gliders moving across the grid, stable blocks remaining fixed in place, and classic structures like loaves and boats maintaining their distinctive shapes. The successful replication of Game of Life's characteristic patterns demonstrates that our circuit has effectively learned the underlying local rules.Training plot for DiffLogic CA learning Game of LifeGame of Life simulated by the learned circuitAnalysis of the Generated Circuit While circuit optimization is not the primary focus of this project, this section provides a brief analysis of the generated circuit.The total number of active gates used (excluding the pass-through gates A and B), is 336. Examining the gate distributions, we observe that the most frequently used gates in both networks are OR and AND.Since our final circuit is simply a series of binary gates, we can step even deeper and visualize the entirety of the circuit logic involved! Below is a visualization of most of these 336 gates (some gates are pruned, when we determine they don’t contribute to the output). Complete learned perceive-update circuit implementing Game of Life (available interactively)The squares arranged in a three-by-three grid on the left are the input gates, arranged as they would be when viewed from the perspective of a single, central, cell somewhere in the game of life. The wires are colored green when high (1), and red when low (0). Finally, each gate should be somewhat self-explanatory, being one of AND, OR or XOR gates, with small circles on inputs or on outputs to denote NOTs on those particular connections. We've additionally replaced the binary NotB and NotA gates with a unary Not gate, and pruned the unused input, to simplify visualization. Finally, some gates are simply “True” or “False”, and these look almost identical to the inputs, appearing as nested squares, either filled in (True) or empty (False). On the far right, we see the single output channel of this circuit - denoting the new state of the cell in the Game of Life. In this particular configuration in the figure, we see the circuit correctly computing the rule “Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.”We encourage readers to directly interact with the circuit.Experiment 2: Pattern GenerationNeural Cellular Automata (NCA) have shown remarkable capabilities in pattern generation tasks , inspiring us to explore similar capabilities with diffLogic CA. In this task, the system evolves from a random initial state toward a target image, allowing multiple steps of computation. By evaluating the loss function only at the final time-step, we challenge the model to discover the discrete transition rules that guide the system through a coherent sequence of states without step-by-step supervision. Successfully learning to reconstruct images would validate two key aspects: the model's ability to develop meaningful long-term dynamics through learned rules, and its capability to effectively learn stateful, recurrent-in-time, recurrent-in-space circuits. This investigation is particularly significant as it represents, according to the best of our knowledge, the first exploration of differentiable logic gate networks in a recurrent setting.State and ParametersWe consider a cell state (channels) of 8 bits and iterate the DiffLogic CA for 20 steps. The model architecture includes 16 perception circuit-kernels, each with 8, 4, then 2 gates per layer, respectively. The update network has 16 layers: 10 layers with 256 gates each, and then layers with [128, 64, 32, 16, 8, 8] gates, respectively. Loss functionWe define the loss function as the sum of the squared differences between the first channel in the predicted grid and the target grid at the last time step.∑i,jN(yi,j,0−y~i,j,0)2\\sum_{i,j}^N(y_{i,j,0} - \\tilde{y}_{i,j,0})^2 Training DatasetThe model was trained to reconstruct a 16x16 checkerboard pattern within 20 time steps. For each training step, the initial state was randomly sampled. The target checkerboard pattern is shown on the right.Target patternResultsThe DiffLogic CA fully converges to the target pattern. The training plot (left) reveals consistent convergence of both soft and hard loss functions. The evolution of the first channel (right), which is used for computing the loss function, shows clear pattern formation. An intriguing emergent property is the directional propagation of patterns from bottom-left to top-right, despite the model having no built-in directional bias.Training plot for DiffLogic CAEvolution of the diffLogic CA, only considering the first bit in the cell state. Analysis of the Generated CircuitThe total number of active gates used (excluding pass-through gates A and B) is 22. Analysis of the learned logic gates reveals a different distribution of gates between the perception kernels and update networks. The TRUE gate appears to play a key role in perception but not in the update one. Distribution of gate counts across all perception kernel circuitsDistribution of gate counts across the update circuit.Below, we provide an interactive visualization of the circuit, after pruning. Remarkably, we are left with just six gates - one of which is redundant - an AND between the same input. In other words; the entirety of the procedural checkerboard-generation function learned by the circuit can be implemented using just five logic gates. Likewise, most of the inputs and outputs remain unused. Even more remarkably, the cell's own current visual output isn't even considered in an update step. We encourage readers to interact with the circuit below , clicking on and off inputs on the left to observe the effect on the outputs. Complete learned perceive-update circuit generating checkerboard, interactive How general is the solution? To the naked eye, our solution appears to build the grid iteratively—brick by brick, as it were. However, during training, we only employed one fixed size of the grid. Naturally, we should investigate what happens if we change the grid size: is the rule we learned truly an iterative, procedural solution, or is it overfit to one particular grid size? Let's scale up both the spatial and temporal dimensions by a factor of four—using a grid four times larger and running it for four times as many steps.Generalization Test: Learned Rules Applied to 4x Larger GridSuccess! The circuit works just as well in this new setting. This raises an interesting question as to the inductive biases of this model. In the NCA setting, it was possible to coax behavior invariant to grid size and time, but this required either special spatially invariant loss functions , and in the case of the growing lizard a special \"alive/dead\" regime to prevent overfitting to boundary conditions. Here, our boundary conditions are also fixed, yet the model has learned a \"boundary-size-invariant\" way to produce the pattern. Could the discretization and minimal circuit size be finding some minimal procedural description for generating patterns of interest? Given our setting, we tested the system's resilience to damage and its recovery capabilities through two experiments. In the first test (left), we evaluated pattern reconstruction when a large portion of cells were permanently disabled, simulating faulty components. In the second test (right), the disabled cells were reactivated after a set number of steps. The system demonstrated robust behavior in both scenarios: maintaining pattern integrity despite permanent cell damage in the first case, and successfully self-repairing to produce the correct pattern once damaged cells came back online in the second case.DiffLogic CA as new paradigm for robust computing Robust computing represents a fundamental shift in system design, prioritizing reliable operation under real-world conditions. In contrast to traditional computing, which relies on precise, error-free components, robust systems are designed to remain functional even in the face of hardware failures, environmental interference, unexpected inputs, or manufacturing variations. While contemporary computing, especially distributed computing, has some affordances around robustness to certain types of failures, it's generally still far more brittle than any similarly complex system in the natural world, and those affordances are usually designed around very specific failure cases that we are unable to control for by other means (think cosmic ray-induced bit flips in RAM). In the example reported above, we observed how the DiffLogic CA learned rules that exhibit both fault tolerance and self-healing behavior, without explicitly designing around these conditions. When some cells fail, the damage is contained, and the system continues to function with a gradual decline rather than experiencing catastrophic failure. This mirrors how biological systems achieve reliability through networks of imperfect components, suggesting a powerful approach for future computing systems that can maintain functionality even under imperfect conditions.Asynchronicity Inspired by the approach used in traditional NCA training , we explored asynchronous updates. Instead of updating all cells simultaneously (which can be likened to a global clock), we randomly select a subset of cells to update in each step. This simulates a scenario where each cell operates with its own internal clock. Within this framework, each cell can be conceptualized as a tiny computational unit operating independently of other cells, making its own decisions.We proceeded directly to introducing asynchronicity to training, expecting this to be markedly more difficult than in traditional NCAs. Firstly, the updates at every step must output the full new state, and not just an incremental update. Secondly, a cell must now be able to account for surrounding cells being in any combination of desynchronization. Any given neighbour could be one, two, three, or more steps \"behind\" or \"ahead\". This combinatorially increases the possible transitions rules the cell has to effectively learn to deal with. To our surprise - successful asynchronous training was relatively easy to achieve in the simplest pattern - the checkerboard. Below, we demonstrate three different, unique, reconstructions of the pattern , all starting from the same initial state but with distinct random seeds to determine the cell update order. Despite the asynchronous nature of these updates and a more complex resulting update rule, the cells correctly reconstruct the target pattern in 50 steps, compared to the original 20.Asynchronous trained patterns.Furthermore, the learned circuit demonstrated generalization capabilities, exhibiting successful reconstruction on larger grids and resilience to errors - a self-healing checkerboard..Generalization with asynchronous trainingSelf-healing behaviour with asynchronous trainingThe biggest surprise came when sanity checking the original synchronously trained rule, but using asynchronous inference. It works! This is surprising and further speaks to the robustness of the circuit originally discovered. This unexpected success with asynchronous inference led us to hypothesize that models trained directly with asynchronous updates would exhibit even greater robustness. To test this, we randomly deactivate a 10x10 pixel square within the image domain at each inference time-step, as shown in the simulations below. The images hint at the difference in resilience to noise - the asynchronous cells recover from the damage slightly more quickly, while the synchronously trained rule appears to be more impacted. By measuring the error as the sum of the absolute difference between the target and reconstructed images, we found that asynchronous training improves robustness considering these perturbations. Errort=∑i,jN∣y−y~t∣Error_t = \\sum_{i,j}^N |y - \\tilde{y}_t| Experiment 3: Growing a LizardFor the next experiment, we tested DiffLogic CA's ability to learn arbitrary shapes by training it on the outline of a lizard, in an homage to the original NCA work. This involves more memorization than reproducing a highly-compressible regular pattern like the checkerboard. We use a cell state of 128 bits and iterate the DiffLogic CA for 12 steps. The model architecture includes four perception circuit-kernels with 8, 4, 2, and 1 gates at each layer, respectively. The update network has 10 layers: eight layers with 512 gates each, and then layers with [256, 128] nodes, respectively. Training DatasetWe trained the model to generate a 20x20 lizard pattern, in 12 time steps. Just as in NCA, the initial condition consists of a central seed to break symmetry, with periodic boundary conditions applied to the grid edges. We employed the same loss function previously used in the checkerboard experiment.Outline of a lizardResultsTo assess the model's generalization capabilities, we evaluated its performance on a larger 40x40 grid. The results demonstrate that the model successfully learned the growth pattern without exploiting boundary conditions.On the left, the plot shows the convergence of both the soft and hard losses to zero. On the right, the visualization illustrates the successful growth of the lizard within the larger grid.Loss function for the lizard. Growing Lizard with diffLogic CABelow, visualizations of the first 32 hidden states offer a glimpse into the internal dynamics of the model during the growth process.Visualization of the first 32 channels. Training DiffLogic CA to generate complex patterns presents significant optimization challenges. The process required extensive hyper-parameter tuning. Future improvements to both the model architecture and circuit topology could enhance convergence speed and stability, potentially reducing the need for such intensive hyper-parameter optimization.Analysis of the Generated CircuitA total of 577 active gates were used, excluding pass-through gates A and B.The perception kernels predominantly employed the TRUE gate, while the update circuit employed almost all available gates.Experiment 4: Learning the G with colors Previous experiments have primarily focused on effectively monochrome images, using the last channel for visualization purposes. Wanting to investigate more complex target states, we trained the model to generate a 16x16 \"colored\" image, over 15 steps. Using 64 channels per cell state, the model has four perception circuit-kernels, each with four three layers with 8, 4, and 2 gates, respectively. The update network architecture consists of 11 layers: 8 layers of 512 nodes each, and a final sequence of 3 layers with [256, 128, 64] nodes, respectively.Training DatasetThe model was trained to generate a 16x16 colored letter of the alphabet (that might be reminiscent to some), over 15 steps. The initial state is fully zero, without periodic boundary conditions. Following the convention used in standard NCA , the first three channels represent RGB color values. However, in our case, these values are constrained to a binary representation of 0s0s﻿ and 1s1s﻿, resulting in a palette of eight possible colors.Target PatternLoss functionThe loss function is defined as the sum of the squared differences between the predicted grid and the target grid at the final time-step, considering only the first three channels (0, 1, 2).∑i,jN(yi,j,0:3−y~i,j,0:3)2\\sum_{i,j}^N(y_{i,j,0:3} - \\tilde{y}_{i,j,0:3})^2 ResultsThe results demonstrate that the model successfully learns this colorful G. On the left, the loss function plots show the convergence of both the soft and hard losses. On the right, the reconstruction the colorful G in 15 steps is shown.Loss function for the colored G \"G\" being generated by learned circuitAnalysis of the Generated CircuitA total of 927 active gates were used (excluding pass-through gates A and B). Analysis of the learned logic gates revealed distinct distributions across perception and update networks. Notably, TRUE and FALSE gates were extensively employed in both networks, while the OR gate was the most prevalent in the update network. We note that this circuit was more complex than previous experiments, both in the difficulty of finding suitable hyperparameters and in size of the circuit.Summary and DiscussionThis work introduces DiffLogic CA, a novel NCA architecture and training regime, utilising a fully discrete cell state, updated using a learned, recurrent binary circuit. We replace the neural network components with Deep Differentiable Logic Networks, which bring the flexibility of differentiable training to discrete logic gates. The successful application of differentiable logic gates to cellular automata is demonstrated through two key results: replicating the rules of Conway's Game of Life and generating patterns via learned discrete dynamics. These findings highlights the significant potential of integrating discrete logic within the framework of neural cellular automata and prove that differentiable logic gate networks can be effectively learned in recurrent architectures. While the current model exhibits promising results in learning patterns, training it to generate more complex shapes and structures presents ongoing challenges. Potential directions for improvement include the exploration of hierarchical NCA architectures and the incorporation of specialized gates designed to facilitate state forgetting. For instance, integrating LSTM-like gating mechanisms into the state update process could enable a richer and diverse combination of past and newly computed candidate states, potentially enhancing the model's dynamics and expressiveness.AcknowledgmentsWe thank Blaise Aguera y Arcas for his support and the Paradigm of Intelligence Team for the fruitful and inspiring discussions. Many thanks to Marek Materzok, and the contributors to the excellent DigitalJS circuit visualization library, which was used to power all the interactive circuits in this article.",
  "image": "https://pietromiotti.github.io/diffLogicCA/images/card.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle id=\"17b0a320-00ae-80fd-b261-f8c156a456ad\" class=\"page\"\u003e\u003cheader\u003e\u003cp\u003eFrom Game of Life to pattern generation with learned recurrent circuits\u003c/p\u003e\u003c/header\u003e\u003cdiv\u003e\u003chr id=\"1a00a320-00ae-80de-a29e-dbb965692ffb\"/\u003e\u003cdiv id=\"1a00a320-00ae-80af-b579-fb795f51bafd\"\u003e\u003cp id=\"1a00a320-00ae-8011-b4ba-c28643baceb5\"\u003eAFFILIATIONS:\u003c/p\u003e\u003cp id=\"1a00a320-00ae-805b-85c7-f25884be9e9d\"\u003eGoogle, Paradigms of Intelligence Team\u003c/p\u003e\u003c/div\u003e\u003chr id=\"1a00a320-00ae-80bc-abd0-c2cdd760cf39\"/\u003e\u003cp id=\"1a00a320-00ae-80bb-a273-e899edfd6cf5\"\u003eImagine trying to reverse-engineer the complex, often unexpected patterns and behaviors that emerge from simple rules. This challenge has inspired researchers and enthusiasts that work with cellular automata for decades.  In cellular automata, we generally approach things from the bottom-up. We choose local rules, then investigate the resulting emergent patterns. What if we could create systems that, given some complex desired pattern, can, in a fully differentiable fashion, learn the local rules that generate it, while preserving the inherent discrete nature of cellular automata? This is what we\u0026#39;ll  explore with you today.\u003c/p\u003e\u003cdiv id=\"17c0a320-00ae-8050-84d9-eed83c749260\"\u003e\u003cdiv id=\"9f03a6f1-88e6-40f7-addb-635001c9dac0\"\u003e\u003cfigure id=\"17c0a320-00ae-8051-b45b-f1e017e41857\"\u003e\u003cfigcaption\u003eZoomed view of learned circuit\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"078f6020-e34b-49ff-ac61-550d1722c0df\"\u003e\u003cfigure id=\"17c0a320-00ae-80cd-a191-f479ea5492f4\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u0026#34;G\u0026#34; being generated by learned circuit\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"1910a320-00ae-80c4-a7d4-ee00e98e6b47\"\u003ePrior work has explored learning transition rules using non-differentiable techniques, demonstrating the feasibility of evolving local rules for specific computation\u003cd-cite key=\"Mitchell1994-mi\"\u003e\u003c/d-cite\u003e. Likewise prior exploration of making one-dimensional cellular automata differentiable exist\u003cd-cite key=\"Martin2017-dx\"\u003e\u003c/d-cite\u003e. We propose a novel, fully end-to-end differentiable approach, combining two interesting concepts from the world of artificial intelligence: Neural Cellular Automata (NCA) \u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e and Differentiable Logic Gates Networks \u003cd-cite key=\"Petersen2022-ai\"\u003e\u003c/d-cite\u003e\u003cd-cite key=\"Petersen2024-rr\"\u003e\u003c/d-cite\u003e. NCA exhibit the ability to learn arbitrary patterns and behaviors, however, they do not inherently operate within a discrete state space. This makes interpretability more challenging, and leaves them stuck in a regime where current hardware must perform costly matrix multiplications to gradually update their continuous internal states. Differentiable Logic Gates Networks, meanwhile, have been used to discover combinatorial logic circuits, blending discrete states with differentiable training signals. But they haven\u0026#39;t yet been shown to work  in recurrent settings. NCA, as it were, are recurrent in both space, and time.  Sounds intriguing, right?\u003c/p\u003e\u003cp id=\"17b0a320-00ae-80b3-8af8-f8d7b98ddb34\"\u003eZooming out, we believe the integration of differentiable logic gates and neural cellular automata is a potential step towards programmable matter - \u003cem\u003eComputronium\u003c/em\u003e  \u003cd-cite key=\"Amato1991-ck\"\u003e\u003c/d-cite\u003e - a theoretical physical substance capable of performing arbitrary computation. Toffoli and Margolus pioneered this direction with  CAM-8, a cellular automata based computing architecture \u003cd-cite key=\"Margolus1995-hg\"\u003e\u003c/d-cite\u003e\u003cd-cite key=\"Toffoli1991-do\"\u003e\u003c/d-cite\u003e, in theory capable of immense, horizontally scalable computation. However, they faced a fundamental challenge: actually crafting the local rules needed to achieve a desired macroscopic computation, with Amato et al. noting that “other researchers [...] still worry about the difficulty of finding local rules that correspond to real natural systems” \u003cd-cite key=\"Amato1991-ck\"\u003e\u003c/d-cite\u003e.  What if we could directly learn these local rules, and create models that combine binary logic, the flexibility of neural networks, and the local processing of cellular automata?  We believe our prototypes  offer a glimpse into the future of computing: learnable, local, and discrete.\u003c/p\u003e\u003cp id=\"17b0a320-00ae-8046-8ed4-e7cb4deb6da4\"\u003eThis article will walk you through implementing cellular automata using differentiable logic gates, and demonstrate some key results along the way.\u003c/p\u003e\u003cp id=\"1820a320-00ae-8036-b527-f6da83547f0a\"\u003eWe\u0026#39;re faced with two fundamental questions.\u003cem\u003e                                      \u003c/em\u003e \u003c/p\u003e\u003cfigure id=\"1820a320-00ae-800f-a24a-ec0ee8f611ec\"\u003e\u003cp\u003e\u003cspan\u003e❓\u003c/span\u003e\u003c/p\u003e\u003cp id=\"1820a320-00ae-80b1-9312-cf2feaaf9f38\"\u003e\u003cem\u003eCan a Differentiable Logic CA learn at all?   \u003c/em\u003e\u003c/p\u003e\u003c/figure\u003e\u003cp id=\"1820a320-00ae-804b-bef7-d0f44f912fad\"\u003eTo answer this, we\u0026#39;ll start by attacking Conway\u0026#39;s Game of Life - perhaps the most iconic cellular automata,  having captivated researchers for decades. While this first experiment might seem overly simplistic (functionally equivalent to learning a truth table), it will prove the basic learning capability of our setup. The more profound question follows: \u003c/p\u003e\u003cfigure id=\"1820a320-00ae-806a-8d96-d17225e588f1\"\u003e\u003cp\u003e\u003cspan\u003e❓\u003c/span\u003e\u003c/p\u003e\u003cp id=\"1820a320-00ae-8061-9b8f-c36fa2937fc1\"\u003e\u003cem\u003eCan recurrent-in-space and recurrent-in-time circuits learn complex patterns similar to those generated by traditional NCAs? \u003c/em\u003e\u003c/p\u003e\u003c/figure\u003e\u003cp id=\"1990a320-00ae-804e-a1ae-fd0f1eca6c2c\"\u003eWhile both Differentiable Logic Gate Networks and Neural Cellular Automata (NCAs) have demonstrated trainability, effectively training circuits that exhibit both temporal and spatial recurrence of NCA, within the framework of differentiable logic, remains unexplored. \u003c/p\u003e\u003cp id=\"1990a320-00ae-80ec-830f-c68734ecb12e\"\u003eThe second experiment will demonstrate the model\u0026#39;s ability to learn recurrent circuits that generate complex patterns similar to the ones generated by traditional NCA. \u003c/p\u003e\u003ch2 id=\"17b0a320-00ae-80e7-8662-c6ca0699315a\"\u003eRecap - Neural Cellular Automata\u003c/h2\u003e\u003cp id=\"17b0a320-00ae-8094-8353-cbf1959b13bb\"\u003eAt the heart of this project lies Neural Cellular Automata (NCA), a synthesis of classical cellular automata with modern deep learning techniques. This powerful paradigm, pioneered by Mordvintsev et al. \u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e, represents a fundamental shift in how we think about computational systems that can grow, adapt, and self-organize.\u003c/p\u003e\u003cp id=\"17b0a320-00ae-8058-837d-d64466738811\"\u003eTraditional cellular automata have long captivated researchers with their ability to generate complex behaviors from simple, local rules. Neural Cellular Automata take this concept further by making these rules learnable through gradient descent. Instead of hand-designing update rules, the system discovers them automatically, opening up entirely new possibilities for self-organizing computational systems.\u003c/p\u003e\u003cp id=\"17b0a320-00ae-80ce-a251-c52dd6986d31\"\u003eWhat makes this approach particularly elegant is how it preserves the core principles of cellular automata - locality, parallelism, and state-based computation - while introducing the adaptability of neural networks. \u003c/p\u003e\u003cp id=\"17b0a320-00ae-802b-b083-ddbd44add2b7\"\u003eIn the following sections, we will summarize the main concepts from the “\u003cstrong\u003eGrowing Neural Cellular Automata”\u003c/strong\u003e work \u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e, which presents a Neural Cellular Automata developed for morphogenesis. If you are already familiar with it, feel free to skip it.\u003c/p\u003e\u003ch3 id=\"17b0a320-00ae-8015-91a4-e90b65fe9a6c\"\u003eThe Structure: A 2D Grid of Intelligent Cells\u003c/h3\u003e\u003cp id=\"17b0a320-00ae-80ef-923a-d9cc324efe92\"\u003eAt the heart of the system is a 2D grid, much like classic cellular automata. Each cell contains an \u003cstrong\u003en-dimensional vector\u003c/strong\u003e of information which is called the cell\u0026#39;s \u003cstrong\u003estate (or channels)\u003c/strong\u003e and for the specific case of Growing-NCA it is composed by these elements:\u003c/p\u003e\u003cul id=\"17b0a320-00ae-8070-92fb-c1b3f696df56\"\u003e\u003cli\u003e\u003cstrong\u003eRGB Colors\u003c/strong\u003e (3 channels): These represent the visible properties of the cell, essentially its color.\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-80ab-bdc9-f15b1fe22d1d\"\u003e\u003cli\u003e\u003cstrong\u003eAlpha (α) Channel\u003c/strong\u003e (1 channel): This indicates cell vitality. If the alpha value is greater than 0.1, the cell is considered “alive.”\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-8001-88e8-eb07b7d7db40\"\u003e\u003cli\u003e\u003cstrong\u003eHidden Channels\u003c/strong\u003e (n minus 4 channels): These allow cells to communicate more complex information about their environment, making interactions richer and more dynamic.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"17b0a320-00ae-8053-886b-ddf0aadc026e\"\u003eBut the magic doesn’t stop here. What really sets this system apart is how the cells interact and evolve through a two-stage process.\u003c/p\u003e\u003ch3 id=\"17b0a320-00ae-80cb-9108-d89841539c77\"\u003eThe Two-Stage Update Mechanism: Perception and Update\u003c/h3\u003e\u003col type=\"1\" id=\"17b0a320-00ae-804c-a4a8-d1b14e54e541\" start=\"1\"\u003e\u003cli\u003e\u003cstrong\u003eThe Perception Stage\u003c/strong\u003e\u003cp id=\"17b0a320-00ae-80db-bdc0-f7258a4a6278\"\u003eIn the first stage, each cell perceives its environment. Think of it as a cell sensing the world around it. To do this, it uses \u003cstrong\u003eSobel filters\u003c/strong\u003e, mathematical tools designed to numerically approximate spatial gradients - \u0026#34;changes across its surroundings\u0026#34;. The filters are applied channel-wise, and the result is termed the \u003cstrong\u003eperception vector\u003c/strong\u003e, which combines the cell’s current state with the information it gathers about its environment. A bit like how biological cells use chemical gradients to sense and react to their surroundings.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17b0a320-00ae-8088-acd2-c653be5101a3\" start=\"2\"\u003e\u003cli\u003e\u003cstrong\u003eThe Update Stage\u003c/strong\u003e\u003cp id=\"17b0a320-00ae-80de-9206-f48a8894d617\"\u003eNext, the neural network steps in. Each cell uses its perception vector as input to a neural network, which performs identical operations on every cell in the grid. Using around ~\u003cstrong\u003e8,000 parameters\u003c/strong\u003e, the neural network determines how each cell should change based on the information it has gathered. It’s here that the system evolves, with the cells adapting and responding to environmental changes.\u003c/p\u003e\u003cfigure id=\"17b0a320-00ae-8098-80a0-e69315e4c00b\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/model.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/model.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eLearning process for Growing NCA, image by Mordvintsev et al.\u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e \u003c/figcaption\u003e\u003c/figure\u003e\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"17b0a320-00ae-80d5-9c81-ca1b38c6eef5\"\u003eThe Power of Differentiability\u003c/h3\u003e\u003cp id=\"17b0a320-00ae-803f-b0f6-e2eb73004110\"\u003eWhat makes this system truly powerful is its \u003cstrong\u003edifferentiability\u003c/strong\u003e. Every operation, from perceiving the environment to updating its state, is fully differentiable. This means we can optimize the entire system through \u003cstrong\u003egradient descent\u003c/strong\u003e, just like how neural networks learn from data. As a result, the system isn’t statically pre-defined with some arbitrary rules — it can actually \u003cstrong\u003elearn\u003c/strong\u003e to grow specific patterns or behaviors, making it a powerful tool for modeling complex systems.\u003c/p\u003e\u003cfigure id=\"1910a320-00ae-8027-a1a6-db5e3610fa63\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/regen2.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/regen2.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eNCA Growing process, credit to \u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e \u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"17b0a320-00ae-80c0-98fe-e15f2925d588\"\u003eWhile the individual components of the system (like Sobel filters and neural networks) are relatively simple, their combination creates something much more sophisticated. It’s a balance between simplicity and complexity, much like biological systems in nature, where local interactions lead to the emergence of surprising, intricate behaviors.\u003c/p\u003e\u003cp id=\"17b0a320-00ae-8054-80ce-d80770602c35\"\u003eThis approach doesn’t just push the boundaries of what cellular automata can do, it opens up a world of possibilities for learning, growth, and pattern formation through local interactions alone. Whether you’re a researcher, a developer, or simply someone fascinated by the intersection of AI and complexity, there’s a lot to explore here.  \u003c/p\u003e\u003cp id=\"17b0a320-00ae-800a-87f3-f2bfda7a56e3\"\u003eOther applications of Neural Cellular Automata include Image Segmentation \u003cd-cite key=\"Sandler2020-nx\"\u003e\u003c/d-cite\u003e, Image classification \u003cd-cite key=\"Randazzo2020-mh\"\u003e\u003c/d-cite\u003e and many more. \u003c/p\u003e\u003cdiv id=\"17c0a320-00ae-8082-9fe2-d7ba3a948c55\"\u003e\u003cp id=\"d21df3d1-8bd1-4991-a135-4d7a1ff782ee\"\u003e\u003ch2 id=\"3c1f6714-1e60-4811-a242-1890db2faa19\"\u003eRecap - Differentiable Logic Gate Networks\u003c/h2\u003e\u003c/p\u003e\u003c/div\u003e\u003cp id=\"17b0a320-00ae-8032-afd2-d1679ae2ad41\"\u003eWhat if we could take the basic building blocks of computation (logic gates like AND, OR, and XOR) and combine them in a learned fashion, to solve some task ? That\u0026#39;s exactly what \u003cstrong\u003eDeep Differentiable Logic Gate Networks\u003c/strong\u003e (DLGNs) achieve, merging the efficiency of digital circuits with the power of machine learning. This approach, developed by Petersen et al. \u003cd-cite key=\"Petersen2022-ai\"\u003e\u003c/d-cite\u003e\u003cd-cite key=\"Petersen2024-rr\"\u003e\u003c/d-cite\u003e, opens up exciting possibilities, especially in resource-constrained environments like edge computing and embedded systems. \u003c/p\u003e\u003cfigure id=\"17c0a320-00ae-80e3-9e65-fe8301c314b1\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/diffLogicGateNetwork.png\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/diffLogicGateNetwork.png\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eConvolution Differentiable Logic Gate Network, image by Petersen et al.\u003cd-cite key=\"Petersen2024-rr\"\u003e\u003c/d-cite\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"17b0a320-00ae-80a9-8959-fd52f3a68f89\"\u003e\u003cstrong\u003eHow Do Deep Differentiable Logic Gate Networks Work?\u003c/strong\u003e\u003c/h3\u003e\u003ch3 id=\"17b0a320-00ae-803b-ab43-df550941a8e8\"\u003e\u003cstrong\u003eLogic Gates as Neurons\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17b0a320-00ae-807a-ada3-f42de63afc1d\"\u003eAt their core, DLGNs use \u003cstrong\u003elogic gates\u003c/strong\u003e as their building blocks, instead of the traditional artificial neurons found in neural networks. Each node in this case is a logic gate, and instead of performing weighted sums and matrix multiplications, each gate performs simple operations like \u003cstrong\u003eAND, OR, XOR\u003c/strong\u003e, etc.\u003c/p\u003e\u003ch3 id=\"17b0a320-00ae-80fd-b4a9-d40ad5d9e6dc\"\u003e\u003cstrong\u003eThe Architecture: \u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17b0a320-00ae-802a-9d09-ea4fc259be20\"\u003eThe architecture of a DLGN is surprisingly simple:\u003c/p\u003e\u003cul id=\"17b0a320-00ae-80e0-88e6-f540f2557e3c\"\u003e\u003cli\u003eThe network is composed of \u003cstrong\u003elayers of gates\u003c/strong\u003e. Each gate takes inputs from two gates in the previous layer, resulting in a naturally \u003cstrong\u003esparse \u003c/strong\u003enetwork.\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-8051-9e01-d3a37f22065d\"\u003e\u003cli\u003eThe \u003cstrong\u003econnections\u003c/strong\u003e between gates are \u003cstrong\u003efixed\u003c/strong\u003e; they are randomly initialized but do not change during training. The learning process determines what each gate does, not the connections between gates.\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-80a2-98b4-d4d6224c522e\"\u003e\u003cli\u003e\u003cstrong\u003eDuring inference\u003c/strong\u003e, each gate performs one simple binary operation (think AND or OR) based on the operation it learned. \u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"17b0a320-00ae-80ea-8efd-f37c705c5ee8\"\u003e\u003cstrong\u003eThe Learning Process: Making Discrete Operations Differentiable\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-8005-a9e7-d933d0ca3d1a\"\u003eInstead of learning weights as traditional neural networks do, this network \u003cstrong\u003elearns which logic operation each gate should perform\u003c/strong\u003e. During training, each node solves a classification task to identify the correct gate to use in order to minimize the objective function.\u003c/p\u003e\u003cp id=\"1a00a320-00ae-8075-958f-fad7dc45a4ba\"\u003eThe challenge is that logic gates are inherently \u003cstrong\u003ediscrete\u003c/strong\u003e and \u003cstrong\u003enon-differentiable\u003c/strong\u003e, making them unsuitable for gradient-based learning. So how do we make them learn? Through two key tricks:\u003c/p\u003e\u003col type=\"1\" id=\"17b0a320-00ae-80cc-b278-ca1bb0950836\" start=\"1\"\u003e\u003cli\u003e\u003cstrong\u003eContinuous Logic Operations\u003c/strong\u003e\u003cp id=\"17b0a320-00ae-8006-99e9-e4703974fd0c\"\u003eDuring training, each logic operation is replaced by a continuous relaxation, which is a \u003cstrong\u003edifferentiable version\u003c/strong\u003e that operates on continuous values between 0 and 1. For example, instead of a \u003cem\u003ehard\u003c/em\u003e AND gate that only accepts 0 or 1, we use a \u003cem\u003esoft\u003c/em\u003e AND gate that can handle values between 0 and 1 as inputs, and passes a continuous mix of the two inputs as its output. These continuous relaxations (listed below) allow us to train the network using \u003cstrong\u003egradient descent.\u003c/strong\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17b0a320-00ae-8058-bcc0-e1969485202e\" start=\"2\"\u003e\u003cli\u003e\u003cstrong\u003eProbabilistic Gate Selection\u003c/strong\u003e\u003cp id=\"17b0a320-00ae-8038-aecd-d59a11a90eb6\"\u003eEach gate maintains a \u003cstrong\u003eprobability distribution\u003c/strong\u003e over the 16 possible binary operations for two inputs. This distribution is represented by a 16-dimensional parameter vector, which is then transformed into a probability distribution using \u003cem\u003esoftmax\u003c/em\u003e. The values of the 16-dimensional vector are modified during the training process: over time, the gate \u003cem\u003elearns\u003c/em\u003e to prefer one operation over others.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003ctable id=\"17c0a320-00ae-807b-96a5-fc5da4beace8\"\u003e\u003ctbody\u003e\u003ctr id=\"17c0a320-00ae-8019-b393-cb5454de12fe\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003eIndex\u003c/td\u003e\u003ctd id=\"AewD\"\u003eOperation\u003c/td\u003e\u003ctd id=\"yM_;\"\u003eContinuous Relaxation\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003eSymbol\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-8051-a8a6-ea87f18d390e\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e0\u003c/td\u003e\u003ctd id=\"AewD\"\u003eFALSE\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e0\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/FALSE.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80fc-bd4d-efa3309483f2\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e1\u003c/td\u003e\u003ctd id=\"AewD\"\u003eAND\u003c/td\u003e\u003ctd id=\"yM_;\"\u003ea * b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/AND.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80be-bc07-e0ee2bce83cb\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e2\u003c/td\u003e\u003ctd id=\"AewD\"\u003eA AND (NOT B)\u003c/td\u003e\u003ctd id=\"yM_;\"\u003ea - a*b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/AANDNOTB.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-8025-9ee0-fea1a0311050\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e3\u003c/td\u003e\u003ctd id=\"AewD\"\u003eA\u003c/td\u003e\u003ctd id=\"yM_;\"\u003ea\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/A.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80f8-b4de-dec5453e190f\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e4\u003c/td\u003e\u003ctd id=\"AewD\"\u003e(NOT A) AND B\u003c/td\u003e\u003ctd id=\"yM_;\"\u003eb - a*b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/NOTAANDB.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-802e-8c3f-f80d00c69053\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e5\u003c/td\u003e\u003ctd id=\"AewD\"\u003eB\u003c/td\u003e\u003ctd id=\"yM_;\"\u003eb\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/B.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80f5-9a84-ed1adc3a7614\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e6\u003c/td\u003e\u003ctd id=\"AewD\"\u003eXOR\u003c/td\u003e\u003ctd id=\"yM_;\"\u003ea + b - 2a\u003cem\u003e*\u003c/em\u003eb\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/XOR.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80bd-a29f-ea6d14a536c7\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e7\u003c/td\u003e\u003ctd id=\"AewD\"\u003eOR\u003c/td\u003e\u003ctd id=\"yM_;\"\u003ea + b - a*b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/OR.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80eb-b6f9-e952034333bc\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e8\u003c/td\u003e\u003ctd id=\"AewD\"\u003eNOR\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - (a + b - a*b)\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/NOR.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-802f-a05e-ea21aded15f3\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e9\u003c/td\u003e\u003ctd id=\"AewD\"\u003eXNOR\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - (a + b - 2a*b)\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/XNOR.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80b3-a49c-ebe99a8723f6\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e10\u003c/td\u003e\u003ctd id=\"AewD\"\u003eNOT B\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/NOTB.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80f8-9123-def2f0786f18\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e11\u003c/td\u003e\u003ctd id=\"AewD\"\u003eA OR (NOT B)\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - b + a*b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/AORNOTB.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-8045-9de1-cfd5a5c32556\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e12\u003c/td\u003e\u003ctd id=\"AewD\"\u003eNOT A\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - a\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/NOTA.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80dc-970c-c24859f19813\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e13\u003c/td\u003e\u003ctd id=\"AewD\"\u003e(NOT A) OR B\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - a + a*b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/NOTAORB.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-8048-aa3f-f188631922c8\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e14\u003c/td\u003e\u003ctd id=\"AewD\"\u003eNAND\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1 - a*b\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/NAND.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr id=\"17c0a320-00ae-80d2-8d65-ec7ff8d46314\"\u003e\u003ctd id=\"\u0026gt;zdq\"\u003e15\u003c/td\u003e\u003ctd id=\"AewD\"\u003eTRUE\u003c/td\u003e\u003ctd id=\"yM_;\"\u003e1\u003c/td\u003e\u003ctd id=\"i\u0026gt;w[\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/TRUE.png\"/\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003cp id=\"17c0a320-00ae-8070-b380-c442ec22ce0a\"\u003eDuring \u003cstrong\u003etraining\u003c/strong\u003e, the network uses the continuous relaxations of the logic operations, but once the network is trained, we switch to \u003cstrong\u003epure binary operations\u003c/strong\u003e for lightning-fast inference.\u003c/p\u003e\u003cdiv\u003e\u003cfigure id=\"17c0a320-00ae-807d-a43c-f2e551e9acf8\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/ed21e753-3109-4d2d-9df2-9c4d7a037e61.png\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/ed21e753-3109-4d2d-9df2-9c4d7a037e61.png\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eSketch illustrating the training of a single Gate\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp id=\"17b0a320-00ae-80d2-8e9c-c28c10d4b78e\"\u003eTo facilitate training stability, the initial distribution of gates is biased toward the \u003cem\u003epass-through\u003c/em\u003e gate.\u003c/p\u003e\u003ch3 id=\"17b0a320-00ae-801d-a985-f6758054bec4\"\u003e\u003cstrong\u003eTraining: \u003c/strong\u003e\u003cstrong\u003eL\u003c/strong\u003e\u003cstrong\u003eearning the Gates\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17b0a320-00ae-80c1-864f-fa24481561eb\"\u003eThe training process follows a standard forward-backward pass:\u003c/p\u003e\u003col type=\"1\" id=\"17b0a320-00ae-80f4-9cbb-f210c1ed6a82\" start=\"1\"\u003e\u003cli\u003e\u003cstrong\u003eForward Pass\u003c/strong\u003e\u003cul id=\"17b0a320-00ae-8081-8f58-ee7638036e4c\"\u003e\u003cli\u003eThe input values propagate through the network.\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-80bd-8e52-cf1e8133140f\"\u003e\u003cli\u003eEach gate, given two inputs, computes the results of all 16 possible logic operations using their continuous relaxations.\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-803a-94f0-e1c705058759\"\u003e\u003cli\u003eThese results are weighted according to the gate’s probability distribution, and the \u003cstrong\u003eweighted sum\u003c/strong\u003e becomes the output of the gate.\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17b0a320-00ae-8061-b44d-f961bceae50a\" start=\"2\"\u003e\u003cli\u003e\u003cstrong\u003eBackward Pass\u003c/strong\u003e\u003cul id=\"17b0a320-00ae-80d2-8ffe-e3e960d4d715\"\u003e\u003cli\u003eThe network computes the \u003cstrong\u003egradients\u003c/strong\u003e with respect to the probability distributions, which are then updated using \u003cstrong\u003egradient descent\u003c/strong\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cul id=\"17b0a320-00ae-8050-aed2-d26278b130aa\"\u003e\u003cli\u003eOver time, each gate’s distribution becomes more squeezed and spontaneously converge on one operation, whether it’s AND, OR, XOR, or another.\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"17b0a320-00ae-8043-8fec-f86cfb47debb\"\u003e\u003cstrong\u003eInference: The Magic of Binary Operations\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17b0a320-00ae-80c9-a69a-d6e102d0e685\"\u003eOnce training is complete, we can freeze the network. This means that each gate \u003cstrong\u003esettles on its most probable operation\u003c/strong\u003e, and the continuous versions of the logic operations are discarded. What’s left is a \u003cstrong\u003epure logic circuit\u003c/strong\u003e that operates on binary values (0 or 1).\u003c/p\u003e\u003cp id=\"17b0a320-00ae-80fb-809b-c3220e533e6f\"\u003eThis final form is incredibly efficient. When it’s time to deploy, the network runs using only \u003cstrong\u003ebinary operations\u003c/strong\u003e, making it exceptionally fast on any hardware.\u003c/p\u003e\u003ch2 id=\"17b0a320-00ae-8021-8f9d-eb9f303ac034\"\u003eDifferentiable Logic Cellular Automata\u003c/h2\u003e\u003cp id=\"17c0a320-00ae-808e-8573-fdd175f0ac57\"\u003eThe integration of differentiable logic gate networks with neural cellular automata provides a solution for handling discrete states while maintaining differentiability. \u003c/p\u003e\u003cp id=\"1a80a320-00ae-804b-abf1-c0ba0aaf46a6\"\u003eLet\u0026#39;s explore this system in depth, examining how it differs from traditional Neural Cellular Automata, while highlighting their common principles and understanding the fundamental role of differentiable logic gates. We\u0026#39;ll borrow the terminology of NCA stages, highlighting where our model differs.\u003c/p\u003e\u003ch3 id=\"17b0a320-00ae-80d8-853f-e6d5a9fcb909\"\u003eThe Structure: A 2D Grid of binary, intelligent cells\u003c/h3\u003e\u003cp id=\"1960a320-00ae-80c7-b58b-d5e6c567ca01\"\u003eAs with NCA, the system is built around a 2D grid of cells, where each cell\u0026#39;s state is represented by an \u003cstrong\u003en-dimensional binary vector\u003c/strong\u003e This binary state vector acts as the cell\u0026#39;s working memory, storing information from previous iterations. Throughout this article, \u003cem\u003ecell state\u003c/em\u003e and \u003cem\u003echannels\u003c/em\u003e will be used interchangeably.\u003c/p\u003e\u003ch3 id=\"17b0a320-00ae-80c6-b0da-fcc71275aac2\"\u003eThe Two-Stage Update Mechanism: Perception and Update\u003c/h3\u003e\u003col type=\"1\" id=\"17b0a320-00ae-8034-ab51-ff1b4ac57cb3\" start=\"1\"\u003e\u003cli\u003e\u003cstrong\u003eThe \u003c/strong\u003e\u003cstrong\u003ePerception\u003c/strong\u003e\u003cstrong\u003e Stage\u003c/strong\u003e\u003cdiv id=\"17c0a320-00ae-8061-a387-ecb4b1d2d84f\"\u003e\u003cdiv id=\"76bb245b-f562-4640-b34a-75e3bd6f4507\"\u003e\u003cp id=\"17c0a320-00ae-80c8-afeb-d3933761f7ad\"\u003eIn cellular automata systems, each cell must be aware of its environment. While traditional NCA use Sobel filters to model this perception, DiffLogic CA takes a different approach, following \u003cd-cite key=\"Petersen2024-rr\"\u003e\u003c/d-cite\u003e. Each kernel is a distinct circuit, where connections are fixed with a particular structure, but the gates are learned. The kernels are computed channel-wise. Each circuit employs four layers whose connections are designed to compute  \u003cem\u003einteractions\u003c/em\u003e between the central cell and its neighboring cells as in the figure on the right. The output dimension is the number of kernels multiplied by the number of channels. Alternative approaches involve kernels with multiple bits of output per channel, rather than only one, improving convergence in some cases.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"9a000272-c6fe-4248-972e-6ec94af6e057\"\u003e\u003cfigure id=\"1820a320-00ae-80a0-a05d-fc29118859d4\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/perceive_(4).svg\"/\u003e\u003cfigcaption\u003eEach kernel operates channel-wise and computes the interaction between the central cell and its neighbors, emulating the CA\u0026#39;s interaction within the Moore neighborhood. This 3x3 patch shows a state dimension of 3. The circuit is wired to process interactions between the central cell and its surrounding cells. The first layer has 8 gates, with each gate taking the central cell as its first input and a neighboring cell as its second input.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17b0a320-00ae-8055-967a-dbcb60fd9aa9\" start=\"2\"\u003e\u003cli\u003e\u003cstrong\u003eThe Update Stage\u003c/strong\u003e\u003cdiv id=\"17c0a320-00ae-80f0-a694-ed77a59540bc\"\u003e\u003cdiv id=\"9a9dc48d-e2d6-4bc8-aae3-4a36879bf8fb\"\u003e\u003cp id=\"6d38c7a5-9c98-4b70-84df-074f0cbf26e1\"\u003eThe update mechanism follows the NCA paradigm, but employs a Differentiable Logic Network to compute each cell\u0026#39;s new state. The network\u0026#39;s connections can be either randomly initialized or specifically structured to ensure all inputs are included in the computation. The updated state is determined by applying a Differentiable Logic Gate Network to the concatenation of the cell\u0026#39;s previous memory (represented in gray), and the information received from its neighbors (represented in orange). In standard NCA, at this point, one would incrementally update the state, treating the whole system like an ODE. With DiffLogic CAs, we output the new state directly.  \u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"c392a3cb-bd32-4a40-9cd3-668148e146de\"\u003e\u003cfigure id=\"1820a320-00ae-807f-bb72-f0fe7f137292\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/update_(2).svg\"/\u003e\u003cfigcaption\u003eA representation of the update step given a cell state of dimension 4 and 2 kernels.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"1a00a320-00ae-80cb-822b-c86cdc13c579\"\u003eIn summary: the perception phase uses a logic gate network to process the binary neighborhood states, replacing traditional convolution filter-based operations, and the update rule is implemented as another logic gate network that takes the perception output and current state as inputs, and outputs the next binary state of the cell.\u003c/p\u003e\u003cfigure id=\"1a00a320-00ae-80d6-9ac9-c9b7651dc6e6\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/cell_architecture.svg\"/\u003e\u003cfigcaption\u003eSchematic representation of a 4x4 DiffLogic CA grid. At each time step, each cell reads and processes the information stored in its neighboring cells\u0026#39; states and then updates its own state\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"1a00a320-00ae-807d-a0d8-cd4ede77f9c4\"\u003eThe diagram above schematically represents a 4x4 DiffLogic CA grid,  each of the small squares is a tiny computer with a dual-memory system. We visualize these two registers as gray and orange, respectively. Every cell in our grid performs a two-step process, which we will later see can be either performed synchronously, or in some cases asynchronously: \u003c/p\u003e\u003col type=\"1\" id=\"1a00a320-00ae-80cf-95c1-d27d65e00a0d\" start=\"1\"\u003e\u003cli\u003eStep 1: The Perception Phase\u003cbr/\u003eFirst, every cell in our grid becomes a data gatherer. They examine their neighbors\u0026#39; gray registers, process what they observe, and store their results in their orange registers.\u003cbr/\u003e\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"1a00a320-00ae-8032-90c0-f862ce0748d1\" start=\"2\"\u003e\u003cli\u003eStep 2: The Update Phase\u003cbr/\u003eRight after that, each cell becomes a decision maker. Using the information stored in both its registers (the original gray one and the newly filled orange one), the cell calculates its new state. This new state gets written to the gray register, while the orange register is cleared, ready for the next round of perception.\u003cbr/\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"1a00a320-00ae-80f3-8b64-dd80800837d7\"\u003eThe system behaves like a network of tiny, independent computers that communicate with their neighbors and make decisions based on their observations. Each cell is  a miniature processor in a vast, interconnected grid, working together to perform complex computations through these simple local interactions. By combining local connections with distributed processing, we\u0026#39;ve built something that can tackle tasks exploiting the emergence of collective behavior. \u003c/p\u003e\u003cp id=\"1a00a320-00ae-80ca-a49e-efb4665081d4\"\u003eWe again find strong kinship with the the work \u003cem\u003eProgrammable Matter \u003c/em\u003eand \u003cem\u003eComputronium\u003c/em\u003e by Toffoli and Margolus, who proposed the CAM-8 \u003cd-cite key=\"Margolus1995-hg\"\u003e\u003c/d-cite\u003e\u003cd-cite key=\"Toffoli1991-do\"\u003e\u003c/d-cite\u003e, a computer architecture based on cellular automata which is similar to the system above where each cell uses a DRAM chips for state variables and an SRAM for processing.\u003c/p\u003e\u003cfigure id=\"1a00a320-00ae-80f3-92e0-c43cb1668296\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/CAM-8.png\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/CAM-8.png\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eCam-8 architecture and image from from Margolus et al.\u003cd-cite key=\"Margolus1995-hg\"\u003e\u003c/d-cite\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"17c0a320-00ae-8043-af6b-d7667381714c\"\u003eExperiment 1: Learning Game of Life\u003c/h2\u003e\u003cdiv id=\"17c0a320-00ae-8036-975b-df6ed2216f95\"\u003e\u003cdiv id=\"6ecea7c3-689a-4597-b6a9-03aae07f9b1f\"\u003e\u003cp id=\"12744ce8-f2bc-4573-9602-f3f251460b90\"\u003eConway\u0026#39;s Game of Life is a fascinating mathematical simulation that demonstrates how complex patterns can emerge from simple rules. Created by mathematician John Conway in 1970, this \u003cem\u003egame\u003c/em\u003e isn\u0026#39;t played in the traditional sense - it\u0026#39;s a cellular automaton where cells on a grid live or die based on just four basic rules. Despite its simplicity, the Game of Life can produce amazing behaviors, from stable structures to dynamic patterns that seem to take on a life of their own.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"5732a09e-ef35-4104-b416-0f7aafae68de\"\u003e\u003cfigure id=\"17c0a320-00ae-804f-8698-d5b06774ecdf\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/game_of_life_simulation.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/game_of_life_simulation.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eSimulation of Conway\u0026#39;s Game of Life\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"17c0a320-00ae-8092-b9ea-ed2c070ba6b0\"\u003eThe rules of the game are elegantly simple, focusing on how each cell interacts with its eight neighboring cells:\u003c/p\u003e\u003col type=\"1\" id=\"17c0a320-00ae-804d-85aa-d9526a7e68af\" start=\"1\"\u003e\u003cli\u003e\u003cem\u003eBirth\u003c/em\u003e: A dead cell (whose current value is 0) with exactly three living neighbors springs to life in the next generation, as if by reproduction.\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17c0a320-00ae-8006-930a-c889e1f40943\" start=\"2\"\u003e\u003cli\u003e\u003cem\u003eSurvival\u003c/em\u003e: A living cell (whose current value is 1) with either two or three living neighbors survives to the next generation, representing a balanced environment.\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17c0a320-00ae-8077-b3bd-f32ad09cc8e6\" start=\"3\"\u003e\u003cli\u003e\u003cem\u003eUnderpopulation\u003c/em\u003e: A living cell with fewer than two living neighbors dies from isolation in the next generation.\u003c/li\u003e\u003c/ol\u003e\u003col type=\"1\" id=\"17c0a320-00ae-80e3-a940-c61f42e07b6b\" start=\"4\"\u003e\u003cli\u003e\u003cem\u003eOverpopulation\u003c/em\u003e: A living cell with more than three living neighbors dies from overcrowding in the next generation.\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"17c0a320-00ae-808c-8056-fd1db396f4d4\"\u003eThese four rules, applied simultaneously to every cell in the grid at each step, create a dance of patterns. From these basic interactions emerge complex behaviors: \u003cem\u003estable structures\u003c/em\u003e that never change, \u003cem\u003eoscillators\u003c/em\u003e that pulse in regular patterns, and even \u003cem\u003egliders\u003c/em\u003e that appear to move across the grid. It\u0026#39;s this emergence of complexity from simplicity that has made the Game of Life a powerful metaphor for self-organization in natural systems, from biological evolution to the formation of galaxies.\u003c/p\u003e\u003cp id=\"17c0a320-00ae-8087-89e5-caa7c074f76e\"\u003eGiven its binary and dynamic nature, Game of Life is a good sanity check of the DiffLogic CA. \u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-8061-a777-eeca554601ce\"\u003eState and Parameters\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-8043-915b-d32ea04bcf22\"\u003eGiven that we know the rules are independent of previous state iterations, we consider a cell state consisting of 1 bit, meaning the system is essentially memory-less.  The model architecture includes 16 perception circuit-kernels, each of them with the same structure of nodes [8, 4, 2, 1]. The update network instead has 23 layers: first 16 layers have 128 nodes each, and the subsequent layers have [64, 32, 16, 8, 4, 2, 1] nodes, respectively.\u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-8050-b070-c81a2f73bfea\"\u003eLoss function\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-80a6-8fa8-d9dff565d888\"\u003eThe loss function is computed by summing the squared differences between the predicted grid and the ground truth grid.\u003c/p\u003e\u003cfigure id=\"17c0a320-00ae-8006-baad-fd12853ac1a2\"\u003e\u003cp\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmunderover\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/munderover\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmsub\u003e\u003cmover accent=\"true\"\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmo\u003e~\u003c/mo\u003e\u003c/mover\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmsup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sum_{i,j}^N(y_{i,j} - \\tilde{y}_{i,j})^2  \u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003ch3 id=\"17c0a320-00ae-800e-8361-d0ed4714fa5e\"\u003eTraining Dataset\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-8007-8251-fc1ae5ea91e5\"\u003eThe model was trained on 3x3 periodic grids for a single time step. Given that each cell in the Game of Life interacts with its eight neighbors, and its next state is determined by its current state and the states of its neighbors, there are 512 possible unique configurations for a 3x3 grid. To train the model, we constructed a grid including all 512 possible grid configurations. Learning the next state of grid correctly implies learning the complete Game of Life rule set. The trained parameters were subsequently used to simulate the model\u0026#39;s behavior on larger grids.\u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-80ef-b8b5-ceb5e36e8b3e\"\u003e\u003cstrong\u003eResults\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-80d3-88f2-cef619c26726\"\u003eOn the left, you can observe the loss plot comparing the two representations of logic gates. The \u003cem\u003e\u003cmark\u003e\u003cstrong\u003esoft\u003c/strong\u003e\u003c/mark\u003e\u003c/em\u003e\u003cmark\u003e\u003cstrong\u003e loss\u003c/strong\u003e\u003c/mark\u003e computes the output of the gates using their continuous approximation as explained in the previous section, while the \u003cem\u003e\u003cmark\u003e\u003cstrong\u003ehard\u003c/strong\u003e\u003c/mark\u003e\u003c/em\u003e\u003cem\u003e\u003cmark\u003e\u003cstrong\u003e loss\u003c/strong\u003e\u003c/mark\u003e\u003c/em\u003e selects only the most probable gate and uses its discrete output. Both losses fully converge, indicating that we were able to generate a circuit that perfectly simulates the Game of Life.\u003c/p\u003e\u003cp id=\"1990a320-00ae-80a8-83cc-f84133c2d11e\"\u003eUsing hard inference (selecting most probable gates), the simulation on the right displays the learned circuit\u0026#39;s performance on a larger grid. The emergent patterns capture the structures from Conway\u0026#39;s Game of Life: gliders moving across the grid, stable blocks remaining fixed in place, and classic structures like loaves and boats maintaining their distinctive shapes. The successful replication of Game of Life\u0026#39;s characteristic patterns demonstrates that our circuit has effectively learned the underlying local rules.\u003c/p\u003e\u003cdiv id=\"17c0a320-00ae-8023-8d93-ca1fe9b614cc\"\u003e\u003cdiv id=\"6374f26a-1ff6-4c15-a6cb-288b0dfb7aff\"\u003e\u003cfigure id=\"1980a320-00ae-8061-85ea-f591ef1029d7\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/gof_loss.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/gof_loss.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eTraining plot for DiffLogic CA learning Game of Life\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"c01e6682-51f8-4834-9291-d86c414afc83\"\u003e\u003cfigure id=\"17b0a320-00ae-806b-955e-daf04e669128\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/gif_game_of_life.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/gif_game_of_life.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eGame of Life simulated by the learned circuit\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003ch3 id=\"19a0a320-00ae-8063-bd2d-c699f4db50e0\"\u003eAnalysis of the Generated Circuit \u003c/h3\u003e\u003cp id=\"19a0a320-00ae-80af-8991-f65fef5f2047\"\u003eWhile circuit optimization is not the primary focus of this project, this section provides a brief analysis of the generated circuit.\u003c/p\u003e\u003cp id=\"17c0a320-00ae-8066-884e-f2b96588559f\"\u003eThe total number of \u003cem\u003eactive\u003c/em\u003e gates used (excluding the pass-through gates A and B), is 336. Examining the gate distributions, we observe that the most frequently used gates in both networks are OR and AND.\u003c/p\u003e\u003cp id=\"1a70a320-00ae-8064-a718-f9867702f336\"\u003eSince our final circuit is simply a series of binary gates, we can step even deeper and visualize the entirety of the circuit logic involved! Below is a visualization of most of these 336 gates (some gates are pruned, when we determine they don’t contribute to the output). \u003c/p\u003e\u003cfigure id=\"1a70a320-00ae-8057-81b6-d5a09ba88fb3\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/gol_circuit_full.png\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/gol_circuit_full.png\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eComplete learned perceive-update circuit implementing Game of Life (\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/gol.html\"\u003eavailable interactively\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"1a70a320-00ae-801a-a4f4-f2b54a03f311\"\u003eThe squares arranged in a three-by-three grid on the left are the input gates, arranged as they would be when viewed from the perspective of a single, central, cell somewhere in the game of life. The wires are colored green when high (1), and red when low (0). Finally, each gate should be somewhat self-explanatory, being one of AND, OR or XOR gates, with small circles on inputs or on outputs to denote NOTs on those particular connections. We\u0026#39;ve additionally replaced the binary NotB and NotA gates with a unary Not gate, and pruned the unused input, to simplify visualization. Finally, some gates are simply “True” or “False”, and these look almost identical to the inputs, appearing as nested squares, either filled in (True) or empty (False).  \u003c/p\u003e\u003cp id=\"1a70a320-00ae-800f-ae77-e6586a7d4263\"\u003eOn the far right, we see the single output channel of this circuit - denoting the new state of the cell in the Game of Life. In this particular configuration in the figure, we see the circuit correctly computing the rule “Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.”\u003c/p\u003e\u003cp id=\"1a70a320-00ae-800c-8cdb-f6a07a46a6dd\"\u003eWe encourage readers to \u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/gol.html\"\u003edirectly interact with the circuit\u003c/a\u003e\u003cd-cite key=\"MaterzokUnknown-wb\"\u003e\u003c/d-cite\u003e.\u003c/p\u003e\u003ch2 id=\"17c0a320-00ae-806e-83c8-cf2856b2b387\"\u003eExperiment 2: Pattern Generation\u003c/h2\u003e\u003cp id=\"17c0a320-00ae-80a8-a075-f0f39993e28b\"\u003eNeural Cellular Automata (NCA) have shown remarkable capabilities in pattern generation tasks \u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e, inspiring us to explore similar capabilities with diffLogic CA. In this task, the system evolves from a random initial state toward a target image, allowing multiple steps of computation. By evaluating the loss function only at the final time-step, we challenge the model to discover the discrete transition rules that guide the system through a coherent sequence of states without step-by-step supervision. \u003c/p\u003e\u003cp id=\"1a80a320-00ae-8026-89b3-d3c8f76f6740\"\u003e\u003cbr/\u003eSuccessfully learning to reconstruct images would validate two key aspects: the model\u0026#39;s ability to develop meaningful long-term dynamics through learned rules, and its capability to effectively learn \u003cem\u003estateful, recurrent-in-time, recurrent-in-space\u003c/em\u003e circuits. This investigation is particularly significant as it represents, according to the best of our knowledge, the first exploration of differentiable logic gate networks \u003cd-cite key=\"Petersen2022-ai\"\u003e\u003c/d-cite\u003e\u003cd-cite key=\"Petersen2024-rr\"\u003e\u003c/d-cite\u003e in a recurrent setting.\u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-8083-8659-e20f9a41611e\"\u003eState and Parameters\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-80a3-8347-cb14d7db4b62\"\u003eWe consider a cell state (channels) of 8 bits and iterate the DiffLogic CA for 20 steps. The model architecture includes 16 perception circuit-kernels, each with 8, 4, then  2 gates per layer, respectively. The update network has 16 layers: 10 layers with 256 gates each, and then layers with [128, 64, 32, 16, 8, 8] gates, respectively. \u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-801f-ab3f-ead7589b668c\"\u003eLoss function\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-80a4-80cd-e1cf54b12061\"\u003eWe define the loss function as the sum of the squared differences between the first channel in the predicted grid and the target grid at the last time step.\u003c/p\u003e\u003cfigure id=\"17c0a320-00ae-8098-a736-e918eb6b04da\"\u003e\u003cp\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmunderover\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/munderover\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmsub\u003e\u003cmover accent=\"true\"\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmo\u003e~\u003c/mo\u003e\u003c/mover\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmsup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sum_{i,j}^N(y_{i,j,0} - \\tilde{y}_{i,j,0})^2  \u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003ch3 id=\"17c0a320-00ae-801c-a912-f98499dc9d47\"\u003eTraining Dataset\u003c/h3\u003e\u003cdiv id=\"17c0a320-00ae-8063-aba4-d927930e8cd1\"\u003e\u003cdiv id=\"41027de1-db12-49a7-9b8b-a2e7fe1c3892\"\u003e\u003cp id=\"17c0a320-00ae-8012-a208-d2be1d27409c\"\u003eThe model was trained to reconstruct a 16x16 checkerboard pattern within 20 time steps. For each training step, the initial state was randomly sampled. The target checkerboard pattern is shown on the right.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"b2f4fe42-1f3c-4dc2-94f2-efc12224d5be\"\u003e\u003cfigure id=\"17c0a320-00ae-8048-a627-cbcd662de7ee\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/train_set.png\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/train_set.png\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eTarget pattern\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003ch3 id=\"17c0a320-00ae-80ed-b462-f42a3ae1680b\"\u003e\u003cstrong\u003eResults\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-807e-8245-c331ebdc614d\"\u003eThe DiffLogic CA fully converges to the target pattern. The training plot (left) reveals consistent convergence of both soft and hard loss functions. The evolution of the first channel (right), which is used for computing the loss function, shows clear pattern formation. An intriguing emergent property is the directional propagation of patterns from bottom-left to top-right, despite the model having no built-in directional bias.\u003c/p\u003e\u003cdiv id=\"1910a320-00ae-8066-bd37-df2342c6feb9\"\u003e\u003cdiv id=\"1910a320-00ae-80a8-ad71-e34a62674acc\"\u003e\u003cfigure id=\"17c0a320-00ae-80ba-af4c-fad9791b0ab9\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checkerboard_loss.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checkerboard_loss.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eTraining plot for DiffLogic CA\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"1910a320-00ae-80fd-8d01-f41c9c542454\"\u003e\u003cfigure id=\"1900a320-00ae-80ab-9996-c2f3bb4703ae\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checker_board_small.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checker_board_small.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eEvolution of the diffLogic CA, only considering the first bit in the cell state. \u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003ch3 id=\"17c0a320-00ae-8029-84c0-c0a04827a153\"\u003eAnalysis of the Generated Circuit\u003c/h3\u003e\u003cp id=\"17c0a320-00ae-80dc-bddf-e75bba1ae1e5\"\u003eThe total number of active gates used (excluding pass-through gates A and B) is 22. Analysis of the learned logic gates reveals a different distribution of gates between the perception kernels and update networks. The TRUE gate appears to play a key role in perception but not in the update one. \u003c/p\u003e\u003cdiv id=\"17c0a320-00ae-8050-84d9-eed83c749260\"\u003e\u003cdiv id=\"9f03a6f1-88e6-40f7-addb-635001c9dac0\"\u003e\u003cfigure id=\"17c0a320-00ae-8051-b45b-f1e017e41857\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checkerboard_sync_perceive_gates.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checkerboard_sync_perceive_gates.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eDistribution of gate counts across all perception kernel circuits\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"078f6020-e34b-49ff-ac61-550d1722c0df\"\u003e\u003cfigure id=\"17c0a320-00ae-80cd-a191-f479ea5492f4\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checkerboard_sync_update_gates.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checkerboard_sync_update_gates.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eDistribution of gate counts across the update circuit.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"1a80a320-00ae-804f-bb69-c8a252e2d836\"\u003eBelow, we provide an interactive visualization of the circuit, after pruning. Remarkably, we are left with just six gates - one of which is redundant - an \u003cem\u003eAND\u003c/em\u003e between the same input. In other words; the entirety of the procedural checkerboard-generation function learned by the circuit can be implemented using just five logic gates. Likewise, most of the inputs and outputs remain unused. Even more remarkably, the cell\u0026#39;s own current visual output isn\u0026#39;t even considered in an update step. We encourage readers to interact with the circuit below \u003cd-cite key=\"MaterzokUnknown-wb\"\u003e\u003c/d-cite\u003e, clicking on and off inputs on the left to observe the effect on the outputs.\u003c/p\u003e\u003cfigure\u003e\n\n\u003cfigcaption\u003eComplete learned perceive-update circuit generating checkerboard, interactive\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\n\n\u003c/div\u003e\u003ch3 id=\"1900a320-00ae-8093-9c21-fa0096e85afe\"\u003eHow general is the solution? \u003c/h3\u003e\u003cp id=\"1910a320-00ae-8063-b6f3-c3712abdae01\"\u003eTo the naked eye, our solution appears to build the grid iteratively—brick by brick, as it were. However, during training, we only employed one fixed size of the grid. Naturally, we should investigate what happens if we change the grid size: is the rule we learned truly an iterative, procedural solution, or is it overfit to one particular grid size? Let\u0026#39;s scale up both the spatial and temporal dimensions by a factor of four—using a grid four times larger and running it for four times as many steps.\u003c/p\u003e\u003cfigure id=\"1900a320-00ae-80e2-a164-f1c5a41da8f5\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checker_board_large.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/checker_board_large.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eGeneralization Test: Learned Rules Applied to 4x Larger Grid\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"1900a320-00ae-8012-8000-d24e45e6528c\"\u003eSuccess! The circuit works just as well in this new setting. This raises an interesting question as to the inductive biases of this model. In the NCA setting, it was possible to coax behavior invariant to grid size and time, but this required either special spatially invariant loss functions \u003cd-cite key=\"Niklasson2021-vb\"\u003e\u003c/d-cite\u003e , and in the case of the growing lizard a special \u0026#34;alive/dead\u0026#34;\u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e regime to prevent overfitting to boundary conditions. Here, our boundary conditions are also fixed, yet the model has learned a \u0026#34;boundary-size-invariant\u0026#34; way to produce the pattern. Could the discretization and minimal circuit size be finding some minimal procedural description for generating patterns of interest? \u003c/p\u003e\u003cp id=\"1910a320-00ae-80b6-9642-fda8db6a59db\"\u003eGiven our setting, we tested the system\u0026#39;s resilience to damage and its recovery capabilities through two experiments. In the first test (left), we evaluated pattern reconstruction when a large portion of cells were permanently disabled, simulating faulty components. In the second test (right), the disabled cells were reactivated after a set number of steps. The system demonstrated robust behavior in both scenarios: maintaining pattern integrity despite permanent cell damage in the first case, and successfully self-repairing to produce the correct pattern once damaged cells came back online in the second case.\u003c/p\u003e\u003ch3 id=\"1980a320-00ae-800d-bdc1-e5bf455b1d0e\"\u003eDiffLogic CA as new paradigm for robust computing \u003c/h3\u003e\u003cp id=\"1980a320-00ae-80f4-a198-c9d7fa195e69\"\u003eRobust computing \u003cd-cite key=\"Ackley2013-im\"\u003e\u003c/d-cite\u003e represents a fundamental shift in system design, prioritizing reliable operation under real-world conditions. In contrast to traditional computing, which relies on precise, error-free components, robust systems are designed to remain functional even in the face of hardware failures, environmental interference, unexpected inputs, or manufacturing variations. While contemporary computing, especially distributed computing, has some affordances around robustness to certain types of failures, it\u0026#39;s generally still far more brittle than any similarly complex system in the natural world, and those affordances are usually designed around very specific failure cases that we are unable to control for by other means (think cosmic ray-induced bit flips in RAM). In the example reported above, we observed how the DiffLogic CA learned rules that exhibit both fault tolerance and self-healing behavior, without explicitly designing around these conditions. When some cells fail, the damage is contained, and the system continues to function with a gradual decline rather than experiencing catastrophic failure. This mirrors how biological systems achieve reliability through networks of imperfect components, suggesting a powerful approach for future computing systems that can maintain functionality even under imperfect conditions.\u003c/p\u003e\u003ch3 id=\"1930a320-00ae-8016-8dd7-d421f595e190\"\u003eAsynchronicity \u003c/h3\u003e\u003cp id=\"1960a320-00ae-8082-a939-e7211db1d6ed\"\u003eInspired by the approach used in traditional NCA training \u003cd-cite key=\"Niklasson2021-ft\"\u003e\u003c/d-cite\u003e, we explored asynchronous updates. Instead of updating all cells simultaneously (which can be likened to a global clock), we randomly select a subset of cells to update in each step. This simulates a scenario where each cell operates with its own internal clock. Within this framework, each cell can be conceptualized as a tiny computational unit operating independently of other cells, making its own decisions.\u003c/p\u003e\u003cp id=\"19c0a320-00ae-8002-b441-cebc9f9c150c\"\u003eWe proceeded directly to introducing asynchronicity to training, expecting this to be markedly more difficult than in traditional NCAs. Firstly, the updates at every step must output the full new state, and not just an incremental update. Secondly, a cell must now be able to account for surrounding cells being in any combination of desynchronization. Any given neighbour could be one, two, three, or more steps \u0026#34;behind\u0026#34; or \u0026#34;ahead\u0026#34;. This combinatorially increases the possible transitions rules the cell has to effectively learn to deal with. To our surprise -  successful asynchronous training was relatively easy to achieve in the simplest pattern - the checkerboard. Below, we demonstrate three different, unique, reconstructions of the pattern , all starting  from the same initial state but with distinct random seeds to determine the cell update order. Despite the asynchronous nature of these updates and a more complex resulting update rule, the cells correctly reconstruct the target pattern in 50 steps, compared to the original 20.\u003c/p\u003e\u003cfigure id=\"1980a320-00ae-80be-b66e-d6355a0280ab\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/async__.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/async__.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eAsynchronous trained patterns.\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"1980a320-00ae-80ff-8aca-ea0fc5505fa0\"\u003eFurthermore, the learned circuit demonstrated generalization capabilities, exhibiting successful reconstruction on larger grids and resilience to errors -  a self-healing checkerboard..\u003c/p\u003e\u003cdiv id=\"1980a320-00ae-805c-8eb1-e3f89fc9fe84\"\u003e\u003cdiv id=\"1980a320-00ae-805e-a10a-fc53a3247820\"\u003e\u003cfigure id=\"1980a320-00ae-805b-a87d-fc94afd8ee18\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/generalization.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/generalization.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eGeneralization with asynchronous training\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"1980a320-00ae-80d3-a34b-ded90815deca\"\u003e\u003cfigure id=\"1980a320-00ae-8016-a53b-d2c9818b2441\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/self_healing.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/self_healing.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eSelf-healing behaviour with asynchronous training\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"1a80a320-00ae-807e-aecd-d610a20882b2\"\u003eThe biggest surprise came when sanity checking the original synchronously trained rule, but using asynchronous inference. It works! This is surprising and further speaks to the robustness of the circuit originally discovered. \u003c/p\u003e\u003cp id=\"1a80a320-00ae-8095-900a-f90ff269de71\"\u003eThis unexpected success with asynchronous inference led us to hypothesize that models trained directly with asynchronous updates would exhibit even greater robustness. To test this, we randomly deactivate a 10x10 pixel square within the image domain at each inference time-step, as shown in the simulations below.    \u003c/p\u003e\u003cp id=\"1a80a320-00ae-80ea-a82e-f52164befdcd\"\u003eThe images hint at the difference in resilience to noise - the asynchronous cells recover from the damage slightly more quickly, while the synchronously trained rule appears to be more impacted. By measuring the error as the sum of the absolute difference between the target and reconstructed images, we found that asynchronous training improves robustness considering these perturbations. \u003c/p\u003e\u003cfigure id=\"1a80a320-00ae-80c5-a841-ddf938cd000c\"\u003e\u003cp\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmsub\u003e\u003cmi\u003er\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmunderover\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/munderover\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmsub\u003e\u003cmover accent=\"true\"\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmo\u003e~\u003c/mo\u003e\u003c/mover\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eError_t = \\sum_{i,j}^N |y - \\tilde{y}_t|  \u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003cfigure id=\"1a80a320-00ae-8069-9429-cbb1d0946770\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/async_sync.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/async_sync.svg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003ch2 id=\"1900a320-00ae-801c-9a12-c65e03e9b6e5\"\u003eExperiment 3: Growing a Lizard\u003c/h2\u003e\u003cp id=\"1900a320-00ae-80e5-b44f-e35e162e2266\"\u003eFor the next experiment, we tested DiffLogic CA\u0026#39;s ability to learn arbitrary shapes by training it on the outline of a lizard, in an homage to the original NCA work. This involves more memorization than reproducing a highly-compressible regular pattern like the checkerboard. We use a cell state  of 128 bits and iterate the DiffLogic CA for 12 steps. The model architecture includes four perception circuit-kernels with 8, 4, 2, and 1 gates at each layer, respectively. The update network has 10 layers: eight layers with 512 gates each, and then layers with [256, 128] nodes, respectively. \u003c/p\u003e\u003ch3 id=\"1910a320-00ae-801e-a93f-f67b742085f5\"\u003eTraining Dataset\u003c/h3\u003e\u003cp id=\"1910a320-00ae-8023-bf3a-e2874f1e8ef2\"\u003eWe trained the model to generate a 20x20 lizard pattern, in 12  time steps. Just as in NCA, the initial condition consists of a central seed to break symmetry, with periodic boundary conditions applied to the grid edges. We employed the same loss function previously used in the checkerboard experiment.\u003c/p\u003e\u003cfigure id=\"1900a320-00ae-8052-8f20-c41edada6da6\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_out.png\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_out.png\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eOutline of a lizard\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"1980a320-00ae-809f-8368-e169b4ae4207\"\u003e\u003cstrong\u003eResults\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"1980a320-00ae-809d-a272-d689a49e93d9\"\u003eTo assess the model\u0026#39;s generalization capabilities, we evaluated its performance on a larger 40x40 grid. The results demonstrate that the model successfully learned the growth pattern without exploiting boundary conditions.\u003c/p\u003e\u003cp id=\"19c0a320-00ae-8003-b682-f2ee76e35047\"\u003eOn the left, the plot shows the convergence of both the soft and hard losses to zero. On the right, the visualization illustrates the successful growth of the lizard within the larger grid.\u003c/p\u003e\u003cdiv id=\"1980a320-00ae-80ab-9e9b-e7ba3d378361\"\u003e\u003cdiv id=\"1980a320-00ae-80b0-8dfe-fa8b2b2c78c3\"\u003e\u003cfigure id=\"1910a320-00ae-801c-a00c-d6f1ba16ed4d\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_logo_loss.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_logo_loss.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eLoss function for the lizard. \u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"1980a320-00ae-80ff-9538-dc8a323d7b67\"\u003e\u003cfigure id=\"1980a320-00ae-80c1-90e6-c877f598dfef\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_video_bigger.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_video_bigger.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eGrowing Lizard with diffLogic CA\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003cp id=\"1980a320-00ae-80a2-88ce-e27e102d1872\"\u003eBelow, visualizations of the first 32 hidden states offer a glimpse into the internal dynamics of the model during the growth process.\u003c/p\u003e\u003cfigure id=\"1910a320-00ae-8022-ad8e-c742a50946a9\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_32_channels.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/lizard_32_channels.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eVisualization of the first 32 channels. \u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"1980a320-00ae-8031-82aa-d59dd76aa6fa\"\u003eTraining DiffLogic CA to generate complex patterns presents significant optimization challenges. The process required extensive hyper-parameter tuning. Future improvements to both the model architecture and circuit topology could enhance convergence speed and stability, potentially reducing the need for such intensive hyper-parameter optimization.\u003c/p\u003e\u003ch3 id=\"1980a320-00ae-8000-9039-f9308ef536fc\"\u003eAnalysis of the Generated Circuit\u003c/h3\u003e\u003cp id=\"1980a320-00ae-80dc-9b30-f003157154a3\"\u003eA total of 577 active gates were used, excluding pass-through gates A and B.\u003c/p\u003e\u003cp id=\"19a0a320-00ae-80ba-a25c-cd71756eeb32\"\u003eThe perception kernels predominantly employed the TRUE gate, while the update circuit employed almost all available gates.\u003c/p\u003e\u003ch2 id=\"1990a320-00ae-80dc-9f06-c609a5f81ab0\"\u003eExperiment 4: Learning the G with colors \u003c/h2\u003e\u003cp id=\"1990a320-00ae-8038-868d-e4044bacdd59\"\u003ePrevious experiments have primarily focused on effectively monochrome images, using the last channel for visualization purposes. Wanting to investigate more complex target states,  we trained the model to generate a 16x16 \u0026#34;colored\u0026#34; image, over 15 steps. Using 64 channels per cell state, the model has four perception circuit-kernels, each with four three layers with 8, 4, and 2 gates, respectively. The update network architecture consists of 11 layers: 8 layers of 512 nodes each, and a final sequence of 3 layers with [256, 128, 64] nodes, respectively.\u003c/p\u003e\u003ch3 id=\"1990a320-00ae-8005-95df-ce842d66c1fc\"\u003eTraining Dataset\u003c/h3\u003e\u003cp id=\"1990a320-00ae-80e1-a19d-f20f440dc67b\"\u003eThe model was trained to generate a 16x16 colored letter of the alphabet (that might be reminiscent to some), over 15 steps. The initial state is fully zero, without periodic boundary conditions. Following the convention used in standard NCA \u003cd-cite key=\"Mordvintsev2020-oh\"\u003e\u003c/d-cite\u003e, the first three channels represent RGB color values. However, in our case, these values are constrained to a binary representation of \u003cspan data-token-index=\"0\" contenteditable=\"false\"\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e0s\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e﻿\u003c/span\u003e\u003c/span\u003e and \u003cspan data-token-index=\"0\" contenteditable=\"false\"\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1s\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e﻿\u003c/span\u003e\u003c/span\u003e, resulting in a palette of eight possible colors.\u003c/p\u003e\u003cfigure id=\"1990a320-00ae-804f-af51-e7b703801dde\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo_target.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo_target.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eTarget Pattern\u003c/figcaption\u003e\u003c/figure\u003e\u003ch3 id=\"1990a320-00ae-8038-9920-d7e58950365b\"\u003eLoss function\u003c/h3\u003e\u003cp id=\"1990a320-00ae-8077-9efd-db1aaba4e056\"\u003eThe loss function is defined as the sum of the squared differences between the predicted grid and the target grid at the final time-step, considering only the first three channels (0, 1, 2).\u003c/p\u003e\u003cfigure id=\"1990a320-00ae-8034-817d-f2eff8a918fb\"\u003e\u003cp\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmunderover\u003e\u003cmo\u003e∑\u003c/mo\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003c/mrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/munderover\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmsub\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo\u003e:\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmsub\u003e\u003cmover accent=\"true\"\u003e\u003cmi\u003ey\u003c/mi\u003e\u003cmo\u003e~\u003c/mo\u003e\u003c/mover\u003e\u003cmrow\u003e\u003cmi\u003ei\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ej\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmn\u003e0\u003c/mn\u003e\u003cmo\u003e:\u003c/mo\u003e\u003cmn\u003e3\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003cmsup\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\sum_{i,j}^N(y_{i,j,0:3} \n - \\tilde{y}_{i,j,0:3})^2  \u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003ch3 id=\"1990a320-00ae-806f-8318-d8ed0c9b8796\"\u003e\u003cstrong\u003eResults\u003c/strong\u003e\u003c/h3\u003e\u003cp id=\"1990a320-00ae-8015-a847-e48d76781606\"\u003eThe results demonstrate that the model successfully learns this colorful G. On the left, the loss function plots show the convergence of both the soft and hard losses. On the right, the  reconstruction the colorful G in 15 steps is shown.\u003c/p\u003e\u003cdiv id=\"1990a320-00ae-8082-8ce5-c73c02457a73\"\u003e\u003cdiv id=\"1990a320-00ae-801b-ae06-f8c1b140d14b\"\u003e\u003cfigure id=\"1990a320-00ae-80a4-8329-c1179850382e\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo_loss.svg\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo_loss.svg\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eLoss function for the colored G \u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv id=\"1990a320-00ae-80ae-a30a-e42733cae682\"\u003e\u003cfigure id=\"1990a320-00ae-80af-892b-e83ed518255f\"\u003e\u003ca href=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo%201.gif\"\u003e\u003cimg src=\"https://google-research.github.io/self-organising-systems/difflogic-ca/images/google_logo%201.gif\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u0026#34;G\u0026#34; being generated by learned circuit\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003ch3 id=\"1990a320-00ae-8006-b6fe-c4898652a097\"\u003eAnalysis of the Generated Circuit\u003c/h3\u003e\u003cp id=\"1990a320-00ae-80f7-8ef1-e87febb0c8ce\"\u003eA total of 927 active gates were used (excluding pass-through gates A and B). Analysis of the learned logic gates revealed distinct distributions across perception and update networks. Notably, TRUE and FALSE gates were extensively employed in both networks, while the OR gate was the most prevalent in the update network. We note that this circuit was more complex than previous experiments, both in the difficulty of finding suitable hyperparameters and in size of the circuit.\u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-8098-b773-d5d0c2587283\"\u003eSummary and Discussion\u003c/h3\u003e\u003cp id=\"1a00a320-00ae-809b-b46a-cb16a2bdf0f3\"\u003eThis work introduces DiffLogic CA, a novel NCA architecture and training regime, utilising a fully discrete cell state, updated using a learned, recurrent binary circuit. We replace the neural network components with Deep Differentiable Logic Networks, which bring the flexibility of differentiable training to discrete logic gates. The successful application of differentiable logic gates to cellular automata is demonstrated through two key results: replicating the rules of Conway\u0026#39;s Game of Life and generating patterns via learned discrete dynamics. These findings highlights the significant potential of integrating discrete logic within the framework of neural cellular automata and prove that differentiable logic gate networks can be effectively learned in recurrent architectures.  While the current model exhibits promising results in learning patterns, training it to generate more complex shapes and structures presents ongoing challenges. Potential directions for improvement include the exploration of hierarchical NCA architectures and the incorporation of specialized gates designed to facilitate state forgetting. For instance, integrating LSTM-like gating mechanisms into the state update process could enable a richer and diverse combination of past and newly computed candidate states, potentially enhancing the model\u0026#39;s dynamics and expressiveness.\u003c/p\u003e\u003ch3 id=\"17c0a320-00ae-8098-b773-d5d0c2587283\"\u003eAcknowledgments\u003c/h3\u003e\u003cp id=\"1a00a320-00ae-809b-b46a-cb16a2bdf0f3\"\u003eWe thank Blaise Aguera y Arcas for his support and the Paradigm of Intelligence Team for the fruitful and inspiring discussions. Many thanks to Marek Materzok, and the contributors to the excellent \u003ca href=\"https://github.com/tilk/digitaljs\"\u003eDigitalJS circuit visualization library\u003c/a\u003e, which was used to power all the interactive circuits in this article.\u003c/p\u003e\n\u003c/article\u003e\u003c/div\u003e",
  "readingTime": "42 min read",
  "publishedTime": null,
  "modifiedTime": null
}
