{
  "id": "508bcd06-0ae1-43de-ae11-67bad1d69b9e",
  "title": "Chat-Driven Development: A Better Way to Use LLMs for Coding",
  "link": "https://shekhargulati.com/2025/01/07/chat-first-development-a-better-way-to-use-llms-for-coding/",
  "description": "Comments",
  "author": "",
  "published": "Tue, 07 Jan 2025 06:53:14 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "",
  "length": 2581,
  "excerpt": "In the last couple of years, I have subscribed to GitHub Copilot multiple times, each time canceling its subscription. It never felt natural to me, feeling annoying and getting too much in my way. …",
  "siteName": "Shekhar Gulati",
  "favicon": "https://s2.wp.com/i/webclip.png",
  "text": "Skip to content In the last couple of years, I have subscribed to GitHub Copilot multiple times, each time canceling its subscription. It never felt natural to me, feeling annoying and getting too much in my way. To me, chat-driven development with ChatGPT or Claude feels more natural. I feel I’m in more control as I can be explicit about what I want, work on smaller problems, and pass relevant context. This helps LLMs generate better code for me. Today, I was reading a blog where the author shared similar experiences. They listed the following reasons: Clean slate advantage: The author mentions that IDE workspaces are often messy, repositories too large, and full of distractions. LLMs can get confused with too much complexity and ambiguity. Using chat through a web browser provides a blank slate for well-contained requests. Control over context: Chat allows carefully crafting specific, exam-style questions with just the necessary background material, leading to better results than overwhelming the LLM with the entire IDE context. Energy management: The author uses chat-driven programming when they know what needs to be written but lack the energy to start from scratch (especially after 11 AM or during context switches between languages/frameworks). Getting a first draft from an LLM with dependencies and structure makes it easier to fix mistakes than starting from zero. Protection of development environment: The author explicitly states “I do not want an LLM spewing its first draft all over my current branch.” They prefer keeping LLM experimentation separate from their main development environment. Feedback cycle: The author finds that using chat makes it easier to iterate on code by simply pasting compiler errors or test failures back to the LLM for corrections, without cluttering the IDE workspace. Along with the above, there are a few more reasons why I didn’t like LLM IDE integrations: For me, LLMs are a thinking tool. I use them to think about possible designs, table structures, and do brainstorming. IDE-based LLM integrations do not promote such thinking processes. Their incentive is to generate code only. I want to reach for help when I need it rather than having it tell me it can help. This inversion of dependency just doesn’t work. ChatGPT requires explicit intent/questions, whereas GitHub Copilot relies on implicit intent. I prefer editors to be lightweight without any baggage. Fast, basic code completion is what I need from my IDEs. Post navigation",
  "image": "https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"page\"\u003e\n\t\t\u003cp\u003e\u003ca href=\"#content\"\u003e\n\t\t\tSkip to content\t\t\u003c/a\u003e\u003c/p\u003e\n\n\t\t\u003cdiv id=\"content\"\u003e\n\t\u003cmain id=\"main\"\u003e\n\t\t\n\u003carticle id=\"post-9589\"\u003e\n\t\n\n\t\n\t\n\t\t\u003cp\u003e\u003cimg width=\"1024\" height=\"768\" src=\"https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png?w=1024\" alt=\"\" decoding=\"async\" srcset=\"https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png 1024w, https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png?w=150 150w, https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png?w=300 300w, https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png?w=768 768w\" sizes=\"(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 60vw, (max-width: 1362px) 62vw, 840px\" data-attachment-id=\"9594\" data-permalink=\"https://shekhargulati.com/2025/01/07/chat-first-development-a-better-way-to-use-llms-for-coding/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-3/\" data-orig-file=\"https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png\" data-orig-size=\"1024,768\" data-comments-opened=\"1\" data-image-meta=\"{\u0026#34;aperture\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;credit\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;camera\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;caption\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;created_timestamp\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;copyright\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;focal_length\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;iso\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;shutter_speed\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;orientation\u0026#34;:\u0026#34;0\u0026#34;}\" data-image-title=\"create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png?w=300\" data-large-file=\"https://shekhargulati.com/wp-content/uploads/2025/01/create-a-highly-detailed-high-resolution-image-showcasing-a-modern-programmer-2.png?w=840\"/\u003e\t\u003c/p\u003e\n\n\t\n\t\u003cdiv\u003e\n\t\t\n\u003cp\u003eIn the last couple of years, I have subscribed to GitHub Copilot multiple times, each time canceling its subscription. It never felt natural to me, feeling annoying and getting too much in my way. To me, chat-driven development with ChatGPT or Claude feels more natural. I feel I’m in more control as I can be explicit about what I want, work on smaller problems, and pass relevant context. This helps LLMs generate better code for me.\u003c/p\u003e\n\n\n\n\u003cp\u003eToday, I was reading a \u003ca href=\"https://crawshaw.io/blog/programming-with-llms\"\u003eblog\u003c/a\u003e where the author shared similar experiences. They listed the following reasons:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eClean slate advantage: The author mentions that IDE workspaces are often messy, repositories too large, and full of distractions. LLMs can get confused with too much complexity and ambiguity. Using chat through a web browser provides a blank slate for well-contained requests.\u003c/li\u003e\n\n\n\n\u003cli\u003eControl over context: Chat allows carefully crafting specific, exam-style questions with just the necessary background material, leading to better results than overwhelming the LLM with the entire IDE context.\u003c/li\u003e\n\n\n\n\u003cli\u003eEnergy management: The author uses chat-driven programming when they know what needs to be written but lack the energy to start from scratch (especially after 11 AM or during context switches between languages/frameworks). Getting a first draft from an LLM with dependencies and structure makes it easier to fix mistakes than starting from zero.\u003c/li\u003e\n\n\n\n\u003cli\u003eProtection of development environment: The author explicitly states “I do not want an LLM spewing its first draft all over my current branch.” They prefer keeping LLM experimentation separate from their main development environment.\u003c/li\u003e\n\n\n\n\u003cli\u003eFeedback cycle: The author finds that using chat makes it easier to iterate on code by simply pasting compiler errors or test failures back to the LLM for corrections, without cluttering the IDE workspace.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eAlong with the above, there are a few more reasons why I didn’t like LLM IDE integrations:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eFor me, LLMs are a thinking tool. I use them to think about possible designs, table structures, and do brainstorming. IDE-based LLM integrations do not promote such thinking processes. Their incentive is to generate code only.\u003c/li\u003e\n\n\n\n\u003cli\u003eI want to reach for help when I need it rather than having it tell me it can help. This inversion of dependency just doesn’t work. ChatGPT requires explicit intent/questions, whereas GitHub Copilot relies on implicit intent.\u003c/li\u003e\n\n\n\n\u003cli\u003eI prefer editors to be lightweight without any baggage. Fast, basic code completion is what I need from my IDEs.\u003c/li\u003e\n\u003c/ol\u003e\n\t\u003c/div\u003e\n\n\t\n\u003c/article\u003e\n\n\n\n\t\u003cnav aria-label=\"Posts\"\u003e\n\t\t\u003ch2\u003ePost navigation\u003c/h2\u003e\n\t\t\n\t\u003c/nav\u003e\n\t\u003c/main\u003e\n\n\t\n\u003c/div\u003e\n\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-01-07T04:49:40Z",
  "modifiedTime": "2025-01-07T11:38:22Z"
}
