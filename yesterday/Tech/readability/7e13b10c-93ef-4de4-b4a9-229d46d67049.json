{
  "id": "7e13b10c-93ef-4de4-b4a9-229d46d67049",
  "title": "OpenAI Sam Altman Says the Company Is 'Out of GPUs'",
  "link": "https://tech.slashdot.org/story/25/02/27/2147257/openai-sam-altman-says-the-company-is-out-of-gpus?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "An anonymous reader quotes a report from TechCrunch: OpenAI CEO Sam Altman said that the company was forced to stagger the rollout of its newest model, GPT-4.5, because OpenAI is \"out of GPUs.\" In a post on X, Altman said that GPT-4.5, which he described as \"giant\" and \"expensive,\" will require \"tens of thousands\" more GPUs before additional ChatGPT users can gain access. GPT-4.5 will come first to subscribers to ChatGPT Pro starting Thursday, followed by ChatGPT Plus customers next week. Perhaps in part due to its enormous size, GPT-4.5 is wildly expensive. OpenAI is charging $75 per million tokens (~750,000 words) fed into the model and $150 per million tokens generated by the model. That's 30x the input cost and 15x the output cost of OpenAI's workhorse GPT-4o model. \"We've been growing a lot and are out of GPUs,\" Altman wrote. \"We will add tens of thousands of GPUs next week and roll it out to the Plus tier then [] This isn't how we want to operate, but it's hard to perfectly predict growth surges that lead to GPU shortages.\" Read more of this story at Slashdot.",
  "author": "BeauHD",
  "published": "2025-02-28T00:02:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "ai"
  ],
  "byline": "",
  "length": 1047,
  "excerpt": "An anonymous reader quotes a report from TechCrunch: OpenAI CEO Sam Altman said that the company was forced to stagger the rollout of its newest model, GPT-4.5, because OpenAI is \"out of GPUs.\" In a post on X, Altman said that GPT-4.5, which he described as \"giant\" and \"expensive,\" will require \"ten...",
  "siteName": "",
  "favicon": "",
  "text": "An anonymous reader quotes a report from TechCrunch: OpenAI CEO Sam Altman said that the company was forced to stagger the rollout of its newest model, GPT-4.5, because OpenAI is \"out of GPUs.\" In a post on X, Altman said that GPT-4.5, which he described as \"giant\" and \"expensive,\" will require \"tens of thousands\" more GPUs before additional ChatGPT users can gain access. GPT-4.5 will come first to subscribers to ChatGPT Pro starting Thursday, followed by ChatGPT Plus customers next week. Perhaps in part due to its enormous size, GPT-4.5 is wildly expensive. OpenAI is charging $75 per million tokens (~750,000 words) fed into the model and $150 per million tokens generated by the model. That's 30x the input cost and 15x the output cost of OpenAI's workhorse GPT-4o model. \"We've been growing a lot and are out of GPUs,\" Altman wrote. \"We will add tens of thousands of GPUs next week and roll it out to the Plus tier then [] This isn't how we want to operate, but it's hard to perfectly predict growth surges that lead to GPU shortages.\"",
  "image": "https://a.fsdn.com/sd/topics/ai_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-176565273\"\u003e\n\t\n\t\t\n\t\n\n\t\n\t\t\n\t\t\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tAn anonymous reader quotes a report from TechCrunch: \u003ci\u003eOpenAI CEO Sam Altman said that the company was forced to \u003ca href=\"https://slashdot.org/story/25/02/27/2022254/openai-rolls-out-gpt-45\"\u003estagger the rollout\u003c/a\u003e of its newest model, GPT-4.5, \u003ca href=\"https://techcrunch.com/2025/02/27/openai-ceo-sam-altman-says-the-company-is-out-of-gpus/\"\u003ebecause OpenAI is \u0026#34;out of GPUs\u003c/a\u003e.\u0026#34; In \u003ca href=\"https://x.com/sama/status/1895203654103351462\"\u003ea post\u003c/a\u003e on X, Altman said that GPT-4.5, which he described as \u0026#34;giant\u0026#34; and \u0026#34;expensive,\u0026#34; will require \u0026#34;tens of thousands\u0026#34; more GPUs before additional ChatGPT users can gain access. GPT-4.5 will come first to subscribers to ChatGPT Pro starting Thursday, followed by ChatGPT Plus customers next week.\n\u003cp\u003e \nPerhaps in part due to its enormous size, GPT-4.5 is wildly expensive. OpenAI is charging $75 per million tokens (~750,000 words) fed into the model and $150 per million tokens generated by the model. That\u0026#39;s 30x the input cost and 15x the output cost of OpenAI\u0026#39;s workhorse GPT-4o model. \u0026#34;We\u0026#39;ve been growing a lot and are out of GPUs,\u0026#34; Altman wrote. \u0026#34;We will add tens of thousands of GPUs next week and roll it out to the Plus tier then [] This isn\u0026#39;t how we want to operate, but it\u0026#39;s hard to perfectly predict growth surges that lead to GPU shortages.\u0026#34;\u003c/p\u003e\u003c/i\u003e\u003cbr/\u003e\n\t\t \t\n\t\t\u003c/p\u003e\n\n\t\t\n\n\t\t\n\n\t\t\n\t\t\t\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
