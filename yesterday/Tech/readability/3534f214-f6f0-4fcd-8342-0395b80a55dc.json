{
  "id": "3534f214-f6f0-4fcd-8342-0395b80a55dc",
  "title": "Bluesky's 2024 moderation report shows how quickly harmful content grew as new users flocked in",
  "link": "https://www.engadget.com/social-media/blueskys-2024-moderation-report-shows-how-quickly-harmful-content-grew-as-new-users-flocked-in-000149354.html?src=rss",
  "description": "Bluesky experienced explosive growth last year, particularly toward the end, necessitating that the platform ramp up its moderation efforts. In its recently released moderation report for 2024, Bluesky said it grew by about 23 million users, jumping from 2.9 million users to nearly 26 million. And, its moderators received 17 times the number of user reports they got in 2023 — 6.48 million in 2024 compared to 358,000 the previous year.  The bulk of these reports were related to “harassment, trolling or intolerance,” spam and misleading content (including impersonation and misinformation). The presence of accounts posing as other people has been a known issue in the wake of Bluesky’s popularity spike, and the platform updated its impersonation policy in November with a “more aggressive” approach in an attempt to crack down on it. At the time, it said it had quadrupled its moderation team. The new report says Bluesky’s moderation team has grown to about 100, and hiring is ongoing. “Some moderators specialize in particular policy areas, such as dedicated agents for child safety,” it notes. Other categories Bluesky says it received a lot of reports about include “illegal and urgent issues” and unwanted sexual content. There were also 726,000 reports marked as “other.” Bluesky says it complied with 146 requests from “law enforcement, governments, legal firms” out of a total of 238 last year. The platform plans on making some changes to the way reports and appeals are handled this year that it says will “streamline user communication,” like providing users with updates about actions it has taken on content they’ve reported and, further down the line, letting users appeal takedown decisions directly in the app. Moderators took down 66,308 accounts in 2024, while its automated systems took down 35,842 spam and bot profiles. “Looking ahead to 2025, we're investing in stronger proactive detection systems to complement user reporting, as a growing network needs multiple detection methods to rapidly identify and address harmful content,” Bluesky says. This article originally appeared on Engadget at https://www.engadget.com/social-media/blueskys-2024-moderation-report-shows-how-quickly-harmful-content-grew-as-new-users-flocked-in-000149354.html?src=rss",
  "author": "Cheyenne MacDonald",
  "published": "Mon, 20 Jan 2025 00:01:49 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Internet \u0026 Networking Technology",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Cheyenne MacDonald"
  ],
  "byline": "Cheyenne MacDonald",
  "length": 2070,
  "excerpt": "Bluesky had to ramp up moderation to deal with an influx of about 23 million new users last year.",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "Bluesky experienced explosive growth last year, particularly toward the end, necessitating that the platform ramp up its moderation efforts. In its recently released moderation report for 2024, Bluesky said it grew by about 23 million users, jumping from 2.9 million users to nearly 26 million. And, its moderators received 17 times the number of user reports they got in 2023 — 6.48 million in 2024 compared to 358,000 the previous year.The bulk of these reports were related to “harassment, trolling or intolerance,” spam and misleading content (including impersonation and misinformation). The presence of accounts posing as other people has been a known issue in the wake of Bluesky’s popularity spike, and the platform updated its impersonation policy in November with a “more aggressive” approach in an attempt to crack down on it. At the time, it said it had quadrupled its moderation team. The new report says Bluesky’s moderation team has grown to about 100, and hiring is ongoing. “Some moderators specialize in particular policy areas, such as dedicated agents for child safety,” it notes.Other categories Bluesky says it received a lot of reports about include “illegal and urgent issues” and unwanted sexual content. There were also 726,000 reports marked as “other.” Bluesky says it complied with 146 requests from “law enforcement, governments, legal firms” out of a total of 238 last year.The platform plans on making some changes to the way reports and appeals are handled this year that it says will “streamline user communication,” like providing users with updates about actions it has taken on content they’ve reported and, further down the line, letting users appeal takedown decisions directly in the app. Moderators took down 66,308 accounts in 2024, while its automated systems took down 35,842 spam and bot profiles. “Looking ahead to 2025, we're investing in stronger proactive detection systems to complement user reporting, as a growing network needs multiple detection methods to rapidly identify and address harmful content,” Bluesky says.",
  "image": "https://s.yimg.com/ny/api/res/1.2/mH1tTev_8cq30XeMusKqdw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2023-12/9a321f80-a1b6-11ee-aefd-07ebdd04771f",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eBluesky experienced explosive growth last year, \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1\" href=\"https://www.engadget.com/social-media/bluesky-hits-20-million-users-143920955.html\" data-ylk=\"slk:particularly toward the end;elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1;itc:0;sec:content-canvas\"\u003e\u003cins\u003eparticularly toward the end\u003c/ins\u003e\u003c/a\u003e, necessitating that the platform ramp up its moderation efforts. In its recently released \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1\" href=\"https://bsky.social/about/blog/01-17-2025-moderation-2024\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:moderation report;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas\"\u003emoderation report\u003c/a\u003e for 2024, Bluesky said it grew by about 23 million users, jumping from 2.9 million users to nearly 26 million. And, its moderators received 17 times the number of user reports they got in 2023 — 6.48 million in 2024 compared to 358,000 the previous year.\u003c/p\u003e\u003cp\u003eThe bulk of these reports were related to “harassment, trolling or intolerance,” spam and misleading content (including impersonation and misinformation). The presence of accounts posing as other people \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1\" href=\"https://www.engadget.com/social-media/bluesky-has-a-verification-problem-190047733.html\" data-ylk=\"slk:has been a known issue;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas\"\u003e\u003cins\u003ehas been a known issue\u003c/ins\u003e\u003c/a\u003e in the wake of Bluesky’s popularity spike, and the platform \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1\" href=\"https://www.engadget.com/apps/bluesky-implements-a-more-aggressive-impersonation-policy-130047163.html\" data-ylk=\"slk:updated its impersonation policy in November;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas\"\u003e\u003cins\u003eupdated its impersonation policy in November\u003c/ins\u003e\u003c/a\u003e with a “more aggressive” approach in an attempt to crack down on it. At the time, it said it had quadrupled its moderation team. The new report says Bluesky’s moderation team has grown to about 100, and hiring is ongoing. “Some moderators specialize in particular policy areas, such as dedicated agents for child safety,” it notes.\u003c/p\u003e\u003cp\u003eOther categories Bluesky says it received a lot of reports about include “illegal and urgent issues” and unwanted sexual content. There were also 726,000 reports marked as “other.” Bluesky says it complied with 146 requests from “law enforcement, governments, legal firms” out of a total of 238 last year.\u003c/p\u003e\u003cp\u003eThe platform plans on making some changes to the way reports and appeals are handled this year that it says will “streamline user communication,” like providing users with updates about actions it has taken on content they’ve reported and, further down the line, letting users appeal takedown decisions directly in the app. Moderators took down 66,308 accounts in 2024, while its automated systems took down 35,842 spam and bot profiles. “Looking ahead to 2025, we\u0026#39;re investing in stronger proactive detection systems to complement user reporting, as a growing network needs multiple detection methods to rapidly identify and address harmful content,” Bluesky says.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-01-20T00:01:49Z",
  "modifiedTime": null
}
