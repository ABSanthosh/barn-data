{
  "id": "7f91394e-09b6-45f8-b6c5-68156ac3fb3d",
  "title": "Use Whisper on Mac to Transcribe Audio and Video Files Instantly in Terminal",
  "link": "https://macos.gadgethacks.com/how-to/whisper-transcribe-audio-video-terminal-mac/",
  "description": "Turn your Mac into a powerful transcription machine using the same AI that powers OpenAI's ChatGPT. With just a few Terminal commands, you can convert audio and video files into accurate text in minutes. If you've never touched Terminal before, don't worry — setting up Whisper on macOS Sequoia 15 is easier than it looks and worth it. Whether you're working with YouTube videos, interviews, lectures, or voice notes, Whisper can handle all the heavy lifting. Whisper is a free, open-source speech-to-text neural network from OpenAI that runs entirely on your machine — no internet required after setup. Once you get it going, it's fast, secure, and dead simple — and it can chew through just about any audio or video format you throw at it. And it's the perfect tool if you're sick of glitchy web-based transcription services, expensive Mac apps, and clunky browser extensions with limitations, such as file size caps, watermarks, ads, or lousy accuracy. Yes, it lives in the Terminal — that black...more",
  "author": "Justin Meyers",
  "published": "Thu, 27 Mar 2025 21:27:01 GMT",
  "source": "https://www.wonderhowto.com/rss.xml",
  "categories": null,
  "byline": "By Justin Meyers",
  "length": 19685,
  "excerpt": "Turn your Mac into a powerful transcription machine using the same AI that powers OpenAI's ChatGPT. With just a few Terminal commands, you can convert audio and video files into accurate text in minutes. If you've never touched Terminal before, don't worry — setting up Whisper on macOS Sequoia 15 is easier than it looks and worth it. Whether you're working with YouTube videos, interviews, lectures, or voice notes, Whisper can handle all the heavy lifting. Whisper is a free, open-source speech-to...",
  "siteName": "Gadget Hacks",
  "favicon": "",
  "text": "Turn your Mac into a powerful transcription machine using the same AI that powers OpenAI's ChatGPT. With just a few Terminal commands, you can convert audio and video files into accurate text in minutes.If you've never touched Terminal before, don't worry — setting up Whisper on macOS Sequoia 15 is easier than it looks and worth it. Whether you're working with YouTube videos, interviews, lectures, or voice notes, Whisper can handle all the heavy lifting.Whisper is a free, open-source speech-to-text neural network from OpenAI that runs entirely on your machine — no internet required after setup. Once you get it going, it's fast, secure, and dead simple — and it can chew through just about any audio or video format you throw at it. And it's the perfect tool if you're sick of glitchy web-based transcription services, expensive Mac apps, and clunky browser extensions with limitations, such as file size caps, watermarks, ads, or lousy accuracy.Yes, it lives in the Terminal — that black box of mystery most folks avoid. But here's the thing: if you can copy and paste, you can run Whisper. Once it's installed, transcribing a file is literally one line. There is no bloated interface, no uploading and waiting, and no monthly fee.And if you're not ready to mess with the command line? You still have options. There are Mac apps like MacWhisper and Whisper Transcription that give you a drag-and-drop interface powered by Whisper under the hood. Browser-based services like Whisper demo on Hugging Face make it even easier — though you'll usually trade some privacy and flexibility for convenience. However, the command-line version is still the most powerful and flexible way to use Whisper, and it's the official implementation maintained by OpenAI. If you want complete control, this is the version you want.Or you can skip all of it and just send ChatGPT the file via its web or desktop app — it can transcribe or translate it for you using Whisper.So if you're tired of jumping through hoops just to get clean transcripts — whether you're a student, podcaster, journalist, or just someone trying to archive your Zoom calls — it's time to take five minutes and set up something that just works. Let's dive in.RequirementsThrough the instructions below, you'll be installing and using the following tools:Whisper command-line tool from OpenAI: The core transcription engine that converts speech to text.FFmpeg: Required for Whisper to open, convert, and process audio and video files.Python 3.10 or later: The programming language Whisper is written in.Homebrew: A package manager that makes installing Whisper, FFmpeg, and Python easy.To run these tools successfully, you'll need:A Mac running macOS Monterey 12.3 or later: Preferably macOS Sequoia 15 or later on an Apple Silicon chip for faster performance.At least 8 GB of RAM and some free disk space: Larger Whisper models can use a lot of memory — especially on long files — but smaller models work fine on most setups.Terminal app: Preinstalled on macOS — you'll use it to enter the setup and transcription commands. Setting up Whisper on macOSFollow these steps to install everything you need and start transcribing files. If you already have Homebrew, Python, and FFmpeg installed, it's still worth checking those steps out to ensure everything is up to date. Open Terminal on your MacTerminal is the command-line app built into macOS — it’s how you’ll install and run Whisper. You don’t need to know how to code, just how to paste in commands. To open Terminal, press Command + Space, type “Terminal,” and hit Return. You can also find it in the Utilities folder in your Applications directory or in the Other folder in Launchpad. Install or update HomebrewHomebrew is a package manager for macOS — like the App Store but for powerful command-line tools. It makes it easy to install everything Whisper needs behind the scenes.If you don't have Homebrew installed, paste this command and press Return:/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"This command may look intimidating, but here's what it all means:/bin/bash -c tells your Mac to run a command in the Bash shell.The part in quotes — \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" — uses curl (a tool that fetches files from the internet) to download Homebrew's official installer script from GitHub.Here's what those flags mean:-f = fail silently on errors.-s = run silently (don't show the download progress bar).-S = show errors if any occur (used with -s).-L = follow redirects automatically.The whole script installs Homebrew safely and automatically.If Homebrew is already installed, update it by running:brew update Install Python 3.10 (or newer)Python is the programming language Whisper is written in. Apple includes an older version on macOS, but Whisper needs a newer one to run properly. Homebrew makes it easy to install the correct version.Whisper requires Python 3.10 or above. Install it with:brew install pythonIf you already have Python installed but aren't sure if it's the right version, check it with:python3 --versionIf it's older than 3.10, you can upgrade it with:brew upgrade pythonYou're good to go once you're on Python 3.10 or newer. Install FFmpegFFmpeg is a tool for processing audio and video files. It helps Whisper handle all kinds of media formats, such as MP3, MP4, M4A, and WAV. Without FFmpeg, Whisper can't read or convert your files.To install it using Homebrew:brew install ffmpegIf you already have FFmpeg installed, make sure it's up to date:brew upgrade ffmpegYou can verify that FFmpeg is working by running:ffmpeg -versionIf it prints version info, you're good. Install Whisper via pipPip is Python's built-in package manager — it's how you install Python apps like Whisper. You'll use pip to download and install Whisper directly from OpenAI's GitHub repository.First, make sure pip is up to date:pip3 install --upgrade pipThen install Whisper:pip3 install git+https://github.com/openai/whisper.git Run a transcription with WhisperOnce Whisper is installed, you can transcribe audio and video files (MP3, MP4, M4A, WAV, and more) using a single command. It supports a range of pretrained models, from lightweight and fast to large and highly accurate.Audio files are transcribed much faster than video files, so you may want to extract the audio from your videos and use that with Whisper instead — especially when working with a larger model. On a Mac, you can quickly export audio from a video file using QuickTime Player. Basic usage (auto-detects language)The --model tiny option runs the fastest and uses the least memory, while the --model large option offers the best accuracy but requires significantly more RAM and takes longer to process.whisper your_file.mp4 --model tiny whisper your_file.mp4 --model base whisper your_file.mp4 --model small whisper your_file.mp4 --model medium whisper your_file.mp4 --model large Specify language for faster, more accurate resultsIf you know your file is in English, you can specify it using --language en or --language English:whisper your_file.mp4 --language English --model tiny whisper your_file.mp4 --language English --model base whisper your_file.mp4 --language English --model small whisper your_file.mp4 --language English --model medium whisper your_file.mp4 --language English --model largeWhen using one of the commands above, the output will print directly in the same Terminal window.However, Whisper can create .txt (plain transcript), .srt (standard subtitle format used by most video players and editors), and .vtt (Web Video Text Tracks format used for HTML5 video, YouTube, etc.) transcription files in the same directory as the original media file. If needed, add flags like --output_format txt (to specify a specific format) or --task translate (which automatically translates foreign languages into English).For example, the following transcribes the file in English and outputs it to a .txt document in the same directory.whisper your_file.mp4 --language en --model small --output_format txtTo generate subtitles for a foreign-language video in English, the following command will generate .txt, .srt, and .vtt transcription files in the same folder as your video or audio file.whisper your_file.mp4 --task translate --model mediumWant just subtitle files (like .srt) and not the plain text transcript? Run:whisper your_file.mp4 --language en --task translate --output_format srtTo see all available options:whisper --help Final thoughtsWhisper in Terminal isn't just a transcription tool — it's a secret weapon for creators, journalists, students, and anyone who deals with spoken content. The setup process might feel a bit technical the first time, but once it's up and running, it's incredibly simple to use.That said, Whisper models run locally and can be slow, depending on your Mac's hardware. If you work with large files and want faster results, stick to the tiny or base models. If you need higher accuracy and don't mind the extra processing time, go for medium or large. Full list of Whisper arguments and optionsIf you want to explore everything Whisper can do — including output formats, language support, and advanced flags — you can run whisper --help in Terminal. Here's the complete list of available options for quick reference:usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE] [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}] [--verbose VERBOSE] [--task {transcribe,translate}] [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}] [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE] [--patience PATIENCE] [--length_penalty LENGTH_PENALTY] [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT] [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16] [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK] [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD] [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD] [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS] [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS] [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT] [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS] [--clip_timestamps CLIP_TIMESTAMPS] [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD] audio [audio ...] positional arguments: audio audio file(s) to transcribe options: -h, --help show this help message and exit --model MODEL name of the Whisper model to use (default: turbo) --model_dir MODEL_DIR the path to save model files; uses ~/.cache/whisper by default (default: None) --device DEVICE device to use for PyTorch inference (default: cpu) --output_dir OUTPUT_DIR, -o OUTPUT_DIR directory to save the outputs (default: .) --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all} format of the output file; if not specified, all available formats will be produced (default: all) --verbose VERBOSE whether to print out the progress and debug messages (default: True) --task {transcribe,translate} whether to perform X-\u003eX speech recognition ('transcribe') or X-\u003eEnglish translation ('translate') (default: transcribe) --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba} language spoken in the audio, specify None to perform language detection (default: None) --temperature TEMPERATURE temperature to use for sampling (default: 0) --best_of BEST_OF number of candidates when sampling with non-zero temperature (default: 5) --beam_size BEAM_SIZE number of beams in beam search, only applicable when temperature is zero (default: 5) --patience PATIENCE optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search (default: None) --length_penalty LENGTH_PENALTY optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default (default: None) --suppress_tokens SUPPRESS_TOKENS comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations (default: -1) --initial_prompt INITIAL_PROMPT optional text to provide as a prompt for the first window. (default: None) --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop (default: True) --fp16 FP16 whether to perform inference in fp16; True by default (default: True) --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK temperature to increase when falling back when the decoding fails to meet either of the thresholds below (default: 0.2) --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD if the gzip compression ratio is higher than this value, treat the decoding as failed (default: 2.4) --logprob_threshold LOGPROB_THRESHOLD if the average log probability is lower than this value, treat the decoding as failed (default: -1.0) --no_speech_threshold NO_SPEECH_THRESHOLD if the probability of the \u003c|nospeech|\u003e token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence (default: 0.6) --word_timestamps WORD_TIMESTAMPS (experimental) extract word-level timestamps and refine the results based on them (default: False) --prepend_punctuations PREPEND_PUNCTUATIONS if word_timestamps is True, merge these punctuation symbols with the next word (default: \"'“¿([{-) --append_punctuations APPEND_PUNCTUATIONS if word_timestamps is True, merge these punctuation symbols with the previous word (default: \"'.。,，!！?？:：”)]}、) --highlight_words HIGHLIGHT_WORDS (requires --word_timestamps True) underline each word as it is spoken in srt and vtt (default: False) --max_line_width MAX_LINE_WIDTH (requires --word_timestamps True) the maximum number of characters in a line before breaking the line (default: None) --max_line_count MAX_LINE_COUNT (requires --word_timestamps True) the maximum number of lines in a segment (default: None) --max_words_per_line MAX_WORDS_PER_LINE (requires --word_timestamps True, no effect with --max_line_width) the maximum number of words in a segment (default: None) --threads THREADS number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS (default: 0) --clip_timestamps CLIP_TIMESTAMPS comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process, where the last end timestamp defaults to the end of the file (default: 0) --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD (requires --word_timestamps True) skip silent periods longer than this threshold (in seconds) when a possible hallucination is detected (default: None) Don't Miss: How to Remove or Add 'Where from' Metadata in Files on macOSCover photo, screenshots, and GIFs by Gadget Hacks.",
  "image": "https://assets.content.technologyadvice.com/mac_whisper_cover_9d36cd1d1e.webp",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"contents\" itemprop=\"articleBody\"\u003e \u003cp\u003eTurn your \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://macos.gadgethacks.com/\"\u003eMac\u003c/a\u003e into a powerful transcription machine using the same AI that powers OpenAI\u0026#39;s ChatGPT. With just a few \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://macos.gadgethacks.com/collection/terminal-tips-tricks/\"\u003eTerminal\u003c/a\u003e commands, you can convert audio and video files into accurate text in minutes.\u003c/p\u003e\u003cp\u003eIf you\u0026#39;ve never touched Terminal before, don\u0026#39;t worry — setting up \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://openai.com/index/whisper/\"\u003eWhisper\u003c/a\u003e on \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://macos.gadgethacks.com/collection/macos-15-tips-news/\"\u003emacOS Sequoia 15\u003c/a\u003e is easier than it looks and worth it. Whether you\u0026#39;re working with YouTube videos, interviews, lectures, or voice notes, Whisper can handle all the heavy lifting.\u003c/p\u003e\u003cp\u003eWhisper is a \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://platform.openai.com/docs/guides/speech-to-text\"\u003efree, open-source speech-to-text neural network\u003c/a\u003e from OpenAI that runs entirely on your machine — no internet required after setup. Once you get it going, it\u0026#39;s fast, secure, and dead simple — and it can chew through just about any audio or video format you throw at it. And it\u0026#39;s the perfect tool if you\u0026#39;re sick of glitchy web-based transcription services, expensive Mac apps, and clunky browser extensions with limitations, such as file size caps, watermarks, ads, or lousy accuracy.\u003c/p\u003e\u003cp\u003eYes, it lives in the Terminal — that black box of mystery most folks avoid. But here\u0026#39;s the thing: if you can copy and paste, you can run Whisper. Once it\u0026#39;s installed, transcribing a file is literally one line. There is no bloated interface, no uploading and waiting, and no monthly fee.\u003c/p\u003e\u003cp\u003eAnd if you\u0026#39;re not ready to mess with the command line? You still have options. There are Mac apps like \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://goodsnooze.gumroad.com/l/macwhisper\"\u003eMacWhisper\u003c/a\u003e and \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://apps.apple.com/us/app/whisper-transcription/id1668083311?mt=12\"\u003eWhisper Transcription\u003c/a\u003e that give you a drag-and-drop interface powered by Whisper under the hood. Browser-based services like \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://huggingface.co/spaces/openai/whisper\"\u003eWhisper demo on Hugging Face\u003c/a\u003e make it even easier — though you\u0026#39;ll usually trade some privacy and flexibility for convenience. However, the command-line version is still the most powerful and flexible way to use Whisper, and it\u0026#39;s the official implementation maintained by OpenAI. If you want complete control, this is the version you want.\u003c/p\u003e\u003cp\u003eOr you can skip all of it and just send ChatGPT the file via its \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://chatgpt.com/\"\u003eweb\u003c/a\u003e or \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://openai.com/chatgpt/desktop/\"\u003edesktop app\u003c/a\u003e — it can transcribe or translate it for you using Whisper.\u003c/p\u003e\u003cp\u003eSo if you\u0026#39;re tired of jumping through hoops just to get clean transcripts — whether you\u0026#39;re a student, podcaster, journalist, or just someone trying to archive your Zoom calls — it\u0026#39;s time to take five minutes and set up something that just works. Let\u0026#39;s dive in.\u003c/p\u003e\u003ch2\u003e\u003cspan id=\"jump-requirements\"\u003e\u003c/span\u003eRequirements\u003c/h2\u003e\u003cp\u003eThrough the instructions below, you\u0026#39;ll be installing and using the following tools:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eWhisper command-line tool from OpenAI:\u003c/strong\u003e The core transcription engine that converts speech to text.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eFFmpeg:\u003c/strong\u003e Required for Whisper to open, convert, and process audio and video files.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003ePython 3.10 or later:\u003c/strong\u003e The programming language Whisper is written in.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eHomebrew:\u003c/strong\u003e A package manager that makes installing Whisper, FFmpeg, and Python easy.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo run these tools successfully, you\u0026#39;ll need:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eA Mac running macOS Monterey 12.3 or later:\u003c/strong\u003e Preferably macOS Sequoia 15 or later on an Apple Silicon chip for faster performance.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eAt least 8 GB of RAM and some free disk space:\u003c/strong\u003e Larger Whisper models can use a lot of memory — especially on long files — but smaller models work fine on most setups.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cstrong\u003eTerminal app:\u003c/strong\u003e Preinstalled on macOS — you\u0026#39;ll use it to enter the setup and transcription commands.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e \u003ch2\u003e\u003cspan id=\"jump-settingupwhisperonmacos\"\u003e\u003c/span\u003eSetting up Whisper on macOS\u003c/h2\u003e\u003cp\u003eFollow these steps to install everything you need and start transcribing files. If you already have Homebrew, Python, and FFmpeg installed, it\u0026#39;s still worth checking those steps out to ensure everything is up to date.\u003c/p\u003e \u003ch3 data-ordered=\"\" data-prefix=\"Step\" data-ordered-count=\"1\"\u003e\u003cspan id=\"jump-step1\"\u003e\u003c/span\u003eOpen Terminal on your Mac\u003c/h3\u003e\u003cp\u003eTerminal is the command-line app built into macOS — it’s how you’ll install and run Whisper. You don’t need to know how to code, just how to paste in commands. To open Terminal, press Command + Space, type “Terminal,” and hit Return. You can also find it in the Utilities folder in your Applications directory or in the Other folder in Launchpad.\u003c/p\u003e\u003castro-island uid=\"Z1avaDd\" prefix=\"v23\" component-url=\"https://static.gadgethacks.com/_astro/CarouselArticleImages.BbWvd2o7.js\" component-export=\"default\" renderer-url=\"https://static.gadgethacks.com/_astro/client.CD_APfvn.js\" props=\"{\u0026#34;images\u0026#34;:[1,[[0,\u0026#34;\u0026lt;img src=\\\u0026#34;https://assets.content.technologyadvice.com/other_folder_in_launchpad_c038fbb2be.webp\\\u0026#34; alt=\\\u0026#34;Mac Launchpad’s “Other” folder showing system utility apps like Terminal, Activity Monitor, Disk Utility, and Console, with a magnified focus on the Terminal app icon.\\\u0026#34; srcset=\\\u0026#34;https://assets.content.technologyadvice.com/xsmall_other_folder_in_launchpad_c038fbb2be.webp 64w, https://assets.content.technologyadvice.com/thumbnail_other_folder_in_launchpad_c038fbb2be.webp 230w, https://assets.content.technologyadvice.com/small_other_folder_in_launchpad_c038fbb2be.webp 500w, https://assets.content.technologyadvice.com/medium_other_folder_in_launchpad_c038fbb2be.webp 750w, https://assets.content.technologyadvice.com/large_other_folder_in_launchpad_c038fbb2be.webp 1000w\\\u0026#34; sizes=\\\u0026#34;(min-width: 768px) 80vw, 100vw\\\u0026#34; data-id=\\\u0026#34;632004\\\u0026#34;\u0026gt;\u0026#34;]]]}\" ssr=\"\" client=\"visible\" opts=\"{\u0026#34;name\u0026#34;:\u0026#34;CarouselArticleImages\u0026#34;,\u0026#34;value\u0026#34;:true}\" await-children=\"\"\u003e\u003c/astro-island\u003e \u003ch3 data-ordered=\"\" data-prefix=\"Step\" data-ordered-count=\"2\"\u003e\u003cspan id=\"jump-step2\"\u003e\u003c/span\u003eInstall or update Homebrew\u003c/h3\u003e\u003cp\u003eHomebrew is a package manager for macOS — like the App Store but for powerful command-line tools. It makes it easy to install everything Whisper needs behind the scenes.\u003c/p\u003e\u003cp\u003eIf you don\u0026#39;t have Homebrew installed, paste this command and press Return:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003e/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34;\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThis command may look intimidating, but here\u0026#39;s what it all means:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003e/bin/bash -c\u003c/code\u003e tells your Mac to run a command in the Bash shell.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe part in quotes — \u003ccode\u003e\u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34;\u003c/code\u003e — uses \u003ccode\u003ecurl\u003c/code\u003e (a tool that fetches files from the internet) to download Homebrew\u0026#39;s official installer script from GitHub.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eHere\u0026#39;s what those flags mean:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003e-f\u003c/code\u003e = fail silently on errors.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003e-s\u003c/code\u003e = run silently (don\u0026#39;t show the download progress bar).\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003e-S\u003c/code\u003e = show errors if any occur (used with \u003ccode\u003e-s\u003c/code\u003e).\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003e-L\u003c/code\u003e = follow redirects automatically.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe whole script installs Homebrew safely and automatically.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf Homebrew is already installed, update it by running:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ebrew update\u003c/code\u003e\u003c/pre\u003e \u003ch3 data-ordered=\"\" data-prefix=\"Step\" data-ordered-count=\"3\"\u003e\u003cspan id=\"jump-step3\"\u003e\u003c/span\u003eInstall Python 3.10 (or newer)\u003c/h3\u003e\u003cp\u003ePython is the programming language Whisper is written in. Apple includes an older version on macOS, but Whisper needs a newer one to run properly. Homebrew makes it easy to install the correct version.\u003c/p\u003e\u003cp\u003eWhisper requires Python 3.10 or above. Install it with:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ebrew install python\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf you already have Python installed but aren\u0026#39;t sure if it\u0026#39;s the right version, check it with:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003epython3 --version\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf it\u0026#39;s older than 3.10, you can upgrade it with:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ebrew upgrade python\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou\u0026#39;re good to go once you\u0026#39;re on Python 3.10 or newer.\u003c/p\u003e \u003ch3 data-ordered=\"\" data-prefix=\"Step\" data-ordered-count=\"4\"\u003e\u003cspan id=\"jump-step4\"\u003e\u003c/span\u003eInstall FFmpeg\u003c/h3\u003e\u003cp\u003eFFmpeg is a tool for processing audio and video files. It helps Whisper handle all kinds of media formats, such as MP3, MP4, M4A, and WAV. Without FFmpeg, Whisper can\u0026#39;t read or convert your files.\u003c/p\u003e\u003cp\u003eTo install it using Homebrew:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ebrew install ffmpeg\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf you already have FFmpeg installed, make sure it\u0026#39;s up to date:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ebrew upgrade ffmpeg\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can verify that FFmpeg is working by running:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003effmpeg -version\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf it prints version info, you\u0026#39;re good.\u003c/p\u003e \u003ch3 data-ordered=\"\" data-prefix=\"Step\" data-ordered-count=\"5\"\u003e\u003cspan id=\"jump-step5\"\u003e\u003c/span\u003eInstall Whisper via pip\u003c/h3\u003e\u003cp\u003ePip is Python\u0026#39;s built-in package manager — it\u0026#39;s how you install Python apps like Whisper. You\u0026#39;ll use pip to download and install Whisper directly from OpenAI\u0026#39;s GitHub repository.\u003c/p\u003e\u003cp\u003eFirst, make sure pip is up to date:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003epip3 install --upgrade pip\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen install Whisper:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003epip3 install git+https://github.com/openai/whisper.git\u003c/code\u003e\u003c/pre\u003e \u003ch3 data-ordered=\"\" data-prefix=\"Step\" data-ordered-count=\"6\"\u003e\u003cspan id=\"jump-step6\"\u003e\u003c/span\u003eRun a transcription with Whisper\u003c/h3\u003e\u003cp\u003eOnce Whisper is installed, you can transcribe audio and video files (MP3, MP4, M4A, WAV, and more) using a single command. It supports a range of pretrained models, from lightweight and fast to large and highly accurate.\u003c/p\u003e\u003cp\u003eAudio files are transcribed much faster than video files, so you may want to extract the audio from your videos and use that with Whisper instead — especially when working with a larger model. On a Mac, you can quickly export audio from a video file using QuickTime Player.\u003c/p\u003e \u003ch4\u003e\u003cspan id=\"jump-basicusageauto-detectslanguage\"\u003e\u003c/span\u003e\u003cstrong\u003eBasic usage (auto-detects language)\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eThe \u003ccode\u003e--model tiny\u003c/code\u003e option runs the fastest and uses the least memory, while the \u003ccode\u003e--model large\u003c/code\u003e option offers the best accuracy but requires significantly more RAM and takes longer to process.\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ewhisper your_file.mp4 --model tiny\nwhisper your_file.mp4 --model base\nwhisper your_file.mp4 --model small\nwhisper your_file.mp4 --model medium\nwhisper your_file.mp4 --model large\u003c/code\u003e\u003c/pre\u003e \u003ch4\u003e\u003cspan id=\"jump-specifylanguageforfastermoreaccurateresults\"\u003e\u003c/span\u003e\u003cstrong\u003eSpecify language for faster, more accurate results\u003c/strong\u003e\u003c/h4\u003e\u003cp\u003eIf you know your file is in English, you can specify it using \u003ccode\u003e--language en\u003c/code\u003e or \u003ccode\u003e--language English\u003c/code\u003e:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ewhisper your_file.mp4 --language English --model tiny\nwhisper your_file.mp4 --language English --model base\nwhisper your_file.mp4 --language English --model small\nwhisper your_file.mp4 --language English --model medium\nwhisper your_file.mp4 --language English --model large\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen using one of the commands above, the output will print directly in the same Terminal window.\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://i.giphy.com/N5gkRHm57G1UDVmON9.gif\" sizes=\"(min-width: 768px) 80vw, 100vw\"/\u003e\u003c/p\u003e\u003cp\u003eHowever, Whisper can create .txt (plain transcript), .srt (standard subtitle format used by most video players and editors), and .vtt (Web Video Text Tracks format used for HTML5 video, YouTube, etc.) transcription files in the same directory as the original media file. If needed, add flags like \u003ccode\u003e--output_format txt\u003c/code\u003e (to specify a specific format) or \u003ccode\u003e--task translate\u003c/code\u003e (which automatically translates foreign languages into English).\u003c/p\u003e\u003cp\u003eFor example, the following transcribes the file in English and outputs it to a .txt document in the same directory.\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ewhisper your_file.mp4 --language en --model small --output_format txt\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTo generate subtitles for a foreign-language video in English, the following command will generate .txt, .srt, and .vtt transcription files in the same folder as your video or audio file.\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ewhisper your_file.mp4 --task translate --model medium\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWant just subtitle files (like .srt) and not the plain text transcript? Run:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ewhisper your_file.mp4 --language en --task translate --output_format srt\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTo see all available options:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ewhisper --help\u003c/code\u003e\u003c/pre\u003e \u003ch2\u003e\u003cspan id=\"jump-finalthoughts\"\u003e\u003c/span\u003eFinal thoughts\u003c/h2\u003e\u003cp\u003eWhisper in Terminal isn\u0026#39;t just a transcription tool — it\u0026#39;s a secret weapon for creators, journalists, students, and anyone who deals with spoken content. The setup process might feel a bit technical the first time, but once it\u0026#39;s up and running, it\u0026#39;s incredibly simple to use.\u003c/p\u003e\u003cp\u003eThat said, Whisper models run locally and can be slow, depending on your Mac\u0026#39;s hardware. If you work with large files and want faster results, stick to the tiny or base models. If you need higher accuracy and don\u0026#39;t mind the extra processing time, go for medium or large.\u003c/p\u003e \u003ch2\u003e\u003cspan id=\"jump-fulllistofwhisperargumentsandoptions\"\u003e\u003c/span\u003eFull list of Whisper arguments and options\u003c/h2\u003e\u003cp\u003eIf you want to explore everything Whisper can do — including output formats, language support, and advanced flags — you can run \u003ccode\u003ewhisper --help\u003c/code\u003e in Terminal. Here\u0026#39;s the complete list of available options for quick reference:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003eusage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n               [--output_dir OUTPUT_DIR]\n               [--output_format {txt,vtt,srt,tsv,json,all}]\n               [--verbose VERBOSE] [--task {transcribe,translate}]\n               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n               [--temperature TEMPERATURE] [--best_of BEST_OF]\n               [--beam_size BEAM_SIZE] [--patience PATIENCE]\n               [--length_penalty LENGTH_PENALTY]\n               [--suppress_tokens SUPPRESS_TOKENS]\n               [--initial_prompt INITIAL_PROMPT]\n               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n               [--fp16 FP16]\n               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n               [--logprob_threshold LOGPROB_THRESHOLD]\n               [--no_speech_threshold NO_SPEECH_THRESHOLD]\n               [--word_timestamps WORD_TIMESTAMPS]\n               [--prepend_punctuations PREPEND_PUNCTUATIONS]\n               [--append_punctuations APPEND_PUNCTUATIONS]\n               [--highlight_words HIGHLIGHT_WORDS]\n               [--max_line_width MAX_LINE_WIDTH]\n               [--max_line_count MAX_LINE_COUNT]\n               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n               [--clip_timestamps CLIP_TIMESTAMPS]\n               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n               audio [audio ...]\n\npositional arguments:\n  audio                 audio file(s) to transcribe\n\noptions:\n  -h, --help            show this help message and exit\n  --model MODEL         name of the Whisper model to use (default: turbo)\n  --model_dir MODEL_DIR\n                        the path to save model files; uses ~/.cache/whisper by\n                        default (default: None)\n  --device DEVICE       device to use for PyTorch inference (default: cpu)\n  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n                        directory to save the outputs (default: .)\n  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n                        format of the output file; if not specified, all\n                        available formats will be produced (default: all)\n  --verbose VERBOSE     whether to print out the progress and debug messages\n                        (default: True)\n  --task {transcribe,translate}\n                        whether to perform X-\u0026gt;X speech recognition\n                        (\u0026#39;transcribe\u0026#39;) or X-\u0026gt;English translation (\u0026#39;translate\u0026#39;)\n                        (default: transcribe)\n  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n                        language spoken in the audio, specify None to perform\n                        language detection (default: None)\n  --temperature TEMPERATURE\n                        temperature to use for sampling (default: 0)\n  --best_of BEST_OF     number of candidates when sampling with non-zero\n                        temperature (default: 5)\n  --beam_size BEAM_SIZE\n                        number of beams in beam search, only applicable when\n                        temperature is zero (default: 5)\n  --patience PATIENCE   optional patience value to use in beam decoding, as in\n                        https://arxiv.org/abs/2204.05424, the default (1.0) is\n                        equivalent to conventional beam search (default: None)\n  --length_penalty LENGTH_PENALTY\n                        optional token length penalty coefficient (alpha) as\n                        in https://arxiv.org/abs/1609.08144, uses simple\n                        length normalization by default (default: None)\n  --suppress_tokens SUPPRESS_TOKENS\n                        comma-separated list of token ids to suppress during\n                        sampling; \u0026#39;-1\u0026#39; will suppress most special characters\n                        except common punctuations (default: -1)\n  --initial_prompt INITIAL_PROMPT\n                        optional text to provide as a prompt for the first\n                        window. (default: None)\n  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n                        if True, provide the previous output of the model as a\n                        prompt for the next window; disabling may make the\n                        text inconsistent across windows, but the model\n                        becomes less prone to getting stuck in a failure loop\n                        (default: True)\n  --fp16 FP16           whether to perform inference in fp16; True by default\n                        (default: True)\n  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n                        temperature to increase when falling back when the\n                        decoding fails to meet either of the thresholds below\n                        (default: 0.2)\n  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n                        if the gzip compression ratio is higher than this\n                        value, treat the decoding as failed (default: 2.4)\n  --logprob_threshold LOGPROB_THRESHOLD\n                        if the average log probability is lower than this\n                        value, treat the decoding as failed (default: -1.0)\n  --no_speech_threshold NO_SPEECH_THRESHOLD\n                        if the probability of the \u0026lt;|nospeech|\u0026gt; token is higher\n                        than this value AND the decoding has failed due to\n                        `logprob_threshold`, consider the segment as silence\n                        (default: 0.6)\n  --word_timestamps WORD_TIMESTAMPS\n                        (experimental) extract word-level timestamps and\n                        refine the results based on them (default: False)\n  --prepend_punctuations PREPEND_PUNCTUATIONS\n                        if word_timestamps is True, merge these punctuation\n                        symbols with the next word (default: \u0026#34;\u0026#39;“¿([{-)\n  --append_punctuations APPEND_PUNCTUATIONS\n                        if word_timestamps is True, merge these punctuation\n                        symbols with the previous word (default:\n                        \u0026#34;\u0026#39;.。,，!！?？:：”)]}、)\n  --highlight_words HIGHLIGHT_WORDS\n                        (requires --word_timestamps True) underline each word\n                        as it is spoken in srt and vtt (default: False)\n  --max_line_width MAX_LINE_WIDTH\n                        (requires --word_timestamps True) the maximum number\n                        of characters in a line before breaking the line\n                        (default: None)\n  --max_line_count MAX_LINE_COUNT\n                        (requires --word_timestamps True) the maximum number\n                        of lines in a segment (default: None)\n  --max_words_per_line MAX_WORDS_PER_LINE\n                        (requires --word_timestamps True, no effect with\n                        --max_line_width) the maximum number of words in a\n                        segment (default: None)\n  --threads THREADS     number of threads used by torch for CPU inference;\n                        supercedes MKL_NUM_THREADS/OMP_NUM_THREADS (default:\n                        0)\n  --clip_timestamps CLIP_TIMESTAMPS\n                        comma-separated list start,end,start,end,...\n                        timestamps (in seconds) of clips to process, where the\n                        last end timestamp defaults to the end of the file\n                        (default: 0)\n  --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD\n                        (requires --word_timestamps True) skip silent periods\n                        longer than this threshold (in seconds) when a\n                        possible hallucination is detected (default: None)\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote data-type=\"pullquote\"\u003e\u003cp\u003e\u003cstrong\u003eDon\u0026#39;t Miss: \u003c/strong\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://macos.gadgethacks.com/how-to/remove-add-where-from-metadata-files-macos-0385559/\"\u003e\u003cstrong\u003eHow to Remove or Add \u0026#39;Where from\u0026#39; Metadata in Files on macOS\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003e\u003cem\u003eCover photo, screenshots, and GIFs by Gadget Hacks.\u003c/em\u003e\u003c/p\u003e \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "21 min read",
  "publishedTime": null,
  "modifiedTime": null
}
