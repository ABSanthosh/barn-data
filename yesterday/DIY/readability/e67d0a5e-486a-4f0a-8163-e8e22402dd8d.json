{
  "id": "e67d0a5e-486a-4f0a-8163-e8e22402dd8d",
  "title": "Your PC Can’t Handle Meta’s New Llama AI Model (Probably)",
  "link": "https://www.howtogeek.com/meta-llama-3-3-70b-release/",
  "description": "It's smaller than Meta's 405B model, but that doesn't make it small.",
  "author": "Corbin Davenport",
  "published": "Fri, 06 Dec 2024 21:34:39 GMT",
  "source": "https://www.howtogeek.com/feed/",
  "categories": [
    "Cutting Edge",
    "ai",
    "Meta"
  ],
  "byline": "Corbin Davenport",
  "length": 9029,
  "excerpt": "It's smaller than Meta's 405B model, but that doesn't make it small.",
  "siteName": "How-To Geek",
  "favicon": "https://www.howtogeek.com/public/build/images/favicon-240x240.f06f736a.png",
  "text": "AI (Artificial Intelligence) Sign in to your How-To Geek account DALL-E Meta has released Llama 3.3 70B, a modified version of the company’s most powerful AI model that can be downloaded to run on your own hardware. Your PC probably isn’t ready for it, though. Like many other large language models (LLMs), Meta’s Llama generative AI model is available in several parameter sizes for different use cases. For example, the smallest Llama 3.2 1B model can handle basic tasks with fast performance on the average smartphone, while the larger 11B and 90B versions are more powerful and need higher-end PCs and servers. The Llama models are primarily intended for text and chat functionality, but some versions can understand images too. Meta’s new Llama 3.3 70B model is supposed to offer the same performance as the company’s largest model, the 405B version, but with the ability to run on more PCs and servers. Meta’s VP of generative AI said in a social media post, “By leveraging the latest advancements in post-training techniques including online preference optimization, this model improves core performance at a significantly lower cost.” Even though this new 70B model is significantly shrunk down from the original 405B version, you’ll still need a beefy PC or server to run it locally with acceptable performance. The file size is 37.14 GB, and LLMs generally need to fit in RAM to run well, so you’d probably need a machine with 64 GB RAM. You would also need a powerful GPU (or several paired together) for running the model. The model’s description explains, “Llama 3.3 is intended for commercial and research use in multiple languages. Instruction tuned text only models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks. The Llama 3.3 model also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation.” Even though Llama 3.3 70B won’t run on most computing hardware, you can run the smaller 1B, 3B, and 8B on many desktops and laptops with apps like LM Studio or Nvidia’s Chat With RTX. My 16GB M1 Mac Mini runs Llama 3.1 8B at similar speeds as cloud-based AI chatbots, but I use smaller 3B models with my 8GB MacBook Air, since I have less RAM available. You can download Llama 3.3 70B and the other Lama models from Meta’s website, Hugging Face, the built-in search in LM Studio, and other repositories. Source: TechCrunch",
  "image": "https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n        \n        \n\n            \u003carticle\u003e\n\n        \n                \n    \n\n\n\n    \n    \n    \n        \n           \u003cheader\u003e\n            \n                                                \n\n\n    \n                           \n            \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n    \n        \n    \n        \n                            \n\n            \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n    \n        \n    \n        \n                            \n            \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n    \n        \n    \n                    \n\n        \u003ca href=\"https://www.howtogeek.com/tag/ai/\"\u003e\u003cspan\u003eAI (Artificial Intelligence)\u003c/span\u003e\u003c/a\u003e\n\n\u003cdiv\u003e\n                            \u003cp\u003e\u003cimg src=\"https://static1.howtogeekimages.com/wordpress%2Fwp-content%2Fauthors%2F6699298a4dee1-Corbin%20Davenport%20500px%20Square.jpg?fit=crop\u0026amp;w=90\u0026amp;h=90\" alt=\"4\" loading=\"lazy\" decoding=\"async\"/\u003e\n                                    \u003c/p\u003e\n                    \u003c/div\u003e\n\n            \n\n    \n\n            \u003ca id=\"login-button-article-sidebar\"\u003e\n            \u003cp\u003eSign in to your \u003cspan\u003eHow-To Geek\u003c/span\u003e account\u003c/p\u003e\n            \n        \u003c/a\u003e\n            \n                                \n                                    \n                                                                                                                        \n                                            \n                                                    \n    \u003cdiv data-img-url=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;DALL-E\u0026#34;\"\u003e\n\n        \n    \n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n            \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=70\u0026amp;fit=crop\u0026amp;w=1100\u0026amp;h=618\u0026amp;dpr=1\" srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=70\u0026amp;fit=crop\u0026amp;w=1100\u0026amp;h=618\u0026amp;dpr=1\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n            \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=49\u0026amp;fit=crop\u0026amp;w=943\u0026amp;h=530\u0026amp;dpr=2\" srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=49\u0026amp;fit=crop\u0026amp;w=943\u0026amp;h=530\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n            \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=49\u0026amp;fit=crop\u0026amp;w=767\u0026amp;h=431\u0026amp;dpr=2\" srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=49\u0026amp;fit=crop\u0026amp;w=767\u0026amp;h=431\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n            \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=49\u0026amp;fit=crop\u0026amp;w=480\u0026amp;h=270\u0026amp;dpr=2\" srcset=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg?q=49\u0026amp;fit=crop\u0026amp;w=480\u0026amp;h=270\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"2100\" height=\"1400\" alt=\"An illustration of a llama popping out of a laptop.\" data-img-url=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg\" src=\"https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/12/llama.jpg\"/\u003e\n    \u003c/picture\u003e\n                                        \u003cfigcaption\u003eDALL-E\u003c/figcaption\u003e\n                        \n    \u003c/figure\u003e\n\n\n    \u003c/div\u003e\n\n\n            \n                \n    \n    \n        \n    \n\n    \n            \u003c/header\u003e\n\n                                                        \n        \n\n        \n                                        \n                                \n            \n                        \n        \n        \n\n    \n            \n    \n                                                            \n            \n    \n    \n                                                                            \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n                                                    \n                        \n    \n                                                        \n                                                                                                                                    \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n                                                        \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n                                                        \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n                                                        \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n                                                        \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n                                                        \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n                \n    \n    \n        \n    \n\n    \n    \n            \n    \n    \n            \n    \n    \n                                                        \n                                \n                                \n                                                \n            \n        \n    \n        \n                                                                                                                                                                    \n            \n    \n    \n        \n                    \n                        \n                                    \u003cdiv id=\"article-body\" itemprop=\"articleBody\"\u003e\n\u003cp\u003eMeta has released Llama 3.3 70B, a modified version of the company’s most powerful AI model that can be downloaded to run on your own hardware. Your PC probably isn’t ready for it, though.\u003c/p\u003e    \n\u003cp\u003eLike many other \u003ca href=\"https://www.howtogeek.com/what-is-an-llm-how-ai-holds-conversations/\" target=\"_blank\"\u003elarge language models (LLMs)\u003c/a\u003e, Meta’s Llama generative AI model is available in several parameter sizes for different use cases. For example, the smallest Llama 3.2 1B model can handle basic tasks with fast performance on the average smartphone, while the larger 11B and 90B versions are more powerful and need higher-end PCs and servers. The Llama models are primarily intended for text and chat functionality, but \u003ca href=\"https://www.howtogeek.com/meta-llama-3-2-release/\" target=\"_blank\"\u003esome versions can understand images\u003c/a\u003e too.\u003c/p\u003e    \n\u003cp\u003eMeta’s new Llama 3.3 70B model is supposed to offer the same performance as the company’s largest model, the 405B version, but with the ability to run on more PCs and servers. Meta’s VP of generative AI said in a social media post, “By leveraging the latest advancements in post-training techniques including online preference optimization, this model improves core performance at a significantly lower cost.”\u003c/p\u003e    \n\u003cp\u003eEven though this new 70B model is significantly shrunk down from the original 405B version, you’ll still need a beefy PC or server to run it locally with acceptable performance. The file size is 37.14 GB, and LLMs generally need to fit in RAM to run well, so you’d probably need a machine with 64 GB RAM. You would also need a powerful GPU (or several paired together) for running the model.\u003c/p\u003e    \n\u003cp\u003eThe model’s description explains, “Llama 3.3 is intended for commercial and research use in multiple languages. Instruction tuned text only models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks. The Llama 3.3 model also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation.”\u003c/p\u003e    \n\u003cp\u003eEven though Llama 3.3 70B won’t run on most computing hardware, you can run the smaller 1B, 3B, and 8B on many desktops and laptops with apps like \u003ca href=\"https://www.howtogeek.com/you-can-run-dozens-of-different-ai-chat-bots-on-your-pc-with-this-app/\" target=\"_blank\"\u003eLM Studio\u003c/a\u003e or \u003ca href=\"https://blogs.nvidia.com/blog/chat-with-rtx-available-now/\" target=\"_blank\"\u003eNvidia’s Chat With RTX\u003c/a\u003e. My 16GB M1 Mac Mini runs Llama 3.1 8B at similar speeds as cloud-based AI chatbots, but I use smaller 3B models with my 8GB MacBook Air, since I have less RAM available.\u003c/p\u003e    \n\u003cp\u003eYou can download Llama 3.3 70B and the other Lama models from \u003ca href=\"https://www.llama.com/\" target=\"_blank\"\u003eMeta’s website\u003c/a\u003e, \u003ca href=\"https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct\" target=\"_blank\"\u003eHugging Face\u003c/a\u003e, the built-in search in LM Studio, and other repositories.\u003c/p\u003e    \n\u003cp\u003eSource: \u003ca href=\"https://techcrunch.com/2024/12/06/meta-unveils-a-new-more-efficient-llama-model/\" target=\"_blank\"\u003eTechCrunch\u003c/a\u003e\u003c/p\u003e    \u003c/div\u003e\n    \n        \n\n    \n\n        \n\n\n                \n        \n        \n\n\n        \n\n\n\n\n\n                    \n        \n    \u003c/article\u003e\n\n    \n        \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2024-12-06T21:34:39Z",
  "modifiedTime": "2024-12-06T21:34:39Z"
}
