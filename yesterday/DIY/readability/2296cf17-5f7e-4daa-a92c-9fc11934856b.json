{
  "id": "2296cf17-5f7e-4daa-a92c-9fc11934856b",
  "title": "Hackaday Links: February 23, 2025",
  "link": "https://hackaday.com/2025/02/23/hackaday-links-february-23-2025/",
  "description": "Ho-hum — another week, another high-profile bricking. In a move anyone could see coming, Humane has announced that their pricey AI Pin widgets will cease to work in any meaningful …read more",
  "author": "Dan Maloney",
  "published": "Mon, 24 Feb 2025 00:00:37 +0000",
  "source": "https://hackaday.com/blog/feed/",
  "categories": [
    "Hackaday Columns",
    "Hackaday links",
    "ai",
    "AI Pin",
    "astronomy",
    "brick",
    "chatbot",
    "cognitive decline",
    "dementia",
    "failure",
    "hackaday links",
    "LLM",
    "Montreal Cognitive Assesment",
    "radio quiet",
    "reflection",
    "wearable"
  ],
  "byline": "",
  "length": 4245,
  "excerpt": "Ho-hum — another week, another high-profile bricking. In a move anyone could see coming, Humane has announced that their pricey AI Pin widgets will cease to work in any meaningful way as of n…",
  "siteName": "Hackaday",
  "favicon": "https://hackaday.com/wp-content/themes/hackaday-2/img/hackaday-logo_1024x1024.png?v=3",
  "text": "Ho-hum — another week, another high-profile bricking. In a move anyone could see coming, Humane has announced that their pricey AI Pin widgets will cease to work in any meaningful way as of noon on February 28. The company made a splash when it launched its wearable assistant in April of 2024, and from an engineering point of view, it was pretty cool. Meant to be worn on one’s shirt, it had a little bit of a Star Trek: The Next Generation comm badge vibe as the primary UI was accessed through tapping the front of the thing. It also had a display that projected information onto your hand, plus the usual array of sensors and cameras which no doubt provided a rich stream of user data. Somehow, though, Humane wasn’t able to make the numbers work out, and as a result they’ll be shutting down their servers at the end of the month, with refunds offered only to users who bought their AI Pins in the last 90 days. How exactly Humane thought that offering what amounts to a civilian badge cam was going to be a viable business model is a bit of a mystery. Were people really going to be OK walking into a meeting where Pin-wearing coworkers could be recording everything they say? Wouldn’t wearing a device like that in a gym locker room cause a stir? Sure, the AI Pin was a little less obtrusive than something like the Google Glass — not to mention a lot less goofy — but all wearables seem to suffer the same basic problem: they’re too obvious. About the only one that comes close to passing that hurdle is the Meta Ray-Ban smart glasses, and those still have the problem of obvious cameras built into their chunky frames. Plus, who can wear Ray-Bans all the time without looking like a tool? Good news for everyone worried about a world being run by LLMs and chatbots. It looks like all we’re going to have to do is wait them out, if a study finding that older LLMs are already showing signs of cognitive decline pans out. To come to that conclusion, researchers gave the Montreal Cognitive Assessment test to a bunch of different chatbots. The test uses simple questions to screen for early signs of impairment; some of the questions seem like something from a field sobriety test, and for good reason. Alas for the tested chatbots, the general trend was that the older the model, the poorer they did on the test. The obvious objection here is that the researchers aren’t comparing each model’s current score with results from when the model was “younger,” but that’s pretty much what happens when the test is used for humans. You’ve got to feel sorry for astronomers. Between light pollution cluttering up the sky and an explosion in radio frequency interference, astronomers face observational challenges across the spectrum. These challenges are why astronomers prize areas like dark sky reserves, where light pollution is kept to a minimum, and radio quiet zones, which do the same for the RF part of the spectrum. Still, it’s a busy world, and noise always seems to find a way to leak into these zones. A case in point is the recent discovery that TV signals that had been plaguing the Murchison Wide-field Array in Western Australia for five years were actually bouncing off airplanes. The MWA is in a designated radio quiet zone, so astronomers were perplexed until someone had the bright idea to use the array’s beam-forming capabilities to trace the signal back to its source. The astronomers plan to use the method to identify and exclude other RFI getting into their quiet zone, both from terrestrial sources and from the many satellites whizzing overhead. And finally, most of us are more comfortable posting our successes online than our failures, and for obvious reasons. Everyone loves a winner, after all, and admitting our failures publicly can be difficult. But Daniel Dakhno finds value in his failures, to the point where he’s devoted a special section of his project portfolio to them. They’re right there at the bottom of the page for anyone to see, meticulously organized by project type and failure mode. Each failure assessment includes an estimate of the time it took; importantly, Daniel characterizes this as “time invested” rather than “time wasted.” When you fall down, you should pick something up, right?",
  "image": "https://hackaday.com/wp-content/uploads/2014/11/had-links-banner.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"content\"\u003e\n        \u003cmain id=\"main\" role=\"main\"\u003e\n\n        \n            \n\u003carticle itemscope=\"\" itemtype=\"http://schema.org/Article\" id=\"post-759166\"\u003e\n    \n\n    \u003cdiv itemprop=\"articleBody\"\u003e\n        \u003cp\u003eHo-hum — another week, \u003ca href=\"https://arstechnica.com/gadgets/2025/02/truly-a-middle-finger-humane-bricking-700-ai-pins-with-limited-refunds\" target=\"_blank\"\u003eanother high-profile bricking\u003c/a\u003e. In a move anyone could see coming, Humane has announced that their pricey AI Pin widgets will cease to work in any meaningful way as of noon on February 28. The company made a splash when it launched its wearable assistant in April of 2024, and from an engineering point of view, it was pretty cool. Meant to be worn on one’s shirt, it had a little bit of a \u003cem\u003eStar Trek: The Next Generation\u003c/em\u003e comm badge vibe as the primary UI was accessed through tapping the front of the thing. It also had a display that projected information onto your hand, plus the usual array of sensors and cameras which no doubt provided a rich stream of user data. Somehow, though, Humane wasn’t able to make the numbers work out, and as a result they’ll be shutting down their servers at the end of the month, with refunds offered only to users who bought their AI Pins in the last 90 days.\u003c/p\u003e\n\n\u003cp\u003eHow exactly Humane thought that offering what amounts to a civilian badge cam was going to be a viable business model is a bit of a mystery. Were people really going to be OK walking into a meeting where Pin-wearing coworkers could be recording everything they say? Wouldn’t wearing a device like that in a gym locker room cause a stir? Sure, the AI Pin was a little less obtrusive than something like the Google Glass — not to mention a lot less goofy — but all wearables seem to suffer the same basic problem: they’re too obvious. About the only one that comes close to passing that hurdle is the Meta Ray-Ban smart glasses, and those still have the problem of obvious cameras built into their chunky frames. Plus, who can wear Ray-Bans all the time without looking like a tool?\u003c/p\u003e\n\u003cp\u003eGood news for everyone worried about a world being run by LLMs and chatbots. It looks like all we’re going to have to do is wait them out, if a \u003ca href=\"https://www.livescience.com/technology/artificial-intelligence/older-ai-models-show-signs-of-cognitive-decline-study-shows\" target=\"_blank\"\u003estudy finding that older LLMs are already showing signs of cognitive decline\u003c/a\u003e pans out. To come to that conclusion, researchers gave the Montreal Cognitive Assessment test to a bunch of different chatbots. The test uses simple questions to screen for early signs of impairment; some of the questions seem like something from a field sobriety test, and for good reason. Alas for the tested chatbots, the general trend was that the older the model, the poorer they did on the test. The obvious objection here is that the researchers aren’t comparing each model’s current score with results from when the model was “younger,” but that’s pretty much what happens when the test is used for humans.\u003c/p\u003e\n\u003cp\u003eYou’ve got to feel sorry for astronomers. Between light pollution cluttering up the sky and an explosion in radio frequency interference, astronomers face observational challenges across the spectrum. These challenges are why astronomers prize areas like dark sky reserves, where light pollution is kept to a minimum, and \u003ca href=\"https://hackaday.com/2016/04/13/all-quiet-on-the-west-virginia-border-the-national-radio-quiet-zone/\"\u003eradio quiet zones\u003c/a\u003e, which do the same for the RF part of the spectrum. Still, it’s a busy world, and noise always seems to find a way to leak into these zones. A case in point is the recent discovery that TV signals that had been plaguing the Murchison Wide-field Array in Western Australia for five years were \u003ca href=\"https://www.space.com/space-exploration/tech/astronomers-realize-mysterious-tv-signal-in-their-data-bounced-off-an-airplane\" target=\"_blank\"\u003eactually bouncing off airplanes\u003c/a\u003e. The MWA is in a designated radio quiet zone, so astronomers were perplexed until someone had the bright idea to use the array’s beam-forming capabilities to trace the signal back to its source. The astronomers plan to use the method to identify and exclude other RFI getting into their quiet zone, both from terrestrial sources and from the many satellites whizzing overhead.\u003c/p\u003e\n\u003cp\u003eAnd finally, most of us are more comfortable posting our successes online than our failures, and for obvious reasons. Everyone loves a winner, after all, and admitting our failures publicly can be difficult. But Daniel Dakhno finds value in his failures, to the point where \u003ca href=\"https://daniel.dakhno.de/\" target=\"_blank\"\u003ehe’s devoted a special section of his project portfolio to them\u003c/a\u003e. They’re right there at the bottom of the page for anyone to see, meticulously organized by project type and failure mode. Each failure assessment includes an estimate of the time it took; importantly, Daniel characterizes this as “time invested” rather than “time wasted.” When you fall down, you should pick something up, right?\u003c/p\u003e\n\t            \u003c/div\u003e\n    \u003cul\u003e\n    \t\t\t\t\t\u003cli\u003e\n    \t\t\t\t\u003ca href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fhackaday.com%2F2025%2F02%2F23%2Fhackaday-links-february-23-2025%2F\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_face.png\"/\u003e \u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n                        \u003ca href=\"https://twitter.com/intent/tweet?text=Hackaday%20Links:%20February%2023,%202025%20via%20@hackaday\u0026amp;url=https://hackaday.com/2025/02/23/hackaday-links-february-23-2025/\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_twitter.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n    \t\t\t\t\u003ca href=\"https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fhackaday.com%2F2025%2F02%2F23%2Fhackaday-links-february-23-2025%2F\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_in.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n                \u003ca href=\"mailto:?subject=Hackaday+Links%3A+February+23%2C+2025 | Hackaday\u0026amp;body=https%3A%2F%2Fhackaday.com%2F2025%2F02%2F23%2Fhackaday-links-february-23-2025%2F\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_mail1.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\u003c/ul\u003e\n    \n\u003c/article\u003e\n\n            \t\n\t\n            \n\n            \n\n\n        \n        \n\n        \n        \n\n        \n        \u003c/main\u003e\n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-02-24T00:00:37Z",
  "modifiedTime": "2025-02-23T17:34:32Z"
}
