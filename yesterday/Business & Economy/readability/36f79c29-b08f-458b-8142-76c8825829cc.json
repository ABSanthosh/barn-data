{
  "id": "36f79c29-b08f-458b-8142-76c8825829cc",
  "title": "Why Nvidia, Broadcom, Microsoft, and Other Artificial Intelligence (AI) Stocks Crashed Monday Morning",
  "link": "https://finance.yahoo.com/news/why-nvidia-broadcom-microsoft-other-172700731.html",
  "description": "",
  "author": "",
  "published": "2025-01-27T17:27:00Z",
  "source": "https://finance.yahoo.com/news/rssindex",
  "categories": null,
  "byline": "Danny Vena, The Motley Fool",
  "length": 3831,
  "excerpt": "Unexpected results from an AI upstart have sent these stocks reeling.",
  "siteName": "Yahoo Finance",
  "favicon": "https://s.yimg.com/cv/apiv2/default/finance/favicon-180x180.png",
  "text": "One of the biggest market drivers of technology stocks over the past couple of years has been rapid advancements in the field of artificial intelligence (AI). These next-generation algorithms took a giant leap forward from their predecessors, promising to streamline processes and improve productivity. Many big tech companies have been spending heavily to get a jump on the technology. But a Chinese start-up called DeepSeek may have just upended conventional thinking about how best to train AI models. As a result, a slew of AI stocks tumbled on Monday. AI-centric chipmaker Nvidia (NASDAQ: NVDA) crashed 17.3%, semiconductor specialist Broadcom (NASDAQ: AVGO) crumbled 16.4%, cloud and software giant Microsoft (NASDAQ: MSFT) slumped 3.8%, and cloud computing and search titan Alphabet (NASDAQ: GOOGL) (NASDAQ: GOOG) fell 2.8%, as of 11:43 a.m. ET. Image source: Getty Images. One-year-old Chinese start-up DeepSeek introduced its latest AI model, dubbed R1, and its abilities caught many in the tech world off guard. The performance of the system, which is similar to OpenAI's ChatGPT, quickly ascended the ranks to become one of the top 10 in the world. What made these results even more striking was that they were achieved with older-generation processors at a much lower cost, according to the company. DeepSeek achieved these remarkable results by taking a new approach to training its AI models. The process, known as reinforcement learning -- or reward-driven optimization -- appears to be more adept at refining its strategy for problem-solving or attempting different approaches to achieve the desired results. Thus far, one of the biggest challenges with AI is not knowing how the algorithms arrived at a particular conclusion, making them a \"black box.\" DeepSeek's R1 model shows its work, thus eliminating the uncertainty. Venture capitalist and well-known tech aficionado Marc Andreessen fueled the fire this weekend when he posted on X (formerly Twitter) that \"DeepSeek R1 is one of the most amazing and impressive breakthroughs I've ever seen -- and as open source, a profound gift to the world.\" To be clear, experts say that DeepSeek's R1 still trails the performance capability of models produced by OpenAI and Alphabet, but the fact that it was able to do so with a smaller number of inferior chips threatened to upend the existing paradigm. AI stocks and the broader tech sector plunged on the news, reeling from the potential implications for the industry: Nvidia is the gold standard and leading provider of the graphics processing units (GPUs) used to train and run AI systems. The company is believed to control as much as 98% of the data center GPU market, according to semiconductor analyst firm TechInsights. If AI models can be trained on lower-cost, inferior chips, Nvidia has a lot to lose. Broadcom supplies many of the networking products that work side-by-side with chips in the data center. The company's Ethernet switching and application-specific integrated circuits (ASICs) help facilitate the movement of data. If demand for these high-end chips falters, sales of ancillary products -- like those in Broadcom's arsenal -- could suffer as well. Microsoft helped kick-start the AI revolution with its hefty $13 billion investment in OpenAI and by integrating its AI capabilities across its suite of products and services. The company recently announced plans to spend $80 billion on data centers over the coming year. If there's a more cost-effective approach, customers might not be as willing to fork over top dollar for Microsoft's solutions. Alphabet was another company that was quick off the mark, spending heavily to develop next-generation AI models for its Google Cloud customers. Like Microsoft, if there are less costly alternatives, Alphabet's results could suffer.",
  "image": "https://s.yimg.com/ny/api/res/1.2/h8idm_mr.ywjdv1F2tK12A--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://media.zenfs.com/en/motleyfool.com/b9c8a792203b6e762796380115d4cadb",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e    \u003cp\u003eOne of the biggest market drivers of technology stocks over the past couple of years has been rapid advancements in the field of artificial intelligence (AI). These next-generation algorithms took a giant leap forward from their predecessors, promising to streamline processes and improve productivity. Many big tech companies have been spending heavily to get a jump on the technology.\u003c/p\u003e  \u003cp\u003eBut a Chinese start-up called DeepSeek may have just upended conventional thinking about how best to train AI models. As a result, a slew of AI stocks tumbled on Monday. AI-centric chipmaker \u003cstrong\u003eNvidia\u003c/strong\u003e \u003cspan\u003e(NASDAQ: NVDA)\u003c/span\u003e crashed 17.3%, semiconductor specialist \u003cstrong\u003eBroadcom\u003c/strong\u003e \u003cspan\u003e(NASDAQ: AVGO)\u003c/span\u003e crumbled 16.4%, cloud and software giant \u003cstrong\u003eMicrosoft\u003c/strong\u003e \u003cspan\u003e(NASDAQ: MSFT)\u003c/span\u003e slumped 3.8%, and cloud computing and search titan \u003cstrong\u003eAlphabet\u003c/strong\u003e \u003cspan\u003e(NASDAQ: GOOGL)\u003c/span\u003e \u003cspan\u003e(NASDAQ: GOOG)\u003c/span\u003e fell 2.8%, as of 11:43 a.m. ET.\u003c/p\u003e \u003cfigure\u003e\u003cdiv\u003e \u003cp\u003e\u003cimg src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==\" alt=\"An angry person with hands outstretched looking at a computer monitor.\" loading=\"eager\" height=\"640\" width=\"960\"/\u003e\u003c/p\u003e\u003c/div\u003e \u003cfigcaption\u003eImage source: Getty Images.  \u003c/figcaption\u003e \u003c/figure\u003e  \u003cp\u003eOne-year-old Chinese start-up DeepSeek introduced its latest AI model, dubbed R1, and its abilities caught many in the tech world off guard. The performance of the system, which is similar to OpenAI\u0026#39;s ChatGPT, quickly ascended the ranks to become one of the top 10 in the world. What made these results even more striking was that they were achieved with older-generation processors at a much lower cost, according to the company.\u003c/p\u003e \u003cp\u003eDeepSeek achieved these remarkable results by taking a new approach to training its AI models. The process, known as reinforcement learning -- or reward-driven optimization -- appears to be more adept at refining its strategy for problem-solving or attempting different approaches to achieve the desired results.\u003c/p\u003e  \u003cp\u003eThus far, one of the biggest challenges with AI is not knowing how the algorithms arrived at a particular conclusion, making them a \u0026#34;black box.\u0026#34; DeepSeek\u0026#39;s R1 model shows its work, thus eliminating the uncertainty.\u003c/p\u003e \u003cp\u003eVenture capitalist and well-known tech aficionado Marc Andreessen fueled the fire this weekend when he posted on X (formerly Twitter) that \u0026#34;DeepSeek R1 is one of the most amazing and impressive breakthroughs I\u0026#39;ve ever seen -- and as open source, a profound gift to the world.\u0026#34;\u003c/p\u003e \u003cp\u003eTo be clear, experts say that DeepSeek\u0026#39;s R1 still trails the performance capability of models produced by OpenAI and Alphabet, but the fact that it was able to do so with a smaller number of inferior chips threatened to upend the existing paradigm.\u003c/p\u003e  \u003cp\u003eAI stocks and the broader tech sector plunged on the news, reeling from the potential implications for the industry:\u003c/p\u003e \u003cul\u003e\u003cli\u003e \u003cp\u003eNvidia is the gold standard and leading provider of the \u003ca href=\"https://www.fool.com/terms/g/gpu/?utm_source=yahoo-host-full\u0026amp;utm_medium=feed\u0026amp;utm_campaign=article\u0026amp;referring_guid=754c4fc7-417a-4ff1-96ed-43d4c54f04ee\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:graphics processing units (GPUs);elm:context_link;itc:0;sec:content-canvas\"\u003egraphics processing units (GPUs)\u003c/a\u003e used to train and run AI systems. The company is believed to control as much as 98% of the data center GPU market, according to semiconductor analyst firm TechInsights. If AI models can be trained on lower-cost, inferior chips, Nvidia has a lot to lose.\u003c/p\u003e \u003c/li\u003e\u003cli\u003e \u003cp\u003eBroadcom supplies many of the networking products that work side-by-side with chips in the data center. The company\u0026#39;s Ethernet switching and application-specific integrated circuits (ASICs) help facilitate the movement of data. If demand for these high-end chips falters, sales of ancillary products -- like those in Broadcom\u0026#39;s arsenal -- could suffer as well.\u003c/p\u003e \u003c/li\u003e\u003cli\u003e \u003cp\u003eMicrosoft helped kick-start the AI revolution with its hefty $13 billion investment in OpenAI and by integrating its AI capabilities across its suite of products and services. The company recently announced plans to spend $80 billion on data centers over the coming year. If there\u0026#39;s a more cost-effective approach, customers might not be as willing to fork over top dollar for Microsoft\u0026#39;s solutions.\u003c/p\u003e \u003c/li\u003e\u003cli\u003e \u003cp\u003eAlphabet was another company that was quick off the mark, spending heavily to develop next-generation AI models for its Google Cloud customers. Like Microsoft, if there are less costly alternatives, Alphabet\u0026#39;s results could suffer.\u003c/p\u003e \u003c/li\u003e \u003c/ul\u003e        \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-01-27T17:27:00Z",
  "modifiedTime": null
}
