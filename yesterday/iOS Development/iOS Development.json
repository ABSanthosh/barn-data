[
  {
    "id": "e593da64-230c-4e68-bb12-1d1623320f18",
    "title": "All Your Brand Are Belong To Us",
    "link": "https://tyler.io/2025/06/all-your-brand-are-belong-to-us/",
    "description": "The last iOS redesign, iOS 7 in 2013, laid the foundation for a neutral, nearly agnostic visual language that third-party developers and companies could build their own brand and corporate design on top of. It was such a clean slate that, twelve years later, most major apps look similar â€” if not identical â€” between ... Read more",
    "author": "Tyler",
    "published": "Thu, 12 Jun 2025 17:30:30 +0000",
    "image": "",
    "source": "https://tyler.io/feed/",
    "categories": [
      "Uncategorized"
    ]
  },
  {
    "id": "8a31a997-c94e-4d91-b91b-5161d01cbb52",
    "title": "minifeed",
    "link": "https://tyler.io/2025/01/minifeed/",
    "description": "I recently discovered minifeed, and it has quickly become one of my favorite things on the internet. Once, maybe twice a day, I load the homepage and browse through the latest posts from real blogs written by real humans. I almost always find something surprising, delightful, weird, or just plain fun to read. Even better, I come away with a new blogger to follow.",
    "author": "Tyler",
    "published": "Wed, 15 Jan 2025 02:47:20 +0000",
    "image": "",
    "source": "https://tyler.io/feed/",
    "categories": [
      "Uncategorized"
    ]
  },
  {
    "id": "037ea8a0-4fa8-44d5-859b-b194a717f768",
    "title": "How to setup a Swift Package Registry in Artifactory",
    "link": "https://albertodebortoli.com/2025/06/06/how-to-setup-a-swift-package-registry-in-artifactory/",
    "description": "A quick guide to setting up a Swift Package Registry with Artifactory to speed up builds and streamline dependency management.",
    "author": "Alberto De Bortoli",
    "published": "Fri, 06 Jun 2025 08:00:00 GMT",
    "image": "https://albertodebortoli.com/content/images/2025/06/Gemini_Generated_Image_p2p1t1p2p1t1p2p1.jpeg",
    "source": "https://albertodebortoli.com/rss/",
    "categories": [
      "swift",
      "registry",
      "artifactory"
    ]
  },
  {
    "id": "d8c9d892-cd09-4a92-8312-c29ab70b09b3",
    "title": "Scalable Continuous Integration for iOS",
    "link": "https://albertodebortoli.com/2024/01/03/scalable-continuous-integration-for-ios/",
    "description": "How Just Eat Takeaway.com leverage AWS, Packer, Terraform and GitHub Actions to manage a CI stack of macOS runners.",
    "author": "Alberto De Bortoli",
    "published": "Wed, 03 Jan 2024 22:26:50 GMT",
    "image": "https://albertodebortoli.com/content/images/2024/01/1_SaGE67XSSeflkTKknVOHbg.webp",
    "source": "https://albertodebortoli.com/rss/",
    "categories": [
      "CI",
      "mobile",
      "iOS",
      "AWS",
      "macOS"
    ]
  },
  {
    "id": "0434d808-df1b-4ee5-9a91-b2e47e091f42",
    "title": "Swift 6 suitable notification observers in iOS",
    "link": "https://augmentedcode.io/2024/11/18/swift-6-friendlier-notification-observers/",
    "description": "The author discusses challenges managing side projects, specifically updating SignalPath to Swift 6. They encountered errors related to multiple notification observations but resolved them by shifting to publishers, avoiding sendable closure issues. Although the new approach risks background thread notifications, the compiler is satisfied with the adjustments made to the code.",
    "author": "Toomas Vahter",
    "published": "Mon, 18 Nov 2024 16:00:00 +0000",
    "image": "https://2.gravatar.com/avatar/e55a8cd331ba727a325fb2029717f9d584df498403c1462d032f2fa0be8e4777?s=96\u0026d=identicon\u0026r=G",
    "source": "https://augmentedcode.io/feed/",
    "categories": [
      "iOS",
      "Swift"
    ]
  },
  {
    "id": "8474c4a7-3bc9-4cfb-8f56-d71b3b304632",
    "title": "AnyClass protocol and Objective-C methods",
    "link": "https://augmentedcode.io/2024/11/04/anyclass-protocol-and-objective-c-methods/",
    "description": "AnyClass is a protocol all classes conform to and it comes with a feature I was not aware of. But first, how to I ended up with using AnyClass. While working on code using CoreData, I needed a way to enumerate all the CoreData entities and call a static function on them. If that function [â€¦]",
    "author": "Toomas Vahter",
    "published": "Mon, 04 Nov 2024 16:00:00 +0000",
    "image": "https://2.gravatar.com/avatar/e55a8cd331ba727a325fb2029717f9d584df498403c1462d032f2fa0be8e4777?s=96\u0026d=identicon\u0026r=G",
    "source": "https://augmentedcode.io/feed/",
    "categories": [
      "iOS",
      "Swift",
      "AnyClass"
    ]
  },
  {
    "id": "2fd87e8e-f218-4997-b50e-aa7c8e8ddee7",
    "title": "From Engineer to Manager: A Year of Growth and Transformation",
    "link": "https://benoitpasquier.com/2023/06/from-engineer-to-manager-a-year-of-growth-and-transformation/",
    "description": "It feels like it was yesterday when I became an engineering manager but it has been almost a year. I want to take this time to reflect on the challenges and learnings from this journey.",
    "author": "",
    "published": "Sun, 11 Jun 2023 06:00:00 +0000",
    "image": "",
    "source": "https://benoitpasquier.com/index.xml",
    "categories": null
  },
  {
    "id": "2718a0fa-6377-4149-bf10-c64771e85df4",
    "title": "Things to know before becoming an Engineering Manager",
    "link": "https://benoitpasquier.com/2023/02/things-to-know-before-becoming-an-engineering-manager/",
    "description": "The journey from individual contributor to engineering manager isnâ€™t always straightforward. Today, Iâ€™ll share what it means to become an engineering manager from my point of view, and a few important points to be aware of before making this transition.",
    "author": "",
    "published": "Sun, 19 Feb 2023 06:00:00 +0000",
    "image": "",
    "source": "https://benoitpasquier.com/index.xml",
    "categories": null
  },
  {
    "id": "5324c6af-7072-4cbf-9214-290886bfbaac",
    "title": "iOS Accessibility Values",
    "link": "https://mobilea11y.com/blog/accessibility-values/",
    "description": "For iOS, Accessibility values are one of the building blocks of how Accessibility works on the platform, along with traits, labels, hints, and showing/hiding elements. If youâ€™re familiar with WCAG or web accessibility, accessibility values are the value part of WCAG 4.1.2: Name, Role, Value. Values Not every element in your view will have a value - in fact, most wonâ€™t. Any element that â€˜containsâ€™ some data, data that is not included in the elementâ€™s label requires an accessibility value to be set.",
    "author": "",
    "published": "Sun, 19 Jun 2022 10:30:56 +0000",
    "image": "",
    "source": "https://mobilea11y.com/index.xml",
    "categories": null
  },
  {
    "id": "a942e786-12b7-4235-8647-36148aec3c1d",
    "title": "iOS UIKit Accessibility traits",
    "link": "https://mobilea11y.com/blog/traits/",
    "description": "Accessibility traits on iOS is the system by which assistive technologies know how to present your interface to your users. The exact experience will vary between assistive technologies, in some cases they may change the intonation of what VoiceOver reads, or add additional options for navigation, sometimes they will disable that assistive technology from accessing the element, or change how the assistive tech functions. They are the â€˜Roleâ€™ part of the fundamental rule of making something accessible to screen readers - WCAGâ€™s 4.",
    "author": "",
    "published": "Fri, 13 Aug 2021 07:30:56 +0000",
    "image": "",
    "source": "https://mobilea11y.com/index.xml",
    "categories": null
  },
  {
    "id": "a7ad89e3-a7af-49c8-b55f-992b8c4cd598",
    "title": "Today @ WWDC25: Day 5",
    "link": "https://developer.apple.com/news/?id=k2rqp041",
    "description": "It's the final day of WWDC25. Revisit the week's highlights, and dive into group labs on live streaming, immersive video, and spatial audio.",
    "author": "",
    "published": "Fri, 13 Jun 2025 07:00:56 PDT",
    "image": "",
    "source": "https://developer.apple.com/news/rss/news.rss",
    "categories": null
  },
  {
    "id": "7d7dd689-2178-4650-a498-1c5956934ac9",
    "title": "Today @ WWDC25: Day 4",
    "link": "https://developer.apple.com/news/?id=8kawba5a",
    "description": "Day 4 is all about Apple Intelligence. Join us in todayâ€™s group labs to find out more about making machine learning and AppleÂ Intelligence work for your app. And dive into video sessions to learn all about the latest tools and technologies.",
    "author": "",
    "published": "Thu, 12 Jun 2025 08:00:56 PDT",
    "image": "",
    "source": "https://developer.apple.com/news/rss/news.rss",
    "categories": null
  },
  {
    "id": "ec0ce6fa-5a08-4eb9-82b9-ad9e72a0d00b",
    "title": "Building with nightly Swift toolchains on macOS",
    "link": "https://oleb.net/2024/swift-toolchains/",
    "description": "",
    "author": "Ole Begemann",
    "published": "2024-03-05T18:54:44Z",
    "image": "",
    "source": "https://oleb.net/blog/atom.xml",
    "categories": null
  },
  {
    "id": "6c830c90-09fb-45a7-8ee3-f10555fac28c",
    "title": "How the Swift compiler knows that DispatchQueue.main implies @MainActor",
    "link": "https://oleb.net/2024/dispatchqueue-mainactor/",
    "description": "",
    "author": "Ole Begemann",
    "published": "2024-02-29T18:54:47Z",
    "image": "",
    "source": "https://oleb.net/blog/atom.xml",
    "categories": null
  },
  {
    "id": "b962e872-729c-4c06-aced-80de8978cb31",
    "title": "You Should Feed Ducks The Good Bread",
    "link": "https://fabisevi.ch/2025/05/12/you-should-feed-ducks-the-good-bread/",
    "description": "Colleen and I were binge-watching Gossip Girl last winter, and there are a few scenes where a stressed and irate Blair Waldorf wanders over to Central Park to feed the ducks. I told Colleen, \"that sounds soothing â€” we should do that when the weather gets better\". And then, as Iâ€™m wont to do, I promptly forgot. But Colleen takes note of moments like that, and a few months later she reminded me: we should actually go feed some ducks. Thatâ€™s how I found myself in Central Park last weekend, feeding ducks. It was the first beautiful day of spring in New York â€” the kind of day New Yorkers wait for, when everyone pours out to enjoy sunlight finally breaking through after a long dark winter. We had a picnic, strolled through the park, wandered amidst thousands of New Yorkers â€” and of course, we fed the ducks. My wife (who I should preface is an extremely kind, caring, and loving person) and I got into a small debate over what kind of bread to feed the ducks. I insisted on buying them a nice loaf, and she felt it was unnecessary â€” the ducks would happily take our scraps. I argued that buying a good loaf cost us very little but could potentially make their day. Heck, it could even possibly be the best meal they ever have. She replied that thereâ€™s no way to know if theyâ€™d even notice the difference â€” to them, it might just be one carb versus another. Three Philosphers Interject I bought the dang bread, and she didnâ€™t mind. I spent the whole afternoon thinking about that moment, and why it meant so much to me. In the end, I came back to three philosophers and their philosophies.",
    "author": "Joe Fabisevich",
    "published": "Mon, 12 May 2025 00:00:00 GMT",
    "image": "",
    "source": "https://www.fabisevi.ch/feed.xml",
    "categories": null
  },
  {
    "id": "57b6e0aa-aa70-4dcb-9e14-3652dafb65d2",
    "title": "A Trick For Opening Magic Links in Your RSS Reader",
    "link": "https://fabisevi.ch/2025/03/28/opening-magic-links-in-your-rss-reader/",
    "description": "This blog post is documentation for a very specific problem I run into about once a year. Thatâ€™s rare enough to forget how I solved it, but frequent enough to waste 15 minutes rediscovering the answer. And letâ€™s be honest: itâ€™s not the big problems that drive you mad â€” itâ€™s the little ones that feel like their own Sisyphean hell. The Problem Some websites 1 require you to log in using a magic link â€” a one-time link emailed to you that signs you in when clicked. Itâ€™s usually seamless. But on iOS, it can quietly become a headache. 2",
    "author": "Joe Fabisevich",
    "published": "Fri, 28 Mar 2025 00:00:00 GMT",
    "image": "",
    "source": "https://www.fabisevi.ch/feed.xml",
    "categories": null
  },
  {
    "id": "5102f623-7a50-45c4-89de-c83c1ede1623",
    "title": "Tips and tricks for when using SwiftUIâ€™s ViewBuilder",
    "link": "https://www.swiftbysundell.com/articles/swiftui-viewbuilder-tips-and-tricks",
    "description": "Letâ€™s explore how we can use SwiftUIâ€™s ViewBuilder within our own code, and a few things that can be good to keep in mind when doing so.",
    "author": "",
    "published": "Fri, 30 May 2025 14:25:00 +0200",
    "image": "",
    "source": "https://www.swiftbysundell.com/feed.rss",
    "categories": null
  },
  {
    "id": "fc36ae79-e306-446c-9833-a868ca6a4e03",
    "title": "Using Swiftâ€™s defer keyword within async and throwing contexts",
    "link": "https://www.swiftbysundell.com/articles/using-defer-within-async-and-throwing-contexts",
    "description": "How Swiftâ€™s defer keyword can be incredibly useful when working with code scopes that have multiple exit points, such as throwing or async functions.",
    "author": "",
    "published": "Tue, 15 Apr 2025 16:45:00 +0200",
    "image": "",
    "source": "https://www.swiftbysundell.com/feed.rss",
    "categories": null
  },
  {
    "id": "1e6cb99e-84f8-44b6-ad1d-b2190a7d4dc7",
    "title": "Magical Particle Effects with SwiftUI Canvas",
    "link": "https://nerdyak.tech/development/2024/06/27/particle-effects-with-SwiftUI-Canvas.html",
    "description": "In one of the previous posts, I shared a simple way of Creating particle effects in SwiftUI. The approach is super easy and utilizes the power of viewModifiers, but I would not recommend it for production use as it is performance-greedy when having a bigger amount of particles in place (because each particle is a single view)",
    "author": "Pavel Zak",
    "published": "2024-06-27T00:00:00+00:00",
    "image": "",
    "source": "https://nerdyak.tech/atom.xml",
    "categories": [
      "development",
      "SwiftUI",
      "Canvas",
      "Particles",
      "BlendMode",
      "TimelineView"
    ]
  },
  {
    "id": "249e853c-6386-4018-9542-565296095c07",
    "title": "SwiftUI transitions with distortion effect and Metal Shaders",
    "link": "https://nerdyak.tech/development/2023/06/16/distortionEffect-with-Metal-shaders-for-better-transitions.html",
    "description": "This year DubDub is over and I am very excited about the new developer treats that iOS17 will bring us that expand the animation possibilities of SwiftUI. I am talking mainly about the PhaseAnimator, KeyframeAnimator and the ability to utilize Metal shaders on SwiftUI views through modifiers .distortionEffect, .layerEffect, and .colorEffect (docs).",
    "author": "Pavel Zak",
    "published": "2023-06-16T00:00:00+00:00",
    "image": "",
    "source": "https://nerdyak.tech/atom.xml",
    "categories": [
      "development",
      "SwiftUI",
      "distortionEffect",
      "Metal",
      "Shaders",
      "transitions"
    ]
  },
  {
    "id": "fb7cdbd9-7125-49c4-9b49-b02ed09253fd",
    "title": "Tips and tricks for when using SwiftUIâ€™s ViewBuilder",
    "link": "https://www.swiftbysundell.com/articles/swiftui-viewbuilder-tips-and-tricks",
    "description": "Letâ€™s explore how we can use SwiftUIâ€™s ViewBuilder within our own code, and a few things that can be good to keep in mind when doing so.",
    "author": "",
    "published": "Fri, 30 May 2025 14:25:00 +0200",
    "image": "",
    "source": "https://swiftbysundell.com/feed.rss",
    "categories": null
  },
  {
    "id": "c1bdd84f-ba39-403b-9b0b-ecc82c46c4ff",
    "title": "Using Swiftâ€™s defer keyword within async and throwing contexts",
    "link": "https://www.swiftbysundell.com/articles/using-defer-within-async-and-throwing-contexts",
    "description": "How Swiftâ€™s defer keyword can be incredibly useful when working with code scopes that have multiple exit points, such as throwing or async functions.",
    "author": "",
    "published": "Tue, 15 Apr 2025 16:45:00 +0200",
    "image": "",
    "source": "https://swiftbysundell.com/feed.rss",
    "categories": null
  },
  {
    "id": "76f20a5c-696e-49eb-a3b1-1abe4fb5a949",
    "title": "How I'm using AI to improve my software engineering productivity (and why it will not steal your job)",
    "link": "https://swiftrocks.com/how-im-using-ai-for-software-engineering",
    "description": "AI has become an important part of my daily software engineering work, so I wanted to write a post sharing how exactly I've been using it in case you're wondering how to use it to improve your productivity as well! Foreword: AI will not steal your software engineering job Before getting to the details of how AI has been helping me to code, I wanted to address the topic of AI replacing software engineers. Recently, my social media feeds have become full of people making predictions about how in X months/years everything in the software engineering industry will be done by AI, via doomsday-style content about how everyone is going to lose their jobs and everything will fall apart. If you look at who's writing these kinds of posts, you'll notice something interesting: they are either executives who have never done any kind of software engineering, or beginners with no industry experience. Honestly, that should tell you everything you need to know about these \"predictions\". But in the interest of being informative, I'll try to explain why they are nonsense. The problem with these \"predictions\" is that the people making them for some reason seem to view software engineering as nothing more than coding and closing tasks on JIRA. You arrive at work, pick a task that is very well defined and requires no clarification whatsoever, code it, close it, pick another task that is once again perfectly defined, and repeat that ad-infimum for the entire duration of your career. But the reality of software engineering is far more complex than that. While there's certainly a good amount of coding, it's extremely rare that the problems a software engineer needs to solve are perfectly defined from the get-go as claimed by the people making these predictions. This means that more often than not the job is not really about coding, but rather figuring out what exactly needs to be coded, by asking yourself questions such as: What problems are we facing right now? What are the current objectives of the company? What is the current state of the company? What is most important for our users? Who will benefit from X problem being solved? What does the codebase looks like today? Are there any patterns or traps I need to be aware of? Are there any political fights going on around me that would affect what I should focus on? What's the current state of the industry? Are there any new tools that can help me solve my problems? The answers to questions like the ones above provide you with context that helps you define how (and when) exactly certain problems should be solved, and is a critical aspect of software engineering even for junior developers. And the interesting part is that the more senior you become, the less coding you do, and the more time you spend answering these types of questions to help your team/company determine which way it should go. This is something I've also written about on my Focus not on the task, but on the problem behind the task blog post. While AI can be quite good at solving very simple and perfectly defined problems, it is exceptionally bad at handling anything that requires taking this level of context into account, which is something that software engineers constantly have to do. This is very easy to confirm if you have doubts about it: Grab any AI agent and project of your choice (or ask the agent to make a new one), and keep asking it to include more features in your project. While it may do relatively well the first time, it is inevitable that the AI will start confusing itself and destroying the codebase on the subsequent requests. This is because AI today doesn't understand context, and as one user on HackerNews wrote, it's like working with a junior developer that has amnesia. Thus, while AI today can be amazing as a coding assistant (which I'll go into more detail further below), the thought of it replacing software engineers is frankly hilarious. One counterargument that some people have is that while this is true today, it doesn't mean that in the future the AI won't be able to understand context and thus be able to do complex tasks. While this is true, what must be noted about this is that an AI capable of understanding context (and gathering it on its own) would be so powerful that it wouldn't just replace software engineers; it would replace all of humanity. If such a thing is achieved then software engineering jobs would be the least of our concerns, so I think it's a sort of weird argument to consider. Our entire lives would change in this scenario. With that out of the way, I'd like to now present my favorite use cases for AI today! Use case 1: Getting simple tasks done quickly One thing that AI is very good as of writing is solving very concrete and straightforward problems. So when I have to do very menial tasks like changing configuration files or writing a simple function that does X and Y, nowadays what I do is simply ask Cursor to do it for me, sit back, and watch the show. Even when taking into account that the AI might not get it 100% correct and that I'll still have to patch the code afterward, this still saves me a massive amount of time overall compared to having me do everything by myself and is definitely my favorite use case of AI today. This is especially true when doing (simple) work on languages that I'm not very familiar with, as the AI in this case is also sparing me from having to do multiple trips to StackOverflow. I still need to do so since the AI will sometimes recommend things that are not correct for my case, but again, even when considering these setbacks, I can get the work done at a much faster pace. It must be noted however that the important keyword here is simple, concrete, and straightforward. As mentioned previously, trying to have the AI solve complex problems that require large amounts of context such as code reviews or designing large features will not work in any meaningful way and is a sure way to waste everyone's time. Use case 2: Understanding complex codebases quickly Another thing that I've found AI to be amazing at is when I'm working on a repository that I'm not familiar with and I need to figure out how certain things are wired together. The way I would do this before AI was to spend hours painstakingly reading through the codebase, but now, with the right questions, it's possible for me to get started in a matter of seconds. Here's a concrete recent example to demonstrate what I mean by this. I was recently attempting to craft a Build Server Protocol that would connect to SourceKit-LSP in order to enable iOS development on my specific non-Xcode conditions. The problem here is that SourceKit-LSP is a very complex project. Even though I know what I have to do in theory, I have no idea what SourceKit-LSP expects me to do in practice. But nowadays, instead of having to spend weeks trying to figure this out by searching keywords on the codebase, I can simply ask Cursor to explain the project to me! Similarly to Use case 1, it's to be expected that the explanation provided by the AI will not be 100% accurate. But once again, even when taking this into consideration, the amount of time these explanations save me is mindblowing. Since Cursor in this case provides shortcuts to the relevant parts of the codebase, I am able to very quickly piece together what I am supposed to do / determine which parts of the explanation are correct and which ones aren't. Use case 3: Searching for things when I don't know what exactly I'm looking for I find that Google tends to provide good results if you know exactly what you're looking for. But if you don't really know what is it that you're trying to find out, you'll have a hard time with it. For example, the other day I was trying to find what the _start function in iOS (the first function called when your app is launched) is, where it's defined, and what it does. But if I go now and search for \"_start function iOS\" on Google, I will not find a straight answer to this question. Google does return somewhat good results (the second search result contains some interesting information about it if you scroll down far enough), but it cannot give me a direct response because I asked the wrong question. I know today that what I should've done is ask it about details of how C programs are linked, but I didn't know this back then, so I couldn't have done that. AI does not have this problem. If you don't know what you're looking for, you can explain your situation to it and it will point you in the right direction: In this example, you can see that ChatGPT immediately pointed out that I asked the wrong question before attempting to explain it! Although the AI's answers won't always be 100% accurate, I find them to be accurate enough to allow me to use Google to find the rest of the information. Just like the previous case, this is not so much about having the AI do everything for me (which it can't), but rather allowing me to save time and get where I want faster. Use case 4: Asking questions that are too specific for Google Even if you know exactly what you're looking for, you may have difficulty using Google if your question is too specific. For example, you cannot search Google on \"how to implement X thing in Swift in my app that is using XYZ frameworks in X iOS version with dependency injection bridging an Obj-C type after the user logged in on my TODO list app using Apple Sign-in from Italy during a rainy day in October\". For cases like this, usually what you need to do is break your problem into multiple, more generic queries, open many tabs that each help you with a specific part of the problem, and then use all of that combined knowledge to come up with the actual answer to your question. AI excels at this. You can be as specific as you want and you'll get a relevant answer. Most coding questions fall into this category, although for these specifically nowadays I prefer using Cursor's code gen features directly as mentioned above. In this case, I could've probably found the answer I was looking for in Google by making a bunch of generic searches about C++ global constructors and good practices, opening a bunch of tabs, and summarizing everything I found. But by asking ChatGPT, I was able to save several hours of my time instead. Use case 5: I want FAST answers It has been getting harder and harder to get fast answers to your questions with Google. Today, it's very unlikely that the answer to a question will lie at the top of a page you've opened. As SEO optimization became more and more important for survival on the web, the amount of stuff you have to endure before getting to the actual content has increased significantly. There will be a lengthy introduction, a pause for sponsors, ten paragraphs about how the question reminds the author about a personal story of how their dog bodyslammed their grandma on Christmas, a call to action for the author's newsletter, some backstory on the question, and only then you'll get to the actual content. I find that there are many cases where this fluff is relevant and worth reading. But there are also many cases when I'm in a hurry and would much rather just get a straight answer to my question. This is also something that I find AI to be quite good at. It generally doesn't try to educate you on things you didn't ask, it just straight up answers your question. By asking follow-up questions regarding one or more things it mentioned in its answer, I can get all of the information I need to learn something new considerably faster than if I had used Google instead. Even though I still need to use Google to double-check if the AI didn't hallucinate particular pieces of information, this ability to quickly gather relevant information saves me an absurd amount of time.",
    "author": "Bruno Rocha",
    "published": "Tue, 15 Apr 2025 11:50:00 GMT+2",
    "image": "https://i.imgur.com/4u0M9kM.png",
    "source": "https://swiftrocks.com/rss.xml",
    "categories": null
  },
  {
    "id": "a363b660-81a9-4726-b44e-0172f0db7f0d",
    "title": "Things that did (and didn't) contribute to Burnout Buddy's success",
    "link": "https://swiftrocks.com/things-that-did-and-didnt-contribute-to-burnout-buddys-success",
    "description": "Back in 2022 I launched Burnout Buddy, and today the app has succeeded far beyond my expectations. Netting between $600 and $1000 each month as of writing, BB has been growing 100% organically with little to no effort on my part. In this post, I'd like to lay out exactly what I've done that I believe contributed (and didn't contribute) to this growth, serving as documentation and inspiration for the indie dev community out there. Things that helped Understanding ASO I cannot understate the value of having a good grasp of App Store Optimization (ASO). The case is simple: It doesn't matter how good your app is, if you don't get eyes on it, it will never succeed. ASO refers to being strategic about how you assemble your app's store listing (keywords, name, subtitle, description, screenshots, etc) so that it ranks well when people search for keywords related to your app. In many cases what you actually want to do is avoid popular keywords in the beginning, focusing on less popular ones where you have more of a fighting chance until you get \"popular\" enough that you can try challenging the real ones. How and when you ask for reviews also plays a big role here as reviews also affect your app's rank. I strongly recommend Appfigures for learning and applying ASO for your apps. The owner, Ariel, has posted many videos explaining different strategies you can take, and that's how I got to know about it. In my case, ASO was only time-intensive in the first few weeks following the app's launch. After it picked up some steam and became no.1 in a couple of important keywords, I was able to leave it alone and enjoy full organic growth ever since. I'm my app's primary user Most indie apps fail because they are trying to solve problems that don't exist. The devs come up with the solution first, and then try to find users who have a problem that match their solution. This rarely works. The easiest way to avoid this is to ignore other people and just focus on your own set of problems. If you can manage to build something that would make your own life better, certainly you'll find other people who will also appreciate it. In my case, I built Burnout Buddy because iOS's default Screen Time feature was too simple for me. I wanted to make more complex scenarios such as schedule or location based conditions, but iOS only allows you to setup simple time limits. You also can't do \"strict\" conditions where there's no way to disable the block once it goes into effect. I searched for other alternatives, but none of them were good enough for me. So I built my own! Once my problem was solved, I figured out that most likely there were others out there who could also make use of it. I made the app public with zero expectations, and sure enough, there were tons of other people with the same problem I had. Being my app's primary user also means that I'm perfectly positioned to know which features the app should and shouldn't have. I don't need things like user interviews, because again, I built this for myself. All I have to do is ask myself what I'd like the app to do, and the result is sure to also be a hit with others with the same problem the app aims to solve. I attribute Pieter Level's Make book for helping me understand this concept. It's also a great resource for learning more about indie development and how to create successful products in general! No backend, everything happens client-side Another decision that I've made that massively simplified things for me is that everything happens on the client. There are no accounts or backend, and I gather zero data from the users. This means I have no backend to manage, and most importantly, no monthly server costs. As long as Apple doesn't push iOS updates that break the APIs I use (unfortunately happens a lot), I can trust that everything is working as it should and focus my attention on other things. People seem to really appreciate this too, since many apps nowadays have accounts for no reason other than wanting to hoard data which is really shady. The app just works After the first couple of releases, I spent a good amount of time building a good suite of tests and architecting the app so that it would be easy to expand and make it even more testable. This means I very rarely have to worry about whether or not I'll push something that will fundamentally break the app. Having no backend-related code also greatly helped here. This doesn't mean that the app is bug-free (there are a bunch of SwiftUI issues I can't seem to solve, and Apple somehow manages to break their APIs on every iOS release as mentioned above), but when it comes to the core experience of the app, I can trust that everything works as it should. This saved a lot of testing / debugging time on my end and also made sure I almost never had to deal with support e-mails regarding broken features and such. I don't extort my users Burnout Buddy is a one-time $9.99 bucks purchase. For a long time it used to be $4.99 even. Why this matters? Because most alternatives are stupidly expensive subscriptions. Most of them also don't have backends and have even less features than BB, why the hell are these apps subscription-based??? Some people justify that subscriptions are necessary even for \"simple\" apps like BB because of things like recurring support work. While I can see the point, I also think there are other ways to tackle these issues. I for example created a FAQ support page, and that reduced 99.9% of the support requests. I'm not trying to extort my users and I believe this was a strong factor for the app's success. Things that didn't help It would be naive of me to claim that everything went right. I've made a couple of bad decisions that worked against the app's success, and I wanted to document them as well. Thinking I could make it big without marketing Like I mentioned in the ASO section, it doesn't matter how good your app is. You need to get the word out, otherwise it will just not work. There is a saying in tech that goes \"if you build something good, people will follow\". Whoever said this has absolutely never attempted to sell something. I'm as a tech nerd as it can get and I can safely say that when it comes to building businesses, marketing is a billion times more important than building the actual product! Unfortunately for me, I hate doing marketing work. I'm fine with putting a sponsorship section on this blog, but reaching out to journalists and hustling on X / LinkedIn is really not my thing. This means that while thankfully I was able to do just enough of it to get some nice results in the beginning, the app is destined to die a slow death as it drops in ranking in the App Store and other similar apps manage to get their word out better than me. Marketing is something you have to do constantly, but unfortunately for me it's something I just don't want to do, so there will always be a hard cap to how far I can go with any given project alone. Making the app too cheap This will sound weird because I mentioned above that not extorting my users was a positive. But allow me to clarify this. One thing I've learned the hard way is that you need to avoid cheapskates like the plague. This means people who expect nothing but the highest quality products, but at the same time are not willing to pay anything for it. You know when you see one because they behave like huge assholes and will do everything in their power to extract as much value from you as possible while giving nothing in return, much like the meme of a Karen screaming at the supermarket cashier because of some worthless coupon. When Burnout Buddy was $4.99, I was constantly having my support e-mail being spammed by such people. They would constantly aggressively complain about different app features and demand refunds, often threatening that they would download a different app if I didn't help them (...why would I care about that?). A lot of these reports didn't even make sense, they were clearly people just searching for excuses to be an asshole and get free stuff. It was such a waste of my time that I even briefly considered abandoning the project entirely / pulling it from the App Store just so I wouldn't have to deal with them anymore. It was only when I read someone complaining about the exact same problem on HackerNews that I realized what my issue was. It's not that giving support is a thankless job, it's that the app was too cheap. The cheapskates are attracted by free (or in this case, almost free) products. If you raise the price of your product just slightly, you can filter out these people without driving way the good (and kind) users. After doing just that, these bizarre e-mails completely vanished without resulting in any loss of revenue. While I of course still get support requests every now and then, they are now all very polite and helpful, which makes everything a breeze! In other words, the \"fail\" here is that I should've made the app cost $9.99 from the get-go to have filtered the cheapskates from the very beginning. Not gathering analytics This is an interesting one because it's both a good and a bad thing depending on how you look at it. I mentioned above that having no accounts was a good thing because it made things easier on my side and was appreciated by the users. But it also meant that I had no information regarding how users were using the app. This made things harder for me because 1) I couldn't determine which features were more popular / worth expanding upon (and which ones weren't), and 2) when people reported bugs, I had no easy way to trace their steps in order to quickly reproduce the issue (or to confirm they misunderstood the app / were doing something wrong). If I could go back, I would probably have gone for a solution that allowed me to gather analytics data for the above reasons. Using SwiftUI This is mostly out-of-topic for this post, so I'll keep it short. I decided to use SwiftUI for this project as a learning opportunity, and I sort of regret it. As mentioned in my SwiftUI vs UIKit post, SwiftUI is good for simple apps, but awful for more complex ones. As BB grew and became more intricate, SwiftUI became more and more of an issue. The app today is full of dirty hacks and visual bugs that are impossible to solve (as of writing) because they originate from SwiftUI itself, in ways that are impossible for me to control without dumping the entire framework.",
    "author": "Bruno Rocha",
    "published": "Thu, 23 Jan 2025 13:00:00 GMT+1",
    "image": "",
    "source": "https://swiftrocks.com/rss.xml",
    "categories": null
  },
  {
    "id": "a8905163-d7b2-4db5-96d7-89ebfbda732e",
    "title": "320: Before the Barrier",
    "link": "http://relay.fm/radar/320",
    "description": "Expectations and preparations for WWDC 2025.",
    "author": "Marco Arment and David Smith",
    "published": "Thu, 05 Jun 2025 13:30:00 GMT",
    "image": "https://www.podtrac.com/pts/redirect.mp3/traffic.libsyn.com/secure/radarrelay/undertheradar320.mp3",
    "source": "https://www.relay.fm/radar/feed",
    "categories": null
  },
  {
    "id": "48c6fe32-7673-45cc-a71c-2b4a2258bc1f",
    "title": "319: Unfreezing Your Brain",
    "link": "http://relay.fm/radar/319",
    "description": "Motivating ourselves to get back into coding after time away.",
    "author": "Marco Arment and David Smith",
    "published": "Thu, 22 May 2025 15:00:00 GMT",
    "image": "https://www.podtrac.com/pts/redirect.mp3/traffic.libsyn.com/secure/radarrelay/undertheradar319.mp3",
    "source": "https://www.relay.fm/radar/feed",
    "categories": null
  },
  {
    "id": "2df2b442-5117-4d1f-9b70-a2bcb924e216",
    "title": "Saturday March",
    "link": "https://inessential.com/2025/06/13/saturday-march.html",
    "description": "Tomorrow is No Kings. Thereâ€™s one near you! Chatting with my friends about how I hate these fascist assholes doesnâ€™t do a damn thing. Protests work. (Imperfectly, sure, with no guarantees. But it sure beats not protesting.)",
    "author": "",
    "published": "Fri, 13 Jun 2025 20:04:06 -0700",
    "image": "",
    "source": "https://inessential.com/xml/rss.xml",
    "categories": null
  },
  {
    "id": "f8f17975-3f97-43d1-884a-b35f25bcc21e",
    "title": "Retirement Day",
    "link": "https://inessential.com/2025/06/06/retirement-day.html",
    "description": "I wrote in my love letter to my colleagues at Audible that retirement is coming up â€”Â and now itâ€™s here. Todayâ€™s the day! Iâ€™ve attended my last meetings. Iâ€™ve said my goodbyes. My laptopâ€™s ready to ship back to Audible HQ. * * * I started working in 1984, while in high school, busing tables part time at Schaefers Canal House in Chesapeake City, MD. And I stopped working this day in 2025, almost 41 years later, as a senior engineer (which is surprisingly a lot like busing tables â€”Â lots of cleanup and setting the table just right for the customers to have a great time). Along the way I worked on, among other apps, Userland Frontier, NetNewsWire, MarsEdit, Glassboard, Vesper, OmniFocus, OmniOutliner, and Audible. * * * My immediate plan â€”Â Exhale! Breathe. Enjoy a steak. Watch WWDC from the comfort of home next week. Get back to work on NetNewsWire. ðŸŒ²",
    "author": "",
    "published": "Fri, 06 Jun 2025 11:20:46 -0700",
    "image": "",
    "source": "https://inessential.com/xml/rss.xml",
    "categories": null
  },
  {
    "id": "8574b8ca-db36-4287-9d9e-91d1677648ca",
    "title": "WWDC 2025 Viewing Guide",
    "link": "https://useyourloaf.com/blog/wwdc-2025-viewing-guide/",
    "description": "My WWDC 2025 viewing guide to help you plan the sessions you want to watch. Where Do I Start? The two big themes for the year are Liquid Glass design and Apple Intelligence. Start by watching the Platforms State of the Union (SOTU) for a summary of whatâ€™s new this year. You donâ€™t have to learn everything new today! There are over 100 sessions and a lot of new stuff to learn. You may feel like youâ€™re getting left behind. Donâ€™t let it overwhelm you. Youâ€™ve got time. Donâ€™t burn yourself out trying to keep up. Watching The Sessions I watch the videos using the Apple Developer app. Itâ€™s available on macOS and iOS. The video player supports from 0.5x to 2x playback, most videos have transcripts, some have summaries, and allow copying of the onscreen sample code. You can also watch on YouTube. There are a lot of sessions, but many are short (10-20 minutes). Thereâ€™s no padding and Appleâ€™s engineers get to the point quickly. Swift Swift 6.2 is here with some updates to ease the pain of adopting Swift Concurrency: Whatâ€™s new in Swift Install toolchains with Swiftly. Faster clean builds for macros with pre-built swift-syntax dependencies. Finer controls for compiler diagnostics/warnings. Concrete notification types. New Observation type for tracking changes. Testing attachments and exit tests. InlineArray and Span types. Swift 6.2 is single-threaded by default. Opt-in to infer main actor. Improve memory usage and perforamce with Swift Profile a test to find performance issues. Just because itâ€™s shorter, doesnâ€™t mean itâ€™s faster. Reduce allocations and copying. Exclusivity checks. InlineArray fixed size array. Span types to work with contiguous memory. Swift Binary Parsing library. These Swift Concurrency sessions are essential viewing. This seems like a better Concurrency approach: Embracing Swift concurrency Start by running code on the main thread. Introduce concurrency as you need it. Swift 6.2 allows a module to default to main-actor isolation. Use async tasks to await for data. Interleaving - single thread alternating between tasks. Run code on a background thread by marking method with @concurrent. Use nonisolated for library API and let client decide. Actors to move data off main thread. Enable Approachable Concurrency and Default Actor Isolation build settings. Code-along: Elevate an app with Swift concurrency Transform a single-threaded app to use concurrency as needed. Explore concurrency in SwiftUI SwiftUI views are isolated to the main actor. Tasks in the view run on the main actor. Find the boundaries between your UI code and non-UI code. Default actor isolation setting removes need for most @MainActor annotations. Interoperability with C, C++, and Java: Safely mix C, C++, and Swift Strict memory safety build setting, off by default. Annotate C and C++ functions and types so Swift can use them safely. Explore Swift and Java interoperability Incremental adoption of Swift by mixing Swift and Java code. Calling Swift from Java or vice-versa. Meet Containerization Open source Swift framework to create and run Linux containers on macOS. SwiftUI Thereâ€™s work to be done updating apps for the new design: Whatâ€™s new in SwiftUI Recompile for new liquid glass design. Toolbar spacer API. Glass effect. iPadOS menu bar using commands API. Large lists on macOS load 6x faster. New SwiftUI performance instrument. New Animatable macro. Scene bridging to UIKit and AppKit. AssistiveAccess scene type. WebView. 3D charts. New drag and drop API. Rich text editor. Build a SwiftUI app with the new design Liquid glass design system. Extend views outside the safe area with BackgroundExtensionEffect. Sidebars, toolbars, and tab bars float above content. Remove custom presentation backgrounds. Toolbar spacer API splits items into groups. Search at bottom on iPhone. Slider tick marks. GlassEffectContainer for custom controls. Code-along: Cook up a rich text experience in SwiftUI with AttributedString TextEditor supports rich text when bound to an attributed string. Bring Swift Charts to the third dimension Support for 3D charts. PointMark, RuleMark, and RectangleMark take a Z value. Use gestures to rotate the chart. SurfacePlot is a 3D extension to LinePlot. Two camera projections. Meet WebKit for SwiftUI New WebView API to load and display web pages. WebPage is Observable. URLSchemeHandler for custom URLs to load content bundled with App. New Observations API in Swift 6.2 to respond to navigation events. Directly evaluate Javascript. Supports look to scroll on VisionOS. Find-in-page support. UIKit UIKit is not going away and continues to get useful updates: Whatâ€™s new in UIKit New design system. UISplitViewController support for inspectors and resizable columns. iPadOS menu bar. Menu bars no longer supported in storyboards. Swift Observable to invalidate and update views. Back-deploys to iOS 18. updateProperties() called before layoutSubviews. Support for SwiftUI scene lifecycle, deprecating app delegate callbacks. SF Symbols new effects. Build a UIKit app with the new design UIKit components have been updated with Liquid Glass. Tab bar floats above content. Set desired direction when it minimizes on scroll. Extend background behind sidebars. Toolbars visually group items. Navigation item subtitle. Remove custom backgrounds from navigation, toolbars, and sheets. Search bar placement. Search as a dedicated view. Control sizes are larger. UIGlassEffect. iPadOS A good year for iPadOS bringing macOS style windowing and menu bars to the platform: Make your UIKit app more flexible Best practises to make your app adapt across sizes and platforms. Adopt UIScene life cycle - mandatory in next major release. New trait to determine if parent split view is collapsed. Split view support for Inspector column. UISceneSizeRestrictions to set preferred minimum size. Scenes on iPadOS have macOS style window controls. Use layout guide to keep content clear. UIRequiresFullScreen is deprecated and will be ignored in a future release. Apps will no longer be scaled for new screen sizes. AppKit Build an AppKit app with the new design Rebuild with Xcode 26 to get the Liquid Glass design. Use NSSplitViewController for new glass sidebar, removing any visual effects from sidebar. NSBackgroundExtensionView to mirror and extend content. New larger control sizes and corner radius. Add icons to menu items. watchOS Whatâ€™s new in watchOS 26 New toolbar and control styles. Use Icon Composer to update your icon. The arm64 architecture is used by Series 9 and later, and Ultra 2 devices. WidgetKit controls in control center, smart stack, or action button. Widgets now configurable. RelevanceKit to suggest widgets in smart stack. Push updates to widgets using APNs. Developer Tools Xcode gets LLM-based coding assistants: Whatâ€™s new in Xcode 26 Xcode is 24% smaller, no Intel simulator runtimes by default. New tab start page. Pin tabs. Multi-word search. Swift Mode for Voice Control. Playground macro work likes Preview to iterate on code. Type safe Swift symbols for localized strings with auto-generated comments. Coding assist using ChatGPT and other third-party LLMâ€™s (needs macOS Tahoe). Debugger now follows execution into async tasks. Metrics recommendations. Explicitly Built Modules now the default. Enhanced Security capability. XCTHitchMetric. Icon Composer Create icons with Icon Composer New tool to build icons for all platforms in a single file. Start in preferred design tool then export layers for Icon Composer. Add .icon file direct to Xcode project. Instruments Profile and optimize power usage in your app Power Profiler in Instruments. Also available on-device in Developer mode. Optimize CPU performance with Instruments Processor Trace collects complete trace, avoiding sampling bias. Requires M4 or A18. Enable developer setting on device. CPU Counters instrument to find code bottlenecks. Optimize SwiftUI performance with Instruments Interesting new instrument to find performance issues with SwiftUI. Use Cause \u0026 Effect graph to understand dependencies including Observables and the Environment that might be causing view updates. Localization Code-along: Explore localization with Xcode Walk-through localizing an App with String Catalogs. Automatic comment generation using on-device model. New #Bundle macro to refer to resource bundle of current target. Xcode generated symbol names from key/value, enabled by default for new projects. Refactor to convert strings to symbols. Testing Record, replay, and review: UI automation with Xcode Coding Assistant can add accessibilityIdentifiers to relevant parts of view. New code generation system for UI test recording. SwiftData No Core Data sessions this year and only a small update to SwiftData. Not sure anyone was asking for inheritance: SwiftData: Dive into inheritance and schema migration Class inheritance for models. Use for IS-A relationships when you need deep and shallow searches (queries for both root class and subclass). New sortBy property on HistoryDescriptor to fetch history in order. Example of using history tracking to update context for remote changes. WidgetKit Whatâ€™s new in widgets Adjust existing widgets for clear glass or accented tint presentation. Widgets now on visionOS 26. Can be elevated or recessed into surface. Fixed in space, adapt based on distance of viewer. Widgets and Live Activities on CarPlay. Live Activities on a paired iPhone now appear on macOS Tahoe menu bar. Controls on macOS and watchOS. Widget push updates. Design The Liquid Glass sessions are essential viewing this year: Meet Liquid Glass Liquid Glass lensing bends and shapes light. Adapts to ensure legibility and separate controls from content. Best reserved for navigation layer that floats above content. Do not stack Liquid Glass. Only tint to emphasise primary elements and actions. Reduced Transparency makes Liquid Glass frostier. Get to know the new design system Adjusted System colors for Liquid Glass. Alert Text is left-aligned. Concentricity aligns radii so shapes nest. Larger controls use capsule shapes. Sheets spring from an action source. Remove custom backgrounds from controls. Primary action stays separate and tinted. Hard scroll edge effect on macOS for stronger boundary. Bars rely more on symbols, see HIG for glyphs for common actions. Design foundations from idea to interface Start with app structure. Where am I? What can I do? Where can I go from here? Use toolbar for screen specific actions. Progressive disclosure. Group by time, progress or patterns. Use a cohesive visual style. Design is never really finished. Make a big impact with small writing changes Simplify. Too many filler adverbs and adjectives. Does each word add value. Donâ€™t apologise for errors. Avoid repetition. Lead with the why (move the benefit to the front). Word list to track terms with use/donâ€™t use and definition. Read your writing out loud. Principles of inclusive app design One in seven people have a disability. Vision. Hearing. Motor. Speech. Cognitive. Inclusive design is better for everyone. Involve members of the disability community in your design. Test with VoiceOver and Switch Control. Whatâ€™s new in SF Symbols 7 Draw path animation inspired by handwriting. Symbol gradients. Annotate custom symbols with path to draw. Say hello to the new look of app icons Liquid glass material layers. Monochrome, light, and dark tint, translucent appearance modes. Rounder corner radius. macOS icons no longer extend outside the shape. Layers \u0026 translucency. Use softer light-to-dark gradients for backgrounds. Use System Light and System Dark for white or black backgrounds. Design interactive snippets Compact views displayed from App Intents in Siri, Spotlight, and Shortcuts. Quick, in-moment experiences. Easy to read with larger type, concise, clear contrast. Buttons for interaction. Result and confirmation snippets. Platform specific sessions: Elevate the design of your iPad app Consider starting with a tab bar. Extend content around navigation. New windowing system with new controls. Apps not yet updated for iOS 26 show controls in safe area. Create a new window for each document. Name your windows. New pointer shape. Menu bar on top edge of iPad. Design widgets for visionOS Three dimensional objects. Compatibility mode for existing iPadOS widgets. Widgets persist in location and are fixed in size. Adapt with user proximity. Paper or glass styles. Elevated or recessed mounting styles. Design hover interactions for visionOS Custom hover effects. Look to scroll. Starts when user looks at edge of scroll view. Opt-in, enable when view is primarily for reading or browsing. Persistent controls stay visible while you look at them. Accessibility Evaluate your app for Accessibility Nutrition Labels Show which accessibility features you support in App Store Connect. Contrast. Dark interface. Larger text. Color. Captions. Reduced Motion. VoiceOver. Make your Mac app more accessible to everyone Group accessibility items into containers for faster navigation with VoiceOver. Merge label and buttons. Rotors to define collections of views. In macOS 26 can suggest initial focus for VoiceOver. Add keyboard shortcuts. Customize your app for Assistive Access Streamlined experience for people with cognitive disabilities. Create an assistive access scene. Set UISupportsAssistiveAccess in Info.plist. Keep to essential features. Icons are supported in the navigation bar. App Store and Distribution Whatâ€™s new in App Store Connect Upload builds with App Store Connect API later this year. Can reuse a build number if upload fails. Apple-hosted background assets (up to 200GB). TestFlight feedback now in App Store Connect app. App Store Tags generated by Appleâ€™s LLM (human reviewed) you can deselect unwanted tags. Keywords for custom product pages. Offer codes for consumables, non-consumables and non-renewing subscriptions. Review summaries. New age ratings. Accessibility Nutrition Labels. Over 100 new App Analytics metrics. Automate your development process with the App Store Connect API Build upload API and Feedback API. Webhook notifcations API. Apple-Hosted Background Assets API. Dive into App Store server APIs for In-App Purchase App transaction ID added to AppTransaction. Unique ID for each Apple Account per app use to associate customer account with all transactions. Signing requests all use JWS signature format. New Send Consumption Information endpoint when responding to refunds. Optimize your monetization with App Analytics New App Analytics home. Expanded filtering and over 100 new metrics. New monetization section. Machine Learning and Apple Intelligence An API to access an on-device Large Language Model (LLM) was high on everyoneâ€™s wish list: Meet the Foundation Models framework API access to Appleâ€™s LLM. On-device so data stays private and can run offline. Experiment with prompts using the new Playground feature in Xcode. On-device model not intended for world knowledge or advanced reasoning. Adapters for common tasks. Use @Generable and @Guide to define Swift type that models returns. Streams partially generated types. Model can callout to tools you define. Session instructions get priority over user prompts. Context is retained during a session. Only available where Apple Intelligence is available. Deep dive into the Foundation Models framework Session throws error when it reaches available context size. Create new session with extract or summary from previous session to provide context. Greedy sampling produces deterministic output. Check for supported languages. @Generable macro defines structured schema for responses. Constrained decoding forces model to return valid tokens for the schema. String properties can use a regex pattern guide. Tool protocol to define functions model can call to access external data. Explore prompt design \u0026 safety for on-device foundation models On-device LLM has ~3-billion parameters, small when compared to cloud based models. May need to break down complex prompts. Avoid maths, code, or tasks requiring real world knowledge. Avoid where facts are critical or provide verified information in prompt. Use prompts like â€œin a few wordsâ€ or â€œin detailâ€ to control output. Provide model with a role. Ask a single, detailed task. Less than five examples in prompt. Use â€œDO NOTâ€. Apple designed guardrails to block harmful inputs and throw safety errors. Use instructions to steer model output. Never include user input in instructions. Code-along: Bring on-device AI to your app using the Foundation Models framework See sample code for example of adding Foundation model to generate trip itineraries. Using FoundationModel instrument to profile performance. Discover machine learning \u0026 AI frameworks on Apple platforms Platform tools: Writing Tools, Genmoji. Image Playground. ImageCreator and Foundation Models. ML-APIâ€™s: Vision. Natural Language. Translation. Sound Analysis. SpeechAnalyzer. Core ML models. Apple MLX for numerical computing and machine learning. Get started with MLX for Apple silicon MLX open source array framework for Apple silicon. Closely follows numPy. Use from Python, Swift, C++, or C. Explore large language models on Apple silicon with MLX Example of using an M3 Ultra with 512GB unified memory to run latest DeepSeek model. Use Python to load and query LLMâ€™s on-device. Reduce precision by quantizing a model thatâ€™s faster to run with reduced memory. Fine tune by training on-device with domain-specific data. MLXSwift to integrate model into Swift code. Dive deeper into writing tools Now on visionOS. Follow-up requests. Rich text with presentation intents. Writing Tools coordinator for custom text engines. Bring advanced speech-to-text to your app with SpeechAnalyzer New API with new speech-to-text model. Faster and more flexible than SFSpeechRecognizer. Supports long-form, conversational, and distant speakers. Live transcription. Private on-device model. Read documents using the Vision framework New API for reading documents. Extract document structure such tables, lists, paragraphs. Identify QR codes, email addresses, phone numbers, URLs. Camera lens smudge detection - prompt user to clean camera lens when dirty. Hand pose detection uses a smaller, modernized model. Whatâ€™s new in BNNS Graph Basic Neural Network Subroutines, CPU-based inference for tasks like audio or image processing. BNNSGraphBuilder new Swift API to write graphs of operations in Swift. Smaller, real-time and latency-sensitive use cases. App Intents Get to know App Intents Recap of how and why to implement App Intents. App Intents can be added to Swift packages and libraries. Explore new advances in App Intents Interactive snippets. Appâ€™s search results show up in image search. NSUserActivities to ask ChatGPT about onscreen content. Conform app entities to IndexedEntity and donate to Spotlight. UndoableIntent protocol. New Intent to work with SwiftUI navigation path. Computed App Entity properties. Develop for Shortcuts and Spotlight with App Intents Access Apple Intelligence models from shortcuts. On-device, private compute cloud, or ChatGPT. Run app actions from Spotlight on Mac. App Services Whatâ€™s new in Apple Pay Apple Pay dynamic button shows default payment card. Unified preauthorized payments view and notifications. Automatic order tracking, Apple Intelligence detects order and delivery emails in the mail app, converting them to Wallet orders. FinanceKit API now available in UK. Now supports background delivery extension. Whatâ€™s new in Wallet Poster Event Ticket (iOS 18) now supports multiple upcoming events from one ticket. Boarding passes integrate with Appleâ€™s flight service for updates. New live activity for access to flight information (share via messages). Add passes to wallet automatically (one-time user prompt). Turbocharge your app for CarPlay Message tapbacks, pinned conversations, and compact incoming call UI that doesnâ€™t interrupt navigation. Widgets and Live Activities donâ€™t need CarPlay App (support system small widget). Can exclude CarPlay for game and highly interactive widgets. Whatâ€™s new in AdAttributionKit Privacy preserving Ad analytics (iOS 17.4). From iOS 18.4, multiple re-engagement campaigns. Configurable attribution window and cooldown period to handle overlapping campaigns. Country code in the postback. Create test postbacks in the iOS Settings app (iOS 18.4). Enhance your appâ€™s multilingual experience Better support for people who are multilingual. Arabizi transliteration keyboard converts latin script to Arabic. Bilingual Arabic-English keyboard. Thai keyboard. Multilingual Siri recommendations. Locale.preferredLanguages may be deprecated, switch to Locale.preferredLocales. Alternate calendars for Gujarati, Marathi, and Korean. Natural selection of bidirectional text (combining LTR and RTL). Writing direction is determined dynamically. Wake up to the AlarmKit API Framework to create alarm based on schedule or countdown. Countdown live activity. Authorization required. Secondary button to run app intent to open app. Whatâ€™s new in StoreKit and In-App Purchase AppTransaction now includes appTransactionID and originalPlatform. New SubscriptionStatus API. Offer codes now available for consumables, non-consumables, and non-renewing subscriptions. New server APIs require a JSON web signature. New subscription offer view. Meet PaperKit Canvas for drawing and markup elements. Uses by Notes and Journal apps. Now available for macOS Tahoe. System Services Finish tasks in the background New continued processing task. Started by explicit user action, like an export. Has a definite end. Not for routine maintenance, backups, sync. Provide progress updates to the system and an expiration handler. Background GPU access. Supercharge device connectivity with Wi-Fi Aware New in iOS 26, Wi-Fi Aware, cross-platform standard, for direct device-to-device connectivity. Filter and tunnel network traffic with NetworkExtension Use Network Extension to build a VPN app. Use Content Filter API to filter content. In iOS 26, filter on full URL using URL filter. App has no access to traffic. System performs the filtering on behalf of app to maintain privacy. Use structured concurrency with Network framework In iOS and macOS 26 Network framework integrates with Swift concurrency. Declarative syntax to define the protocol stack. Send and receive are async functions. Built-in type, length, value (TLV) framer. Directly send/receive codable types. Network browser to discover devices using Wi-Fi Aware or Bonjour. Optimize home electricity usage with EnergyKit Seems to be US only, provides insights into the local electricity grid so people can reduce or shift usage to take advantage of cheaper/cleaner energy. Discover Apple-Hosted Background Assets On Demand Resources is a legacy technology and will be deprecated, migrate to Background Assets. Apple Developer Program includes 200GB of Apple hosting capacity. Packaging tool to create asset packs. System provides full-featured downloader extension which you can drop into your app. Mock server ships with Xcode so you can test locally. Photos and Camera Enhance your appâ€™s audio recording capabilities In-app input device selection on iOS using new AVKit API. New high quality bluetooth recording option using AirPods. Spatial Audio capture and AudioMix effect. Enhancing your camera experience with capture controls Using device buttons to control camera capture. AirPod clicks to remotely control camera without touching device. Privacy and Security Integrate privacy into your development process Data minimization, on-device processing, transparency and control, protections. Whatâ€™s new in passkeys New account creation API shows a pre-filled sheet and saves passkey in Passwords app. Synced across devices. New Signal API to tell password manager that user details changed, revoke a passkey, or that a password is no longer needed. Securely transfer passkeys between credential manager apps. Enhance child safety with PermissionKit Uses Family Sharing group to allow child to ask permission from a parent or guardian using Messages. Deliver age-appropriate experiences in your app App Store has finer grained age categories. Parent sets a childâ€™s age range. Declared Age Range framework to confirm a childâ€™s age range. Using age range keeps birth date private. Get ahead with quantum-secure cryptography Harvest now and decrypt later attack requires mitigation now. Quantum secure algorithms are ready for adoption. iMessage already uses quantum secure hybrid encryption. TLS 1.3 has a quantum secure encryption upgrade. Enabled by default in iOS 26. CryptoKit has new secure algorithms. Maps and Location Go further with MapKit New GeoToolbox framework with PlaceDescriptor to find rich data about a place when working with MapKit or other mapping providers. Geocoding now in MapKit deprecating Core Location classes CLGeocoder and CLPlacemark. Cycle directions. Many MapKit APIs now on watchOS. Look Around on MapKitJS. Health and Fitness Meet the HealthKit Medications API New Medications API to read medications data user adds in the Health app. Sample app shows logging of side-effects. Track workouts with HealthKit on iOS and iPadOS Best practises for tracking workouts on iOS. Pair with a heart rate monitor. Access workout data when locked. Siri intent handler to start and stop workouts. App is automatically relaunched on crash, recover active workout. Audio and Video Enhance your app with machine-learning-based video effects New ML-based video-editing effects for Video Toolbox now also available on iOS. Includes frame rate conversion, super resolution and motion blur. Create a seamless mutliview playback experience Playing multiple streams of audio/video, synchronized and unsynchronized using AVFoundation and AVRouting with AirPlay integration. Capture cinema video in your app Cinematic video introduced with iPhone 13 allowing user to rack focus between subjects. New Cinematic Video API to capture cinematic video. Safari and Web Whatâ€™s new in Safari and WebKit Safari 19 features. CSS scroll-driven animations. Cross document transitions. Anchor layout positioning. Background-clip, shape(), text-wrap: pretty. SVG icons. HDR images. Ogg Opus and Ogg Vorbis. Verify identity documents on the web Online identity verification using digital identity documents. IDâ€™s in Apple Wallet use the mdoc format (US only). W3C Digital Credentials API to request mdocs from Safari and WebKit. Learn more about Declarative Web Push Enhancement of original Web Push to allow notifications to be defined directly in JSON without code. Whatâ€™s new for the spatial web New HTML Model element, stereoscopic rendering. 180/360-degree or wide field of view spatial video. Website environments in Safari developer preview to provide a virtual environment to website visitors. Spatial Computing Apple continues to extend visionOS: Whatâ€™s new in visionOS 26 SwiftUI 3D layout modifiers. Presentation from volumes. Render outside appâ€™s bounds. Object Manipulation API. Unified coordinate conversion. RealityKit entities are Observable, directly attach SwiftUI gestures. Spatial Audio Experience API. Persist views in place across restarts. Faster (3x) hand tracking. Support for Sony VR2 and Logitech Muse controllers. Increased memory limits. Render and stream content from a Mac. Nearby Window Sharing in SharePlay apps. Apple Projected Media Profiles. Look to scroll. New Enterpise APIs. Whatâ€™s new in RealityKit tvOS support. Direct access to ARKit data for anchoring. Pick up and rotate 3D objects and swap hands. Add collision and physics to real world objects. Hide entities behind static real objects. Present 2D images, spatial photos and scenes. Immersive video. Add SwiftUI views directly to entities. Set the scene with SwiftUI in visionOS Windows, volumes, and widgets can lock in place, use scene restoration to bring them back. Default launch behaviour. Snap windows and volumes to physical environment. Stream immersive spaces from macOS to visionOS. Scene Bridging to add SwiftUI volumes and immersive spaces to UIKit or AppKit apps. Meet SwiftUI spatial layout 3D extensions to SwiftUI layout system to build 3D scenes without RealityKit. Most modifiers have a 3D analog. Better together: SwiftUI and RealityKit Load animations from a Model3DAsset. RealityKit entities are now observable. Object Manipulation API works from both SwiftUI or RealityKit. Attach SwiftUI views, gestures, and presentations directly within RealityKit scenes. Unified Coordinate Conversion to convert between RealityKit and SwiftUI. Share visionOS experiences with nearby people Share apps with nearby people in the same space. Participate remotely with FaceTime. Builds on SharePlay. Explore spatial accessory input on visionOS Support for spatial accessories: Sony PlayStation VR2 Sense controller and Logitech Muse. Optimize your custom environments for visionOS Optimizing and baking assets using Houdini procedural tools. Explore video experiences for visionOS Choosing between different video profiles from 2D, 3D, Spatial, 180, 360, Wide and Apple Immersive Video. Blackmagic URSA Cine Immersive camera captures 8160 x 7200 pixels per eye at 90fps. Learn about Apple Immersive Video technologies Apple Immersive Video requires specific cameras like the BlackMagic URSA to capture. How to read, write, and publish immersive videos. New Apple Spatial Audio Format (ASAF) encode with Apple Positional Audio Codec (APAC), playback on all platforms except watchOS. Support immersive video playback in visionOS apps Immersive video playback using QuickLook, AVKit, or RealityKit. Comfort mitigation to detect high motion and reduce immersion. Learn about the Apple Projected Media Profile APMP supports 180, 360, and wide FOV video, can be captured with consumer devices. QuickTime and MP4 file formats. Already supported by Final Cut Pro. Reading, writing, editing, and publishing with Core Media, Video Toolbox, and AVFoundation. Business and Education Whatâ€™s new in Apple device management and identity Prevent personal Apple Accounts from signing-in to work devices. Migrate between MDM servers. Declarative Device Management extended to Vision Pro and Apple TV. Safari management of bookmarks and homepage. Device reset can now preserve managed apps when wiping user data. Per-app control of app updates. Authenticated Guest mode for shared macs. Tap to login using iPhone or watch. Get to know the ManagedApp Framework New framework for managed deployments. Provide app configuration, provision passwords, certs, and identities. Works with single sign-on, and device attestation. Explore enhancements to your spatial business app Enterprise APIs for in-house visionOS apps. External video and Neural Engine access no longer needs enterprise license. Vision Entitlement Services to check licenses and entitlements. Window follow mode. New ARKit enterprise API to share coordinate spaces. Protected content API to prevent screen captures and sharing. CameraRegionView for dedicated view of specific area you want to watch. Metal and Games Metal 4 is supported on the M1 and A14 Bionic or later: Discover Metal 4 Explore Metal 4 games Go further with Metal 4 games Level up your games Combine Metal 4 machine learning and graphics Whatâ€™s new in Metal rendering for immersive apps Apple Games Get started with Game Center Use GameKit bundle in Xcode to configure Game Center features. Allows testing of achievements and leaderboards in Xcode. New features for Challenges and Activities. Engage players with the Apple Games app New Games app pre-installed on devices. Any Apps with the Games category show up in the app. Includes Apple Arcade and Game Center in a dedicated games app to make it easier to discover games. Bring your SceneKit project to RealityKit SceneKit is soft-deprecated. SceneKit apps continue to work but framework is in maintenance mode and not recommended. New apps and significant updates should use RealityKit. Differences and ways to port SceneKit apps to RealityKit. WWDC 2025 Viewing Guide was originally posted 16 Jun 2025 on useyourloaf.com. WWDC25 Sale! Save 20% off Modern Auto Layout",
    "author": "",
    "published": "Mon, 16 Jun 2025 09:00:00 +0100",
    "image": "",
    "source": "https://useyourloaf.com/blog/rss.xml",
    "categories": null
  },
  {
    "id": "82b6f62e-6932-474d-85e4-9afef5ff8096",
    "title": "Syncing TipKit with CloudKit",
    "link": "https://useyourloaf.com/blog/syncing-tipkit-with-cloudkit/",
    "description": "Starting in iOS 18 you can sync the state of TipKit tips across devices with CloudKit. TipKit Tip State Apple introduced TipKit in iOS 17 as a consistent way to show in-context tips to users. TipKit keeps track of how often it displays tips, when it has invalidated tips, and the events/rules that control when it should show tips. Starting in iOS 18, you can opt-in to syncing the TipKit state across devices using CloudKit. That avoids showing the user the same tips on each of their devices. Syncing With CloudKit Enabling CloudKit sync for TipKit follows a similar process to enabling sync for Core Data. Select your App target in Xcode. In the Signing \u0026 Capabilities tab, use the + Capability button, double-click the iCloud capability and select CloudKit in the iCloud section. This also adds the Push Notifications capability: In the iCloud capability section, use the + button, below the list of containers, to add a container identifier for the TipKit datastore: Use a reverse domain name to create the identifier, ending with â€œ.tipsâ€. Xcode automatically includes the â€œiCloudâ€ prefix. The new container can take a few seconds to show up in the iCloud console. Xcode shows the identifier in red until itâ€™s ready: Repeat the process to add the Background Modes capability to your App target and enable the Remote notifcations option: TipKit does not sync to CloudKit by default. You must enable the CloudKit container when configuring the Tips datastore: try Tips.configure([ .cloudKitContainer(.automatic) ]) Note: The .automatic option uses the first container in your appâ€™s entitlements that ends with â€œ.tipsâ€. You can override the automatic behaviour by passing an identifier: try Tips.configure([ .cloudKitContainer(.named(\"iCloud.com.apple.myapp.tips\")) ]) Core Data Container Identifier Be careful if youâ€™re already syncing a Core Data/SwiftData database with CloudKit. By default, NSPersistentCloudKitContainer looks for the first iCloud Container identifier in the Appâ€™s entitlements file. If youâ€™re not careful you may have listed your TipKit identifier first and your Core Data stack can end up trying to use it. Apple recommends you use a separate container for syncing tips. As a workaround, make sure to list your Core Data/SwiftData identifier first in the entitlements file: Alternatively you can explicitly set the container identifier before loading the persistent store when creating your Core Data stack: storeDescription.cloudKitContainerOptions = NSPersistentCloudKitContainerOptions( containerIdentifier: \"com.useyourloaf.myapp\") Learn More WWDC24 Customize feature discovery with TipKit One More Thing If youâ€™re working with UIKit and want to brush up your layout skills make sure to grab a copy of my book Modern Auto Layout. Itâ€™s 20% off in the WWDC25 sale!. Syncing TipKit with CloudKit was originally posted 02 Jun 2025 on useyourloaf.com. WWDC25 Sale! Save 20% off Modern Auto Layout",
    "author": "",
    "published": "Mon, 02 Jun 2025 11:43:39 +0100",
    "image": "https://useyourloaf.com/blog/syncing-tipkit-with-cloudkit/001.png",
    "source": "https://useyourloaf.com/blog/rss.xml",
    "categories": null
  },
  {
    "id": "c6fab443-2f7f-467b-b279-99baa1ea6a76",
    "title": "Solar Powered Birdhouse",
    "link": "https://atomicbird.com/blog/birdhouse-solar-power/",
    "description": "In my last couple of posts Iâ€™ve talked about the hardware and software behind my birdhouse camera project. I havenâ€™t previously covered how Iâ€™m giving it all enough power to operate, and therein lies a tale. No Power? No Problem If I had a power outlet located anywhere near the bird house, this would have been easy. Pretty much any micro-USB power adapter would plug into the Raspberry Pi, and Iâ€™d be set.",
    "author": "",
    "published": "Thu, 19 May 2022 00:00:00 +0000",
    "image": "",
    "source": "https://atomicbird.com/index.xml",
    "categories": null
  },
  {
    "id": "8b1e7b7c-b3e6-49aa-879f-3119ad691027",
    "title": "Raspberry Pi Birdhouse Software",
    "link": "https://atomicbird.com/blog/birdhouse-software/",
    "description": "In my last post I went over the components of the bird house camera I set up this year to get a better look at the local black-capped chickadees. Today Iâ€™ll talk about the software that makes it work. Initial Setup Being relatively new to Raspberry Pi, I started off with a full install of Raspbian Deskop. Itâ€™s more than I need, since I wonâ€™t have anything like a desktop setup, but with a 64GB SD card I wasnâ€™t concerned about the space.",
    "author": "",
    "published": "Mon, 09 May 2022 00:00:00 +0000",
    "image": "",
    "source": "https://atomicbird.com/index.xml",
    "categories": null
  }
]
