{
  "id": "7f91c1c9-d94f-4686-8ec0-6183b693094d",
  "title": "Meta faces Ghana lawsuits over impact of extreme content on moderators",
  "link": "https://www.theguardian.com/technology/2025/apr/27/meta-faces-ghana-lawsuits-over-impact-of-extreme-content-on-moderators",
  "description": "Workers at contractor in Accra say they have suffered from depression and anxiety as a result of their work‘I didn’t eat or sleep’: a Meta moderator on his breakdownMeta is facing a second set of lawsuits in Africa over the psychological distress experienced by content moderators employed to take down disturbing social media content including depictions of murders, extreme violence and child sexual abuse.Lawyers are gearing up for court action against a company contracted by Meta, which owns Facebook and Instagram, after meeting moderators at a facility in Ghana that is understood to employ about 150 people.In the UK and Ireland, Samaritans can be contacted on freephone 116 123, or email jo@samaritans.org or jo@samaritans.ie. In the US, you can call or text the National Suicide Prevention Lifeline on 988, chat on 988lifeline.org, or text HOME to 741741 to connect with a crisis counselor. In Australia, the crisis support service Lifeline is 13 11 14. Other international helplines can be found at befrienders.org Continue reading...",
  "author": "Rachel Hall and Claire Wilmot in Nairobi",
  "published": "Sun, 27 Apr 2025 05:00:24 GMT",
  "source": "https://www.theguardian.com/world/rss",
  "categories": [
    "Meta",
    "Social media",
    "Ghana",
    "Africa",
    "World news",
    "Technology"
  ],
  "byline": "Rachel Hall",
  "length": 7790,
  "excerpt": "Workers at contractor in Accra say they have suffered from depression and anxiety as a result of their work",
  "siteName": "the Guardian",
  "favicon": "https://assets.guim.co.uk/static/frontend/icons/homescreen/apple-touch-icon-512.png",
  "text": "Meta is facing a second set of lawsuits in Africa over the psychological distress experienced by content moderators employed to take down disturbing social media content including depictions of murders, extreme violence and child sexual abuse.Lawyers are gearing up for court action against a company contracted by Meta, which owns Facebook and Instagram, after meeting moderators at a facility in Ghana that is understood to employ about 150 people.Moderators working for Majorel in Accra claim they have suffered from depression, anxiety, insomnia and substance abuse as a direct consequence of the work they do checking extreme content.The allegedly gruelling conditions endured by workers in Ghana are revealed in a joint investigation by the Guardian and the Bureau of Investigative Journalism.It comes after more than 140 Facebook content moderators in Kenya were diagnosed with severe post-traumatic stress disorder caused by exposure to graphic social media content.The workers in Kenya were employed by Samasource, an outsourcing company that carries out content moderation for Meta using workers from across Africa. Majorel, the company at the centre of the allegations in Ghana, is owned by the French multinational Teleperformance.One man, who cannot be named for legal reasons, said he attempted suicide owing to the nature of his work. His claims his contract was subsequently terminated and he has returned to his home country.Facebook and other large social media companies employ armies of content moderators, often based in the poorest parts of the world, to remove posts that breach their community standards and to train AI systems to do the same.Moderators are required to review distressing and often brutal pictures and videos to establish whether they should be removed from Meta’s platforms. According to workers in Ghana, they have seen videos of a person being skinned alive and a woman being beheaded.The moderators claim mental health care offered by the firm was unhelpful, was not delivered by medical doctors, and that personal disclosures made by staff about the effects of their work were circulated among managers.Teleperformance disputed this, saying it employed licensed mental health professionals who are registered with the local regulatory body and hold a master’s degree in psychology, counselling, or another mental health field.The legal case is being prepared by a UK-based nonprofit, Foxglove. It would be the second case brought by content moderators in Africa, after Samasource workers in Kenya sued in 2023.Foxglove said it was “urgently investigating these shocking abuses of workers” with a view to using “every tool at our disposal, including potential legal action” to improve working conditions.It is working with a Ghanaian firm, Agency Seven Seven, on preparing two possible lawsuits. One would allege psychological harms and could involve a group of moderators, and the other unfair dismissal, involving the moderator from east Africa whose contract was terminated after he attempted suicide.Foxglove’s co-executive director Martha Dark said: “These are the worst conditions I have seen in six years of working with social media content moderators around the world.“In Ghana, Meta is displaying nothing short of a complete disregard for the humanity of its key safety workers upon whom all its profits rely: content moderators. They are treated as objects who can be used up, burned out and replaced with no care whatsoever for the permanent damage to their mental and physical wellbeing.”Dark said basic wages for content moderators in Accra were below living costs, incentivising them to work overtime, for which pay is understood to be even lower than normal rates. Moderators faced deductions from their pay for failing to meet performance targets, she added.Contracts seen by the Guardian show that the base wage starts at about 1,300 Ghanaian cedis a month – just over £64. This is supplemented by a system of performance-related bonuses, the upper range of which amounts to about 4,900 cedis (£243) a month, significantly less than the estimated cost of living in Accra.A Teleperformance spokesperson said content moderators enjoyed “strong pay and benefits, including monthly pay that is roughly 10 times the country’s minimum wage for domestic moderators, and 16 times the minimum wage for those who have relocated from other countries, when including project allowance, transportation allowance, language premium and more – all of which are automatically paid to the moderator and are not performance-based”. Foxglove’s researcher Michaela Chen said she had seen photos of moderators’ living quarters, in which they were “crammed five to a flat, two to a room”. She said there appeared to be a culture of secrecy, including surveillance from managers, who follow workers into the toilets during breaks.This extends to moderators’ work for Meta. She said: “Workers spend all day working on Meta’s platforms, moderating to Meta’s standards and using Meta’s systems, but at the same time, moderators are told constantly: ‘You do not work for Meta,’ and are forbidden from telling anyone they do.” Teleperformance said moderators were “offered housing in … one of the most upscale and well-known residential and commercial neighbourhoods in Accra”. The spokesperson described the housing as “safe, with strong security” and having air conditioning, recreation facilities, including gyms and pools.Carla Olympio, a partner at Agency Seven Seven, said she believed a personal injury case could succeed in Ghana’s courts and would set a precedent establishing that worker protections extend to psychological harms as well as physical injury.“[There is] currently a gap in our laws because they haven’t necessarily caught up with the new developments that cover technology and virtual work,” she said. Rosa Curling, a co-executive director at Foxglove, said it was seeking for the court to “order immediate changes to the content moderators’ workplace”, including proper safeguards and psychiatric care.A spokesperson for Teleperformance said: “At TP in Ghana, we take our content moderation work seriously. From the very beginning during the interview process, within the employee contract and through employee training and resiliency testing, we are fully transparent with our prospective moderators regarding the content they might see during their work to help keep the internet safe for our communities. We have robust people management systems and workplace practices, including a robust wellbeing programme staffed by fully licensed psychologists to support our content moderators throughout their content moderation journey.” Meta said the companies it worked with were “contractually obliged to pay their employees who review content on Facebook and Instagram above the industry standard in the markets they operate”.The tech company said it took “the support of content reviewers seriously”, including detailing expectations around counselling, training and other support in contracts with the companies it outsourced. It said all content moderators signed client confidentiality agreements because they were dealing with user information which needed to be protected and for their own safety, but moderators may discuss their jobs with doctors and counsellors, and some aspects with family members. In the UK and Ireland, Samaritans can be contacted on freephone 116 123, or email jo@samaritans.org or jo@samaritans.ie. In the US, you can call or text the National Suicide Prevention Lifeline on 988, chat on 988lifeline.org, or text HOME to 741741 to connect with a crisis counselor. In Australia, the crisis support service Lifeline is 13 11 14. Other international helplines can be found at befrienders.org",
  "image": "https://i.guim.co.uk/img/media/66e7026f6525d25aa0746ee38bc9a029c35f3844/0_125_3500_2099/master/3500.jpg?width=1200\u0026height=630\u0026quality=85\u0026auto=format\u0026fit=crop\u0026overlay-align=bottom%2Cleft\u0026overlay-width=100p\u0026overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc\u0026enable=upscale\u0026s=6cae2e489b93994b3bc29314fa45b592",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"maincontent\"\u003e\u003cp\u003eMeta is facing a second set of lawsuits in \u003ca href=\"https://www.theguardian.com/world/africa\" data-link-name=\"in body link\" data-component=\"auto-linked-tag\"\u003eAfrica\u003c/a\u003e over the psychological distress experienced by content moderators employed to take down disturbing social media content including depictions of murders, extreme violence and child sexual abuse.\u003c/p\u003e\u003cp\u003eLawyers are gearing up for court action against a company contracted by Meta, which owns Facebook and Instagram, after meeting moderators at a facility in \u003ca href=\"https://www.theguardian.com/world/ghana\" data-link-name=\"in body link\" data-component=\"auto-linked-tag\"\u003eGhana\u003c/a\u003e that is understood to employ about 150 people.\u003c/p\u003e\u003cp\u003eModerators working for Majorel in Accra claim they have suffered from depression, anxiety, insomnia and substance abuse as a direct consequence of the work they do checking extreme content.\u003c/p\u003e\u003cp\u003eThe allegedly gruelling conditions endured by workers in Ghana are revealed in a joint investigation by the Guardian and the Bureau of Investigative Journalism.\u003c/p\u003e\u003cp\u003eIt comes after \u003ca href=\"https://www.theguardian.com/media/2024/dec/18/kenya-facebook-moderators-sue-after-diagnoses-of-severe-ptsd\" data-link-name=\"in body link\"\u003emore than 140 Facebook\u003c/a\u003e content moderators in Kenya were diagnosed with severe post-traumatic stress disorder caused by exposure to graphic social media content.\u003c/p\u003e\u003cp\u003eThe workers in Kenya were employed by Samasource, an outsourcing company that carries out content moderation for \u003ca href=\"https://www.theguardian.com/technology/meta\" data-link-name=\"in body link\" data-component=\"auto-linked-tag\"\u003eMeta\u003c/a\u003e using workers from across Africa. Majorel, the company at the centre of the allegations in Ghana, is owned by the French multinational Teleperformance.\u003c/p\u003e\u003cp\u003eOne man, who cannot be named for legal reasons, said he attempted suicide owing to the nature of his work. His claims his contract was subsequently terminated and he has returned to his home country.\u003c/p\u003e\u003cp\u003eFacebook and other large social media companies employ armies of content moderators, often based in the poorest parts of the world, to remove posts that breach their community standards and to train AI systems to do the same.\u003c/p\u003e\u003cp\u003eModerators are required to review distressing and often brutal pictures and videos to establish whether they should be removed from Meta’s platforms. According to workers in Ghana, they have seen videos of a person being skinned alive and a woman being beheaded.\u003c/p\u003e\u003cp\u003eThe moderators claim mental health care offered by the firm was unhelpful, was not delivered by medical doctors, and that personal disclosures made by staff about the effects of their work were circulated among managers.\u003cbr/\u003e\u003cstrong\u003e\u003cbr/\u003e\u003c/strong\u003eTeleperformance disputed this, saying it employed licensed mental health professionals who are registered with the local regulatory body and hold a master’s degree in psychology, counselling, or another mental health field.\u003c/p\u003e\u003cp\u003eThe legal case is being prepared by a UK-based nonprofit, Foxglove. It would be the second case brought by content moderators in Africa, after Samasource workers in Kenya sued in 2023.\u003c/p\u003e\u003cp\u003eFoxglove said it was “urgently investigating these shocking abuses of workers” with a view to using “every tool at our disposal, including potential legal action” to improve working conditions.\u003c/p\u003e\u003cp\u003eIt is working with a Ghanaian firm, Agency Seven Seven, on preparing two possible lawsuits. One would allege psychological harms and could involve a group of moderators, and the other unfair dismissal, involving the moderator from east Africa whose contract was terminated after he attempted suicide.\u003c/p\u003e\u003cp\u003eFoxglove’s co-executive director Martha Dark said: “These are the worst conditions I have seen in six years of working with social media content moderators around the world.\u003c/p\u003e\u003cp\u003e“In Ghana, Meta is displaying nothing short of a complete disregard for the humanity of its key safety workers upon whom all its profits rely: content moderators. They are treated as objects who can be used up, burned out and replaced with no care whatsoever for the permanent damage to their mental and physical wellbeing.”\u003c/p\u003e\u003cp\u003eDark said basic wages for content moderators in Accra were below living costs, incentivising them to work overtime, for which pay is understood to be even lower than normal rates. Moderators faced deductions from their pay for failing to meet performance targets, she added.\u003c/p\u003e\u003cp\u003eContracts seen by the Guardian show that the base wage starts at about 1,300 Ghanaian cedis a month – just over £64. This is supplemented by a system of performance-related bonuses, the upper range of which amounts to about 4,900 cedis (£243) a month, significantly less than the estimated \u003ca href=\"https://www.numbeo.com/cost-of-living/in/Accra\" data-link-name=\"in body link\"\u003ecost of living in Accra\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eA Teleperformance spokesperson said content moderators enjoyed “strong pay and benefits, including monthly pay that is roughly 10 times the country’s minimum wage for domestic moderators, and 16 times the minimum wage for those who have relocated from other countries, when including project allowance, transportation allowance, language premium and more – all of which are automatically paid to the moderator and are not performance-based”.\u003c/p\u003e\u003cp\u003e\n Foxglove’s researcher Michaela Chen said she had seen photos of moderators’ living quarters, in which they were “crammed five to a flat, two to a room”. She said there appeared to be a culture of secrecy, including surveillance from managers, who follow workers into the toilets during breaks.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003eThis extends to moderators’ work for Meta. She said: “Workers spend all day working on Meta’s platforms, moderating to Meta’s standards and using Meta’s systems, but at the same time, moderators are told constantly: ‘You do not work for Meta,’ and are forbidden from telling anyone they do.”\u003c/p\u003e\u003cp\u003e\n Teleperformance said moderators were “offered housing in … one of the most upscale and well-known residential and commercial neighbourhoods in Accra”. \u003cstrong\u003e\u003cbr/\u003e\u003c/strong\u003e\u003cbr/\u003e\n The spokesperson described the housing as “safe, with strong security” and having air conditioning, recreation facilities, including gyms and pools.\u003c/p\u003e\u003c/div\u003e\u003cp\u003eCarla Olympio, a partner at Agency Seven Seven, said she believed a personal injury case could succeed in Ghana’s courts and would set a precedent establishing that worker protections extend to psychological harms as well as physical injury.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e“[There is] currently a gap in our laws because they haven’t necessarily caught up with the new developments that cover technology and virtual work,” she said.\u003c/p\u003e\u003cp\u003e\n Rosa Curling, a co-executive director at Foxglove, said it was seeking for the court to “order immediate changes to the content moderators’ workplace”, including proper safeguards and psychiatric care.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp\u003eA spokesperson for Teleperformance said: “At TP in Ghana, we take our content moderation work seriously. From the very beginning during the interview process, within the employee contract and through employee training and resiliency testing, we are fully transparent with our prospective moderators regarding the content they might see during their work to help keep the internet safe for our communities. We have robust people management systems and workplace practices, including a robust wellbeing programme staffed by fully licensed psychologists to support our content moderators throughout their content moderation journey.”\u003c/p\u003e\u003cp\u003e\n Meta said the companies it worked with were “contractually obliged to pay their employees who review content on Facebook and Instagram above the industry standard in the markets they operate”.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp\u003eThe tech company said it took “the support of content reviewers seriously”, including detailing expectations around counselling, training and other support in contracts with the companies it outsourced.\u003c/p\u003e\u003cp\u003e\n It said all content moderators signed client confidentiality agreements because they were dealing with user information which needed to be protected and for their own safety, but moderators may discuss their jobs with doctors and counsellors, and some aspects with family members.\u003c/p\u003e\u003c/div\u003e\u003cul\u003e\n \u003cli\u003e\n  \u003cp\u003e\u003cem\u003eIn the UK and Ireland, \u003ca href=\"https://www.samaritans.org/\" data-link-name=\"in body link\"\u003eSamaritans\u003c/a\u003e can be contacted on freephone 116 123, or email \u003ca href=\"mailto:jo@samaritans.org\" data-link-name=\"in body link | mailto:jo@samaritans.org\"\u003ejo@samaritans.org\u003c/a\u003e or \u003ca href=\"mailto:jo@samaritans.ie\" data-link-name=\"in body link | mailto:jo@samaritans.ie\"\u003ejo@samaritans.ie\u003c/a\u003e. In the US, you can call or text the \u003ca href=\"https://988lifeline.org/\" data-link-name=\"in body link\"\u003eNational Suicide Prevention Lifeline\u003c/a\u003e on 988, chat on \u003ca href=\"https://988lifeline.org/chat/\" data-link-name=\"in body link\"\u003e988lifeline.org\u003c/a\u003e, or \u003ca href=\"https://www.crisistextline.org/\" data-link-name=\"in body link\"\u003etext HOME\u003c/a\u003e to 741741 to connect with a crisis counselor. In Australia, the crisis support service \u003ca href=\"https://www.lifeline.org.au/\" data-link-name=\"in body link\"\u003eLifeline\u003c/a\u003e is 13 11 14. Other international helplines can be found at \u003ca href=\"http://www.befrienders.org/\" data-link-name=\"in body link\"\u003ebefrienders.org\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-04-27T05:00:24Z",
  "modifiedTime": "2025-04-27T13:46:29Z"
}
