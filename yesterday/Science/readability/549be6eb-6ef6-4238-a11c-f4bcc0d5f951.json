{
  "id": "549be6eb-6ef6-4238-a11c-f4bcc0d5f951",
  "title": "Don’t Panic. AI Isn’t Coming to End Scientific Exploration",
  "link": "https://www.scientificamerican.com/article/dont-panic-ai-isnt-coming-to-end-scientific-exploration/",
  "description": "Science is filled with tools that once seemed revolutionary and are now just part of the research tool kit. That time may have come for artificial intelligence",
  "author": "",
  "published": "Thu, 17 Oct 2024 17:15:00 +0000",
  "source": "http://rss.sciam.com/ScientificAmerican-Global",
  "categories": null,
  "byline": "Dan Garisto",
  "length": 7312,
  "excerpt": "Science is filled with tools that once seemed revolutionary and are now just part of the research tool kit. That time may have come for artificial intelligence",
  "siteName": "Scientific American",
  "favicon": "",
  "text": "October 17, 20245 min readScience is filled with tools that once seemed revolutionary and are now just part of the research tool kit. That time may have come for artificial intelligence Moor Studio/Getty ImagesOn October 8 the Nobel Prize in Physics was awarded for the development of machine learning. The next day, the chemistry Nobel honored protein structure prediction via artificial intelligence. Reaction to this AI–double whammy might have registered on the Richter scale.Some argued that the physics prize, in particular, was not physics. “A.I. is coming for science, too,” the New York Times concluded. Less moderate commenters went further: “Physics is now officially finished,” one onlooker declared on X (formerly Twitter). Future physics and chemistry prizes, a physicist joked, would inevitably be awarded to advances in machine learning. In a laconic email to the AP, newly anointed physics laureate and AI pioneer Geoffrey Hinton issued his own prognostication: “Neural networks are the future.”For decades, AI research was a relatively fringe domain of computer science. Its proponents often trafficked in prophetic predictions that AI would eventually bring about the dawn of superhuman intelligence. Suddenly, within the past few years, those visions have become vivid. The advent of large language models with powerful generative capabilities has led to speculation about encroachment on all branches of human achievement. AIs can receive a prompt, spit out illustrated pictures, essays, solutions to complex math problems—and now, provide Nobel-winning discoveries. Have AIs taken over the science Nobels, and possibly science itself?On supporting science journalismIf you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.Not so fast. Before we either happily swear fealty to our future benevolent computer overlords or eschew every technology since the pocket calculator (co-inventor Jack Kilby won part of the 2000 Physics Nobel, by the way), perhaps a bit of circumspection is in order.To begin with, what were the Nobels really awarded for? The physics prize went to Hinton and John Hopfield, a physicist (and former president of the American Physical Society), who discovered how the physical dynamics of a network can encode memory. Hopfield came up with an intuitive analogy: a ball, rolling across a bumpy landscape, will often “remember” to return to the same lowest valley. Hinton’s work extended Hopfield’s model by showing how increasingly complex neural networks with hidden “layers” of artificial neurons can learn better. In short, the physics Nobel was awarded for fundamental research about the physical principles of information, not the broad umbrella of “AI” and its applications.The chemistry prize, meanwhile, was half awarded to David Baker, a biochemist, while the other half went to two researchers at the AI company DeepMind: Demis Hassabis, a computer scientist and DeepMind’s CEO, and John Jumper, a chemist and DeepMind director. For proteins, form is function, their tangled skeins assembling into elaborate shapes that act as keys to fit into myriad molecular locks. But it has been extremely difficult to predict the emergent structure of a protein from its amino acid sequence—imagine trying to guess the way a length of chain will fold up. First Baker developed software to address this problem, including a program to design novel protein structures from scratch. Yet by 2018, of the roughly 200 million proteins cataloged in all genetic databases, only about 150,000, less than 0.1 percent, had confirmed structures. Then Hassabis and Jumper debuted AlphaFold in a predictive protein-folding challenge. Its first iteration beat the competition by a wide margin; the second provided highly accurate calculations of folding structures for the 200 million remaining proteins.AlphaFold is “the ground-breaking application of AI in science” a 2023 review of protein folding stated. But even so, the AI has limitations; its second iteration failed to predict defects in proteins and struggled with “loops,” a kind of structure crucial for drug design. It’s not a panacea for each and every problem in protein folding, but rather a tool par excellence, akin to many others that have received prizes over the years: the 2014 physics prize for blue light diodes (in nearly every LED screen today) or the 2019 chemistry prize for lithium ion batteries (still essential, even in an age of phone flashlights).Many of these tools have since disappeared into their uses. We rarely pause to consider the transistor (for which the 1956 physics prize was awarded) when we use electronics containing them by the billions. Some powerful machine-learning features are already on this path. The neural networks that provide accurate language translation or eerily apt song recommendations in popular consumer software programs are simply part of the service; the algorithm has faded into the background. In science, as in so many other domains, this trend suggests that when AI tools become commonplace, they will fade into the background, too.Still a reasonable concern might then be that such automation, whether subtle or overt, threatens to supersede or sully the efforts of human physicists and chemists. As AI becomes integral to further scientific progress, will any prizes recognize work truly free of AI? “It is difficult to make predictions, especially about the future,” as many—including the Nobel-winning physicist Niels Bohr and the iconic baseball player, Yogi Berra—are reported to have said.AI can revolutionize science; of that there is no doubt. It has already helped us see proteins with previously unimaginably clarity. Soon AIs may dream up new molecules for batteries, or find new particles hiding in data from colliders—in short, they may do many things, some of which previously seemed impossible. But they have a crucial limitation tied to something wonderful about science: its empirical dependence on the real world, which cannot be overcome by computation alone.An AI, in some respects, can only be as good as the data it’s given. It cannot, for example, use pure logic to discover the nature of dark matter, the mysterious substance that makes up 80 percent of matter in the universe. Instead it will have to rely on observations from an ineluctably physical detector with components perennially in need of elbow grease. To discover the real world, we will always have to contend with such corporeal hiccups.Science also needs experimenters—human experts driven to study the universe, and who will ask questions an AI cannot. As Hopfield himself explained in a 2018 essay, physics—science itself, really—is not a subject so much as “a point of view,” its core ethos being “that the world is understandable” in quantitative, predictive terms solely by virtue of careful experiment and observation.That real world, in its endless majesty and mystery, still exists for future scientists to study, whether aided by AI or not.This is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of Scientific American.",
  "image": "https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003eOctober 17, 2024\u003c/p\u003e\u003cp\u003e5 min read\u003c/p\u003e\u003c/div\u003e\u003cp\u003eScience is filled with tools that once seemed revolutionary and are now just part of the research tool kit. That time may have come for artificial intelligence\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=600\" alt=\"Vector illustration of a giant robot in silhouette looming over a scientist standing on an elevated catwalk\" srcset=\"https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=600 600w, https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=900 900w, https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=1000 1000w, https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=1200 1200w, https://static.scientificamerican.com/dam/m/72129dcbccb70b2d/original/rise_of_the_machines_ai.jpg?w=1350 1350w\" sizes=\"(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw\" fetchpriority=\"high\"/\u003e\u003cfigcaption\u003e \u003cp\u003eMoor Studio/Getty Images\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp data-block=\"sciam/paragraph\"\u003eOn October 8 the Nobel Prize in Physics was awarded for the development of \u003ca href=\"https://www.scientificamerican.com/article/nobel-prize-in-physics-awarded-for-breakthroughs-in-machine-learning/\"\u003emachine learning\u003c/a\u003e. The next day, the chemistry Nobel honored \u003ca href=\"https://www.scientificamerican.com/article/chemistry-nobel-2024/\"\u003eprotein structure prediction\u003c/a\u003e via artificial intelligence. Reaction to this AI–double whammy might have registered on the Richter scale.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eSome argued that the physics prize, in particular, \u003ca href=\"https://www.nature.com/articles/d41586-024-03310-8\"\u003ewas not physics\u003c/a\u003e. “A.I. is coming for science, too,” the \u003ci\u003eNew York Times\u003c/i\u003e \u003ca href=\"https://www.nytimes.com/2024/10/13/briefing/nobel-prize-artificial-intelligence.html\"\u003econcluded\u003c/a\u003e. Less moderate commenters went further: “Physics is now officially finished,” one onlooker \u003ca href=\"https://x.com/tunguz/status/1843605826403193229\"\u003edeclared\u003c/a\u003e on X (formerly Twitter). Future physics and chemistry prizes, a physicist \u003ca href=\"https://x.com/Hassaan_PHY/status/1843693032094478463\"\u003ejoked\u003c/a\u003e, would inevitably be awarded to advances in machine learning. In a \u003ca href=\"https://apnews.com/article/ai-nobel-prizes-physics-chemistry-google-deepmind-hinton-cb963de3b4235f28f8c95ca9080830f6?utm_campaign=TrueAnthem\u0026amp;utm_medium=AP\u0026amp;utm_source=Twitter\"\u003elaconic email\u003c/a\u003e to the AP, newly anointed physics laureate and AI pioneer Geoffrey Hinton issued his own prognostication: “Neural networks are the future.”\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eFor decades, AI research was \u003ca href=\"https://www.scientificamerican.com/article/springtime-for-ai-the-rise-of-deep-learning/\"\u003ea relatively fringe domain\u003c/a\u003e of computer science. Its proponents often trafficked in prophetic predictions that AI would eventually bring about the dawn of superhuman intelligence. Suddenly, within the past few years, those visions have become vivid. The advent of \u003ca href=\"https://www.scientificamerican.com/article/how-does-chatgpt-think-psychology-and-neuroscience-crack-open-ai-large/\"\u003elarge language models\u003c/a\u003e with powerful generative capabilities has led to speculation about encroachment on all branches of human achievement. AIs can receive a prompt, spit out illustrated pictures, essays, solutions to complex math problems—and now, provide Nobel-winning discoveries. Have AIs taken over the science Nobels, and possibly science itself?\u003c/p\u003e\u003chr/\u003e\u003ch2\u003eOn supporting science journalism\u003c/h2\u003e\u003cp\u003eIf you\u0026#39;re enjoying this article, consider supporting our award-winning journalism by \u003ca href=\"https://www.scientificamerican.com/getsciam/\"\u003esubscribing\u003c/a\u003e. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.\u003c/p\u003e\u003chr/\u003e\u003cp data-block=\"sciam/paragraph\"\u003eNot so fast. Before we either happily swear fealty to our future benevolent computer overlords or eschew every technology since the pocket calculator (co-inventor Jack Kilby won part of \u003ca href=\"https://www.nobelprize.org/prizes/physics/2000/kilby/facts/\"\u003ethe 2000 Physics Nobel\u003c/a\u003e, by the way), perhaps a bit of circumspection is in order.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eTo begin with, what were the Nobels really awarded for? \u003ca href=\"https://www.nobelprize.org/prizes/physics/\"\u003eThe physics prize\u003c/a\u003e went to Hinton and John Hopfield, a physicist (and former president of the American Physical Society), who discovered how the physical dynamics of a network can encode memory. Hopfield came up with an intuitive analogy: a ball, rolling across a bumpy landscape, will often “remember” to return to the same lowest valley. Hinton’s work extended Hopfield’s model by showing how increasingly complex neural networks with hidden “layers” of artificial neurons can learn better. In short, the physics Nobel was awarded for fundamental research about the physical principles of information, not the broad umbrella of “AI” and its applications.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe \u003ca href=\"https://www.nobelprize.org/prizes/chemistry/\"\u003echemistry prize\u003c/a\u003e, meanwhile, was half awarded to David Baker, a biochemist, while the other half went to two researchers at the AI company DeepMind: Demis Hassabis, a computer scientist and DeepMind’s CEO, and John Jumper, a chemist and DeepMind director. For proteins, form is function, their tangled skeins assembling into elaborate shapes that act as keys to fit into myriad molecular locks. But it has been extremely difficult to predict the \u003ca href=\"https://www.scientificamerican.com/article/deepminds-ai-makes-gigantic-leap-in-solving-protein-structures/\"\u003eemergent structure of a protein\u003c/a\u003e from its amino acid sequence—imagine trying to guess the way a length of chain will fold up. First Baker developed software to address this problem, including a program to design novel protein structures from scratch. Yet by 2018, of the roughly 200 million proteins cataloged in all genetic databases, only about 150,000, less than 0.1 percent, had confirmed structures. Then Hassabis and Jumper debuted AlphaFold in a predictive protein-folding challenge. Its first iteration beat the competition by a wide margin; the second provided highly accurate calculations of folding structures for the 200 million remaining proteins.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAlphaFold is “the ground-breaking application of AI in science” a \u003ca href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC10011655/\"\u003e2023 review\u003c/a\u003e of protein folding stated. But even so, the AI has limitations; its second iteration failed to predict defects in proteins and struggled with “loops,” a kind of structure crucial for drug design. It’s not a panacea for each and every problem in protein folding, but rather a tool par excellence, akin to many others that have received prizes over the years: the 2014 physics prize for blue light diodes (in nearly every LED screen today) or the 2019 chemistry prize for lithium ion batteries (still essential, even in an age of phone flashlights).\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eMany of these tools have since disappeared into their uses. We rarely pause to consider the transistor (for which the 1956 physics prize was awarded) when we use electronics containing them by the billions. Some powerful machine-learning features are already on this path. The neural networks that provide accurate language translation or eerily apt song recommendations in popular consumer software programs are simply part of the service; the algorithm has faded into the background. In science, as in so many other domains, this trend suggests that when AI tools become commonplace, they will fade into the background, too.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eStill a reasonable concern might then be that such automation, whether subtle or overt, threatens to supersede or sully the efforts of human physicists and chemists. As AI becomes integral to further scientific progress, will any prizes recognize work truly free of AI? “It is difficult to make predictions, especially about the future,” as many—including the Nobel-winning physicist Niels Bohr and the iconic baseball player, Yogi Berra—are reported to have said.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAI can revolutionize science; of that there is no doubt. It has already helped us see proteins with previously unimaginably clarity. Soon AIs may \u003ca href=\"https://www.scientificamerican.com/article/proteins-never-seen-in-nature-are-designed-using-ai-to-address-biomedical-and-industrial-problems-unsolved-by-evolution/\"\u003edream up new molecules\u003c/a\u003e for batteries, or find new particles hiding in data from colliders—in short, they may do many things, some of which previously seemed impossible. But they have a crucial limitation tied to something wonderful about science: its empirical dependence on the real world, which cannot be overcome by computation alone.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAn AI, in some respects, can only be as good as the data it’s given. It cannot, for example, use pure logic to discover the nature of dark matter, the mysterious substance that makes up 80 percent of matter in the universe. Instead it will have to rely on observations from an ineluctably physical detector with components perennially in need of elbow grease. To discover the real world, we will always have to contend with such corporeal hiccups.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eScience also needs experimenters—human experts driven to study the universe, and who will ask questions an AI cannot. As Hopfield himself explained in a \u003ca href=\"https://pni.princeton.edu/people/john-j-hopfield/now-what\"\u003e2018 essay\u003c/a\u003e, physics—science itself, really—is not a subject so much as “a point of view,” its core ethos being “that the world is understandable” in quantitative, predictive terms solely by virtue of careful experiment and observation.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThat real world, in its endless majesty and mystery, still exists for future scientists to study, whether aided by AI or not.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003e\u003ci\u003eThis is an opinion and analysis article, and the views expressed by the author or authors are not necessarily those of \u003c/i\u003eScientific American.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2024-10-17T17:15:00Z",
  "modifiedTime": null
}
