{
  "id": "046802f7-3abc-4040-95b6-994f58b757c4",
  "title": "Thinking AI models emit 50x more CO2—and often for nothing",
  "link": "https://www.sciencedaily.com/releases/2025/06/250619035520.htm",
  "description": "Every query typed into a large language model (LLM), such as ChatGPT, requires energy and produces CO2 emissions. Emissions, however, depend on the model, the subject matter, and the user. Researchers have now compared 14 models and found that complex answers cause more emissions than simple answers, and that models that provide more accurate answers produce more emissions. Users can, however, to an extent, control the amount of CO2 emissions caused by AI by adjusting their personal use of the technology, the researchers said.",
  "author": "",
  "published": "Thu, 19 Jun 2025 03:55:20 EDT",
  "source": "https://www.sciencedaily.com/rss/all.xml",
  "categories": null,
  "byline": "",
  "length": 3892,
  "excerpt": "Every query typed into a large language model (LLM), such as ChatGPT, requires energy and produces CO2 emissions. Emissions, however, depend on the model, the subject matter, and the user. Researchers have now compared 14 models and found that complex answers cause more emissions than simple answers, and that models that provide more accurate answers produce more emissions. Users can, however, to an extent, control the amount of CO2 emissions caused by AI by adjusting their personal use of the technology, the researchers said.",
  "siteName": "ScienceDaily",
  "favicon": "",
  "text": "No matter which questions we ask an AI, the model will come up with an answer. To produce this information - regardless of whether than answer is correct or not - the model uses tokens. Tokens are words or parts of words that are converted into a string of numbers that can be processed by the LLM. This conversion, as well as other computing processes, produce CO2 emissions. Many users, however, are unaware of the substantial carbon footprint associated with these technologies. Now, researchers in Germany measured and compared CO2 emissions of different, already trained, LLMs using a set of standardized questions. \"The environmental impact of questioning trained LLMs is strongly determined by their reasoning approach, with explicit reasoning processes significantly driving up energy consumption and carbon emissions,\" said first author Maximilian Dauner, a researcher at Hochschule München University of Applied Sciences and first author of the Frontiers in Communication study. \"We found that reasoning-enabled models produced up to 50 times more CO2 emissions than concise response models.\" 'Thinking' AI causes most emissions The researchers evaluated 14 LLMs ranging from seven to 72 billion parameters on 1,000 benchmark questions across diverse subjects. Parameters determine how LLMs learn and process information. Reasoning models, on average, created 543.5 'thinking' tokens per questions, whereas concise models required just 37.7 tokens per question. Thinking tokens are additional tokens that reasoning LLMs generate before producing an answer. A higher token footprint always means higher CO2 emissions. It doesn't, however, necessarily mean the resulting answers are more correct, as elaborate detail that is not always essential for correctness. The most accurate model was the reasoning-enabled Cogito model with 70 billion parameters, reaching 84.9% accuracy. The model produced three times more CO2 emissions than similar sized models that generated concise answers. \"Currently, we see a clear accuracy-sustainability trade-off inherent in LLM technologies,\" said Dauner. \"None of the models that kept emissions below 500 grams of CO2 equivalent achieved higher than 80% accuracy on answering the 1,000 questions correctly.\" CO2 equivalent is the unit used to measure the climate impact of various greenhouse gases. Subject matter also resulted in significantly different levels of CO2 emissions. Questions that required lengthy reasoning processes, for example abstract algebra or philosophy, led to up to six times higher emissions than more straightforward subjects, like high school history. Practicing thoughtful use The researchers said they hope their work will cause people to make more informed decisions about their own AI use. \"Users can significantly reduce emissions by prompting AI to generate concise answers or limiting the use of high-capacity models to tasks that genuinely require that power,\" Dauner pointed out. Choice of model, for instance, can make a significant difference in CO2 emissions. For example, having DeepSeek R1 (70 billion parameters) answer 600,000 questions would create CO2 emissions equal to a round-trip flight from London to New York. Meanwhile, Qwen 2.5 (72 billion parameters) can answer more than three times as many questions (about 1.9 million) with similar accuracy rates while generating the same emissions. The researchers said that their results may be impacted by the choice of hardware used in the study, an emission factor that may vary regionally depending on local energy grid mixes, and the examined models. These factors may limit the generalizability of the results. \"If users know the exact CO2 cost of their AI-generated outputs, such as casually turning themselves into an action figure, they might be more selective and thoughtful about when and how they use these technologies,\" Dauner concluded.",
  "image": "https://www.sciencedaily.com/images/1920/Carbon-Dioxide-CO2-Control-Dial.webp",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp id=\"first\"\u003eNo matter which questions we ask an AI, the model will come up with an answer. To produce this information - regardless of whether than answer is correct or not - the model uses tokens. Tokens are words or parts of words that are converted into a string of numbers that can be processed by the LLM.\u003c/p\u003e\u003cdiv id=\"text\"\u003e\n\u003cp\u003eThis conversion, as well as other computing processes, produce CO\u003csub\u003e2\u003c/sub\u003e emissions. Many users, however, are unaware of the substantial carbon footprint associated with these technologies. Now, researchers in Germany measured and compared CO\u003csub\u003e2\u003c/sub\u003e emissions of different, already trained, LLMs using a set of standardized questions.\u003c/p\u003e\n\u003cp\u003e\u0026#34;The environmental impact of questioning trained LLMs is strongly determined by their reasoning approach, with explicit reasoning processes significantly driving up energy consumption and carbon emissions,\u0026#34; said first author Maximilian Dauner, a researcher at Hochschule München University of Applied Sciences and first author of the \u003cem\u003eFrontiers in Communication\u003c/em\u003e study. \u0026#34;We found that reasoning-enabled models produced up to 50 times more CO2 emissions than concise response models.\u0026#34;\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u0026#39;Thinking\u0026#39; AI causes most emissions\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe researchers evaluated 14 LLMs ranging from seven to 72 billion parameters on 1,000 benchmark questions across diverse subjects. Parameters determine how LLMs learn and process information.\u003c/p\u003e\n\u003cp\u003eReasoning models, on average, created 543.5 \u0026#39;thinking\u0026#39; tokens per questions, whereas concise models required just 37.7 tokens per question. Thinking tokens are additional tokens that reasoning LLMs generate before producing an answer. A higher token footprint always means higher CO2 emissions. It doesn\u0026#39;t, however, necessarily mean the resulting answers are more correct, as elaborate detail that is not always essential for correctness.\u003c/p\u003e\n\u003cp\u003eThe most accurate model was the reasoning-enabled Cogito model with 70 billion parameters, reaching 84.9% accuracy. The model produced three times more CO\u003csub\u003e2\u003c/sub\u003e emissions than similar sized models that generated concise answers. \u0026#34;Currently, we see a clear accuracy-sustainability trade-off inherent in LLM technologies,\u0026#34; said Dauner. \u0026#34;None of the models that kept emissions below 500 grams of CO2 equivalent achieved higher than 80% accuracy on answering the 1,000 questions correctly.\u0026#34; CO\u003csub\u003e2\u003c/sub\u003e equivalent is the unit used to measure the climate impact of various greenhouse gases.\u003c/p\u003e\n\n\n\u003cp\u003eSubject matter also resulted in significantly different levels of CO\u003csub\u003e2\u003c/sub\u003e emissions. Questions that required lengthy reasoning processes, for example abstract algebra or philosophy, led to up to six times higher emissions than more straightforward subjects, like high school history.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePracticing thoughtful use \u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe researchers said they hope their work will cause people to make more informed decisions about their own AI use. \u0026#34;Users can significantly reduce emissions by prompting AI to generate concise answers or limiting the use of high-capacity models to tasks that genuinely require that power,\u0026#34; Dauner pointed out.\u003c/p\u003e\n\u003cp\u003eChoice of model, for instance, can make a significant difference in CO\u003csub\u003e2\u003c/sub\u003e emissions. For example, having DeepSeek R1 (70 billion parameters) answer 600,000 questions would create CO\u003csub\u003e2\u003c/sub\u003e emissions equal to a round-trip flight from London to New York. Meanwhile, Qwen 2.5 (72 billion parameters) can answer more than three times as many questions (about 1.9 million) with similar accuracy rates while generating the same emissions.\u003c/p\u003e\n\u003cp\u003eThe researchers said that their results may be impacted by the choice of hardware used in the study, an emission factor that may vary regionally depending on local energy grid mixes, and the examined models. These factors may limit the generalizability of the results.\u003c/p\u003e\n\u003cp\u003e\u0026#34;If users know the exact CO2 cost of their AI-generated outputs, such as casually turning themselves into an action figure, they might be more selective and thoughtful about when and how they use these technologies,\u0026#34; Dauner concluded.\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": null,
  "modifiedTime": null
}
