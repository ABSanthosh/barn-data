{
  "id": "b084cca0-8bb7-4832-9612-8b0748556c31",
  "title": "Marginalized Americans are highly skeptical of artificial intelligence, research finds",
  "link": "https://phys.org/news/2025-07-marginalized-americans-highly-skeptical-artificial.html",
  "description": "Artificial intelligence may be marketed as society's great equalizer—transforming businesses, streamlining work and making life easier for all—but for many marginalized Americans, AI doesn't feel like a promise.",
  "author": "",
  "published": "Wed, 02 Jul 2025 17:14:04 EDT",
  "source": "https://phys.org/rss-feed/",
  "categories": [
    "Social Sciences Political science"
  ],
  "byline": "Jared Wadley",
  "length": 3484,
  "excerpt": "Artificial intelligence may be marketed as society's great equalizer—transforming businesses, streamlining work and making life easier for all—but for many marginalized Americans, AI doesn't feel like a promise.",
  "siteName": "Phys.org",
  "favicon": "https://phys.b-cdn.net/tmpl/v6/img/favicons/web-app-manifest-512x512.png",
  "text": "Credit: AI-generated image Artificial intelligence may be marketed as society's great equalizer—transforming businesses, streamlining work and making life easier for all—but for many marginalized Americans, AI doesn't feel like a promise. It feels like a threat. A new University of Michigan study finds that gender minorities, women and disabled individuals—especially those who are neurodivergent or living with mental health conditions—hold significantly more negative attitudes toward AI than their majority-group peers. Using data from a nationally representative survey of 742 people, researchers asked participants to report their attitudes about AI's impact on their lives and work. The responses reveal a sharp divide in positivity toward AI across lines of identity. \"AI may be everywhere, but it's not for everyone—at least not yet,\" said lead author Oliver Haimson, assistant professor at the U-M School of Information and Digital Studies Institute. \"If we continue to ignore the perspectives of marginalized people, we risk building an AI-powered future that deepens inequities rather than reducing them.\" Key findings: Nonbinary and transgender participants reported the most negative views of AI overall. Women were significantly less likely than men to view AI positively. Disabled participants, particularly those who are neurodivergent or have mental health conditions, also expressed negative AI attitudes. Surprisingly, Black participants held more positive views of AI than white participants, suggesting a more nuanced relationship with the technology among people of color. The study highlights real-world harms that may fuel negative perceptions of AI: Facial recognition software that misgenders or misclassifies trans and nonbinary people—often while surveilling them. Predictive policing algorithms that reinforce racial bias and lead to unjust arrests. Health care systems that rely on AI models not designed with disabled people in mind. \"These are not abstract concerns,\" Haimson said. \"People who are wary of AI often have lived experiences with systems that misidentify, exclude or harm them due to their gender or disability.\" The research calls into question the dominant narrative of AI as a neutral or universally beneficial tool. It urges technologists, companies and policymakers to pause and ask: Who is this technology working for—and who is being left behind? The study's co-authors are doctoral student Samuel Reiji Mayworm, research fellow Alexis Shore Ingber and assistant professor Nazanin Andalibi. The research was presented at the recent 2025 ACM Conference on Fairness, Accountability and Transparency (FAccT '25). More information: Oliver L. Haimson et al, AI Attitudes Among Marginalized Populations in the U.S.: Nonbinary, Transgender, and Disabled Individuals Report More Negative AI Attitudes, Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (2025). DOI: 10.1145/3715275.3732081",
  "image": "https://scx2.b-cdn.net/gfx/news/hires/2025/marginalized-americans.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n        \u003cdiv\u003e\n\n                \n\u003cfigure data-lightbox=\"\"\u003e\n    \u003cdiv id=\"i1225157\"\u003e\n        \u003ca href=\"https://scx2.b-cdn.net/gfx/news/hires/2025/marginalized-americans.jpg\" target=\"_self\"\u003e\n            \u003cpicture\u003e\n                \u003csource srcset=\"https://scx1.b-cdn.net/csz/news/800a/2025/marginalized-americans.jpg?f=webp 800w, https://scx1.b-cdn.net/csz/news/500a/2025/marginalized-americans.jpg?f=webp 500w\" sizes=\"(max-width: 500px) 500px, 800px\" type=\"image/webp\"/\u003e\n                \u003csource srcset=\"https://scx1.b-cdn.net/csz/news/800a/2025/marginalized-americans.jpg 800w, https://scx1.b-cdn.net/csz/news/500a/2025/marginalized-americans.jpg 500w\" sizes=\"(max-width: 500px) 500px, 800px\"/\u003e\n                \u003cimg src=\"https://scx1.b-cdn.net/csz/news/800a/2025/marginalized-americans.jpg\" width=\"800\" height=\"457\" alt=\"Marginalized Americans are highly skeptical of artificial intelligence\" title=\"Credit: AI-generated image\" fetchpriority=\"high\"/\u003e\n            \u003c/picture\u003e\n        \u003c/a\u003e\n    \u003c/div\u003e\n\n            \u003cfigcaption\u003e\n            \u003cp\u003eCredit: AI-generated image\u003c/p\u003e\n        \u003c/figcaption\u003e\n    \u003c/figure\u003e\u003cp\u003eArtificial intelligence may be marketed as society\u0026#39;s great equalizer—transforming businesses, streamlining work and making life easier for all—but for many marginalized Americans, AI doesn\u0026#39;t feel like a promise.\u003c/p\u003e\n\n                \n                                \n                \n                \n                                                            \u003cp\u003eIt feels like a threat.\u003c/p\u003e\n\u003cp\u003eA new University of Michigan study finds that gender minorities, women and disabled individuals—especially those who are neurodivergent or living with mental health conditions—hold significantly more negative attitudes toward AI than their majority-group peers.\u003c/p\u003e\n\u003cp\u003eUsing data from a nationally representative survey of 742 people, researchers asked participants to report their attitudes about AI\u0026#39;s impact on their lives and work. The responses reveal a sharp divide in positivity toward AI across lines of identity.\u003c/p\u003e\n\u003cp\u003e\u0026#34;AI may be everywhere, but it\u0026#39;s not for everyone—at least not yet,\u0026#34; said lead author Oliver Haimson, assistant professor at the U-M School of Information and Digital Studies Institute. \u0026#34;If we continue to ignore the perspectives of marginalized people, we risk building an AI-powered future that deepens inequities rather than reducing them.\u0026#34;\u003c/p\u003e\n\u003ch2\u003eKey findings:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eNonbinary and transgender participants reported the most negative views of AI overall.\u003c/li\u003e\n\u003cli\u003eWomen were significantly less likely than men to view AI positively.\u003c/li\u003e\n\u003cli\u003eDisabled participants, particularly those who are neurodivergent or have \u003ca href=\"https://phys.org/tags/mental+health+conditions/\" rel=\"tag\"\u003emental health conditions\u003c/a\u003e, also expressed negative AI attitudes.\u003c/li\u003e\n\u003cli\u003eSurprisingly, Black participants held more positive views of AI than white participants, suggesting a more nuanced relationship with the technology among people of color.\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                                  \n                                                                    \u003cp\u003eThe study highlights real-world harms that may fuel negative perceptions of AI:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFacial recognition software that misgenders or misclassifies trans and nonbinary people—often while surveilling them.\u003c/li\u003e\n\u003cli\u003ePredictive policing algorithms that reinforce \u003ca href=\"https://phys.org/tags/racial+bias/\" rel=\"tag\"\u003eracial bias\u003c/a\u003e and lead to unjust arrests.\u003c/li\u003e\n\u003cli\u003eHealth care systems that rely on AI models not designed with disabled people in mind.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026#34;These are not abstract concerns,\u0026#34; Haimson said. \u0026#34;People who are wary of AI often have lived experiences with systems that misidentify, exclude or harm them due to their gender or disability.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThe research calls into question the dominant narrative of AI as a neutral or universally beneficial tool. It urges technologists, companies and policymakers to pause and ask: Who is this technology working for—and who is being left behind?\u003c/p\u003e\n\u003cp\u003eThe study\u0026#39;s co-authors are doctoral student Samuel Reiji Mayworm, research fellow Alexis Shore Ingber and assistant professor Nazanin Andalibi.\u003c/p\u003e\n\u003cp\u003eThe research was \u003ca href=\"https://dl.acm.org/doi/10.1145/3715275.3732081\" target=\"_blank\"\u003epresented\u003c/a\u003e at the recent 2025 ACM Conference on Fairness, Accountability and Transparency (FAccT \u0026#39;25).\u003c/p\u003e\n\n                                                            \n                  \n\n                \n                                    \u003cp\u003e\n                                \u003cstrong\u003eMore information:\u003c/strong\u003e \n                                Oliver L. Haimson et al, AI Attitudes Among Marginalized Populations in the U.S.: Nonbinary, Transgender, and Disabled Individuals Report More Negative AI Attitudes, \u003ci\u003eProceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency\u003c/i\u003e (2025). \u003ca data-doi=\"1\" href=\"https://dx.doi.org/10.1145/3715275.3732081\" target=\"_blank\"\u003eDOI: 10.1145/3715275.3732081\u003c/a\u003e\n                            \u003c/p\u003e\n                \t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\n                                    \n                \n\n                \t\t\t\t\t    \n\t\t\t\t\u003c/div\u003e\n\t\t  \n    \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-07-02T17:14:04-04:00",
  "modifiedTime": null
}
