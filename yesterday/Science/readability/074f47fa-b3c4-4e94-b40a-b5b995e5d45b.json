{
  "id": "074f47fa-b3c4-4e94-b40a-b5b995e5d45b",
  "title": "Study shines headlights on consumer driverless vehicle safety deficiencies",
  "link": "https://www.sciencedaily.com/releases/2025/03/250304143529.htm",
  "description": "Researchers have demonstrated that multicolored stickers applied to stop or speed limit signs on the roadside can 'confuse' self-driving vehicles, causing unpredictable and possibly hazardous operations.",
  "author": "",
  "published": "Tue, 04 Mar 2025 14:35:29 EST",
  "source": "https://www.sciencedaily.com/rss/all.xml",
  "categories": null,
  "byline": "",
  "length": 4513,
  "excerpt": "Researchers have demonstrated that multicolored stickers applied to stop or speed limit signs on the roadside can 'confuse' self-driving vehicles, causing unpredictable and possibly hazardous operations.",
  "siteName": "ScienceDaily",
  "favicon": "",
  "text": "For the first time,researchers at the University of California, Irvine have demonstrated that multicolored stickers applied to stop or speed limit signs on the roadside can confuse self-driving vehicles, causing unpredictable and possibly hazardous operations. In a presentation at the recent Network and Distributed System Security Symposium in San Diego, researchers from UC Irvine's Donald Bren School of Information \u0026 Computer Sciences described the real-world implications of what previously was only theorized: that low-cost and highly deployable malicious attacks can make traffic signs undetectable to artificial intelligence algorithms in some autonomous vehicles while making nonexistent signs appear out of nowhere to others. Both types of assaults can result in cars ignoring road commands, triggering unintended emergency braking, speeding and other violations. The scientists said that their study, which involved the three most representative AI attack designs, was the first large-scale evaluation of traffic sign recognition systems in top-selling consumer vehicle brands. \"Waymo has been delivering more than 150,000 autonomous rides per week, and there are millions of Autopilot-equipped Tesla vehicles on the road, which demonstrates that autonomous vehicle technology is becoming an integral part of daily life in America and around the world,\" said co-author Alfred Chen, UC Irvine assistant professor of computer science. \"This fact spotlights the importance of security, since vulnerabilities in these systems, once exploited, can lead to safety hazards that become a matter of life and death.\" The lead author of the study, Ningfei Wang, a research scientist at Meta who performed this work as a Ph.D. student in computer science at UC Irvine, said that his team's attack vectors of choice were stickers that had swirling, multicolored designs that confuse AI algorithms used for traffic sign recognition in driverless vehicles. \"These stickers can be cheaply and easily produced by anyone with access to an open-source programming language such as Python and image processing libraries,\" Wang said. \"Those tools combined with a computer with a graphics card and a color printer are all someone would need to foil TSR systems in autonomous vehicles.\" He added that an interesting discovery made during the project relates to the spatial memorization design common to many of today's commercial TSR systems. While this feature makes a disappearing attack (seeming to remove a sign from the vehicle's view) more difficult, Wang said, it makes spoofing a fake stop sign \"much easier than we expected.\" Chen noted that the research was the first of its type on this security threat in real-world scenarios with commercially available vehicles. \"Academics have studied driverless vehicle security for years and have discovered various practical security vulnerabilities in the latest autonomous driving technology,\" he said. \"But these studies have been limited mostly to academic setups, leaving our understanding of such vulnerabilities in commercial autonomous vehicle systems highly limited. Our study fills this critical gap.\" Chen said that by focusing on a small subset of existing research in this area, his group was able to uncover various broken assumptions, inaccuracies and false claims. For example, no prior academic studies realized the common existence of spatial memorization design in commercial TSR systems. When Chen's team members modeled such a design in previously devised academic study setups, they uncovered results that directly challenge earlier observations and claims made in the state-of-the-art research community. \"We believe this work should only be the beginning, and we hope that it inspires more researchers in both academia and industry to systematically revisit the actual impacts and meaningfulness of such types of security threats against real-world autonomous vehicles,\" Chen said. \"This would be the necessary first step before we can actually know if, at the society level, action is needed to ensure safety on our streets and highways.\" Joining Chen and Wang on this project were former UC Irvine graduate students Takami Sato and Yunpeng Luo; current UC Irvine graduate student Shaoyuan Xie; and Kaidi Xu, assistant professor of computer science at Drexel University. The work was supported by the National Science Foundation and the U.S. Department of Transportation's CARMEN+ University Transportation Center, of which UC Irvine is a member.",
  "image": "https://www.sciencedaily.com/images/scidaily-icon.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp id=\"first\"\u003eFor the first time,researchers at the University of California, Irvine have demonstrated that multicolored stickers applied to stop or speed limit signs on the roadside can confuse self-driving vehicles, causing unpredictable and possibly hazardous operations.\u003c/p\u003e\u003cdiv id=\"text\"\u003e\n\u003cp\u003eIn a presentation at the recent Network and Distributed System Security Symposium in San Diego, researchers from UC Irvine\u0026#39;s Donald Bren School of Information \u0026amp; Computer Sciences described the real-world implications of what previously was only theorized: that low-cost and highly deployable malicious attacks can make traffic signs undetectable to artificial intelligence algorithms in some autonomous vehicles while making nonexistent signs appear out of nowhere to others. Both types of assaults can result in cars ignoring road commands, triggering unintended emergency braking, speeding and other violations.\u003c/p\u003e\n\u003cp\u003eThe scientists said that their study, which involved the three most representative AI attack designs, was the first large-scale evaluation of traffic sign recognition systems in top-selling consumer vehicle brands.\u003c/p\u003e\n\u003cp\u003e\u0026#34;Waymo has been delivering more than 150,000 autonomous rides per week, and there are millions of Autopilot-equipped Tesla vehicles on the road, which demonstrates that autonomous vehicle technology is becoming an integral part of daily life in America and around the world,\u0026#34; said co-author Alfred Chen, UC Irvine assistant professor of computer science. \u0026#34;This fact spotlights the importance of security, since vulnerabilities in these systems, once exploited, can lead to safety hazards that become a matter of life and death.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThe lead author of the study, Ningfei Wang, a research scientist at Meta who performed this work as a Ph.D. student in computer science at UC Irvine, said that his team\u0026#39;s attack vectors of choice were stickers that had swirling, multicolored designs that confuse AI algorithms used for traffic sign recognition in driverless vehicles.\u003c/p\u003e\n\u003cp\u003e\u0026#34;These stickers can be cheaply and easily produced by anyone with access to an open-source programming language such as Python and image processing libraries,\u0026#34; Wang said. \u0026#34;Those tools combined with a computer with a graphics card and a color printer are all someone would need to foil TSR systems in autonomous vehicles.\u0026#34;\u003c/p\u003e\n\u003cp\u003eHe added that an interesting discovery made during the project relates to the spatial memorization design common to many of today\u0026#39;s commercial TSR systems. While this feature makes a disappearing attack (seeming to remove a sign from the vehicle\u0026#39;s view) more difficult, Wang said, it makes spoofing a fake stop sign \u0026#34;much easier than we expected.\u0026#34;\u003c/p\u003e\n\u003cp\u003eChen noted that the research was the first of its type on this security threat in real-world scenarios with commercially available vehicles.\u003c/p\u003e\n\n\n\u003cp\u003e\u0026#34;Academics have studied driverless vehicle security for years and have discovered various practical security vulnerabilities in the latest autonomous driving technology,\u0026#34; he said. \u0026#34;But these studies have been limited mostly to academic setups, leaving our understanding of such vulnerabilities in commercial autonomous vehicle systems highly limited. Our study fills this critical gap.\u0026#34;\u003c/p\u003e\n\u003cp\u003eChen said that by focusing on a small subset of existing research in this area, his group was able to uncover various broken assumptions, inaccuracies and false claims. For example, no prior academic studies realized the common existence of spatial memorization design in commercial TSR systems. When Chen\u0026#39;s team members modeled such a design in previously devised academic study setups, they uncovered results that directly challenge earlier observations and claims made in the state-of-the-art research community.\u003c/p\u003e\n\u003cp\u003e\u0026#34;We believe this work should only be the beginning, and we hope that it inspires more researchers in both academia and industry to systematically revisit the actual impacts and meaningfulness of such types of security threats against real-world autonomous vehicles,\u0026#34; Chen said. \u0026#34;This would be the necessary first step before we can actually know if, at the society level, action is needed to ensure safety on our streets and highways.\u0026#34;\u003c/p\u003e\n\u003cp\u003eJoining Chen and Wang on this project were former UC Irvine graduate students Takami Sato and Yunpeng Luo; current UC Irvine graduate student Shaoyuan Xie; and Kaidi Xu, assistant professor of computer science at Drexel University. The work was supported by the National Science Foundation and the U.S. Department of Transportation\u0026#39;s CARMEN+ University Transportation Center, of which UC Irvine is a member.\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": null,
  "modifiedTime": null
}
