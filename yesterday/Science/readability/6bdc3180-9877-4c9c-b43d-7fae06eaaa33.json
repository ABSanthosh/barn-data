{
  "id": "6bdc3180-9877-4c9c-b43d-7fae06eaaa33",
  "title": "Elon Musk's New Grok 4 Takes on ‘Humanity’s Last Exam’ as the AI Race Heats Up",
  "link": "https://www.scientificamerican.com/article/elon-musks-new-grok-4-takes-on-humanitys-last-exam-as-the-ai-race-heats-up/",
  "description": "Elon Musk has launched xAI’s Grok 4—calling it the “world’s smartest AI” and claiming it can ace Ph.D.-level exams and outpace rivals such as Google’s Gemini and OpenAI’s o3 on tough benchmarks",
  "author": "",
  "published": "Fri, 11 Jul 2025 18:30:00 +0000",
  "source": "http://rss.sciam.com/ScientificAmerican-Global",
  "categories": null,
  "byline": "Deni Ellis Béchard",
  "length": 6056,
  "excerpt": "Elon Musk has launched xAI’s Grok 4—calling it the “world’s smartest AI” and claiming it can ace Ph.D.-level exams and outpace rivals such as Google’s Gemini and OpenAI’s o3 on tough benchmarks",
  "siteName": "Scientific American",
  "favicon": "",
  "text": "Elon Musk has launched xAI’s Grok 4—calling it the “world’s smartest AI” and claiming it can ace Ph.D.-level exams and outpace rivals such as Google’s Gemini and OpenAI’s o3 on tough benchmarks Floriana/Getty ImagesElon Musk released the newest artificial intelligence model from his company xAI on Wednesday night. In an hour-long public reveal session, he called the model, Grok 4, “the smartest AI in the world” and claimed it was capable of getting perfect SAT scores and near-perfect GRE results in every subject, from the humanities to the sciences.During the online launch, Musk and members of his team described testing Grok 4 on a metric called Humanity’s Last Exam (HLE)—a 2,500-question benchmark designed to evaluate an AI’s academic knowledge and reasoning skill. Created by nearly 1,000 human experts across more than 100 disciplines and released in January 2025, the test spans topics from the classics to quantum chemistry and mixes text with images. Grok 4 reportedly scored 25.4 percent on its own. But given access to tools (such as external aids for code execution or Web searches), it hit 38.6 percent. That jumped to 44.4 percent with a version called Grok 4 Heavy, which uses multiple AI agents to solve problems. The two next best-performing AI models are Google’s Gemini-Pro (which achieved 26.9 percent with the tools) and OpenAI’s o3 model (which got 24.9 percent, also with the tools). The results from xAI’s internal testing have yet to appear on the leaderboard for HLE, however, and it remains unclear whether this is because xAI has yet to submit the results or because those results are pending review. Manifold, a social prediction market platform where users bet play money (called “Mana”) on future events in politics, technology and other subjects, predicted a 1 percent chance, as of Friday morning, that Grok 4 would debut on HLE’s leaderboard with a 45 percent score or greater on the exam within a month of its release. (Meanwhile xAI has claimed a score of only 44.4.)During the launch, the xAI team also ran live demonstrations showing Grok 4 crunching baseball odds, determining which xAI employee has the “weirdest” profile picture on X and generating a simulated visualization of a black hole. Musk suggested that the system may discover entirely new technologies by later this year—and possibly “new physics” by the end of next year. Games and movies are on the horizon, too, with Musk predicting that Grok 4 will be able to make playable titles and watchable films by 2026. Grok 4 also has new audio capabilities, including a voice that sang during the launch, and Musk said new image generation and coding tools are soon to be released. The regular version of Grok 4 costs $30 a month; SuperGrok Heavy—the deluxe package with multiple agents and research tools—runs at $300.On supporting science journalismIf you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.Artificial Analysis, an independent benchmarking platform that ranks AI models, now lists Grok 4 as highest on its Artificial Analysis Intelligence Index, slightly ahead of Gemini 2.5 Pro and OpenAI’s o4-mini-high. And Grok 4 appears as the top-performing publicly available model on the leaderboards for the Abstraction and Reasoning Corpus, or ARC-AGI-1, and its second edition, ARC-AGI-2—benchmarks that measure progress toward “humanlike” general intelligence. Greg Kamradt, president of ARC Prize Foundation, a nonprofit organization that maintains the two leaderboards, says that when the xAI team contacted the foundation with Grok 4’s results, the organization then independently tested Grok 4 on a dataset to which the xAI team did not have access and confirmed the results. “Before we report performance for any lab, it’s not verified unless we verify it,” Kamradt says. “We approved the [testing results] slide that [the xAI team] showed in the launch.”According to xAI, Grok 4 also outstrips other AI systems on a number of additional benchmarks that suggest its strength in STEM subjects (read a full breakdown of the benchmarks here). Alex Olteanu, a senior data science editor at AI education platform DataCamp, has tested it. “Grok has been strong on math and programming in my tests, and I’ve been impressed by the quality of its chain-of-thought reasoning, which shows an ingenious and logically sound approach to problem-solving,” Olteanu says. “Its context window, however, isn’t very competitive, and it may struggle with large code bases like those you encounter in production. It also fell short when I asked it to analyze a 170-page PDF, likely due to its limited context window and weak multimodal abilities.” (Multimodal abilities refer to a model’s capacity to analyze more than one kind of data at the same time, such as a combination of text, images, audio and video.)On a more nuanced front, issues with Grok 4 have surfaced since its release. Several posters on X—owned by Musk himself—as well as tech-industry news outlets have reported that when Grok 4 was asked questions about the Israeli-Palestinian conflict, abortion and U.S. immigration law, it often searched for Musk’s stance on these issues by referencing his X posts and articles written about him. And the release of Grok 4 comes after several controversies with Grok 3, the previous model, which issued outputs that included antisemitic comments, praise for Hitler and claims of “white genocide”—incidents that xAI publicly acknowledged, attributing them to unauthorized manipulations and stating that the company was implementing corrective measures.At one point during the launch, Musk commented on how making an AI smarter than humans is frightening, though he said he believes the ultimate result will be good—probably. “I somewhat reconciled myself to the fact that, even if it wasn’t going to be good, I’d at least like to be alive to see it happen,” he said.",
  "image": "https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eElon Musk has launched xAI’s Grok 4—calling it the “world’s smartest AI” and claiming it can ace Ph.D.-level exams and outpace rivals such as Google’s Gemini and OpenAI’s o3 on tough benchmarks\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026amp;w=600\" alt=\"Digital illustration, structure made of cubes evolves from simple (on the left) to gradually a more complex shape of a thinking or contemplating person seated on a rock\" srcset=\"https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026amp;w=600 600w, https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026amp;w=900 900w, https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/42c24646dca7cb96/original/large_language_model_evolving_ai_concept.jpg?m=1752257663.541\u0026amp;w=1350 1350w\" sizes=\"(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw\" fetchpriority=\"high\"/\u003e\u003cfigcaption\u003e \u003cp\u003eFloriana/Getty Images\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp data-block=\"sciam/paragraph\"\u003eElon Musk released the newest artificial intelligence model from his company xAI on Wednesday night. In an hour-long public reveal session, he called the model, Grok 4, “the smartest AI in the world” and claimed it was capable of getting perfect SAT scores and near-perfect GRE results in every subject, from the humanities to the sciences.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eDuring the online launch, Musk and members of his team described testing Grok 4 on a metric called \u003ca href=\"https://agi.safe.ai/\"\u003eHumanity’s Last Exam\u003c/a\u003e (HLE)—a \u003ca href=\"https://scale.com/leaderboard/humanitys_last_exam\"\u003e2,500-question benchmark designed to evaluate an AI’s academic knowledge and reasoning skill\u003c/a\u003e. Created by nearly 1,000 human experts across more than 100 disciplines and released in January 2025, the test spans topics from the classics to quantum chemistry and mixes text with images. Grok 4 reportedly scored 25.4 percent on its own. But given access to tools (such as external aids for code execution or Web searches), it hit 38.6 percent. That jumped to 44.4 percent with a version called Grok 4 Heavy, which uses multiple AI agents to solve problems. The two next best-performing AI models are Google’s Gemini-Pro (which achieved 26.9 percent with the tools) and OpenAI’s o3 model (which got 24.9 percent, also with the tools). The results from xAI’s internal testing have yet to appear on the \u003ca href=\"https://agi.safe.ai/\"\u003eleaderboard for HLE\u003c/a\u003e, however, and it remains unclear whether this is because xAI has yet to submit the results or because those results are pending review. \u003ca href=\"https://manifold.markets/Bayesian/humanitys-last-exam-lists-grok-4-at\"\u003eManifold\u003c/a\u003e, a social prediction market platform where users bet play money (called “Mana”) on future events in politics, technology and other subjects, predicted a 1 percent chance, as of Friday morning, that Grok 4 would debut on HLE’s leaderboard with a 45 percent score or greater on the exam within a month of its release. (Meanwhile xAI has claimed a score of only 44.4.)\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eDuring the launch, the xAI team also ran live demonstrations showing Grok 4 crunching baseball odds, determining which xAI employee has the “weirdest” profile picture on X and generating a simulated visualization of \u003ca href=\"https://www.scientificamerican.com/black-holes/\"\u003ea black hole\u003c/a\u003e. Musk suggested that the system may discover entirely new technologies by later this year—and possibly “new physics” by the end of next year. Games and movies are on the horizon, too, with Musk predicting that Grok 4 will be able to make playable titles and watchable films by 2026. Grok 4 also has new audio capabilities, including a voice that sang during the launch, and Musk said new image generation and coding tools are soon to be released. The regular version of Grok 4 costs $30 a month; SuperGrok Heavy—the deluxe package with multiple agents and research tools—runs at $300.\u003c/p\u003e\u003chr/\u003e\u003ch2\u003eOn supporting science journalism\u003c/h2\u003e\u003cp\u003eIf you\u0026#39;re enjoying this article, consider supporting our award-winning journalism by \u003ca href=\"https://www.scientificamerican.com/getsciam/\"\u003esubscribing\u003c/a\u003e. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.\u003c/p\u003e\u003chr/\u003e\u003cp data-block=\"sciam/paragraph\"\u003e\u003ca href=\"https://artificialanalysis.ai/\"\u003eArtificial Analysis\u003c/a\u003e, an independent benchmarking platform that ranks AI models, now lists Grok 4 as highest on its Artificial Analysis Intelligence Index, slightly ahead of Gemini 2.5 Pro and OpenAI’s o4-mini-high. And Grok 4 appears as the top-performing publicly available model on the \u003ca href=\"https://arcprize.org/leaderboard\"\u003eleaderboards for the Abstraction and Reasoning Corpus, or ARC-AGI-1, and its second edition, ARC-AGI-2\u003c/a\u003e—benchmarks that measure progress toward “humanlike” general intelligence. Greg Kamradt, president of ARC Prize Foundation, a nonprofit organization that maintains the two leaderboards, says that when the xAI team contacted the foundation with Grok 4’s results, the organization then independently tested Grok 4 on a dataset to which the xAI team did not have access and confirmed the results. “Before we report performance for any lab, it’s not verified unless we verify it,” Kamradt says. “We approved the [testing results] slide that [the xAI team] showed in the launch.”\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAccording to xAI, Grok 4 also outstrips other AI systems on a number of additional benchmarks that suggest its strength in STEM subjects (read a full breakdown of the benchmarks \u003ca href=\"https://kingy.ai/blog/grok-4-benchmarks-explained-why-its-performance-is-a-game-changer/\"\u003ehere\u003c/a\u003e). Alex Olteanu, a senior data science editor at AI education platform \u003ca href=\"https://www.datacamp.com/blog/grok-4\"\u003eDataCamp\u003c/a\u003e, has tested it. “Grok has been strong on math and programming in my tests, and I’ve been impressed by the quality of its chain-of-thought reasoning, which shows an ingenious and logically sound approach to problem-solving,” Olteanu says. “Its context window, however, isn’t very competitive, and it may struggle with large code bases like those you encounter in production. It also fell short when I asked it to analyze a 170-page PDF, likely due to its limited context window and weak multimodal abilities.” (Multimodal abilities refer to a model’s capacity to analyze more than one kind of data at the same time, such as a combination of text, images, audio and video.)\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eOn a more nuanced front, issues with Grok 4 have surfaced since its release. Several \u003ca href=\"https://x.com/jeremyphoward/status/1943436621556466171\"\u003eposters on X\u003c/a\u003e—owned by Musk himself—as well as tech-industry \u003ca href=\"https://techcrunch.com/2025/07/10/grok-4-seems-to-consult-elon-musk-to-answer-controversial-questions/\"\u003enews\u003c/a\u003e \u003ca href=\"https://www.theverge.com/news/705015/grok-ai-uses-elon-musks-opinions-for-controversial-questions\"\u003eoutlets\u003c/a\u003e have reported that when Grok 4 was asked questions about the Israeli-Palestinian conflict, abortion and U.S. immigration law, it often searched for Musk’s stance on these issues by referencing his X posts and articles written about him. And the release of Grok 4 comes after several controversies with Grok 3, the previous model, which issued outputs that included antisemitic comments, praise for Hitler and claims of “white genocide”—incidents that xAI publicly acknowledged, attributing them to \u003ca href=\"https://www.bbc.com/news/articles/c4g8r34nxeno\"\u003eunauthorized manipulations\u003c/a\u003e and stating that the company was \u003ca href=\"https://www.reuters.com/business/musks-xai-updates-grok-chatbot-after-white-genocide-comments-2025-05-17/\"\u003eimplementing corrective measures\u003c/a\u003e.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAt one point during the launch, Musk commented on how making an AI smarter than humans is frightening, though he said he believes the ultimate result will be good—probably. “I somewhat reconciled myself to the fact that, even if it wasn’t going to be good, I’d at least like to be alive to see it happen,” he said.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-07-11T14:30:00-04:00",
  "modifiedTime": null
}
