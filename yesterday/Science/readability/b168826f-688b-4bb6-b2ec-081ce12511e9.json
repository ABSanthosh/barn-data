{
  "id": "b168826f-688b-4bb6-b2ec-081ce12511e9",
  "title": "AI Report Highlights Smaller, Better, Cheaper Models",
  "link": "https://www.scientificamerican.com/article/ai-report-highlights-smaller-better-cheaper-models/",
  "description": "A state of the AI industry report shows that 2024 was a breakthrough year for small, sleek models to rival the behemoths",
  "author": "",
  "published": "Wed, 09 Apr 2025 20:45:00 +0000",
  "source": "http://rss.sciam.com/ScientificAmerican-Global",
  "categories": null,
  "byline": "Nicola Jones",
  "length": 6333,
  "excerpt": "A state of the AI industry report shows that 2024 was a breakthrough year for small, sleek models to rival the behemoths",
  "siteName": "Scientific American",
  "favicon": "",
  "text": "Where AI Is Now: Smaller, Better, Cheaper ModelsA state of the AI industry report shows that 2024 was a breakthrough year for small, sleek models to rival the behemothsTop AI models’ performance is improving quickly, and the competition between them is growing ever fiercer. J Studios/Getty ImagesThe artificial intelligence (AI) race is heating up: the number and quality of high-performing Chinese AI models is rising to challenge the US lead, and the performance edge between top models is shrinking, according to an annual state of the industry report.The report highlights that as AI continues to improve quickly, no one firm is pulling ahead. On the Chatbot Arena Leaderboard, which asks users to vote on the performance of various bots, the top-ranked model scored about 12% higher than the tenth-ranked model in early 2024, but only 5% higher in early 2025 (see ‘All together now’). “The frontier is increasingly competitive — and increasingly crowded,” the report says.The Artificial Intelligence Index Report 2025 was released today by the Institute for Human Centered AI at Stanford University in California.On supporting science journalismIf you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.Nature; Source: AI Index Report 2025The index shows that notable generative AI models are, on average, still getting bigger, by using more decision-making variables, more computing power and bigger training data sets. But developers are also proving that smaller, sleeker models are capable of great things. Thanks to better algorithms, a modern model can now match the performance that could be achieved by a model 100 times larger two years ago. “2024 was a breakthrough year for smaller AI models,” the index says.Bart Selman, a computer scientist at Cornell University in Ithaca, New York, who was not involved in writing the Index report, says it’s good to see relatively small, cheap efforts such as China’s DeepSeek proving they can be competitive. “I’m predicting we’ll see some individual teams with five people, two people, that come up with some new algorithmic ideas that will shake things up,” he says. “Which is all good. We don’t want the world just to be run by some big companies.”Neck and neckThe report shows that the vast majority of notable AI models are now developed by industry rather than academia: a reversal of the situation in the early 2000s, when neural nets and generative AI had not yet taken off. Industry produced fewer than 20% of notable AI models before 2006, but 60% of them in 2023 and nearly 90% in 2024, the report says.The United States continues to be the top producer of notable models, releasing 40 in 2024, compared with China’s 15 and Europe’s 3. But plenty of other regions are joining the race, including the Middle East, Latin America and southeast Asia.And the previous US lead in terms of model quality has disappeared, the report adds. China, which produces the most AI publications and patents, is now developing models that match their US competition in performance. In 2023, the leading Chinese models lagged behind the top US model by nearly 20 percentage points on the Massive Multitask Language Understanding test (MMLU), a common benchmark for large language models. However, as of the end of 2024, the US lead had shrunk to 0.3 percentage points.“Around 2015, China put itself on the path to be a top player in AI, and they did it through investments in education,” says Selman. “We’re seeing that’s starting to pay off.”The field has also seen a surprising surge in the number and performance of ‘open weight’ models such as DeepSeek and Facebook’s LLaMa. Users can freely view the parameters that these models learn during training and use to make predictions, although other details, such as the training code, might remain secret. Originally, closed systems, in which none of these factors are disclosed, were markedly superior, but the performance gap between top contenders in these categories narrowed to 8% in early 2024, and to just 1.7% in early 2025.“It’s certainly good for anyone who can’t afford to build a model from scratch, which is a lot of little companies and academics,” says Ray Perrault, a computer scientist at SRI, a non-profit research institute in Menlo Park, California, and co-director of the report. OpenAI in San Francisco, California, which developed the chatbot ChatGPT, plans to release an open-weight model in the next few months.After the public launch of ChatGPT in 2022, developers put most of their energy into making systems better by making them bigger. That trend continues, the index reports: the energy used to train a typical leading AI model is currently doubling annually; the amount of computing resources used per model is doubling every five months; and the training data sets are doubling in size every eight months.Yet companies are also releasing very capable small models. The smallest model registering a score higher than 60% on the MMLU in 2022, for example, used 540 billion parameters; by 2024, a model achieved the same score with just 3.8 billion parameters. Smaller models train faster, give faster answers and use less energy than larger ones. “It helps everything,” says Perrault.Some smaller models can emulate the behaviour of larger models, says Selman, or take advantage of better algorithms and hardware than those in older systems. The index reports that the average energy efficiency of hardware used by AI systems improves by about 40% annually. As a result of such advances, the cost of scoring just over 60% on the MMLU has plummeted, from about US$20 per million tokens (bits of words produced by language models) in November 2022 to 7 cents per million tokens in October 2024.Despite striking improvements on several common benchmark tests, the index highlights that generative AI still suffers from issues such as implicit bias and a tendency to ‘hallucinate’, or spit out false information. “They impress me in many ways, but horrify me in others,” says Selman. “They surprise me in terms of making very basic errors.”This article is reproduced with permission and was first published on April 7, 2025.",
  "image": "https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2\u003e\u003cp\u003eWhere AI Is Now: Smaller, Better, Cheaper Models\u003c/p\u003e\u003c/h2\u003e\u003cp\u003eA state of the AI industry report shows that 2024 was a breakthrough year for small, sleek models to rival the behemoths\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026amp;w=600\" alt=\"Conceptual and abstract digital generated image of multiple AI chat icons hovering over a digital surface\" srcset=\"https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026amp;w=600 600w, https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026amp;w=900 900w, https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/59ddd80774f60255/original/AI_chat_icons.jpg?m=1744229519.147\u0026amp;w=1350 1350w\" sizes=\"(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw\" fetchpriority=\"high\"/\u003e\u003cfigcaption\u003e\u003cp\u003eTop AI models’ performance is improving quickly, and the competition between them is growing ever fiercer.\u003c/p\u003e \u003cp\u003eJ Studios/Getty Images\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe artificial intelligence (AI) race is heating up: the number and quality of \u003ca href=\"https://www.nature.com/articles/d41586-025-00275-0\"\u003ehigh-performing Chinese AI models\u003c/a\u003e is rising to challenge the US lead, and the performance edge between top models is shrinking, according to \u003ca href=\"https://hai.stanford.edu/ai-index\"\u003ean annual state of the industry report\u003c/a\u003e.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe report highlights that as AI continues to improve quickly, no one firm is pulling ahead. On the Chatbot Arena Leaderboard, which asks users to vote on the performance of various bots, the top-ranked model scored about 12% higher than the tenth-ranked model in early 2024, but only 5% higher in early 2025 (see ‘All together now’). “The frontier is increasingly competitive — and increasingly crowded,” the report says.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe Artificial Intelligence Index Report 2025 was released today by the Institute for Human Centered AI at Stanford University in California.\u003c/p\u003e\u003chr/\u003e\u003ch2\u003eOn supporting science journalism\u003c/h2\u003e\u003cp\u003eIf you\u0026#39;re enjoying this article, consider supporting our award-winning journalism by \u003ca href=\"https://www.scientificamerican.com/getsciam/\"\u003esubscribing\u003c/a\u003e. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.\u003c/p\u003e\u003chr/\u003e\u003cfigure data-block=\"contentful/image\" data-disable-apple-news=\"true\"\u003e\u003cpicture\u003e\u003csource media=\"(min-width: 0px)\" srcset=\"https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=600 600w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=750 750w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=900 900w\" sizes=\"(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw\"/\u003e\u003cimg alt=\"All together now. Line chart showing Chatbot Arena scores for Google, OpenAI, DeepSeek, xAI, Anthropic, Meta and Mistral AI from January 2024. The world’s top AI models are converging in performance, as measured by scores of human preference for the answers from various providers’ chatbots.\" decoding=\"async\" loading=\"lazy\" src=\"https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=900\" width=\"3130\" height=\"2292\" srcset=\"https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=1350 1350w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=2000 2000w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=600 600w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=750 750w, https://static.scientificamerican.com/dam/m/407705d6c9213c76/original/nature_AI-race_graphic.png?m=1744229323.877\u0026amp;w=900 900w\" sizes=\"(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003e\u003cp\u003eNature; Source: AI Index Report 2025\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe index shows that \u003ca href=\"https://www.nature.com/articles/d41586-023-00641-w\"\u003enotable generative AI models are, on average, still getting bigger\u003c/a\u003e, by using more decision-making variables, more computing power and bigger training data sets. But developers are also proving that smaller, sleeker models are capable of great things. Thanks to better algorithms, a modern model can now match the performance that could be achieved by a model 100 times larger two years ago. “2024 was a breakthrough year for smaller AI models,” the index says.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eBart Selman, a computer scientist at Cornell University in Ithaca, New York, who was not involved in writing the Index report, says it’s good to see relatively \u003ca href=\"https://www.nature.com/articles/d41586-025-00229-6\"\u003esmall, cheap efforts such as China’s\u003c/a\u003e\u003ca href=\"https://www.nature.com/articles/d41586-025-00229-6\"\u003e DeepSeek\u003c/a\u003e proving they can be competitive. “I’m predicting we’ll see some individual teams with five people, two people, that come up with some new algorithmic ideas that will shake things up,” he says. “Which is all good. We don’t want the world just to be run by some big companies.”\u003c/p\u003e\u003ch2 id=\"neck-and-neck\" data-block=\"sciam/heading\"\u003eNeck and neck\u003c/h2\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe report shows that the vast majority of notable AI models are now developed by industry rather than academia: a reversal of the situation in the early 2000s, when \u003ca href=\"https://www.nature.com/articles/d41586-023-03272-3\"\u003eneural nets\u003c/a\u003e and \u003ca href=\"https://www.nature.com/articles/d41586-023-00340-6\"\u003egenerative AI\u003c/a\u003e had not yet taken off. Industry produced fewer than 20% of notable AI models before 2006, but 60% of them in 2023 and nearly 90% in 2024, the report says.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe United States continues to be the top producer of notable models, releasing 40 in 2024, compared with China’s 15 and Europe’s 3. But plenty of other regions are joining the race, including the Middle East, Latin America and southeast Asia.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAnd the previous US lead in terms of model quality has disappeared, the report adds. \u003ca href=\"https://www.nature.com/articles/d41586-024-02515-1\"\u003eChina, which produces the most AI publications and patents\u003c/a\u003e, is now developing models that match their US competition in performance. In 2023, the leading Chinese models lagged behind the top US model by nearly 20 percentage points on the Massive Multitask Language Understanding test (MMLU), a common benchmark for large language models. However, as of the end of 2024, the US lead had shrunk to 0.3 percentage points.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003e“Around 2015, China put itself on the path to be a top player in AI, and they did it through investments in education,” says Selman. “We’re seeing that’s starting to pay off.”\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe field has also seen a surprising surge in the number and performance of ‘open weight’ models such as DeepSeek and \u003ca href=\"https://www.nature.com/articles/d41586-023-01970-6\"\u003eFacebook’s LLaMa\u003c/a\u003e. Users can freely view the parameters that these models learn during training and use to make predictions, although other details, such as the training code, might remain secret. Originally, closed systems, in which none of these factors are disclosed, were markedly superior, but the performance gap between top contenders in these categories narrowed to 8% in early 2024, and to just 1.7% in early 2025.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003e“It’s certainly good for anyone who can’t afford to build a model from scratch, which is a lot of little companies and academics,” says Ray Perrault, a computer scientist at SRI, a non-profit research institute in Menlo Park, California, and co-director of the report. OpenAI in San Francisco, California, which developed the chatbot ChatGPT, plans to release an open-weight model in the next few months.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAfter the public launch of ChatGPT in 2022, developers put most of their energy into making systems better by making them bigger. That trend continues, the index reports: the energy used to train a typical leading AI model is currently doubling annually; the amount of computing resources used per model is doubling every five months; and the training data sets are doubling in size every eight months.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eYet companies are also releasing very capable small models. The smallest model registering a score higher than 60% on the MMLU in 2022, for example, used 540 billion parameters; by 2024, a model achieved the same score with just 3.8 billion parameters. Smaller models train faster, give faster answers and \u003ca href=\"https://www.nature.com/articles/d41586-025-00616-z\"\u003euse less energy than larger ones\u003c/a\u003e. “It helps everything,” says Perrault.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eSome smaller models can emulate the behaviour of larger models, says Selman, or take advantage of better algorithms and hardware than those in older systems. The index reports that the average energy efficiency of hardware used by AI systems improves by about 40% annually. As a result of such advances, the cost of scoring just over 60% on the MMLU has plummeted, from about US$20 per million tokens (bits of words produced by language models) in November 2022 to 7 cents per million tokens in October 2024.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eDespite \u003ca href=\"https://www.nature.com/articles/d41586-025-00110-6\"\u003estriking improvements on several common benchmark tests\u003c/a\u003e, the index highlights that generative AI still suffers from issues such as implicit bias and a tendency to ‘hallucinate’, or spit out false information. “They impress me in many ways, but horrify me in others,” says Selman. “They surprise me in terms of making very basic errors.”\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003e\u003ci\u003eThis article is reproduced with permission and was \u003c/i\u003e\u003ca href=\"https://www.nature.com/articles/d41586-025-01033-y\"\u003e\u003ci\u003efirst published\u003c/i\u003e\u003c/a\u003e\u003ci\u003e on April 7, 2025\u003c/i\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-04-09T16:45:00-04:00",
  "modifiedTime": null
}
