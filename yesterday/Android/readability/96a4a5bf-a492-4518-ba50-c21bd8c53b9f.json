{
  "id": "96a4a5bf-a492-4518-ba50-c21bd8c53b9f",
  "title": "How well do you know our I/O 2025 announcements?",
  "link": "https://blog.google/technology/ai/google-io-2025-quiz/",
  "description": "Take this quiz about Google I/O 2025 to see how well you know what we announced this year at I/O.",
  "author": "Zahra ThompsonContributorThe Keyword",
  "published": "Thu, 22 May 2025 16:00:00 +0000",
  "source": "https://blog.google/products/android/rss",
  "categories": [
    "Search",
    "Android",
    "Google One",
    "Google Labs",
    "Developers",
    "Learning \u0026 Education",
    "Google Workspace",
    "Shopping",
    "Gemini",
    "AI",
    "Gemini App",
    "Gemini Models",
    "Gemini Features",
    "Research"
  ],
  "byline": "Zahra Thompson",
  "length": 61988,
  "excerpt": "Take this quiz about Google I/O 2025 to see how well you know what we announced this year at I/O.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20250514-1654",
  "text": "May 22, 2025 [[read-time]] min read Take our quiz to find out how well you know our I/O announcements about Search, Gemini, generative AI and beyond. Another Google I/O is in the books, and it was our most exciting one yet. This year, Googlers took the stage to share how we’re releasing new intelligent AI models, agentic products and personalized features faster than ever before, making them helpful for everyone. We announced updates to our Gemini models and the Gemini app, AI Mode in Search, our generative AI technology and even more. Test how much you know about our biggest I/O announcements with this quiz. (And if you want to study up first, check out this list of the many, many things we announced at Google I/O 2025.) True or false: We’re making Gemini 2.5 Pro even better by introducing an enhanced reasoning mode we’re calling Deep Think. Don’t think twice about your answer, because it’s correct: We’re making Gemini 2.5 Pro even better by introducing Deep Think, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the Gemini API to get their feedback before making it widely available. Think again: We’re making Gemini 2.5 Pro even better by introducing Deep Think, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the Gemini API to get their feedback before making it widely available. Don’t think twice about your answer, because it’s correct: We’re making Gemini 2.5 Pro even better by introducing Deep Think, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the Gemini API to get their feedback before making it widely available. Think again: We’re making Gemini 2.5 Pro even better by introducing Deep Think, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the Gemini API to get their feedback before making it widely available. We’re starting to roll out AI Mode, our most powerful AI search, to: That’s right, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. Better yet, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. That’s right, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. Better yet, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. That’s right, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. Better yet, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. That’s right, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. Better yet, we’re rolling out AI Mode for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we're bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S. Veo 3, our new state-of-the-art video generation model, not only improves on the quality of Veo 2, but also generates what for the first time? Sounds about right: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. It’s music to our ears: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. Sounds about right: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. It’s music to our ears: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. Sounds about right: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. It’s music to our ears: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. Sounds about right: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. It’s music to our ears: Veo 3 can generate videos with audio — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the Gemini app and in Flow. It’s also available for enterprise users on Vertex AI. What’s the name of our new AI subscription plan with the highest usage limits and access to our most capable models and premium features? That’s ultra-correct. Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. The correct answer is Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. That’s ultra-correct. Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. The correct answer is Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. That’s ultra-correct. Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. The correct answer is Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. That’s ultra-correct. Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. The correct answer is Google AI Ultra, which offers access to our most capable models and premium features, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries. Which updated Gemini model did we just make available to everyone in the Gemini app? What’s the name of our new AI filmmaking tool custom-designed for Google’s most advanced models — Veo, Imagen and Gemini? Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. Let’s just say we’re going with the flow. Built with and for creatives, Flow can help storytellers explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon. True or false: You can now get a complete, customized Deep Research report that combines public data with your own uploaded files. Yes, it’s not too good to be true: Now that you can upload your own PDFs, images and files from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed. It’s actually not too good to be true: Now that you can upload your own PDFs, images and files from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed. Yes, it’s not too good to be true: Now that you can upload your own PDFs, images and files from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed. It’s actually not too good to be true: Now that you can upload your own PDFs, images and files from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed. With Search Live, you’ll be able to talk back-and-forth with Search using your ____. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. Live from your camera, it’s…Search Live! We’re bringing Project Astra’s live capabilities into Search so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see. On average, how much longer are people’s conversations with Gemini Live than their text-based Gemini conversations? High five, that’s right! People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. Even longer: People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. High five, that’s right! People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. Even longer: People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. High five, that’s right! People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. Even longer: People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. High five, that’s right! People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. Even longer: People love Gemini Live. In fact, the conversations are five times longer than text-based conversations on average because it offers new ways to get help, whether it's troubleshooting a broken appliance or getting personalized shopping advice. Your brain’s not on vacation mode: Agent Mode is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Agent Mode is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Your brain’s not on vacation mode: Agent Mode is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Agent Mode is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Your brain’s not on vacation mode: Agent Mode is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Agent Mode is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Your brain’s not on vacation mode: Agent Mode is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. Agent Mode is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you. If you head to Search Labs in the U.S., what can you upload to virtually try on billions of apparel listings? That’s right! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. Nope! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. That’s right! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. Nope! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. That’s right! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. Nope! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. That’s right! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. Nope! With our “try on” experiment, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies. In the coming weeks, we’ll make Gemini Live more personal by connecting some of your favorite Google apps so you can take actions mid-conversation. Which app(s) will you be able to connect? Exactly: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Even better: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Exactly: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Even better: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Exactly: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Even better: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Exactly: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. Even better: Gemini Live will integrate more deeply into your daily life starting with Google Maps, Calendar, Tasks and Keep, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings. AI Overviews are now available in more than ____ countries and territories and more than ____ languages. You’re right on target. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. Not quite. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. You’re right on target. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. Not quite. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. You’re right on target. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. Not quite. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. You’re right on target. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. Not quite. AI Overviews are now available in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more. Our new video communication platform Google Beam combines our AI video model and ____ to transform standard 2D video streams into realistic 3D experiences. In an I/O demo, XR product manager Nishtha Bhatia used Gemini on her Android XR glasses to recall a detail about the coffee she had backstage. What was that detail? You’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. That’s not right, but we still like you a latte. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. You’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. That’s not right, but we still like you a latte. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. You’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. That’s not right, but we still like you a latte. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. You’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. That’s not right, but we still like you a latte. Nishtha used Gemini on her Android XR glasses to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time. Speech translation in Google Meet translates your spoken words into your listener’s preferred language — while preserving your voice and expression. Which languages are now available? Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. Talk about exciting: Google Meet’s near real-time, low-latency speech translation is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We're also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations. We’re infusing LearnLM directly into Gemini 2.5, which is now the world’s leading model for learning. LearnLM is our family of models and capabilities that is: This answer gets an A+. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. Almost, but the A+ answer is all of the above. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. This answer gets an A+. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. Almost, but the A+ answer is all of the above. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. This answer gets an A+. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. Almost, but the A+ answer is all of the above. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. This answer gets an A+. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. Almost, but the A+ answer is all of the above. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively. Finally, what did I/O originally stand for? You’re an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? No, but you can still be an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? You’re an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? No, but you can still be an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? You’re an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? No, but you can still be an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? You’re an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? No, but you can still be an I/O pro. Originally, the name I/O was based on the first two digits in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think? You have answered 0/18 questions. POSTED IN: AI Developers Gemini Gemini App Gemini Models Gemini Features Search Shopping Learning \u0026 Education Android Google Labs Google Workspace Research Google One",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_QuizSocialShare.width-1300.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;How well do you know our I/O 2025 announcements?\u0026#34;\n  }\"\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eMay 22, 2025\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          Take our quiz to find out how well you know our I/O announcements about Search, Gemini, generative AI and beyond.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n      \n\n\n\n\n\n\n\n\n\n\n\u003cdiv\u003e\n    \u003cfigure\u003e\n      \u003cdiv\u003e\n        \u003cp\u003e\u003cimg alt=\"Black text saying Google I/O sits against a white and gray grid, surrounded by rainbow Google product logos.\" data-component=\"uni-progressive-image\" fetchpriority=\"high\" height=\"150px\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_QuizHero.width-200.format-webp.webp\" width=\"360px\" data-sizes=\"(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px\" data-srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_QuizHero.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_QuizHero.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_QuizHero.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_QuizHero.width-2200.format-webp.webp 2200w\"/\u003e\n        \u003c/p\u003e\n      \u003c/div\u003e\n      \n    \u003c/figure\u003e\n  \u003c/div\u003e\n\n\n\n\n\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\n\n\n\u003cuni-article-speakable page-title=\"How well do you know our I/O 2025 announcements?\" listen-to-article=\"Listen to article\" data-date-modified=\"2025-05-22T16:47:06.846954+00:00\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-script-src=\"https://www.gstatic.com/readaloud/player/web/api/js/api.js\"\u003e\u003c/uni-article-speakable\u003e\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How well do you know our I/O 2025 announcements?\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"7uaov\"\u003eAnother \u003ca href=\"https://blog.google/technology/developers/google-io-2025-collection\"\u003eGoogle I/O\u003c/a\u003e is in the books, and it was our \u003ca href=\"https://x.com/Google/status/1924901352070676540\"\u003emost exciting one yet\u003c/a\u003e. This year, Googlers took the stage to share how we’re releasing new intelligent AI models, agentic products and personalized features faster than ever before, making them helpful for everyone. We announced updates to our \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025\"\u003eGemini models\u003c/a\u003e and the \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025\"\u003eGemini app\u003c/a\u003e, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update\"\u003eAI Mode in Search\u003c/a\u003e, our \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025\"\u003egenerative AI technology\u003c/a\u003e and even more. Test how much you know about our biggest I/O announcements with this quiz. (And if you want to study up first, check out this list of \u003ca href=\"https://blog.google/technology/ai/google-io-2025-all-our-announcements\"\u003ethe many, many things we announced at Google I/O 2025\u003c/a\u003e.)\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\u003csection id=\"quiz-2\" data-component=\"uni-quizzes\" data-partial-response-msg=\"You have only answered \u0026lt;strong\u0026gt;[[answered]]/[[questions]] questions.\u0026lt;/strong\u0026gt;\" data-complete-response-msg=\"You answered [[answered]]/[[questions]] questions correctly.\" data-analytics-module=\"{\n      \u0026#34;module_name\u0026#34;: \u0026#34;Quiz\u0026#34;,\n      \u0026#34;section_header\u0026#34;: \u0026#34;undefined\u0026#34;\n    }\"\u003e\n  \n  \n\n  \n  \u003cul\u003e\n    \n      \u003cli id=\"question-entry-1\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Quiz.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Quiz.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Quiz.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Text saying Gemini 2.5 sits against a dark background, surrounded by blue and gray technological icons.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"9fvk5\"\u003eTrue or false: We’re making Gemini 2.5 Pro even better by introducing an enhanced reasoning mode we’re calling Deep Think.\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-1\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"syxcp\"\u003eDon’t think twice about your answer, because it’s correct: We’re making Gemini 2.5 Pro even better by \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#deep-think\"\u003eintroducing Deep Think\u003c/a\u003e, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the \u003ca href=\"https://ai.google.dev/\"\u003eGemini API\u003c/a\u003e to get their feedback before making it widely available.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bmj7m\"\u003eThink again: We’re making Gemini 2.5 Pro even better by \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#deep-think\"\u003eintroducing Deep Think\u003c/a\u003e, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the \u003ca href=\"https://ai.google.dev/\"\u003eGemini API\u003c/a\u003e to get their feedback before making it widely available.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"syxcp\"\u003eDon’t think twice about your answer, because it’s correct: We’re making Gemini 2.5 Pro even better by \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#deep-think\"\u003eintroducing Deep Think\u003c/a\u003e, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the \u003ca href=\"https://ai.google.dev/\"\u003eGemini API\u003c/a\u003e to get their feedback before making it widely available.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bmj7m\"\u003eThink again: We’re making Gemini 2.5 Pro even better by \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#deep-think\"\u003eintroducing Deep Think\u003c/a\u003e, an experimental, enhanced reasoning mode for highly-complex math and coding. We’re making it available to trusted testers via the \u003ca href=\"https://ai.google.dev/\"\u003eGemini API\u003c/a\u003e to get their feedback before making it widely available.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-2\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_AIM.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_AIM.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_AIM.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A white oval against a white background. Inside the oval are icons for a microphone and camera and a button that says AI Mode.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"432x4\"\u003eWe’re starting to roll out AI Mode, our most powerful AI search, to:\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-2\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s right, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eBetter yet, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s right, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eBetter yet, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s right, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eBetter yet, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s right, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eBetter yet, \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search\"\u003ewe’re rolling out AI Mode\u003c/a\u003e for everyone in the U.S. — no Labs sign-up required. AI Mode uses more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web. Over the coming weeks, you’ll see a new tab for AI Mode appear in Search and in the search bar in the Google app. And starting this week, we\u0026#39;re bringing a custom version of Gemini 2.5, our most intelligent model, into Search for both AI Mode and AI Overviews in the U.S.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-3\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Veo3.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Veo3.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Veo3.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Still from a Veo 3-generated video showing a bearded sailor in a blue outfit with a pipe in his hand. Text at the bottom says Generated with Veo 3\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"eic6n\"\u003eVeo 3, our new state-of-the-art video generation model, not only improves on the quality of Veo 2, but also generates what for the first time?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-3\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eSounds about right: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eIt’s music to our ears: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eSounds about right: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eIt’s music to our ears: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eSounds about right: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eIt’s music to our ears: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eSounds about right: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eIt’s music to our ears: \u003ca href=\"https://blog.google/technology/ai/generative-media-models-io-2025/#veo-3\"\u003eVeo 3 can generate videos with audio\u003c/a\u003e — traffic noises in the background of a city street scene, birds singing in a park, even dialogue between characters. Across the board, Veo 3 excels from text and image prompting to real-world physics and accurate lip syncing. Veo 3 is available today for Ultra subscribers in the United States in the \u003ca href=\"http://gemini.google.com/\"\u003eGemini app\u003c/a\u003e and in \u003ca href=\"http://flow.google/\"\u003eFlow\u003c/a\u003e. It’s also available for enterprise users on \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai\"\u003eVertex AI\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-4\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Subscription.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Subscription.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Subscription.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A dark background with rainbow ombre at the top, with text saying Google AI Ultra subscription, and tiles with text including Gemini app and Flow. Underneath that, neon jellyfish float over Earth.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"432x4\"\u003eWhat’s the name of our new AI subscription plan with the highest usage limits and access to our most capable models and premium features?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-4\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s ultra-correct. \u003ca href=\"http://one.google.com/ai\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eThe correct answer is \u003ca href=\"http://one.google.com/ai?utm_source=g1\u0026amp;utm_medium=web\u0026amp;utm_campaign=google_ai_plan_blog\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s ultra-correct. \u003ca href=\"http://one.google.com/ai\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eThe correct answer is \u003ca href=\"http://one.google.com/ai?utm_source=g1\u0026amp;utm_medium=web\u0026amp;utm_campaign=google_ai_plan_blog\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s ultra-correct. \u003ca href=\"http://one.google.com/ai\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eThe correct answer is \u003ca href=\"http://one.google.com/ai?utm_source=g1\u0026amp;utm_medium=web\u0026amp;utm_campaign=google_ai_plan_blog\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eThat’s ultra-correct. \u003ca href=\"http://one.google.com/ai\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eThe correct answer is \u003ca href=\"http://one.google.com/ai?utm_source=g1\u0026amp;utm_medium=web\u0026amp;utm_campaign=google_ai_plan_blog\"\u003eGoogle AI Ultra\u003c/a\u003e, which offers access to our \u003ca href=\"https://blog.google/products/google-one/google-ai-ultra/\"\u003emost capable models and premium features\u003c/a\u003e, including Gemini, Flow and Whisk. You’ll also have access to our agentic research prototype, Project Mariner. Google AI Ultra is starting to roll out in the U.S. for $249.99/month (with a special offer for first-time users of 50% off for your first three months), and coming soon to more countries.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-5\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiApp.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiApp.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiApp.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"The bottom half of a phone screen against a black screen. The phone shows the Gemini app with text saying Hello, Josh.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"qb03a\"\u003eWhich updated Gemini model did we just make available to everyone in the Gemini app?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-5\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-6\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/182Gen_Media_Flow_demo_v33.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/182Gen_Media_Flow_demo_v33.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/182Gen_Media_Flow_demo_v33.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Four frames in which Flow is generating a video of a man driving in a convertible with a gold rooster gearstick and huge rooster in the backseat\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"eic6n\"\u003eWhat’s the name of our new AI filmmaking tool custom-designed for Google’s most advanced models — Veo, Imagen and Gemini?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-6\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eLet’s just say we’re going with the flow. Built with and for creatives, \u003ca href=\"https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/\"\u003eFlow can help storytellers\u003c/a\u003e explore their ideas without bounds and create cinematic clips and scenes for their stories by bringing together Veo, Imagen and Gemini. It’s available today for Google AI Pro and Ultra plan subscribers in the U.S., with more countries coming soon.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-7\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_DR.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_DR.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_DR.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A black screen showing a Deep Research prompt box with a prompt about researching the movement of comets.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"qb03a\"\u003eTrue or false: You can now get a complete, customized Deep Research report that combines public data with your own uploaded files.\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-7\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eYes, it’s not too good to be true: Now that you can \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#deep-research\"\u003eupload your own PDFs, images and files\u003c/a\u003e from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eIt’s actually not too good to be true: Now that you can \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#deep-research\"\u003eupload your own PDFs, images and files\u003c/a\u003e from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eYes, it’s not too good to be true: Now that you can \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#deep-research\"\u003eupload your own PDFs, images and files\u003c/a\u003e from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eIt’s actually not too good to be true: Now that you can \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#deep-research\"\u003eupload your own PDFs, images and files\u003c/a\u003e from Drive to Deep Research, you’ll get a holistic understanding that cross-references your unique knowledge with broader trends all in one place, saving you time and revealing connections you might have otherwise missed.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-8\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_SearchLive.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_SearchLive.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_SearchLive.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A black phone screen showing the Search Live experience, against a white background.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"1g18a\"\u003eWith Search Live, you’ll be able to talk back-and-forth with Search using your ____.\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-8\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"vfvd0\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0e6we\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"vfvd0\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0e6we\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"vfvd0\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0e6we\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"vfvd0\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0e6we\"\u003eLive from your camera, it’s…Search Live! We’re \u003ca href=\"https://blog.google/products/search/google-search-ai-mode-update/#live-capabilities\"\u003ebringing Project Astra’s live capabilities into Search\u003c/a\u003e so you can talk back-and-forth with Search about what you see in real time, using your camera. For example, if you’re feeling stumped on a project and need some help, simply tap the “Live” icon in AI Mode or in Lens, point your camera and ask your question. Just like that, Search becomes a learning partner that can see what you see.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-9\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Quiz-Live.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Quiz-Live.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Quiz-Live.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Phone screen against a black background showing a shopping list in Gemini Live\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"qb03a\"\u003eOn average, how much longer are people’s conversations with Gemini Live than their text-based Gemini conversations?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-9\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eHigh five, that’s right! People love Gemini Live. In fact, the conversations are\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003e five times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven longer: People love Gemini Live. In fact, the conversations are \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003efive times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eHigh five, that’s right! People love Gemini Live. In fact, the conversations are\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003e five times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven longer: People love Gemini Live. In fact, the conversations are \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003efive times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eHigh five, that’s right! People love Gemini Live. In fact, the conversations are\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003e five times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven longer: People love Gemini Live. In fact, the conversations are \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003efive times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eHigh five, that’s right! People love Gemini Live. In fact, the conversations are\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003e five times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven longer: People love Gemini Live. In fact, the conversations are \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003efive times longer\u003c/a\u003e than text-based conversations on average because it offers new ways to get help, whether it\u0026#39;s troubleshooting a broken appliance or getting personalized shopping advice.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-10\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Agent.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Agent.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Agent.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A blue oval against a white background. Inside the oval is a blue sparkle and blue text that says Agent Mode.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \n\n  \n  \u003cul id=\"question-10\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"6afbk\"\u003eYour brain’s not on vacation mode: \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"lcsyh\"\u003e\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"6afbk\"\u003eYour brain’s not on vacation mode: \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"lcsyh\"\u003e\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"6afbk\"\u003eYour brain’s not on vacation mode: \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"lcsyh\"\u003e\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"6afbk\"\u003eYour brain’s not on vacation mode: \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"lcsyh\"\u003e\u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#plans\"\u003eAgent Mode\u003c/a\u003e is actually a catchy name for a new experimental capability arriving on desktop soon when you upgrade the Gemini app to the Ultra plan, where you’ll be able to simply state your objective, and Gemini intelligently orchestrates the steps to achieve it. Agent Mode combines advanced features like live web browsing, in-depth research and smart integrations with your Google apps so it can manage complex, multi-step tasks from start to finish with minimal oversight from you.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-11\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_TIO.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_TIO.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_TIO.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Phone screen showing the try on experiment in Search Labs\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"y9y88\"\u003eIf you head to Search Labs in the U.S., what can you upload to virtually try on billions of apparel listings?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-11\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"fwryt\"\u003eThat’s right! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"j0cmv\"\u003eNope! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"fwryt\"\u003eThat’s right! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"j0cmv\"\u003eNope! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"fwryt\"\u003eThat’s right! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"j0cmv\"\u003eNope! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"fwryt\"\u003eThat’s right! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"j0cmv\"\u003eNope! With our \u003ca href=\"https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/\"\u003e“try on” experiment\u003c/a\u003e, online shoppers using Search Labs in the U.S. can now try billions of apparel listings just by uploading a single image of themselves. It’s powered by a new custom image generation model, which understands the human body and the nuances of clothing — like how different materials fold, stretch and drape on different bodies.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-12\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiLive.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiLive.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiLive.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Blue text saying Gemini Live sits against a black background, with a wavy, hazy purple and blue shape at the bottom.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"qb03a\"\u003eIn the coming weeks, we’ll make Gemini Live more personal by connecting some of your favorite Google apps so you can take actions mid-conversation. Which app(s) will you be able to connect?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-12\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eExactly: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven better: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eExactly: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven better: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eExactly: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven better: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"3ljau\"\u003eExactly: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kp60v\"\u003eEven better: Gemini Live will integrate more deeply into your daily life starting with \u003ca href=\"https://blog.google/products/gemini/gemini-app-updates-io-2025/#gemini-live\"\u003eGoogle Maps, Calendar, Tasks \u003ci\u003eand\u003c/i\u003e Keep\u003c/a\u003e, with more app connections coming later. You can always manage these app connections and your information anytime in the app’s settings.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-13\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_AIO.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_AIO.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_AIO.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A phone screen showing an AI overview about how to DIY soundproof a room.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"432x4\"\u003eAI Overviews are now available in more than ____ countries and territories and more than ____ languages.\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-13\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eYou’re right on target. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eNot quite. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eYou’re right on target. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eNot quite. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eYou’re right on target. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eNot quite. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"bnfwu\"\u003eYou’re right on target. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"5tk8c\"\u003eNot quite. \u003ca href=\"https://blog.google/products/search/ai-overview-expansion-may-2025-update/\"\u003eAI Overviews are now available\u003c/a\u003e in more than 200 countries and territories and in more than 40 languages, with support added for Arabic, Chinese, Malay, Urdu and more.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-14\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Beam.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Beam.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Beam.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A large black screen with text that says Google Beam sits in front of a desk and office chair. On the table is a tablet showing upcoming meetings.\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"7rwls\"\u003eOur new video communication platform Google Beam combines our AI video model and ____ to transform standard 2D video streams into realistic 3D experiences.\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-14\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-15\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_XR_SS_5JeZU77.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_XR_SS_5JeZU77.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_XR_SS_5JeZU77.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Collage showing text that says Android XR surrounded by images of people using Android XR headsets and glasses\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"eic6n\"\u003eIn an I/O demo, XR product manager Nishtha Bhatia used Gemini on her Android XR glasses to recall a detail about the coffee she had backstage. What was that detail?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-15\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eThat’s not right, but we still like you a latte. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eThat’s not right, but we still like you a latte. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eThat’s not right, but we still like you a latte. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’ve got a latte going for you, because that’s correct. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eThat’s not right, but we still like you a latte. Nishtha used Gemini on her \u003ca href=\"https://blog.google/products/android/android-xr-gemini-glasses-headsets/\"\u003eAndroid XR glasses\u003c/a\u003e to remember the name of the coffee shop. She also used her glasses to schedule a coffee at that cafe for later in the day, take a picture of I/O attendees and translate a conversation in Hindi and Farsi in real time.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-16\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Translator_Still_Frame.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Translator_Still_Frame.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Translator_Still_Frame.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"A Google Meet call shows two women using speech translation\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"7rwls\"\u003eSpeech translation in Google Meet translates your spoken words into your listener’s preferred language — while preserving your voice and expression. Which languages are now available?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-16\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kxn7p\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"ovn7e\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kxn7p\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"ovn7e\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kxn7p\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"ovn7e\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"kxn7p\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"ovn7e\"\u003eTalk about exciting: Google Meet’s \u003ca href=\"https://blog.google/products/workspace/google-workspace-gemini-may-2025-updates/\"\u003enear real-time, low-latency speech translation\u003c/a\u003e is available now to Google AI Pro and Ultra subscribers in beta, initially in English and Spanish, with more languages coming in the next few weeks. We\u0026#39;re also further developing this capability for businesses, with early testing coming to Workspace customers this year. Speech translation makes sure your voice, tone and expressions still shine through — even when translated — allowing people speaking different languages to have natural conversations.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-17\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IOLearnLM.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IOLearnLM.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IOLearnLM.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Learning-related icons against a white background, including the menu for generating a NotebookLM Audio Overview\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"eic6n\"\u003eWe’re infusing LearnLM directly into Gemini 2.5, which is now the world’s leading model for learning. LearnLM is our family of models and capabilities that is:\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-17\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eThis answer gets an A+. \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eLearnLM is our family of models and capabilities\u003c/a\u003e fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eAlmost, but the A+ answer is \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eall of the above\u003c/a\u003e. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eThis answer gets an A+. \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eLearnLM is our family of models and capabilities\u003c/a\u003e fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eAlmost, but the A+ answer is \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eall of the above\u003c/a\u003e. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eThis answer gets an A+. \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eLearnLM is our family of models and capabilities\u003c/a\u003e fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eAlmost, but the A+ answer is \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eall of the above\u003c/a\u003e. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eThis answer gets an A+. \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eLearnLM is our family of models and capabilities\u003c/a\u003e fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eAlmost, but the A+ answer is \u003ca href=\"https://blog.google/outreach-initiatives/education/google-gemini-learnlm-update/\"\u003eall of the above\u003c/a\u003e. LearnLM is our family of models and capabilities fine-tuned for learning and built in partnership with education experts. With LearnLM, Gemini adheres to the principles of learning science to go beyond just giving you the answer. Instead, Gemini can explain how you get there, helping you untangle even the most complex questions and topics so you can learn more effectively.\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli id=\"question-entry-18\"\u003e\n        \n          \n        \n\n        \n\n\n  \n  \n    \n\n\n\n  \n  \n  \n  \u003cfigure\u003e\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_logo.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n        \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_logo.width-500.format-webp.webp\u0026#34;,\n        \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_logo.width-1000.format-webp.webp\u0026#34;\n      }\" alt=\"Huge rainbow block letters spelling out I/O lie against the surface of the Earth underneath a starry blue sky\"/\u003e\n  \u003c/figure\u003e\n\n  \n\n  \n  \u003cdiv\u003e\u003cp data-block-key=\"eic6n\"\u003eFinally, what did I/O originally stand for?\u003c/p\u003e\u003c/div\u003e\n\n  \n  \u003cul id=\"question-18\"\u003e\n    \n      \u003cli id=\"answer-1\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’re an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eNo, but you can still be an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-2\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’re an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eNo, but you can still be an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-3\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’re an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eNo, but you can still be an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n      \u003cli id=\"answer-4\"\u003e\n        \n        \u003cdiv\u003e\n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"0v3rm\"\u003eYou’re an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n          \n            \u003cdiv\u003e\n              \u003cp data-block-key=\"v3uwa\"\u003eNo, but you can still be an I/O pro. Originally, \u003ca href=\"https://blog.google/inside-google/google-io-meaning/\"\u003ethe name I/O was based on the first two digits\u003c/a\u003e in a googol (a one, followed by 100 zeroes), the number that lends our company its name. According to lore, I/O has evolved to also nod to “input / output,” referencing the computational concept of interfacing between a computer system and the outside world, and “innovation in the open.” Pretty fitting, don’t you think?\u003c/p\u003e\n            \u003c/div\u003e\n          \n      \u003c/div\u003e\u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n\n      \u003c/li\u003e\n    \n  \u003c/ul\u003e\n\n  \n  \n    \u003cdiv\u003e\n      \n      \n        \u003cp\u003e\n          You have answered \u003cstrong\u003e0/18 questions.\u003c/strong\u003e\n        \u003c/p\u003e\n      \n      \n      \n      \n      \n    \u003c/div\u003e\n  \n\u003c/section\u003e\n\n  \n\n\n            \n            \n\n            \n              \n\n\n\u003cdiv data-analytics-module=\"{\n       \u0026#34;module_name\u0026#34;: \u0026#34;Article Tags\u0026#34;,\n       \u0026#34;section_header\u0026#34;: \u0026#34;How well do you know our I/O 2025 announcements?\u0026#34;\n     }\"\u003e\n  \u003cp\u003e\u003cspan\u003ePOSTED IN:\u003c/span\u003e\n  \u003c/p\u003e\n  \u003cnav data-analytics=\"{\n                \u0026#34;category\u0026#34;: \u0026#34;landing page lead\u0026#34;,\n                \u0026#34;action\u0026#34;: \u0026#34;article tag\u0026#34;\n              }\"\u003e\n    \u003cul\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/ai/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: AI\u0026#34;}\"\u003e\n\n\nAI\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/developers/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Developers\u0026#34;}\"\u003e\n\n\nDevelopers\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini\u0026#34;}\"\u003e\n\n\nGemini\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini App\u0026#34;}\"\u003e\n\n\nGemini App\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini Models\u0026#34;}\"\u003e\n\n\nGemini Models\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/gemini/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Gemini Features\u0026#34;}\"\u003e\n\n\nGemini Features\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/search/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Search\u0026#34;}\"\u003e\n\n\nSearch\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/shopping/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Shopping\u0026#34;}\"\u003e\n\n\nShopping\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/outreach-initiatives/education/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Learning \u0026amp; Education\u0026#34;}\"\u003e\n\n\nLearning \u0026amp; Education\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/android/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Android\u0026#34;}\"\u003e\n\n\nAndroid\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/google-labs/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Google Labs\u0026#34;}\"\u003e\n\n\nGoogle Labs\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/workspace/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Google Workspace\u0026#34;}\"\u003e\n\n\nGoogle Workspace\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/technology/research/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;topics: Research\u0026#34;}\"\u003e\n\n\nResearch\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n      \u003cli\u003e\n        \n        \n        \n\n\n  \u003ca href=\" https://blog.google/products/google-one/ \" data-ga4-analytics-landing-lead=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;landing_page_lead\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;AI\u0026#34;\n}\" data-analytics=\"{\u0026#34;label\u0026#34;: \u0026#34;product: Google One\u0026#34;}\"\u003e\n\n\nGoogle One\n\n\n  \u003c/a\u003e\n\n\n      \u003c/li\u003e\n    \n    \u003c/ul\u003e\n  \u003c/nav\u003e\n\u003c/div\u003e\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "65 min read",
  "publishedTime": "2025-05-22T16:00:00Z",
  "modifiedTime": null
}
