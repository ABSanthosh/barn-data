{
  "id": "d86fd641-5561-4b4c-99ec-22e6e233e87a",
  "title": "It's time to accept Nvidia's \"fake frames\" might be the new normal",
  "link": "https://www.xda-developers.com/nvidia-fake-frames-new-normal/",
  "description": "Nvidia's RTX 50 series shows that AI-generated frames are here to stay.",
  "author": "Tanveer Singh",
  "published": "Fri, 31 Jan 2025 01:00:11 GMT",
  "source": "https://www.xda-developers.com/feed/",
  "categories": [
    "GPU",
    "Nvidia GeForce RTX 50 Series",
    "Nvidia"
  ],
  "byline": "Tanveer Singh",
  "length": 18805,
  "excerpt": "Nvidia's RTX 50 series shows that AI-generated frames are here to stay.",
  "siteName": "XDA",
  "favicon": "https://www.xda-developers.com/public/build/images/favicon-240x240.43161a66.png",
  "text": "Over the last few weeks, I've been busy consuming all kinds of reactions and opinions about Nvidia's new RTX 50 series cards and their heavy reliance on Multi Frame Generation (MFG). From being uninterested to passionately opposed to these \"fake frames,\" gamers haven't shied away from making their feelings known. I think I'm finally ready to share my own opinion on the entire thing. On the one hand, I echo the sentiment of not wanting DLSS and Frame Generation as a crutch on mid-range and high-end graphics cards. On the other hand, however, I feel we're seeing the natural lifecycle of hardware advancements, with software playing a much bigger role starting this generation. AI-generated frames have real downsides, but like it or not, it looks like we're entering a new normal in GPU rendering. Related Here's when it's worth paying $2,000 for the RTX 5090 Yes, the RTX 5090's price might be bonkers for 99% of us, but for the right consumer, it makes an awful lot of sense Hardware brute-forcing had to have a shelf life AI-driven performance gains are the future It might come as a surprise to the uninitiated, but it's been a while since Nvidia CEO Jensen Huang declared that \"Moore's Law is dead.\" More an observation than a literal \"law,\" it shows that the number of transistors on a microchip, and, by extension, computing power, doubles every two years or so. While other players like Intel stand divided on this, it's becoming increasingly difficult to squeeze more performance solely by miniaturizing transistors. As companies encounter hardware limitations at the 2nm-3nm level, something has to give. For gen-on-gen performance uplifts to stay significant, chip manufacturing has to call for help from other sources. Nvidia's Blackwell GPUs are manufactured on essentially the same TSMC node as Ada Lovelace and rely on AI in the form of DLSS 4's Multi Frame Generation to overcome the limits of traditional rendering. And Nvidia isn't the only one doing this. Even AMD has proudly declared in its FSR 4 marketing material that AI and ML will be huge levers on its RDNA 4 GPUs set to launch in March. The industry has already transitioned to AI-powered upscaling and frame generation as the de facto standard, and a lot of gamers don't really care where they get their performance from. Related Nvidia and AMD are in their AI era, and gamers can do nothing but watch The AI wave has turned into a tsunami for gamers, as Nvidia and AMD turn all their energies to data center GPUs AI is simply the next software innovation We've always needed software to leverage hardware Gamers are up in arms about fake frames, and a lot of the criticisms are valid. A frame rendered by the game engine will not be equivalent to one rendered outside it, no matter what the FPS counter on your screen says. The responsiveness of the image will still be tied to the frames actually drawn without the use of AI. Most of the performance jump of the RTX 50 series that Nvidia is touting is generated by AI, and it's understandable that gamers aren't too happy about it. However, manufacturers needed something to overcome the limits of traditional rendering. The shader cores, tensor cores, and RT cores inside your GPU can do nothing by themselves. They've always needed excellent software to leverage their raw power, whether that's optimized game engines, robust drivers, or, more recently, upscaling. Frame generation (bolstered by AI) is simply the next step on that journey. Granted, frame generation isn't \"pure performance\" in the way upscaling is, but chances are it's only going to get better from here. Nvidia's MFG and other technologies soon to be unveiled by the competition will continue to refine the AI at the heart of modern graphics cards. As for the artifacts and responsiveness limitations inherent to the technology, you might not even notice it, given the right situation. Related 5 reasons Nvidia's RTX 50 series hype is misplaced Nvidia's RTX 50 series is out, but the company is still keeping the real details under wraps Frame generation latency isn't the end of the world MFG is worth it, but only in the right scenarios There's a fundamental difference between upscaling and frame generation when it comes to the actual gaming experience. Upscaling renders the game at a lower resolution and then uses AI to enhance the image to the target resolution with minimal loss in image quality and virtually no latency penalties. DLSS, FSR, and XeSS have gotten exceedingly efficient at upscaling over the last six years. Frame generation, on the other hand, is essentially a frame smoothing technique that predicts and adds frames between traditionally generated frames to result in a better framerate. The argument against this technique is that it only \"looks\" better without \"feeling\" better. Third-party benchmarks from multiple tech publications have conclusively shown that this is indeed true. Nvidia's MFG, especially in the 4x mode, might boost framerates and fluidity, but it doesn't provide the same responsiveness as some extra \"traditionally rendered\" frames would have done. Moreover, any artifacts intrinsic to 2x frame generation (as seen on the RTX 40 series) are now exacerbated by enabling 3x or 4x frame generation. Does this mean all is doom and gloom, and Nvidia's \"fake frames\" are worthless? It's a bit more complicated. MFG, in its current state, needs the base framerate to be above 60 FPS, at a minimum, and above 100 FPS, ideally, to provide a mostly decent experience. This means that your GPU should be powerful enough to output 60 or 100 frames before enabling any frame generation. This limits the use of MFG to certain games and GPUs, meaning it's far from the silver bullet Nvidia would like you to believe it is. Most people with 144Hz-180Hz 1080p or 1440p monitors might not find any use for 3x or 4x frame generation since one of these modern GPUs will output more than playable FPS with the help of upscaling alone in a lot of games. However, users with, say, 240Hz or even 360Hz monitors can make great use of the tech to saturate their monitor's refresh rate. Moreover, most people won't be able to notice any artifacts or sluggish performance as long as the base framerate provides the model with enough information (ideally 100 FPS without frame-gen). This does put a dent in Nvidia's RTX 50 series marketing, but those who are buying one of the latest GPUs can find real use for all the software trickery in the right scenarios. Related GeForce RTX 40 owners are getting a little treat in the wake of the RTX 50 reveals If you're sticking with the RTX 40 series for now, there's some good news: you're not being left out. Let the \"chips\" fall where they may As things stand, Nvidia's RTX 5090 provides only around a 30% boost in raw power over the RTX 4090. Presumably, the rest of the SKUs will deliver similarly disappointing results. The AI-generated \"fake frames,\" however, are here to stay. Relying on AI to boost performance is simply the next innovation to overcome the hardware limitations of semiconductors. AMD is heading in the same direction, and other manufacturers are sure to follow suit. Nvidia's MFG might be worth it only in situations when it makes little sense to use it, but for consumers who have high-refresh-rate monitors (240Hz at the minimum) and want to saturate their screens by boosting already high framerates, it makes sense to enable it. In such cases, you might not even notice the downsides that MFG is known for.",
  "image": "https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/dlss-4-vs-dlss-off-comparison.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article-body\" itemprop=\"articleBody\"\u003e\n\u003cp\u003eOver the last few weeks, I\u0026#39;ve been busy consuming all kinds of reactions and opinions about \u003ca href=\"https://www.xda-developers.com/nvidia-once-again-creates-the-most-powerful-gpu/\" target=\"_blank\"\u003eNvidia\u0026#39;s new RTX 50 series\u003c/a\u003e cards and their heavy reliance on Multi Frame Generation (MFG). From being uninterested to passionately opposed to these \u0026#34;fake frames,\u0026#34; gamers haven\u0026#39;t shied away from making their feelings known. I think I\u0026#39;m finally ready to share my own opinion on the entire thing.\u003c/p\u003e    \n\u003cp\u003eOn the one hand, I echo the sentiment of not \u003cem\u003ewanting \u003c/em\u003e\u003ca href=\"https://www.xda-developers.com/dlss/\" target=\"_blank\"\u003eDLSS\u003c/a\u003e and Frame Generation as a crutch on mid-range and high-end graphics cards. On the other hand, however, I feel we\u0026#39;re seeing the natural lifecycle of hardware advancements, with software playing a much bigger role starting this generation. AI-generated frames have real downsides, but like it or not, it looks like we\u0026#39;re entering a new normal in GPU rendering.\u003c/p\u003e            \n    \n                    \n                        \n                \n    \n                                        \n    \n        \n    \n        \n                \n        \n    \u003cdiv data-include-community-rating=\"false\" id=\"9d4e-47d1-9c66aeabcd94\" data-nosnippet=\"\"\u003e\n        \n        \n                        \t                \n\t\t\u003ca href=\"https://www.xda-developers.com/scenarios-when-paying-fortune-rtx-5090-fine/\"\u003e\n\t\n\t\u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"2713\" height=\"1527\" loading=\"lazy\" decoding=\"async\" alt=\"GeForce RTX 5090 visual\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/geforce-rtx-5090-visual.jpg\"/\u003e\n    \u003c/picture\u003e\n                \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\t\t\u003c/a\u003e\n\t\n\n        \n                    \u003cp\u003e\u003cspan data-field=\"label\"\u003eRelated\u003c/span\u003e\u003c/p\u003e\u003cdiv\u003e\n\n                \n                 \n                \t\n\u003ch5\u003e\n\t\t\t\t\t        \t\t\t\t\n\t\t\u003ca href=\"https://www.xda-developers.com/scenarios-when-paying-fortune-rtx-5090-fine/\" title=\"Here\u0026#39;s when it\u0026#39;s worth paying $2,000 for the RTX 5090\" target=\"_blank\"\u003e\n\t\t\tHere\u0026#39;s when it\u0026#39;s worth paying $2,000 for the RTX 5090\n\t\t\u003c/a\u003e\n\t\u003c/h5\u003e\n\n                                                    \n                \t\t\t\u003cp\u003eYes, the RTX 5090\u0026#39;s price might be bonkers for 99% of us, but for the right consumer, it makes an awful lot of sense\u003c/p\u003e\n\t\n\n                    \n\n\n                \n                \n                \n                \n\n                \n                \n                \n                \t\n\n\n                \n\n                \n                \n                \n            \u003c/div\u003e\n                \n        \n        \n        \n            \u003c/div\u003e\n\u003ch2 id=\"hardware-brute-forcing-had-to-have-a-shelf-life\"\u003e\n                        Hardware brute-forcing had to have a shelf life\n               \u003c/h2\u003e\u003ch3 id=\"ai-driven-performance-gains-are-the-future\"\u003e\n            AI-driven performance gains are the future\n    \u003c/h3\u003e\n\n\n\n\n    \n\n\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n    \n\n\u003cp\u003eIt might come as a surprise to the uninitiated, but it\u0026#39;s been a while since Nvidia CEO Jensen Huang declared that \u0026#34;Moore\u0026#39;s Law is dead.\u0026#34; More an observation than a literal \u0026#34;law,\u0026#34; it shows that the number of transistors on a microchip, and, by extension, computing power, doubles every two years or so. While other players like Intel stand divided on this, it\u0026#39;s becoming increasingly difficult to squeeze more performance solely by miniaturizing transistors.\u003c/p\u003e    \n\u003cp\u003eAs companies encounter hardware limitations at the 2nm-3nm level, something has to give. For gen-on-gen performance uplifts to stay significant, chip manufacturing has to call for help from other sources. Nvidia\u0026#39;s Blackwell GPUs are manufactured on essentially the same TSMC node as Ada Lovelace and rely on AI in the form of DLSS 4\u0026#39;s Multi Frame Generation to overcome the limits of traditional rendering.\u003c/p\u003e    \n\u003cp\u003eAnd Nvidia isn\u0026#39;t the only one doing this. Even AMD has proudly declared in its FSR 4 marketing material that AI and ML will be huge levers on its RDNA 4 GPUs set to launch in March. The industry has already transitioned to AI-powered upscaling and frame generation as the de facto standard, and a lot of gamers don\u0026#39;t really care where they get their performance from.\u003c/p\u003e            \n    \n                    \n                        \n                \n    \n                                        \n    \n        \n    \n        \n                \n        \n    \u003cdiv data-include-community-rating=\"false\" id=\"4449-4473-b7b38acfbe7a\" data-nosnippet=\"\"\u003e\n        \n        \n                        \t                \n\t\t\u003ca href=\"https://www.xda-developers.com/nvidia-amd-ai-era-gamers-can-only-watch/\"\u003e\n\t\n\t\u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"1920\" height=\"1283\" loading=\"lazy\" decoding=\"async\" alt=\"NVIDIA GeForce RTX 4090 AMD Radeon RX 7900 XTX\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2022/12/nvidia-geforce-rtx-4090-founders-edition-amd-radeon-rx-7900-xtx-reference.jpg\"/\u003e\n    \u003c/picture\u003e\n                \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\t\t\u003c/a\u003e\n\t\n\n        \n                    \u003cp\u003e\u003cspan data-field=\"label\"\u003eRelated\u003c/span\u003e\u003c/p\u003e\u003cdiv\u003e\n\n                \n                 \n                \t\n\u003ch5\u003e\n\t\t\t\t\t        \t\t\t\t\n\t\t\u003ca href=\"https://www.xda-developers.com/nvidia-amd-ai-era-gamers-can-only-watch/\" title=\"Nvidia and AMD are in their AI era, and gamers can do nothing but watch\" target=\"_blank\"\u003e\n\t\t\tNvidia and AMD are in their AI era, and gamers can do nothing but watch\n\t\t\u003c/a\u003e\n\t\u003c/h5\u003e\n\n                                                    \n                \t\t\t\u003cp\u003eThe AI wave has turned into a tsunami for gamers, as Nvidia and AMD turn all their energies to data center GPUs\u003c/p\u003e\n\t\n\n                    \n\n\n                \n                \n                \n                \n\n                \n                \n                \n                \t\n\n\n                \n\n                \n                \n                \n            \u003c/div\u003e\n                \n        \n        \n        \n            \u003c/div\u003e\n\u003ch2 id=\"ai-is-simply-the-next-software-innovation\"\u003e\n                        AI is simply the next software innovation\n               \u003c/h2\u003e\u003ch3 id=\"we-39-ve-always-needed-software-to-leverage-hardware\"\u003e\n            We\u0026#39;ve always needed software to leverage hardware\n    \u003c/h3\u003e\n\n\n\n\n    \n\n\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n    \n\n\u003cp\u003eGamers are up in arms about fake frames, and a lot of the criticisms are valid. A frame rendered by the game engine will not be equivalent to one rendered outside it, no matter what the FPS counter on your screen says. The responsiveness of the image will still be tied to the frames actually drawn without the use of AI. Most of the performance jump of the RTX 50 series that Nvidia is touting is generated by AI, and it\u0026#39;s understandable that gamers aren\u0026#39;t too happy about it.\u003c/p\u003e    \n\u003cp\u003eHowever, manufacturers needed something to overcome the limits of traditional rendering. The shader cores, tensor cores, and RT cores inside your GPU can do nothing by themselves. They\u0026#39;ve always needed excellent software to leverage their raw power, whether that\u0026#39;s optimized game engines, robust drivers, or, more recently, upscaling. Frame generation (bolstered by AI) is simply the next step on that journey.\u003c/p\u003e    \n\u003cp\u003eGranted, frame generation isn\u0026#39;t \u0026#34;pure performance\u0026#34; in the way upscaling is, but chances are it\u0026#39;s only going to get better from here. Nvidia\u0026#39;s MFG and other technologies soon to be unveiled by the competition will continue to refine the AI at the heart of modern graphics cards. As for the artifacts and responsiveness limitations inherent to the technology, you might not even notice it, given the right situation.\u003c/p\u003e            \n    \n                    \n                        \n                \n    \n                                        \n    \n        \n    \n        \n                \n        \n    \u003cdiv data-include-community-rating=\"false\" id=\"009b-4f16-b61154f6af07\" data-nosnippet=\"\"\u003e\n        \n        \n                        \t                \n\t\t\u003ca href=\"https://www.xda-developers.com/nvidia-rtx-5000-not-what-you-think/\"\u003e\n\t\n\t\u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"3840\" height=\"2160\" loading=\"lazy\" decoding=\"async\" alt=\"Render of the RTX 5070 from Nvidia\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/rtx-5070-key-visual.jpg\"/\u003e\n    \u003c/picture\u003e\n                \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\t\t\u003c/a\u003e\n\t\n\n        \n                    \u003cp\u003e\u003cspan data-field=\"label\"\u003eRelated\u003c/span\u003e\u003c/p\u003e\u003cdiv\u003e\n\n                \n                 \n                \t\n\u003ch5\u003e\n\t\t\t\t\t        \t\t\t\t\n\t\t\u003ca href=\"https://www.xda-developers.com/nvidia-rtx-5000-not-what-you-think/\" title=\"5 reasons Nvidia\u0026#39;s RTX 50 series hype is misplaced\" target=\"_blank\"\u003e\n\t\t\t5 reasons Nvidia\u0026#39;s RTX 50 series hype is misplaced\n\t\t\u003c/a\u003e\n\t\u003c/h5\u003e\n\n                                                    \n                \t\t\t\u003cp\u003eNvidia\u0026#39;s RTX 50 series is out, but the company is still keeping the real details under wraps\u003c/p\u003e\n\t\n\n                    \n\n\n                \n                \n                \n                \n\n                \n                \n                \n                \t\n\n\n                \n\n                \n                \n                \n            \u003c/div\u003e\n                \n        \n        \n        \n            \u003c/div\u003e\n\u003ch2 id=\"frame-generation-latency-isn-39-t-the-end-of-the-world\"\u003e\n                        Frame generation latency isn\u0026#39;t the end of the world\n               \u003c/h2\u003e\u003ch3 id=\"mfg-is-worth-it-but-only-in-the-right-scenarios\"\u003e\n            MFG is worth it, but only in the right scenarios\n    \u003c/h3\u003e\n\n    \n    \n\n\u003cp\u003eThere\u0026#39;s a fundamental difference between upscaling and frame generation when it comes to the actual gaming experience. Upscaling renders the game at a lower resolution and then uses AI to enhance the image to the target resolution with minimal loss in image quality and virtually no latency penalties. DLSS, FSR, and \u003ca href=\"https://www.xda-developers.com/intel-xess/\" target=\"_blank\"\u003eXeSS\u003c/a\u003e have gotten exceedingly efficient at upscaling over the last six years.\u003c/p\u003e    \n\u003cp\u003eFrame generation, on the other hand, is essentially a frame smoothing technique that predicts and adds frames between traditionally generated frames to result in a better framerate. The argument against this technique is that it only \u0026#34;looks\u0026#34; better without \u0026#34;feeling\u0026#34; better. Third-party benchmarks from multiple tech publications have conclusively shown that this is indeed true.\u003c/p\u003e    \n\u003cp\u003eNvidia\u0026#39;s MFG, especially in the 4x mode, might boost framerates and fluidity, but it doesn\u0026#39;t provide the same responsiveness as some extra \u0026#34;traditionally rendered\u0026#34; frames would have done. Moreover, any artifacts intrinsic to 2x frame generation (as seen on the RTX 40 series) are now exacerbated by enabling 3x or 4x frame generation. Does this mean all is doom and gloom, and Nvidia\u0026#39;s \u0026#34;fake frames\u0026#34; are worthless? It\u0026#39;s a bit more complicated.\u003c/p\u003e    \n\u003cp\u003eMFG, in its current state, needs the base framerate to be above 60 FPS, at a minimum, and above 100 FPS, ideally, to provide a mostly decent experience. This means that your GPU should be powerful enough to output 60 or 100 frames before enabling any frame generation. This limits the use of MFG to certain games and GPUs, meaning it\u0026#39;s far from the silver bullet Nvidia would like you to believe it is. Most people with 144Hz-180Hz 1080p or 1440p monitors might not find any use for 3x or 4x frame generation since one of these modern GPUs will output more than playable FPS with the help of upscaling alone in a lot of games.\u003c/p\u003e    \n\u003cp\u003eHowever, users with, say, 240Hz or even 360Hz monitors can make great use of the tech to saturate their monitor\u0026#39;s refresh rate. Moreover, most people won\u0026#39;t be able to notice any artifacts or sluggish performance as long as the base framerate provides the model with enough information (ideally 100 FPS without frame-gen). This does put a dent in Nvidia\u0026#39;s RTX 50 series marketing, but those who are buying one of the latest GPUs can find real use for all the software trickery in the right scenarios.\u003c/p\u003e            \n    \n                    \n                        \n                \n    \n                                        \n    \n        \n    \n        \n                \n        \n    \u003cdiv data-include-community-rating=\"false\" id=\"ca19-4969-942e67eaef74\" data-nosnippet=\"\"\u003e\n        \n        \n                        \t                \n\t\t\u003ca href=\"https://www.xda-developers.com/geforce-rtx-40-owners-little-treat/\"\u003e\n\t\n\t\u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"2160\" height=\"1214\" loading=\"lazy\" decoding=\"async\" alt=\"Close up shot of Nvidia GeForce RTX 4060 GPU inside Lenovo Legion Tower 5i Gen 8 (2024)\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/08/lenovo-legion-tower-5i-gen-8-2024-nvidia-4060.jpg\"/\u003e\n    \u003c/picture\u003e\n                \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\t\t\u003c/a\u003e\n\t\n\n        \n                    \u003cp\u003e\u003cspan data-field=\"label\"\u003eRelated\u003c/span\u003e\u003c/p\u003e\u003cdiv\u003e\n\n                \n                 \n                \t\n\u003ch5\u003e\n\t\t\t\t\t        \t\t\t\t\n\t\t\u003ca href=\"https://www.xda-developers.com/geforce-rtx-40-owners-little-treat/\" title=\"GeForce RTX 40 owners are getting a little treat in the wake of the RTX 50 reveals\" target=\"_blank\"\u003e\n\t\t\tGeForce RTX 40 owners are getting a little treat in the wake of the RTX 50 reveals\n\t\t\u003c/a\u003e\n\t\u003c/h5\u003e\n\n                                                    \n                \t\t\t\u003cp\u003eIf you\u0026#39;re sticking with the RTX 40 series for now, there\u0026#39;s some good news: you\u0026#39;re not being left out.\u003c/p\u003e\n\t\n\n                    \n\n\n                \n                \n                \n                \n\n                \n                \n                \n                \t\n\n\n                \n\n                \n                \n                \n            \u003c/div\u003e\n                \n        \n        \n        \n            \u003c/div\u003e\n\u003ch3 id=\"let-the-quot-chips-quot-fall-where-they-may\"\u003e\n            Let the \u0026#34;chips\u0026#34; fall where they may\n    \u003c/h3\u003e\n\n\u003cp\u003eAs things stand, Nvidia\u0026#39;s RTX 5090 provides only around a 30% boost in raw power over the RTX 4090. Presumably, the rest of the SKUs will deliver similarly disappointing results. The AI-generated \u0026#34;fake frames,\u0026#34; however, are here to stay. Relying on AI to boost performance is simply the next innovation to overcome the hardware limitations of semiconductors. AMD is heading in the same direction, and other manufacturers are sure to follow suit.\u003c/p\u003e    \n\u003cp\u003eNvidia\u0026#39;s MFG might be worth it only in situations when it makes little sense to use it, but for consumers who have high-refresh-rate monitors (240Hz at the minimum) and want to saturate their screens by boosting already high framerates, it makes sense to enable it. In such cases, you might not even notice the downsides that MFG is known for.\u003c/p\u003e    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "20 min read",
  "publishedTime": "2025-01-31T01:00:11Z",
  "modifiedTime": "2025-01-31T01:00:11Z"
}
