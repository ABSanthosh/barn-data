{
  "id": "90110900-2601-4d65-a9d1-0af363b04673",
  "title": "Mistral AI Releases Pixtral Large: a Multimodal Model for Advanced Image and Text Analysis",
  "link": "https://www.infoq.com/news/2024/12/pixtral-large-mistral-ai/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Mistral AI released Pixtral Large, a 124-billion-parameter multimodal model designed for advanced image and text processing with a 1-billion-parameter vision encoder. Built on Mistral Large 2, it achieves leading performance on benchmarks like MathVista and DocVQA, excelling in tasks that require reasoning across text and visual data. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Wed, 04 Dec 2024 19:55:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Artificial Intelligence",
    "Machine Learning",
    "Open Source",
    "Hugging Face",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 3065,
  "excerpt": "Mistral AI released Pixtral Large, a 124-billion-parameter multimodal model designed for advanced image and text processing with a 1-billion-parameter vision encoder. Built on Mistral Large 2, it achi",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20241203101948/apple-touch-icon.png",
  "text": "Mistral AI released Pixtral Large, a 124-billion-parameter multimodal model designed for advanced image and text processing with a 1-billion-parameter vision encoder. Built on Mistral Large 2, it achieves leading performance on benchmarks like MathVista and DocVQA, excelling in tasks that require reasoning across text and visual data. Pixtral Large has demonstrated significant performance improvements on multiple benchmarks. It achieved 69.4% on MathVista, a dataset assessing mathematical reasoning using visual data, surpassing all previous models. In complex document and chart comprehension evaluations, the model outperformed GPT-4o and Gemini-1.5 Pro on DocVQA and ChartQA, solidifying its capabilities in structured visual reasoning tasks. Additionally, on MM-MT-Bench, which reflects real-world use cases for multimodal models, Pixtral Large outperformed Claude-3.5 Sonnet, Gemini-1.5 Pro, and GPT-4o. Source: Mistral AI Blog The release has garnered positive reactions from the AI community. Nagesh Nama, a CEO at xLM, shared:  The release of Mistral AI's Pixtral Large is a good piece of news for the AI community. Open-sourcing such a massive multimodal model will undoubtedly encourage innovation and collaboration among researchers and smaller companies. The fact that it can handle both text and images together and is easy to fine-tune for specific needs is a significant advantage. It will be exciting to see how this model is utilized and what breakthroughs it will bring to the field of AI. Kudos to Mistral AI for taking this bold step towards open-source AI. Naveed Sarwar, a CEO at TechloSet Solutions, added: By making it open-source, Mistral is empowering researchers, start-ups, and innovators to fine-tune and tailor the model to their needs, unlocking the massive potential for new applications. To evaluate Pixtral Large’s architecture, it combines Mistral Large 2’s text backbone with a vision encoder and extended multimodal capabilities. This integration ensures high performance on tasks requiring advanced reasoning across visual and textual domains while preserving the robustness of text-only processing. For instance, the vision encoder works alongside the text model, enabling seamless multimodal interactions. Pixtral Large supports document interpretation, chart analysis, and natural image understanding, providing tools for sectors requiring advanced image-text integration. While Pixtral Large is not designed for Optical Character Recognition (OCR), Mistral AI has indicated that enhancing OCR capabilities is a priority for future developments. Pixtral Large is available under the Mistral Research License (MRL) for academic and non-commercial use, and a separate commercial license is offered for enterprise deployment. Users can access the model via the pixtral-large-latest API or download it for self-hosted implementations on HuggingFace. About the Author Robert Krzaczyński",
  "image": "https://res.infoq.com/news/2024/12/pixtral-large-mistral-ai/en/headerimage/generatedHeaderImage-1733341366361.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://mistral.ai/news/pixtral-large/\"\u003eMistral AI released Pixtral Large\u003c/a\u003e, a 124-billion-parameter multimodal model designed for advanced image and text processing with a 1-billion-parameter vision encoder. Built on Mistral Large 2, it achieves leading performance on benchmarks like MathVista and DocVQA, excelling in tasks that require reasoning across text and visual data.\u003c/p\u003e\n\n\u003cp\u003ePixtral Large has demonstrated significant performance improvements on multiple benchmarks. It achieved 69.4% on MathVista, a dataset assessing mathematical reasoning using visual data, surpassing all previous models. In complex document and chart comprehension evaluations, the model outperformed GPT-4o and Gemini-1.5 Pro on DocVQA and ChartQA, solidifying its capabilities in structured visual reasoning tasks. Additionally, on MM-MT-Bench, which reflects real-world use cases for multimodal models, Pixtral Large outperformed Claude-3.5 Sonnet, Gemini-1.5 Pro, and GPT-4o.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2024/12/pixtral-large-mistral-ai/en/resources/1Screenshot 2024-12-04 203511-1733341365518.png\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2024/12/pixtral-large-mistral-ai/en/resources/1Screenshot 2024-12-04 203511-1733341365518.png\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eSource: Mistral AI Blog\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eThe release has garnered positive reactions from the AI community. Nagesh Nama, a CEO at xLM, \u003ca href=\"https://www.linkedin.com/feed/update/urn:li:activity:7264593802068156417?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7264593802068156417%2C7264631170217250818%29\u0026amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287264631170217250818%2Curn%3Ali%3Aactivity%3A7264593802068156417%29\"\u003eshared\u003c/a\u003e: \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe release of Mistral AI\u0026#39;s Pixtral Large is a good piece of news for the AI community. Open-sourcing such a massive multimodal model will undoubtedly encourage innovation and collaboration among researchers and smaller companies. The fact that it can handle both text and images together and is easy to fine-tune for specific needs is a significant advantage. It will be exciting to see how this model is utilized and what breakthroughs it will bring to the field of AI. Kudos to Mistral AI for taking this bold step towards open-source AI.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eNaveed Sarwar, a CEO at TechloSet Solutions, \u003ca href=\"https://www.linkedin.com/feed/update/urn:li:activity:7264593802068156417?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7264593802068156417%2C7264601023606902784%29\u0026amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287264601023606902784%2Curn%3Ali%3Aactivity%3A7264593802068156417%29\"\u003eadded\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eBy making it open-source, Mistral is empowering researchers, start-ups, and innovators to fine-tune and tailor the model to their needs, unlocking the massive potential for new applications.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eTo evaluate Pixtral Large’s architecture, it combines Mistral Large 2’s text backbone with a vision encoder and extended multimodal capabilities. This integration ensures high performance on tasks requiring advanced reasoning across visual and textual domains while preserving the robustness of text-only processing. For instance, the vision encoder works alongside the text model, enabling seamless multimodal interactions.\u003c/p\u003e\n\n\u003cp\u003ePixtral Large supports document interpretation, chart analysis, and natural image understanding, providing tools for sectors requiring advanced image-text integration. While Pixtral Large is not designed for Optical Character Recognition (OCR), Mistral AI has indicated that enhancing OCR capabilities is a priority for future developments.\u003c/p\u003e\n\n\u003cp\u003ePixtral Large is available under the Mistral Research License (MRL) for academic and non-commercial use, and a separate \u003ca href=\"https://mistral.ai/terms/\"\u003ecommercial license\u003c/a\u003e is offered for enterprise deployment. Users can access the model via the pixtral-large-latest \u003ca href=\"https://docs.mistral.ai/api/\"\u003eAPI\u003c/a\u003e or download it for self-hosted implementations on \u003ca href=\"https://huggingface.co/mistralai/Pixtral-Large-Instruct-2411\"\u003eHuggingFace\u003c/a\u003e.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2024-12-04T00:00:00Z",
  "modifiedTime": null
}
