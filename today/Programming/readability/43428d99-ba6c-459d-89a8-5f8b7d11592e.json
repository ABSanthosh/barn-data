{
  "id": "43428d99-ba6c-459d-89a8-5f8b7d11592e",
  "title": "How to waste half a day by not reading RFC 1034",
  "link": "https://signalvnoise.com/svn3/how-to-waste-half-a-day-by-not-reading-rfc-1034/",
  "description": "HEY uses a branch deploy system that I‚Äôve written about here on SvN and talked about frequently on Twitter. Plenty of other companies have implemented their own version of branch deploys (typically under a different name), but this was my own implementation, so I‚Äôm proud of it. First, a primer on how it works: Developer‚Ä¶ keep reading",
  "author": "Blake Stoddard",
  "published": "Fri, 30 Oct 2020 20:59:44 +0000",
  "source": "https://signalvnoise.com/posts.rss",
  "categories": [
    "Tech"
  ],
  "byline": "",
  "length": 6678,
  "excerpt": "HEY uses a branch deploy system that I‚Äôve written about here on SvN and talked about frequently on Twitter. Plenty of other companies have implemented their own version of branch deploys (typ‚Ä¶",
  "siteName": "Signal v. Noise",
  "favicon": "",
  "text": "HEY uses a branch deploy system that I‚Äôve written about here on SvN and talked about frequently on Twitter. Plenty of other companies have implemented their own version of branch deploys (typically under a different name), but this was my own implementation, so I‚Äôm proud of it. First, a primer on how it works: Developer makes a code change in a git branch and pushes it to GitHub.An automated build pipeline run is kicked off by a GitHub webhook. It builds some Docker images and kicks off another build that handles the deploy itself.That deploy build, well, it deploys ‚Äî to AWS EKS, Amazon‚Äôs managed Kubernetes offering, via a Helm chart that contains all of the YAML specifications for deployments, services, ingresses, etc.alb-ingress-controller (now aws-load-balancer-controller) creates an ALB for the branch.external-dns creates a DNS record pointing to the new ALB.Dev can access their branch from their browser using a special branch-specific URLThis process takes 5-10 minutes for a brand new branch from push to being accessible (typically). Our current setup works well, but it‚Äôs got two big faults: Each branch needs its own ALB (that‚Äôs what is generated by the Ingress resource).DNS is DNS is DNS and sometimes it takes a while to propagate and requires that we manage a ton of records (3-5 for each branch). These faults are intertwined: if I didn‚Äôt have to give each branch it‚Äôs own ALB, I could use a wildcard record and point every subdomain on our branch-deploy-specific-domain to a single ALB and let the ALB route requests to where they belong via host headers. That means I can save money by not needing all of those ALBs and we can reduce the DNS-being-DNS time to zero (and the complexity of external-dns annotations and conditionals spread throughout our YAML). (While waiting a few minutes for DNS to propagate and resolve doesn‚Äôt sound like a big deal, we shoot ourselves in the foot with the way our deploy flow works by checking that the revision has actually been deployed by visiting an internal path on the new hostname as soon as the deploy build finishes, causing us to attempt to resolve DNS prior to the record being created and your local machine caching that NXDOMAIN response until the TTL expires.) Before now, this was doable but required some extra effort that made it not worthwhile ‚Äî it would likely need to be done through a custom controller that would take care of adding your services to a single Ingress object via custom annotations. This path was Fine‚Ñ¢Ô∏è (I even made a proof-of-concept controller that did just that), but it meant there was some additional piece of tooling that we now had to manage, along with needing to create and manage that primary Ingress object. Enter a new version of alb-ingress-controller (and it‚Äôs new name: aws-load-balancer-controller) that includes a new IngressGroup feature that does exactly what I need. It adds a new set of annotations that I can add to my Ingresses which will cause all of my Ingress resources to be routing rules on a single ALB rather than individual ALBs. ‚ÄúGreat!‚Äù I think to myself on the morning I start the project of testing the new revision and figuring out how I want to implement this (using it as an opportunity to clean up a bunch of technical debt, too). I get everything in place ‚Äî I‚Äôve updated aws-load-balancer-controller in my test cluster, deleted all of the branch-specific ALIAS records that existed for the old ALBs, told external-dns not to manage Ingress resources anymore, and setup a wildcard ALIAS pointing to my new single ALB that all of these branches should be sharing. It doesn‚Äôt work. $ curl --header \"Host: alb-v2.branch-deploy.com\" https://alb-v2.branch-deploy.com curl: (6) Could not resolve host: alb-v2.branch-deploy.com But if I call the ALB directly with the proper host header, it does: $ curl --header \"Host: alb-v2.branch-deploy.com\" --insecure https://internal-k8s-swiper-no-swiping.us-east-1.elb.amazonaws.com \u003chtml\u003e\u003cbody\u003eYou are being \u003ca href=\"https://alb-v2.branch-deploy.com/sign_in\"\u003eredirected\u003c/a\u003e.\u003c/body\u003e\u003c/html\u003e (‚ïØ¬∞‚ñ°¬∞)‚ïØÔ∏µ ‚îª‚îÅ‚îª I have no clue what is going on. I can clearly see that the record exists in Route53, but I can‚Äôt resolve it locally, nor can some DNS testing services (‚ù§Ô∏è MX Toolbox). Maybe it‚Äôs the ‚ÄúEvaluate Target Health‚Äù option on the wildcard record? Disabled that and tried again, still nothing. I‚Äôm thoroughly stumped and start browsing the Route53 documentation and find this line and think it‚Äôs the answer to my problem: If you create a record named *.example.com and there‚Äôs no example.com record, Route¬†53 responds to DNS queries for example.com with¬†NXDOMAIN¬†(non-existent domain). So off I go to create a record for branch-deploy.com to see if maybe that‚Äôs it. But that still doesn‚Äôt do it. This is when I re-read that line and realize that it doesn‚Äôt apply to me anyway ‚Äî I had read it incorrectly the first time, I‚Äôm not trying to resolve branch-deploy.com. (My initial reading was that *.branch-deploy.com wouldn‚Äôt resolve without a record for branch-deploy.com existing). Welp, time to dig into the RFC, there‚Äôs bound to be some obscure thing I‚Äôm missing here. Correct that assumption was. Wildcard RRs do not apply:‚Äì When the query is in another zone. That is, delegation cancels the wildcard defaults.‚Äì When the query name or a name between the wildcard domain and the query name is know to exist. For example, if a wildcard RR has an owner name of ‚Äú*.X‚Äù, and the zone also contains RRs attached to B.X, the wildcards would apply to queries for name Z.X (presuming there is no explicit information for Z.X), but not to B.X, A.B.X, or X. Hmm, that second bullet point sounds like a lead. Let me go back to my Route53 zone and look. ‚î¨‚îÄ‚î¨ „Éé( „Çú-„Çú„Éé) Ah, I see it. One feature of our branch deploy system is that you can also have a functioning mail pipeline that is specific to your branch. To use that feature, you email [email¬†protected]. To make that work, each branch gets an MX record on your-branch.branch-deploy.com. Here-in lies the problem. While you can have a wildcard record for branch-deploy.com, if an MX record (or other any record really) exists for a given subdomain and you try to visit your-branch.branch-deploy.com, that A/AAAA/CNAME resolution will not climb the tree to the wildcard. üôÉ This is likely a well-known quirk (is it even a quirk or is it common sense? it surely wasn‚Äôt common sense for me), but I blew half a day banging my head against my desk trying to figure out why this wasn‚Äôt working because I made a bad assumption and I really needed to vent about it. Thank you for indulging me.",
  "image": "/assets/svn3/images/2019/01/cropped-svn-icon.gif",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle id=\"post-13001\" class=\"post-13001 post type-post status-publish format-standard hentry category-tech\"\u003e\n\n\t\n\n\t\u003cdiv\u003e\n\n\u003cp\u003eHEY uses a branch deploy system that I‚Äôve \u003ca href=\"https://signalvnoise.com/svn3/seamless-branch-deploys-with-kubernetes/\"\u003ewritten about here on SvN\u003c/a\u003e and talked about frequently \u003ca href=\"https://twitter.com/t3rabytes\"\u003eon Twitter\u003c/a\u003e. Plenty of other companies have implemented their own version of branch deploys (typically under a different name), but this was my own implementation, so I‚Äôm proud of it. First, a primer on how it works:\u003c/p\u003e\n\n\n\n\u003cul\u003e\u003cli\u003eDeveloper makes a code change in a \u003ca href=\"https://git-scm.com\"\u003egit\u003c/a\u003e branch and pushes it to \u003ca href=\"https://github.com\"\u003eGitHub\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eAn automated build pipeline run is kicked off by a GitHub webhook. It builds some Docker images and kicks off another build that handles the deploy itself.\u003c/li\u003e\u003cli\u003eThat deploy build, well, it deploys ‚Äî to \u003ca href=\"https://aws.amazon.com/eks/\"\u003eAWS EKS\u003c/a\u003e, Amazon‚Äôs managed Kubernetes offering, via a Helm chart that contains all of the YAML specifications for deployments, services, ingresses, etc.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/aws-load-balancer-controller\"\u003ealb-ingress-controller\u003c/a\u003e (now aws-load-balancer-controller) creates an \u003ca href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html\"\u003eALB\u003c/a\u003e for the branch.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://github.com/kubernetes-sigs/external-dns\"\u003eexternal-dns\u003c/a\u003e creates a DNS record pointing to the new ALB.\u003c/li\u003e\u003cli\u003eDev can access their branch from their browser using a special branch-specific URL\u003cp\u003e\u003csup\u003eThis process takes 5-10 minutes for a brand new branch from push to being accessible (typically).\u003c/sup\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\n\n\n\n\u003cp\u003eOur current setup works well, but it‚Äôs got two big faults:\u003c/p\u003e\n\n\n\n\u003cul\u003e\u003cli\u003eEach branch needs its own ALB (that‚Äôs what is generated by the Ingress resource).\u003c/li\u003e\u003cli\u003eDNS is DNS is DNS and sometimes it takes a while to propagate and requires that we manage a ton of records (3-5 for each branch).\u003c/li\u003e\u003c/ul\u003e\n\n\n\n\u003cp\u003eThese faults are intertwined: if I didn‚Äôt have to give each branch it‚Äôs own ALB, I could use a wildcard record and point every subdomain on our branch-deploy-specific-domain to a single ALB and let the ALB route requests to where they belong via host headers. That means I can save money by not needing all of those ALBs and we can reduce the DNS-being-DNS time to zero (and the complexity of external-dns annotations and conditionals spread throughout our YAML).\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e(While waiting a few minutes for DNS to propagate and resolve doesn‚Äôt sound like a big deal, we shoot ourselves in the foot with the way our deploy flow works by checking that the revision has actually been deployed by visiting an internal path on the new hostname as soon as the deploy build finishes, causing us to attempt to resolve DNS prior to the record being created and your local machine caching that NXDOMAIN response until the TTL expires.)\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eBefore now, this was doable but required some extra effort that made it not worthwhile ‚Äî it would likely need to be done through a custom controller that would take care of adding your services to a single Ingress object via custom annotations. This path was Fine‚Ñ¢Ô∏è (I even made a proof-of-concept controller that did just that), but it meant there was some additional piece of tooling that we now had to manage, along with needing to create and manage that primary Ingress object.\u003c/p\u003e\n\n\n\n\u003cp\u003eEnter \u003ca href=\"https://aws.amazon.com/about-aws/whats-new/2020/10/introducing-aws-load-balancer-controller/\"\u003ea new version of alb-ingress-controller (and it‚Äôs new name: aws-load-balancer-controller)\u003c/a\u003e that includes a new \u003ca href=\"https://github.com/kubernetes-sigs/aws-load-balancer-controller/issues/914\"\u003eIngressGroup\u003c/a\u003e feature that does \u003cem\u003eexactly\u003c/em\u003e what I need. It adds a new set of annotations that I can add to my Ingresses which will cause all of my Ingress resources to be routing rules on a single ALB rather than individual ALBs.\u003c/p\u003e\n\n\n\n\u003cp\u003e‚ÄúGreat!‚Äù I think to myself on the morning I start the project of testing the new revision and figuring out how I want to implement this (using it as an opportunity to clean up a bunch of technical debt, too).\u003c/p\u003e\n\n\n\n\u003cp\u003eI get everything in place ‚Äî I‚Äôve updated aws-load-balancer-controller in my test cluster, deleted all of the branch-specific ALIAS records that existed for the old ALBs, told external-dns not to manage Ingress resources anymore, and setup a wildcard ALIAS pointing to my new single ALB that all of these branches should be sharing.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt doesn‚Äôt work.\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e$ curl --header \u0026#34;Host: alb-v2.branch-deploy.com\u0026#34; https://alb-v2.branch-deploy.com\ncurl: (6) Could not resolve host: alb-v2.branch-deploy.com\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eBut if I call the ALB directly with the proper host header, it does:\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e$ curl --header \u0026#34;Host: alb-v2.branch-deploy.com\u0026#34; --insecure https://internal-k8s-swiper-no-swiping.us-east-1.elb.amazonaws.com\n\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;You are being \u0026lt;a href=\u0026#34;https://alb-v2.branch-deploy.com/sign_in\u0026#34;\u0026gt;redirected\u0026lt;/a\u0026gt;.\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003e(‚ïØ¬∞‚ñ°¬∞)‚ïØÔ∏µ ‚îª‚îÅ‚îª\u003c/p\u003e\n\n\n\n\u003cp\u003eI have no clue what is going on. I can clearly see that the record exists in Route53, but I can‚Äôt resolve it locally, nor can some DNS testing services (‚ù§Ô∏è MX Toolbox).\u003c/p\u003e\n\n\n\n\u003cp\u003eMaybe it‚Äôs the ‚ÄúEvaluate Target Health‚Äù option on the wildcard record? Disabled that and tried again, still nothing.\u003c/p\u003e\n\n\n\n\u003cp\u003eI‚Äôm thoroughly stumped and start browsing the \u003ca href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/DomainNameFormat.html\"\u003eRoute53 documentation\u003c/a\u003e and find this line and think it‚Äôs the answer to my problem:\u003c/p\u003e\n\n\n\n\u003cblockquote\u003e\u003cp\u003eIf you create a record named *.example.com and there‚Äôs no example.com record, Route¬†53 responds to DNS queries for example.com with¬†\u003ccode\u003eNXDOMAIN\u003c/code\u003e¬†(non-existent domain).\u003c/p\u003e\u003c/blockquote\u003e\n\n\n\n\u003cp\u003eSo off I go to create a record for branch-deploy.com to see if maybe that‚Äôs it. But that still doesn‚Äôt do it. This is when I re-read that line and realize that it doesn‚Äôt apply to me anyway ‚Äî I had read it incorrectly the first time, I‚Äôm not trying to resolve branch-deploy.com. (My initial reading was that *.branch-deploy.com wouldn‚Äôt resolve without a record for branch-deploy.com existing).\u003c/p\u003e\n\n\n\n\u003cp\u003eWelp, time to dig into \u003ca href=\"https://tools.ietf.org/html/rfc1034\"\u003ethe RFC\u003c/a\u003e, there‚Äôs bound to be some obscure thing I‚Äôm missing here. Correct that assumption was.\u003c/p\u003e\n\n\n\n\u003cblockquote\u003e\u003cp\u003eWildcard RRs do not apply:\u003c/p\u003e\u003cp\u003e‚Äì When the query is in another zone. That is, delegation cancels the wildcard defaults.\u003c/p\u003e\u003cp\u003e‚Äì When the query name or a name between the wildcard domain and the query name is know to exist. For example, if a wildcard RR has an owner name of ‚Äú*.X‚Äù, and the zone also contains RRs attached to B.X, the wildcards would apply to queries for name Z.X (presuming there is no explicit information for Z.X), but not to B.X, A.B.X, or X.\u003c/p\u003e\u003c/blockquote\u003e\n\n\n\n\u003cp\u003eHmm, that second bullet point sounds like a lead. Let me go back to my Route53 zone and look.\u003c/p\u003e\n\n\n\n\u003cp\u003e‚î¨‚îÄ‚î¨ „Éé( „Çú-„Çú„Éé)\u003c/p\u003e\n\n\n\n\u003cp\u003eAh, I see it.\u003c/p\u003e\n\n\n\n\u003cp\u003eOne feature of our branch deploy system is that you can also have a functioning mail pipeline that is specific to your branch. To use that feature, you email \u003ccode\u003e\u003ca href=\"https://signalvnoise.com/cdn-cgi/l/email-protection\" data-cfemail=\"5d2432282f2e38313b1d2432282f703f2f3c333e35733f2f3c333e357039382d313224733e3230\"\u003e[email¬†protected]\u003c/a\u003e\u003c/code\u003e. To make that work, each branch gets an MX record on your-branch.branch-deploy.com.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eHere-in lies the problem. While you can have a wildcard record for branch-deploy.com, if an MX record (or other any record really) exists for a given subdomain and you try to visit your-branch.branch-deploy.com, that A/AAAA/CNAME resolution will not climb the tree to the wildcard.\u003c/strong\u003e üôÉ\u003c/p\u003e\n\n\n\n\u003cp\u003eThis is likely a well-known quirk (is it even a quirk or is it common sense? it surely wasn‚Äôt common sense for me), but I blew half a day banging my head against my desk trying to figure out why this wasn‚Äôt working because I made a bad assumption and I really needed to vent about it. Thank you for indulging me.\u003c/p\u003e\n\t\u003c/div\u003e\n\n\u003c/article\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2020-10-30T20:59:44Z",
  "modifiedTime": "2020-10-30T21:59:21Z"
}
