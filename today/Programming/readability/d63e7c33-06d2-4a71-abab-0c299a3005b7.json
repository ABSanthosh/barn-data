{
  "id": "d63e7c33-06d2-4a71-abab-0c299a3005b7",
  "title": "AI Code Completion: Less Is More",
  "link": "https://blog.jetbrains.com/ai/2025/03/ai-code-completion-less-is-more/",
  "description": "If you’ve been following our journey, you might’ve read our recent blog post on the Complete the Un-Completable: The State of AI Completion in JetBrains IDEs. From that post, you might remember this cool chart on code completions. In April, something exciting happened: our acceptance rate went up while the explicit cancel rate dropped. In […]",
  "author": "Irina Mariasova",
  "published": "Tue, 18 Mar 2025 10:55:26 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": [
    "ai-assistant",
    "ai",
    "ai-code-completion",
    "code-completion",
    "llm"
  ],
  "byline": "Darya Rovdo",
  "length": 5776,
  "excerpt": "If you've been following our journey, you might've read our recent blog post on the Complete the Un-Completable: The State of AI Completion in JetBrains IDEs. From that post, you might remember this c",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "Supercharge your tools with AI-powered features inside many JetBrains products AI AssistantAI Code Completion: Less Is More If you’ve been following our journey, you might’ve read our recent blog post on the Complete the Un-Completable: The State of AI Completion in JetBrains IDEs. From that post, you might remember this cool chart on code completions. In April, something exciting happened: our acceptance rate went up while the explicit cancel rate dropped. In this blog post, we’ll break down why and how we got the results without retraining our generation model.  Man shall not live on LLM alone The LLM that provides your code suggestions is the heart of AI-powered code completion, but it’s not the whole show. There’s a ton happening behind the scenes, in particular on the plugin side, like deciding: When to show a suggestion.  If a suggestion should be single-line or multi-line. Which suggestions to show or conceal – for instance, a suggestion could be semantically incorrect, score too low, or use offensive or inappropriate language.  But sometimes, defining the filtering rules is not that straightforward. What we are trying to achieve Simply put, we want to show you only the suggestions you’ll actually use. That means fewer unwanted suggestions – ones you’ll cancel, edit, or delete – without losing the power of our code completion feature. In terms of metrics, we’re working to:  Increase the acceptance rate. Cut down the explicit cancel rate and the percentage of edited/deleted suggestions. Maintain or increase the ratio of completed code.  All you need is logs So, how do we achieve all of this? The obvious answer is to improve the completion model.  However, it’s not that simple: It’s expensive and time-consuming. Training a better model takes a lot of resources. We can’t see where things go wrong. We don’t store users’ code, so we can’t analyze bad suggestions. Context alone isn’t enough – things like user behavior and how a suggestion fits with nearby lines also matter. Lightweight local filter model Instead of going down that long road of improving the completion LLM, we took a different approach: a lightweight local filter model. This model runs on top of the completion LLM and is trained using anonymized logs. The model helps decide whether a suggestion should be shown by analyzing: Context: The file/project context (like the language used as well as the number and type of imports) and the completion context (like features that describe a caret location).  User behavior: The typing speed and the time spent since last typing. The suggestion itself: Whether references are resolved, if the suggestion repeats itself or is similar to surrounding lines, and additional model outputs like token scores and token entropy. The job of the lightweight local filter model is simple: it decides whether to accept or reject a suggestion based on your actions. However, we’ve guided the model a bit during training. We gave extra weight to explicit user actions, like when you explicitly accept or cancel a suggestion. If you edit or delete a suggestion after accepting it, we treat it as less of a win – the more you change, the less weight it gets. Technically speaking, the model is built with CatBoost, which is efficient and doesn’t need tons of data. The model is specifically designed to be lightweight – once trained, it becomes a compact 2.5 MB file and runs directly in Kotlin on users’ machines, making predictions in 1–2 milliseconds. What we have achieved Our A/B tests in the EAP showed great results, and they’re getting even better. The filter model boosted the acceptance rate by ~50% and cut the explicit cancel rate by ~40%, all while keeping the ratio of completed code steady. We officially rolled out the filter model in version 2024.1 of JetBrains IDEs for a range of languages, including Java, Kotlin, Python, PHP, JavaScript/TypeScript, Go, CSS, and Ruby. In later versions we also covered C#, C++, Rust, and HCL, plus the local filter model for cloud completion with Mellum in Python, Java, and Kotlin. We plan to cover even more languages soon. Meanwhile, both the local code completion model and the lightweight local filter model continue to evolve and improve together. What we have learned Even if your LLM is already doing a great job, there’s always room for improvement. You don’t always need massive, complex models to make a difference. Sometimes, the smart use of extra data like logs can do the trick. So, what’s next for AI-powered code completion? How far can we push it? Share your thoughts and ideas in the comments below! Subscribe to JetBrains AI Blog updates Discover more",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2025/03/jbai-social_share_blog_1280x720_en.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n    \u003cdiv\u003e\n                        \u003ca href=\"https://blog.jetbrains.com/ai/\"\u003e\n                            \u003cimg src=\"https://blog.jetbrains.com/wp-content/uploads/2024/01/JetBrains-AI.svg\" alt=\"Ai logo\"/\u003e\n                                                                                                \n                                                                                    \u003c/a\u003e\n                                                    \u003cp\u003eSupercharge your tools with AI-powered features inside many JetBrains products\u003c/p\u003e\n                                            \u003c/div\u003e\n                            \u003csection data-clarity-region=\"article\"\u003e\n                \u003cdiv\u003e\n                    \t\t\t\t\u003cp\u003e\u003ca href=\"https://blog.jetbrains.com/ai/category/ai-assistant/\"\u003eAI Assistant\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"major-updates\"\u003eAI Code Completion: Less Is More\u003c/h2\u003e                    \n                    \n\u003cp\u003eIf you’ve been following our journey, you might’ve read our recent blog post on the \u003ca href=\"https://blog.jetbrains.com/ai/2024/10/complete-the-un-completable-the-state-of-ai-completion-in-jetbrains-ides/\"\u003eComplete the Un-Completable: The State of AI Completion in JetBrains IDEs\u003c/a\u003e. From that post, you might remember this cool chart on code completions. In April, something exciting happened: our acceptance rate went up while the explicit cancel rate dropped.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdz1jeDqppkC5bTJi0wWcC8E68iN75IMo_IlZGD6UdNaONB_DXsV9crMnSJnDDlgDpNhyxW3PmIwa3RFklNEa6ZzWHwNmS66833MTNkc0URw0hzftWQi3kIHyP3cgpdOWNZ6zH74g?key=5RxS4DKSSVZME4dBLpCt6GBs\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIn this blog post, we’ll break down why and how we got the results without retraining our generation model. \u003c/p\u003e\n\n\n\n\u003ch2\u003eMan shall not live on LLM alone\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe LLM that provides your code suggestions is the heart of AI-powered code completion, but it’s not the whole show. There’s a ton happening behind the scenes, in particular on the plugin side, like deciding:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eWhen to show a suggestion. \u003c/li\u003e\n\n\n\n\u003cli\u003eIf a suggestion should be single-line or multi-line.\u003c/li\u003e\n\n\n\n\u003cli\u003eWhich suggestions to show or conceal – for instance, a suggestion could be semantically incorrect, score too low, or use offensive or inappropriate language. \u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eBut sometimes, defining the filtering rules is not that straightforward.\u003c/p\u003e\n\n\n\n\u003ch2\u003eWhat we are trying to achieve\u003c/h2\u003e\n\n\n\n\u003cp\u003eSimply put, we want to show you only the suggestions you’ll actually use. That means fewer unwanted suggestions – ones you’ll cancel, edit, or delete – without losing the power of our code completion feature. In terms of metrics, we’re working to: \u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eIncrease the acceptance rate.\u003c/li\u003e\n\n\n\n\u003cli\u003eCut down the explicit cancel rate and the percentage of edited/deleted suggestions.\u003c/li\u003e\n\n\n\n\u003cli\u003eMaintain or increase the ratio of completed code. \u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2\u003eAll you need is logs\u003c/h2\u003e\n\n\n\n\u003cp\u003eSo, how do we achieve all of this? The obvious answer is to improve the completion model. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, it’s not that simple:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eIt’s expensive and time-consuming. Training a better model takes a lot of resources.\u003c/li\u003e\n\n\n\n\u003cli\u003eWe can’t see where things go wrong. We don’t store users’ code, so we can’t analyze bad suggestions.\u003c/li\u003e\n\n\n\n\u003cli\u003eContext alone isn’t enough – things like user behavior and how a suggestion fits with nearby lines also matter.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch3\u003eLightweight local filter model\u003c/h3\u003e\n\n\n\n\u003cp\u003eInstead of going down that long road of improving the completion LLM, we took a different approach: a lightweight local filter model.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis model runs on top of the completion LLM and is trained using anonymized logs.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model helps decide whether a suggestion should be shown by analyzing:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eContext\u003c/strong\u003e: The file/project context (like the language used as well as the number and type of imports) and the completion context (like features that describe a caret location). \u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eUser behavior\u003c/strong\u003e: The typing speed and the time spent since last typing.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eThe suggestion itself\u003c/strong\u003e: Whether references are resolved, if the suggestion repeats itself or is similar to surrounding lines, and additional model outputs like token scores and token entropy.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdQVqSQo0ujQo6kvNL8EjMEPFPZ9-iGTpfKPpK_0OqqJExI-DYqmRrFJmVQQUYXMzP-ERMVPXdxmhBs39ofTY2eQqlwDg2D88wFHAWiFk1cdq4oGzWSi6IG6wEhdfeJWE5Dd694?key=5RxS4DKSSVZME4dBLpCt6GBs\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe job of the lightweight local filter model is simple: it decides whether to accept or reject a suggestion based on your actions. However, we’ve guided the model a bit during training. We gave extra weight to explicit user actions, like when you explicitly accept or cancel a suggestion. If you edit or delete a suggestion after accepting it, we treat it as less of a win – the more you change, the less weight it gets.\u003c/p\u003e\n\n\n\n\u003cp\u003eTechnically speaking, the model is built with \u003ca href=\"https://catboost.ai/\" target=\"_blank\" rel=\"noopener\"\u003eCatBoost\u003c/a\u003e, which is efficient and doesn’t need tons of data. The model is specifically designed to be lightweight – once trained, it becomes a compact 2.5 MB file and runs directly in Kotlin on users’ machines, making predictions in 1–2 milliseconds.\u003c/p\u003e\n\n\n\n\u003ch2\u003eWhat we have achieved\u003c/h2\u003e\n\n\n\n\u003cp\u003eOur A/B tests in the \u003ca href=\"https://www.jetbrains.com/resources/eap/\" target=\"_blank\" rel=\"noopener\"\u003eEAP\u003c/a\u003e showed great results, and they’re getting even better. The filter model boosted the acceptance rate by ~50% and cut the explicit cancel rate by ~40%, all while keeping the ratio of completed code steady.\u003c/p\u003e\n\n\n\n\u003cp\u003eWe officially rolled out the filter model in version 2024.1 of JetBrains IDEs for a range of languages, including Java, Kotlin, Python, PHP, JavaScript/TypeScript, Go, CSS, and Ruby. In later versions we also covered C#, C++, Rust, and HCL, plus the local filter model for cloud completion with Mellum in Python, Java, and Kotlin. We plan to cover even more languages soon.\u003c/p\u003e\n\n\n\n\u003cp\u003eMeanwhile, both the local code completion model and the lightweight local filter model continue to evolve and improve together.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdq879sS5_nqhdiXANZgWKNM-WM7G_b9gaAW78kgs7zq60szRg6hXM2LLZpMN3YjoXfh_2AFhm6w_pIgTS7iFwN-5qHaVZKIlbjvqCKW2rQNcCNQJQFH8FcF34BTtho1kkCYalXcQ?key=5RxS4DKSSVZME4dBLpCt6GBs\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003ch2\u003eWhat we have learned\u003c/h2\u003e\n\n\n\n\u003cp\u003eEven if your LLM is already doing a great job, there’s always room for improvement. You don’t always need massive, complex models to make a difference. Sometimes, the smart use of extra data like logs can do the trick. So, what’s next for AI-powered code completion? How far can we push it?\u003c/p\u003e\n\n\n\n\u003cp\u003eShare your thoughts and ideas in the comments below!\u003c/p\u003e\n                    \n                                                                                                                                                                                                                            \u003cdiv\u003e\n                                \u003cdiv\u003e\n                                                                            \u003ch4\u003eSubscribe to JetBrains AI Blog updates\u003c/h4\u003e\n                                                                                                            \n                                \u003c/div\u003e\n                                \n                                \u003cp\u003e\u003cimg src=\"https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg\" alt=\"image description\"/\u003e\n                                                                    \u003c/p\u003e\n                            \u003c/div\u003e\n                                                            \u003c/div\u003e\n                \u003ca href=\"#\"\u003e\u003c/a\u003e\n                \n                \n            \u003c/section\u003e\n                    \u003cdiv\u003e\n                \u003cp\u003e\n                    \u003ch2\u003eDiscover more\u003c/h2\u003e\n                \u003c/p\u003e\n                \n            \u003c/div\u003e\n                \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": null,
  "modifiedTime": null
}
