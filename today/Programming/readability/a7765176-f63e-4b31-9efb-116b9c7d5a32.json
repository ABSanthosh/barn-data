{
  "id": "a7765176-f63e-4b31-9efb-116b9c7d5a32",
  "title": "Ongoing community data protection",
  "link": "https://stackoverflow.blog/2024/09/30/ongoing-community-data-protection/",
  "description": "Socially responsible use of community data needs to be mutually beneficial: the more potential partners are willing to contribute to community development, the more access to community content they receive.",
  "author": "Ellen Brandenberger, Ryan Polk",
  "published": "Mon, 30 Sep 2024 15:43:00 GMT",
  "source": "https://stackoverflow.blog/feed/",
  "categories": [
    "socially-responsible-ai",
    "data-ethics",
    "ai",
    "se-stackoverflow",
    "se-all"
  ],
  "byline": "Ellen Brandenberger",
  "length": 5726,
  "excerpt": "This post is the third in a series focused on the importance of human-centered sources of knowledge as LLMs transform the information landscape. The first post focuses on the changing state of the internet and the data marketplace, and the second post discusses the importance of attribution.",
  "siteName": "",
  "favicon": "https://stackoverflow.blog/apple-touch-icon.png",
  "text": "This post is the third in a series focused on the importance of human-centered sources of knowledge as LLMs transform the information landscape. The first post focuses on the changing state of the internet and the data marketplace, and the second post discusses the importance of attribution.Socially responsible use of community data needs to be mutually beneficial: the more potential partners are willing to contribute to community development, the more access to community content they receive. The reverse is also true: AI providers who take from our community without giving back will have increasingly limited access to community data.The data used to train LLMs is not available in perpetuity. These partnerships are a recurring revenue model and a subscription service. Loss of access is retroactive—partners must retrain models without the data after this data is no longer available to consume and update.Terms outlined in contracts are one type of data protection, but other methods, both subtle and overt, supplement them: block lists (via Robots.txt and other means), rate limiting, and gated access to long-term archives are ways to politely guide those who might be searching for workarounds and back doors to leverage community content for commercial purposes without the appropriate licensing. In the last year, Stack has seen numerous data points that suggest LLM providers have escalated their methods for procuring community content for commercial use. In the last few months, non-partners have begun posing as cloud providers to hack into community sites, which led us to take steps to block hosted commercial applications that do so without attributing community content. At the same time, these strategies will help turn potential violators into trusted customers and partners by re-directing them to mutually beneficial pathways for all parties. (This also serves as a reminder for users of all tools and services to pay close attention to terms, conditions, and policies to know what you agree to.)When done thoughtfully, those pathways can still open the front doors to data use for the public and community good. For example, academic institutions wishing to use data for research purposes or communities looking to guard their collective work against unexpected systemic failure should not have their legitimate activities restricted. This balances the licensing of community content and preservation against the continued openness of the Stack Exchange platform for community use, evolution, and curation.That said, more complex techniques will continue to evolve as technology advances. Search, still a hub for clearly-sourced, organized knowledge, can also be a trojan horse for LLM summarization, choking off traffic and attribution. Monitoring approaches and data scraping policies will continue to evolve along with the patterns of unacceptable exploitation. As these methods evolve, so must our responses: Stack will continue to protect community content and health while creating pathways for socially responsible commercial use and open access to collective knowledge for its community. In doing so, communities and AI can continue to add to and reinforce each other instead of creating mutually assured destruction.This series has outlined a vision in which continuous feedback loops and cycles in the data marketplace benefit all involved.We know from the 2024 Developer Survey findings the top three challenges developers listed in our 2024 survey when it comes to using AI with their teams at work are that they don’t trust the output or answers (66%), AI lacks the context of internal codebase or company knowledge (63%), and the right policies are not in place to reduce security risks (31%). Companies and organizations who partner with Stack Exchange (and other human-centered platforms) get:Increased trust from users of their products via brand affiliation with reputable sources; increased awareness and reputation of those products and services.Higher accuracy of the data delivered to end users via APIs that package and filter data, focusing on integrity, speed, and structure. Content that is not useful can be excluded or handled differently.Reduced legal risk via licensed use of human-curated data sets.We know that the top three ethical issues related to AI that developers are concerned with: AI's potential to circulate misinformation (79%), missing or incorrect attribution for sources of data (65%), and bias that does not represent a diversity of viewpoints (50%). Developers and technologists using partner products that include community content get:Higher trust in the content delivered to them.Easy ways to go deeper on topics and do their verification via attribution and linking to sources.The ability to pair internal organizational knowledge with broader community knowledge via knowledge-as-a-service solutions.We know that Stack Overflow contributors also share these fundamental concerns about the circulation of incorrect information, clear and accurate attribution, and ensuring that diverse perspectives are available. They also care deeply about the platforms that house their work, overshadowed and forgotten. Knowledge authors and curators get:Reassurance that their contributions will persist into the future and continue to be open to benefit others.Recognition of their individual and collective efforts via attribution.Revenue from licensing invested into the platforms and tools they use to create the knowledge sets.Earlier in this series, we mentioned that we are all (users and companies) at an inflection point with AI tools. Only by following a vision like ours can we preserve a more open internet as the technology space and AI evolve.",
  "image": "https://cdn.stackoverflow.co/images/jo7n4k8s/production/ce36ac1749e406c5af8f32145248d0a54e271baf-2400x1200.png?w=1200\u0026fm=png\u0026auto=format",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv itemprop=\"articleBody\"\u003e\u003cp\u003e\u003cem\u003eThis post is the third in a series focused on the importance of human-centered sources of knowledge as LLMs transform the information landscape. The \u003c/em\u003e\u003cem\u003e\u003ca href=\"https://stackoverflow.blog/2024/09/30/knowledge-as-a-service-the-future-of-community-business-models/\" rel=\"noopener\" target=\"_blank\"\u003efirst post\u003c/a\u003e\u003c/em\u003e\u003cem\u003e focuses on the changing state of the internet and the data marketplace, and the \u003c/em\u003e\u003cem\u003e\u003ca href=\"https://stackoverflow.blog/2024/09/30/attribution-as-the-foundation-of-developer-trust/\" rel=\"noopener\" target=\"_blank\"\u003esecond post \u003c/a\u003e\u003c/em\u003e\u003cem\u003ediscusses the importance of attribution.\u003c/em\u003e\u003c/p\u003e\u003cp\u003eSocially responsible use of community data needs to be mutually beneficial: the more potential partners are willing to contribute to community development, the more access to community content they receive. The reverse is also true: AI providers who take from our community without giving back will have increasingly limited access to community data.\u003c/p\u003e\u003cp\u003eThe data used to train LLMs is not available in perpetuity. These partnerships are a recurring revenue model and a subscription service. Loss of access is retroactive—partners must retrain models \u003cstrong\u003ewithout\u003c/strong\u003e the data after this data is no longer available to consume and update.\u003c/p\u003e\u003cp\u003eTerms outlined in contracts are one type of data protection, but other methods, both subtle and overt, supplement them: block lists (via Robots.txt and other means), rate limiting, and gated access to long-term archives are ways to politely guide those who might be searching for workarounds and back doors to leverage community content for commercial purposes without the appropriate licensing. In the last year, Stack has seen numerous data points that suggest LLM providers have escalated their methods for procuring community content for commercial use. In the last few months, non-partners have begun posing as cloud providers to hack into community sites, which led us to take steps to block hosted commercial applications that do so without attributing community content. At the same time, these strategies will help turn potential violators into trusted customers and partners by re-directing them to mutually beneficial pathways for all parties. (\u003cem\u003eThis also serves as a reminder for users of all tools and services to pay close attention to terms, conditions, and policies to know what you agree to\u003c/em\u003e.)\u003c/p\u003e\u003cp\u003eWhen done thoughtfully, those pathways can still open the front doors to data use for the public and community good. For example, academic institutions wishing to use data for research purposes or communities looking to guard their collective work against unexpected systemic failure should not have their legitimate activities restricted. This balances the licensing of community content and preservation against the continued openness of the Stack Exchange platform for community use, evolution, and curation.\u003c/p\u003e\u003cp\u003eThat said, more complex techniques will continue to evolve as technology advances. Search, still a hub for clearly-sourced, organized knowledge, can also be a trojan horse for LLM summarization, choking off traffic and attribution. Monitoring approaches and data scraping policies will continue to evolve along with the patterns of unacceptable exploitation. As these methods evolve, so must our responses: Stack will continue to protect community content and health while creating pathways for \u003ca href=\"https://stackoverflow.blog/2024/01/18/the-path-to-socially-responsible-ai/\"\u003esocially responsible commercial use\u003c/a\u003e and open access to collective knowledge for its community. In doing so, communities and AI can continue to add to and reinforce each other instead of creating mutually assured destruction.\u003c/p\u003e\u003cp\u003eThis series has outlined a vision in which continuous feedback loops and cycles in the data marketplace benefit all involved.\u003c/p\u003e\u003cp\u003eWe know from the 2024 Developer Survey findings the top three challenges developers listed in our 2024 survey when it comes to using AI with their teams at work are that they don’t trust the output or answers (66%), AI lacks the context of internal codebase or company knowledge (63%), and the right policies are not in place to reduce security risks (31%). Companies and organizations who partner with Stack Exchange (and other human-centered platforms) get:\u003c/p\u003e\u003cul\u003e\u003cli\u003eIncreased trust from users of their products via brand affiliation with reputable sources; increased awareness and reputation of those products and services.\u003c/li\u003e\u003cli\u003eHigher accuracy of the data delivered to end users via APIs that package and filter data, focusing on integrity, speed, and structure. Content that is not useful can be excluded or handled differently.\u003c/li\u003e\u003cli\u003eReduced legal risk via licensed use of human-curated data sets.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe know that the top three ethical issues related to AI that developers are concerned with: AI\u0026#39;s potential to circulate misinformation (79%), missing or incorrect attribution for sources of data (65%), and bias that does not represent a diversity of viewpoints (50%). Developers and technologists using partner products that include community content get:\u003c/p\u003e\u003cul\u003e\u003cli\u003eHigher trust in the content delivered to them.\u003c/li\u003e\u003cli\u003eEasy ways to go deeper on topics and do their verification via attribution and linking to sources.\u003c/li\u003e\u003cli\u003eThe ability to pair internal organizational knowledge with broader community knowledge via knowledge-as-a-service solutions.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe know that Stack Overflow contributors also share these fundamental concerns about the circulation of incorrect information, clear and accurate attribution, and ensuring that diverse perspectives are available. They also care deeply about the platforms that house their work, overshadowed and forgotten. Knowledge authors and curators get:\u003c/p\u003e\u003cul\u003e\u003cli\u003eReassurance that their contributions will persist into the future and continue to be open to benefit others.\u003c/li\u003e\u003cli\u003eRecognition of their individual and collective efforts via attribution.\u003c/li\u003e\u003cli\u003eRevenue from licensing invested into the platforms and tools they use to create the knowledge sets.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eEarlier in this series, we mentioned that we are all (users and companies) at an inflection point with AI tools. Only by following a vision like ours can we preserve a more open internet as the technology space and AI evolve.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": null,
  "modifiedTime": null
}
