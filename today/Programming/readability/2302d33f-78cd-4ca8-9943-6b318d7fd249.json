{
  "id": "2302d33f-78cd-4ca8-9943-6b318d7fd249",
  "title": "Introducing PaliGemma 2 mix: A vision-language model for multiple tasks",
  "link": "https://developers.googleblog.com/en/introducing-paligemma-2-mix/",
  "description": "PaliGemma 2 mix, an upgraded vision-language model, is now available, offering capabilities like image captioning, OCR, and object detection in various sizes.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Omar Sanseviero, Andreas Steiner",
  "length": 5390,
  "excerpt": "PaliGemma 2 mix, an upgraded vision-language model, is now available, offering capabilities like image captioning, OCR, and object detection in various sizes.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Products More Solutions Events Learn Community Developer Program Blog This past December, we launched PaliGemma 2, an upgraded vision-language model in the Gemma family. The release included pretrained checkpoints of different sizes (3B, 10B, and 28B parameters) that can be easily fine-tuned on a wide range of vision-language tasks and domains, such as image segmentation, short video captioning, scientific question answering and text-related tasks with high performance.Now, we’re thrilled to announce the launch of PaliGemma 2 mix checkpoints. PaliGemma 2 mix are models tuned to a mixture of tasks that allow directly exploring the model capabilities and using it out-of-the-box for common use cases.What’s new in PaliGemma 2 mix?Multiple tasks with one model: PaliGemma 2 mix can solve tasks such as short and long captioning, optical character recognition (OCR), image question answering, object detection and segmentation.Developer-friendly sizes: Use the best model for your needs thanks to the different model sizes (3B, 10B, and 28B parameters) and resolutions (224px and 448px).Use with your preferred framework: Leverage your preferred tools and frameworks, including Hugging Face Transformers, Keras, PyTorch, JAX, and Gemma.cpp.If you were already using the original PaliGemma mix checkpoints, you can directly upgrade to PaliGemma 2 without needing to do any changes. The model performs different tasks depending on how it’s prompted. You can review the different prompt task syntax in the official documentation and learn more about how PaliGemma 2 was developed in our technical report.DetectionTask: Detection (PaliGemma-2-3b-mix-224)Input: \"detect android\\n\" Result: Multiple Object DetectionTask: Multiple Object Detection (PaliGemma-2-3b-mix-224)Input: “detect chair ; table\\n” Result: Task: Multiple Object Detection (PaliGemma-2-3b-mix-224)Input - \"detect food ; plate ; bowl\\n\" Result: Optical Character Recognition (OCR)Task: Multiple Object Detection (PaliGemma-2-3b-mix-224)Input - \"ocr\\n\" Result: SegmentationTask: Segmentation (PaliGemma-2-3b-mix-224) [Image generated by ImageFX]Input - \"segment cat\\n\" Result: Question AnsweringTask: Question Answering (PaliGemma2-mix-3b-448) [Image generated by ImageFX]Input: “answer en where is the cow standing?\\n\" Result: beachCaptioningInput: “caption en\\n” Result: a cow standing on a beach next to a sign that says warning dangerous rip current.Optical Character Recognition (OCR) Result:WARNINGDANGEROUSRIP CURRENTDetectionInput: “detect cow\\n” Result: SegmentationInput: “segment cow\\n” Result: CaptioningTask: Captioning (PaliGemma 2-mix-10b-448)Input: “caption en\\n” Result: A cow standing on a beach next to a warning sign. Optical Character Recognition (OCR)Task: \"ocr\\n\" Result:WARNING DANGEROUSRIP CURRENTGet Started TodayReady to discover the potential of PaliGemma 2? Here is how you can explore the mix model capabilities:Try out the mix model with a few clicks: Explore the mix model capabilities directly on the Hugging Face demo.Download models: Access the mix models weights on Kaggle and Hugging Face.Learn how to run the model: Try out the Keras inference notebook directly in Google Colab or locally.Deploy and tune with a few clicks: Use PaliGemma 2 mix directly in Vertex Model Garden.While PaliGemma 2 mix has strong performance across multiple tasks, you will get the best results by fine-tuning PaliGemma 2 in your own task or domain. To learn how to do it, dive into our comprehensive documentation, check our official example notebooks for Keras and JAX, or use the Hugging Face transformers example. We’re looking forward to seeing what you build with it!",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Paligemma_2_-_Meta.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\n        \n        \n        \n\n        \n\n\t\t\t\t\n        \n\n\n\n\n\u003cdiv top-level-nav=\"\"\u003e\n  \u003cnav aria-label=\"Side menu\"\u003e\n    \n    \u003cdiv\u003e\n        \u003cul\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/products\" data-label=\"Tab: Products\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Products\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003cspan tabindex=\"0\" data-label=\"More Products\"\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    More\n                  \u003c/span\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    \n                  \u003c/span\u003e\n                \u003c/span\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/solutions/catalog\" data-label=\"Tab: Solutions\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Solutions\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/events\" data-label=\"Tab: Events\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Events\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/learn\" data-label=\"Tab: Learn\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Learn\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/community\" data-label=\"Tab: Community\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Community\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/profile/u/me\" data-label=\"Tab: Developer Program\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Developer Program\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.googleblog.com/\" data-label=\"Tab: Blog\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Blog\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/div\u003e\n  \u003c/nav\u003e\n  \u003c/div\u003e\n\n\n\n        \n  \u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"zt635\"\u003eThis past December, \u003ca href=\"https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/\"\u003ewe launched PaliGemma 2\u003c/a\u003e, an upgraded vision-language model in the \u003ca href=\"https://ai.google.dev/gemma\"\u003eGemma\u003c/a\u003e family. The release included pretrained checkpoints of different sizes (3B, 10B, and 28B parameters) that can be easily fine-tuned on a wide range of vision-language tasks and domains, such as image segmentation, short video captioning, scientific question answering and text-related tasks with high performance.\u003c/p\u003e\u003cp data-block-key=\"equrv\"\u003eNow, we’re thrilled to announce the launch of PaliGemma 2 mix checkpoints. PaliGemma 2 mix are models tuned to a mixture of tasks that allow directly exploring the model capabilities and using it out-of-the-box for common use cases.\u003c/p\u003e\u003ch2 data-block-key=\"bk99l\"\u003e\u003cbr/\u003e\u003cb\u003eWhat’s new in PaliGemma 2 mix?\u003c/b\u003e\u003c/h2\u003e\u003cul\u003e\u003cli data-block-key=\"8t0ve\"\u003e\u003cb\u003eMultiple tasks with one model\u003c/b\u003e: PaliGemma 2 mix can solve tasks such as short and long captioning, optical character recognition (OCR), image question answering, object detection and segmentation.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"549q3\"\u003e\u003cb\u003eDeveloper-friendly sizes\u003c/b\u003e: Use the best model for your needs thanks to the different model sizes (3B, 10B, and 28B parameters) and resolutions (224px and 448px).\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"5v52d\"\u003e\u003cb\u003eUse with your preferred framework\u003c/b\u003e: Leverage your preferred tools and frameworks, including \u003ca href=\"https://huggingface.co/blog/paligemma2mix\"\u003eHugging Face Transformers\u003c/a\u003e, \u003ca href=\"https://ai.google.dev/gemma/docs/paligemma/inference-with-keras\"\u003eKeras\u003c/a\u003e, PyTorch, JAX, and \u003ca href=\"https://github.com/google/gemma.cpp/tree/main?tab=readme-ov-file#paligemma-vision-language-model\"\u003eGemma.cpp\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"2tcmi\"\u003eIf you were already using the original PaliGemma mix checkpoints, you can directly upgrade to PaliGemma 2 without needing to do any changes. The model performs different tasks depending on how it’s prompted. You can review the different prompt task syntax in the \u003ca href=\"https://ai.google.dev/gemma/docs/paligemma/prompt-system-instructions\"\u003eofficial documentation\u003c/a\u003e and learn more about how PaliGemma 2 was developed in our \u003ca href=\"https://arxiv.org/abs/2412.03555\"\u003etechnical report\u003c/a\u003e.\u003c/p\u003e\u003ch3 data-block-key=\"3toap\"\u003e\u003cb\u003e\u003cbr/\u003eDetection\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"15llt\"\u003eTask: Detection (PaliGemma-2-3b-mix-224)\u003c/li\u003e\u003cli data-block-key=\"77rg3\"\u003eInput: \u0026#34;detect android\\n\u0026#34;\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/14.original.png\" alt=\"Input - \u0026#34;detect android\\n\u0026#34;\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/13.original.png\" alt=\"Result in PaliGemma 2 Mix: A large, green Android figure stands on a white platform, enclosed by a red box. The word \u0026#34;android\u0026#34; is written in red above the figure.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"oy0xd\"\u003e\u003cb\u003eMultiple Object Detection\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"as8ld\"\u003eTask: Multiple Object Detection (PaliGemma-2-3b-mix-224)\u003c/li\u003e\u003cli data-block-key=\"6vpdr\"\u003eInput: “detect chair ; table\\n”\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/12.original.png\" alt=\"Multiple object detection of items in a dining room\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/11.original_kAI0v1s.png\" alt=\"A wooden table and chair are in the foreground. Additional tables and chairs can be seen in the background within a room with a bee patterned wall and wooden floors. Labeled boxes highlight the furniture with the text \u0026#34;table\u0026#34; and \u0026#34;chair.\u0026#34;\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cul\u003e\u003cli data-block-key=\"oy0xd\"\u003eTask: Multiple Object Detection (PaliGemma-2-3b-mix-224)\u003c/li\u003e\u003cli data-block-key=\"jms2\"\u003eInput - \u0026#34;detect food ; plate ; bowl\\n\u0026#34;\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/1_0DdPxg0.original.png\" alt=\"Plates and bowls of food on a wooden table\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"fie67\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/2_oaiGtNp.original.png\" alt=\"Plates and bowls of food on a wooden table labeled with boxes that accurately identify \u0026#34;plate\u0026#34;, \u0026#34;bowl\u0026#34; and \u0026#34;food\u0026#34;\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"oy0xd\"\u003e\u003cb\u003eOptical Character Recognition (OCR)\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"b2rj\"\u003eTask: Multiple Object Detection (PaliGemma-2-3b-mix-224)\u003c/li\u003e\u003cli data-block-key=\"475ml\"\u003eInput - \u0026#34;ocr\\n\u0026#34;\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/8.original.png\" alt=\"Lighting labels in Japanese kanji\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/PaliGemma_inline_images.original.png\" alt=\"Japanese Kanji reads: Downlight, Dining Room, Kitchen, Living Room, Bathroom/Dressing Room]\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"oy0xd\"\u003e\u003cb\u003eSegmentation\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"ujm4\"\u003eTask: Segmentation (PaliGemma-2-3b-mix-224) [Image generated by ImageFX]\u003c/li\u003e\u003cli data-block-key=\"dopi3\"\u003eInput - \u0026#34;segment cat\\n\u0026#34;\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/5.original_wx3552I.png\" alt=\"Image of a cat looking at the camera behind a wooden sign that reads \u0026#39;Hello PaliGemma 2\u0026#39; generated by ImageFX\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/4.original.png\" alt=\"highlighted image of a cat looking at the camera behind a wooden sign that reads \u0026#39;Hello PaliGemma 2\u0026#39; generated by ImageFX\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"oy0xd\"\u003e\u003cb\u003eQuestion Answering\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"926rj\"\u003eTask: Question Answering (PaliGemma2-mix-3b-448) [Image generated by ImageFX]\u003c/li\u003e\u003cli data-block-key=\"83p9i\"\u003eInput: “answer en where is the cow standing?\\n\u0026#34;\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e \u003ccode\u003ebeach\u003c/code\u003e\u003c/p\u003e\u003ch3 data-block-key=\"ds6se\"\u003e\u003cbr/\u003e\u003cb\u003eCaptioning\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"a9svt\"\u003eInput: “caption en\\n”\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e \u003ccode\u003ea cow standing on a beach next to a sign that says warning dangerous rip current.\u003c/code\u003e\u003c/p\u003e\u003cp data-block-key=\"fr3vh\"\u003e\u003cbr/\u003e\u003cb\u003eOptical Character Recognition (OCR)\u003c/b\u003e\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e\u003cp data-block-key=\"4qjfa\"\u003e\u003ccode\u003eWARNING\u003c/code\u003e\u003c/p\u003e\u003cp data-block-key=\"f3274\"\u003e\u003ccode\u003eDANGEROUS\u003c/code\u003e\u003c/p\u003e\u003cp data-block-key=\"3ubhn\"\u003e\u003ccode\u003eRIP CURRENT\u003c/code\u003e\u003c/p\u003e\u003ch3 data-block-key=\"evbe7\"\u003e\u003cbr/\u003e\u003cb\u003eDetection\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"3ci2p\"\u003eInput: “detect cow\\n”\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"fie67\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/2_3P429qe.original.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking. A red box outlines the cow, with a label that reads \u0026#34;cow\u0026#34;\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"0jncb\"\u003e\u003cb\u003eSegmentation\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"1h6op\"\u003eInput: “segment cow\\n”\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"fie67\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/1_a1xyThE.original.png\" alt=\"A highlighted cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"oy0xd\"\u003e\u003cb\u003eCaptioning\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"5ur6n\"\u003eTask: Captioning (PaliGemma 2-mix-10b-448)\u003c/li\u003e\u003cli data-block-key=\"79di3\"\u003eInput: “caption en\\n”\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e \u003ccode\u003eA cow standing on a beach next to a warning sign.\u003c/code\u003e\u003c/p\u003e  \u003cdiv\u003e\n    \u003ch3 data-block-key=\"oy0xd\"\u003e\u003cb\u003eOptical Character Recognition (OCR)\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"2cckf\"\u003eTask: \u0026#34;ocr\\n\u0026#34;\u003c/li\u003e\u003c/ul\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3.original_uC39cPq.png\" alt=\"A cow standing on the beach next to a yellow sign that reads \u0026#39;Warning Dangerous Rip Current\u0026#39; with an illustration of a large wave breaking.\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"oy0xd\"\u003e\u003cb\u003eResult:\u003c/b\u003e\u003c/p\u003e\u003cp data-block-key=\"40f5\"\u003e\u003ccode\u003eWARNING DANGEROUS\u003c/code\u003e\u003c/p\u003e\u003cp data-block-key=\"c3p01\"\u003e\u003ccode\u003eRIP CURRENT\u003c/code\u003e\u003c/p\u003e\u003ch2 data-block-key=\"ebub4\"\u003e\u003cb\u003e\u003cbr/\u003eGet Started Today\u003c/b\u003e\u003c/h2\u003e\u003cp data-block-key=\"mtog\"\u003eReady to discover the potential of PaliGemma 2? Here is how you can explore the mix model capabilities:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"7tg5p\"\u003e\u003cb\u003eTry out the mix model with a few clicks:\u003c/b\u003e Explore the mix model capabilities directly on the \u003ca href=\"https://huggingface.co/spaces/google/paligemma2-10b-mix\"\u003eHugging Face demo\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"1l8h6\"\u003e\u003cb\u003eDownload models\u003c/b\u003e: Access the mix models weights on \u003ca href=\"https://www.kaggle.com/models/google/paligemma-2/\"\u003eKaggle\u003c/a\u003e and \u003ca href=\"https://huggingface.co/collections/google/paligemma-2-mix-67ac6a251aaf3ee73679dcc4\"\u003eHugging Face\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"9of3j\"\u003e\u003cb\u003eLearn how to run the model\u003c/b\u003e: Try out the Keras \u003ca href=\"https://ai.google.dev/gemma/docs/paligemma/inference-with-keras\"\u003einference notebook\u003c/a\u003e directly in Google Colab or locally.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"a4o92\"\u003e\u003cb\u003eDeploy and tune with a few clicks\u003c/b\u003e: Use PaliGemma 2 mix directly in \u003ca href=\"https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/paligemma\"\u003eVertex Model Garden\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"8mgbv\"\u003e\u003cbr/\u003eWhile PaliGemma 2 mix has strong performance across multiple tasks, you will get the best results by fine-tuning PaliGemma 2 in your own task or domain. To learn how to do it, dive into our \u003ca href=\"https://ai.google.dev/gemma/docs/paligemma\"\u003ecomprehensive documentation\u003c/a\u003e, check our official \u003ca href=\"https://github.com/google-gemini/gemma-cookbook/tree/main/PaliGemma\"\u003eexample notebooks for Keras and JAX\u003c/a\u003e, or use the \u003ca href=\"https://github.com/merveenoyan/smol-vision/blob/main/Fine_tune_PaliGemma.ipynb\"\u003eHugging Face transformers example\u003c/a\u003e. We’re looking forward to seeing what you build with it!\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\n\n\n\t\t\t\t\n\t\t\t\t\n\n\n\n\n\n        \n\t\t\t\t\n\n        \n        \n        \n        \n\n        \n\n        \n  \n\n    \n\n\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-02-19T00:00:00Z",
  "modifiedTime": null
}
