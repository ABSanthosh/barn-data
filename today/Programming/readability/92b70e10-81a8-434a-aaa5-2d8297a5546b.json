{
  "id": "92b70e10-81a8-434a-aaa5-2d8297a5546b",
  "title": "Article: Being Functionless: How to Develop a Serverless Mindset to Write Less Code!",
  "link": "https://www.infoq.com/articles/functionless-serverless-mindset/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Innovative cloud architect focusing on serverless computing and Function as a Service. Advocates for optimized, functionless architecture to reduce complexity and costs. Expertise in leveraging cloud-native services for sustainable operations and minimizing code liabilities. Committed to transforming engineering mindsets for efficient application development in a rapidly evolving tech landscape. By Sheen Brisals",
  "author": "Sheen Brisals",
  "published": "Fri, 03 Jan 2025 10:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "FaaS",
    "AWS Lambda",
    "Cloud",
    "Serverless",
    "Architecture \u0026 Design",
    "Development",
    "DevOps",
    "article"
  ],
  "byline": "Sheen Brisals",
  "length": 25670,
  "excerpt": "The rise of serverless technology and Function as a Service (FaaS) transformed cloud computing but requires a shift in mindset to avoid complexity and optimize efficiency.",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20241210082243/apple-touch-icon.png",
  "text": "Key Takeaways Building applications with serverless technology is not all about implementing functions for every purpose. Overusing interdependent functions coupled with other services causes the architecture to devolve into spaghetti. It is essential to develop a mindset that recognizes functions as code liability. Eliminating them where possible reduces cost and complexity. There are use cases where functions are not the best fit. Assessing and avoiding them in such situations helps build well-architected applications that optimize cost and efficiency and promote sustainability. Business logic is not always concentrated as functions in modern distributed and event-driven systems. Service orchestration, for example, is well suited for handling distributed business logic. Services operated and managed by cloud providers - known as fully managed services - are not new. For example, Amazon Simple Queue Service (SQS) and Amazon Simple Storage Service (S3) are fully managed services from AWS and are nearly two decades old. As platforms and infrastructure became available as services from Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and other cloud providers, it promoted the growth of independent software vendors (ISVs) offering several products as Software as a Service (SaaS). Though the term serverless appeared in 2012 - inspired by the evolving cloud landscape and how SaaS applications eliminated the need to own and manage physical hardware - its association with the existing fully managed cloud services wasn’t evident. Related Sponsored Content Top 15 Tech Trends in 2024 (By McKinsey) - Download the Report While the growth of the SaaS market was fueling innovations, the industry was missing a crucial piece in the managed services repertoire - a fully managed compute service in the cloud. In 2014, when Amazon released AWS Lambda - the fully managed compute service in the cloud, popularly known as Function as a Service (FaaS) - it changed the cloud industry forever, instantly elevating serverless to new heights! Soon after, Microsoft and Google followed with their FaaS offerings, Azure Functions, and Google Cloud Functions, respectively. As the industry's first FaaS offering, AWS Lambda gained instant popularity. As a result, several case studies, lessons, patterns, and anti-patterns on serverless development revolved around Lambda functions. Hence, its name became associated with some of the early industry thoughts referenced in this article. However, these thoughts are equally applicable and valid with every FaaS offering. With the release of API gateway and management services from the leading cloud providers, the world was open to consuming functions' computational logic. Thus, the serverless revolution became unstoppable - together, the overutilization of FaaS! The Unglamorous Side Effects of FaaS Programming purists often pay the least attention to non-computational managed cloud services, viewing the services as configuration-oriented and suited for infrastructure engineers. However, these purists are now equipped with a computation service in the cloud to explore the programming model behind functions. As the adoption of FaaS increased, cloud providers added a variety of language runtimes to cater to different computational needs, skills, etc., offering something for most programmers. Language runtimes such as Java, .NET, Node.js, Python, Ruby, Go, etc., are the most popular and widely adopted. However, this also brings some challenges to organizations adopting serverless technology. More than technology challenges, these are mindset challenges for engineers. The following sections highlight some of the side effects of the overuse of FaaS in serverless applications. The Lambda Hammer mindset \"If the only tool you have is a hammer, everything looks like a nail\". - Abraham Maslow. Writing FaaS functions is easy for engineering teams, allowing for a quick turnaround in implementing business logic and releasing features, which improves team velocity. This newfound fame and the speed of development inevitably create a mindset of doing anything and everything as functions - the only solution to every business problem. On AWS, Lambda functions were considered the one-fix remedy for everything. Hence, the term Lambda Hammer! One of the primary reasons engineers develop a Lambda Hammer mindset can be attributed to their industry experience and programming competency. Many engineers developing traditional applications in a non-cloud environment mainly focus on the programming aspects of software engineering. In such environments, siloed teams share the responsibilities of bringing an application to production or releasing a feature to customers. Developers - confined to programming - implement a solution according to an architect's vision, test it by QA engineers, and hand it over to a platform or infrastructure team to deploy and operate it. When programming-focused engineers transition to working with serverless technology, the Lambda programming model and the concept of FaaS become natural attractions - they are perceived as the tools to solve every problem! The Lambda Pinball Architectures! In a pinball game, a ball is propelled into a cabinet where it bounces off various lights, bumpers, ramps, and other obstacles. - Wikipedia. Thoughtworks initially coined the term Lambda Pinball Architecture to warn of a situation where an interdependent and tangled web of Lambda functions, along with services such as S3 buckets and SQS queues, bounce requests around, resulting in a complex and distributed monolith application that is hard to test and maintain. Though Thoughtworks highlighted Lambda and other AWS services, the pinball situation can also occur with Azure, Google Cloud, and other providers. All major cloud providers offer services with similar capabilities. Hence, the serverless development best practices are relevant and applicable to all. The above condition occurs due to a poorly architected approach to employing functions to implement computational logic, data ingestion, data transformation, data transport, service mediation, and other activities without clear service boundaries. The dreadful outcome of a prolonged pinball situation is a tangled architecture, the serverless ball of mud, as shown in Figure 1. Figure 1: An entangled serverless architecture Unintentional increase in cloud cost With FaaS functions, you only pay for the execution (if you don’t use some advanced features). However, implementing more functions than necessary increases your cloud cost and total cost of ownership (TCO). With most cloud providers, a function’s cost has two main parts: The price for each request made to the cloud service to invoke the function The time to complete each invocation and the memory (RAM) allocated Let’s say your function is Allocated with 1,024 MB of memory Invoked 3 million times a month (100,000 invocations per day) Each invocation executes for 10 milliseconds (ms) on average For an AWS Lambda function deployed in the Europe Central Region, the above will cost 0.40 USD per month (with the free-tier allowance). The cost is the same for an Azure Function with the above configuration running in the Germany West Central Region. However, if the average execution duration of the function were 10 seconds (instead of 10 ms), then the monthly cost of the AWS Lambda function would jump to 493 USD, and the Azure Function would increase to 474 USD. Now, think of the cost savings if several such functions perform non-computational tasks that can be achieved by other means - i.e., in a function-less way! Note: The above Lambda cost is for the use of an x86 processor. By switching to the Arm processor, the price will be reduced to 395 USD. Impact on sustainable cloud operation Sustainability is a crucial aspect of modern cloud operation. Consuming renewable energy, reducing carbon footprint, and achieving green energy targets are top priorities for cloud providers. Cloud providers invest in efficient power and cooling technologies and operate an efficient server population to achieve higher utilization. For this reason, AWS recommends using managed services for efficient cloud operation, as part of their Well-Architected Framework best practices for sustainability. As a service consumer, you are also responsible for sustainability. Hence, the major cloud providers have set out well-architected best practices for sustainability that promote a shared responsibility between the provider and its consumers. While the cloud providers manage the resources for FaaS to achieve sustainability of the cloud, you have equal responsibility to operate the functions sustainably in the cloud. This includes, The optimal use of the number of functions Optimizing the memory allocation of each function Optimizing performance to the required level and not to the maximum When you implement a FaaS function for unsuitable purposes or operate in a suboptimal way, you indirectly impact the three core elements of the cloud: compute, storage, and network. Each consumes energy for its operation. Increasing your code liability \"All the code you ever write is business logic\". - Dr. Werner Vogels, CTO, Amazon.com. As a software engineer, you hear similar statements and arguments in the industry about program code. \"Code is a liability, not an asset, for an organization\". \"The code you write today becomes legacy tomorrow\". \"The more code a company has, the more money it spends to maintain adding to its TCO\". Regardless of such arguments, one cannot avoid writing code - be it function code, data code, integration code, or infrastructure code. However, the focus here is on unnecessary and unwanted function code. As discussed earlier, the Lambda hammer mindset often drives engineers to implement a function instead of an alternate cloud service or feature. The function now becomes an unnecessary burden for the team to maintain. When you think of a function, think beyond your joy of coding it - the testing, the CI/CD process, releasing, observing, and your cloud account’s concurrency limit, etc. How to Develop a Low-code Mindset For engineers new to serverless, equipping their minds to its needs can be challenging. Hence, you hear about the serverless mindset as a prerequisite to adopting serverless. This is because working with serverless requires a new way of thinking, developing, and operating applications in the cloud. You must think of serverless applications as orchestrations of managed cloud services knitted with infrastructure code. Serverless as a technology ecosystem Often, engineers view serverless environments with a programming eye, ignoring the capabilities of the managed services and the roles and responsibilities of the people involved. In the book Serverless Development on AWS (O’Reilly, 2024), which I co-authored with Luke Hedger, we advise seeing serverless technology as an ecosystem that contains the cloud provider, FaaS, and other managed services, tools, frameworks, engineers, stakeholders, etc. This brings a sociotechnical mindset to technology, which is vital to working with modern technology and engineering practices. Figure 2: The view of the serverless ecosystem Another way of viewing it is through systems thinking. Diana Montalion's book Learning Systems Thinking (O’Reilly, 2024) states that a system is a group of interrelated hardware, software, people, organization(s), and other elements that interact and/or interdepend to serve a shared purpose. Not all microservices need functions When you build microservices, depending on your domain and your team’s bounded context, as explained in my talk, The Set Piece Strategy, at QCon 2024, not all services perform computations that require functions. As you will learn below, the business logic of a service can be orchestrated and collaborated with other services via native integration and event-driven communication. Fast flow teams seek quick turn around to incidents. Less is more for such teams. Modern product teams that are stream-aligned (as advocated by Team Topologies) and autonomous develop and release new features and updates in quick iterations. Serverless is a great technology that enables fast flow. As the teams operate their workloads in the cloud, observing and remediating issues in production is crucial. The square of balance is a term used in Serverless Development on AWS (O’Reilly, 2024) to explain how the four activities of testing, delivering, observing, and recovery are key to achieving balance. Figure 3: The serverless square of balance for fast flow Having minimal code liability is advantageous when serverless teams operate in a fast-paced development environment. It reduces the potential sources of bugs and failure points and shifts more responsibility to the cloud provider. What is Functionless? In a serverless context, the terms functionless, codeless, Lambda-less, no-code, low-code, etc., express the idea of reducing the number of FaaS functions in an application with native service integrations. I first heard about Functionless in 2019 at the Serverless Days conference in Helsinki. Realizing the need to educate engineers about the side effects of too many functions, I have been advocating in the community, reiterating the benefits of eliminating functions where feasible. In addition to understanding the nuances of cloud computing, a crucial part of architecting and developing serverless applications is thinking beyond FaaS and remembering that functions are a part of the serverless ecosystem, not all of it. Doesn’t functionless increase lock-in? The moment a business decides to consume services from a cloud provider or a product from a vendor, it introduces some form of lock-in. Businesses are aware of this and consciously choose to grow their business with a stable and cordial partnership with the provider - not to switch products, services, and providers frequently. It is true that if you use native service integrations and cloud platform-specific features, your dependency increases. Even if you make the computational logic of a function cloud-agnostic, it is hard to make it pure agnostic. As you learned above, a function must collaborate with one or more cloud services to offer business functionality. When you focus on making a function cloud-agnostic, you are not capitalizing on the reasons for being in the cloud. It is counterintuitive and harms the business if it chooses a cloud provider and then decides to work against its core benefits. Architecting serverless applications with fewer functions \"Simplicity is better than elaborate embellishments. Sometimes, something simple is better than something advanced or complicated\". - From the web. Though it is easy to advocate simplicity, arriving at simplicity is not always easy. It requires experience dealing with complex architectures, knowledge, and awareness of the areas where simplicity can be practiced. Your experience building serverless applications helps you view architectures with a simple lens. This section will examine areas where you can use patterns to avoid functions and make your architecture functionless. Handling data An advisory in the serverless community says you should use a function to transform data, not transport it. If you use a function to move data between services, you use it for the wrong purpose, or the cloud provider lacks a native feature. Data handling is a core part of the cloud, and modern data sets' volume and growth rate are exponential. From a cost and scale point of view, it is not advisable to employ functions for every data operation in such situations. Hence, you should find ways to leave the heavy lifting to the core cloud services. Traditionally, databases refer mainly to relational database systems (RDBMS) and, to a lesser extent, other variants such as vector and graph data stores. However, several data storage options, such as relational or SQL, NoSQL, object, graph, vector, document, and more, are now available in the cloud. In addition to the above, services that ingest, buffer, and route messages and events also offer temporary storage. You can apply functionless and native operations for many of these service operations, and this must be considered in your architectural thinking. Storing and retrieving data Many engineers have the preconceived mindset that a function is needed to perform data operations. With such thinking, functions creep in where they have no role. The two places where a function is commonly used to transport data are API gateway backends and workflow orchestrations. As explained below, several ways exist to handle data operations without the help of functions. Storing API request payload in a data table: Figure 4 shows a simple serverless pattern in which a function receives the API request payload, say, a new book title, and persists in a table. Most API gateways offer schema validation on the incoming data. Once validated, you can store the data from the API directly in the table using native service integration. Thus, the function in the middle becomes unnecessary. Figure 4: Eliminating unnecessary functions in data operation Like above, you can perform fetching data from data tables to send as API response payload without a function in the middle. Atomic data counter operations without a function: Amazon DynamoDB, for example, has no built-in feature to generate unique sequence numbers like traditional relational databases. However, this can be accomplished with the atomic counter concept in DynamoDB, as shown in Figure 5. If you have a service that generates unique values for orders, customer registrations, site visitors, etc., this can be achieved between the API and a DynamoDB table. Figure 5: Native service integration between API Gateway and DynamoDB table to generate sequence numbers {     \"TableName\": \"sequence-numbers\",     \"Key\": {         \"id\": {             \"S\": \"visitor\"         }     },     \"ExpressionAttributeValues\": {         \":val\": {             \"N\": \"1\"         }     },     \"UpdateExpression\": \"ADD sequence :val\",     \"ReturnValues\": \"UPDATED_NEW\" } Sample VTL script to perform the atomic counter increment. Buffering high-volume API requests: Another widespread use case is handling spikey API requests and processing them asynchronously, as shown in Figure 6. In such situations, it is vital to control the load to protect the downstream systems. Adding a queue behind the API can be a buffer to control the data flow. In this scenario, the data is stored before processing, known as the Storage First pattern. It is common to see this pattern implemented with other data stores. Figure 6: API requests buffered in a queue for asynchronous processing Data expiry One traditional approach to purge expired data from databases is to run a task on a scheduler to query data with specific parameters and perform delete operations. Depending on the volume of data, such clean-up tasks can take minutes or hours to complete. When engineers bring the above experience into serverless development, the apparent choice for querying and deleting data is with a suite of purpose-built functions. However, modern data stores offer automated data purging at no cost and without impacting performance. Opting for such native features avoids implementing functions. For example, Amazon DynamoDB has the option to set time-to-live (TTL) for every data item (record) in a table. Though some deletes may take up to 48 hours, it is far more efficient than handling programmatically by yourself. Azure Cosmos DB also offers a similar TTL feature to remove unwanted data. The most popular object store in the cloud, Amazon S3, supports data retention policies for data buckets. With data retention policies, you let S3 manage the lifecycle of data objects to either delete expired objects or move them to an archive or low-cost storage to comply with your business requirements. Use a service’s native feature to perform data cleanup with every data store you work with. Beyond the benefits of dealing with fewer functions, this also brings sustainability benefits to your cloud operation. Though data is central to everything we do, not all data is valuable or remains valuable beyond a certain point. Hence, thinking about your data lifecycle is crucial to removing unwanted data and reducing compute storage, and network use. Thinking beyond the CRUD Operations An API implementation includes endpoints that perform typical operations, such as Creating, Reading, Updating, and Deleting (CRUD) data in a database system, aligning with the appropriate HTTP methods. Though every API contract and the invocation type - synchronous or asynchronous - can be categorized into one of those four distinct data operations, in modern distributed systems, the backend operations are not always strictly CRUD. As you saw earlier, when a synchronous API fetches a new order number, it performs an atomic data operation. However, the behavior need not be the same in an asynchronous invocation. For example, when a customer places an order, one or more services, owned and operated by several teams from multiple business domains, collaborate to fulfill the request. In this case, not every activity within or across various services needs to be atomic. From a modularity and extensibility point of view, a monolith function comprising complex logic interacting with several services to coordinate tasks is not an ideal solution. Service orchestration is the apt design pattern to consider in such scenarios. Instead of a function, a service workflow becomes the backend orchestrator, as shown in Figure 7. Cloud services such as AWS Step Functions and Azure Logic Apps are prominent workflow orchestrators available today. Figure 7: A workflow that initiates async operations and handles an API request Filtering and transforming events The popular fully managed cloud services that ingest and deliver events offer native integration with many other services. Event filtering, transformation, archiving, and delivery to several destinations are some of the core features of these services that eliminate the need for custom functions. Amazon EventBridge, Azure EventGrid, Google Cloud Pub/Sub, etc., are cloud services that provide event transport and act as event brokers to easily coordinate with multiple applications in a loosely coupled event-driven communication. Low-code Integration Trade-Offs One primary motivation for using cloud services is to delegate as much as possible to the cloud provider. In this regard, native service integration that reduces unnecessary function code must be a factor when architecting serverless and cloud applications. However, while developing a functionless mindset, it is equally important to be aware of some limitations and trade-offs, as highlighted below. Most native service integration acts as a black box without visibility of the integration code at runtime. This can make investigating bugs challenging. In AWS, for example, integration code is written using Velocity Template Language (VTL). Because VTL's syntax differs from familiar programming languages, learning and becoming familiar with it takes time. Though API gateway and management services support native integration with several cloud services, each target service's integration format is not uniform. Knowing the differences in permitted data payload sizes between the source and target services is crucial to preventing processing failures. Like the payload size, the service timeout and throttling limits can also differ between the integrated services. Sometimes, you may require a function for nonfunctional operations, such as security checks on parts of the request context data. Conclusion \"The first step toward change is awareness. The second step is acceptance\". - Nathaniel Branden. As an evolution of the cloud, serverless technology enables organizations to quickly add value by removing the unnecessary baggage of server and hardware management. However, while building applications using serverless technology, you must continue exploring ways to simplify your architecture and operational overheads. In this article, capturing every use case that reduces the FaaS footprint is impossible. It intends to raise awareness. According to industry feedback, newly adopted serverless teams will likely make costly architectures and implementation mistakes. Though this is understandable to some extent, the motivation should be to avoid such errors by employing apt patterns and principles from the beginning. One size does not fit all. The business domains and use cases differ from team to team. While implementing a pattern - functionless or another - you must first analyze its applicability. When you know the possibilities, you can take the necessary actions to simplify your architecture. About the Author Sheen Brisals",
  "image": "https://res.infoq.com/articles/functionless-serverless-mindset/en/headerimage/functionless-header-1735812500913.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\t\u003ch3\u003eKey Takeaways\u003c/h3\u003e\n\t\t\t\t\t\t\t\t\t\u003cul\u003e\n\t\u003cli\u003eBuilding applications with serverless technology is not all about implementing functions for every purpose.\u003c/li\u003e\n\t\u003cli\u003eOverusing interdependent functions coupled with other services causes the architecture to devolve into spaghetti.\u003c/li\u003e\n\t\u003cli\u003eIt is essential to develop a mindset that recognizes functions as \u003cem\u003ecode liability\u003c/em\u003e. Eliminating them where possible reduces cost and complexity.\u003c/li\u003e\n\t\u003cli\u003eThere are use cases where functions are not the best fit. Assessing and avoiding them in such situations helps build well-architected applications that optimize cost and efficiency and promote sustainability.\u003c/li\u003e\n\t\u003cli\u003eBusiness logic is not always concentrated as functions in modern distributed and event-driven systems. Service orchestration, for example, is well suited for handling distributed business logic.\u003c/li\u003e\n\u003c/ul\u003e\n\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\u003c/div\u003e\n\t\t\t\t\t\t\t\n                                                        \n                                                        \n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\u003cp\u003eServices operated and managed by cloud providers - known as \u003cem\u003efully managed services\u003c/em\u003e - are not new. For example, \u003ca href=\"https://aws.amazon.com/sqs/\"\u003eAmazon Simple Queue Service (SQS)\u003c/a\u003e and \u003ca href=\"https://aws.amazon.com/s3/\"\u003eAmazon Simple Storage Service (S3)\u003c/a\u003e are fully managed services from AWS and are nearly two decades old.\u003c/p\u003e\n\n\u003cp\u003eAs platforms and infrastructure became available as services from \u003ca href=\"https://aws.amazon.com/\"\u003eAmazon Web Services (AWS)\u003c/a\u003e, \u003ca href=\"https://azure.microsoft.com/en-gb\"\u003eMicrosoft Azure\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/\"\u003eGoogle Cloud Platform (GCP)\u003c/a\u003e, and other cloud providers, it promoted the growth of independent software vendors (ISVs) offering several products as \u003ca href=\"https://en.wikipedia.org/wiki/Software_as_a_service\"\u003eSoftware as a Service (SaaS)\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eThough the term \u003cem\u003e\u003ca href=\"https://readwrite.com/why-the-future-of-software-and-apps-is-serverless/\"\u003eserverless\u003c/a\u003e\u003c/em\u003e appeared in 2012 - inspired by the evolving cloud landscape and how SaaS applications eliminated the need to own and manage physical hardware - its association with the existing fully managed cloud services wasn’t evident.\u003c/p\u003e\n\n\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\u003cdiv data-trk-view=\"true\" data-trk-impr=\"true\" data-place=\"EMBEDDED\"\u003e\n\t\n\t\u003cul\u003e\n\t\t\u003ch4\u003eRelated Sponsored Content\u003c/h4\u003e\n\t\t\n\t\t\t\n\t\t\t\t\u003cli\u003e\n\t\t\t\t\t\u003cspan\u003e\u003c/span\u003e\n\t\t\t\t\t\u003ch5\u003e\n\t\t\t\t\t\t\u003ca href=\"https://www.infoq.com/url/f/550f1d93-d676-446a-b64a-ad5190e564d6/\" rel=\"nofollow\"\u003e\n\t\t\t\t\t\t\tTop 15 Tech Trends in 2024 (By McKinsey) - Download the Report\n\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\t\t\u003c/h5\u003e\n\t\t\t\t\u003c/li\u003e\n\t\t\t\n\t\t\n\t\t\n\t\t\n\t\u003c/ul\u003e\n\t\n\t\t\n\t\n\t\n\u003c/div\u003e\n\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\u003cp\u003eWhile the growth of the SaaS market was fueling innovations, the industry was missing a crucial piece in the managed services repertoire - a fully managed compute service in the cloud. In 2014, when Amazon released \u003ca href=\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e - the fully managed compute service in the cloud, popularly known as \u003ca href=\"https://en.wikipedia.org/wiki/Function_as_a_service\"\u003eFunction as a Service (FaaS)\u003c/a\u003e - it changed the cloud industry forever, instantly elevating serverless to new heights! Soon after, Microsoft and Google followed with their FaaS offerings, \u003ca href=\"https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview\"\u003eAzure Functions\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/functions?hl=en\"\u003eGoogle Cloud Functions\u003c/a\u003e, respectively.\u003c/p\u003e\n\n\u003cp\u003eAs the industry\u0026#39;s first FaaS offering, AWS Lambda gained instant popularity. As a result, several case studies, lessons, patterns, and anti-patterns on serverless development revolved around Lambda functions. Hence, its name became associated with some of the early industry thoughts referenced in this article. However, these thoughts are equally applicable and valid with every FaaS offering.\u003c/p\u003e\n\n\u003cp\u003eWith the release of API gateway and management services from the leading cloud providers, the world was open to consuming functions\u0026#39; computational logic. Thus, the serverless revolution became unstoppable - together, the overutilization of FaaS!\u003c/p\u003e\n\n\u003ch2\u003eThe Unglamorous Side Effects of FaaS\u003c/h2\u003e\n\n\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\u003cp\u003eProgramming purists often pay the least attention to non-computational managed cloud services, viewing the services as configuration-oriented and suited for infrastructure engineers. However, these purists are now equipped with a computation service in the cloud to explore the programming model behind functions.\u003c/p\u003e\n\n\u003cp\u003eAs the adoption of FaaS increased, cloud providers added a variety of language runtimes to cater to different computational needs, skills, etc., offering something for most programmers. Language runtimes such as Java, .NET, Node.js, Python, Ruby, Go, etc., are the most popular and widely adopted. However, this also brings some challenges to organizations adopting serverless technology. More than technology challenges, these are mindset challenges for engineers.\u003c/p\u003e\n\n\u003cp\u003eThe following sections highlight some of the side effects of the overuse of FaaS in serverless applications.\u003c/p\u003e\n\n\u003ch3\u003eThe Lambda Hammer mindset\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026#34;If the only tool you have is a hammer, everything looks like a nail\u0026#34;. - Abraham Maslow.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWriting FaaS functions is easy for engineering teams, allowing for a quick turnaround in implementing business logic and releasing features, which improves team velocity. This newfound fame and the speed of development inevitably create a mindset of doing anything and everything as functions - the \u003cem\u003eonly\u003c/em\u003e solution to every business problem. On AWS, Lambda functions were considered the one-fix remedy for everything. Hence, the term \u003cem\u003eLambda Hammer\u003c/em\u003e!\u003c/p\u003e\n\n\u003cp\u003eOne of the primary reasons engineers develop a \u003cem\u003eLambda Hammer\u003c/em\u003e mindset can be attributed to their industry experience and \u003cem\u003eprogramming\u003c/em\u003e competency. Many engineers developing traditional applications in a non-cloud environment mainly focus on the \u003cem\u003eprogramming\u003c/em\u003e aspects of software engineering. In such environments, siloed teams share the responsibilities of bringing an application to production or releasing a feature to customers. Developers - confined to programming - implement a solution according to an architect\u0026#39;s vision, test it by QA engineers, and hand it over to a platform or infrastructure team to deploy and operate it.\u003c/p\u003e\n\n\u003cp\u003eWhen programming-focused engineers transition to working with serverless technology, the Lambda programming model and the concept of FaaS become natural attractions - they are perceived as the tools to solve every problem!\u003c/p\u003e\n\n\u003ch3\u003eThe Lambda Pinball Architectures!\u003c/h3\u003e\n\n\u003cp\u003e\u003cem\u003eIn a pinball game, a ball is propelled into a cabinet where it bounces off various lights, bumpers, ramps, and other obstacles. - Wikipedia.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.thoughtworks.com/\"\u003eThoughtworks\u003c/a\u003e initially coined the term \u003ca href=\"https://www.thoughtworks.com/en-gb/radar/techniques/lambda-pinball\"\u003eLambda Pinball Architecture\u003c/a\u003e to warn of a situation where an interdependent and tangled web of Lambda functions, along with services such as S3 buckets and SQS queues, bounce requests around, resulting in a complex and distributed monolith application that is hard to test and maintain.\u003c/p\u003e\n\n\u003cp\u003eThough Thoughtworks highlighted Lambda and other AWS services, the pinball situation can also occur with Azure, Google Cloud, and other providers. All major cloud providers offer services with similar capabilities. Hence, the serverless development best practices are relevant and applicable to all.\u003c/p\u003e\n\n\u003cp\u003eThe above condition occurs due to a poorly architected approach to employing functions to implement computational logic, data ingestion, data transformation, data transport, service mediation, and other activities without clear service boundaries. The dreadful outcome of a prolonged pinball situation is a tangled architecture, the serverless ball of mud, as shown in Figure 1.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/15figure1-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/15figure1-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 1: An entangled serverless architecture\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003ch3\u003eUnintentional increase in cloud cost\u003c/h3\u003e\n\n\u003cp\u003eWith FaaS functions, you only pay for the execution (if you don’t use some advanced features). However, implementing more functions than necessary increases your cloud cost and total cost of ownership (TCO).\u003c/p\u003e\n\n\u003cp\u003eWith most cloud providers, a function’s cost has two main parts:\u003c/p\u003e\n\n\u003cul\u003e\n\t\u003cli\u003eThe price for each request made to the cloud service to invoke the function\u003c/li\u003e\n\t\u003cli\u003eThe time to complete each invocation and the memory (RAM) allocated\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eLet’s say your function is\u003c/p\u003e\n\n\u003cul\u003e\n\t\u003cli\u003eAllocated with 1,024 MB of memory\u003c/li\u003e\n\t\u003cli\u003eInvoked 3 million times a month (100,000 invocations per day)\u003c/li\u003e\n\t\u003cli\u003eEach invocation executes for 10 milliseconds (ms) on average\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFor an \u003ca href=\"https://calculator.aws/#/createCalculator/Lambda\"\u003eAWS Lambda function\u003c/a\u003e deployed in the Europe Central Region, the above will cost 0.40 USD per month (with the free-tier allowance). The cost is the same for an \u003ca href=\"https://azure.microsoft.com/en-gb/pricing/calculator/\"\u003eAzure Function\u003c/a\u003e with the above configuration running in the Germany West Central Region.\u003c/p\u003e\n\n\u003cp\u003eHowever, if the average execution duration of the function were 10 seconds (instead of 10 ms), then the monthly cost of the AWS Lambda function would jump to 493 USD, and the Azure Function would increase to 474 USD.\u003c/p\u003e\n\n\u003cp\u003eNow, think of the cost savings if several such functions perform non-computational tasks that can be achieved by other means - i.e., in a function-less way!\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote\u003c/strong\u003e: The above Lambda cost is for the use of an x86 processor. By switching to the Arm processor, the price will be reduced to 395 USD.\u003c/em\u003e\u003c/p\u003e\n\n\u003ch3\u003eImpact on sustainable cloud operation\u003c/h3\u003e\n\n\u003cp\u003eSustainability is a crucial aspect of modern cloud operation. Consuming renewable energy, reducing carbon footprint, and achieving green energy targets are top priorities for cloud providers. Cloud providers invest in efficient power and cooling technologies and operate an efficient server population to achieve higher utilization. For this reason, \u003ca href=\"https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/sus_sus_hardware_a4.html\"\u003eAWS recommends using managed services\u003c/a\u003e for efficient cloud operation, as part of their Well-Architected Framework best practices for sustainability.\u003c/p\u003e\n\n\u003cp\u003eAs a service consumer, you are also responsible for sustainability. Hence, the major cloud providers have set out well-architected best practices for sustainability that promote a shared responsibility between the provider and its consumers.\u003c/p\u003e\n\n\u003cp\u003eWhile the cloud providers manage the resources for FaaS to achieve sustainability of the cloud, you have equal responsibility to operate the functions sustainably \u003cem\u003ein\u003c/em\u003e the cloud. This includes,\u003c/p\u003e\n\n\u003cul\u003e\n\t\u003cli\u003eThe optimal use of the number of functions\u003c/li\u003e\n\t\u003cli\u003eOptimizing the memory allocation of each function\u003c/li\u003e\n\t\u003cli\u003eOptimizing performance to the required level and not to the maximum\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhen you implement a FaaS function for unsuitable purposes or operate in a suboptimal way, you indirectly impact the three core elements of the cloud: compute, storage, and network. Each consumes energy for its operation.\u003c/p\u003e\n\n\u003ch3\u003eIncreasing your code liability\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026#34;All the code you ever write is business logic\u0026#34;. - Dr. Werner Vogels, CTO, Amazon.com.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAs a software engineer, you hear similar statements and arguments in the industry about program code.\u003c/p\u003e\n\n\u003cp\u003e\u0026#34;\u003cem\u003eCode is a liability, not an asset, for an organization\u003c/em\u003e\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003e\u0026#34;\u003cem\u003eThe code you write today becomes legacy tomorrow\u003c/em\u003e\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003e\u0026#34;\u003cem\u003eThe more code a company has, the more money it spends to maintain adding to its TCO\u003c/em\u003e\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003eRegardless of such arguments, one cannot avoid writing code - be it function code, data code, integration code, or infrastructure code. However, the focus here is on unnecessary and unwanted function code.\u003c/p\u003e\n\n\u003cp\u003eAs discussed earlier, the Lambda hammer mindset often drives engineers to implement a function instead of an alternate cloud service or feature. The function now becomes an unnecessary burden for the team to maintain.\u003c/p\u003e\n\n\u003cp\u003eWhen you think of a function, think beyond your joy of coding it - the testing, the CI/CD process, releasing, observing, and your cloud account’s concurrency limit, etc.\u003c/p\u003e\n\n\u003ch2\u003eHow to Develop a Low-code Mindset\u003c/h2\u003e\n\n\u003cp\u003eFor engineers new to serverless, equipping their minds to its needs can be challenging. Hence, you hear about the serverless mindset as a prerequisite to adopting serverless. This is because working with serverless requires a new way of thinking, developing, and operating applications in the cloud. You must think of serverless applications as orchestrations of managed cloud services knitted with infrastructure code.\u003c/p\u003e\n\n\u003ch3\u003eServerless as a technology ecosystem\u003c/h3\u003e\n\n\u003cp\u003eOften, engineers view serverless environments with a programming eye, ignoring the capabilities of the managed services and the roles and responsibilities of the people involved.\u003c/p\u003e\n\n\u003cp\u003eIn the book \u003cem\u003e\u003ca href=\"https://www.goodreads.com/book/show/182346447-serverless-development-on-aws\"\u003eServerless Development on AWS (O’Reilly, 2024)\u003c/a\u003e\u003c/em\u003e, which I co-authored with \u003ca href=\"https://level-out.com/\"\u003eLuke Hedger\u003c/a\u003e, we advise seeing serverless technology as an ecosystem that contains the cloud provider, FaaS, and other managed services, tools, frameworks, engineers, stakeholders, etc. This brings a \u003ca href=\"https://en.wikipedia.org/wiki/Sociotechnical_system\"\u003esociotechnical mindset\u003c/a\u003e to technology, which is vital to working with modern technology and engineering practices.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/10figure2-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/10figure2-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 2: The view of the serverless ecosystem\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003cp\u003eAnother way of viewing it is through systems thinking. Diana Montalion\u0026#39;s book \u003ca href=\"https://learning.oreilly.com/library/view/learning-systems-thinking/9781098151324/\"\u003e\u003cem\u003eLearning Systems Thinking (O’Reilly, 2024)\u003c/em\u003e\u003c/a\u003e states that a system is a group of interrelated hardware, software, people, organization(s), and other elements that interact and/or interdepend to serve a shared purpose.\u003c/p\u003e\n\n\u003ch3\u003eNot all microservices need functions\u003c/h3\u003e\n\n\u003cp\u003eWhen you build microservices, depending on your domain and your team’s bounded context, as explained in my talk, \u003ca href=\"https://www.infoq.com/articles/set-piece-strategy-sheen-brisals/\"\u003e\u003cem\u003eThe Set Piece Strategy\u003c/em\u003e, at QCon 2024\u003c/a\u003e, not all services perform computations that require functions. As you will learn below, the business logic of a service can be orchestrated and collaborated with other services via native integration and event-driven communication.\u003c/p\u003e\n\n\u003ch3\u003eFast flow teams seek quick turn around to incidents. Less is more for such teams.\u003c/h3\u003e\n\n\u003cp\u003eModern product teams that are stream-aligned (as advocated by \u003ca href=\"https://www.goodreads.com/book/show/44135420-team-topologies\"\u003eTeam Topologies\u003c/a\u003e) and autonomous develop and release new features and updates in quick iterations. Serverless is a great technology that enables fast flow.\u003c/p\u003e\n\n\u003cp\u003eAs the teams operate their workloads in the cloud, observing and remediating issues in production is crucial. The square of balance is a term used in \u003ca href=\"https://www.goodreads.com/book/show/182346447-serverless-development-on-aws\"\u003e\u003cem\u003eServerless Development on AWS (O’Reilly, 2024)\u003c/em\u003e\u003c/a\u003e to explain how the four activities of testing, delivering, observing, and recovery are key to achieving balance.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/10figure3-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/10figure3-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 3: The serverless square of balance for fast flow\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003cp\u003eHaving minimal code liability is advantageous when serverless teams operate in a fast-paced development environment. It reduces the potential sources of bugs and failure points and shifts more responsibility to the cloud provider.\u003c/p\u003e\n\n\u003ch2\u003eWhat is Functionless?\u003c/h2\u003e\n\n\u003cp\u003eIn a serverless context, the terms \u003cem\u003efunctionless\u003c/em\u003e, \u003cem\u003ecodeless\u003c/em\u003e, \u003cem\u003eLambda-less\u003c/em\u003e, \u003cem\u003eno-code\u003c/em\u003e, \u003cem\u003elow-code\u003c/em\u003e, etc., express the idea of reducing the number of FaaS functions in an application with native service integrations.\u003c/p\u003e\n\n\u003cp\u003eI first heard about \u003cem\u003eFunctionless\u003c/em\u003e in 2019 at the \u003ca href=\"https://helsinki.serverlessdays.io/2019/\"\u003eServerless Days conference in Helsinki\u003c/a\u003e. Realizing the need to educate engineers about the side effects of too many functions, I have been advocating in the community, reiterating the benefits of eliminating functions where feasible.\u003c/p\u003e\n\n\u003cp\u003eIn addition to understanding the nuances of cloud computing, a crucial part of architecting and developing serverless applications is thinking beyond FaaS and remembering that functions are a part of the serverless ecosystem, not all of it.\u003c/p\u003e\n\n\u003ch3\u003eDoesn’t functionless increase lock-in?\u003c/h3\u003e\n\n\u003cp\u003eThe moment a business decides to consume services from a cloud provider or a product from a vendor, it introduces some form of lock-in. Businesses are aware of this and consciously choose to grow their business with a stable and cordial partnership with the provider - not to switch products, services, and providers frequently.\u003c/p\u003e\n\n\u003cp\u003eIt is true that if you use native service integrations and cloud platform-specific features, your dependency increases. Even if you make the computational logic of a function cloud-agnostic, it is hard to make it pure agnostic. As you learned above, a function must collaborate with one or more cloud services to offer business functionality. When you focus on making a function cloud-agnostic, you are not capitalizing on the reasons for being in the cloud. It is counterintuitive and harms the business if it chooses a cloud provider and then decides to work against its core benefits.\u003c/p\u003e\n\n\u003ch2\u003eArchitecting serverless applications with fewer functions\u003c/h2\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026#34;Simplicity is better than elaborate embellishments. Sometimes, something simple is better than something advanced or complicated\u0026#34;. - From the web.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThough it is easy to advocate simplicity, arriving at simplicity is not always easy. It requires experience dealing with complex architectures, knowledge, and awareness of the areas where simplicity can be practiced.\u003c/p\u003e\n\n\u003cp\u003eYour experience building serverless applications helps you view architectures with a simple lens. This section will examine areas where you can use patterns to avoid functions and make your architecture functionless.\u003c/p\u003e\n\n\u003ch3\u003eHandling data\u003c/h3\u003e\n\n\u003cp\u003eAn advisory in the serverless community says \u003cem\u003eyou should use a function to transform data, not transport it\u003c/em\u003e. If you use a function to move data between services, you use it for the wrong purpose, or the cloud provider lacks a native feature.\u003c/p\u003e\n\n\u003cp\u003eData handling is a core part of the cloud, and modern data sets\u0026#39; volume and growth rate are exponential. From a cost and scale point of view, it is not advisable to employ functions for every data operation in such situations. Hence, you should find ways to leave the heavy lifting to the core cloud services.\u003c/p\u003e\n\n\u003cp\u003eTraditionally, databases refer mainly to relational database systems (RDBMS) and, to a lesser extent, other variants such as vector and graph data stores. However, several data storage options, such as relational or SQL, NoSQL, object, graph, vector, document, and more, are now available in the cloud.\u003c/p\u003e\n\n\u003cp\u003eIn addition to the above, services that ingest, buffer, and route messages and events also offer temporary storage. You can apply functionless and native operations for many of these service operations, and this must be considered in your architectural thinking.\u003c/p\u003e\n\n\u003ch4\u003eStoring and retrieving data\u003c/h4\u003e\n\n\u003cp\u003eMany engineers have the preconceived mindset that a function is needed to perform data operations. With such thinking, functions creep in where they have no role. The two places where a function is commonly used to transport data are API gateway backends and workflow orchestrations.\u003c/p\u003e\n\n\u003cp\u003eAs explained below, several ways exist to handle data operations without the help of functions.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eStoring API request payload in a data table\u003c/strong\u003e: Figure 4 shows a simple serverless pattern in which a function receives the API request payload, say, a new book title, and persists in a table. Most API gateways offer schema validation on the incoming data. Once validated, you can store the data from the API directly in the table using native service integration. Thus, the function in the middle becomes unnecessary.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/7figure4-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/7figure4-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 4: Eliminating unnecessary functions in data operation\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003cp\u003eLike above, you can perform fetching data from data tables to send as API response payload without a function in the middle.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eAtomic data counter operations without a function\u003c/strong\u003e: Amazon DynamoDB, for example, has no built-in feature to generate unique sequence numbers like traditional relational databases. However, this can be accomplished with the atomic counter concept in DynamoDB, as shown in Figure 5. If you have a service that generates unique values for orders, customer registrations, site visitors, etc., this can be achieved between the API and a DynamoDB table.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/6figure5-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/6figure5-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 5: Native service integration between API Gateway and DynamoDB table to generate sequence numbers\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003e{\n    \u0026#34;TableName\u0026#34;: \u0026#34;sequence-numbers\u0026#34;,\n    \u0026#34;Key\u0026#34;: {\n        \u0026#34;id\u0026#34;: {\n            \u0026#34;S\u0026#34;: \u0026#34;visitor\u0026#34;\n        }\n    },\n    \u0026#34;ExpressionAttributeValues\u0026#34;: {\n        \u0026#34;:val\u0026#34;: {\n            \u0026#34;N\u0026#34;: \u0026#34;1\u0026#34;\n        }\n    },\n    \u0026#34;UpdateExpression\u0026#34;: \u0026#34;ADD sequence :val\u0026#34;,\n    \u0026#34;ReturnValues\u0026#34;: \u0026#34;UPDATED_NEW\u0026#34;\n}\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eSample VTL script to perform the atomic counter increment.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eBuffering high-volume API requests\u003c/strong\u003e: Another widespread use case is handling spikey API requests and processing them asynchronously, as shown in Figure 6. In such situations, it is vital to control the load to protect the downstream systems. Adding a queue behind the API can be a buffer to control the data flow. In this scenario, the data is stored before processing, known as the \u003cem\u003e\u003ca href=\"https://www.jeremydaly.com/the-storage-first-pattern/\"\u003eStorage First pattern\u003c/a\u003e\u003c/em\u003e. It is common to see this pattern implemented with other data stores.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/5figure6-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/5figure6-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 6: API requests buffered in a queue for asynchronous processing\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003ch4\u003eData expiry\u003c/h4\u003e\n\n\u003cp\u003eOne traditional approach to purge expired data from databases is to run a task on a scheduler to query data with specific parameters and perform delete operations. Depending on the volume of data, such clean-up tasks can take minutes or hours to complete.\u003c/p\u003e\n\n\u003cp\u003eWhen engineers bring the above experience into serverless development, the apparent choice for querying and deleting data is with a suite of purpose-built functions. However, modern data stores offer automated data purging at no cost and without impacting performance. Opting for such native features avoids implementing functions.\u003c/p\u003e\n\n\u003cp\u003eFor example, \u003ca href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html\"\u003eAmazon DynamoDB has the option to set time-to-live (TTL)\u003c/a\u003e for every data item (record) in a table. Though some deletes may take up to 48 hours, it is far more efficient than handling programmatically by yourself. \u003ca href=\"https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/time-to-live\"\u003eAzure Cosmos DB\u003c/a\u003e also offers a similar TTL feature to remove unwanted data.\u003c/p\u003e\n\n\u003cp\u003eThe most popular object store in the cloud, \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html\"\u003eAmazon S3, supports data retention policies for data buckets\u003c/a\u003e. With data retention policies, you let S3 manage the lifecycle of data objects to either delete expired objects or move them to an archive or low-cost storage to comply with your business requirements.\u003c/p\u003e\n\n\u003cp\u003eUse a service’s native feature to perform data cleanup with every data store you work with. Beyond the benefits of dealing with fewer functions, this also brings sustainability benefits to your cloud operation. Though data is central to everything we do, not all data is valuable or remains valuable beyond a certain point. Hence, thinking about your data lifecycle is crucial to removing unwanted data and reducing compute storage, and network use.\u003c/p\u003e\n\n\u003ch3\u003eThinking beyond the CRUD Operations\u003c/h3\u003e\n\n\u003cp\u003eAn API implementation includes endpoints that perform typical operations, such as Creating, Reading, Updating, and Deleting (CRUD) data in a database system, aligning with the appropriate HTTP methods. Though every API contract and the invocation type - synchronous or asynchronous - can be categorized into one of those four distinct data operations, in modern distributed systems, the backend operations are not always strictly CRUD.\u003c/p\u003e\n\n\u003cp\u003eAs you saw earlier, when a synchronous API fetches a new order number, it performs an atomic data operation. However, the behavior need not be the same in an asynchronous invocation. For example, when a customer places an order, one or more services, owned and operated by several teams from multiple business domains, collaborate to fulfill the request. In this case, not every activity within or across various services needs to be atomic.\u003c/p\u003e\n\n\u003cp\u003eFrom a modularity and extensibility point of view, a monolith function comprising complex logic interacting with several services to coordinate tasks is not an ideal solution. Service orchestration is the apt design pattern to consider in such scenarios. Instead of a function, a service workflow becomes the backend orchestrator, as shown in Figure 7. Cloud services such as \u003ca href=\"https://aws.amazon.com/step-functions\"\u003eAWS Step Functions\u003c/a\u003e and \u003ca href=\"https://azure.microsoft.com/services/logic-apps\"\u003eAzure Logic Apps\u003c/a\u003e are prominent workflow orchestrators available today.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"articles/functionless-serverless-mindset/en/resources/4figure7-1735816460315.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/articles/functionless-serverless-mindset/en/resources/4figure7-1735816460315.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eFigure 7: A workflow that initiates async operations and handles an API request\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003ch3\u003eFiltering and transforming events\u003c/h3\u003e\n\n\u003cp\u003eThe popular fully managed cloud services that ingest and deliver events offer native integration with many other services. Event filtering, transformation, archiving, and delivery to several destinations are some of the core features of these services that eliminate the need for custom functions.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/eventbridge/\"\u003eAmazon EventBridge\u003c/a\u003e, \u003ca href=\"https://azure.microsoft.com/services/event-grid\"\u003eAzure EventGrid\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/pubsub?hl=en\"\u003eGoogle Cloud Pub/Sub\u003c/a\u003e, etc., are cloud services that provide event transport and act as event brokers to easily coordinate with multiple applications in a loosely coupled event-driven communication.\u003c/p\u003e\n\n\u003ch2\u003eLow-code Integration Trade-Offs\u003c/h2\u003e\n\n\u003cp\u003eOne primary motivation for using cloud services is to delegate as much as possible to the cloud provider. In this regard, native service integration that reduces unnecessary function code must be a factor when architecting serverless and cloud applications.\u003c/p\u003e\n\n\u003cp\u003eHowever, while developing a functionless mindset, it is equally important to be aware of some limitations and trade-offs, as highlighted below.\u003c/p\u003e\n\n\u003cul\u003e\n\t\u003cli\u003eMost native service integration acts as a black box without visibility of the integration code at runtime. This can make investigating bugs challenging.\u003c/li\u003e\n\t\u003cli\u003eIn AWS, for example, integration code is written using \u003ca href=\"https://velocity.apache.org/engine/1.7/user-guide.html\"\u003eVelocity Template Language (VTL)\u003c/a\u003e. Because VTL\u0026#39;s syntax differs from familiar programming languages, learning and becoming familiar with it takes time.\u003c/li\u003e\n\t\u003cli\u003eThough API gateway and management services support native integration with several cloud services, each target service\u0026#39;s integration format is not uniform.\u003c/li\u003e\n\t\u003cli\u003eKnowing the differences in permitted data payload sizes between the source and target services is crucial to preventing processing failures.\u003c/li\u003e\n\t\u003cli\u003eLike the payload size, the service timeout and throttling limits can also differ between the integrated services.\u003c/li\u003e\n\t\u003cli\u003eSometimes, you may require a function for nonfunctional operations, such as security checks on parts of the request context data.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026#34;The first step toward change is awareness. The second step is acceptance\u0026#34;. - Nathaniel Branden.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAs an evolution of the cloud, serverless technology enables organizations to quickly add value by removing the unnecessary baggage of server and hardware management. However, while building applications using serverless technology, you must continue exploring ways to simplify your architecture and operational overheads.\u003c/p\u003e\n\n\u003cp\u003eIn this article, capturing every use case that reduces the FaaS footprint is impossible. It intends to raise awareness. According to industry feedback, newly adopted serverless teams will likely make costly architectures and implementation mistakes. Though this is understandable to some extent, the motivation should be to avoid such errors by employing apt patterns and principles from the beginning.\u003c/p\u003e\n\n\u003cp\u003eOne size does not fit all. The business domains and use cases differ from team to team. While implementing a pattern - functionless or another - you must first analyze its applicability. When you know the possibilities, you can take the necessary actions to simplify your architecture.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Sheen-Brisals\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSheen Brisals\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\n                            \n                            \n\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "27 min read",
  "publishedTime": "2025-01-03T00:00:00Z",
  "modifiedTime": null
}
