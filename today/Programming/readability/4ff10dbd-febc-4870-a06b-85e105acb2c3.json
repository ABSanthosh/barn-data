{
  "id": "4ff10dbd-febc-4870-a06b-85e105acb2c3",
  "title": "Looking back at the first year of the Gemini era",
  "link": "https://developers.googleblog.com/en/looking-back-at-the-first-year-of-the-gemini-era/",
  "description": "The range of family of Gemini models has expanded in the past year in response to developer needs, introducing faster and more cost-effective models, and enhancing tools in Google AI Studio.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Lauren Usui",
  "length": 4907,
  "excerpt": "The range of family of Gemini models has expanded in the past year in response to developer needs, introducing faster and more cost-effective models, and enhancing tools in Google AI Studio.",
  "siteName": "",
  "favicon": "",
  "text": "One year ago, we introduced the world to Gemini, our family of frontier multimodal models that set a high bar, achieving state-of-the-art results on major AI benchmarks. In the past 12 months, we've collaborated with ML experts and developers to build amazing things with our AI models. Today, on the first anniversary of Gemini's launch, we’re taking a minute to reflect on the progress we’ve made together.Building with GeminiMillions of developers around the world are using Google AI Studio and the Gemini API to innovate—launching groundbreaking new applications and enhancing existing ones with powerful AI capabilities.We’re particularly inspired by the ways you’re making AI helpful for your own users. Thousands of you entered our Gemini API Developer Competition and built impactful, creative, and useful apps, like the grand prize-winning Jayu personal assistant and people's choice award Vite Vere app that helps people achieve greater independence. Sorry, your browser doesn't support playback for this video Winners of the Gemini API Developer Competition The evolution of Gemini is a direct result of your feedback and the applications you’ve developed. While Gemini 1.5 Pro delivered impressive performance and long-context windows, we recognized your need for a faster and more cost-effective option for your apps. That’s why we introduced Gemini 1.5 Flash, which has rapidly become our most popular model. We’re also accelerating our learning by continuously releasing experimental models to understand what serves you best. And your response to Gemini Nano’s on-device capabilities has been overwhelmingly positive, with thousands joining our Chrome hackathon and Android preview.To empower developers, we've improved both our models and our tools. The Gemini API is now even more powerful with the addition of function calling and search grounding. Plus, Google AI Studio now supports a wider range of models, starting with the ability to quickly evaluate Gemma open models, and we’ll be adding more soon.Creation of the GemmaverseWe're committed to making powerful AI accessible to everyone. That's why we launched Gemma, a family of open models built on the same foundation as Gemini. Gemma gives you the freedom to customize models with your own data and the flexibility to run them on your own hardware, thanks to a range of accessible size options. Gemma 2, available in 2B, 9B, and 27B parameter versions, offers impressive performance, even outperforming larger models, while remaining widely accessible—the 2B model even runs on mobile devices! We're constantly working to make Gemma models even more useful, releasing new innovative research models like DataGemma, GemmaScope, and most recently, PaliGemma 2.Models like Navarasa, a community Gemma variant tuned on 9 Indic languages, are enabling developers access to language specific models for their users. It's heartening to see the vibrant community that's grown around Gemma language models, with over 50,000 model variations now available on Hugging Face. This collaborative spirit is driving innovation across industries, and it's particularly exciting to see how Gemma is helping break down language barriers. The Gemma tokenizer makes it possible to fine-tune the model for the world’s languages, enabling the Kaggle community to create Gemma models to foster global understanding.Developing with Gemini assistanceIn addition to providing access to Gemini and Gemma models directly, we integrated Gemini throughout our developer tools to help you be more productive and build better apps. Android Studio, Chrome Dev Tools, Colab, Firebase, Google Cloud and IDX, all use Gemini models in a variety of ways to help you write high-quality code, answer questions, and more. Additionally, Gemini is available in your favorite IDE with Gemini Code Assist, including now in GitHub CoPilot.We're expanding the role of AI beyond code assistance to support the entire development lifecycle. For instance, Gemini in Android Studio can automate routine tasks, generate boilerplate code, and even predict potential bugs. Sorry, your browser doesn't support playback for this video Gemini in Android Studio The future of AI in software development is incredibly bright, with more innovation to come in the days, weeks and months ahead. Our experimental data science agent, showcased at I/O this year, offers a glimpse into this future and we're actively working to bring more to you.Excitement for the futureWe're committed to pushing the boundaries of what's possible with AI, and we have some exciting developments in the pipeline that we can't wait to share with you soon.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Blog-metadata-gemini-anniversary_.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"kl52s\"\u003eOne year ago, we \u003ca href=\"https://blog.google/technology/ai/google-gemini-ai/\"\u003eintroduced\u003c/a\u003e the world to Gemini, our family of frontier multimodal models that set a high bar, achieving state-of-the-art results on major AI benchmarks. In the past 12 months, we\u0026#39;ve collaborated with ML experts and developers to build amazing things with our AI models. Today, on the first anniversary of Gemini\u0026#39;s launch, we’re taking a minute to reflect on the progress we’ve made together.\u003c/p\u003e\u003ch2 data-block-key=\"1tova\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBuilding with Gemini\u003c/h2\u003e\u003cp data-block-key=\"bb1iq\"\u003eMillions of developers around the world are using \u003ca href=\"http://aistudio.google.com/\"\u003eGoogle AI Studio\u003c/a\u003e and the \u003ca href=\"http://ai.google.dev/gemini-api/docs\"\u003eGemini API\u003c/a\u003e to innovate—launching groundbreaking new applications and enhancing existing ones with powerful AI capabilities.\u003c/p\u003e\u003cp data-block-key=\"cipad\"\u003eWe’re particularly inspired by the ways you’re \u003ca href=\"http://ai.google.dev/showcase\"\u003emaking AI helpful for your own users\u003c/a\u003e. Thousands of you entered our \u003ca href=\"http://ai.google.dev/competition\"\u003eGemini API Developer Competition\u003c/a\u003e and built \u003ca href=\"https://developers.googleblog.com/en/announcing-the-winners-of-the-gemini-api-developer-competition/\"\u003eimpactful, creative, and useful apps\u003c/a\u003e, like the grand prize-winning \u003ca href=\"https://youtu.be/shnW3VerkiM\"\u003eJayu personal assistant\u003c/a\u003e and people\u0026#39;s choice award \u003ca href=\"https://youtu.be/yul0L5YWBp0\"\u003eVite Vere\u003c/a\u003e app that helps people achieve greater independence.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-z1pxd5lk_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/0177-AIfD-AI-Competition-Winner-Promos-Almanac-1x1-Nov21_1.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n        \n            \u003cp\u003e\n                Winners of the Gemini API Developer Competition\n            \u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"kl52s\"\u003eThe evolution of Gemini is a direct result of your feedback and the applications you’ve developed. While \u003ca href=\"https://deepmind.google/technologies/gemini/pro/\"\u003eGemini 1.5 Pro\u003c/a\u003e delivered impressive performance and long-context windows, we recognized your need for a faster and more cost-effective option for your apps. That’s why we introduced \u003ca href=\"https://deepmind.google/technologies/gemini/flash/\"\u003eGemini 1.5 Flash,\u003c/a\u003e which has rapidly become our most popular model. We’re also accelerating our learning by continuously \u003ca href=\"https://x.com/JeffDean/status/1865079431544607089\"\u003ereleasing experimental models\u003c/a\u003e to understand what serves you best. And your response to \u003ca href=\"https://deepmind.google/technologies/gemini/nano/\"\u003eGemini Nano\u003c/a\u003e’s on-device capabilities has been overwhelmingly positive, with thousands joining our \u003ca href=\"https://developer.chrome.com/blog/ai-challenge\"\u003eChrome hackathon\u003c/a\u003e and \u003ca href=\"https://developer.android.com/ai/gemini-nano\"\u003eAndroid preview\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"lrlm\"\u003eTo empower developers, we\u0026#39;ve improved both our models and our tools. The \u003ca href=\"http://ai.google.dev/gemini-api/docs\"\u003eGemini API\u003c/a\u003e is now even more powerful with the addition of \u003ca href=\"https://ai.google.dev/gemini-api/docs/function-calling\"\u003efunction calling\u003c/a\u003e and \u003ca href=\"https://ai.google.dev/gemini-api/docs/grounding\"\u003esearch grounding\u003c/a\u003e. Plus, \u003ca href=\"http://aistudio.google.com/\"\u003eGoogle AI Studio\u003c/a\u003e now supports a wider range of models, starting with the ability to quickly evaluate Gemma open models, and we’ll be adding more soon.\u003c/p\u003e\u003ch2 data-block-key=\"9u5uj\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eCreation of the Gemmaverse\u003c/h2\u003e\u003cp data-block-key=\"24mnk\"\u003eWe\u0026#39;re committed to making powerful AI accessible to everyone. That\u0026#39;s why we launched \u003ca href=\"http://ai.google.dev/gemma\"\u003eGemma\u003c/a\u003e, a family of open models built on the same foundation as Gemini. Gemma gives you the freedom to customize models with your own data and the flexibility to run them on your own hardware, thanks to a range of accessible size options. \u003ca href=\"https://blog.google/technology/developers/google-gemma-2/\"\u003eGemma 2\u003c/a\u003e, available in 2B, 9B, and 27B parameter versions, offers impressive performance, even outperforming larger models, while remaining widely accessible—the 2B model even runs on mobile devices! We\u0026#39;re constantly working to make Gemma models even more useful, releasing new innovative research models like \u003ca href=\"https://research.google/blog/grounding-ai-in-reality-with-a-little-help-from-data-commons/\"\u003eDataGemma\u003c/a\u003e, \u003ca href=\"https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/\"\u003eGemmaScope\u003c/a\u003e, and most recently, \u003ca href=\"https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning\"\u003ePaliGemma 2\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"bhk0l\"\u003eModels like \u003ca href=\"https://www.youtube.com/watch?v=ZhExnit0UdM\"\u003eNavarasa\u003c/a\u003e, a community Gemma variant tuned on 9 Indic languages, are enabling developers access to language specific models for their users.\u003c/p\u003e\n\u003c/div\u003e    \u003cdiv\u003e\n    \u003cp data-block-key=\"kl52s\"\u003eIt\u0026#39;s heartening to see the vibrant community that\u0026#39;s grown around Gemma language models, with over 50,000 model variations now available on Hugging Face. This collaborative spirit is driving innovation across industries, and it\u0026#39;s particularly exciting to see how Gemma is helping \u003ca href=\"https://www.youtube.com/watch?v=ZhExnit0UdM\"\u003ebreak down language barriers\u003c/a\u003e. The Gemma tokenizer makes it possible to \u003ca href=\"https://developers.googleblog.com/en/advancing-multilingual-ai-with-gemma-2-and-a-150k-challenge/\"\u003efine-tune the model\u003c/a\u003e for the world’s languages, enabling the \u003ca href=\"http://kaggle.com/\"\u003eKaggle\u003c/a\u003e community to create \u003ca href=\"https://www.kaggle.com/c/gemma-language-tuning\"\u003eGemma models\u003c/a\u003e to foster global understanding.\u003c/p\u003e\u003ch2 data-block-key=\"6p8sn\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eDeveloping with Gemini assistance\u003c/h2\u003e\u003cp data-block-key=\"3jhqb\"\u003eIn addition to providing access to Gemini and Gemma models directly, we integrated Gemini throughout our developer tools to help you be more productive and build better apps. \u003ca href=\"https://developer.android.com/gemini-in-android\"\u003eAndroid Studio\u003c/a\u003e, \u003ca href=\"https://developer.chrome.com/docs/devtools/ai-assistance/quickstart\"\u003eChrome Dev Tools\u003c/a\u003e, \u003ca href=\"http://colab.google/\"\u003eColab\u003c/a\u003e, \u003ca href=\"https://firebase.google.com/docs/gemini-in-firebase\"\u003eFirebase\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/products/gemini/code-assist\"\u003eGoogle Cloud\u003c/a\u003e and \u003ca href=\"https://developers.google.com/idx/guides/code-with-gemini-in-idx\"\u003eIDX\u003c/a\u003e, all use Gemini models in a variety of ways to help you write high-quality code, answer questions, and more. Additionally, Gemini is available in your favorite IDE with \u003ca href=\"https://cloud.google.com/products/gemini/code-assist\"\u003eGemini Code Assist\u003c/a\u003e, including now in \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/gemini-models-on-github-copilot\"\u003eGitHub CoPilot\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"9s5mu\"\u003eWe\u0026#39;re expanding the role of AI beyond code assistance to support the entire development lifecycle. For instance, \u003ca href=\"https://android-developers.googleblog.com/2024/10/whats-new-in-gemini-in-android.html\"\u003eGemini in Android Studio\u003c/a\u003e can automate routine tasks, generate boilerplate code, and even predict potential bugs.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-8u2horv__thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/image5-ezgif.com-gif-to-mp4-converter.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n        \n            \u003ca href=\"https://android-developers.googleblog.com/2024/10/whats-new-in-gemini-in-android.html\" target=\"_blank\" rel=\"noopener\"\u003e\n                \u003cp\u003e\n                    Gemini in Android Studio\n                \u003c/p\u003e\n            \u003c/a\u003e\n        \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"kl52s\"\u003eThe future of AI in software development is incredibly bright, with more innovation to come in the days, weeks and months ahead. Our experimental \u003ca href=\"https://labs.google.com/code/dsa\"\u003edata science agent\u003c/a\u003e, showcased at I/O this year, offers a glimpse into this future and we\u0026#39;re actively working to bring more to you.\u003c/p\u003e\u003ch2 data-block-key=\"dfigf\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eExcitement for the future\u003c/h2\u003e\u003cp data-block-key=\"coqbl\"\u003eWe\u0026#39;re committed to pushing the boundaries of what\u0026#39;s possible with AI, and we have some exciting developments in the pipeline that we can\u0026#39;t wait to share with you soon.\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-12-06T00:00:00Z",
  "modifiedTime": null
}
