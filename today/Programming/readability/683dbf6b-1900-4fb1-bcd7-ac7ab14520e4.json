{
  "id": "683dbf6b-1900-4fb1-bcd7-ac7ab14520e4",
  "title": "Build an ML app pipeline with GitLab Model Registry using MLflow",
  "link": "https://about.gitlab.com/blog/2024/09/17/build-an-ml-app-pipeline-with-gitlab-model-registry-using-mlflow",
  "description": "",
  "author": "Gufran Yeşilyurt, OBSS",
  "published": "2024-09-17T00:00:00.000Z",
  "source": "https://about.gitlab.com/atom.xml",
  "categories": null,
  "byline": "Gufran Yeşilyurt, OBSS, Péter Bozsó",
  "length": 7524,
  "excerpt": "Learn how to manage your ML apps entirely through GitLab with this tutorial. Also discover the role machine learning operations, or MLOps, plays in automating the DevSecOps lifecycle.",
  "siteName": "GitLab",
  "favicon": "https://about.gitlab.com/blog/nuxt-images/ico/favicon-192x192.png?cache=2022041",
  "text": "Editor's note: From time to time, we invite members of our partner community to contribute to the GitLab Blog. Thanks to Gufran Yeşilyurt, a DevOps consultant at OBSS Technology, for co-creating with us. This tutorial will walk you through setting up an MLOps pipeline with GitLab Model Registry, utilizing MLflow. This will be a great starting point to manage your ML apps entirely through GitLab. But first, it is crucial to understand why we need MLOps and what GitLab offers. MLOps, or machine learning operations, is a critical practice for managing and automating the lifecycle of machine learning models, from development to deployment and maintenance. Its importance lies in addressing the complexity and dynamism of machine learning workflows, which involve not just software development but also data management, model training, testing, deployment, and continuous monitoring. MLOps ensures that models are reproducible, scalable, and maintainable, facilitating collaboration between data scientists, machine learning engineers, and operations teams. By incorporating MLOps, organizations can streamline the deployment process, reduce time to market, and improve the reliability and performance of their machine learning applications. The necessity of MLOps arises from the unique challenges posed by machine learning projects. Unlike traditional software development, machine learning involves handling large datasets, experimenting with various models, and continuously updating models based on new data and feedback. Without proper operations, managing these aspects becomes cumbersome, leading to potential issues like model drift, where the model's performance degrades over time due to changes in the underlying data. MLOps provides a structured approach to monitor and manage these changes, ensuring that models remain accurate and effective. Moreover, it introduces automation in various stages, such as data preprocessing, model training, and deployment, thereby reducing manual errors and enhancing efficiency. GitLab's features play a pivotal role in implementing MLOps effectively. GitLab provides an integrated platform that combines source code management, CI/CD pipelines, tracking and collaboration tools, making it ideal for managing machine learning projects. With GitLab, teams can leverage version control to track changes in both code and data, ensuring reproducibility and transparency. The CI/CD pipelines in GitLab automate the testing and deployment of machine learning models, allowing for continuous integration and continuous delivery. This automation not only speeds up the deployment process but also ensures consistency and reliability in the models being deployed. Additionally, GitLab's collaboration features, such as merge requests and code reviews, facilitate better communication and coordination among team members, ensuring that everyone is aligned and any issues are promptly addressed. Prerequisites: basic knowledge of GitLab pipelines basic knowledge of MLflow a Kubernetes cluster Dockerfile This tutorial includes instructions to: Set up environment variables of MLflow Train and log candidates at merge request Register the most successful candidate Dockerize and deploy an ML app with the registered model In this example, to decide whether to provide the user a loan, we make use of Random Forest Classifier, Decision Tree, and Logistic Regression. At the end of this showcase, we will have a web application that utilizes machine learning to respond to the user. To reproduce this example in your own GitLab environment, you can read the rest of this article or follow the video below. You can find the source code of this example in these OBSS repositories. Set up environment variables of MLflow On the host where the code is executed, set the environment variables for tracking URI and token. This might be a remote host, CI pipeline, or your local environment. When they are set, you can call mlflow.set_experiment(\"\u003cexperiment_name\u003e\"). As a reference: export MLFLOW_TRACKING_URI=\"\u003cyour gitlab endpoint\u003e/api/v4/projects/\u003cyour project id\u003e/ml/mlflow\" export MLFLOW_TRACKING_TOKEN=\"\u003cyour_access_token\u003e\" Note: If the training code contains the call to mlflow.set_tracking_uri(), remove it. Train and log candidates at merge request In your model train code, you can use MLflow methods to log metrics, artifacts, and parameters. You can also divide the train steps into pipeline stages if you are comfortable with that part. In this example, one Python file will be used for both training and report generation. mlflow.log_params(params) mlflow.log_metrics(metrics_data) mlflow.log_artifact(artifacts) You can then create the necessary pipeline to train the experiment. By adding the relevant rules, you can trigger this pipeline manually in merge requests and observe the report generated as MR Note. When the pipeline is finished, you can see the details about the candidate in Analyze \u003e Model Experiments. Register the most successful candidate According to the measurements you have made, we can register the most successful candidate (may be the one with the highest accuracy value) with the Run ID of the candidate. But first, we need to create a model and its version in Registry. I created these steps in separate stages and components (because I may need these steps in other projects). You should be careful to use semantic versioning when versioning. Register source model parameters and metrics source_candidate = client.get_run(source_candidate_id) params = { k: v for k, v in source_candidate.data.params.items() } metric = { k: v for k, v in source_candidate.data.metrics.items() } model_version = client.get_model_version(model_name, version) run_id = model_version.run_id model_class = \"\" for name, value in params.items(): client.log_param(run_id, name, value) if name == \"Class\": model_class = value for name, value in metric.items(): client.log_metric(run_id, name, value) After logging the parameters and metrics, you can register the artifacts as you did in the train step. You may want to manually enter the inputs of the relevant steps as a variable in the pipeline. CI/CD components I have used CI/CD components because they provide a structured environment for managing machine learning workflows. These components enable reusability by allowing teams to store and share standardized scripts, models, and datasets, ensuring that previous work can be easily accessed, modified, and redeployed in future projects, thus accelerating development and reducing redundancy. Learn more about CI/CD components and the CI/CD Catalog. Dockerize and deploy an ML app with the registered model In this project, while registering the model, I also register the pkl file as an artifact and then create the docker image with that artifact and send it to GitLab Container Registry. You can now access your Docker image from the Container Registry and deploy it to your environment with the method you want. Resources Model experiments MLflow client compatibility CI/CD components Building GitLab with GitLab: Why there is no MLOps without DevSecOps Credits: This tutorial and the corresponding sample projects were created and generously shared with the community by OBSS. OBSS is an EMEA-based channel partner of GitLab. They have deep expertise across the whole DevSecOps lifecycle and amongst many other things, they are more than happy to support customers with migrating their MLOps workloads to GitLab.",
  "image": "https://images.ctfassets.net/r9o86ar0p03f/3lH4gZFVIGCndksN6Rlg85/a6b99b2d87dc52678ba976e7b3360555/blog-image-template-1800x945__26_.png?fm=webp\u0026w=820\u0026h=500",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-v-b794d8fe=\"\" data-v-7488832a=\"\" data-v-74bd29c6=\"\"\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eEditor\u0026#39;s note: From time to time, we invite members of our partner community to contribute to the GitLab Blog. Thanks to Gufran Yeşilyurt, a DevOps consultant at OBSS Technology, for co-creating with us.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis tutorial will walk you through setting up an MLOps pipeline with GitLab Model Registry, utilizing MLflow. This will be a great starting point to manage your ML apps entirely through GitLab. But first, it is crucial to understand why we need MLOps and what GitLab offers.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://about.gitlab.com/direction/modelops/mlops/#overview\"\u003eMLOps\u003c/a\u003e, or machine learning operations, is a critical practice for managing and automating the lifecycle of machine learning models, from development to deployment and maintenance. Its importance lies in addressing the complexity and dynamism of machine learning workflows, which involve not just software development but also data management, model training, testing, deployment, and continuous monitoring.\u003c/p\u003e\n\u003cp\u003eMLOps ensures that models are reproducible, scalable, and maintainable, facilitating collaboration between data scientists, machine learning engineers, and operations teams. By incorporating MLOps, organizations can streamline the deployment process, reduce time to market, and improve the reliability and performance of their machine learning applications.\u003c/p\u003e\n\u003cp\u003eThe necessity of MLOps arises from the unique challenges posed by machine learning projects. Unlike traditional software development, machine learning involves handling large datasets, experimenting with various models, and continuously updating models based on new data and feedback.\u003c/p\u003e\n\u003cp\u003eWithout proper operations, managing these aspects becomes cumbersome, leading to potential issues like model drift, where the model\u0026#39;s performance degrades over time due to changes in the underlying data. MLOps provides a structured approach to monitor and manage these changes, ensuring that models remain accurate and effective. Moreover, it introduces automation in various stages, such as data preprocessing, model training, and deployment, thereby reducing manual errors and enhancing efficiency.\u003c/p\u003e\n\u003cp\u003eGitLab\u0026#39;s features play a pivotal role in implementing MLOps effectively. GitLab provides an integrated platform that combines source code management, \u003ca href=\"https://about.gitlab.com/topics/ci-cd/\"\u003eCI/CD pipelines\u003c/a\u003e, tracking and collaboration tools, making it ideal for managing machine learning projects.\u003c/p\u003e\n\u003cp\u003eWith GitLab, teams can leverage version control to track changes in both code and data, ensuring reproducibility and transparency. The CI/CD pipelines in GitLab automate the testing and deployment of machine learning models, allowing for continuous integration and continuous delivery. This automation not only speeds up the deployment process but also ensures consistency and reliability in the models being deployed.\u003c/p\u003e\n\u003cp\u003eAdditionally, GitLab\u0026#39;s collaboration features, such as merge requests and code reviews, facilitate better communication and coordination among team members, ensuring that everyone is aligned and any issues are promptly addressed.\u003c/p\u003e\n\u003cp\u003ePrerequisites:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ebasic knowledge of GitLab pipelines\u003c/li\u003e\n\u003cli\u003ebasic knowledge of MLflow\u003c/li\u003e\n\u003cli\u003ea Kubernetes cluster\u003c/li\u003e\n\u003cli\u003eDockerfile\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis tutorial includes instructions to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#set-up-environment-variables-of-mlflow\"\u003eSet up environment variables of MLflow\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#train-and-log-candidates-at-merge-request\"\u003eTrain and log candidates at merge request\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#register-the-most-successful-candidate\"\u003eRegister the most successful candidate\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dockerize-and-deploy-an-ml-app-with-the-registered-model\"\u003eDockerize and deploy an ML app with the registered model\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this example, to decide whether to provide the user a loan, we make use of Random Forest Classifier, Decision Tree, and Logistic Regression. At the end of this showcase, we will have a web application that utilizes machine learning to respond to the user.\u003c/p\u003e\n\u003cp\u003eTo reproduce this example in your own GitLab environment, you can read the rest of this article or follow the video below. You can find the source code of this example in \u003ca href=\"https://gitlab.com/gitlab-partners-public/obss\"\u003ethese OBSS repositories\u003c/a\u003e.\u003c/p\u003e\n\u003cfigure\u003e\n  \u003ciframe src=\"https://www.youtube.com/embed/grNJAp1xAi0?si=Bf9CAP9lB1uWErOZ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\u003e \u003c/iframe\u003e\n\u003c/figure\u003e\n\n\u003ch2 id=\"set-up-environment-variables-of-mlflow\" tabindex=\"-1\"\u003eSet up environment variables of MLflow \u003ca href=\"#set-up-environment-variables-of-mlflow\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOn the host where the code is executed, set the environment variables for tracking URI and token. This might be a remote host, CI pipeline, or your local environment. When they are set, you can call \u003ccode\u003emlflow.set_experiment(\u0026#34;\u0026lt;experiment_name\u0026gt;\u0026#34;)\u003c/code\u003e. As a reference:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MLFLOW_TRACKING_URI=\u0026#34;\u0026lt;your gitlab endpoint\u0026gt;/api/v4/projects/\u0026lt;your project id\u0026gt;/ml/mlflow\u0026#34;\nexport MLFLOW_TRACKING_TOKEN=\u0026#34;\u0026lt;your_access_token\u0026gt;\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e If the training code contains the call to \u003ccode\u003emlflow.set_tracking_uri()\u003c/code\u003e, remove it.\u003c/p\u003e\n\u003ch2 id=\"train-and-log-candidates-at-merge-request\" tabindex=\"-1\"\u003eTrain and log candidates at merge request \u003ca href=\"#train-and-log-candidates-at-merge-request\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn your model train code, you can use MLflow methods to log metrics, artifacts, and parameters. You can also divide the train steps into pipeline stages if you are comfortable with that part. In this example, one Python file will be used for both training and report generation.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emlflow.log_params(params)\nmlflow.log_metrics(metrics_data)\nmlflow.log_artifact(artifacts)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can then create the necessary pipeline to train the experiment. By adding the relevant rules, you can trigger this pipeline manually in merge requests and observe the report generated as MR Note.\u003c/p\u003e\n\u003cp\u003eWhen the pipeline is finished, you can see the details about the candidate in \u003cstrong\u003eAnalyze \u0026gt; Model Experiments\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/40DMSl5Z8wqSMaf5vZEROw/21482f0888b05f535cff3c9d4553187d/Screenshot_1.png\" alt=\"details about the candidate in the finished pipeline\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"register-the-most-successful-candidate\" tabindex=\"-1\"\u003eRegister the most successful candidate \u003ca href=\"#register-the-most-successful-candidate\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eAccording to the measurements you have made, we can register the most successful candidate (may be the one with the highest accuracy value) with the Run ID of the candidate.\u003c/p\u003e\n\u003cp\u003eBut first, we need to create a model and its version in Registry. I created these steps in separate stages and components (because I may need these steps in other projects). You should be careful to use semantic versioning when versioning.\u003c/p\u003e\n\u003ch3 id=\"register-source-model-parameters-and-metrics\" tabindex=\"-1\"\u003eRegister source model parameters and metrics \u003ca href=\"#register-source-model-parameters-and-metrics\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003esource_candidate = client.get_run(source_candidate_id)\nparams = { k: v for k, v in source_candidate.data.params.items() }\nmetric = { k: v for k, v in source_candidate.data.metrics.items() }\n\nmodel_version = client.get_model_version(model_name, version)\nrun_id = model_version.run_id\nmodel_class = \u0026#34;\u0026#34;\nfor name, value in params.items():\n    client.log_param(run_id, name, value)\n    if name == \u0026#34;Class\u0026#34;:\n        model_class = value\n\nfor name, value in metric.items():\n    client.log_metric(run_id, name, value)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter logging the parameters and metrics, you can \u003ca href=\"https://gitlab.com/gitlab-partners-public/obss/mlops-loan-prediction/-/blob/main/register_candidate.py\"\u003eregister the artifacts\u003c/a\u003e as you did in the train step.\u003c/p\u003e\n\u003cp\u003eYou may want to manually enter the inputs of the relevant steps as \u003ca href=\"https://gitlab.com/gitlab-partners-public/obss/components/-/blob/main/templates/register-candidate.yml\"\u003ea variable in the pipeline\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"cicd-components\" tabindex=\"-1\"\u003eCI/CD components \u003ca href=\"#cicd-components\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eI have used \u003ca href=\"https://docs.gitlab.com/ee/ci/components/\"\u003eCI/CD components\u003c/a\u003e because they provide a structured environment for managing machine learning workflows. These components enable reusability by allowing teams to store and share standardized scripts, models, and datasets, ensuring that previous work can be easily accessed, modified, and redeployed in future projects, thus accelerating development and reducing redundancy.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://about.gitlab.com/blog/2024/05/08/ci-cd-catalog-goes-ga-no-more-building-pipelines-from-scratch/\"\u003eLearn more about CI/CD components and the CI/CD Catalog\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"dockerize-and-deploy-an-ml-app-with-the-registered-model\" tabindex=\"-1\"\u003eDockerize and deploy an ML app with the registered model \u003ca href=\"#dockerize-and-deploy-an-ml-app-with-the-registered-model\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIn this project, while registering the model, I also register the pkl file as an artifact and then create the docker image with that artifact and send it to \u003ca href=\"https://about.gitlab.com/blog/2024/07/23/next-generation-gitlab-container-registry-goes-ga/\"\u003eGitLab Container Registry\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can now access your Docker image from the Container Registry and deploy it to your environment with the method you want.\u003c/p\u003e\n\u003ch2 id=\"resources\" tabindex=\"-1\"\u003eResources \u003ca href=\"#resources\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.gitlab.com/ee/user/project/ml/experiment_tracking/\"\u003eModel experiments\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.gitlab.com/ee/user/project/ml/experiment_tracking/mlflow_client.html\"\u003eMLflow client compatibility\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.gitlab.com/ee/ci/components/\"\u003eCI/CD components\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://about.gitlab.com/blog/2023/10/05/there-is-no-mlops-without-devsecops/\"\u003eBuilding GitLab with GitLab: Why there is no MLOps without DevSecOps\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eCredits:\u003c/strong\u003e\nThis tutorial and the corresponding sample projects were created and generously shared with the community by \u003ca href=\"https://obss.tech/en/\"\u003eOBSS\u003c/a\u003e. OBSS is an EMEA-based channel partner of GitLab. They have deep expertise across the whole DevSecOps lifecycle and amongst many other things, they are more than happy to support customers with migrating their MLOps workloads to GitLab.\u003c/em\u003e\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2024-09-17T00:00:00Z",
  "modifiedTime": null
}
