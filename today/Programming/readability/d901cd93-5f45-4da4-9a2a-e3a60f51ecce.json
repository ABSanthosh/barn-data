{
  "id": "d901cd93-5f45-4da4-9a2a-e3a60f51ecce",
  "title": "Embedding-Based Retrieval for Airbnb Search",
  "link": "https://medium.com/airbnb-engineering/embedding-based-retrieval-for-airbnb-search-aabebfc85839?source=rss----53c7c27702d5---4",
  "description": "",
  "author": "Huiji Gao",
  "published": "Wed, 19 Mar 2025 17:02:45 GMT",
  "source": "https://medium.com/feed/airbnb-engineering",
  "categories": [
    "engineering",
    "machine-learning",
    "embedding",
    "ai",
    "retrieval-system"
  ],
  "byline": "Huiji Gao",
  "length": 8424,
  "excerpt": "Our journey in applying embedding-based retrieval techniques to build an accurate and scalable candidate retrieval system for Airbnb Homes search Authors: Mustafa (Moose) Abdool, Soumyadip Banerjee…",
  "siteName": "The Airbnb Tech Blog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "Embedding-Based Retrieval for Airbnb SearchOur journey in applying embedding-based retrieval techniques to build an accurate and scalable candidate retrieval system for Airbnb Homes searchAuthors: Mustafa (Moose) Abdool, Soumyadip Banerjee, Karen Ouyang, Do-Kyum Kim, Moutupsi Paul, Xiaowei Liu, Bin Xu, Tracy Yu, Hui Gao, Yangbo Zhu, Huiji Gao, Liwei He, Sanjeev KatariyaIntroductionSearch plays a crucial role in helping Airbnb guests find the perfect stay. The goal of Airbnb Search is to surface the most relevant listings for each user’s query — but with millions of available homes, that’s no easy task. It’s especially difficult when searches include large geographic areas (like California or France) or high-demand destinations (like Paris or London). Recent innovations — such as flexible date search, which allows guests to explore stays without fixed check-in and check-out dates — have added yet another layer of complexity to ranking and finding the right results.To tackle these challenges, we need a system that can retrieve relevant homes while also being scalable enough (in terms of latency and compute) to handle queries with a large candidate count. In this blog post, we share our journey in building Airbnb’s first-ever Embedding-Based Retrieval (EBR) search system. The goal of this system is to narrow down the initial set of eligible homes into a smaller pool, which can then be scored by more compute-intensive machine learning models later in the search ranking process.Figure 1: The general stages and scale for the various types of ranking models used in Airbnb SearchWe’ll explore three key challenges in building this EBR system: (1) constructing training data, (2) designing the model architecture, and (3) developing an online serving strategy using Approximate Nearest Neighbor (ANN) solutions.Training Data ConstructionThe first step in building our EBR system was training a machine learning model to map both homes and de-identified search queries into numerical vectors. To achieve this, we built a training data pipeline (Figure 3) that leveraged contrastive learning — a strategy that involves identifying pairs of positive- and negative-labeled homes for a given query. During training, the model learns to map a query, a positive home, and a negative home into a numerical vector, such that the similarity between the query and the positive home is much higher than the similarity between the query and the negative home.To construct these pairs, we devised a sampling method based on user trips. This was an important design decision, since users on Airbnb generally undergo a multi-stage search journey. Data shows that before making a final booking, users tend to perform multiple searches and take various actions — such as clicking into a home’s details, reading reviews, or adding a home to a wishlist. As such, it was crucial to develop a strategy that captures this entire multi-stage journey and accounts for the diverse types of listings a user might explore.Diving deeper, we first grouped all historical queries of users who made bookings, using key query parameters such as location, number of guests, and length of stay — our definition of a “trip.” For each trip, we analyzed all searches performed by the user, with the final booked listing as the positive label. To construct (positive, negative) pairs, we paired this booked listing with other homes the user had seen but not booked. Negative labels were selected from homes the user encountered in search results, along with those they had interacted with more intentfully — such as by wishlisting — but ultimately did not book. This choice of negative labels was key: Randomly sampling homes made the problem too easy and resulted in poor model performance.Figure 2: Example of constructing (positive, negative) pairs for a given user journey. The booked home is always treated as a positive. Negatives are selected from homes that appeared in the search result (and were potentially interacted with) but that the user did not end up booking.Figure 3: Example of overall data pipeline used to construct training data for the EBR model.Model ArchitectureThe model architecture followed a traditional two-tower network design. One tower (the listing tower) processes features about the home listing itself — such as historical engagement, amenities, and guest capacity. The other tower (the query tower) processes features related to the search query — such as the geographic search location, number of guests, and length of stay. Together, these towers generate the embeddings for home listings and search queries, respectively.A key design decision here was choosing features such that the listing tower could be computed offline on a daily basis. This enabled us to pre-compute the home embeddings in a daily batch job, significantly reducing online latency, since only the query tower had to be evaluated in real-time for incoming search requests.Figure 4: Two-tower architecture as used in the EBR model. Note that the listing tower is computed offline daily for all homes.Online ServingThe final step in building our EBR system was choosing the infrastructure for online serving. We explored a number of approximate nearest neighbor (ANN) solutions and narrowed them down to two main candidates: inverted file index (IVF) and hierarchical navigable small worlds (HNSW). While HNSW performed slightly better in terms of evaluation metrics — using recall as our main evaluation metric — we ultimately found that IVF offered the best trade-off between speed and performance.The core reason for this is the high volume of real-time updates per second for Airbnb home listings, as pricing and availability data is frequently updated. This caused the memory footprint of the HNSW index to grow too large. In addition, most Airbnb searches include filters, especially geographic filters. We found that parallel retrieval with HNSW alongside filters resulted in poor latency performance.In contrast, the IVF solution, where listings are clustered beforehand, only required storing cluster centroids and cluster assignments within our search index. At serving time, we simply retrieve listings from the top clusters by treating the cluster assignments as a standard search filter, making integration with our existing search system quite straightforward.Figure 5: Overall serving flow using IVF. Homes are clustered beforehand and, during online serving, homes are retrieved from the closest clusters to the query embedding.In this approach, our choice of similarity function in the EBR model itself ended up having interesting implications. We explored both dot product and Euclidean distance; while both performed similarly from a model perspective, using Euclidean distance produced much more balanced clusters on average. This was a key insight, as the quality of IVF retrieval is highly sensitive to cluster size uniformity: If one cluster had too many homes, it would greatly reduce the discriminative power of our retrieval system.We hypothesize that this imbalance arises with dot product similarity because it inherently only considers the direction of feature vectors while ignoring their magnitudes — whereas many of our underlying features are based on historical counts, making magnitude an important factor.Figure 6: Example of the distribution of cluster sizes when using dot product vs. Euclidean distance as a similarity measure. We found that Euclidean distance produced much more balanced cluster sizes.ResultsThe EBR system described in this post was fully launched in both Search and Email Marketing production and led to a statistically-significant gain in overall bookings when A/B tested. Notably, the bookings lift from this new retrieval system was on par with some of the largest machine learning improvements to our search ranking in the past two years.The key improvement over the baseline was that our EBR system effectively incorporated query context, allowing homes to be ranked more accurately during retrieval. This ultimately helped us display more relevant results to users, especially for queries with a high number of eligible results.AcknowledgmentsWe would like to especially thank the entire Search and Knowledge Infrastructure \u0026 ML Infrastructure org (led by Yi Li) and Marketing Technology org (led by Michael Kinoti) for their great collaborations throughout this project!",
  "image": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*dhEL1kHnOpCWnqJa",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"2231\" data-testid=\"storyTitle\"\u003e\u003cstrong\u003eEmbedding-Based Retrieval for Airbnb Search\u003c/strong\u003e\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca rel=\"noopener follow\" href=\"https://medium.com/@huiji.gao?source=post_page---byline--aabebfc85839---------------------------------------\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Huiji Gao\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*QJBw9p2GFxG32ybruPxGMQ.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"ccd8\"\u003eOur journey in applying embedding-based retrieval techniques to build an accurate and scalable candidate retrieval system for Airbnb Homes search\u003c/p\u003e\u003cp id=\"c492\"\u003eAuthors: \u003ca href=\"https://www.linkedin.com/in/mustafa-moose-abdool-8aab037a/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMustafa (Moose) Abdool\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/soumyadip-banerjee-75991b42/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSoumyadip Banerjee\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/kouyang1/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKaren Ouyang\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/do-kyum-kim-9a810417/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDo-Kyum Kim\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/moutupsi-paul/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMoutupsi Paul\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/xiaowei-liu-60415841/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eXiaowei Liu\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/bin-xu-96253aa5/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBin Xu\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/tracy-xiaoxi-yu/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTracy Yu\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/hui-gao-275a924/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHui Gao\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/yangbo-zhu/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eYangbo Zhu\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/huiji-gao/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHuiji Gao\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/liweihe/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLiwei He\u003c/a\u003e, \u003ca href=\"https://www.linkedin.com/in/sanjeevkatariya/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSanjeev Katariya\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"9f6c\"\u003eIntroduction\u003c/h2\u003e\u003cp id=\"54e7\"\u003eSearch plays a crucial role in helping Airbnb guests find the perfect stay. The goal of Airbnb Search is to surface the most relevant listings for each user’s query — but with millions of available homes, that’s no easy task. It’s especially difficult when searches include large geographic areas (like California or France) or high-demand destinations (like Paris or London). Recent innovations — such as \u003cem\u003eflexible date search\u003c/em\u003e, which allows guests to explore stays without fixed check-in and check-out dates — have added yet another layer of complexity to ranking and finding the right results.\u003c/p\u003e\u003cp id=\"93c9\"\u003eTo tackle these challenges, we need a system that can retrieve relevant homes while also being scalable enough (in terms of latency and compute) to handle queries with a large candidate count. In this blog post, we share our journey in building Airbnb’s first-ever Embedding-Based Retrieval (EBR) search system. The goal of this system is to narrow down the initial set of eligible homes into a smaller pool, which can then be scored by more compute-intensive machine learning models later in the search ranking process.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"7e29\"\u003e\u003cstrong\u003eFigure 1:\u003c/strong\u003e The general stages and scale for the various types of ranking models used in Airbnb Search\u003c/p\u003e\u003cp id=\"ed08\"\u003eWe’ll explore three key challenges in building this EBR system: (1) constructing training data, (2) designing the model architecture, and (3) developing an online serving strategy using Approximate Nearest Neighbor (ANN) solutions.\u003c/p\u003e\u003ch2 id=\"7ffa\"\u003eTraining Data Construction\u003c/h2\u003e\u003cp id=\"89fc\"\u003eThe first step in building our EBR system was training a machine learning model to map both homes and de-identified search queries into numerical vectors. To achieve this, we built a training data pipeline (Figure 3) that leveraged contrastive learning — a strategy that involves identifying pairs of positive- and negative-labeled homes for a given query. During training, the model learns to map a query, a positive home, and a negative home into a numerical vector, such that the similarity between the query and the positive home is much higher than the similarity between the query and the negative home.\u003c/p\u003e\u003cp id=\"3d7e\"\u003eTo construct these pairs, we devised a sampling method based on user trips. This was an important design decision, since users on Airbnb generally undergo a multi-stage search journey. Data shows that before making a final booking, users tend to perform multiple searches and take various actions — such as clicking into a home’s details, reading reviews, or adding a home to a wishlist. As such, it was crucial to develop a strategy that captures this entire multi-stage journey and accounts for the diverse types of listings a user might explore.\u003c/p\u003e\u003cp id=\"1079\"\u003eDiving deeper, we first grouped all historical queries of users who made bookings, using key query parameters such as location, number of guests, and length of stay — our definition of a “trip.” For each trip, we analyzed all searches performed by the user, with the final booked listing as the positive label. To construct (positive, negative) pairs, we paired this booked listing with other homes the user had seen but not booked. Negative labels were selected from homes the user encountered in search results, along with those they had interacted with more intentfully — such as by wishlisting — but ultimately did not book. This choice of negative labels was key: Randomly sampling homes made the problem too easy and resulted in poor model performance.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"f1d7\"\u003e\u003cstrong\u003eFigure 2: \u003c/strong\u003eExample of constructing (positive, negative) pairs for a given user journey. The booked home is always treated as a positive. Negatives are selected from homes that appeared in the search result (and were potentially interacted with) but that the user did not end up booking.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"a19a\"\u003e\u003cstrong\u003eFigure 3: \u003c/strong\u003eExample of overall data pipeline used to construct training data for the EBR model.\u003c/p\u003e\u003ch2 id=\"a19c\"\u003eModel Architecture\u003c/h2\u003e\u003cp id=\"7c66\"\u003eThe model architecture followed a traditional two-tower network design. One tower (the \u003cem\u003elisting tower\u003c/em\u003e) processes features about the home listing itself — such as historical engagement, amenities, and guest capacity. The other tower (the \u003cem\u003equery tower\u003c/em\u003e) processes features related to the search query — such as the geographic search location, number of guests, and length of stay. Together, these towers generate the embeddings for home listings and search queries, respectively.\u003c/p\u003e\u003cp id=\"133b\"\u003eA key design decision here was choosing features such that the listing tower could be computed offline on a daily basis. This enabled us to pre-compute the home embeddings in a daily batch job, significantly reducing online latency, since only the query tower had to be evaluated in real-time for incoming search requests.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"65cc\"\u003e\u003cstrong\u003eFigure 4: \u003c/strong\u003eTwo-tower architecture as used in the EBR model. Note that the listing tower is computed offline daily for all homes.\u003c/p\u003e\u003ch2 id=\"951a\"\u003eOnline Serving\u003c/h2\u003e\u003cp id=\"6409\"\u003eThe final step in building our EBR system was choosing the infrastructure for online serving. We explored a number of approximate nearest neighbor (ANN) solutions and narrowed them down to two main candidates: inverted file index (IVF) and hierarchical navigable small worlds (HNSW). While HNSW performed slightly better in terms of evaluation metrics — using recall as our main evaluation metric — we ultimately found that IVF offered the best trade-off between speed and performance.\u003c/p\u003e\u003cp id=\"6dce\"\u003eThe core reason for this is the high volume of real-time updates per second for Airbnb home listings, as pricing and availability data is frequently updated. This caused the memory footprint of the HNSW index to grow too large. In addition, most Airbnb searches include filters, especially geographic filters. We found that parallel retrieval with HNSW alongside filters resulted in poor latency performance.\u003c/p\u003e\u003cp id=\"5742\"\u003eIn contrast, the IVF solution, where listings are clustered beforehand, only required storing cluster centroids and cluster assignments within our search index. At serving time, we simply retrieve listings from the top clusters by treating the cluster assignments as a standard search filter, making integration with our existing search system quite straightforward.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"0041\"\u003e\u003cstrong\u003eFigure 5: \u003c/strong\u003eOverall serving flow using IVF. Homes are clustered beforehand and, during online serving, homes are retrieved from the closest clusters to the query embedding.\u003c/p\u003e\u003cp id=\"1ffa\"\u003eIn this approach, our choice of similarity function in the EBR model itself ended up having interesting implications. We explored both dot product and Euclidean distance; while both performed similarly from a model perspective, using Euclidean distance produced much more balanced clusters on average. This was a key insight, as the quality of IVF retrieval is highly sensitive to cluster size uniformity: If one cluster had too many homes, it would greatly reduce the discriminative power of our retrieval system.\u003c/p\u003e\u003cp id=\"d4a9\"\u003eWe hypothesize that this imbalance arises with dot product similarity because it inherently only considers the direction of feature vectors while ignoring their magnitudes — whereas many of our underlying features are based on historical counts, making magnitude an important factor.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"9d29\"\u003e\u003cstrong\u003eFigure 6: \u003c/strong\u003eExample of the distribution of cluster sizes when using dot product vs. Euclidean distance as a similarity measure. We found that Euclidean distance produced much more balanced cluster sizes.\u003c/p\u003e\u003ch2 id=\"474a\"\u003eResults\u003c/h2\u003e\u003cp id=\"fd5f\"\u003eThe EBR system described in this post was fully launched in both Search and Email Marketing production and led to a statistically-significant gain in overall bookings when A/B tested. Notably, the bookings lift from this new retrieval system was on par with some of the largest machine learning improvements to our search ranking in the past two years.\u003c/p\u003e\u003cp id=\"3fc9\"\u003eThe key improvement over the baseline was that our EBR system effectively incorporated query context, allowing homes to be ranked more accurately during retrieval. This ultimately helped us display more relevant results to users, especially for queries with a high number of eligible results.\u003c/p\u003e\u003ch2 id=\"bc88\"\u003eAcknowledgments\u003c/h2\u003e\u003cp id=\"d216\"\u003eWe would like to especially thank the entire Search and Knowledge Infrastructure \u0026amp; ML Infrastructure org (led by \u003ca href=\"https://www.linkedin.com/in/yi-li-755a6b24/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eYi Li\u003c/a\u003e) and Marketing Technology org (led by \u003ca href=\"https://www.linkedin.com/in/michael-kinoti-7a309215/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMichael Kinoti\u003c/a\u003e) for their great collaborations throughout this project!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-03-19T17:02:45.08Z",
  "modifiedTime": null
}
