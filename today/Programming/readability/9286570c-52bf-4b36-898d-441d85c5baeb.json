{
  "id": "9286570c-52bf-4b36-898d-441d85c5baeb",
  "title": "Making instagram.com faster: Part 3 — cache first",
  "link": "https://instagram-engineering.com/making-instagram-com-faster-part-3-cache-first-6f3f130b9669?source=rss----37dc2a3034f2---4",
  "description": "",
  "author": "Glenn Conner",
  "published": "Fri, 11 Oct 2019 00:04:26 GMT",
  "source": "https://instagram-engineering.com/feed/",
  "categories": [
    "instagram",
    "javascript",
    "redux",
    "react",
    "web-performance"
  ],
  "byline": "Glenn Conner",
  "length": 5568,
  "excerpt": "In recent years instagram.com has seen a lot of changes — we’ve launched stories, filters, creation tools, notifications, and direct messaging as well as a myriad of other features and enhancements…",
  "siteName": "Instagram Engineering",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "In recent years instagram.com has seen a lot of changes — we’ve launched stories, filters, creation tools, notifications, and direct messaging as well as a myriad of other features and enhancements. However, as the product grew, a side effect was that our web performance began to slow. Over the last year we made a conscious effort to improve this. This ongoing effort has thus far resulted in almost 50% cumulative improvement to our feed page load time. This series of blog posts will outline some of the work we’ve done that led to these improvements. In part 1 we talked about prefetching data and in part 2 we talked about improving performance by pushing data directly to the client rather than waiting for the client to request the data.Cache firstSince we’re already pushing data to the client at the earliest possible time in the page load — the only faster way to get data to the client would be to not have to fetch or push any data at all. We can do this using a cache-first rendering approach, though this does mean that we have to display stale feed data to users for a short period of time. With this approach, when the page is loaded, we immediately present users with a cached copy of their previous feed and stories tray, and then replace it with fresh data once it’s available.We use Redux to manage state on instagram.com, so at a high level the way we implemented this was to store a subset of our Redux store on the client in an indexedDB table, and then rehydrate the store when the page first loads. However, because of the asynchronous nature of indexedDB access, server data fetching, and user interactions, we can run into problems where the user interacts with the cached state, but then we want to ensure that those interactions are still applied to the new state when it arrives from the server.For example, if we were to handle caching in a naive way we could run into the following problem: We begin loading from cache and from the network concurrently and since the cached feed is ready first, we display it to the user. The user then proceeds to like a post, but once the network response for the latest feed comes back it overwrites that post with a copy that doesn’t include the like action that the user applied to the cached copy (see the diagram below).Race conditions when the user interacts with cached data (Redux actions in green, state in grey)To solve this issue, we needed a way to apply interactions to the cached state, but also store those interactions so they can be replayed later over the new state from the server. If you’ve ever used Git or similar source control systems before, this problem might seem familiar. If we think of the cached feed state as a branch, and the server feed response as master, what we effectively want to do is to do a rebase operation, applying the commits (likes, comments etc.) from our local branch onto the head of master. This brings us to the following design:On page load, we send a request for the new data (or wait for it to be pushed)Create a staged subset of the Redux stateWhile the request/push is pending, we store any dispatched actionsOnce the request resolves, we apply the action with the new data and any actions that have been pending to the staged stateWhen the staged state is committed, we simply replace the current state with the staged one.Fixing interaction race conditions with staging (Redux actions in green, state in grey)By having a staging state, all the existing reducer behavior can be reused. It also keeps the staged state (which has the most recent data) separate from the current state. Also, since staging is implemented using Redux, we just need to dispatch actions to use it!APIThe staging API consists of two main functions: stagingAction \u0026 stagingCommit (as well as a couple of others for handling reverts and edge cases that we won't cover here).stagingAction accepts a promise that resolves an action to be dispatched to the staged state. It initializes the staging state and keeps track of any actions that have been dispatched since it was initialized. In the source control analogy we can think of this as creating a local branch as any actions that take place will now be queued and applied over the staged state when the new data arrives.stagingCommit commits the staging state to the current state. If any async actions on the staging state are pending, it will wait before committing. This is similar to a rebase in source control terms, in that we apply all our local changes (from the cache branch) on top of master (the new data from the server), leaving our local branch up to date.To enable staging, we wrap the root reducer with a reducer enhancer that handles the stagingCommit action and applies the staged actions to the new state. To use all this, we just need to dispatch the relevant actions and everything is handled for us. For example, if we want to fetch a new feed and apply it to a staged state, we can do something similar to the following:Using cache-first rendering for both feed posts and the stories tray led to a 2.5% and 11% improvement in respective display done times and bought the user experience more in-line with what is available on the native iOS and android Instagram apps.Stay tuned for part 4In part 4 we’ll cover how we reduced the size of our codebase and improved its performance through code size and execution optimizations. If you want to learn more about this work or are interested joining one of our engineering teams, please visit our careers page, follow us on Facebook or on Twitter.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*NGABlwJjUR2g0T23xTvWoQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ca href=\"https://medium.com/@mr_sharpoblunto?source=post_page-----6f3f130b9669--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Glenn Conner\" src=\"https://miro.medium.com/v2/resize:fill:88:88/0*w7Dexcjl8a_rHczk.png\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003ca href=\"https://instagram-engineering.com/?source=post_page-----6f3f130b9669--------------------------------\" rel=\"noopener  ugc nofollow\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Instagram Engineering\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*CPgwLHR6jno_tOmF0--7eg.jpeg\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp id=\"0ede\"\u003eIn recent years \u003ca href=\"http://instagram.com\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003einstagram.com\u003c/a\u003e has seen a lot of changes — we’ve launched stories, filters, creation tools, notifications, and direct messaging as well as a myriad of other features and enhancements. However, as the product grew, a side effect was that our web performance began to slow. Over the last year we made a conscious effort to improve this. This ongoing effort has thus far resulted in almost 50% cumulative improvement to our feed page load time. This series of blog posts will outline some of the work we’ve done that led to these improvements. In \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://instagram-engineering.com/making-instagram-com-faster-part-1-62cc0c327538\"\u003epart 1\u003c/a\u003e we talked about prefetching data and in \u003ca rel=\"noopener ugc nofollow\" target=\"_blank\" href=\"https://instagram-engineering.com/making-instagram-com-faster-part-2-f350c8fba0d4\"\u003epart 2\u003c/a\u003e we talked about improving performance by pushing data directly to the client rather than waiting for the client to request the data.\u003c/p\u003e\u003ch2 id=\"8bc3\"\u003eCache first\u003c/h2\u003e\u003cp id=\"5f4b\"\u003eSince we’re already pushing data to the client at the earliest possible time in the page load — the only faster way to get data to the client would be to not have to fetch or push any data at all. We can do this using a cache-first rendering approach, though this does mean that we have to display stale feed data to users for a short period of time. With this approach, when the page is loaded, we immediately present users with a cached copy of their previous feed and stories tray, and then replace it with fresh data once it’s available.\u003c/p\u003e\u003cp id=\"6c64\"\u003eWe use Redux to manage state on instagram.com, so at a high level the way we implemented this was to store a subset of our Redux store on the client in an indexedDB table, and then rehydrate the store when the page first loads. However, because of the asynchronous nature of indexedDB access, server data fetching, and user interactions, we can run into problems where the user interacts with the cached state, but then we want to ensure that those interactions are still applied to the new state when it arrives from the server.\u003c/p\u003e\u003cp id=\"06a1\"\u003eFor example, if we were to handle caching in a naive way we could run into the following problem: We begin loading from cache and from the network concurrently and since the cached feed is ready first, we display it to the user. The user then proceeds to like a post, but once the network response for the latest feed comes back it overwrites that post with a copy that doesn’t include the like action that the user applied to the cached copy (see the diagram below).\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eRace conditions when the user interacts with cached data (Redux actions in green, state in grey)\u003c/figcaption\u003e\u003c/figure\u003e\u003cdiv id=\"0bd4\"\u003e\u003cp\u003eTo solve this issue, we needed a way to apply interactions to the cached state, but also store those interactions so they can be replayed later over the new state from the server. If you’ve ever used Git or similar source control systems before, this problem might seem familiar. If we think of the cached feed state as a branch, and the server feed response as master, what we effectively want to do is to do a rebase operation, applying the commits (likes, comments etc.) from our local branch onto the head of master.\u003c/p\u003e\u003cp\u003e  This brings us to the following design:\u003c/p\u003e\u003c/div\u003e\u003cul\u003e\u003cli id=\"bd86\"\u003eOn page load, we send a request for the new data (or wait for it to be pushed)\u003c/li\u003e\u003cli id=\"621c\"\u003eCreate a staged subset of the Redux state\u003c/li\u003e\u003cli id=\"e4af\"\u003eWhile the request/push is pending, we store any dispatched actions\u003c/li\u003e\u003cli id=\"5645\"\u003eOnce the request resolves, we apply the action with the new data and any actions that have been pending to the staged state\u003c/li\u003e\u003cli id=\"4687\"\u003eWhen the staged state is committed, we simply replace the current state with the staged one.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eFixing interaction race conditions with staging (Redux actions in green, state in grey)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"c49f\"\u003eBy having a staging state, all the existing reducer behavior can be reused. It also keeps the staged state (which has the most recent data) separate from the current state. Also, since staging is implemented using Redux, we just need to dispatch actions to use it!\u003c/p\u003e\u003ch2 id=\"965a\"\u003eAPI\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"7165\"\u003eThe staging API consists of two main functions: \u003ccode\u003estagingAction\u003c/code\u003e \u0026amp; \u003ccode\u003estagingCommit\u003c/code\u003e (as well as a couple of others for handling reverts and edge cases that we won\u0026#39;t cover here).\u003c/p\u003e\u003cp id=\"e16f\"\u003e\u003ccode\u003estagingAction\u003c/code\u003e accepts a promise that resolves an action to be dispatched to the staged state. It initializes the staging state and keeps track of any actions that have been dispatched since it was initialized. In the source control analogy we can think of this as creating a local branch as any actions that take place will now be queued and applied over the staged state when the new data arrives.\u003c/p\u003e\u003cp id=\"924a\"\u003e\u003ccode\u003estagingCommit\u003c/code\u003e commits the staging state to the current state. If any async actions on the staging state are pending, it will wait before committing. This is similar to a rebase in source control terms, in that we apply all our local changes (from the cache branch) on top of master (the new data from the server), leaving our local branch up to date.\u003c/p\u003e\u003cp id=\"7c19\"\u003eTo enable staging, we wrap the root reducer with a reducer enhancer that handles the stagingCommit action and applies the staged actions to the new state. To use all this, we just need to dispatch the relevant actions and everything is handled for us. For example, if we want to fetch a new feed and apply it to a staged state, we can do something similar to the following:\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"3f4d\"\u003eUsing cache-first rendering for both feed posts and the stories tray led to a 2.5% and 11% improvement in respective display done times and bought the user experience more in-line with what is available on the native iOS and android Instagram apps.\u003c/p\u003e\u003ch2 id=\"e55c\"\u003eStay tuned for part 4\u003c/h2\u003e\u003cp id=\"defb\"\u003eIn part 4 we’ll cover how we reduced the size of our codebase and improved its performance through code size and execution optimizations. If you want to learn more about this work or are interested joining one of our engineering teams, please visit our \u003ca href=\"https://www.facebook.com/careers/jobs/?q=instagram\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecareers page\u003c/a\u003e, follow us \u003ca href=\"https://www.facebook.com/instagramengineering/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eon Facebook\u003c/a\u003e or \u003ca href=\"https://twitter.com/instagrameng\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eon Twitter\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2019-10-11T00:04:26.097Z",
  "modifiedTime": null
}
