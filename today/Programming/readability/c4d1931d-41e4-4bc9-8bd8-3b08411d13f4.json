{
  "id": "c4d1931d-41e4-4bc9-8bd8-3b08411d13f4",
  "title": "OpenAI Launches New API, SDK, and Tools to Develop Custom Agents",
  "link": "https://www.infoq.com/news/2025/03/openai-responses-api-agents-sdk/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "OpenAI has announced the new Responses API, the Agents SDK, and observability tools to address the challenges that creating production-ready agents pose, such as building custom orchestration, and handling prompt iteration across complex, multi-step tasks. By Sergio De Simone",
  "author": "Sergio De Simone",
  "published": "Sat, 15 Mar 2025 17:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "ChatGPT",
    "GPT-4",
    "OpenAI",
    "Agents",
    "AI, ML \u0026 Data Engineering",
    "Development",
    "news"
  ],
  "byline": "Sergio De Simone",
  "length": 4194,
  "excerpt": "OpenAI has announced the new Responses API, the Agents SDK, and observability tools to address the challenges that creating production-ready agents pose, such as building custom orchestration, and han",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250306064810/apple-touch-icon.png",
  "text": "OpenAI has announced the new Responses API, the Agents SDK, and observability tools to address the challenges that creating production-ready agents pose, such as building custom orchestration, and handling prompt iteration across complex, multi-step tasks. OpenAI says agents will soon become integral to the workforce, enhancing productivity across industries, by accomplishing complex tasks using advanced capabilities such as reasoning and multi-modal interactions. The new tools launched by OpenAI aim to make it easier for developers to build agentic workflows using the OpenAI platform. The Responses API combines chat completions with assistant capabilities and should take precedence over the Chat Completions API and the Assistants API for new projects. We believe the Responses API will provide a more flexible foundation for developers building agentic applications. With a single Responses API call, developers will be able to solve increasingly complex tasks using multiple tools and model turns. The new API also provides built-in support to external tools including web search, local file search, and computer control using mouse and keyboard. Additionally, it provides several improvements that will make its use more straightforward based on developer feedback on the previous models, including a unified design, simpler polymorphism, improved streaming, and several SDK helpers. For Web search, the Responses API leverages the same models used for ChatGPT search, GPT-4o search preview and GPT-4o mini search preview. The models scored 90% and 88% accuracy on the SimpleQA benchmark, which is significantly better than \"plain-vanilla\" GPT models performance (comprised between 15% and 63%). However, the computer use tool fares at 38.1% on the OSWorld benchmark, which suggests the model is not yet highly reliable for automating tasks on operating systems. While both the Chat Completions API and the Assistants API will remain available for now, with OpenAI committed to enhancing the former with new models and features, the company has already announced that the Assistants API will be deprecated next year. Along with the Responses API, OpenAI has also launched the new Agents SDK aimed at orchestrating agentic workflows by defining distinct agents, managing control transfer between them (handoffs), defining safety checks for input and output to prevent irrelevant, harmful, or undesirable behavior (guardrails), and visualizing traces to observe agents. The Agents SDK is suitable for various real-world applications, including customer support automation, multi-step research, content generation, code review, and sales prospecting. The Agents SDK supports all current OpenAI models, including o1, o3-mini, GPT-4.5, GPT-4o, and GPT-4o-mini. It also allows developers to augment their agents with external and persistent knowledge represented through vector stores and the Embeddings API. Relying on the Responses API, the Agents SDK supports the same external tools to search the Web, local files, or control a computer. The Agents SDK supersedes its experimental orchestration agent Swarm and is compatible with any Chat Completions-style API, including the Responses API and third-party APIs. Among community reactions, some Hacker News (HN) readers expressed their sentiment that OpenAI's move away from the Chat Completions API is dictated by \"non-technical\" reasons and brings the risk of lock-in with their platform. In the same line, some readers suggest that the phasing out of the Assistant API indicates that a good approach is not rewriting code for the Responses API, but rather creating a wrapper so you have a chance to replace the underlying LLM in case you need it. On another front, several HN readers pointed out that adopting the Agents SDK or any other agentic middleware means you are basically \"outsourcing\" your state management and business logic to a third party whereas you may prefer to keep the LLM-component as small as possible and build your own logic around it. About the Author Sergio De Simone",
  "image": "https://res.infoq.com/news/2025/03/openai-responses-api-agents-sdk/en/headerimage/openai-responses-agents-1742057096199.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://openai.com/index/new-tools-for-building-agents/\"\u003eOpenAI has announced the new Responses API, the Agents SDK, and observability tools\u003c/a\u003e to address the challenges that creating production-ready agents pose, such as building custom orchestration, and handling prompt iteration across complex, multi-step tasks.\u003c/p\u003e\n\n\u003cp\u003eOpenAI says agents will soon become integral to the workforce, enhancing productivity across industries, by accomplishing complex tasks using advanced capabilities such as reasoning and multi-modal interactions. The new tools launched by OpenAI aim to make it easier for developers to build agentic workflows using the OpenAI platform.\u003c/p\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://platform.openai.com/docs/quickstart?api-mode=responses\"\u003eResponses API\u003c/a\u003e combines chat completions with assistant capabilities and should take precedence over the \u003ca href=\"https://platform.openai.com/docs/guides/text-generation\"\u003eChat Completions API\u003c/a\u003e and the \u003ca href=\"https://platform.openai.com/docs/assistants/overview\"\u003eAssistants API\u003c/a\u003e for new projects.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eWe believe the Responses API will provide a more flexible foundation for developers building agentic applications. With a single Responses API call, developers will be able to solve increasingly complex tasks using multiple tools and model turns.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe new API also provides built-in support to external tools including \u003ca href=\"https://platform.openai.com/docs/guides/tools-web-search\"\u003eweb search\u003c/a\u003e, \u003ca href=\"https://platform.openai.com/docs/guides/tools-file-search\"\u003elocal file search\u003c/a\u003e, and \u003ca href=\"https://platform.openai.com/docs/guides/tools-computer-use\"\u003ecomputer control\u003c/a\u003e using mouse and keyboard. Additionally, it provides several improvements that will make its use more straightforward based on developer feedback on the previous models, including a unified design, simpler polymorphism, improved streaming, and several SDK helpers.\u003c/p\u003e\n\n\u003cp\u003eFor Web search, the Responses API leverages the same models used for ChatGPT search, GPT-4o search preview and GPT-4o mini search preview. The models scored 90% and 88% accuracy on the SimpleQA benchmark, which is significantly better than \u0026#34;plain-vanilla\u0026#34; GPT models performance (comprised between 15% and 63%). However, the computer use tool fares at 38.1% on the OSWorld benchmark, which suggests the model is not yet highly reliable for automating tasks on operating systems.\u003c/p\u003e\n\n\u003cp\u003eWhile both the Chat Completions API and the Assistants API will remain available for now, with OpenAI committed to enhancing the former with new models and features, the company has already announced that the Assistants API will be deprecated next year.\u003c/p\u003e\n\n\u003cp\u003eAlong with the Responses API, OpenAI has also launched the new \u003ca href=\"https://platform.openai.com/docs/guides/agents\"\u003eAgents SDK\u003c/a\u003e aimed at orchestrating agentic workflows by defining distinct agents, managing control transfer between them (handoffs), defining safety checks for input and output to prevent irrelevant, harmful, or undesirable behavior (guardrails), and \u003ca href=\"https://platform.openai.com/docs/guides/agents#orchestration\"\u003evisualizing traces to observe agents\u003c/a\u003e.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe Agents SDK is suitable for various real-world applications, including customer support automation, multi-step research, content generation, code review, and sales prospecting.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe Agents SDK supports all current OpenAI models, including o1, o3-mini, GPT-4.5, GPT-4o, and GPT-4o-mini. It also allows developers to augment their agents with external and persistent knowledge represented through \u003ca href=\"https://platform.openai.com/docs/guides/retrieval#vector-stores\"\u003evector stores\u003c/a\u003e and the \u003ca href=\"https://platform.openai.com/docs/guides/embeddings\"\u003eEmbeddings API\u003c/a\u003e. Relying on the Responses API, the Agents SDK supports the same external tools to search the Web, local files, or control a computer.\u003c/p\u003e\n\n\u003cp\u003eThe Agents SDK supersedes its \u003ca href=\"https://www.infoq.com/news/2024/10/openai-swarm-orchestration/\"\u003eexperimental orchestration agent Swarm\u003c/a\u003e and is compatible with any Chat Completions-style API, including the Responses API and third-party APIs.\u003c/p\u003e\n\n\u003cp\u003eAmong community reactions, some Hacker News (HN) readers expressed their sentiment that OpenAI\u0026#39;s move away from the Chat Completions API is \u003ca href=\"https://news.ycombinator.com/item?id=43338646\"\u003edictated by \u0026#34;non-technical\u0026#34; reasons\u003c/a\u003e and brings the \u003ca href=\"https://news.ycombinator.com/item?id=43340571\"\u003erisk of lock-in\u003c/a\u003e with their platform. In the same line, some readers suggest that the phasing out of the Assistant API indicates that a good approach is \u003ca href=\"https://news.ycombinator.com/item?id=43339184\"\u003enot rewriting code for the Responses API, but rather creating a wrapper\u003c/a\u003e so you have a chance to replace the underlying LLM in case you need it.\u003c/p\u003e\n\n\u003cp\u003eOn another front, several HN readers pointed out that adopting the Agents SDK or any other agentic middleware means you are basically \u003ca href=\"https://news.ycombinator.com/item?id=43338229\"\u003e\u0026#34;outsourcing\u0026#34; your state management and business logic to a third party\u003c/a\u003e whereas you may prefer to \u003ca href=\"https://news.ycombinator.com/item?id=43340303\"\u003ekeep the LLM-component as small as possible and build your own logic around it\u003c/a\u003e.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Sergio-De-Simone\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSergio De Simone\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-03-16T00:00:00Z",
  "modifiedTime": null
}
