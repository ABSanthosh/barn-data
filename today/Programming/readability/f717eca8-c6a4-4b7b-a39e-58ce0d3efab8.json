{
  "id": "f717eca8-c6a4-4b7b-a39e-58ce0d3efab8",
  "title": "OpenAI Launches o3-pro Model Focused on Reliability, Amid Mixed User Feedback",
  "link": "https://www.infoq.com/news/2025/06/openai-o3-pro/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "OpenAI launched o3-pro, a new version of its most advanced model aimed at delivering more reliable, thoughtful responses across complex tasks. Now available to Pro and Team users in ChatGPT and via API, o3-pro replaces the earlier o1-pro. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Tue, 17 Jun 2025 18:20:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "OpenAI",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 2666,
  "excerpt": "OpenAI launched o3-pro, a new version of its most advanced model aimed at delivering more reliable, thoughtful responses across complex tasks. Now available to Pro and Team users in ChatGPT and via AP",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250605075448/apple-touch-icon.png",
  "text": "OpenAI launched o3-pro, a new version of its most advanced model aimed at delivering more reliable, thoughtful responses across complex tasks. Now available to Pro and Team users in ChatGPT and via API, o3-pro replaces the earlier o1-pro. Based on the o3 architecture, o3-pro maintains access to tools like Python, file analysis, web browsing, and image interpretation, allowing it to tackle multifaceted problems. The model is designed for users who prioritize correctness and depth over speed. OpenAI cautions that o3-pro responses may take longer to generate than those from lighter models. Expert and academic evaluations show improvements. OpenAI reports that in “4/4 reliability” testing—where a model must answer the same question correctly four times in a row—o3-pro outperformed both o1-pro and base o3. It also scored higher in clarity, instruction-following, and domain-specific strength, particularly in STEM, writing, and business contexts. Source: help.openai.com Some users see o3-pro as a practical upgrade. One comment summed it up: This is just going to be like o1-pro except for o3… not game-changing, but it might cross the threshold on tasks where it previously fell just short, which can lead to big productivity gains. However, early testers also raised concerns. Slower performance is one drawback: It is doing alright with algorithmic questions, but it is taking an awfully long time… the Android and MacOS apps time out a lot. Others voiced doubts about hallucination issues being addressed: For me, full o3 was blowing my mind for a while, but recently I have realized how much it hallucinates and that is become a big problem. I doubt o3-pro solves it. I have in my custom instructions for ChatGPT to always cite sources when making a claim, including a direct quote, because I hoped this would cut down on hallucinations, but it does not. I am often querying about medical things, and it will very often simply make up numbers or a direct quote that does not exist. This frustration was echoed in a broader critique: At this point, I do not need smarter general models for my work. I need models that do not hallucinate, that are faster/cheaper, and that have better taste in specific domains. I think that is where we are going to see improvements moving forward. Notably, o3-pro does not currently support image generation, Canvas, or temporary chats due to technical limitations. These features remain accessible via other models like GPT-4o and o4-mini. About the Author Robert Krzaczyński",
  "image": "https://res.infoq.com/news/2025/06/openai-o3-pro/en/headerimage/generatedHeaderImage-1750183401677.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cdiv\u003e\u003cp\u003eOpenAI launched \u003ca href=\"https://help.openai.com/en/articles/9624314-model-release-notes\"\u003eo3-pro\u003c/a\u003e, a new version of its most advanced model aimed at delivering more reliable, thoughtful responses across complex tasks. Now available to Pro and Team users in ChatGPT and via API, o3-pro replaces the earlier o1-pro.\u003c/p\u003e\u003cp\u003e\n\nBased on the o3 architecture, o3-pro maintains access to tools like Python, file analysis, web browsing, and image interpretation, allowing it to tackle multifaceted problems. The model is designed for users who prioritize correctness and depth over speed. OpenAI cautions that o3-pro responses may take longer to generate than those from lighter models.\u003c/p\u003e\u003cp\u003e\n\nExpert and academic evaluations show improvements. OpenAI reports that in “4/4 reliability” testing—where a model must answer the same question correctly four times in a row—o3-pro outperformed both o1-pro and base o3. It also scored higher in clarity, instruction-following, and domain-specific strength, particularly in STEM, writing, and business contexts.\u003c/p\u003e\u003c/div\u003e\n\n\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"OpenAI o3 pro benchmark\" data-src=\"news/2025/06/openai-o3-pro/en/resources/1Zrzut ekranu 2025-06-17 195444-1750183400663.png\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2025/06/openai-o3-pro/en/resources/1Zrzut ekranu 2025-06-17 195444-1750183400663.png\" rel=\"share\"/\u003e\u003cbr/\u003e\n\u003cem\u003eSource: help.openai.com\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\n\nSome users see o3-pro as a practical upgrade. One \u003ca href=\"https://www.reddit.com/r/singularity/comments/1l842hz/comment/mx288pc/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003ecomment \u003c/a\u003esummed it up:\u003c/p\u003e\u003c/div\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThis is just going to be like o1-pro except for o3… not game-changing, but it might cross the threshold on tasks where it previously fell just short, which can lead to big productivity gains.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eHowever, early testers also \u003ca href=\"https://news.ycombinator.com/item?id=44255644\"\u003eraised\u003c/a\u003e concerns. Slower performance is one drawback:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eIt is doing alright with algorithmic questions, but it is taking an awfully long time… the Android and MacOS apps time out a lot.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eOthers voiced doubts about hallucination issues being \u003ca href=\"https://www.reddit.com/r/singularity/comments/1l842hz/comment/mx20oor/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003eaddressed\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eFor me, full o3 was blowing my mind for a while, but recently I have realized how much it hallucinates and that is become a big problem. I doubt o3-pro solves it. I have in my custom instructions for ChatGPT to always cite sources when making a claim, including a direct quote, because I hoped this would cut down on hallucinations, but it does not. I am often querying about medical things, and it will very often simply make up numbers or a direct quote that does not exist.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThis frustration was echoed in a \u003ca href=\"http://news.ycombinator.com/item?id=44254134\"\u003ebroader critique\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eAt this point, I do not need smarter general models for my work. I need models that do not hallucinate, that are faster/cheaper, and that have better taste in specific domains. I think that is where we are going to see improvements moving forward.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eNotably, o3-pro does not currently support image generation, Canvas, or temporary chats due to technical limitations. These features remain accessible via other models like GPT-4o and o4-mini.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-06-17T00:00:00Z",
  "modifiedTime": null
}
