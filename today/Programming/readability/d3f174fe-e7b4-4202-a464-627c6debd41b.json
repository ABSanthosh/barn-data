{
  "id": "d3f174fe-e7b4-4202-a464-627c6debd41b",
  "title": "The End of the Public API Strangler",
  "link": "https://developers.soundcloud.com/blog/end-of-the-strangler",
  "description": "This is the story of how we used the Strangler pattern to migrate our public API from a monolithic codebase to a fully fledged BFF over the…",
  "author": "",
  "published": "Mon, 14 Mar 2022 00:00:00 GMT",
  "source": "https://developers.soundcloud.com/blog/blog.rss",
  "categories": null,
  "byline": "",
  "length": 9010,
  "excerpt": "This is the story of how we used the [Strangler pattern](https://martinfowler.com/bliki/StranglerFigApplication.html) to migrate our [public API](https://developers.soundcloud.com/docs/api/explorer/open-api) from a monolithic codebase to a fully fledged [BFF](https://developers.soundcloud.com/blog/service-architecture-1) over the course of eight years. It also discusses some of the trials and tribulations we encountered along the way.",
  "siteName": "",
  "favicon": "",
  "text": "This is the story of how we used the Strangler pattern to migrate our public API from a monolithic codebase to a fully fledged BFF over the course of eight years. It also discusses some of the trials and tribulations we encountered along the way. History SoundCloud started as a single Ruby on Rails application more than 14 years ago. Back then, this single application served the website and the public API. While going through multiple growth phases — both in terms of user traffic and the size of the engineering team — we made the choice to more formally adopt a type of service architecture commonly referred to as microservices. This move promised to unblock engineering teams and widen technology choices, in turn allowing us to pick appropriate tools for handling our scaling challenges. After the Cambrian explosion of languages, frameworks, and approaches, the engineering organization started to consolidate, and Scala became the default language for delivering our microservice architecture. That’s because it’s underpinned by Twitter’s Finagle as the RPC framework for interservice communication, and we knew we wanted to use Finagle. Motivation In the new reality of a microservices architecture, where some new features now existed outside of the Rails application, and some services supplemented the existing features of the Rails application, we needed to decide how to maintain the public API going forward. It was crucial to ensure that important features — like serving content — continued to work for existing integrations, even though their implementations had changed and now spanned multiple services. We tried various approaches and learned that our Rails application didn’t perform well when interacting with multiple microservices to serve user traffic. As a result, in 2014, we made the decision to not integrate it with other services to serve the public API, but to instead build a Scala service using Finagle that would internally proxy requests to the existing public API. This new service would intercept and augment the public API responses by calling additional services when necessary, (somewhat loosely) following the Strangler pattern. Typically, the goal of the Strangler pattern is to incrementally replace the functionality of one system with the functionality of a new, more desirable system or systems, one piece at a time. It’s commonly used when migrating from a monolithic codebase to a microservice architecture. Although this end goal informed the original decision to adopt the Strangler pattern, our choice to use it was more motivated by an immediate need rather than planning for a future free of the public API monolith. As a result, the Strangler was left, along with the monolith, largely unmaintained while feature development on our internal APIs continued at pace. To facilitate the continued development of our internal APIs, it became necessary to duplicate code paths for accessing core entities, e.g. tracks, playlists, users, etc. This meant one code path for internal clients and one for the public API. In addition to the obvious downside of this duplication, inconsistencies between the two APIs also emerged. A lack of maintenance also meant knowledge loss, security issues from exposing the monolith with deprecated Rails versions via transparent proxying from the Strangler, and scope creep due to feature teams often needing to touch the Strangler and/or the monolith without much prior knowledge. As the business matured further and new investments in the public API were planned, the case to address the current situation became compelling, and the work was scoped to complete the migration of the Strangler to a fully-fledged BFF. In January 2020, after a six-year period in which modest progress was made, the work began in earnest. Porting from the Public API to the BFF Importantly, two preliminary steps helped us reduce the scope of the work. Some of the official apps were still making some direct calls to the public API. These were migrated to use the official BFFs, which enabled us to shrink the API surface, and hence the scope, significantly. Much of the common functionality in the BFFs was consolidated in Value-Added Services, further reducing the scope of the work. Without these preliminary measures, completing this project may have been unrealistic. Endpoints could be ported with varying degrees of difficulty. In some cases, there were existing reference implementations in other BFFs, e.g. for web or mobile, that could be used as a guide. In others, a complete rewrite was needed, and often it was necessary to add missing functionality to downstream microservices. Challenges Due to the lack of experience within the company with the public API codebase, it was actually necessary to first investigate and document the full list of endpoints that the public API exposed. This involved: Adding telemetry to understand which endpoints were still in use. Explicitly declaring all known public API routes in the Strangler codebase. Adding a fallback to call the public API for any undeclared routes. Removing the fallback once we were confident we had identified all routes. Removing routes that weren’t in use and weren’t documented on the developer portal. Creating a JIRA ticket for each endpoint to be ported, i.e. reimplemented in the Strangler, by calling existing microservices instead of the public API. Also, some things that come for free (or “magic”) in Ruby were things we needed to implement ourselves — for example, multipart request parameter parsing. Furthermore, Rails doesn’t need to be explicit about all route and Content-Type combinations it supports. This sometimes led to unpleasant surprises during porting as it became clear that entire chunks of functionality remained to be implemented. Response Comparisons To build up confidence in ported endpoints, the process typically goes like this: The ported implementation gets deployed alongside the old code that proxies to the public API. Incoming requests execute both codepaths — the old (using the proxy) and the new code. The response of the proxy’s call to the public API gets returned to the caller. At the same time, the responses of the proxy and the new code are compared for consistency. If the responses of the old and new code don’t match, a telemetry event is triggered and the difference is logged for inspection by the developer. The developer may then need to make some changes to the ported implementation until they’re confident that the new code matches the original in terms of functionality. At this point, the proxy can be removed and the ported response gets returned. Of course, this is only really possible for non-mutating methods, i.e. GET or HEAD requests. Otherwise, the code might end up creating two entries in the database for a single request. To deal with mutating methods, i.e. PUT or POST requests, it was sometimes necessary to perform extensive manual regression testing. Not everything went as smoothly as we would’ve liked, and the use of rollout flags also proved useful for quickly disabling the ported code where problems did occur. Learnings Decisions need to be made based on data, and telemetry was key in informing such decisions. For example, undocumented endpoints that receive minimal usage can sometimes be deprecated and later removed. The less code to port and maintain, the better. Adopting the Strangler pattern comes with significant risks. As mentioned, there was initially a long fallow period where not much work was done to port the public API endpoints to the Strangler. During this period, some knowledge about the project was lost and the Strangler in fact added some complexity for teams developing new features. If you decide to adopt the Strangler pattern, make sure to have a plan to complete the migration before the knowledge is lost and it becomes a daunting task with increased risk. As with any kind of rewrite, even an incremental one, bugs can occur. The nature of the public API — being accessible to anyone who wishes to use it — meant that sometimes things broke, and sometimes for seemingly innocuous changes. In some instances, the tenet of Hyrum’s Law came into play, where breakages occurred due to third-party integrations relying on undocumented aspects of the APIs. It’s worth considering whether such disruptions to your business are worth the ultimate benefits of the work. Conclusion The work wasn’t without its challenges, and anyone embarking on such a project should be aware of the risks and benefits involved. However, now that all endpoints have finally been ported, there are some notable benefits: the Strangler is now a fully fledged BFF; the entire codebase of the public API has been deleted; and we have a codebase that most engineers can contribute to (Scala service), that doesn’t negatively impact project scope, that fits with our microservice architecture, and that helps ensure data consistency and security.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eThis is the story of how we used the \u003ca href=\"https://martinfowler.com/bliki/StranglerFigApplication.html\"\u003eStrangler pattern\u003c/a\u003e to migrate our \u003ca href=\"https://developers.soundcloud.com/docs/api/explorer/open-api\"\u003epublic API\u003c/a\u003e from a monolithic codebase to a fully fledged \u003ca href=\"https://developers.soundcloud.com/blog/service-architecture-1\"\u003eBFF\u003c/a\u003e over the course of eight years. It also discusses some of the trials and tribulations we encountered along the way.\u003c/p\u003e\n\u003ch2\u003eHistory\u003c/h2\u003e\n\u003cp\u003eSoundCloud started as a single Ruby on Rails application more than 14 years ago. Back then, this single application served the website and the public API. While going through multiple growth phases — both in terms of user traffic and the size of the engineering team — we made the choice to more formally adopt a type of service architecture commonly referred to as microservices. This move promised to unblock engineering teams and widen technology choices, in turn allowing us to pick appropriate tools for handling our scaling challenges.\u003c/p\u003e\n\u003cp\u003eAfter the Cambrian explosion of languages, frameworks, and approaches, the engineering organization started to consolidate, and Scala became the default language for delivering our microservice architecture. That’s because it’s underpinned by Twitter’s Finagle as the RPC framework for interservice communication, and we knew we wanted to use Finagle.\u003c/p\u003e\n\u003ch2\u003eMotivation\u003c/h2\u003e\n\u003cp\u003eIn the new reality of a microservices architecture, where some new features now existed outside of the Rails application, and some services supplemented the existing features of the Rails application, we needed to decide how to maintain the public API going forward. It was crucial to ensure that important features — like serving content — continued to work for existing integrations, even though their implementations had changed and now spanned multiple services.\u003c/p\u003e\n\u003cp\u003eWe tried various approaches and learned that our Rails application didn’t perform well when interacting with multiple microservices to serve user traffic. As a result, in 2014, we made the decision to not integrate it with other services to serve the public API, but to instead build a Scala service using Finagle that would internally proxy requests to the existing public API. This new service would intercept and augment the public API responses by calling additional services when necessary, (somewhat loosely) following the \u003ca href=\"https://martinfowler.com/bliki/StranglerFigApplication.html\"\u003eStrangler pattern\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTypically, the goal of the Strangler pattern is to incrementally replace the functionality of one system with the functionality of a new, more desirable system or systems, one piece at a time. It’s commonly used when migrating from a monolithic codebase to a microservice architecture. Although this end goal informed the original decision to adopt the Strangler pattern, our choice to use it was more motivated by an immediate need rather than planning for a future free of the public API monolith.\u003c/p\u003e\n\u003cp\u003eAs a result, the Strangler was left, along with the monolith, largely unmaintained while feature development on our internal APIs continued at pace. To facilitate the continued development of our internal APIs, it became necessary to duplicate code paths for accessing core entities, e.g. tracks, playlists, users, etc. This meant one code path for internal clients and one for the public API. In addition to the obvious downside of this duplication, inconsistencies between the two APIs also emerged. A lack of maintenance also meant knowledge loss, security issues from exposing the monolith with deprecated Rails versions via transparent proxying from the Strangler, and scope creep due to feature teams often needing to touch the Strangler and/or the monolith without much prior knowledge.\u003c/p\u003e\n\u003cp\u003eAs the business matured further and new investments in the public API were planned, the case to address the current situation became compelling, and the work was scoped to complete the migration of the Strangler to a fully-fledged BFF. In January 2020, after a six-year period in which modest progress was made, the work began in earnest.\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e\n      \u003ca href=\"https://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/35d62/strangler-pattern.png\" target=\"_blank\" rel=\"noopener\"\u003e\n    \u003cspan\u003e\u003c/span\u003e\n  \u003cimg alt=\"The Strangler pattern\" title=\"The Strangler pattern\" src=\"https://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/8ff1e/strangler-pattern.png\" srcset=\"https://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/9ec3c/strangler-pattern.png 200w,\nhttps://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/c7805/strangler-pattern.png 400w,\nhttps://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/8ff1e/strangler-pattern.png 800w,\nhttps://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/6ff5e/strangler-pattern.png 1200w,\nhttps://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/2f950/strangler-pattern.png 1600w,\nhttps://developers.soundcloud.com/blog/static/39f04214a9c8fbada5f8f3fd1eafafd7/35d62/strangler-pattern.png 3604w\" sizes=\"(max-width: 800px) 100vw, 800px\" loading=\"lazy\"/\u003e\n  \u003c/a\u003e\n    \u003c/span\u003e\u003c/p\u003e\n\u003ch2\u003ePorting from the Public API to the BFF\u003c/h2\u003e\n\u003cp\u003eImportantly, two preliminary steps helped us reduce the scope of the work.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSome of the official apps were still making some direct calls to the public API. These were migrated to use the official BFFs, which enabled us to shrink the API surface, and hence the scope, significantly.\u003c/li\u003e\n\u003cli\u003eMuch of the common functionality in the BFFs was consolidated in \u003ca href=\"https://developers.soundcloud.com/blog/service-architecture-2\"\u003eValue-Added Services\u003c/a\u003e, further reducing the scope of the work.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWithout these preliminary measures, completing this project may have been unrealistic.\u003c/p\u003e\n\u003cp\u003eEndpoints could be ported with varying degrees of difficulty. In some cases, there were existing reference implementations in other BFFs, e.g. for web or mobile, that could be used as a guide. In others, a complete rewrite was needed, and often it was necessary to add missing functionality to downstream microservices.\u003c/p\u003e\n\u003ch3\u003eChallenges\u003c/h3\u003e\n\u003cp\u003eDue to the lack of experience within the company with the public API codebase, it was actually necessary to first investigate and document the full list of endpoints that the public API exposed. This involved:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAdding telemetry to understand which endpoints were still in use.\u003c/li\u003e\n\u003cli\u003eExplicitly declaring all known public API routes in the Strangler codebase.\u003c/li\u003e\n\u003cli\u003eAdding a fallback to call the public API for any undeclared routes.\u003c/li\u003e\n\u003cli\u003eRemoving the fallback once we were confident we had identified all routes.\u003c/li\u003e\n\u003cli\u003eRemoving routes that weren’t in use and weren’t documented on the \u003ca href=\"https://developers.soundcloud.com/\"\u003edeveloper portal\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eCreating a JIRA ticket for each endpoint to be ported, i.e. reimplemented in the Strangler, by calling existing microservices instead of the public API.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAlso, some things that come for free (or “magic”) in Ruby were things we needed to implement ourselves — for example, multipart request parameter parsing. Furthermore, Rails doesn’t need to be explicit about all route and \u003ccode\u003eContent-Type\u003c/code\u003e combinations it supports. This sometimes led to unpleasant surprises during porting as it became clear that entire chunks of functionality remained to be implemented.\u003c/p\u003e\n\u003ch3\u003eResponse Comparisons\u003c/h3\u003e\n\u003cp\u003eTo build up confidence in ported endpoints, the process typically goes like this:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe ported implementation gets deployed alongside the old code that proxies to the public API.\u003c/li\u003e\n\u003cli\u003eIncoming requests execute both codepaths — the old (using the proxy) and the new code.\u003c/li\u003e\n\u003cli\u003eThe response of the proxy’s call to the public API gets returned to the caller.\u003c/li\u003e\n\u003cli\u003eAt the same time, the responses of the proxy and the new code are compared for consistency.\u003c/li\u003e\n\u003cli\u003eIf the responses of the old and new code don’t match, a telemetry event is triggered and the difference is logged for inspection by the developer.\u003c/li\u003e\n\u003cli\u003eThe developer may then need to make some changes to the ported implementation until they’re confident that the new code matches the original in terms of functionality.\u003c/li\u003e\n\u003cli\u003eAt this point, the proxy can be removed and the ported response gets returned.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOf course, this is only really possible for non-mutating methods, i.e. \u003ccode\u003eGET\u003c/code\u003e or \u003ccode\u003eHEAD\u003c/code\u003e requests. Otherwise, the code might end up creating two entries in the database for a single request. To deal with mutating methods, i.e. \u003ccode\u003ePUT\u003c/code\u003e or \u003ccode\u003ePOST\u003c/code\u003e requests, it was sometimes necessary to perform extensive manual regression testing. Not everything went as smoothly as we would’ve liked, and the use of rollout flags also proved useful for quickly disabling the ported code where problems did occur.\u003c/p\u003e\n\u003ch2\u003eLearnings\u003c/h2\u003e\n\u003cp\u003eDecisions need to be made based on data, and telemetry was key in informing such decisions. For example, undocumented endpoints that receive minimal usage can sometimes be deprecated and later removed. The less code to port and maintain, the better.\u003c/p\u003e\n\u003cp\u003eAdopting the Strangler pattern comes with significant risks. As mentioned, there was initially a long fallow period where not much work was done to port the public API endpoints to the Strangler. During this period, some knowledge about the project was lost and the Strangler in fact \u003cem\u003eadded\u003c/em\u003e some complexity for teams developing new features. If you decide to adopt the Strangler pattern, make sure to have a plan to complete the migration before the knowledge is lost and it becomes a daunting task with increased risk.\u003c/p\u003e\n\u003cp\u003eAs with any kind of rewrite, even an incremental one, bugs can occur. The nature of the public API — being accessible to anyone who wishes to use it — meant that sometimes things broke, and sometimes for seemingly innocuous changes. In some instances, the tenet of \u003ca href=\"https://www.hyrumslaw.com/\"\u003eHyrum’s Law\u003c/a\u003e came into play, where breakages occurred due to third-party integrations relying on \u003cem\u003eundocumented\u003c/em\u003e aspects of the APIs.\u003c/p\u003e\n\u003cp\u003eIt’s worth considering whether such disruptions to your business are worth the ultimate benefits of the work.\u003c/p\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThe work wasn’t without its challenges, and anyone embarking on such a project should be aware of the risks and benefits involved. However, now that all endpoints have finally been ported, there are some notable benefits: the Strangler is now a fully fledged BFF; the entire codebase of the public API has been deleted; and we have a codebase that most engineers can contribute to (Scala service), that doesn’t negatively impact project scope, that fits with our microservice architecture, and that helps ensure data consistency and security.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": null,
  "modifiedTime": null
}
