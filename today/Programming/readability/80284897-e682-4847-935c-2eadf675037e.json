{
  "id": "80284897-e682-4847-935c-2eadf675037e",
  "title": "How we designed the GitLab Reference Architectures",
  "link": "https://about.gitlab.com/blog/2024/10/02/how-we-designed-the-gitlab-reference-architectures",
  "description": "",
  "author": "Grant Young",
  "published": "2024-10-02T00:00:00.000Z",
  "source": "https://about.gitlab.com/atom.xml",
  "categories": null,
  "byline": "Grant Young",
  "length": 7410,
  "excerpt": "Take a look back with us as we dive into our Reference Architectures design journey to help users easily deploy GitLab at scale. Learn our goals, process, and what's happened in the five years since.",
  "siteName": "GitLab",
  "favicon": "https://about.gitlab.com/blog/nuxt-images/ico/favicon-192x192.png?cache=2022041",
  "text": "We introduced the first GitLab Reference Architectures five years ago. Originally developed as a partnership between the GitLab Test Platform (formally Quality Engineering) and Support teams, along with other contributors, these architectures aim to provide scalable and elastic starting points to deploy GitLab at scale, tailored to an organization's target load. Since their debut, we've been thrilled to see the impact these architectures have had on our customers as they navigate their DevSecOps journey. We continue to iterate, expand, and refine the architectures, reflecting our commitment to providing you with the latest, best-in-class guidance on deploying, scaling, and maintaining your GitLab environments. In recognition of the five-year milestone, here is a peek behind the curtain on how we designed the Reference Architectures and how that design still applies today. The problem Before introducing the Reference Architectures, we frequently heard from our customers about the hurdles they faced when deploying GitLab at scale to meet their performance and availability goals. While every GitLab environment can be considered a little unique because of the need to meet a customer's own requirements, we recognized from running GitLab.com, as well as from our larger customers, that there were common fundamentals to deploying GitLab at scale that were worth sharing. Our objective was to address customer needs while promoting deployment best practices to reduce drift and increase alignment. Simultaneously, we wanted to significantly expand our performance testing efforts. The goals of this expansion were to provide our engineering teams with a deeper understanding of performance bottlenecks, to drive improvements in GitLab's performance, and to continuously test the application moving forward to ensure it remained performant. However, to conduct meaningful performance tests, we needed a standardized GitLab environment design capable of handling the target loads. Enter the Reference Architectures. The goals With the need for a common architecture clear, we turned next to set the goals of this initiative, which ultimately became the following: Performance: Ensure the architecture can handle the target load efficiently. Availability: Maximize uptime and reliability wherever possible. Scalability and elasticity: Ensure the architecture is scalable and elastic to meet individual customer needs. Cost-effectiveness: Optimize resource allocation to avoid unnecessary expenses. Maintainability: Make the architecture deployment and management as straightforward as possible with standardized configurations. It's crucial to note that these goals were not in order and they are goals we stay true to today. The process Once the goals were set, we faced the challenge of designing an architecture, validating it, and making sure that it was fit for purpose and met those goals. The process itself was relatively simple in design: Gather metrics on existing environments and the loads they were able to handle. Define a prototype architecture based on these metrics. Build and test the environment to validate. Adjust the environment iteratively based on the test results and metrics until we had a validated architecture that met the goals. While simple in design, this, of course, was not the case in practice so we got to work. First, we collected and reviewed the data. To that end, we reviewed metrics and logging data from GitLab.com as well as several participating large customers to correlate the environment sizes deployed to the load they were handling. To achieve this, we needed an objective and quantifiable way to measure that load across any environment, and for that we used Requests per Seconds (RPS). With RPS we could see the concurrent load each environment handled and correlate this to the user count accordingly. Specifically, a user count would correlate to the full manual and automated load (such as continuous integration). From that data, we were able to correlate this across several environment sizes and start to pick out common patterns for the architectures. Next, we started with a prototype architecture that aimed to meet the goals while cross-referencing with the data we collected. In fact, we actually started this step in conjunction with the first step initially as we had a good enough idea of where to start: Taking the fundamental GitLab.com design and scaling it down for individual customer loads in cost-effective ways. This allowed us to start performance testing the prototype with the data we were analyzing to corroborate accordingly. After quite a few iterations, we had a starting point for our prototype architecture. To thoroughly test and validate the architecture we needed to turn to performance testing and define our methodology. The approach was to target our most common endpoints with a representative test data set at RPS loads that were also representative. Then, although we had manually built the prototype architecture, we knew we needed tooling to automatically build environments and handle tasks such as updates. These efforts resulted in the GitLab Performance Tool and GitLab Environment Toolkit, which I blogged about previously and which we continue to use to this day (and you can use too!). With all the above in place we started the main work of validating the prototype architecture through multiple cycles of testing and iterating. In each cycle, we would performance test the environment, review the results and metrics, and adjust the environment accordingly. Through iteration we were able to identify what failures were real application performance issues and what were environmental, and eventually we had our first architecture. That architecture is now known as the 200 RPS or 10,000-user Reference Architecture. Where Reference Architectures are today Since publishing our first validated Reference Architecture, the work has never stopped! We like to describe the architectures as living documentation, as they're constantly being improved and expanded with additions such as: various Reference Architecture sizes based on common deployments non-highly available sizes for smaller environments full step-by-step documentation in collaboration with our colleagues in Technical Writing and Support expanded guidance and new naming scheme to help with right sizing, scaling, and how to deal with outliers such as monorepos cloud native hybrid variants where select components are run in Kubernetes recommendations and guidance for cloud provider services and more! Check out the update history section in the Reference Architecture documentation! All this is driven by our comprehensive testing program that we built alongside the Reference Architectures to continuously test that they remain fit for purpose against the latest GitLab code every single week and to catch any unexpected performance issues early. And we're thrilled to see these efforts have helped numerous customers to date as well as our own engineering teams deliver new, exciting services. In fact, our engineering teams used the Reference Architectures to develop GitLab Dedicated. Five years on, our commitment is stronger than ever. The work very much continues in the same way it started to ensure you have the best-in-class guidance for your DevSecOps journey. Learn more about GitLab Reference Architectures.",
  "image": "https://images.ctfassets.net/r9o86ar0p03f/52vS9ne2Hu3TElOeHep0AF/79fe27fd59ed7843e60b0a8bc8257682/blog-image-template-1800x945__2_.png?fm=webp\u0026w=820\u0026h=500",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv data-v-b794d8fe=\"\" data-v-7488832a=\"\" data-v-74bd29c6=\"\"\u003e\u003cp\u003eWe introduced the first \u003ca href=\"https://docs.gitlab.com/ee/administration/reference_architectures\"\u003eGitLab Reference Architectures\u003c/a\u003e five years ago. Originally developed as a partnership between the GitLab Test Platform (formally Quality Engineering) and Support teams, along with other contributors, these architectures aim to provide scalable and elastic starting points to deploy GitLab at scale, tailored to an organization\u0026#39;s target load.\u003c/p\u003e\n\u003cp\u003eSince their debut, we\u0026#39;ve been thrilled to see the impact these architectures have had on our customers as they navigate their DevSecOps journey. We continue to iterate, expand, and refine the architectures, reflecting our commitment to providing you with the latest, best-in-class guidance on deploying, scaling, and maintaining your GitLab environments.\u003c/p\u003e\n\u003cp\u003eIn recognition of the five-year milestone, here is a peek behind the curtain on \u003cem\u003ehow\u003c/em\u003e we designed the Reference Architectures and how that design still applies today.\u003c/p\u003e\n\u003ch2 id=\"the-problem\" tabindex=\"-1\"\u003eThe problem \u003ca href=\"#the-problem\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBefore introducing the Reference Architectures, we frequently heard from our customers about the hurdles they faced when deploying GitLab at scale to meet their performance and availability goals.\u003c/p\u003e\n\u003cp\u003eWhile every GitLab environment can be considered a little unique because of the need to meet a customer\u0026#39;s own requirements, we recognized from running GitLab.com, as well as from our larger customers, that there were common fundamentals to deploying GitLab at scale that were worth sharing. Our objective was to address customer needs while promoting deployment best practices to reduce drift and increase alignment.\u003c/p\u003e\n\u003cp\u003eSimultaneously, we wanted to significantly expand our performance testing efforts. The goals of this expansion were to provide our engineering teams with a deeper understanding of performance bottlenecks, to drive improvements in GitLab\u0026#39;s performance, and to continuously test the application moving forward to ensure it remained performant. However, to conduct meaningful performance tests, we needed a standardized GitLab environment design capable of handling the target loads.\u003c/p\u003e\n\u003cp\u003eEnter the Reference Architectures.\u003c/p\u003e\n\u003ch2 id=\"the-goals\" tabindex=\"-1\"\u003eThe goals \u003ca href=\"#the-goals\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eWith the need for a common architecture clear, we turned next to set the goals of this initiative, which ultimately became the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePerformance: Ensure the architecture can handle the target load efficiently.\u003c/li\u003e\n\u003cli\u003eAvailability: Maximize uptime and reliability wherever possible.\u003c/li\u003e\n\u003cli\u003eScalability and elasticity: Ensure the architecture is scalable and elastic to meet individual customer needs.\u003c/li\u003e\n\u003cli\u003eCost-effectiveness: Optimize resource allocation to avoid unnecessary expenses.\u003c/li\u003e\n\u003cli\u003eMaintainability: Make the architecture deployment and management as straightforward as possible with standardized configurations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIt\u0026#39;s crucial to note that these goals were not in order and they are goals we stay true to today.\u003c/p\u003e\n\u003ch2 id=\"the-process\" tabindex=\"-1\"\u003eThe process \u003ca href=\"#the-process\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOnce the goals were set, we faced the challenge of designing an architecture, validating it, and making sure that it was fit for purpose and met those goals.\u003c/p\u003e\n\u003cp\u003eThe process itself was relatively simple in design:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGather metrics on existing environments and the loads they were able to handle.\u003c/li\u003e\n\u003cli\u003eDefine a prototype architecture based on these metrics.\u003c/li\u003e\n\u003cli\u003eBuild and test the environment to validate.\u003c/li\u003e\n\u003cli\u003eAdjust the environment iteratively based on the test results and metrics until we had a validated architecture that met the goals.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhile simple in design, this, of course, was not the case in practice so we got to work.\u003c/p\u003e\n\u003cp\u003eFirst, we collected and reviewed the data. To that end, we reviewed metrics and logging data from GitLab.com as well as several participating large customers to correlate the environment sizes deployed to the load they were handling. To achieve this, we needed an objective and quantifiable way to measure that load across any environment, and for that we used \u003cstrong\u003eRequests per Seconds (RPS)\u003c/strong\u003e. With RPS we could see the concurrent load each environment handled and correlate this to the user count accordingly. Specifically, a user count would correlate to the full manual and automated load (such as continuous integration). From that data, we were able to correlate this across several environment sizes and start to pick out common patterns for the architectures.\u003c/p\u003e\n\u003cp\u003eNext, we started with a prototype architecture that aimed to meet the goals while cross-referencing with the data we collected. In fact, we actually started this step in conjunction with the first step initially as we had a good enough idea of where to start: Taking the fundamental GitLab.com design and scaling it down for individual customer loads in cost-effective ways. This allowed us to start performance testing the prototype with the data we were analyzing to corroborate accordingly. After quite a few iterations, we had a starting point for our prototype architecture.\u003c/p\u003e\n\u003cp\u003eTo thoroughly test and validate the architecture we needed to turn to performance testing and define our methodology. The approach was to target our most common endpoints with a representative test data set at RPS loads that were also representative. Then, although we had manually built the prototype architecture, we knew we needed tooling to automatically build environments and handle tasks such as updates. These efforts resulted in the \u003ca href=\"https://about.gitlab.com/blog/2020/02/18/how-were-building-up-performance-testing-of-gitlab/\"\u003eGitLab Performance Tool\u003c/a\u003e and \u003ca href=\"https://about.gitlab.com/blog/2021/06/15/why-we-are-building-the-gitlab-environment-toolkit-to-help-deploy-gitlab-at-scale/\"\u003eGitLab Environment Toolkit\u003c/a\u003e, which I blogged about previously and which we continue to use to this day (and you can use too!).\u003c/p\u003e\n\u003cp\u003eWith all the above in place we started the main work of validating the prototype architecture through multiple cycles of testing and iterating. In each cycle, we would performance test the environment, review the results and metrics, and adjust the environment accordingly. Through iteration we were able to identify what failures were real application performance issues and what were environmental, and eventually we had our first architecture. That architecture is now known as the \u003ca href=\"https://docs.gitlab.com/ee/administration/reference_architectures/10k_users.html\"\u003e200 RPS or 10,000-user Reference Architecture\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://images.ctfassets.net/r9o86ar0p03f/5rCSex2bNhQDFnsqGgzttR/82700df53adfe8e57a5dc453da47bf2b/reference_architecture.png\" alt=\"GitLab Reference Architecture - 200 RPS\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"where-reference-architectures-are-today\" tabindex=\"-1\"\u003eWhere Reference Architectures are today \u003ca href=\"#where-reference-architectures-are-today\"\u003e\u003csvg width=\"24\" height=\"24\" viewBox=\"0 0 16 16\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\u003cpath d=\"M12.2426 3.75736C11.4615 2.97631 10.1952 2.97631 9.41416 3.75736L7.99995 5.17157C7.60942 5.56209 6.97626 5.56209 6.58573 5.17157C6.19521 4.78105 6.19521 4.14788 6.58573 3.75736L7.99995 2.34314C9.56205 0.781046 12.0947 0.781046 13.6568 2.34314C15.2189 3.90524 15.2189 6.4379 13.6568 8L12.2426 9.41421C11.8521 9.80473 11.2189 9.80473 10.8284 9.41421C10.4379 9.02369 10.4379 8.39052 10.8284 8L12.2426 6.58578C13.0236 5.80473 13.0236 4.5384 12.2426 3.75736Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M10.5355 5.4645C10.926 5.85502 10.926 6.48819 10.5355 6.87871L6.87863 10.5356C6.4881 10.9261 5.85494 10.9261 5.46441 10.5356C5.07389 10.145 5.07389 9.51188 5.46441 9.12135L9.12127 5.4645C9.51179 5.07397 10.145 5.07397 10.5355 5.4645Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003cpath d=\"M3.75742 9.41422C2.97637 10.1953 2.97637 11.4616 3.75742 12.2426C4.53847 13.0237 5.8048 13.0237 6.58584 12.2426L8.00006 10.8284C8.39058 10.4379 9.02375 10.4379 9.41427 10.8284C9.8048 11.219 9.8048 11.8521 9.41427 12.2426L8.00006 13.6569C6.43796 15.219 3.9053 15.219 2.3432 13.6569C0.781107 12.0948 0.781107 9.56211 2.3432 8.00001L3.75742 6.5858C4.14794 6.19527 4.78111 6.19527 5.17163 6.5858C5.56216 6.97632 5.56215 7.60948 5.17163 8.00001L3.75742 9.41422Z\" fill=\"#333333\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eSince publishing our first validated Reference Architecture, the work has never stopped! We like to describe the architectures as living documentation, as they\u0026#39;re constantly being improved and expanded with additions such as:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003evarious Reference Architecture sizes based on common deployments\u003c/li\u003e\n\u003cli\u003enon-highly available sizes for smaller environments\u003c/li\u003e\n\u003cli\u003efull step-by-step documentation in collaboration with our colleagues in Technical Writing and Support\u003c/li\u003e\n\u003cli\u003eexpanded guidance and new naming scheme to help with right sizing, scaling, and how to deal with outliers such as monorepos\u003c/li\u003e\n\u003cli\u003ecloud native hybrid variants where select components are run in Kubernetes\u003c/li\u003e\n\u003cli\u003erecommendations and guidance for cloud provider services\u003c/li\u003e\n\u003cli\u003eand more! Check out the \u003ca href=\"https://docs.gitlab.com/ee/administration/reference_architectures/#update-history\"\u003eupdate history\u003c/a\u003e section in the Reference Architecture documentation!\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll this is driven by our \u003ca href=\"https://docs.gitlab.com/ee/administration/reference_architectures/#validation-and-test-results\"\u003ecomprehensive testing program\u003c/a\u003e that we built alongside the Reference Architectures to continuously test that they remain fit for purpose against the latest GitLab code \u003cem\u003eevery single week\u003c/em\u003e and to catch any unexpected performance issues early.\u003c/p\u003e\n\u003cp\u003eAnd we\u0026#39;re thrilled to see these efforts have helped numerous customers to date as well as our own engineering teams deliver new, exciting services. In fact, our engineering teams used the Reference Architectures to develop \u003ca href=\"https://about.gitlab.com/dedicated/\"\u003eGitLab Dedicated\u003c/a\u003e. Five years on, our commitment is stronger than ever. The work very much continues in the same way it started to ensure you have the best-in-class guidance for your DevSecOps journey.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLearn more about \u003ca href=\"https://docs.gitlab.com/ee/administration/reference_architectures/\"\u003eGitLab Reference Architectures\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2024-10-02T00:00:00Z",
  "modifiedTime": null
}
