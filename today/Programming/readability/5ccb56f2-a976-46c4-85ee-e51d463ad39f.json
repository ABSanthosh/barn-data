{
  "id": "5ccb56f2-a976-46c4-85ee-e51d463ad39f",
  "title": "QCon SF 2024 - Ten Reasons Your Multi-Agent Workflows Fail",
  "link": "https://www.infoq.com/news/2024/11/qconsf-multiagent-fail/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "At QCon SF 2024, Victor Dibia from Microsoft Research explored the complexities of multi-agent systems powered by generative AI. Highlighting common pitfalls like inadequate prompts and poor orchestration, he shared strategies for enhancing reliability and scalability. Dibia emphasized the need for meticulous design and oversight to unlock the full potential of these innovative systems. By Andrew Hoblitzell",
  "author": "Andrew Hoblitzell",
  "published": "Fri, 29 Nov 2024 18:21:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Machine Learning",
    "Microsoft",
    "QCon San Francisco 2024",
    "Agents",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Andrew Hoblitzell",
  "length": 3123,
  "excerpt": "At QCon SF 2024, Victor Dibia from Microsoft Research explored the complexities of multi-agent systems powered by generative AI. Highlighting common pitfalls like inadequate prompts and poor orchestra",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20241128133034/apple-touch-icon.png",
  "text": "At QCon San Francisco Conference 2024, Victor Dibia of Microsoft Research discussed the challenges of building multi-agent systems powered by generative AI models. Dibia highlighted the immense potential of these systems but noted complexity often leads to failure in real-world applications. Drawing on insights from AutoGen, an open-source framework for multi-agent workflows, he detailed the common reasons these systems falter and strategies to improve their reliability. Dibia outlined ten major reasons multi-agent workflows fail. Some of his key insights included: using detailed instructions for agents, avoiding the use of small models, ensuring that instructions align with the capabilities of the large language model (LLM), equipping the LLM with effective tools, defining clear stopping criteria for agents, utilizing multi-agent patterns, integrating memory into agent workflows, incorporating metacognition, employing task-specific evaluations and metrics, and establishing a mechanism for agents to delegate tasks to humans when necessary. He explained how agents, often driven by LLMs, are highly dependent on detailed prompts to function effectively. Without comprehensive and precise guidance, agents can misinterpret tasks or generate incorrect outputs. Another frequent issue is the use of less capable models, which lack the sophistication to handle intricate tasks or understand nuanced prompts. \"Autonomous multi-agent systems are like self-driving cars: proof of concepts are simple, but the last 5% of reliability is as hard as the first 95%.\" - Dibia One of the more technical challenges is orchestration—how agents coordinate and delegate tasks. Dibia emphasized that poorly defined workflows can lead to inefficiencies or outright failures. Additionally, agents often lack proper memory mechanisms, causing them to forget past interactions and repeat mistakes. “The complexity of multi-agent systems grows exponentially as you add more agents. Success requires careful design and constant iteration,” Dibia remarked during his presentation. Another critical failure point is improper termination conditions. Without clear parameters for when a task is complete, agents can continue indefinitely, wasting computational resources and time. Dibia also addressed the risks associated with giving agents excessive autonomy, such as performing high-stakes actions without human oversight. He recommended implementing safeguards to assess the cost and risk of decisions, delegating to humans when necessary. Scalability was another topic of focus. He emphasized the importance of robust infrastructure and observability tools for debugging and monitoring, noting that these are critical for managing. Developers and engineers interested in Victor Dibia’s work can find more resources on the AutoGen GitHub repository, and a video of his QCon SF presentation is expected to be available on the conference website in the coming weeks. About the Author Andrew Hoblitzell",
  "image": "https://cdn.infoq.com/statics_s1_20241128133034/styles/static/images/logo/logo-big.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eAt \u003cspan\u003e\u003cspan data-testid=\"comment-base-item-66866\"\u003eQCon San Francisco Conference 2024\u003c/span\u003e\u003c/span\u003e, \u003ca href=\"https://qconsf.com/speakers/victordibia\"\u003eVictor Dibia\u003c/a\u003e of Microsoft Research discussed the challenges of building multi-agent systems powered by \u003ca href=\"https://openai.com/index/generative-models/\"\u003egenerative AI\u003c/a\u003e models. Dibia highlighted the immense potential of these systems but noted complexity often leads to failure in real-world applications.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2024/11/qconsf-multiagent-fail/en/resources/1IMG_1898-1732473795060.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2024/11/qconsf-multiagent-fail/en/resources/1IMG_1898-1732473795060.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eDrawing on insights from \u003ca href=\"https://github.com/microsoft/autogen\"\u003eAutoGen\u003c/a\u003e, an open-source framework for multi-agent workflows, he detailed the common reasons these systems falter and strategies to improve their reliability. Dibia outlined ten major reasons multi-agent workflows fail. Some of his key insights included: using detailed instructions for agents, avoiding the use of small models, ensuring that instructions align with the capabilities of the large language model (LLM), equipping the LLM with effective tools, defining clear stopping criteria for agents, utilizing multi-agent patterns, integrating memory into agent workflows, incorporating \u003ca href=\"https://tll.mit.edu/teaching-resources/how-people-learn/metacognition/\"\u003emetacognition\u003c/a\u003e, employing task-specific evaluations and metrics, and establishing a mechanism for agents to delegate tasks to humans when necessary.\u003c/p\u003e\n\n\u003cp\u003eHe explained how agents, often driven by LLMs, are highly dependent on detailed prompts to function effectively. Without comprehensive and precise guidance, agents can misinterpret tasks or generate incorrect outputs. Another frequent issue is the use of less capable models, which lack the sophistication to handle intricate tasks or understand nuanced prompts.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026#34;Autonomous multi-agent systems are like self-driving cars: proof of concepts are simple, but the last 5% of reliability is as hard as the first 95%.\u0026#34; - Dibia\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eOne of the more technical challenges is orchestration—how agents coordinate and delegate tasks. Dibia emphasized that poorly defined workflows can lead to inefficiencies or outright failures. Additionally, agents often lack proper memory mechanisms, causing them to forget past interactions and repeat mistakes. “The complexity of multi-agent systems grows exponentially as you add more agents. Success requires careful design and constant iteration,” Dibia remarked during his presentation.\u003c/p\u003e\n\n\u003cp\u003eAnother critical failure point is improper termination conditions. Without clear parameters for when a task is complete, agents can continue indefinitely, wasting computational resources and time. Dibia also addressed the risks associated with giving agents excessive autonomy, such as performing high-stakes actions without human oversight. He recommended implementing safeguards to assess the cost and risk of decisions, delegating to humans when necessary.\u003c/p\u003e\n\n\u003cp\u003eScalability was another topic of focus. He emphasized the importance of robust infrastructure and observability tools for debugging and monitoring, noting that these are critical for managing.\u003c/p\u003e\n\n\u003cp\u003eDevelopers and engineers interested in Victor Dibia’s work can find more resources on the AutoGen GitHub \u003ca href=\"https://github.com/microsoft/autogen\"\u003erepository\u003c/a\u003e, and a video of his QCon SF presentation is expected to be available on the \u003ca href=\"https://qconsf.com/\"\u003econference website\u003c/a\u003e in the coming weeks.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Andrew-Hoblitzell\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eAndrew Hoblitzell\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2024-11-29T00:00:00Z",
  "modifiedTime": null
}
