{
  "id": "d99bfa81-7d71-4ec7-b52e-8fe2e36d2659",
  "title": "Google Open-Sources Agent2Agent Protocol for Agentic Collaboration",
  "link": "https://www.infoq.com/news/2025/04/google-agentic-a2a/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Google released the Agent2Agent (A2A) Protocol, an open-source specification for building AI agents that can connect with other agents that support the protocol. Google has enlisted over 50 technology partners to contribute to A2A's development. By Anthony Alford",
  "author": "Anthony Alford",
  "published": "Tue, 15 Apr 2025 13:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Agents",
    "Google",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Anthony Alford",
  "length": 3489,
  "excerpt": "Google released the Agent2Agent (A2A) Protocol, an open-source specification for building AI agents that can connect with other agents that support the protocol. Google has enlisted over 50 technology",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250413214448/apple-touch-icon.png",
  "text": "Google released the Agent2Agent (A2A) Protocol, an open-source specification for building AI agents that can connect with other agents that support the protocol. Google has enlisted over 50 technology partners to contribute to A2A's development. Google announced the release at the recent Google Cloud Next conference. A2A is billed as a \"complement\" to Anthropic's Model Context Protocol (MCP) and defines a client-server relationship between AI agents. Google developed the protocol with help from partners like Salesforce, Atlassian, and LangChain, with the goal of creating an interoperability standard for any agent, regardless of vendor or framework. According to Google, A2A has the potential to unlock a new era of agent interoperability, fostering innovation and creating more powerful and versatile agentic systems. We believe that this protocol will pave the way for a future where agents can seamlessly collaborate to solve complex problems and enhance our lives. We’re committed to building the protocol in collaboration with our partners and the community in the open. We’re releasing the protocol as open source and setting up clear pathways for contribution. InfoQ covered Anthropic's MCP release last year. Intended to solve the \"MxN\" problem---the combinatorial difficulty of integrating M different LLMs with N different tools---MCP defines a client-server architecture and a standard protocol that LLM vendors and tool builders can follow. Google's documentation points out that A2A solves a different problem than MCP does: it \"allows agents to communicate as agents (or as users) instead of as tools.\" The difference between a tool and an agent is that tools have structured I/O and behavior, while agents are autonomous and can solve new tasks using reasoning. In Google's vision, an agentic application requires both tools and agents. However, A2A docs do recommend that \"applications model A2A agents as MCP resources.\" A2A defines three types of actor: remote agents, which are \"blackbox\" agents on an A2A server; clients that request action from remote servers; and users (human users or services) that want to accomplish tasks using an agentic system. Like MCP, A2A uses JSON-RPC over HTTP for communication between clients and remote agents. The core abstraction used in the communication spec between agents is the task, which is created by a client and fulfilled by a remote agent. In a Hacker News discussion, several users compared A2A to MCP; some were not sure what value A2A proved over MCP, while others saw it as a \"superset\" of MCP and praised its \"clear documentation and explanation\" compared to MCP. User TS_Posts claimed to be working on A2A and wrote: [T]he current specification and samples are early. We are working on many more advanced examples and official SDKs and client/servers. We're working with partners, other Google teams, and framework providers to turn this into a stable standard. We're doing it in the open - so there are things that are missing because (a) it's early and (b) we want partners and the community to bring features to the table. tldr - this is NOT done. We want your feedback and sincerely appreciate it! The A2A source code is available on GitHub. Google also released a demo video showing collaboration between agents from different frameworks. About the Author Anthony Alford",
  "image": "https://res.infoq.com/news/2025/04/google-agentic-a2a/en/headerimage/generatedHeaderImage-1744467617495.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://developers.google.com/\"\u003eGoogle\u003c/a\u003e released the \u003ca href=\"https://google.github.io/A2A/#/\"\u003eAgent2Agent (A2A) Protocol\u003c/a\u003e, an open-source specification for building AI agents that can connect with other agents that support the protocol. Google has enlisted over 50 technology partners to contribute to A2A\u0026#39;s development.\u003c/p\u003e\n\n\u003cp\u003eGoogle announced the release at the recent \u003ca href=\"https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\"\u003eGoogle Cloud Next conference\u003c/a\u003e. A2A is billed as a \u0026#34;complement\u0026#34; to Anthropic\u0026#39;s \u003ca href=\"https://www.anthropic.com/news/model-context-protocol\"\u003eModel Context Protocol\u003c/a\u003e (MCP) and defines a client-server relationship between AI agents. Google developed the protocol with help from partners like \u003ca href=\"https://www.salesforce.com/\"\u003eSalesforce\u003c/a\u003e, \u003ca href=\"https://www.atlassian.com/\"\u003eAtlassian\u003c/a\u003e, and \u003ca href=\"https://www.langchain.com/\"\u003eLangChain\u003c/a\u003e, with the goal of creating an interoperability standard for any agent, regardless of vendor or framework. According to Google,\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eA2A has the potential to unlock a new era of agent interoperability, fostering innovation and creating more powerful and versatile agentic systems. We believe that this protocol will pave the way for a future where agents can seamlessly collaborate to solve complex problems and enhance our lives. We’re committed to building the protocol in collaboration with our partners and the community in the open. We’re releasing the protocol as open source and setting up clear pathways for contribution.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eInfoQ covered \u003ca href=\"http://www.infoq.com/news/2024/12/anthropic-model-context-protocol/\"\u003eAnthropic\u0026#39;s MCP release\u003c/a\u003e last year. Intended to solve the \u0026#34;MxN\u0026#34; problem---the combinatorial difficulty of integrating M different LLMs with N different tools---MCP defines a client-server architecture and a standard protocol that LLM vendors and tool builders can follow.\u003c/p\u003e\n\n\u003cp\u003eGoogle\u0026#39;s documentation points out that A2A solves a different problem than MCP does: it \u0026#34;allows agents to communicate as agents (or as users) instead of as tools.\u0026#34; The difference between a tool and an agent is that tools have structured I/O and behavior, while agents are autonomous and can solve new tasks using reasoning. In Google\u0026#39;s vision, an agentic application requires both tools and agents. However, A2A docs do recommend that \u0026#34;applications model A2A agents as MCP resources.\u0026#34;\u003c/p\u003e\n\n\u003cp\u003eA2A defines three types of \u003cem\u003eactor\u003c/em\u003e: \u003cem\u003eremote agents\u003c/em\u003e, which are \u0026#34;blackbox\u0026#34; agents on an A2A server; \u003cem\u003eclients\u003c/em\u003e that request action from remote servers; and \u003cem\u003eusers\u003c/em\u003e (human users or services) that want to accomplish tasks using an agentic system. Like MCP, A2A uses JSON-RPC over HTTP for communication between clients and remote agents. The core abstraction used in the communication spec between agents is the \u003cem\u003etask\u003c/em\u003e, which is created by a client and fulfilled by a remote agent.\u003c/p\u003e\n\n\u003cp\u003eIn a Hacker News discussion, several users \u003ca href=\"https://news.ycombinator.com/item?id=43631381\"\u003ecompared A2A to MCP\u003c/a\u003e; some were not sure what value A2A proved over MCP, while others saw it as a \u0026#34;superset\u0026#34; of MCP and praised its \u0026#34;clear documentation and explanation\u0026#34; compared to MCP. User TS_Posts claimed to be working on A2A and wrote:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e[T]he current specification and samples are early. We are working on many more advanced examples and official SDKs and client/servers. We\u0026#39;re working with partners, other Google teams, and framework providers to turn this into a stable standard. We\u0026#39;re doing it in the open - so there are things that are missing because (a) it\u0026#39;s early and (b) we want partners and the community to bring features to the table. tldr - this is NOT done. We want your feedback and sincerely appreciate it!\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://github.com/google/A2A\"\u003eA2A source code\u003c/a\u003e is available on GitHub. Google also released a \u003ca href=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/A2A_demo_v4.mp4\"\u003edemo video showing collaboration between agents\u003c/a\u003e from different frameworks.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Anthony-Alford\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eAnthony Alford\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-04-15T00:00:00Z",
  "modifiedTime": null
}
