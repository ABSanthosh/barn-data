{
  "id": "eaa6aed9-7b4d-4875-b194-158d9b92b8e7",
  "title": "Elevating your search experience: Stack Overflow for Teams ML-powered reranking experiment",
  "link": "https://stackoverflow.blog/2024/09/19/elevating-your-search-experience-stack-overflow-for-teams-ml-powered-reranking-experiment/",
  "description": "Today, we're excited to share details about our latest experiment that aims to make your search results in Stack Overflow for Teams Enterprise even more relevant and useful.",
  "author": "Adrian Brunetto",
  "published": "Thu, 19 Sep 2024 13:55:04 GMT",
  "source": "https://stackoverflow.blog/feed/",
  "categories": [
    "release",
    "so-for-teams",
    "search"
  ],
  "byline": "Adrian Brunetto",
  "length": 6049,
  "excerpt": "At Stack Overflow, we understand the central role search plays in helping technologists solve their problems, so we're constantly striving to improve the way you find the information you need. Today, we're excited to share details about our latest experiment that aims to make your search results in Stack Overflow for Teams Enterprise even more relevant and useful.",
  "siteName": "",
  "favicon": "https://stackoverflow.blog/apple-touch-icon.png",
  "text": "At Stack Overflow, we understand the central role search plays in helping technologists solve their problems, so we're constantly striving to improve the way you find the information you need. Today, we're excited to share details about our latest experiment that aims to make your search results in Stack Overflow for Teams Enterprise even more relevant and useful.As part of our ongoing journey to improve search functionality, which we first launched in January with our Improved Search initiative, we're introducing an ML-powered reranking system that will refine the order of search results. We know you want the most relevant content at the top of your search results when using our Search Bar, API, or Slack/Microsoft Teams integrations. In fact, our data shows that 88% of clicks happen within the first 10 results. Through this experiment, we will help ensure that the most relevant answers appear higher up in the search results listing so you can find the best answers faster.As a user, you may notice subtle but positive changes in your search experience:More relevant results at the top of the listImproved context-based ranking based on your specific queryEnhanced performance of our OverflowAI features, which rely on top search resultsThis experiment is designed to be non-intrusive, and we're starting small to ensure the best possible outcome for our users.Improved Search is not a one-time initiative—it's a commitment that requires continuous investment in data science, machine learning, and software engineering. This reranking experiment is just the first step in a series of planned search relevance improvements and experiments.As we roll out this experiment, we want to assure you that:We're starting conservatively with a phased rollout strategy.We'll be closely monitoring various metrics to ensure a positive impact.Your privacy and data security remain our top priority. There will be no changes to how your data is stored.We're excited about the potential improvements this experiment could bring to your Stack Overflow For Teams Enterprise experience. Stay tuned for future updates as we continue to refine and enhance our search capabilities.If you're interested in the technical aspects of our experiment, here's a more detailed look at what's happening behind the scenes.We're implementing a cross-encoder reranker, specifically the `cross-encoder/ms-marco-MiniLM-L-6-v2` model. This model has been fine-tuned on the MS Marco Passage Ranking task, a large-scale information retrieval corpus built from real user queries on Bing. This gives us a solid baseline to work with, as it's designed to understand the nuanced relationships between search queries and potential results.Our data shows that 88% of clicks happen within the first 10 results. In aggregate, we find that our customers are clicking approximately the 6th result on average. By improving the order within this crucial set, we can significantly enhance the search experience and the performance of OverflowAI, our AI-driven features. We also know that customers of our OverflowAI product depend on the top three results to power many of those features. Therefore, we're focusing our reranking efforts on just these top 10 results retrieved by our hybrid search algorithm.Implementation of the reranking system will increase customer’s ability to find content which they will find higher in their results and more likely to click into.In open benchmarks, this model has shown impressive improvements in Mean Reciprocal Rank (MRR) compared to a baseline of lexical search using BM25 on the MS Marco dataset.Baseline (BM25): 17.29 MRR@10Cross-encoder model: 39.01 MRR@10However, it's important to note that these numbers reflect performance on the dataset the model was fine-tuned on. In our specific use case, with our customers' private and unique data, we expect more modest improvements. Many factors can influence actual performance in a real-world setting, so we also use an internal dataset for offline evaluations.In our internal tests, we've observed promising results:Approximately 6% improvement in MRR compared to our first implementation of Improved Search11% improvement in MRR compared to our legacy search implementationDuring the live experiment, we'll be monitoring several key metrics:Click-Through Rate (CTR)LatencyRanking of clicked resultsRelevance scores of clicked results vs. remaining retrieved resultsWe've been preparing for scale from the ground up. To optimize performance and scalability while maintaining accuracy, we've employed ONNX Runtime. In our local experiments, this optimization has allowed us to:Reduce model latency by approximately halfSelect more cost-efficient machines for deploymentThese optimizations should help us scale the experiment without causing costs to skyrocket. However, it's worth noting that these results are from local experiments and may differ in our production environment.We're taking a cautious approach to ensure minimal disruption:Initial A/B testing with a subset of Enterprise user trafficGradual increase based on performance and user feedbackAbility to quickly adjust or disable the experiment if neededIt's important to note that while we're collecting performance metrics, we're committed to maintaining the highest standards of data privacy. No sensitive user data is or will be collected during this experiment.As we observe the metrics, the data will either confirm or reject our hypothesis. If successful, we will promote the reranking system in its current form as a permanent fixture in our search system. If unsuccessful, we will learn from the data and analyze how to re-approach this problem. In either case, we will come back to you with the results so you can be assured that we are committed to transparency and continuous improvement.As we gather data and insights from this experiment, we'll plan our next steps in the search improvement journey. Stay tuned for future blog updates that will keep you informed about the impacts, lessons learned, and next steps.",
  "image": "https://cdn.stackoverflow.co/images/jo7n4k8s/production/9862ecb5a61326024cb9534d5e1833571cc3d130-2400x1261.png?w=1200\u0026fm=png\u0026auto=format",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv itemprop=\"articleBody\"\u003e\u003cp\u003eAt Stack Overflow, we understand the central role search plays in helping technologists solve their problems, so we\u0026#39;re constantly striving to improve the way you find the information you need. Today, we\u0026#39;re excited to share details about our latest experiment that aims to make your search results in Stack Overflow for Teams Enterprise even more relevant and useful.\u003c/p\u003e\u003cp\u003eAs part of our ongoing journey to improve search functionality, which we first launched in January with our \u003ca href=\"https://stackoverflow.blog/2024/02/05/celebrating-and-improving-your-community-s-knowledge/\"\u003eImproved Search\u003c/a\u003e initiative, we\u0026#39;re introducing an ML-powered reranking system that will refine the order of search results. We know you want the most relevant content at the top of your search results when using our Search Bar, API, or Slack/Microsoft Teams integrations. In fact, our data shows that 88% of clicks happen within the first 10 results. Through this experiment, we will help ensure that the most relevant answers appear higher up in the search results listing so you can find the best answers faster.\u003c/p\u003e\u003cp\u003eAs a user, you may notice subtle but positive changes in your search experience:\u003c/p\u003e\u003col\u003e\u003cli\u003eMore relevant results at the top of the list\u003c/li\u003e\u003cli\u003eImproved context-based ranking based on your specific query\u003c/li\u003e\u003cli\u003eEnhanced performance of our OverflowAI features, which rely on top search results\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThis experiment is designed to be non-intrusive, and we\u0026#39;re starting small to ensure the best possible outcome for our users.\u003c/p\u003e\u003cp\u003eImproved Search is not a one-time initiative—it\u0026#39;s a commitment that requires continuous investment in data science, machine learning, and software engineering. This reranking experiment is just the first step in a series of planned search relevance improvements and experiments.\u003c/p\u003e\u003cp\u003eAs we roll out this experiment, we want to assure you that:\u003c/p\u003e\u003col\u003e\u003cli\u003eWe\u0026#39;re starting conservatively with a phased rollout strategy.\u003c/li\u003e\u003cli\u003eWe\u0026#39;ll be closely monitoring various metrics to ensure a positive impact.\u003c/li\u003e\u003cli\u003eYour privacy and data security remain our top priority. There will be no changes to how your data is stored.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eWe\u0026#39;re excited about the potential improvements this experiment could bring to your Stack Overflow For Teams Enterprise experience. Stay tuned for future updates as we continue to refine and enhance our search capabilities.\u003c/p\u003e\u003cp\u003eIf you\u0026#39;re interested in the technical aspects of our experiment, here\u0026#39;s a more detailed look at what\u0026#39;s happening behind the scenes.\u003c/p\u003e\u003cp\u003eWe\u0026#39;re implementing a cross-encoder reranker, specifically the `cross-encoder/ms-marco-MiniLM-L-6-v2` model. This model has been fine-tuned on the MS Marco Passage Ranking task, a large-scale information retrieval corpus built from real user queries on Bing. This gives us a solid baseline to work with, as it\u0026#39;s designed to understand the nuanced relationships between search queries and potential results.\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/238d41fe8d2c2bb0bd60656fbfbc2d190208e707-1600x1200.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eOur data shows that 88% of clicks happen within the first 10 results. In aggregate, we find that our customers are clicking approximately the 6th result on average. By improving the order within this crucial set, we can significantly enhance the search experience and the performance of OverflowAI, our AI-driven features. We also know that customers of our OverflowAI product depend on the top three results to power many of those features. Therefore, we\u0026#39;re focusing our reranking efforts on just these top 10 results retrieved by our hybrid search algorithm.\u003c/p\u003e\u003cp\u003eImplementation of the reranking system will increase customer’s ability to find content which they will find higher in their results and more likely to click into.\u003c/p\u003e\u003cp\u003eIn open benchmarks, this model has shown impressive improvements in Mean Reciprocal Rank (MRR) compared to a baseline of lexical search using BM25 on the MS Marco dataset.\u003c/p\u003e\u003cul\u003e\u003cli\u003eBaseline (BM25): 17.29 MRR@10\u003c/li\u003e\u003cli\u003eCross-encoder model: 39.01 MRR@10\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eHowever, it\u0026#39;s important to note that these numbers reflect performance on the dataset the model was fine-tuned on. In our specific use case, with our customers\u0026#39; private and unique data, we expect more modest improvements. Many factors can influence actual performance in a real-world setting, so we also use an internal dataset for offline evaluations.\u003c/p\u003e\u003cfigure\u003e\u003cimg loading=\"lazy\" src=\"https://cdn.stackoverflow.co/images/jo7n4k8s/production/f1f831d21bc763864bb808dd4b7d4fcd3ce0aefa-1600x1200.jpg?auto=format\"/\u003e\u003c/figure\u003e\u003cp\u003eIn our internal tests, we\u0026#39;ve observed promising results:\u003c/p\u003e\u003cul\u003e\u003cli\u003eApproximately 6% improvement in MRR compared to our first implementation of Improved Search\u003c/li\u003e\u003cli\u003e11% improvement in MRR compared to our legacy search implementation\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eDuring the live experiment, we\u0026#39;ll be monitoring several key metrics:\u003c/p\u003e\u003cul\u003e\u003cli\u003eClick-Through Rate (CTR)\u003c/li\u003e\u003cli\u003eLatency\u003c/li\u003e\u003cli\u003eRanking of clicked results\u003c/li\u003e\u003cli\u003eRelevance scores of clicked results vs. remaining retrieved results\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe\u0026#39;ve been preparing for scale from the ground up. To optimize performance and scalability while maintaining accuracy, we\u0026#39;ve employed ONNX Runtime. In our local experiments, this optimization has allowed us to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eReduce model latency by approximately half\u003c/li\u003e\u003cli\u003eSelect more cost-efficient machines for deployment\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThese optimizations should help us scale the experiment without causing costs to skyrocket. However, it\u0026#39;s worth noting that these results are from local experiments and may differ in our production environment.\u003c/p\u003e\u003cp\u003eWe\u0026#39;re taking a cautious approach to ensure minimal disruption:\u003c/p\u003e\u003col\u003e\u003cli\u003eInitial A/B testing with a subset of Enterprise user traffic\u003c/li\u003e\u003cli\u003eGradual increase based on performance and user feedback\u003c/li\u003e\u003cli\u003eAbility to quickly adjust or disable the experiment if needed\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eIt\u0026#39;s important to note that while we\u0026#39;re collecting performance metrics, we\u0026#39;re committed to maintaining the highest standards of data privacy. No sensitive user data is or will be collected during this experiment.\u003c/p\u003e\u003cp\u003eAs we observe the metrics, the data will either confirm or reject our hypothesis. If successful, we will promote the reranking system in its current form as a permanent fixture in our search system. If unsuccessful, we will learn from the data and analyze how to re-approach this problem. In either case, we will come back to you with the results so you can be assured that we are committed to transparency and continuous improvement.\u003c/p\u003e\u003cp\u003eAs we gather data and insights from this experiment, we\u0026#39;ll plan our next steps in the search improvement journey. Stay tuned for future blog updates that will keep you informed about the impacts, lessons learned, and next steps.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": null,
  "modifiedTime": null
}
