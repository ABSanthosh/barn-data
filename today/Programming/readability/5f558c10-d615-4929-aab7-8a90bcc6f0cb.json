{
  "id": "5f558c10-d615-4929-aab7-8a90bcc6f0cb",
  "title": "Stable Diffusion 3.5 Improves Text Rendering, Image Quality, Consistency, and More",
  "link": "https://www.infoq.com/news/2024/10/stable-diffusion-3-5-large/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Stability AI has released Stable Diffusion 3.5 Large, its most powerful text-to-image generation model to date, and Stable Diffusion 3.5 Large Turbo, with special emphasis on customizability, efficiency, and flexibility. Both models come with a free licensing model for non commercial and limited commercial use. By Sergio De Simone",
  "author": "Sergio De Simone",
  "published": "Fri, 25 Oct 2024 16:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Stability Diffusion",
    "Generative AI",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Sergio De Simone",
  "length": 3112,
  "excerpt": "Stability AI has released Stable Diffusion 3.5 Large, its most powerful text-to-image generation model to date, and Stable Diffusion 3.5 Large Turbo, with special emphasis on customizability, efficien",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20241022063455/apple-touch-icon.png",
  "text": "Stability AI has released Stable Diffusion 3.5 Large, its most powerful text-to-image generation model to date, and Stable Diffusion 3.5 Large Turbo, with special emphasis on customizability, efficiency, and flexibility. Both models come with a free licensing model for non commercial and limited commercial use. Stable Diffusion 3.5 Large is an 8 billion parameters model which can generate professional images at 1 megapixel resolution, says Stability AI. Stable Diffusion 3.5 Large Turbo is a distilled version of Stable Diffusion 3.5 Large that focuses on being faster by reducing the number of required steps to just four. Both models, says Stability AI, provide top-tier performance in prompt adherence and image quality. One of the goals behind the Stable Diffusion 3.5 models is customizability, meaning the possibility for users to fine-tune the model or build customized workflows. To train LoRAs with Stable Diffusion 3.5, you can use the existing SD3 training script with some additional caveats if you want to have it work with quantization. Stable Diffusion 3.5 is also optimized to run on standard consumer hardware, according to Stability AI, and to provide a diverse output, including skin tones, 3D images, photography, painting, and so on. Stable Diffusion 3.5 follows Stable Diffusion 3 Medium, released last June, which garnered criticism in several areas, including its ability to accurately depict human anatomy and specifically hands. In the 3.5 release announcement, Stability AI acknowledged the community's dissatisfaction and made clear 3.5 is not a quick fix but a step forward in Stable Diffusion evolution. Anyway, while Stable Diffusion 3.5 fixes the known issues with \"girls lying in the grass\", it still may fail with apparently basic prompts. As Stability AI explains, Stable Diffusion 3.5 has a similar architecture to SD3's, with two major changes: the use of QK normalization and of double attention layers. As mentioned, Stable Diffusion 3.5 is released under a permissive license allowing free use for non commercial projects and commercial purposes for creators whose total annual revenue is less than $1M. The free \"community\" model expressly forbids creating competing foundational models. While this could sound too restrictive, custom models trained using common customization techniques such as LoRAs, hypernetworks, finetunes, retrain, retrain from scratch are not considered \"foundational\". Later this month, Stability AI is going to release Stable Diffusion 3.5 Medium, using 2.5 billion parameters and designed to run on consumer hardware. This will further enable the creation of custom models on a variety of hardware, albeit with a slight loss of output quality. You can download Stable Diffusion 3.5 inference code from GitHub, while the model itself is available on huggingface. You can also use the model on platforms like Replicate, ComfyUI, and DeepInfra or directly using Stability AI API. About the Author Sergio De Simone",
  "image": "https://res.infoq.com/news/2024/10/stable-diffusion-3-5-large/en/headerimage/stable-diffusion-3-5-large-1729869649115.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://stability.ai/news/introducing-stable-diffusion-3-5\"\u003eStability AI has released Stable Diffusion 3.5\u003c/a\u003e Large, its most powerful text-to-image generation model to date, and Stable Diffusion 3.5 Large Turbo, with special emphasis on customizability, efficiency, and flexibility. Both models come with a free \u003ca href=\"https://stability.ai/community-license-agreement\"\u003elicensing model\u003c/a\u003e for non commercial and limited commercial use.\u003c/p\u003e\n\n\u003cp\u003eStable Diffusion 3.5 Large is an 8 billion parameters model which can generate professional images at 1 megapixel resolution, says Stability AI. Stable Diffusion 3.5 Large Turbo is a distilled version of Stable Diffusion 3.5 Large that focuses on being faster by reducing the number of required steps to just four. Both models, says Stability AI, provide top-tier performance in prompt adherence and image quality.\u003c/p\u003e\n\n\u003cp\u003eOne of the goals behind the Stable Diffusion 3.5 models is customizability, meaning the possibility for users to fine-tune the model or build customized workflows. To train LoRAs with Stable Diffusion 3.5, you can use the existing \u003ca href=\"https://huggingface.co/blog/sd3#dreambooth-and-lora-fine-tuning\"\u003eSD3 training script\u003c/a\u003e with \u003ca href=\"https://github.com/huggingface/blog/blob/main/sd3-5.md#training-loras-with-sd35-large-with-quantization\"\u003esome additional caveats\u003c/a\u003e if you want to have it work with quantization. Stable Diffusion 3.5 is also optimized to run on standard consumer hardware, according to Stability AI, and to provide a diverse output, including skin tones, 3D images, photography, painting, and so on.\u003c/p\u003e\n\n\u003cp\u003eStable Diffusion 3.5 follows Stable Diffusion 3 Medium, released last June, which garnered \u003ca href=\"https://x.com/EMostaque/status/1801686921967436056\"\u003ecriticism in several areas\u003c/a\u003e, including \u003ca href=\"https://dataconomy.com/2024/06/13/stable-diffusion-3-medium-sd3/\"\u003eits ability to accurately depict human anatomy and specifically hands\u003c/a\u003e. In the 3.5 release announcement, Stability AI acknowledged the community\u0026#39;s dissatisfaction and made clear 3.5 is not a quick fix but a step forward in Stable Diffusion evolution. Anyway, while Stable Diffusion 3.5 \u003ca href=\"https://www.reddit.com/r/StableDiffusion/comments/1g9jdxl/stable_diffusion_35_is_here/\"\u003efixes the known issues with \u0026#34;girls lying in the grass\u0026#34;\u003c/a\u003e, \u003ca href=\"https://x.com/MrDavids1/status/1848880862609477716\"\u003eit still may fail with apparently basic prompts\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eAs Stability AI explains, Stable Diffusion 3.5 has a similar architecture to SD3\u0026#39;s, with two major changes: the use of \u003ca href=\"https://research.google/blog/scaling-vision-transformers-to-22-billion-parameters/\"\u003eQK normalization\u003c/a\u003e and of double attention layers.\u003c/p\u003e\n\n\u003cp\u003eAs mentioned, Stable Diffusion 3.5 is released under a permissive license allowing free use for non commercial projects and commercial purposes for creators whose total annual revenue is less than $1M. The free \u0026#34;community\u0026#34; model expressly forbids creating competing foundational models. While this could sound too restrictive, custom models trained using common customization techniques such as \u003ca href=\"https://huggingface.co/docs/diffusers/en/training/lora\"\u003eLoRAs\u003c/a\u003e, \u003ca href=\"https://stable-diffusion-art.com/hypernetwork/\"\u003ehypernetworks\u003c/a\u003e, \u003ca href=\"https://huggingface.co/docs/transformers/en/training\"\u003efinetunes\u003c/a\u003e, retrain, retrain from scratch are not considered \u0026#34;foundational\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003eLater this month, Stability AI is going to release Stable Diffusion 3.5 Medium, using 2.5 billion parameters and designed to run on consumer hardware. This will further enable the creation of custom models on a variety of hardware, albeit with a slight loss of output quality.\u003c/p\u003e\n\n\u003cp\u003eYou can download \u003ca href=\"https://github.com/Stability-AI/sd3.5#stable-diffusion-35\"\u003eStable Diffusion 3.5 inference code from GitHub\u003c/a\u003e, while \u003ca href=\"https://huggingface.co/stabilityai/stable-diffusion-3.5-large/tree/main\"\u003ethe model itself is available on huggingface\u003c/a\u003e. You can also use the model on platforms like \u003ca href=\"https://replicate.com/stability-ai/stable-diffusion-3.5-large\"\u003eReplicate\u003c/a\u003e, \u003ca href=\"http://blog.comfy.org/sd3-5-comfyui/\"\u003eComfyUI\u003c/a\u003e, and \u003ca href=\"https://deepinfra.com/stabilityai/sd3.5\"\u003eDeepInfra\u003c/a\u003e or directly using \u003ca href=\"https://platform.stability.ai/docs/api-reference\"\u003eStability AI API\u003c/a\u003e.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Sergio-De-Simone\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSergio De Simone\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2024-10-25T00:00:00Z",
  "modifiedTime": null
}
