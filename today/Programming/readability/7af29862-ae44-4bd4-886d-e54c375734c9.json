{
  "id": "7af29862-ae44-4bd4-886d-e54c375734c9",
  "title": "Google Apigee Adds Built-in LLM Governance with Model Armor",
  "link": "https://www.infoq.com/news/2025/07/google-apigee-llm-model-armor/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Google Cloud has launched the public preview of Model Armor, a native LLM governance framework integrated into the Apigee API management platform. Detailed in a community post, Model Armor introduces out-of-the-box enforcement for LLM-specific policies such as prompt validation, output filtering, and token-level controls at the API layer. By Leela Kumili",
  "author": "Leela Kumili",
  "published": "Fri, 25 Jul 2025 09:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "API Gateway",
    "API",
    "Google Cloud Platform",
    "Governance",
    "Artificial Intelligence",
    "Large language models",
    "DevOps",
    "Architecture \u0026 Design",
    "news"
  ],
  "byline": "Leela Kumili",
  "length": 3307,
  "excerpt": "Google Cloud has launched the public preview of Model Armor, a native LLM governance framework integrated into the Apigee API management platform. Detailed in a community post, Model Armor introduces",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250724113904/apple-touch-icon.png",
  "text": "Google Cloud has launched the public preview of Model Armor, a native LLM governance framework integrated into the Apigee API management platform. Detailed in a community post, Model Armor introduces out-of-the-box enforcement for LLM-specific policies such as prompt validation, output filtering, and token-level controls at the API layer. Model Armor operates directly within Apigee’s proxy layer, where it inspects both requests and responses using declarative policies. It is available across all Apigee tiers, allowing teams to adopt LLM governance regardless of their subscription level. LLM APIs enable powerful new customer experiences and automation, but also introduce risks such as prompt injection (a significant OWASP Top 10 risk for LLMs) attacks and exposure of sensitive data. These policies can detect issues like jailbreak attempts, prompt injection, and exposure of personally identifiable information (PII), allowing outputs to be redacted, altered, or blocked as needed, all without modifying downstream systems. According to Google, \"with Model Armor, enterprises can treat LLM traffic with the same governance rigor as traditional APIs\". These controls are expressed in Apigee’s XML-based policy language, allowing teams to integrate LLM safety rules into existing APIs. A hands-on tutorial demonstrates how to apply these policies, covering prompt inspection, token quotas, and integration with Vertex AI. The tutorial includes a downloadable proxy template and step-by-step instructions for configuring Model Armor enforcement rules. Policy enforcement applies at the proxy layer for consistency across services and endpoints. Apigee and Model Armor architecture (Source: Google Community Post) Model Armor supports multiple LLM providers, including Vertex AI (Gemini, Meta Llama), OpenAI, Anthropic, and self-hosted models, allowing centralized governance across heterogeneous architectures. Additionally, Google has integrated Model Armor with Google Kubernetes Engine (GKE) and Security Command Center. This allows organizations to deploy Model Armor policies directly on inference gateways or load balancers running in GKE clusters. These policies inspect model prompts and responses before they reach internal services. Any violations are surfaced as security findings in the Security Command Center, providing centralized monitoring, alerting, and remediation workflows. This integration strengthens Model-Armor’s position as a bridge between LLM traffic governance and broader cloud security operations. Apigee as a gateway between the LLM application and models (Source: Google Community Post) The framework logs detailed metadata for each policy evaluation, including triggered filters and enforcement outcomes. These logs feed into Apigee’s observability and logging pipelines, supporting monitoring, anomaly detection, and post-incident analysis of LLM behavior. While other API gateways offer general-purpose traffic controls, they often require custom middleware for model-level safety. Model Armor aims to eliminate this complexity by offering native enforcement of LLM-specific policies within Apigee. About the Author Leela Kumili",
  "image": "https://res.infoq.com/news/2025/07/google-apigee-llm-model-armor/en/headerimage/google-apigee-llm-model-header-1753257544106.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eGoogle Cloud has launched the \u003ca href=\"https://www.googlecloudcommunity.com/gc/Apigee/Public-Preview-Apigee-Enhancements-for-Generative-AI/td-p/910675\"\u003epublic preview\u003c/a\u003e of Model Armor, a native LLM governance framework integrated into the Apigee API management platform. \u003ca href=\"https://www.googlecloudcommunity.com/gc/Cloud-Product-Articles/Secure-Your-AI-APIs-with-Apigee-amp-Model-Armor/ta-p/889962\"\u003eDetailed in a community post\u003c/a\u003e, Model Armor introduces out-of-the-box enforcement for LLM-specific policies such as prompt validation, output filtering, and token-level controls at the API layer.\u003c/p\u003e\n\n\u003cp\u003eModel Armor operates directly within Apigee’s proxy layer, where it inspects both requests and responses using declarative policies. It is available across \u003ca href=\"https://www.googlecloudcommunity.com/gc/News-Announcements/Apigee-Bytes-Newsletter-May-2025/m-p/916722#M408\"\u003eall Apigee tiers\u003c/a\u003e, allowing teams to adopt LLM governance regardless of their subscription level. LLM APIs enable powerful new customer experiences and automation, but also introduce risks such as prompt injection (a significant \u003ca href=\"https://genai.owasp.org/llm-top-10/\"\u003eOWASP Top 10 risk for LLMs\u003c/a\u003e) attacks and exposure of sensitive data.\u003c/p\u003e\n\n\u003cp\u003eThese policies can detect issues like jailbreak attempts, prompt injection, and exposure of personally identifiable information (PII), allowing outputs to be redacted, altered, or blocked as needed, all without modifying downstream systems. According to Google, \u0026#34;with Model Armor, enterprises can treat LLM traffic with the same governance rigor as traditional APIs\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003eThese controls are expressed in Apigee’s XML-based policy language, allowing teams to integrate LLM safety rules into existing APIs. A \u003ca href=\"https://cloud.google.com/apigee/docs/api-platform/tutorials/using-model-armor-policies\"\u003ehands-on tutorial\u003c/a\u003e demonstrates how to apply these policies, covering prompt inspection, token quotas, and integration with \u003ca href=\"https://cloud.google.com/vertex-ai?hl=en\"\u003eVertex AI\u003c/a\u003e. The tutorial includes a downloadable proxy template and step-by-step instructions for configuring Model Armor enforcement rules. Policy enforcement applies at the proxy layer for consistency across services and endpoints.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2025/07/google-apigee-llm-model-armor/en/resources/129figure-1-1753257543213.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2025/07/google-apigee-llm-model-armor/en/resources/129figure-1-1753257543213.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eApigee and Model Armor architecture (Source: \u003ca href=\"https://www.googlecloudcommunity.com/gc/Cloud-Product-Articles/Secure-Your-AI-APIs-with-Apigee-amp-Model-Armor/ta-p/889962\"\u003eGoogle Community Post\u003c/a\u003e)\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003cp\u003eModel Armor supports multiple LLM providers, including Vertex AI (Gemini, Meta Llama), OpenAI, Anthropic, and self-hosted models, allowing centralized governance across heterogeneous architectures.\u003c/p\u003e\n\n\u003cp\u003eAdditionally, Google has \u003ca href=\"https://cloud.google.com/security-command-center/docs/model-armor-gke-integration\"\u003eintegrated Model Armor with Google Kubernetes Engine\u003c/a\u003e (GKE) and Security Command Center. This allows organizations to deploy Model Armor policies directly on inference gateways or load balancers running in GKE clusters. These policies inspect model prompts and responses before they reach internal services. Any violations are surfaced as security findings in the Security Command Center, providing centralized monitoring, alerting, and remediation workflows. This integration strengthens Model-Armor’s position as a bridge between LLM traffic governance and broader cloud security operations.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg alt=\"\" data-src=\"news/2025/07/google-apigee-llm-model-armor/en/resources/102figure-2-1753257543214.jpg\" src=\"https://imgopt.infoq.com/fit-in/3000x4000/filters:quality(85)/filters:no_upscale()/news/2025/07/google-apigee-llm-model-armor/en/resources/102figure-2-1753257543214.jpg\" rel=\"share\"/\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003csmall\u003e\u003cstrong\u003eApigee as a gateway between the LLM application and models (Source: \u003ca href=\"https://www.googlecloudcommunity.com/gc/Cloud-Product-Articles/Secure-Your-AI-APIs-with-Apigee-amp-Model-Armor/ta-p/889962\"\u003eGoogle Community Post\u003c/a\u003e)\u003c/strong\u003e\u003c/small\u003e\u003c/p\u003e\n\n\u003cp\u003eThe framework logs detailed metadata for each policy evaluation, including triggered filters and enforcement outcomes. These logs feed into Apigee’s observability and logging pipelines, supporting monitoring, anomaly detection, and post-incident analysis of LLM behavior.\u003c/p\u003e\n\n\u003cp\u003eWhile other API gateways offer general-purpose traffic controls, they often require custom middleware for model-level safety. Model Armor aims to eliminate this complexity by offering native enforcement of LLM-specific policies within Apigee.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Leela-Kumili\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eLeela Kumili\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-07-25T00:00:00Z",
  "modifiedTime": null
}
