{
  "id": "b7028d33-76e6-4825-8df4-807136284468",
  "title": "Governing data products using fitness functions",
  "link": "https://martinfowler.com/articles/fitness-functions-data-products.html",
  "description": "",
  "author": "",
  "published": "2024-09-05T09:37:00-04:00",
  "source": "https://martinfowler.com/feed.atom",
  "categories": null,
  "byline": "Kiran Prakash",
  "length": 17511,
  "excerpt": "Fitness functions are an automated governance technique that can help scale the governance of data products in a data mesh – learn how to implement them.",
  "siteName": "martinfowler.com",
  "favicon": "",
  "text": "The key idea behind data mesh is to improve data management in large organizations by decentralizing ownership of analytical data. Instead of a central team managing all analytical data, smaller autonomous domain-aligned teams own their respective data products. This setup allows for these teams to be responsive to evolving business needs and effectively apply their domain knowledge towards data driven decision making. Having smaller autonomous teams presents different sets of governance challenges compared to having a central team managing all of analytical data in a central data platform. Traditional ways of enforcing governance rules using data stewards work against the idea of autonomous teams and do not scale in a distributed setup. Hence with the data mesh approach, the emphasis is to use automation to enforce governance rules. In this article we'll examine how to use the concept of fitness functions to enforce governance rules on data products in a data mesh.1 1: Fitness functions are only one aspect of automated data governance. The wider topic of the varied techniques that are available is outside the scope of the this article. For an outline of the broader topic of governance, see Dehghani. This is particularly important to ensure that the data products meet a minimum governance standard which in turn is crucial for their interoperability and the network effects that data mesh promises. Data product as an architectural quantum of the mesh The term “data product“ has unfortunately taken on various self-serving meanings, and fully disambiguating them could warrant a separate article. However, this highlights the need for organizations to strive for a common internal definition, and that's where governance plays a crucial role. For the purposes of this discussion let's agree on the definition of a data product as an architectural quantum of data mesh. Simply put, it's a self-contained, deployable, and valuable way to work with data. The concept applies the proven mindset and methodologies of software product development to the data space. In modern software development, we decompose software systems into easily composable units, ensuring they are discoverable, maintainable, and have committed service level objectives (SLOs). Similarly, a data product is the smallest valuable unit of analytical data, sourced from data streams, operational systems, or other external sources and also other data products, packaged specifically in a way to deliver meaningful business value. It includes all the necessary machinery to efficiently achieve its stated goal using automation. What are architectural fitness functions As described in the book Building Evolutionary Architectures, a fitness function is a test that is used to evaluate how close a given implementation is to its stated design objectives. By using fitness functions, we're aiming to “shift left” on governance, meaning we identify potential governance issues earlier in the timeline of the software value stream. This empowers teams to address these issues proactively rather than waiting for them to be caught upon inspections. With fitness functions, we prioritize 2: Governance by rule over Governance by inspection. Empowering teams to discover problems over Independent audits Continuous governance over Dedicated audit phase Since data products are the key building blocks of the data mesh architecture, ensuring that they meet certain architectural characteristics is paramount. It’s a common practice to have an organization wide data catalog to index these data products, they typically contain rich metadata about all published data products. Let's see how we can leverage all this metadata to verify architectural characteristics of a data product using fitness functions. Architectural characteristics of a Data Product In her book Data Mesh: Delivering Data-Driven Value at Scale, Zhamak lays out a few important architectural characteristics of a data product. Let's design simple assertions that can verify these characteristics. Later, we can automate these assertions to run against each data product in the mesh. Discoverability Assert that using a name in a keyword search in the catalog or a data product marketplace surfaces the data product in top-n results. Addressability Assert that the data product is accessible via a unique URI. Self Descriptiveness Assert that the data product has a proper English description explaining its purpose Assert for existence of meaningful field-level descriptions. Secure Assert that access to the data product is blocked for unauthorized users. Interoperability Assert for existence of business keys, e.g. customer_id, product_id. Assert that the data product supplies data via locally agreed and standardized data formats like CSV, Parquet etc. Assert for compliance with metadata registry standards such as “ISO/IEC 11179” Trustworthiness Assert for existence of published SLOs and SLIs Asserts that adherence to SLOs is good Valuable on its own Assert - based on the data product name, description and domain name - that the data product represents a cohesive information concept in its domain. Natively Accessible Assert that the data product supports output ports tailored for key personas, e.g. REST API output port for developers, SQL output port for data analysts. Patterns Most of the tests described above (except for the discoverability test) can be run on the metadata of the data product which is stored in the catalog. Let's look at some implementation options. Running assertions within the catalog Modern day data catalogs like Collibra and Datahub provide hooks using which we can run custom logic. For eg. Collibra has a feature called workflows and Datahub has a feature called Metadata Tests where one can execute these assertions on the metadata of the data product. Figure 1: Running assertions using custom hooks In a recent implementation of data mesh where we used Collibra as the catalog, we implemented a custom business asset called “Data Product” that made it straightforward to fetch all data assets of type “data product” and run assertions on them using workflows. Running assertions outside the catalog Not all catalogs provide hooks to run custom logic. Even when they do, it can be severely restrictive. We might not be able to use our favorite testing libraries and frameworks for assertions. In such cases, we can pull the metadata from the catalog using an API and run the assertions outside the catalog in a separate process. Figure 2: Using catalog APIs to retrieve data product metadata and run assertions in a separate process Let's consider a basic example. As part of the fitness functions for Trustworthiness, we want to ensure that the data product includes published service level objectives (SLOs). To achieve this, we can query the catalog using a REST API. Assuming the response is in JSON format, we can use any JSON path library to verify the existence of the relevant fields for SLOs. import json from jsonpath_ng import parse illustrative_get_dataproduct_response = '''{ \"entity\": { \"urn\": \"urn:li:dataProduct:marketing_customer360\", \"type\": \"DATA_PRODUCT\", \"aspects\": { \"dataProductProperties\": { \"name\": \"Marketing Customer 360\", \"description\": \"Comprehensive view of customer data for marketing.\", \"domain\": \"urn:li:domain:marketing\", \"owners\": [ { \"owner\": \"urn:li:corpuser:jdoe\", \"type\": \"DATAOWNER\" } ], \"uri\": \"https://example.com/dataProduct/marketing_customer360\" }, \"dataProductSLOs\": { \"slos\": [ { \"name\": \"Completeness\", \"description\": \"Row count consistency between deployments\", \"target\": 0.95 } ] } } } }''' def test_existence_of_service_level_objectives(): response = json.loads(illustrative_get_dataproduct_response) jsonpath_expr = parse('$.entity.aspects.dataProductSLOs.slos') matches = jsonpath_expr.find(response) data_product_name = parse('$.entity.aspects.dataProductProperties.name').find(response)[0].value assert matches, \"Service Level Objectives are missing for data product : \" + data_product_name assert matches[0].value, \"Service Level Objectives are missing for data product : \" + data_product_name Using LLMs to interpret metadata Many of the tests described above involve interpreting data product metadata like field and job descriptions and assessing their fitness, we believe Large Language Models (LLMs) are well-suited for this task. Let’s take one of the trickier fitness tests, the test for valuable on its own and explore how to implement it. A similar approach can be used for the self descriptiveness fitness test and the interoperability fitness test for compliance with metadata registry standards.3 3: At Thoughtworks, we’ve developed an as-yet internal tool called Pendant, currently in use with a few healthcare clients, to assist data product owners in creating glossary definitions. Pendant leverages a LLM to apply ISO 11179 Part 4 requirements and recommendations, evaluating whether a provided definition meets these standards. If a definition falls short, Pendant suggests improvements to ensure compliance I will use the Function calling feature of OpenAI models to extract structured output from the evaluations. For simplicity, I performed these evaluations using the OpenAI Playground with GPT-4 as our model. The same results can be achieved using their API. Once you have structured output from a large language model (LLM) in JSON format, you can write assertions similar to those described above. System Prompt You are a data product evaluator. Your job is to look at the meta data about a data product provided and evaluate if certain architectural properties of the data product holds true or not. Functions: 4 4: In the context of the OpenAI API, functions are predefined operations or tasks that a model can reference during a conversation. These functions are included in the prompt and guide the model in generating structured responses, including all necessary parameters for function invocation. For example, we’ve defined a function called get_data_product_fitness, which takes in a parameter named valuable_on_its_own. This parameter is an object with two properties: is_fit, a boolean indicating if the data product is independently valuable, and reason, a text field explaining the model's rationale. Functions { \"name\": \"get_data_product_fitness\", \"description\": \"Determine if data product is fit for purpose\", \"strict\": false, \"parameters\": { \"type\": \"object\", \"required\": [], \"properties\": { \"valuable_on_its_own\": { \"type\": \"object\", \"properties\": { \"is_fit\": { \"type\": \"boolean\", \"description\": \"True if the data product is valuable on it's own, false otherwise\" }, \"reason\": { \"type\": \"string\", \"description\": \"Reason why the data product is valuable on it's own or not\" } }, \"description\": \"Determines if data product represents a cohesive information concept in its domain. Has value on its own and can be used independent of other data products\" } } } } We can then send the data product metadata to the LLM to evaluate them. Here's a couple of results. Customer data product: We expect this data product to pass the test for valuable_on_its_own User: { \"entity\": { \"urn\": \"urn:li:dataProduct:marketing_customer360\", \"type\": \"DATA_PRODUCT\", \"aspects\": { \"dataProductProperties\": { \"name\": \"Marketing Customer 360\", \"description\": \"Comprehensive view of customer data for marketing.\", \"domain\": \"urn:li:domain:marketing\" } } } } Assistant: get_data_product_fitness({ \"valuable_on_its_own\": { \"is_fit\": true, \"reason\": \"The 'Marketing Customer 360' data product presumably provides a comprehensive view of customer data, which is valuable for marketing purposes. It could offer insights into customer behaviors, preferences, and engagement with marketing campaigns, all of which can be used to improve marketing strategies.\" } }) Product_Id data product: We expect this data product to fail the test for valuable_on_its_own. As product id needs to be always joined with product or customer to have any use. User: { \"entity\": { \"urn\": \"urn:li:dataProduct:product_id\", \"type\": \"DATA_PRODUCT\", \"aspects\": { \"dataProductProperties\": { \"name\": \"Product_Id\", \"description\": \"Table representing product ids per customer\", \"domain\": \"urn:li:domain:marketing\" } } } } Assistant: get_data_product_fitness({ \"valuable_on_its_own\": { \"is_fit\": false, \"reason\": \"The 'Product_Id' data product may not be valuable on its own. It simply represents product ids per customer and lacks contextual information about what those products are. For it to be meaningful, it would likely need to be used in conjunction with other data products that provide details about the products themselves.\" } }) Publishing the results Once we have the results of the assertions, we can display them on a dashboard. Tools like Dashing and Dash are well-suited for creating lightweight dashboards. Additionally, some data catalogs offer the capability to build custom dashboards as well. Figure 3: A dashboard with green and red data products, grouped by domain, with the ability to drill down and view the failed fitness tests Publicly sharing these dashboards within the organization can serve as a powerful incentive for the teams to adhere to the governance standards. After all, no one wants to be the team with the most red marks or unfit data products on the dashboard. Data product consumers can also use this dashboard to make informed decisions about the data products they want to use. They'd naturally prefer data products that are fit over those that are not. Necessary but not sufficient While these fitness functions are typically run centrally within the data platform, it remains the responsibility of the data product teams to ensure their data products pass the fitness tests. It is important to note that the primary goal of the fitness functions is to ensure adherence to the basic governance standards. However, this does not absolve the data product teams from considering the specific requirements of their domain when building and publishing their data product. For example, merely ensuring that the access is blocked by default is not sufficient to guarantee the security of a data product containing clinical trial data. Such teams may need to implement additional measures, such as differential privacy techniques, to achieve true data security. Having said that, fitness functions are extremely useful. For instance, in one of our client implementations, we found that over 80% of published data products failed to pass basic fitness tests when evaluated retrospectively. Conclusion We have learnt that fitness functions are an effective tool for governance in Data Mesh. Given that the term “Data Product” is still often interpreted according to individual convenience, fitness functions help enforce governance standards mutually agreed upon by the data product teams . This, in turn, helps us to build an ecosystem of data products that are reusable and interoperable. Having to adhere to the standards set by fitness functions encourages teams to build data products using the established “paved roads” provided by the platform, thereby simplifying the maintenance and evolution of these data products. Publishing results of fitness functions on internal dashboards enhances the perception of data quality and helps build confidence and trust among data product consumers. We encourage you to adopt the fitness functions for data products described in this article as part of your Data Mesh journey.",
  "image": "https://martinfowler.com/articles/fitness-functions-data-products/card.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\u003cp\u003eThe key idea behind data mesh is to improve data management in large\n    organizations by decentralizing ownership of analytical data. Instead of a\n    central team managing all analytical data, smaller autonomous domain-aligned\n    teams own their respective data products. This setup allows for these teams\n    to be responsive to evolving business needs and effectively apply their\n    domain knowledge towards data driven decision making.\u003c/p\u003e\n\n\n\n\u003cp\u003eHaving smaller autonomous teams presents different sets of governance\n    challenges compared to having a central team managing all of analytical data\n    in a central data platform. Traditional ways of enforcing governance rules\n    using data stewards work against the idea of autonomous teams and do not\n    scale in a distributed setup. Hence with the data mesh approach, the emphasis\n    is to use automation to enforce governance rules. In this article we\u0026#39;ll\n    examine how to use the concept of fitness functions to enforce governance\n    rules on data products in a data mesh.\u003cspan data-footnote=\"footnote-wider-gov\"\u003e1\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cspan\u003e1: \u003c/span\u003eFitness functions are only one aspect of automated\n    data governance. The wider topic of the varied techniques that are available\n    is outside the scope of the this article. For an outline of the broader\n    topic of governance, see \u003ca href=\"https://www.amazon.com/gp/product/1492092398/ref=as_li_tl?ie=UTF8\u0026amp;camp=1789\u0026amp;creative=9325\u0026amp;creativeASIN=1492092398\u0026amp;linkCode=as2\u0026amp;tag=martinfowlerc-20\"\u003eDehghani\u003c/a\u003e.\n    \u003c/p\u003e\n\n\u003cp\u003eThis is particularly important to ensure that the data products meet a\n    minimum governance standard which in turn is crucial for their\n    interoperability and the network effects that data mesh promises.\u003c/p\u003e\n\n\u003csection id=\"DataProductAsAnArchitecturalQuantumOfTheMesh\"\u003e\n\u003ch2\u003eData product as an architectural quantum of the mesh\u003c/h2\u003e\n\n\u003cp\u003eThe term “\u003ca href=\"https://martinfowler.com/articles/data-mesh-principles.html#DataAsAProduct\"\u003edata product\u003c/a\u003e“ has\n      unfortunately taken on various self-serving meanings, and fully\n      disambiguating them could warrant a separate article. However, this\n      highlights the need for organizations to strive for a common internal\n      definition, and that\u0026#39;s where governance plays a crucial role.\u003c/p\u003e\n\n\u003cp\u003eFor the purposes of this discussion let\u0026#39;s agree on the definition of a\n      data product as an \u003ca href=\"https://www.oreilly.com/library/view/building-evolutionary-architectures/9781491986356/ch04.html\"\u003earchitectural quantum\u003c/a\u003e\n      of data mesh. Simply put, it\u0026#39;s a self-contained, deployable, and valuable\n      way to work with data. The concept applies the proven mindset and\n      methodologies of software product development to the data space. \u003c/p\u003e\n\n\u003cp\u003eIn modern software development, we decompose software systems into\n      easily composable units, ensuring they are discoverable, maintainable, and\n      have committed service level objectives (SLOs). Similarly, a data product\n      is the smallest valuable unit of analytical data, sourced from data\n      streams, operational systems, or other external sources and also other\n      data products, packaged specifically in a way to deliver meaningful\n      business value. It includes all the necessary machinery to efficiently\n      achieve its stated goal using automation.\u003c/p\u003e\n\u003c/section\u003e\n\n\u003csection id=\"WhatAreArchitecturalFitnessFunctions\"\u003e\n\u003ch2\u003eWhat are architectural fitness functions\u003c/h2\u003e\n\n\u003cp\u003eAs described in the book \u003ca href=\"https://martinfowler.com/articles/evo-arch-forward.html\"\u003eBuilding Evolutionary\n      Architectures\u003c/a\u003e,\n      a fitness function is a test that is used to evaluate how close a given\n      implementation is to its stated design objectives.\u003c/p\u003e\n\n\u003cp\u003e\n      By using fitness functions, we\u0026#39;re aiming to\n        \u003ca href=\"https://martinfowler.com/articles/rise-test-impact-analysis.html#ShiftLeftAndRight\"\u003e“shift left”\u003c/a\u003e on governance, meaning we\n        identify potential governance issues earlier in the timeline of\n      the software value stream. This empowers teams to address these issues\n      proactively rather than waiting for them to be caught upon inspections.\n      \u003c/p\u003e\n\n\u003cp\u003e\n      With fitness functions, we prioritize \u003cspan data-footnote=\"footnote-comp-values\"\u003e2\u003c/span\u003e:\n      \u003c/p\u003e\n\n\n\n\u003cdiv\u003e\n\u003cul\u003e\n\u003cli\u003eGovernance by rule \u003ci\u003eover\u003c/i\u003e Governance by inspection.\n          \u003c/li\u003e\n\n\u003cli\u003eEmpowering teams to discover problems \u003ci\u003eover\u003c/i\u003e Independent\n          audits\u003c/li\u003e\n\n\u003cli\u003eContinuous governance \u003ci\u003eover\u003c/i\u003e Dedicated audit phase\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\n\n\u003cp\u003eSince data products are the key building blocks of the data mesh\n      architecture, ensuring that they meet certain architectural\n      characteristics is paramount. It’s a common practice to have an\n      organization wide data catalog to index these data products, they\n      typically contain rich metadata about all published data products. Let\u0026#39;s\n      see how we can leverage all this metadata to verify architectural\n      characteristics of a data product using fitness functions.\u003c/p\u003e\n\u003c/section\u003e\n\n\u003csection id=\"ArchitecturalCharacteristicsOfADataProduct\"\u003e\n\u003ch2\u003eArchitectural characteristics of a Data Product\u003c/h2\u003e\n\n\u003cp\u003eIn her book \u003ca href=\"https://www.amazon.com/gp/product/1492092398/ref=as_li_tl?ie=UTF8\u0026amp;camp=1789\u0026amp;creative=9325\u0026amp;creativeASIN=1492092398\u0026amp;linkCode=as2\u0026amp;tag=martinfowlerc-20\"\u003eData Mesh: Delivering Data-Driven Value at\n      Scale,\u003c/a\u003e\n      Zhamak lays out a few important architectural characteristics of a data\n      product. Let\u0026#39;s design simple assertions that can verify these\n      characteristics. Later, we can automate these assertions to run against\n      each data product in the mesh.\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cdiv\u003e\n\u003cp\u003eDiscoverability\u003c/p\u003e\n\n\u003cp\u003eAssert that using a name in a keyword search in the catalog or a data\n          product marketplace surfaces the data product in top-n\n          results.\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eAddressability\u003c/p\u003e\n\n\u003cp\u003eAssert that the data product is accessible via a unique\n          URI.\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eSelf Descriptiveness\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cp\u003e Assert that the data product has a proper English description explaining\n          its purpose \u003c/p\u003e\n\n\u003cp\u003e Assert for existence of meaningful field-level descriptions.\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eSecure\u003c/p\u003e\n\n\u003cp\u003eAssert that access to the data product is blocked for\n            unauthorized users.\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eInteroperability\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eAssert for existence of business keys, e.g.\n          \u003ccode\u003ecustomer_id\u003c/code\u003e, \u003ccode\u003eproduct_id\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eAssert that the data product supplies data via locally agreed and\n          standardized data formats like CSV, Parquet etc.\u003c/p\u003e\n\n\u003cp\u003eAssert for compliance with metadata registry standards such as\n            \u003ca href=\"https://en.wikipedia.org/wiki/ISO/IEC_11179\"\u003e“ISO/IEC 11179”\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eTrustworthiness\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eAssert for existence of published SLOs and SLIs\u003c/p\u003e\n\n\u003cp\u003eAsserts that adherence to SLOs is good\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eValuable on its own\u003c/p\u003e\n\n\u003cp\u003eAssert - based on the data product name, description and domain\n          name - \n          that the data product represents a cohesive information concept in its\n          domain.\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eNatively Accessible\u003c/p\u003e\n\n\u003cp\u003eAssert that the data product supports output ports tailored for key\n          personas, e.g. REST API output port for developers, SQL output port\n          for data analysts.\u003c/p\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/section\u003e\n\n\u003csection id=\"Patterns\"\u003e\n\u003ch2\u003ePatterns\u003c/h2\u003e\n\n\u003cp\u003eMost of the tests described above (except for the discoverability test)\n      can be run on the metadata of the data product which is stored in the\n      catalog. Let\u0026#39;s look at some implementation options.\u003c/p\u003e\n\n\u003csection id=\"RunningAssertionsWithinTheCatalog\"\u003e\n\u003ch3\u003eRunning assertions within the catalog\u003c/h3\u003e\n\n\u003cp\u003eModern day data catalogs like Collibra and Datahub provide hooks using\n        which we can run custom logic. For eg. Collibra has a feature called \u003ca href=\"https://developer.collibra.com/tutorials/workflows-hello-world\"\u003eworkflows\u003c/a\u003e\n        and Datahub has a feature called \u003ca href=\"https://datahubproject.io/docs/tests/metadata-tests/\"\u003eMetadata\n        Tests\u003c/a\u003e where one can execute these assertions on the metadata of the\n        data product.\u003c/p\u003e\n\n\u003cdiv id=\"inside-catalog.png\"\u003e\u003cp\u003e\u003cimg src=\"https://martinfowler.com/articles/fitness-functions-data-products/inside-catalog.png\"/\u003e\u003c/p\u003e\u003cp\u003eFigure 1: Running assertions using custom hooks\u003c/p\u003e\n\u003c/div\u003e\n\n\n\n\u003cp\u003eIn a recent implementation of data mesh where we used Collibra as the\n        catalog, we implemented a custom business asset called “Data Product”\n        that made it straightforward to fetch all data assets of type “data\n        product” and run assertions on them using workflows.\u003c/p\u003e\n\u003c/section\u003e\n\n\u003csection id=\"RunningAssertionsOutsideTheCatalog\"\u003e\n\u003ch3\u003eRunning assertions outside the catalog\u003c/h3\u003e\n\n\u003cp\u003eNot all catalogs provide hooks to run custom logic. Even when they\n        do, it can be severely restrictive. We might not be able to use our\n        favorite testing libraries and frameworks for assertions. In such cases,\n        we can pull the metadata from the catalog using an API and run the\n        assertions outside the catalog in a separate process.\u003c/p\u003e\n\n\u003cdiv id=\"outside-catalog.png\"\u003e\u003cp\u003e\u003cimg src=\"https://martinfowler.com/articles/fitness-functions-data-products/outside-catalog.png\"/\u003e\u003c/p\u003e\u003cp\u003eFigure 2: Using catalog APIs to retrieve data product metadata\n        and run assertions in a separate process\u003c/p\u003e\n\u003c/div\u003e\n\n\n\n\u003cp\u003eLet\u0026#39;s consider a basic example. As part of the fitness functions for\n          \u003ci\u003eTrustworthiness\u003c/i\u003e, we want to ensure that the data product includes\n        published service level objectives (SLOs). To achieve this, we can query\n        the catalog using a REST API. Assuming the response is in JSON format,\n        we can use any JSON path library to verify the existence of the relevant\n        fields for SLOs.\u003c/p\u003e\n\n\u003cpre\u003eimport json\nfrom jsonpath_ng import parse\n\n\nillustrative_get_dataproduct_response = \u0026#39;\u0026#39;\u0026#39;{\n  \u0026#34;entity\u0026#34;: {\n    \u0026#34;urn\u0026#34;: \u0026#34;urn:li:dataProduct:marketing_customer360\u0026#34;,\n    \u0026#34;type\u0026#34;: \u0026#34;DATA_PRODUCT\u0026#34;,\n    \u0026#34;aspects\u0026#34;: {\n      \u0026#34;dataProductProperties\u0026#34;: {\n        \u0026#34;name\u0026#34;: \u0026#34;Marketing Customer 360\u0026#34;,\n        \u0026#34;description\u0026#34;: \u0026#34;Comprehensive view of customer data for marketing.\u0026#34;,\n        \u0026#34;domain\u0026#34;: \u0026#34;urn:li:domain:marketing\u0026#34;,\n        \u0026#34;owners\u0026#34;: [\n          {\n            \u0026#34;owner\u0026#34;: \u0026#34;urn:li:corpuser:jdoe\u0026#34;,\n            \u0026#34;type\u0026#34;: \u0026#34;DATAOWNER\u0026#34;\n          }\n        ],\n        \u0026#34;uri\u0026#34;: \u0026#34;https://example.com/dataProduct/marketing_customer360\u0026#34;\n      },\n      \u0026#34;dataProductSLOs\u0026#34;: {\n        \u0026#34;slos\u0026#34;: [\n          {\n            \u0026#34;name\u0026#34;: \u0026#34;Completeness\u0026#34;,\n            \u0026#34;description\u0026#34;: \u0026#34;Row count consistency between deployments\u0026#34;,\n            \u0026#34;target\u0026#34;: 0.95\n          }\n        ]\n      }\n    }\n  }\n}\u0026#39;\u0026#39;\u0026#39;\n\n\ndef test_existence_of_service_level_objectives():\n    response = json.loads(illustrative_get_dataproduct_response)\n    jsonpath_expr = parse(\u0026#39;$.entity.aspects.dataProductSLOs.slos\u0026#39;)\n    matches = jsonpath_expr.find(response)\n\n    data_product_name = parse(\u0026#39;$.entity.aspects.dataProductProperties.name\u0026#39;).find(response)[0].value\n\n    assert matches, \u0026#34;Service Level Objectives are missing for data product : \u0026#34; + data_product_name\n    assert matches[0].value, \u0026#34;Service Level Objectives are missing for data product : \u0026#34; + data_product_name\n\n\u003c/pre\u003e\n\u003c/section\u003e\n\n\u003csection id=\"UsingLlmsToInterpretMetadata\"\u003e\n\u003ch3\u003eUsing LLMs to interpret metadata\u003c/h3\u003e\n\n\u003cp\u003eMany of the tests described above involve interpreting data product\n        metadata like field and job descriptions and assessing their fitness, we\n        believe Large Language Models (LLMs) are well-suited for this task.\u003c/p\u003e\n\n\u003cp\u003eLet’s take one of the trickier fitness tests, the test for \u003ci\u003evaluable\n        on its own\u003c/i\u003e and explore how to implement it. A similar approach can be\n        used for the \u003ci\u003eself descriptiveness\u003c/i\u003e fitness test and the\n          \u003ci\u003einteroperability \u003c/i\u003e fitness\n        test for compliance with metadata registry standards.\u003cspan data-footnote=\"footnote-pendant\"\u003e3\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cspan\u003e3: \u003c/span\u003e\n        At Thoughtworks, we’ve developed an as-yet internal tool called Pendant,\n        currently in use with a few healthcare clients, to assist data product\n        owners in creating glossary definitions.\n\n        Pendant leverages a LLM to apply ISO 11179 Part 4 requirements and\n        recommendations, evaluating whether a provided definition meets these standards.\n        If a definition falls short, Pendant suggests improvements to ensure\n        compliance\n        \u003c/p\u003e\n\n\u003cp\u003eI will use the \u003ci\u003eFunction calling\u003c/i\u003e feature of OpenAI models to\n        extract structured output from the evaluations. For simplicity, I\n        performed these evaluations using the OpenAI Playground with GPT-4 as\n        our model. The same results can be achieved using their API. Once you\n        have structured output from a large language model (LLM) in JSON format,\n        you can write assertions similar to those described above.\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cp\u003eSystem Prompt\u003c/p\u003e\u003cp\u003e\n\n          You are a data product evaluator. Your job is to look at the meta data\n          about a data product provided and evaluate if certain architectural\n          properties of the data product holds true or not.\n        \u003c/p\u003e\u003c/div\u003e\n\n\u003cp\u003eFunctions: \u003cspan data-footnote=\"footnote-open-ai-fn\"\u003e4\u003c/span\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cspan\u003e4: \u003c/span\u003eIn the context of the OpenAI API,\n          \u003ci\u003efunctions\u003c/i\u003e are predefined operations or tasks that a model can\n          reference during a conversation. These functions are included in the prompt\n          and guide the model in generating structured responses, including all\n          necessary parameters for function invocation. For example, we’ve defined\n          a function called \u003ccode\u003eget_data_product_fitness\u003c/code\u003e, which takes in a parameter\n          named \u003ccode\u003evaluable_on_its_own\u003c/code\u003e. This parameter is an object with two\n          properties: \u003ccode\u003eis_fit\u003c/code\u003e, a boolean indicating if the data product is\n          independently valuable, and \u003ccode\u003ereason\u003c/code\u003e, a text field explaining the\n          model\u0026#39;s rationale. \u003c/p\u003e\n\n\n\n\u003cdiv\u003e\n\u003cp\u003eFunctions\u003c/p\u003e\n\n\u003cpre\u003e{\n  \u0026#34;name\u0026#34;: \u0026#34;get_data_product_fitness\u0026#34;,\n  \u0026#34;description\u0026#34;: \u0026#34;Determine if data product is fit for purpose\u0026#34;,\n  \u0026#34;strict\u0026#34;: false,\n  \u0026#34;parameters\u0026#34;: {\n    \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;,\n    \u0026#34;required\u0026#34;: [],\n    \u0026#34;properties\u0026#34;: {\n      \u0026#34;valuable_on_its_own\u0026#34;: {\n        \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;,\n        \u0026#34;properties\u0026#34;: {\n          \u0026#34;is_fit\u0026#34;: {\n            \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34;,\n            \u0026#34;description\u0026#34;: \u0026#34;True if the data product is valuable on it\u0026#39;s own, false otherwise\u0026#34;\n          },\n          \u0026#34;reason\u0026#34;: {\n            \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;,\n            \u0026#34;description\u0026#34;: \u0026#34;Reason why the data product is valuable on it\u0026#39;s own or not\u0026#34;\n          }\n        },\n        \u0026#34;description\u0026#34;: \u0026#34;Determines if data product represents a cohesive\n                        information concept in its domain. Has value on its own\n                        and can be used independent of other data products\u0026#34;\n      }\n    }\n  }\n}\n\u003c/pre\u003e\n\u003c/div\u003e\n\n\u003cp\u003eWe can then send the data product metadata to the LLM to evaluate\n        them. Here\u0026#39;s a couple of results. \u003c/p\u003e\n\n\u003cp\u003e\u003ci\u003eCustomer data product\u003c/i\u003e: We expect this data product to pass the test\n        for \u003ci\u003evaluable_on_its_own\u003c/i\u003e\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cpre\u003eUser:\n{\n  \u0026#34;entity\u0026#34;: {\n    \u0026#34;urn\u0026#34;: \u0026#34;urn:li:dataProduct:marketing_customer360\u0026#34;,\n    \u0026#34;type\u0026#34;: \u0026#34;DATA_PRODUCT\u0026#34;,\n    \u0026#34;aspects\u0026#34;: {\n      \u0026#34;dataProductProperties\u0026#34;: {\n        \u0026#34;name\u0026#34;: \u0026#34;Marketing Customer 360\u0026#34;,\n        \u0026#34;description\u0026#34;: \u0026#34;Comprehensive view of customer data for marketing.\u0026#34;,\n        \u0026#34;domain\u0026#34;: \u0026#34;urn:li:domain:marketing\u0026#34;\n      }\n    }\n  }\n}\n\nAssistant:\n \n get_data_product_fitness({\n  \u0026#34;valuable_on_its_own\u0026#34;: {\n    \u0026#34;is_fit\u0026#34;: true,\n    \u0026#34;reason\u0026#34;: \u0026#34;The \u0026#39;Marketing Customer 360\u0026#39; data product presumably provides a\n               comprehensive view of customer data, which is valuable for marketing\n               purposes. It could offer insights into customer behaviors, preferences,\n               and engagement with marketing campaigns, all of which can be used to\n               improve marketing strategies.\u0026#34;\n  }\n})\n\u003c/pre\u003e\n\u003c/div\u003e\n\n\u003cp\u003e\u003ci\u003eProduct_Id data product\u003c/i\u003e: We expect this data product to fail the\n        test for \u003ci\u003evaluable_on_its_own\u003c/i\u003e. As product id needs to be always joined\n        with product or customer to have any use.\u003c/p\u003e\n\n\u003cdiv\u003e\n\u003cpre\u003eUser:\n{\n  \u0026#34;entity\u0026#34;: {\n    \u0026#34;urn\u0026#34;: \u0026#34;urn:li:dataProduct:product_id\u0026#34;,\n    \u0026#34;type\u0026#34;: \u0026#34;DATA_PRODUCT\u0026#34;,\n    \u0026#34;aspects\u0026#34;: {\n      \u0026#34;dataProductProperties\u0026#34;: {\n        \u0026#34;name\u0026#34;: \u0026#34;Product_Id\u0026#34;,\n        \u0026#34;description\u0026#34;: \u0026#34;Table representing product ids per customer\u0026#34;,\n        \u0026#34;domain\u0026#34;: \u0026#34;urn:li:domain:marketing\u0026#34;\n      }\n    }\n  }\n}\n\nAssistant: \n \n get_data_product_fitness({\n  \u0026#34;valuable_on_its_own\u0026#34;: {\n    \u0026#34;is_fit\u0026#34;: false,\n    \u0026#34;reason\u0026#34;: \u0026#34;The \u0026#39;Product_Id\u0026#39; data product may not be valuable on its own. It simply\n               represents product ids per customer and lacks contextual information\n               about what those products are. For it to be meaningful, it would\n               likely need to be used in conjunction with other data products that\n               provide details about the products themselves.\u0026#34;\n  }\n})\n\u003c/pre\u003e\n\u003c/div\u003e\n\u003c/section\u003e\n\n\u003csection id=\"PublishingTheResults\"\u003e\n\u003ch3\u003ePublishing the results\u003c/h3\u003e\n\n\u003cp\u003eOnce we have the results of the assertions, we can display them on a\n        dashboard. Tools like \u003ca href=\"http://dashing.io/\"\u003eDashing\u003c/a\u003e and\n          \u003ca href=\"https://dash.plotly.com/\"\u003eDash\u003c/a\u003e are well-suited for creating lightweight\n        dashboards. Additionally, some data catalogs offer the capability to build custom dashboards as well.\u003c/p\u003e\n\n\u003cdiv id=\"supervision-plane-dashbaord.png\"\u003e\u003cp\u003e\u003cimg src=\"https://martinfowler.com/articles/fitness-functions-data-products/supervision-plane-dashbaord.png\" width=\"960\"/\u003e\u003c/p\u003e\u003cp\u003eFigure 3:  A dashboard with green and red data products, grouped by \n        domain, with the ability to drill down and view the failed fitness tests\u003c/p\u003e\n\u003c/div\u003e\n\n\n\n\u003cp\u003ePublicly sharing these dashboards within the organization\n        can serve as a powerful incentive for the teams to adhere to the\n        governance standards. After all, no one wants to be the team with the\n        most red marks or unfit data products on the dashboard.\u003c/p\u003e\n\n\u003cp\u003eData product consumers can also use this dashboard to make informed\n        decisions about the data products they want to use. They\u0026#39;d naturally\n        prefer data products that are fit over those that are not.\u003c/p\u003e\n\u003c/section\u003e\n\u003c/section\u003e\n\n\u003csection id=\"NecessaryButNotSufficient\"\u003e\n\u003ch2\u003eNecessary but not sufficient\u003c/h2\u003e\n\n\u003cp\u003eWhile these fitness functions are typically run centrally within the\n      data platform, it remains the responsibility of the data product teams to\n      ensure their data products pass the fitness tests. It is important to note\n      that the primary goal of the fitness functions is to ensure adherence to\n      the basic governance standards. However, this does not absolve the data\n      product teams from considering the specific requirements of their domain\n      when building and publishing their data product.\u003c/p\u003e\n\n\u003cp\u003eFor example, merely ensuring that the access is blocked by default is\n      not sufficient to guarantee the security of a data product containing\n      clinical trial data. Such teams may need to implement additional measures,\n      such as differential privacy techniques, to achieve true data\n      security.\u003c/p\u003e\n\n\u003cp\u003eHaving said that, fitness functions are extremely useful. For instance,\n      in one of our client implementations, we found that over 80% of published\n      data products failed to pass basic fitness tests when evaluated\n      retrospectively.\u003c/p\u003e\n\u003c/section\u003e\n\n\u003csection id=\"Conclusion\"\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\n\u003cp\u003eWe have learnt that fitness functions are an effective tool for\n      governance in Data Mesh. Given that the term “Data Product” is still often\n      interpreted according to individual convenience, fitness functions help\n      enforce governance standards mutually agreed upon by the data product\n      teams . This, in turn, helps us to build an ecosystem of data products\n      that are reusable and interoperable.\u003c/p\u003e\n\n\u003cp\u003eHaving to adhere to the standards set by fitness functions encourages\n      teams to build data products using the established “paved roads”\n      provided by the platform, thereby simplifying the maintenance and\n      evolution of these data products. Publishing results of fitness functions\n      on internal dashboards enhances the perception of data quality and helps\n      build confidence and trust among data product consumers.\u003c/p\u003e\n\n\u003cp\u003eWe encourage you to adopt the fitness functions for data products\n      described in this article as part of your Data Mesh journey.\u003c/p\u003e\n\u003c/section\u003e\n\n\u003chr/\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "19 min read",
  "publishedTime": null,
  "modifiedTime": "2024-09-05T00:00:00Z"
}
