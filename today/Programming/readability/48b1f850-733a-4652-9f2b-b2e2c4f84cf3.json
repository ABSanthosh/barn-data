{
  "id": "48b1f850-733a-4652-9f2b-b2e2c4f84cf3",
  "title": "Nvidia Ingest Aims to Make it Easier to Extract Structured Information from Documents",
  "link": "https://www.infoq.com/news/2025/01/nvidia-ingest-document-extract/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Nvidia Ingest is a new microservice aimed at processing document content and extracting metadata into a well-defined JSON schema. Ingest is able to process PDFs, Word, and PowerPoint documents and extract structured information from tables, charts, images, and text using optical character recognition. By Sergio De Simone",
  "author": "Sergio De Simone",
  "published": "Wed, 22 Jan 2025 11:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "CUDA",
    "Metadata",
    "Docker",
    "PDF",
    "Large language models",
    "AI, ML \u0026 Data Engineering",
    "Development",
    "news"
  ],
  "byline": "Sergio De Simone",
  "length": 3166,
  "excerpt": "Nvidia Ingest is a new microservice aimed at processing document content and extracting metadata into a well-defined JSON schema. Ingest is able to process PDFs, Word, and PowerPoint documents and ext",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250121072506/apple-touch-icon.png",
  "text": "Nvidia Ingest is a new microservice aimed at processing document content and extracting metadata into a well-defined JSON schema. Ingest is able to process PDFs, Word, and PowerPoint documents and extract structured information from tables, charts, images, and text using optical character recognition. To use Nvidia Ingest, you provide it with a JSON job description of the payload to ingest. You can then retrieve the results as a JSON dictionary with metadata for all extracted objects, processing annotations, and timing/trace information. Nvidia has not provided figures about Ingest performance but says it is scalable and can use multiple processing methods to improve accuracy or increase throughput. For PDF documents, Ingest can use pdfium, Unstructured.io, or Adobe Content Extraction Services. For example, using nv-ingest-cli, the command line tool used to interact with Nvidia Ingest, you specify how to process a document using the --task argument, which includes an extract_method option: nv-ingest-cli \\ ... \\ --task='extract:{\"document_type\": \"pdf\", \"extract_method\": \"pdfium\", \"extract_text\": true, \"extract_images\": true, \"extract_tables\": true, \"extract_tables_method\": \"yolox\"}' \\ ... Nvidia explicitly states that you cannot use Ingest to create a pipeline to carry through a sequence of operations on the documents in the payload. Yet, you can run various pre- or post-processing transformations, including text splitting and chunking, filtering, embedding generation, and image offloading. This means you can use multiple --task arguments for the same nv-ingest-cli execution. For example, you can add a dedup (de-duplication) step by using: nv-ingest-cli \\ ... \\ --task='extract:{...} \\ --task='dedup:{\"content_type\": \"image\", \"filter\": true}' \\ ... The tool can be used on a single document specified with the --doc argument or on a set of documents simultaneously by providing a JSON-formatted dictionary describing the batch payload. All extracted data are stored in an output directory containing a subdirectory for each document type, e.g., image, text, structured, etc. Each ingested document generates a JSON metadata file with the extracted content; source metadata including source name, location, type, etc.; and content metadata. Content metadata includes both general and type-specific content metadata. For example, for images, you get the image type, any caption, the location, size, and so on; for text, you get a summary, a list of keywords, the language, etc.; for tables, you get the format, location, the content as text, any caption or title, etc. Nvidia Ingest requires a number of supporting services, both from Nvidia and open-source projects, including redis, yolox, otel-collector for open telemetry, prometheus, grafana, and more. They are packaged as a Docker Compose application to make deployment easier. It also requires support for CUDA and the Nvidia Container Toolkit and a minimum of two H100 or A100 GPUs with at least 80GM memory. About the Author Sergio De Simone",
  "image": "https://res.infoq.com/news/2025/01/nvidia-ingest-document-extract/en/headerimage/nvidia-ingest-1737541637605.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003e\u003ca href=\"https://github.com/NVIDIA/nv-ingest\"\u003eNvidia Ingest is a new microservice aimed at processing document content and extracting metadata\u003c/a\u003e into a well-defined JSON schema. Ingest is able to process PDFs, Word, and PowerPoint documents and extract structured information from tables, charts, images, and text using optical character recognition.\u003c/p\u003e\n\n\u003cp\u003eTo use Nvidia Ingest, you provide it with a JSON job description of the payload to \u003cem\u003eingest\u003c/em\u003e. You can then retrieve the results as a JSON dictionary with metadata for all extracted objects, processing annotations, and timing/trace information.\u003c/p\u003e\n\n\u003cp\u003eNvidia has not provided figures about Ingest performance but says it is scalable and can use multiple processing methods to improve accuracy or increase throughput. For PDF documents, Ingest can use pdfium, Unstructured.io, or Adobe Content Extraction Services.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://github.com/NVIDIA/nv-ingest/blob/main/client/client_examples/examples/cli_client_usage.ipynb\"\u003eFor example\u003c/a\u003e, using \u003ccode\u003env-ingest-cli\u003c/code\u003e, the command line tool used to interact with Nvidia Ingest, you specify how to process a document using the \u003ccode\u003e--task\u003c/code\u003e argument, which includes an \u003ccode\u003eextract_method\u003c/code\u003e option:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003env-ingest-cli \\\n... \\\n  --task=\u0026#39;extract:{\u0026#34;document_type\u0026#34;: \u0026#34;pdf\u0026#34;, \u0026#34;extract_method\u0026#34;: \u0026#34;pdfium\u0026#34;, \u0026#34;extract_text\u0026#34;: true, \u0026#34;extract_images\u0026#34;: true, \u0026#34;extract_tables\u0026#34;: true, \u0026#34;extract_tables_method\u0026#34;: \u0026#34;yolox\u0026#34;}\u0026#39; \\\n...\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eNvidia explicitly states that you cannot use Ingest to create a pipeline to carry through a sequence of operations on the documents in the payload. Yet, you can run various pre- or post-processing transformations, including text splitting and chunking, filtering, embedding generation, and image offloading. This means you can use multiple \u003ccode\u003e--task\u003c/code\u003e arguments for the same \u003ccode\u003env-ingest-cli\u003c/code\u003e execution. For example, you can add a \u003ccode\u003ededup\u003c/code\u003e (de-duplication) step by using:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode\u003env-ingest-cli \\\n... \\\n  --task=\u0026#39;extract:{...} \\\n  --task=\u0026#39;dedup:{\u0026#34;content_type\u0026#34;: \u0026#34;image\u0026#34;, \u0026#34;filter\u0026#34;: true}\u0026#39; \\\n...\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eThe tool can be used on a single document specified with the \u003ccode\u003e--doc\u003c/code\u003e argument or on a set of documents simultaneously by providing a JSON-formatted dictionary describing the batch payload.\u003c/p\u003e\n\n\u003cp\u003eAll extracted data are stored in an output directory containing a subdirectory for each document type, e.g., image, text, structured, etc. \u003ca href=\"https://github.com/NVIDIA/nv-ingest/blob/main/docs/docs/user-guide/developer-guide/content-metadata.md\"\u003eEach ingested document generates a JSON metadata\u003c/a\u003e file with the extracted content; source metadata including source name, location, type, etc.; and content metadata. Content metadata includes both general and type-specific content metadata. For example, for images, you get the image type, any caption, the location, size, and so on; for text, you get a summary, a list of keywords, the language, etc.; for tables, you get the format, location, the content as text, any caption or title, etc.\u003c/p\u003e\n\n\u003cp\u003eNvidia Ingest requires a number of supporting services, both from Nvidia and open-source projects, including redis, yolox, otel-collector for open telemetry, prometheus, grafana, and more. They are packaged as a Docker Compose application to make deployment easier. It also requires support for \u003ca href=\"https://developer.nvidia.com/cuda-downloads\"\u003eCUDA\u003c/a\u003e and the \u003ca href=\"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html\"\u003eNvidia Container Toolkit\u003c/a\u003e and a minimum of two H100 or A100 GPUs with at least 80GM memory.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Sergio-De-Simone\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSergio De Simone\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-01-22T00:00:00Z",
  "modifiedTime": null
}
