{
  "id": "7d260b5b-0b58-4e10-b141-09a97d615dbb",
  "title": "Qwen Team Releases Qwen3-Coder, a Large Agentic Coding Model with Open Tooling",
  "link": "https://www.infoq.com/news/2025/07/qwen3-coder/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "Qwen Team has announced Qwen3-Coder, a new family of agentic code models designed for long-context, multi-step programming tasks. The most capable variant, Qwen3-Coder-480B-A35B-Instruct, is a Mixture-of-Experts model with a total of 480 billion parameters and 35 billion active parameters per forward pass. By Robert Krzaczyński",
  "author": "Robert Krzaczyński",
  "published": "Sat, 26 Jul 2025 17:55:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Large language models",
    "Agents",
    "API",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Robert Krzaczyński",
  "length": 2966,
  "excerpt": "Qwen Team has announced Qwen3-Coder, a new family of agentic code models designed for long-context, multi-step programming tasks. The most capable variant, Qwen3-Coder-480B-A35B-Instruct, is a Mixture",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s1_20250724113904/apple-touch-icon.png",
  "text": "Qwen Team has announced Qwen3-Coder, a new family of agentic code models designed for long-context, multi-step programming tasks. The most capable variant, Qwen3-Coder-480B-A35B-Instruct, is a Mixture-of-Experts model with a total of 480 billion parameters and 35 billion active parameters per forward pass. It supports 256K tokens natively and up to 1 million via context extension, aiming to handle repository-scale inputs and extended tool interactions. Unlike static code generation models, Qwen3-Coder emphasizes execution and decision-making. The model was post-trained using reinforcement learning over a broad set of real-world tasks, where success is defined by whether the generated code runs and solves the problem. This approach, referred to by Qwen as \"Hard to Solve, Easy to Verify\", aims to improve robustness and utility. In addition, the team scaled long-horizon agentic RL, training the model to use tools and respond to multi-turn feedback in simulated environments. To support this, Qwen deployed a system capable of running 20,000 parallel environments on cloud infrastructure, enabling scaled agent training on workflows resembling actual developer activity. To support experimentation, Qwen released Qwen Code, an open-source command-line interface forked from Gemini CLI. It features custom prompt structures and enhanced support for tool use and function calling. The tool can be installed via npm and supports OpenAI-compatible APIs. In addition, Claude Code users can route requests through DashScope using proxy or router configuration options. This provides a familiar coding interface while enabling evaluation of Qwen3-Coder’s outputs in a multi-model setup. CLI tools are compatible with Cline, Node.js, and Python environments, with full environment variable and API support. Qwen3-Coder is currently available through DashScope via API. Developers outside mainland China can use the international endpoint, and sample Python code is provided for quick integration. Additional model sizes are expected to be released soon, with a focus on maintaining performance while lowering inference cost. Some Reddit users have noted that while local deployment is possible, running the larger models efficiently requires significant infrastructure: Qwen3-Coder’s local use isn’t a cost-saver unless you’ve got the right multi-GPU setup. Running smaller versions when they release might lower expenses. Balancing GPU costs with cloud or hosted solutions could offer a better approach depending on your workload needs. Power and maintenance are key factors too. Future work includes expanding the capabilities of the Qwen Coding Agent and exploring mechanisms for self-improvement, where agents can iteratively improve performance across tasks with minimal human supervision. About the Author Robert Krzaczyński",
  "image": "https://res.infoq.com/news/2025/07/qwen3-coder/en/headerimage/generatedHeaderImage-1753551520845.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cdiv\u003e\u003cp\u003eQwen Team has announced \u003ca href=\"http://qwenlm.github.io/blog/qwen3-coder/\"\u003eQ\u003c/a\u003e\u003ca href=\"https://qwenlm.github.io/blog/qwen3-coder/\"\u003ewen3-Coder\u003c/a\u003e, a new family of agentic code models designed for long-context, multi-step programming tasks. The most capable variant, Qwen3-Coder-480B-A35B-Instruct, is a Mixture-of-Experts model with a total of 480 billion parameters and 35 billion active parameters per forward pass. It supports 256K tokens natively and up to 1 million via context extension, aiming to handle repository-scale inputs and extended tool interactions.\u003c/p\u003e\u003cp\u003e\n\nUnlike static code generation models, Qwen3-Coder emphasizes execution and decision-making. The model was post-trained using reinforcement learning over a broad set of real-world tasks, where success is defined by whether the generated code runs and solves the problem. This approach, referred to by Qwen as \u0026#34;Hard to Solve, Easy to Verify\u0026#34;, aims to improve robustness and utility.\u003c/p\u003e\u003cp\u003e\n\nIn addition, the team scaled long-horizon agentic RL, training the model to use tools and respond to multi-turn feedback in simulated environments. To support this, Qwen deployed a system capable of running 20,000 parallel environments on cloud infrastructure, enabling scaled agent training on workflows resembling actual developer activity.\u003c/p\u003e\u003cp\u003e\n\nTo support experimentation, Qwen released \u003ca href=\"https://github.com/QwenLM/qwen-code\"\u003eQwen Code\u003c/a\u003e, an open-source command-line interface forked from Gemini CLI. It features custom prompt structures and enhanced support for tool use and function calling. The tool can be installed via npm and supports OpenAI-compatible APIs.\u003c/p\u003e\u003cp\u003e\n\nIn addition, Claude Code users can route requests through DashScope using proxy or router configuration options. This provides a familiar coding interface while enabling evaluation of Qwen3-Coder’s outputs in a multi-model setup.\u003c/p\u003e\u003cp\u003e\n\nCLI tools are compatible with Cline, Node.js, and Python environments, with full environment variable and API support.\u003c/p\u003e\u003cp\u003e\n\nQwen3-Coder is currently available through DashScope via API. Developers outside mainland China can use the international endpoint, and sample Python code is provided for quick integration. Additional model sizes are expected to be released soon, with a focus on maintaining performance while lowering inference cost.\u003c/p\u003e\u003cp\u003e\n\nSome Reddit users have noted that while local deployment is possible, running the larger models efficiently requires significant infrastructure:\u003c/p\u003e\u003c/div\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eQwen3-Coder’s local use isn’t a cost-saver unless you’ve got the right multi-GPU setup. Running smaller versions when they release might lower expenses. Balancing GPU costs with cloud or hosted solutions could offer a better approach depending on your workload needs. Power and maintenance are key factors too.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eFuture work includes expanding the capabilities of the Qwen Coding Agent and exploring mechanisms for self-improvement, where agents can iteratively improve performance across tasks with minimal human supervision.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Robert-Krzaczyński\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eRobert Krzaczyński\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-07-26T00:00:00Z",
  "modifiedTime": null
}
