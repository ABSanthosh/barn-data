{
  "id": "cc2566ec-976c-4a63-a2a2-88436b567ef0",
  "title": "Researchers Attempt to Uncover the Origins of Creativity in Diffusion Models",
  "link": "https://www.infoq.com/news/2025/07/diffusion-model-creativity/?utm_campaign=infoq_content\u0026utm_source=infoq\u0026utm_medium=feed\u0026utm_term=global",
  "description": "In a recent paper, Stanford researchers Mason Kamb and Surya Ganguli proposed a mechanism that could underlie the creativity of diffusion models. The mathematical model they developed suggests that this creativity is a deterministic consequence of how those models use the denoising process to generate images. By Sergio De Simone",
  "author": "Sergio De Simone",
  "published": "Sun, 06 Jul 2025 16:00:00 GMT",
  "source": "https://feed.infoq.com",
  "categories": [
    "Neural Networks",
    "Generative AI",
    "Stability Diffusion",
    "AI, ML \u0026 Data Engineering",
    "news"
  ],
  "byline": "Sergio De Simone",
  "length": 4004,
  "excerpt": "In a recent paper, Stanford researchers Mason Kamb and Surya Ganguli proposed a mechanism that could underlie the creativity of diffusion models. The mathematical model they developed suggests that th",
  "siteName": "InfoQ",
  "favicon": "https://cdn.infoq.com/statics_s2_20250605075544/apple-touch-icon.png",
  "text": "In a recent paper, Stanford researchers Mason Kamb and Surya Ganguli proposed a mechanism that could underlie the creativity of diffusion models. The mathematical model they developed suggests that this creativity is a deterministic consequence of how those models use the denoising process to generate images. In rough terms, diffusion models are trained to sort of uncover an image from an isotropic Gaussian noise distribution that is the outcome of the training process from a finite set of sample images. This process consists of gradually removing the Gaussian noise by learning a scoring function that points in gradient directions of increasing probability. If the network can learn this ideal score function exactly, then they will implement a perfect reversal of the forward process. This, in turn, will only be able to turn Gaussian noise into memorized training examples. This means that, to generate new images that are far from the training set, the models must fail to learn the ideal score (IS) function. One way to explain how this occurs is by hypothesizing the presence of inductive biases that may provide a more exact account of what diffusion models are actually doing when creatively generating new samples. By analyzing how diffusion models estimate the score function using CNNs, the researchers identify two such biases: translational equivariance and locality. Translational equivariance refers to the model’s tendency to reflect shifts in the input image, meaning that if the input is shifted by a few pixels, the generated image will mirror that shift. Locality, on the other hand, arises from the convolutional neural networks (CNNs) used to learn the score function, which only consider a small neighborhood of input pixels rather than the entire image. Based on these insights, the researchers built a mathematical model aimed at optimizing a score function for equivariance and locality, which they called an equivariant local score (ELS) machine. An ELS machine is a set of equations that can calculate the composition of denoised images and compared its output with that of diffusion models such as ResNets and UNets trained on simplified models. What they found was \"a remarkable and uniform quantitative agreement between the CNN outputs and ELS machine outputs\", with an accuracy of around 90% or higher depending on the acutal diffusion model and dataset considered. To our knowledge, this is the first time an analytic theory has explained the creative outputs of a trained deep neural network-based generative model to this level of accuracy. Importantly, the (E)LS machine explains all trained outputs far better than the IS machine. According to Ganguli, their research explains how diffusion model create new images \"by mixing and matching different local training set image patches at different locations in the new output, yielding a local patch mosaic model of creativity\". The theory also helps explain why diffusion models make mistakes, for example generating excess fingers or limbs, due to excessive locality. This result, while compelling, initially excluded diffusion models that incorporate highly non-local self-attention (SA) layers, which violate the locality assumption in the researchers’ hypothesis. To address this, the authors used their ELS machine to predict the output of a publicly available UNet+SA model pretrained on CIFAR-10 and found that it still achieved significantly higher accuracy than the baseline IS machine. According to the researchers, their results suggest that locality and equivariance are sufficient to explain the creativity of convolution-only diffusion models and could form the foundation for further study of more complex diffusion models. The researchers also shared the code they used to train the diffusion models they used in the study. About the Author Sergio De Simone",
  "image": "https://res.infoq.com/news/2025/07/diffusion-model-creativity/en/headerimage/diffusion-models-creativity-1751814254644.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\u003cp\u003eIn a recent paper, Stanford researchers Mason Kamb and Surya Ganguli proposed a \u003ca href=\"https://arxiv.org/abs/2412.20292\"\u003emechanism that could underlie the creativity of diffusion models\u003c/a\u003e. The mathematical model they developed suggests that this creativity is a deterministic consequence of how those models use the \u003cem\u003edenoising\u003c/em\u003e process to generate images.\u003c/p\u003e\n\n\u003cp\u003eIn rough terms, diffusion models are trained to sort of \u003cem\u003euncover\u003c/em\u003e an image from an isotropic Gaussian noise distribution that is the outcome of the training process from a finite set of sample images. This process consists of gradually removing the Gaussian noise by learning a scoring function that points in gradient directions of increasing probability.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eIf the network can learn this ideal score function exactly, then they will implement a perfect reversal of the forward process. This, in turn, will only be able to turn Gaussian noise into memorized training examples.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThis means that, to generate new images that are \u003cem\u003efar\u003c/em\u003e from the training set, the models must \u003cem\u003efail\u003c/em\u003e to learn the ideal score (IS) function. One way to explain how this occurs is by hypothesizing the presence of inductive biases that may provide a more exact account of what diffusion models are actually doing when creatively generating new samples.\u003c/p\u003e\n\n\u003cp\u003eBy analyzing how diffusion models estimate the score function using CNNs, the researchers identify two such biases: \u003cem\u003etranslational equivariance\u003c/em\u003e and \u003cem\u003elocality\u003c/em\u003e. Translational equivariance refers to the model’s tendency to reflect shifts in the input image, meaning that if the input is shifted by a few pixels, the generated image will mirror that shift. Locality, on the other hand, arises from the convolutional neural networks (CNNs) used to learn the score function, which only consider a small neighborhood of input pixels rather than the entire image.\u003c/p\u003e\n\n\u003cp\u003eBased on these insights, the researchers built a mathematical model aimed at optimizing a score function for equivariance and locality, which they called an equivariant local score (ELS) machine.\u003c/p\u003e\n\n\u003cp\u003eAn ELS machine is a set of equations that can calculate the composition of denoised images and compared its output with that of diffusion models such as ResNets and UNets trained on simplified models. What they found was \u0026#34;a remarkable and uniform quantitative agreement between the CNN outputs and ELS machine outputs\u0026#34;, with an accuracy of around 90% or higher depending on the acutal diffusion model and dataset considered.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eTo our knowledge, this is the first time an analytic theory has explained the creative outputs of a trained deep neural network-based generative model to this level of accuracy. Importantly, the (E)LS machine explains all trained outputs far better than the IS machine.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAccording to Ganguli, their research explains how diffusion model create new images \u0026#34;by \u003ca href=\"https://x.com/SuryaGanguli/status/1874130895688650895\"\u003emixing and matching different local training set image patches\u003c/a\u003e at different locations in the new output, yielding a local patch mosaic model of creativity\u0026#34;. The theory also helps explain why diffusion models make mistakes, for example generating excess fingers or limbs, due to excessive locality.\u003c/p\u003e\n\n\u003cp\u003eThis result, while compelling, initially excluded diffusion models that incorporate highly non-local self-attention (SA) layers, which violate the locality assumption in the researchers’ hypothesis. To address this, the authors used their ELS machine to predict the output of a publicly available UNet+SA model pretrained on CIFAR-10 and found that it still achieved significantly higher accuracy than the baseline IS machine.\u003c/p\u003e\n\n\u003cp\u003eAccording to the researchers, their results suggest that locality and equivariance are sufficient to explain the creativity of convolution-only diffusion models and could form the foundation for further study of more complex diffusion models.\u003c/p\u003e\n\n\u003cp\u003eThe researchers also shared the \u003ca href=\"https://github.com/Kambm/convolutional_diffusion\"\u003ecode they used to train the diffusion models\u003c/a\u003e they used in the study.\u003c/p\u003e\n\n\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n  \n    \u003cdiv\u003e \n        \u003ch2\u003eAbout the Author\u003c/h2\u003e \n\n        \n            \n                \n            \n            \u003cdiv data-id=\"author-Sergio-De-Simone\"\u003e\n                    \u003ch4\u003e\u003cstrong\u003eSergio De Simone\u003c/strong\u003e\u003c/h4\u003e\n                    \n                \u003c/div\u003e\n        \n    \u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-07-06T00:00:00Z",
  "modifiedTime": null
}
