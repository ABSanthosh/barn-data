{
  "id": "32d004f6-7ec3-46cf-a343-6796f2b457a1",
  "title": "An upgraded dev experience in Google AI Studio",
  "link": "https://developers.googleblog.com/en/google-ai-studio-native-code-generation-agentic-tools-upgrade/",
  "description": "Google AI Studio has been upgraded to enhance the developer experience, featuring native code generation with Gemini 2.5 Pro, agentic tools, and enhanced multimodal generation capabilities, plus new features like the Build tab, Live API, and improved tools for building sophisticated AI applications.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Olivier Lacombe, Kat Kampf, Ammaar Reshi, Seth Odoom",
  "length": 5187,
  "excerpt": "Google AI Studio has been upgraded to enhance the developer experience, featuring native code generation with Gemini 2.5 Pro, agentic tools, and enhanced multimodal generation capabilities, plus new features like the Build tab, Live API, and improved tools for building sophisticated AI applications.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Google AI Studio is the fastest place to start building with the Gemini API, with access to our most capable models, including Gemini 2.5 preview models, and generative media models like Imagen, Lyria RealTime, and Veo. At Google I/O, we announced new features to help you build and deploy complete applications, new model capabilities, and new features in the Google Gen AI SDK.Build apps with Gemini 2.5 Pro code generationGemini 2.5 Pro is incredible at coding, so we’re excited to bring it to Google AI Studio’s native code editor. It’s tightly optimized with our Gen AI SDK so it’s easier to generate apps with a simple text, image, or video prompt. The new Build tab is now your gateway to quickly build and deploy AI-powered web apps. We’ve also launched new showcase examples to experiment with new models and more. Sorry, your browser doesn't support playback for this video Video of text adventure game being generated with Imagen + Gemini (video sped up for illustrative purposes) In addition to app generation from a single prompt, you can continue to iterate your web app over chat. This allows you to make changes, view diffs, and even jump back to previous checkpoints to revert edits. Sorry, your browser doesn't support playback for this video Compare code versions and use expanded file structure to help manage project development (video sped up for illustrative purposes) You can also deploy those newly created apps in a single click to Cloud Run. Sorry, your browser doesn't support playback for this video Quickly deploy your created apps on Cloud Run (video sped up for illustrative purposes) Google AI Studio apps and generated code leverage a unique placeholder API key, allowing Google AI Studio to proxy all Gemini API calls. Consequently, when you share your app with Google AI Studio, all API usage by its users is attributed to their Google AI Studio free of charge usage, completely bypassing your own API key and quota. You can read more in our FAQ.This feature is experimental, so you should always check code before sharing your project externally. Our one-shot generation has been primarily optimized to work with Gemini and Imagen models, with support for more models and tool calls coming soon.Multimodal generation made easy in Google AI StudioWe've been working hard to get Google DeepMind’s advanced multimodal models into developers’ toolboxes, faster. The new Generate Media page centralizes the discovery of Imagen, Veo, Gemini with native image generation, and new native speech generation models. Plus, experience interactive music generation with Lyria RealTime with the PromptDJ apps built in Google AI Studio. Explore our generative media models from the Google AI Studio Generate Media tab (video sped up for illustrative purposes) New native audio for the Live API and text-to-speech (TTS)With Gemini 2.5 Flash native audio dialog in preview in the Live API, the model now generates even more natural responses with support for over 30 voices. We’ve also added proactive audio so the model can distinguish between the speaker and background conversations, so it knows when to respond. This makes it possible for you to build conversational AI agents and experiences that feel more intuitive and natural. Try native audio dialog in the Google AI Studio Stream tab (video sped up for illustrative purposes) In addition to the Live API, we’ve announced Gemini 2.5 Pro and Flash previews for text-to-speech (TTS) that support native audio output. Now you can craft single and multi-speaker output with flexible control over delivery style. Generate speech using the new TTS capabilities (video sped up for illustrative purposes) Try native audio in the Live API from the Stream tab and experience new TTS capabilities via Generate Speech.Model Context Protocol (MCP) supportModel Context Protocol (MCP) definitions are also now natively supported in the Google Gen AI SDK for easier integration with a growing number of open-source tools. We’ve included a demo app that shows how you can use an MCP server within Google AI Studio that combines Google Maps and the Gemini API New URL Context toolURL Context is a new experimental tool that gives the model the ability to retrieve and reference content from links you provide. This is helpful for fact-checking, comparison, summarization, and deeper research. Sorry, your browser doesn't support playback for this video Start building in Google AI StudioWe’re thrilled to bring all of these updates to Google AI Studio, making it the place for developers to explore and build with the latest models Google has to offer.Explore this announcement and all Google I/O 2025 updates on io.google starting May 22.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-io-event-meta.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"f2l3d\"\u003e\u003cbr/\u003e\u003ca href=\"https://aistudio.google.com/apps\"\u003eGoogle AI Studio\u003c/a\u003e is the fastest place to start building with the Gemini API, with access to our most capable models, including Gemini 2.5 preview models, and generative media models like Imagen, Lyria RealTime, and Veo. At Google I/O, we announced new features to help you build and deploy complete applications, new model capabilities, and new features in the \u003ca href=\"https://ai.google.dev/gemini-api/docs/migrate\"\u003eGoogle Gen AI SDK\u003c/a\u003e.\u003c/p\u003e\u003ch2 data-block-key=\"lsqlg\" id=\"build-apps-with-gemini-2.5-pro-code-generation\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBuild apps with Gemini 2.5 Pro code generation\u003c/h2\u003e\u003cp data-block-key=\"cve2q\"\u003eGemini 2.5 Pro is incredible at coding, so we’re excited to bring it to Google AI Studio’s native code editor. It’s tightly optimized with our Gen AI SDK so it’s easier to generate apps with a simple text, image, or video prompt. The new \u003ca href=\"https://aistudio.google.com/apps\"\u003eBuild\u003c/a\u003e tab is now your gateway to quickly build and deploy AI-powered web apps. We’ve also launched new \u003ca href=\"http://aistudio.google.com/apps?source=showcase\"\u003eshowcase\u003c/a\u003e examples to experiment with new models and more.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-yru3jo8a_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/text-adventure-imagen-gemini-google-ai-studio.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n        \n            \u003cp\u003eVideo of text adventure game being generated with Imagen + Gemini\n(video sped up for illustrative purposes)\u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cp data-block-key=\"ysb9i\"\u003eIn addition to app generation from a single prompt, you can continue to iterate your web app over chat. This allows you to make changes, view diffs, and even jump back to previous checkpoints to revert edits.\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-6txj0c5t_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/code-generation-imagen-gemini-google-ai-studio.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n        \n            \u003cp\u003eCompare code versions and use expanded file structure to help manage project development (video sped up for illustrative purposes)\u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cp data-block-key=\"c7qcj\"\u003eYou can also deploy those newly created apps in a single click to \u003ca href=\"https://cloud.google.com/run\"\u003eCloud Run\u003c/a\u003e.\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-cezbp4n9_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/CR_deploy_mviV4si.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n        \n            \u003cp\u003eQuickly deploy your created apps on Cloud Run (video sped up for illustrative purposes)\u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"ysb9i\"\u003eGoogle AI Studio apps and generated code leverage a unique placeholder API key, allowing Google AI Studio to proxy all Gemini API calls. Consequently, when you share your app with Google AI Studio, all API usage by its users is attributed to their Google AI Studio free of charge usage, completely bypassing your own API key and quota. You can read more in our \u003ca href=\"https://aistudio.google.com/app/apps?source=faq\"\u003eFAQ\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"de0nv\"\u003eThis feature is experimental, so you should always check code before sharing your project externally. Our one-shot generation has been primarily optimized to work with Gemini and Imagen models, with support for more models and tool calls coming soon.\u003c/p\u003e\u003ch2 data-block-key=\"cqlne\" id=\"\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eMultimodal generation made easy in Google AI Studio\u003c/h2\u003e\u003cp data-block-key=\"3qmu4\"\u003eWe\u0026#39;ve been working hard to get Google DeepMind’s advanced multimodal models into developers’ toolboxes, faster. The new \u003ca href=\"http://aistudio.google.com/gen-media\"\u003eGenerate Media\u003c/a\u003e page centralizes the discovery of Imagen, Veo, Gemini with native image generation, and new native speech generation models. Plus, experience interactive music generation with Lyria RealTime with the PromptDJ apps built in Google AI Studio.\u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \n    \n        \n            \u003cp\u003eExplore our generative media models from the Google AI Studio Generate Media tab (video sped up for illustrative purposes)\u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"lgpyc\" id=\"new-native-audio-for-the-live-api-and-text-to-speech-(tts)\"\u003eNew native audio for the Live API and text-to-speech (TTS)\u003c/h2\u003e\u003cp data-block-key=\"bn3mp\"\u003eWith Gemini 2.5 Flash native audio dialog in preview in the Live API, the model now generates even more natural responses with support for over 30 voices. We’ve also added proactive audio so the model can distinguish between the speaker and background conversations, so it knows when to respond. This makes it possible for you to build conversational AI agents and experiences that feel more intuitive and natural.\u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \n    \n        \n            \u003cp\u003eTry native audio dialog in the Google AI Studio Stream tab  (video sped up for illustrative purposes)\u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cp data-block-key=\"ysb9i\"\u003eIn addition to the Live API, we’ve announced Gemini 2.5 Pro and Flash previews for text-to-speech (TTS) that support native audio output. Now you can craft single and multi-speaker output with flexible control over delivery style.\u003c/p\u003e  \u003cdiv\u003e\n    \n    \n        \n            \u003cp\u003eGenerate speech using the new TTS capabilities  (video sped up for illustrative purposes)\u003c/p\u003e\n        \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"ysb9i\"\u003eTry native audio in the Live API from the \u003ca href=\"http://aistudio.google.com/live\"\u003eStream\u003c/a\u003e tab and experience new TTS capabilities via \u003ca href=\"https://aistudio.google.com/generate-speech\"\u003eGenerate Speech\u003c/a\u003e.\u003c/p\u003e\u003ch2 data-block-key=\"qvly9\" id=\"model-context-protocol-(mcp)-support\"\u003e\u003cbr/\u003eModel Context Protocol (MCP) support\u003c/h2\u003e\u003cp data-block-key=\"di62g\"\u003eModel Context Protocol (MCP) definitions are also now natively supported in the Google Gen AI SDK for easier integration with a growing number of open-source tools. We’ve included a demo \u003ca href=\"https://aistudio.google.com/apps/bundled/mcp_maps_basic\"\u003eapp\u003c/a\u003e that shows how you can use an MCP server within Google AI Studio that combines Google Maps and the Gemini API\u003c/p\u003e\n\u003c/div\u003e   \n\n\n    \n    \u003cdiv\u003e\n        \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image6_Ygpnr0j.original.png\" alt=\"Model Context Protocol (MCP)\"/\u003e\n            \n            \n        \u003c/p\u003e\n    \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"1ftqy\" id=\"new-url-context-tool\"\u003eNew URL Context tool\u003c/h2\u003e\u003cp data-block-key=\"1gutl\"\u003eURL Context is a new experimental tool that gives the model the ability to retrieve and reference content from links you provide. This is helpful for fact-checking, comparison, summarization, and deeper research.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \n        \u003cvideo autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-dtlzdb87_thumb.jpg\"\u003e\n\u003csource src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/URLContext.mp4\" type=\"video/mp4\"/\u003e\n\u003cp\u003eSorry, your browser doesn\u0026#39;t support playback for this video\u003c/p\u003e\n\n\u003c/video\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003ch2 data-block-key=\"mfh8o\" id=\"start-building-in-google-ai-studio\"\u003eStart building in Google AI Studio\u003c/h2\u003e\u003cp data-block-key=\"5qalh\"\u003eWe’re thrilled to bring all of these updates to Google AI Studio, making it the place for developers to explore and build with the latest models Google has to offer.\u003c/p\u003e\u003cp data-block-key=\"7loqp\"\u003eExplore this announcement and all Google I/O 2025 updates on \u003ca href=\"https://io.google/2025/?utm_source=blogpost\u0026amp;utm_medium=pr\u0026amp;utm_campaign=event\u0026amp;utm_content=\"\u003eio.google\u003c/a\u003e starting May 22.\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-05-21T00:00:00Z",
  "modifiedTime": null
}
