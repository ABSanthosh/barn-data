{
  "id": "5d427d23-493d-4139-9574-660621129db6",
  "title": "Beyond the Chatbot: Agentic AI with Gemma",
  "link": "https://developers.googleblog.com/en/beyond-the-chatbot-agentic-ai-with-gemma/",
  "description": "A practical guide to constructing a Gemma 2-based Agentic AI system – a type of AI that can make its own decisions and use external tools to achieve goals – that can generate dynamic content for a fictional game world.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Ju-yeong Ji",
  "length": 8213,
  "excerpt": "A practical guide to constructing a Gemma 2-based Agentic AI system – a type of AI that can make its own decisions and use external tools to achieve goals – that can generate dynamic content for a fictional game world.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Gemma is a family of lightweight, generative artificial intelligence (AI) open models, built from the same research and technology used to create the Gemini models. In a blog post last year, we showcased a text-based adventure game creation using Gemma. In this blog post, you will learn how to use Gemma with a form of AI called Agentic AI, which offers a different way to use Large Language Models (LLMs).Most common AIs today are reactive. They respond to specific commands, like a smart speaker playing music when asked. They’re useful, but can only do what they’re told.In contrast, Agentic AI is proactive and autonomous. It makes its own decisions to reach goals. A key feature is using external tools like search engines, specialized software, and other programs to get information beyond their inherent knowledge base. This lets Agentic AI work and solve problems very independently and effectively.Here, we’ll provide a practical guide to constructing a Gemma 2 based Agentic AI system, covering key technical concepts like \"Function Calling\", \"ReAct\" and \"Few-shot prompting\". This AI system will serve as a dynamic lore generator for a fictional game, actively expanding its history and providing a distinct, perpetually evolving narrative landscape for players.Bridging the GapBefore we dive into the coding, let's understand Gemma's agentic AI capabilities. You can experiment directly with it through Google AI Studio. Google AI Studio offers several Gemma 2 models. The 27B model is recommended for the best performance, but the smaller model like 2B can also be used as you can see below. In this example, we tell Gemma that there’s a get_current_time() function and ask Gemma to tell us the time in Tokyo and Paris. This result shows that Gemma 2 does not suggest calling the get_current_time() function. This model capability is called \"Function Calling\", which is a key feature for enabling AI to interact with external systems and APIs to retrieve data.Gemma’s built-in function calling capabilities are limited, which limits its ability to act as an agent. However, its strong instruction-following capabilities can be used to compensate for this missing functionality. Let’s see how we can harness these capabilities to expand Gemma’s functionality.We will implement a prompt based on the ReAct (Reasoning and Acting) prompting style. ReAct defines available tools and a specific format for interaction. This structure enables Gemma to engage in cycles of Thought (reasoning), Action (utilizing tools), and Observation (analyzing the output). As you can see, Gemma is attempting to use the get_current_time() function for both Tokyo and Paris. A Gemma model cannot simply execute on its own. To make this operational, you’ll need to run the generated code yourself or as part of your system. Without it, you can still proceed and observe Gemma’s response, similar to the one provided below. Awesome! Now you’ve witnessed Gemma’s function calling in action. This function calling ability allows it to execute operations autonomously in the background, executing tasks without requiring direct user interaction.Let’s get our hands dirty with the actual demo, building a History AI Agent!Demo SetupAll the prompts below are in the \"Agentic AI with Gemma 2\" notebook in Gemma's Cookbook. One difference when using Gemma in Google AI Studio versus directly with Python on Colab is that you must use a specific format like \u003cstart_of_turn\u003e to give instructions to Gemma. You can learn more about this from the official docs.Let’s imagine a fictional game world where AI agents craft dynamic content.These agents, designed with specific objectives, can generate in-game content like books, poems, and songs, in response to a player choice or significant events within the game’s narrative.A key feature of these AI agents is their ability to break down complex goals into smaller actionable steps. They can analyze different approaches, evaluate potential outcomes, and adapt their plans based on new information.Where Agentic AI truly shines is that they’re not just passively spitting out information. They can interact with digital (and potentially physical) environments, execute tasks, and make decisions autonomously to achieve their programmed objectives.So, how does it work?Here’s an example ReAct style prompt designed for an AI agent that generates in-game content, with the capability to use function calls to retrieve historical information. \u003cstart_of_turn\u003euser You are an AI Historian in a game. Your goal is to create books, poems, and songs found in the game world so that the player's choices meaningfully impact the unfolding of events. You have access to the following tools: * `get_historical_events(year, location=None, keyword=None)`: Retrieves a list of historical events within a specific year. * `get_person_info(name)`: Retrieves information about a historical figure. * `get_location_info(location_name)`: Retrieves information about a location. Use the following multi-step conversation: Thought: I need to do something... Action: I should use the tool `tool_name` with input `tool_input` Wait user to get the result of the tool is `tool_output` And finally answer the Content of books, poems, or songs. Let’s try to write a book. See the example outputs below:Zero-shot prompting As you can see, Gemma may struggle with function calling due to a lack of training in that area.To address this limitation, we can employ \"One-shot prompting\", a form of in-context learning, where demonstrations are embedded within the prompt. This example will serve as a guide for Gemma, allowing it to understand the intended task and improve its performance through contextual learning.One-Shot Prompting(Note: the green section is a provided example, the actual prompt comes after it) Notably, the model performs better since Action contains the correct input.Few-shot promptingFor more complex tasks, use \"Few-shot prompting\". It works by providing a small set of examples (usually 2-5, but sometimes more) that demonstrate the desired input-output relationship, allowing the model to grasp the underlying pattern.Now, we received a function name get_person_info and parameter values \"name: Anya, the Rebel Leader\", the game must connect to an API and call the function. We will use a synthetic response payload for this API interaction. Note that the agent used the provided information to create a book about Eldoria's Rebel Leader.The Future is AgenticWe’re still in the early stages of Agentic AI development, but the progress is rapid. As these systems become more sophisticated, we can expect them to play an increasingly significant role in our lives.Here are some potential applications, focused primarily on gaming:Lifelike NPCs: NPCs will become more believable, exhibiting unique personalities and adapting to player interactions.Dynamic Stories: Games will offer dynamically generated stories and quests, ensuring lasting replayability.Efficient Development: AI can streamline game testing, leading to higher quality and faster development cycles.But with implications beyond:GUI Automation: Models can be used to interact with graphical user interfaces directly within a web browser.Mathematical Tool Integration: AI can utilize tools like calculators to overcome limitations in performing complex calculations.Contextual Knowledge Retrieval: AI can decide when it needs to query external knowledge sources (as in RAG systems).Next stepsThe era of passive, reactive AI is gradually giving way to a future where AI is proactive, goal-oriented, and capable of independent action. This is the dawn of Agentic AI, and it's a future worth getting excited about.The Gemma Cookbook repository is a place where various ideas like this come together. Contributions are always welcome. If you have a notebook that implements a new idea, please send us a Pull Request.Thanks for reading and catch you in the next one.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma-Logo-Agentic-AI.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"v5smj\"\u003e\u003ca href=\"https://goo.gle/gemma\"\u003eGemma\u003c/a\u003e is a family of lightweight, generative artificial intelligence (AI) open models, built from the same research and technology used to create the \u003ca href=\"http://goo.gle/gemini\"\u003eGemini\u003c/a\u003e models. In a \u003ca href=\"https://developers.googleblog.com/build-a-text-based-adventure-game-with-gemma-2/\"\u003eblog post last year\u003c/a\u003e, we showcased a text-based adventure game creation using Gemma. In this blog post, you will learn how to use Gemma with a form of AI called Agentic AI, which offers a different way to use Large Language Models (LLMs).\u003c/p\u003e\u003cp data-block-key=\"3e8l3\"\u003eMost common AIs today are \u003cb\u003ereactive\u003c/b\u003e. They respond to specific commands, like a smart speaker playing music when asked. They’re useful, but can only do what they’re told.\u003c/p\u003e\u003cp data-block-key=\"69q87\"\u003eIn contrast, Agentic AI is \u003cb\u003eproactive and autonomous\u003c/b\u003e. It makes its own decisions to reach goals. A key feature is using external tools like search engines, specialized software, and other programs to get information beyond their inherent knowledge base. This lets Agentic AI work and solve problems very independently and effectively.\u003c/p\u003e\u003cp data-block-key=\"f82on\"\u003eHere, we’ll provide a practical guide to constructing a \u003ca href=\"https://ai.google.dev/gemma/docs/model_card_2\"\u003eGemma 2\u003c/a\u003e based Agentic AI system, covering key technical concepts like \u003cb\u003e\u0026#34;Function Calling\u0026#34;\u003c/b\u003e, \u003cb\u003e\u0026#34;ReAct\u0026#34;\u003c/b\u003e and \u003cb\u003e\u0026#34;Few-shot prompting\u0026#34;\u003c/b\u003e. This AI system will serve as a dynamic lore generator for a fictional game, actively expanding its history and providing a distinct, perpetually evolving narrative landscape for players.\u003c/p\u003e\u003ch2 data-block-key=\"9g809\"\u003e\u003cbr/\u003eBridging the Gap\u003c/h2\u003e\u003cp data-block-key=\"83m9p\"\u003eBefore we dive into the coding, let\u0026#39;s understand Gemma\u0026#39;s agentic AI capabilities. You can experiment directly with it through \u003ca href=\"https://aistudio.google.com/prompts/new_chat?model=gemma-2-2b-it\"\u003eGoogle AI Studio\u003c/a\u003e. Google AI Studio offers several Gemma 2 models. The 27B model is recommended for the best performance, but the smaller model like 2B can also be used as you can see below. In this example, we tell Gemma that there’s a \u003ccode\u003eget_current_time()\u003c/code\u003e function and ask Gemma to tell us the time in Tokyo and Paris.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_R5cJg57.original.png\" alt=\"Time Request Denied in Google AI Studio\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"v5smj\"\u003eThis result shows that Gemma 2 does not suggest calling the \u003ccode\u003eget_current_time()\u003c/code\u003e function. This model capability is called \u003cb\u003e\u0026#34;Function Calling\u0026#34;\u003c/b\u003e, which is a key feature for enabling AI to interact with external systems and APIs to retrieve data.\u003c/p\u003e\u003cp data-block-key=\"el46a\"\u003eGemma’s built-in function calling capabilities are limited, which limits its ability to act as an agent. However, its strong instruction-following capabilities can be used to compensate for this missing functionality. Let’s see how we can harness these capabilities to expand Gemma’s functionality.\u003c/p\u003e\u003cp data-block-key=\"b9tau\"\u003eWe will implement a prompt based on the \u003ca href=\"https://arxiv.org/abs/2210.03629\"\u003eReAct (Reasoning and Acting)\u003c/a\u003e prompting style. ReAct defines available \u003cb\u003etools\u003c/b\u003e and a specific \u003cb\u003eformat\u003c/b\u003e for interaction. This structure enables Gemma to engage in cycles of \u003cb\u003eThought\u003c/b\u003e (reasoning), \u003cb\u003eAction\u003c/b\u003e (utilizing tools), and \u003cb\u003eObservation\u003c/b\u003e (analyzing the output).\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_RwX8Tdk.original.png\" alt=\"AI Assistant : Getting Time in Google AI Studio\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cp data-block-key=\"e06zr\"\u003eAs you can see, Gemma is attempting to use the \u003ccode\u003eget_current_time()\u003c/code\u003e function for both Tokyo and Paris. A Gemma model cannot simply execute on its own. To make this operational, you’ll need to run the generated code yourself or as part of your system. Without it, you can still proceed and observe Gemma’s response, similar to the one provided below.\u003c/p\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_1K68Jdy.original.png\" alt=\"Gemma attempting to use `get_current_time` function for both Tokyo and Paris in Google AI Studio\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"e06zr\"\u003eAwesome! Now you’ve witnessed Gemma’s function calling in action. This function calling ability allows it to execute operations autonomously in the background, executing tasks without requiring direct user interaction.\u003c/p\u003e\u003cp data-block-key=\"2p3ft\"\u003eLet’s get our hands dirty with the actual demo, building a History AI Agent!\u003c/p\u003e\u003ch2 data-block-key=\"8jpeq\"\u003e\u003cbr/\u003e\u003cb\u003eDemo Setup\u003c/b\u003e\u003c/h2\u003e\u003cp data-block-key=\"7bk2m\"\u003eAll the prompts below are in the \u0026#34;\u003ca href=\"https://goo.gle/colab-gemma2-agentic-ai\"\u003eAgentic AI with Gemma 2\u003c/a\u003e\u0026#34; notebook in \u003ca href=\"http://goo.gle/gemma-cookbook\"\u003eGemma\u0026#39;s Cookbook\u003c/a\u003e. One difference when using Gemma in Google AI Studio versus directly with Python on Colab is that you must use a specific format like \u003ccode\u003e\u0026lt;start_of_turn\u0026gt;\u003c/code\u003e to give instructions to Gemma. You can learn more about this from \u003ca href=\"https://ai.google.dev/gemma/docs/formatting\"\u003ethe official docs\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"ct753\"\u003eLet’s imagine a fictional game world where AI agents craft dynamic content.\u003c/p\u003e\u003cp data-block-key=\"9m4eq\"\u003eThese agents, designed with specific objectives, can generate in-game content like books, poems, and songs, in response to a player choice or significant events within the game’s narrative.\u003c/p\u003e\u003cp data-block-key=\"eetvt\"\u003eA key feature of these AI agents is their ability to break down complex goals into smaller actionable steps. They can analyze different approaches, evaluate potential outcomes, and adapt their plans based on new information.\u003c/p\u003e\u003cp data-block-key=\"akndh\"\u003eWhere Agentic AI truly shines is that they’re not just passively spitting out information. They can interact with digital (and potentially physical) environments, execute tasks, and make decisions autonomously to achieve their programmed objectives.\u003c/p\u003e\u003ch2 data-block-key=\"dfec4\"\u003e\u003cbr/\u003eSo, how does it work?\u003c/h2\u003e\u003cp data-block-key=\"2bk80\"\u003eHere’s an example ReAct style prompt designed for an AI agent that generates in-game content, with the capability to use function calls to retrieve historical information.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003e\u003c/span\u003e\u0026lt;start_of_turn\u0026gt;user\nYou are an AI Historian in a game. Your goal is to create books, poems, and songs found in the game world so that the player\u0026#39;s choices meaningfully impact the unfolding of events.\n\nYou have access to the following tools:\n\n\u003cspan\u003e*\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e`get_historical_events(year, location=None, keyword=None)`\u003c/span\u003e: Retrieves a list of historical events within a specific year.\n\u003cspan\u003e*\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e`get_person_info(name)`\u003c/span\u003e: Retrieves information about a historical figure.\n\u003cspan\u003e*\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e`get_location_info(location_name)`\u003c/span\u003e: Retrieves information about a location.\n\nUse the following multi-step conversation:\n\nThought: I need to do something...\nAction: I should use the tool \u003cspan\u003e`tool_name`\u003c/span\u003e with input \u003cspan\u003e`tool_input`\u003c/span\u003e\n\nWait user to get the result of the tool is \u003cspan\u003e`tool_output`\u003c/span\u003e\n\nAnd finally answer the Content of books, poems, or songs.\n\u003c/pre\u003e\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"e06zr\"\u003eLet’s try to write a book. See the example outputs below:\u003c/p\u003e\u003ch3 data-block-key=\"9rv6q\"\u003e\u003cb\u003e\u003cbr/\u003eZero-shot prompting\u003c/b\u003e\u003c/h3\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Agentic-AI-with-Gemma-zero-shot-prompting-examp.original.png\" alt=\"Agentic-AI-with-Gemma-zero-shot-prompting-example\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"e06zr\"\u003eAs you can see, Gemma may struggle with function calling due to a lack of training in that area.\u003c/p\u003e\u003cp data-block-key=\"d8btn\"\u003eTo address this limitation, we can employ \u0026#34;\u003cb\u003eOne-shot prompting\u003c/b\u003e\u0026#34;, a form of in-context learning, where demonstrations are embedded within the prompt. This example will serve as a guide for Gemma, allowing it to understand the intended task and improve its performance through contextual learning.\u003c/p\u003e\u003ch3 data-block-key=\"ei7ia\"\u003e\u003cbr/\u003e\u003cb\u003eOne-Shot Prompting\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"6cjjm\"\u003e\u003ci\u003e(Note: the green section is a provided example, the actual prompt comes after it)\u003c/i\u003e\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Agentic-AI-with-Gemma-One-Shot-prompting-exampl.original.png\" alt=\"Agentic-AI-with-Gemma-One-Shot-prompting-example\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"e06zr\"\u003eNotably, the model performs better since \u003ccode\u003eAction\u003c/code\u003e contains the correct input.\u003c/p\u003e\u003ch3 data-block-key=\"f407g\"\u003e\u003cb\u003e\u003cbr/\u003eFew-shot prompting\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"7d7h9\"\u003eFor more complex tasks, use \u003cb\u003e\u0026#34;Few-shot prompting\u0026#34;\u003c/b\u003e. It works by providing a small set of examples (usually 2-5, but sometimes more) that demonstrate the desired input-output relationship, allowing the model to grasp the underlying pattern.\u003c/p\u003e\u003cp data-block-key=\"b4e9k\"\u003eNow, we received a function name \u003ccode\u003eget_person_info\u003c/code\u003e and parameter values \u003ccode\u003e\u0026#34;name: Anya, the Rebel Leader\u0026#34;\u003c/code\u003e, the game must connect to an API and call the function. We will use a synthetic response payload for this API interaction.\u003c/p\u003e\n\u003c/div\u003e   \n\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Agentic-AI-with-Gemma-few-shot-prompting-exampl.original.png\" alt=\"Agentic-AI-with-Gemma-few-shot-prompting-example\"/\u003e\n        \n        \n    \u003c/p\u003e\n\u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"e06zr\"\u003eNote that the agent used the provided information to create a book about Eldoria\u0026#39;s Rebel Leader.\u003c/p\u003e\u003ch2 data-block-key=\"5166e\"\u003e\u003cbr/\u003eThe Future is Agentic\u003c/h2\u003e\u003cp data-block-key=\"1osq1\"\u003eWe’re still in the early stages of Agentic AI development, but the progress is rapid. As these systems become more sophisticated, we can expect them to play an increasingly significant role in our lives.\u003c/p\u003e\u003cp data-block-key=\"denqn\"\u003eHere are some potential applications, focused primarily on gaming:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"4ckj\"\u003e\u003cb\u003eLifelike NPCs\u003c/b\u003e: NPCs will become more believable, exhibiting unique personalities and adapting to player interactions.\u003c/li\u003e\u003cli data-block-key=\"vshl\"\u003e\u003cb\u003eDynamic Stories\u003c/b\u003e: Games will offer dynamically generated stories and quests, ensuring lasting replayability.\u003c/li\u003e\u003cli data-block-key=\"5kqrc\"\u003e\u003cb\u003eEfficient Development\u003c/b\u003e: AI can streamline game testing, leading to higher quality and faster development cycles.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"ah77p\"\u003eBut with implications beyond:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"dcupk\"\u003e\u003cb\u003eGUI Automation\u003c/b\u003e: Models can be used to interact with graphical user interfaces directly within a web browser.\u003c/li\u003e\u003cli data-block-key=\"db17r\"\u003e\u003cb\u003eMathematical Tool Integration\u003c/b\u003e: AI can utilize tools like calculators to overcome limitations in performing complex calculations.\u003c/li\u003e\u003cli data-block-key=\"804hl\"\u003e\u003cb\u003eContextual Knowledge Retrieval\u003c/b\u003e: AI can decide when it needs to query external knowledge sources (as in RAG systems).\u003c/li\u003e\u003c/ul\u003e\u003ch2 data-block-key=\"68brq\"\u003e\u003cbr/\u003eNext steps\u003c/h2\u003e\u003cp data-block-key=\"10fdd\"\u003eThe era of passive, reactive AI is gradually giving way to a future where AI is proactive, goal-oriented, and capable of independent action. This is the dawn of Agentic AI, and it\u0026#39;s a future worth getting excited about.\u003c/p\u003e\u003cp data-block-key=\"al5tq\"\u003eThe \u003ca href=\"https://github.com/google-gemini/gemma-cookbook\"\u003eGemma Cookbook repository\u003c/a\u003e is a place where various ideas like this come together. Contributions are always welcome. If you have a notebook that implements a new idea, please send us a Pull Request.\u003c/p\u003e\u003cp data-block-key=\"d1fue\"\u003eThanks for reading and catch you in the next one.\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-02-13T00:00:00Z",
  "modifiedTime": null
}
