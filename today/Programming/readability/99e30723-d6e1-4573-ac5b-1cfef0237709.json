{
  "id": "99e30723-d6e1-4573-ac5b-1cfef0237709",
  "title": "Thunderbolting Your Video Card",
  "link": "https://blog.codinghorror.com/thunderbolting-your-video-card/",
  "description": "When I wrote about The Golden Age of x86 Gaming, I implied that, in the future, it might be an interesting, albeit expensive, idea to upgrade your video card via an external Thunderbolt 3 enclosure. I'm here to report that the future is now. Yes, that's",
  "author": "Jeff Atwood",
  "published": "Fri, 24 Mar 2017 09:08:37 GMT",
  "source": "https://feeds.feedburner.com/codinghorror",
  "categories": null,
  "byline": "Jeff Atwood",
  "length": 9485,
  "excerpt": "When I wrote about The Golden Age of x86 Gaming [https://blog.codinghorror.com/the-golden-age-of-x86-gaming/], I implied that, in the future, it might be an interesting, albeit expensive, idea to upgrade your video card via an external Thunderbolt 3 enclosure. I'm here to report that the future is now. Yes, that's right, I paid $500 for an external Thunderbolt 3 enclosure [https://www.razerzone.com/store/razer-core] to fit a $600 video card, all to enable a plug-in upgrade of a GPU on a Skul",
  "siteName": "Coding Horror",
  "favicon": "https://blog.codinghorror.com/content/images/size/w256h256/2020/06/3cffc4b347c3587f19fe222caaac69f63b9a5e73.png",
  "text": "24 Mar 2017 When I wrote about The Golden Age of x86 Gaming, I implied that, in the future, it might be an interesting, albeit expensive, idea to upgrade your video card via an external Thunderbolt 3 enclosure. I'm here to report that the future is now. Yes, that's right, I paid $500 for an external Thunderbolt 3 enclosure to fit a $600 video card, all to enable a plug-in upgrade of a GPU on a Skull Canyon NUC that itself cost around $1000 fully built. I know, it sounds crazy, and … OK fine, I won't argue with you. It's crazy. This matters mostly because of 4k, aka 2160p, aka 3840 × 2160, aka Ultra HD. Plain old regular HD, aka 1080p, aka 1920 × 1080, is one quarter the size of 4k, and ¼ the work. By today's GPU standards HD is pretty much easy mode these days. It's not even interesting. No offense to console fans, or anything. Late in 2016, I got a 4k OLED display and it … kind of blew my mind. I have never seen blacks so black, colors so vivid, on a display so thin. It made my previous 2008 era Panasonic plasma set look lame. It's so good that I'm now a little angry that every display that my eyes touch isn't OLED already. I even got into nerd fights over it, and to be honest, I'd still throw down for OLED. It is legitimately that good. Come at me, bro. Don't believe me? Well, guess which display in the below picture is OLED? Go on, guess: @andrewbstiles if it was physically possible to have sex with this TV I.. uh.. I'd take it on long, romantic walks— Jeff Atwood (@codinghorror) August 13, 2016 There's a reason every site that reviews TVs had to recalibrate their results when they reviewed the 2016 OLED sets. In my extended review at Reference Home Theater, I call it “the best looking TV I’ve ever reviewed.” But we aren’t alone in loving the E6. Vincent Teoh at HDTVtest writes, “We’re not even going to qualify the following endorsement: if you can afford it, this is the TV to buy.” Rtings.com gave the E6 OLED the highest score of any TV the site has ever tested. Reviewed.com awarded it a 9.9 out of 10, with only the LG G6 OLED (which offers the same image but better styling and sound for $2,000 more) coming out ahead. But I digress. Playing games at 1080p in my living room was already possible. But now that I have an incredible 4k display in the living room, it's a whole other level of difficulty. Not just twice as hard – and remember current consoles barely manage to eke out 1080p at 30fps in most games – but four times as hard. That's where external GPU power comes in. The cool technology underpinning all of this is Thunderbolt 3. The thunderbolt cable bundled with the Razer Core is rather … diminutive. There's a reason for this. Is there a maximum cable length for Thunderbolt 3 technology? Thunderbolt 3 passive cables have maximum lengths. 0.5m TB 3 (40Gbps) 1.0m TB 3 (20Gbps) 2.0m TB 3 (20Gbps) In the future we will offer active cables which will provide 40Gbps of bandwidth at longer lengths. 40Gbps is, for the record, an insane amount of bandwidth. Let's use our rule of thumb based on ultra common gigabit ethernet, that 1 gigabit = 120 megabytes/second, and we arrive at 4.8 gigabytes/second. Zow. That's more than enough bandwidth to run even the highest of high end video cards, but it is not without overhead. There's a mild performance hit for running the card externally, on the order of 15%. There's also a further performance hit of 10% if you are in \"loopback\" mode on a laptop where you don't have an external display, so the video frames have to be shuttled back from the GPU to the internal laptop display. This may look like a gamer-only thing, but surprisingly, it isn't. What you get is the general purpose ability to attach any PCI express card to any computer with a Thunderbolt 3 port and, for the most part, it just works! Linus breaks it down and answers all your most difficult questions: Please watch the above video closely if you're actually interested in this stuff; it is essential. I'll add some caveats of my own after working with the Razer Core for a while: Make sure the video card you plan to put into the Razer Core is not too tall, or too wide. You can tell if a card is going to be too tall by looking at pictures of the mounting rear bracket. If the card extends significantly above the standard rear mounting bracket, it won't fit. If the card takes more than 2 slots in width, it also won't fit, but this is more rare. Depth (length) is rarely an issue. There are four fans in the Razer Core and although it is reasonably quiet, it's not super silent or anything. You may want to mod the fans. The Razer Core is a remarkably simple device, internally, it's really just a power supply, some Thunderbolt 3 bridge logic, and a PCI express slot. I agree with Linus that the #1 area Razer could improve in the future, beyond generally getting the price down, is to use fewer and larger fans that run quieter. If you're putting a heavy hitter GPU in the Razer Core, I'd try to avoid blower style cards (the ones that exhaust heat from the rear) in favor of those that cool with large fans blowing down and around the card. Dissipating 150w+ is no mean feat and you'll definitely need to keep the enclosure in open air … and of course within 0.5 meters of the computer it's connected to. There is no visible external power switch on the Razer Core. It doesn't power on until you connect a TB3 cable to it. I was totally not expecting that. But once connected, it powers up and the Windows 10 Thunderbolt 3 drivers kick in and ask you to authorize the device, which I did (always authorize). Then it spun a bit, detected the new GPU, and suddenly I had multiple graphics card active on the same computer. I also installed the latest Nvidia drivers just to make sure everything was ship shape. It's kinda ... weird having multiple GPUs simultaneously active. I wanted to make the Razer Core display the only display, but you can't really turn off the built in GPU – you can select \"only use display 2\", that's all. I got into several weird states where windows were opening on the other display and I had to mess around a fair bit to get things locked down to just one display. You may want to consider whether you have both \"displays\" connected for troubleshooting, or not. And then, there I am, playing Lego Marvel in splitscreen co-op at glorious 3840 × 2160 UltraHD resolution on an amazing OLED display with my son. It is incredible. Beyond the technical \"because I could\", I am wildly optimistic about the future of external Thunderbolt 3 expansion boxes, and here's why: The main expense and bottleneck in any stonking gaming rig is, by far, the GPU. It's also the item you are most likely to need to replace a year or two from now. The CPU and memory speeds available today are so comically fast that any device with a low-end i3-7100 for $120 will make zero difference in real world gaming at 1080p or higher … if you're OK with 30fps minimum. If you bump up to $200, you can get a quad-core i5-7500 that guarantees you 60fps minimum everywhere. If you prefer a small system or a laptop, an external GPU makes it so much more flexible. Because CPU and memory speeds are already so fast, 99.9% of the time your bottleneck is the GPU, and almost any small device you can buy with a Thunderbolt 3 port can now magically transform into a potent gaming rig with a single plug. Thunderbolt 3 may be a bit cutting edge today, but more and more devices are shipping with Thunderbolt 3. Within a few years, I predict TB3 ports will be as common as USB3 ports. A general purpose external PCI express enclosure will be usable for a very long time. My last seven video card upgrades were plug and play PCI Express cards that would have worked fine in any computer I've built in the last ten years. External GPUs are not meaningfully bottlenecked by Thunderbolt 3 bandwidth; the impact is 15% to 25%, and perhaps even less over time as drivers and implementations mature. While Thunderbolt 3 has \"only\" PCI Express x4 bandwidth, many benchmarkers have noted that GPUs moving from PCI Express x16 to x8 has almost no effect on performance. And there's always Thunderbolt 4 on the horizon. The future, as they say, is already here – it's just not evenly distributed. I am painfully aware that costs need to come down. Way, way down. The $499 Razer Core is well made, on the vanguard of what's possible, a harbinger of the future, and fantastically enough, it does even more than what it says on the tin. But it's not exactly affordable. I would absolutely love to see a modest, dedicated $200 external Thunderbolt 3 box that included an inexpensive current-gen GPU. This would clobber any onboard GPU on the planet. Let's compare my Skull Canyon NUC, which has Intel's fastest ever, PS4 class embedded GPU, with the modest $150 GeForce GTX 1050 Ti: 1920 × 1080 high detail Bioshock Infinite15 → 79 fps Rise of the Tomb Raider12 → 49 fps Overwatch43 → 114 fps As predicted, that's a 3x-5x stompdown. Mac users lamenting their general lack of upgradeability, hear me: this sort of box is exactly what you want and need. Imagine if Apple was to embrace upgrading their laptops and all-in-one systems via Thunderbolt 3. I know, I know. It's a stretch. But a man can dream … of externally upgradeable GPUs. That are too expensive, sure, but they are here, right now, today. They'll only get cheaper over time.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n        \n        \n\u003cmain role=\"main\"\u003e\n\n    \u003carticle\u003e\n\n\n            \u003cspan\u003e\u003ctime datetime=\"2017-03-24\"\u003e24 Mar 2017\u003c/time\u003e \u003c/span\u003e\n\n            \n\n            \u003csection\u003e\n                \u003cp\u003eWhen I wrote about \u003ca href=\"https://blog.codinghorror.com/the-golden-age-of-x86-gaming/\"\u003eThe Golden Age of x86 Gaming\u003c/a\u003e, I \u003cem\u003eimplied\u003c/em\u003e that, in the future, it might be an interesting, albeit expensive, idea to upgrade your video card via an external Thunderbolt 3 enclosure.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://blog.codinghorror.com/content/images/2017/03/skull-canyon-nuc-with-razer-core.jpg\" alt=\"\" loading=\"lazy\"/\u003e\u003c/p\u003e\n\u003cp\u003eI\u0026#39;m here to report that \u003cstrong\u003ethe future is now\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eYes, that\u0026#39;s right, I paid $500 for \u003ca href=\"https://www.razerzone.com/store/razer-core?ref=blog.codinghorror.com\"\u003ean external Thunderbolt 3 enclosure\u003c/a\u003e to fit a $600 video card, all to enable a plug-in upgrade of a GPU on a \u003ca href=\"https://blog.codinghorror.com/the-golden-age-of-x86-gaming/\"\u003eSkull Canyon NUC\u003c/a\u003e that itself cost around $1000 fully built. I know, it sounds crazy, and … OK fine, I won\u0026#39;t argue with you. It\u0026#39;s crazy.\u003c/p\u003e\n\u003cp\u003eThis matters mostly because of 4k, aka 2160p, aka 3840 × 2160, aka \u003cstrong\u003eUltra HD\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://blog.codinghorror.com/content/images/2015/08/common-hd-resolutions-compared.png\" alt=\"4k compared to 1080p\" loading=\"lazy\"/\u003e\u003c/p\u003e\n\u003cp\u003ePlain old regular HD, aka 1080p, aka 1920 × 1080, is one quarter the size of 4k, and ¼ the work. By today\u0026#39;s GPU standards HD is pretty much \u003cem\u003eeasy mode\u003c/em\u003e these days. It\u0026#39;s not even interesting. No offense to console fans, or anything.\u003c/p\u003e\n\u003cp\u003eLate in 2016, I got a \u003ca href=\"https://www.amazon.com/gp/product/B01CDD4J58/?tag=codihorr-20\u0026amp;ref=blog.codinghorror.com\"\u003e4k OLED display\u003c/a\u003e and it … kind of blew my mind. I have never seen blacks so black, colors so vivid, on a display so thin. It made my previous 2008 era Panasonic plasma set look lame. It\u0026#39;s so good that I\u0026#39;m now a little angry that every display that my eyes touch isn\u0026#39;t OLED already. I even got into nerd fights over it, and to be honest, I\u0026#39;d still throw down for OLED. It is legitimately \u003cem\u003ethat good\u003c/em\u003e. Come at me, bro.\u003c/p\u003e\n\u003cp\u003eDon\u0026#39;t believe me? Well, guess which display in the below picture is OLED? Go on, guess:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.consumerreports.org/lcd-led-oled-tvs/2016-LG-4K-oled-tvs/?ref=blog.codinghorror.com\"\u003e\u003cimg src=\"https://blog.codinghorror.com/content/images/2017/03/CptX7RCVYAAKNOP.jpg\" alt=\"Guess which screen is OLED?\" loading=\"lazy\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote data-lang=\"en\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003e\u003ca href=\"https://twitter.com/andrewbstiles?ref=blog.codinghorror.com\"\u003e@andrewbstiles\u003c/a\u003e if it was physically possible to have sex with this TV I.. uh.. I\u0026#39;d take it on long, romantic walks\u003c/p\u003e— Jeff Atwood (@codinghorror) \u003ca href=\"https://twitter.com/codinghorror/status/764304493483663361?ref=blog.codinghorror.com\"\u003eAugust 13, 2016\u003c/a\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eThere\u0026#39;s a reason every site that reviews TVs had to recalibrate their results when \u003ca href=\"http://thewirecutter.com/reviews/best-tv/?ref=blog.codinghorror.com\"\u003ethey reviewed the 2016 OLED sets\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn my extended review at Reference Home Theater, I call it “the best looking TV I’ve ever reviewed.” But we aren’t alone in loving the E6. Vincent Teoh at HDTVtest writes, “We’re not even going to qualify the following endorsement: if you can afford it, this is the TV to buy.” Rtings.com gave \u003ca href=\"https://www.amazon.com/gp/product/B01CDD4J58/?tag=codihorr-20\u0026amp;ref=blog.codinghorror.com\"\u003ethe E6 OLED\u003c/a\u003e the highest score of any TV the site has ever tested. Reviewed.com awarded it a 9.9 out of 10, with only the LG G6 OLED (which offers the same image but better styling and sound for $2,000 more) coming out ahead.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eBut I digress.\u003c/p\u003e\n\u003cp\u003ePlaying games at 1080p in my living room was already possible. But now that I have an incredible 4k display in the living room, it\u0026#39;s a whole other level of difficulty. Not just twice as hard – and remember current consoles \u003cem\u003ebarely\u003c/em\u003e manage to eke out 1080p at 30fps in most games – but \u003cstrong\u003efour times as hard\u003c/strong\u003e. That\u0026#39;s where external GPU power comes in.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://blog.codinghorror.com/content/images/2017/03/razer-core-with-gpu.jpg\" alt=\"\" loading=\"lazy\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe cool technology underpinning all of this is \u003cstrong\u003eThunderbolt 3\u003c/strong\u003e. The thunderbolt cable bundled with the Razer Core is rather … diminutive. There\u0026#39;s \u003ca href=\"https://blog.startech.com/post/thunderbolt-3-the-basics/?ref=blog.codinghorror.com\"\u003ea reason for this\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eIs there a maximum cable length for Thunderbolt 3 technology?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThunderbolt 3 passive cables have maximum lengths.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e0.5m TB 3 (40Gbps)\u003c/li\u003e\n\u003cli\u003e1.0m TB 3 (20Gbps)\u003c/li\u003e\n\u003cli\u003e2.0m TB 3 (20Gbps)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn the future we will offer active cables which will provide 40Gbps of bandwidth at longer lengths.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e40Gbps is, for the record, an \u003cem\u003einsane\u003c/em\u003e amount of bandwidth. Let\u0026#39;s use our rule of thumb based on ultra common gigabit ethernet, that 1 gigabit = 120 megabytes/second, and we arrive at \u003cstrong\u003e4.8 gigabytes/second\u003c/strong\u003e. Zow.\u003c/p\u003e\n\u003cp\u003eThat\u0026#39;s more than enough bandwidth to run even the highest of high end video cards, but it is not without overhead. There\u0026#39;s \u003ca href=\"http://www.ultrabookreview.com/10761-razer-core-review/?ref=blog.codinghorror.com\"\u003ea mild performance hit\u003c/a\u003e for running the card externally, on the order of \u003cstrong\u003e15%\u003c/strong\u003e. There\u0026#39;s also a further performance hit of 10% if you are in \u0026#34;loopback\u0026#34; mode on a laptop where you don\u0026#39;t \u003cem\u003ehave\u003c/em\u003e an external display, so the video frames have to be shuttled back from the GPU to the internal laptop display.\u003c/p\u003e\n\u003cp\u003eThis may look like a gamer-only thing, but surprisingly, it isn\u0026#39;t. What you get is the general purpose ability to attach \u003cstrong\u003eany PCI express card\u003c/strong\u003e to any computer with a \u003cstrong\u003eThunderbolt 3\u003c/strong\u003e port and, for the most part, it just works!\u003c/p\u003e\n\u003cp\u003eLinus breaks it down and answers all your most difficult questions:\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2D79GsrEqe4\" frameborder=\"0\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\n\u003cp\u003ePlease watch the above video closely if you\u0026#39;re actually interested in this stuff; it is essential. I\u0026#39;ll add some caveats of my own after working with the Razer Core for a while:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eMake sure the video card you plan to put into the Razer Core is not too tall, or too wide. You can tell if a card is going to be too tall by looking at pictures of the mounting rear bracket. If the card extends significantly above the standard rear mounting bracket, it won\u0026#39;t fit. If the card takes more than 2 slots in width, it also won\u0026#39;t fit, but this is more rare. Depth (length) is rarely an issue.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThere are four fans in the Razer Core and although it is \u003cem\u003ereasonably\u003c/em\u003e quiet, it\u0026#39;s not super silent or anything. You may want to \u003ca href=\"http://forum.notebookreview.com/threads/razer-core-disassembly-fan-location-guide.802000/?ref=blog.codinghorror.com\"\u003emod the fans\u003c/a\u003e. The Razer Core is a remarkably simple device, internally, it\u0026#39;s really just a power supply, some Thunderbolt 3 bridge logic, and a PCI express slot. I agree with Linus that the #1 area Razer could improve in the future, beyond generally getting the price down, is to use fewer and larger fans that run quieter.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you\u0026#39;re putting a heavy hitter GPU in the Razer Core, I\u0026#39;d try to avoid blower style cards (the ones that exhaust heat from the rear) in favor of those that cool with large fans blowing down and around the card. Dissipating 150w+ is no mean feat and you\u0026#39;ll definitely need to keep the enclosure in open air … and of course within 0.5 meters of the computer it\u0026#39;s connected to.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThere is no visible external power switch on the Razer Core. It doesn\u0026#39;t power on until you connect a TB3 cable to it. I was totally not expecting that. But once connected, it powers up and the Windows 10 Thunderbolt 3 drivers kick in and ask you to authorize the device, which I did (always authorize). Then it spun a bit, detected the new GPU, and suddenly I had multiple graphics card active on the same computer. I also installed the latest Nvidia drivers just to make sure everything was ship shape.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIt\u0026#39;s kinda ... \u003cem\u003eweird\u003c/em\u003e having multiple GPUs simultaneously active. I wanted to make the Razer Core display the only display, but you can\u0026#39;t really turn off the built in GPU – you can select \u0026#34;only use display 2\u0026#34;, that\u0026#39;s all. I got into several weird states where windows were opening on the other display and I had to mess around a fair bit to get things locked down to just one display. You may want to consider whether you have both \u0026#34;displays\u0026#34; connected for troubleshooting, or not.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnd then, there I am, playing Lego Marvel in splitscreen co-op at glorious 3840 × 2160 UltraHD resolution on an amazing OLED display with my son. It is \u003cem\u003eincredible\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://blog.codinghorror.com/content/images/2017/03/lego-marvel-4k.jpg\" alt=\"\" loading=\"lazy\"/\u003e\u003c/p\u003e\n\u003cp\u003eBeyond the technical \u0026#34;because I could\u0026#34;, I am \u003cstrong\u003ewildly optimistic about the future of external Thunderbolt 3 expansion boxes\u003c/strong\u003e, and here\u0026#39;s why:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe main expense and bottleneck in any stonking gaming rig is, by \u003cem\u003efar\u003c/em\u003e, the GPU. It\u0026#39;s also the item you are most likely to need to replace a year or two from now.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe CPU and memory speeds available today are so comically fast that any device with a low-end i3-7100 for $120 will make zero difference in real world gaming at 1080p or higher … if you\u0026#39;re OK with 30fps minimum. If you bump up to $200, you can get a quad-core i5-7500 that guarantees you 60fps minimum everywhere.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you prefer a small system or a laptop, an external GPU makes it so much more flexible. Because CPU and memory speeds are already so fast, 99.9% of the time your bottleneck is the GPU, and almost \u003cstrong\u003eany small device you can buy with a Thunderbolt 3 port can now magically transform into a potent gaming rig with a single plug\u003c/strong\u003e. Thunderbolt 3 may be a bit cutting edge today, but more and more devices are shipping with Thunderbolt 3. Within a few years, I predict TB3 ports will be as common as USB3 ports.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA general purpose external PCI express enclosure will be usable for a very long time. My last \u003cem\u003eseven\u003c/em\u003e video card upgrades were plug and play PCI Express cards that would have worked fine in any computer I\u0026#39;ve built in the last ten years.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExternal GPUs are not meaningfully bottlenecked by Thunderbolt 3 bandwidth; the impact is 15%  to 25%, and perhaps even less over time as drivers and implementations mature. While Thunderbolt 3 has \u0026#34;only\u0026#34; PCI Express x4 bandwidth, many benchmarkers have noted that GPUs moving from PCI Express x16 to x8 has \u003ca href=\"https://www.pugetsystems.com/labs/articles/Impact-of-PCI-E-Speed-on-Gaming-Performance-518/?ref=blog.codinghorror.com\"\u003ealmost no effect on performance\u003c/a\u003e. And there\u0026#39;s always Thunderbolt 4 on the horizon.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe future, as they say, is already here – it\u0026#39;s just not evenly distributed.\u003c/p\u003e\n\u003cp\u003eI am painfully aware that \u003cstrong\u003ecosts need to come down\u003c/strong\u003e. Way, \u003cem\u003eway\u003c/em\u003e down. The \u003ca href=\"https://www.razerzone.com/store/razer-core?ref=blog.codinghorror.com\"\u003e$499 Razer Core\u003c/a\u003e is well made, on the vanguard of what\u0026#39;s possible, a harbinger of the future, and fantastically enough, it does \u003cem\u003eeven more\u003c/em\u003e than what it says on the tin. But it\u0026#39;s not exactly \u003cem\u003eaffordable\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eI would absolutely love to see a modest, dedicated $200 external Thunderbolt 3 box that included an inexpensive current-gen GPU. This would \u003cem\u003eclobber\u003c/em\u003e any onboard GPU on the planet. Let\u0026#39;s compare my Skull Canyon NUC, which has Intel\u0026#39;s \u003ca href=\"http://www.notebookcheck.net/Intel-Iris-Pro-Graphics-580.160664.0.html?ref=blog.codinghorror.com\"\u003efastest ever, PS4 class embedded GPU\u003c/a\u003e, with the modest $150 \u003ca href=\"http://www.notebookcheck.com/NVIDIA-GeForce-GTX-1050-Ti-Desktop.181030.0.html?ref=blog.codinghorror.com\"\u003eGeForce GTX 1050 Ti\u003c/a\u003e:\u003c/p\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd colspan=\"2\"\u003e\u003cb\u003e1920 × 1080 high detail\u003c/b\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eBioshock Infinite\u003c/td\u003e\u003ctd\u003e15 → 79 fps\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRise of the Tomb Raider\u003c/td\u003e\u003ctd\u003e12 → 49 fps\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eOverwatch\u003c/td\u003e\u003ctd\u003e43 → 114 fps\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003eAs predicted, that\u0026#39;s a 3x-5x stompdown. Mac users lamenting their general lack of upgradeability, hear me: \u003cem\u003ethis sort of box is exactly what you want and need\u003c/em\u003e. Imagine if Apple was to embrace upgrading their laptops and all-in-one systems via Thunderbolt 3.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://blog.codinghorror.com/content/images/2017/03/razer-core-and-razer-laptop.jpg\" alt=\"\" loading=\"lazy\"/\u003e\u003c/p\u003e\n\u003cp\u003eI know, I know. It\u0026#39;s a stretch. But a man can dream … of externally upgradeable GPUs. That are too expensive, sure, but they are here, right now, today. They\u0026#39;ll only get cheaper over time.\u003c/p\u003e\n  \n            \u003c/section\u003e\n\n            \n\n            \n\n\n    \u003c/article\u003e\n\n    \n\n    \n\n\u003c/main\u003e\n\n\n\n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2017-03-24T09:08:37Z",
  "modifiedTime": "2017-03-24T09:47:21Z"
}
