{
  "id": "e8a538aa-5a07-4e7d-b352-f24e272d7ecb",
  "title": "Faster Python: Concurrency in async/await and threading",
  "link": "https://blog.jetbrains.com/pycharm/2025/06/concurrency-in-async-await-and-threading/",
  "description": "If you have been coding with Python for a while, especially if you have been using frameworks and libraries such as Fast API and discord.py, then you have probably been using async/await or asyncio. You may have heard statements like “multithreading in Python isn’t real”, and you may also know about the famous (or infamous) […]",
  "author": "Cheuk Ting Ho",
  "published": "Tue, 10 Jun 2025 11:57:58 +0000",
  "source": "https://blog.jetbrains.com/feed",
  "categories": [
    "how-tos",
    "tutorials",
    "web-development",
    "concurrency",
    "python"
  ],
  "byline": "Cheuk Ting Ho",
  "length": 30830,
  "excerpt": "Want to write faster Python code? Discover the difference between `async/await` and `threading` and how concurrency works in Python with real-world examples.",
  "siteName": "The JetBrains Blog",
  "favicon": "https://blog.jetbrains.com/wp-content/uploads/2024/01/cropped-mstile-310x310-1-180x180.png",
  "text": "The only Python IDE you need. How-To's Tutorials Web DevelopmentFaster Python: Concurrency in async/await and threading If you have been coding with Python for a while, especially if you have been using frameworks and libraries such as Fast API and discord.py, then you have probably been using async/await or asyncio. You may have heard statements like “multithreading in Python isn’t real”, and you may also know about the famous (or infamous) GIL in Python. In light of the denial about multithreading in Python, you might be wondering what the difference between async/await and multithreading actually is – especially in Python programming. If so, this is the blog post for you! What is multithreading? In programming, multithreading refers to the ability of a program to execute multiple sequential tasks (called threads) concurrently. These threads can run on a single processor core or across multiple cores. However, due to the limitation of the Global Interpreter Lock (GIL), multithreading in Python is only processed on a single core. The exception is nogil (also called thread-free) Python, which removes the GIL and will be covered in part 2 of this series. For this blog post, we will assume that the GIL is always present. What is concurrency? Concurrency in programming means that the computer is doing more than one thing at a time, or seems to be doing more than one thing at a time, even if the different tasks are executed on a single processor. By managing resources and interactions between different parts of a program, different tasks are allowed to make progress independently and in overlapping time intervals. Both asyncio and threading appear concurrent in Python Loosely speaking, both the asyncio and threading Python libraries enable the appearance of concurrency. However, your CPUs are not doing multiple things at the exact same time. It just seems like they are. Imagine you are hosting a multi-course dinner for some guests. Some of the dishes take time to cook, for example, the pie that needs to be baked in the oven or the soup simmering on the stove. While we are waiting for those to cook, we do not just stand around and wait. We will do something else in the meantime. This is similar to concurrency in Python. Sometimes your Python process is waiting for something to get done. For example, some input/output (I/O) processes are being handled by the operating system, and in this time the Python process is just waiting. We can then use async to let another Python process run while it waits. The difference is who is in charge If both asyncio and threading appear concurrent, what is the difference between them? Well, the main difference is a matter of who is in charge of which process is running and when. For async/await, the approach is sometimes called cooperative concurrency. A coroutine or future gives up its control to another coroutine or future to let others have a go. On the other hand, in threading, the operating system’s manager will be in control of which process is running. Cooperative concurrency is like a meeting with a microphone being passed around for people to speak. Whoever has the microphone can talk, and when they are done or have nothing else to say, they will pass the microphone to the next person. In contrast, multithreading is a meeting where there is a chairperson who will determine who has the floor at any given time.  Writing concurrent code in Python Let’s have a look at how concurrency works in Python by writing some example code. We will create a fast food restaurant simulation using both asyncio and threading. How async/await works in Python The asyncio package was introduced in Python 3.4, while the async and await keywords were introduced in Python 3.5. One of the main things that make async/await possible is the use of coroutines. Coroutines in Python are actually generators repurposed to be able to pause and pass back to the main function. Now, imagine a burger restaurant where only one staff member is working. The orders are prepared according to a first-in-first-out queue, and no async operations can be performed: import time def make_burger(order_num): print(f\"Preparing burger #{order_num}...\") time.sleep(5) # time for making the burger print(f\"Burger made #{order_num}\") def main(): for i in range(3): make_burger(i) if __name__ == \"__main__\": s = time.perf_counter() main() elapsed = time.perf_counter() - s print(f\"Orders completed in {elapsed:0.2f} seconds.\") This will take a while to finish: Preparing burger #0... Burger made #0 Preparing burger #1... Burger made #1 Preparing burger #2... Burger made #2 Orders completed in 15.01 seconds. Now, imagine the restaurant brings in more staff, so that it can perform work concurrently: import asyncio import time async def make_burger(order_num):     print(f\"Preparing burger #{order_num}...\")     await asyncio.sleep(5) # time for making the burger     print(f\"Burger made #{order_num}\") async def main():     order_queue = []     for i in range(3):         order_queue.append(make_burger(i))     await asyncio.gather(*(order_queue)) if __name__ == \"__main__\":     s = time.perf_counter()     asyncio.run(main())     elapsed = time.perf_counter() - s     print(f\"Orders completed in {elapsed:0.2f} seconds.\") We see the difference between the two: Preparing burger #0... Preparing burger #1... Preparing burger #2... Burger made #0 Burger made #1 Burger made #2 Orders completed in 5.00 seconds. Using the functions provided by asyncio, like run and gather, and the keywords async and await, we have created coroutines that can make burgers concurrently. Now, let’s take a step further and create a more complicated simulation. Imagine we only have two workers, and we can only make two burgers at a time. import asyncio import time order_queue = asyncio.Queue() def take_order():   for i in range(3):       order_queue.put_nowait(make_burger(i)) async def make_burger(order_num):   print(f\"Preparing burger #{order_num}...\")   await asyncio.sleep(5)  # time for making the burger   print(f\"Burger made #{order_num}\") class Staff:   def __init__(self, name):       self.name = name   async def working(self):       while order_queue.qsize() \u003e 0:           print(f\"{self.name} is working...\")           task = await order_queue.get()           await task           print(f\"{self.name} finished a task...\") async def main():   staff1 = Staff(name=\"John\")   staff2 = Staff(name=\"Jane\")   take_order()   await asyncio.gather(staff1.working(), staff2.working()) if __name__ == \"__main__\":   s = time.perf_counter()   asyncio.run(main())   elapsed = time.perf_counter() - s   print(f\"Orders completed in {elapsed:0.2f} seconds.\") Here we will use a queue to hold the tasks, and the staff will pick them up. John is working... Preparing burger #0... Jane is working... Preparing burger #1... Burger made #0 John finished a task... John is working... Preparing burger #2... Burger made #1 Jane finished a task... Burger made #2 John finished a task... Orders completed in 10.00 seconds. In this example, we use asyncio.Queue to store the tasks, but it will be more useful if we have multiple types of tasks, as shown in the following example. import asyncio import time task_queue = asyncio.Queue() order_num = 0 async def take_order():    global order_num    order_num += 1    print(f\"Order burger and fries for order #{order_num:04d}:\")    burger_num = input(\"Number of burgers:\")    for i in range(int(burger_num)):        await task_queue.put(make_burger(f\"{order_num:04d}-burger{i:02d}\"))    fries_num = input(\"Number of fries:\")    for i in range(int(fries_num)):        await task_queue.put(make_fries(f\"{order_num:04d}-fries{i:02d}\"))    print(f\"Order #{order_num:04d} queued.\")    await task_queue.put(take_order()) async def make_burger(order_num):    print(f\"Preparing burger #{order_num}...\")    await asyncio.sleep(5)  # time for making the burger    print(f\"Burger made #{order_num}\") async def make_fries(order_num):    print(f\"Preparing fries #{order_num}...\")    await asyncio.sleep(2)  # time for making fries    print(f\"Fries made #{order_num}\") class Staff:    def __init__(self, name):        self.name = name    async def working(self):        while True:            if task_queue.qsize() \u003e 0:                print(f\"{self.name} is working...\")                task = await task_queue.get()                await task                print(f\"{self.name} finish task...\")            else:                await asyncio.sleep(1) #rest async def main():    task_queue.put_nowait(take_order())    staff1 = Staff(name=\"John\")    staff2 = Staff(name=\"Jane\")    await asyncio.gather(staff1.working(), staff2.working()) if __name__ == \"__main__\":    s = time.perf_counter()    asyncio.run(main())    elapsed = time.perf_counter() - s    print(f\"Orders completed in {elapsed:0.2f} seconds.\") In this example, there are multiple tasks, including making fries, which takes less time, and taking orders, which involves getting input from the user.  Notice that the program stops waiting for the user’s input, and even the other staff who are not taking the order stop working in the background. This is because the input function is not async and therefore is not awaited. Remember, control in async code is only released when it is awaited. To fix that, we can replace: input(\"Number of burgers:\") With  await asyncio.to_thread(input, \"Number of burgers:\") And we do the same for fries – see the code below. Note that now the program runs in an infinite loop. If we need to stop it, we can deliberately crash the program with an invalid input. import asyncio import time task_queue = asyncio.Queue() order_num = 0 async def take_order():    global order_num    order_num += 1    print(f\"Order burger and fries for order #{order_num:04d}:\")    burger_num = await asyncio.to_thread(input, \"Number of burgers:\")    for i in range(int(burger_num)):        await task_queue.put(make_burger(f\"{order_num:04d}-burger{i:02d}\"))    fries_num = await asyncio.to_thread(input, \"Number of fries:\")    for i in range(int(fries_num)):        await task_queue.put(make_fries(f\"{order_num:04d}-fries{i:02d}\"))    print(f\"Order #{order_num:04d} queued.\")    await task_queue.put(take_order()) async def make_burger(order_num):    print(f\"Preparing burger #{order_num}...\")    await asyncio.sleep(5)  # time for making the burger    print(f\"Burger made #{order_num}\") async def make_fries(order_num):    print(f\"Preparing fries #{order_num}...\")    await asyncio.sleep(2)  # time for making fries    print(f\"Fries made #{order_num}\") class Staff:    def __init__(self, name):        self.name = name    async def working(self):        while True:            if task_queue.qsize() \u003e 0:                print(f\"{self.name} is working...\")                task = await task_queue.get()                await task                print(f\"{self.name} finish task...\")            else:                await asyncio.sleep(1) #rest async def main():    task_queue.put_nowait(take_order())    staff1 = Staff(name=\"John\")    staff2 = Staff(name=\"Jane\")    await asyncio.gather(staff1.working(), staff2.working()) if __name__ == \"__main__\":    s = time.perf_counter()    asyncio.run(main())    elapsed = time.perf_counter() - s    print(f\"Orders completed in {elapsed:0.2f} seconds.\") By using asyncio.to_thread, we have put the input function into a separate thread (see this reference). Do note, however, that this trick only unblocks I/O-bounded tasks if the Python GIL is present. If you run the code above, you may also see that the standard I/O in the terminal is scrambled. The user I/O and the record of what is happening should be separate. We can put the record into a log to inspect later.  import asyncio import logging import time logger = logging.getLogger(__name__) logging.basicConfig(filename='pyburger.log', level=logging.INFO) task_queue = asyncio.Queue() order_num = 0 closing = False async def take_order():    global order_num, closing    try:        order_num += 1        logger.info(f\"Taking Order #{order_num:04d}...\")        print(f\"Order burger and fries for order #{order_num:04d}:\")        burger_num = await asyncio.to_thread(input, \"Number of burgers:\")        for i in range(int(burger_num)):            await task_queue.put(make_burger(f\"{order_num:04d}-burger{i:02d}\"))        fries_num = await asyncio.to_thread(input, \"Number of fries:\")        for i in range(int(fries_num)):            await task_queue.put(make_fries(f\"{order_num:04d}-fries{i:02d}\"))        logger.info(f\"Order #{order_num:04d} queued.\")        print(f\"Order #{order_num:04d} queued, please wait.\")        await task_queue.put(take_order())    except ValueError:        print(\"Goodbye!\")        logger.info(\"Closing down... stop taking orders and finish all tasks.\")        closing = True async def make_burger(order_num):    logger.info(f\"Preparing burger #{order_num}...\")    await asyncio.sleep(5)  # time for making the burger    logger.info(f\"Burger made #{order_num}\") async def make_fries(order_num):    logger.info(f\"Preparing fries #{order_num}...\")    await asyncio.sleep(2)  # time for making fries    logger.info(f\"Fries made #{order_num}\") class Staff:    def __init__(self, name):        self.name = name    async def working(self):        while True:            if task_queue.qsize() \u003e 0:                logger.info(f\"{self.name} is working...\")                task = await task_queue.get()                await task                task_queue.task_done()                logger.info(f\"{self.name} finish task.\")            elif closing:                return            else:                await asyncio.sleep(1) #rest async def main():    global task_queue    task_queue.put_nowait(take_order())    staff1 = Staff(name=\"John\")    staff2 = Staff(name=\"Jane\")    print(\"Welcome to Pyburger!\")    logger.info(\"Ready for business!\")    await asyncio.gather(staff1.working(), staff2.working())    logger.info(\"All tasks finished. Closing now.\") if __name__ == \"__main__\":    s = time.perf_counter()    asyncio.run(main())    elapsed = time.perf_counter() - s    logger.info(f\"Orders completed in {elapsed:0.2f} seconds.\") In this final code block, we have logged the simulation information in pyburger.log and reserved the terminal for messages for customers. We also catch invalid input during the ordering process and switch a closing flag to True if the input is invalid, assuming the user wants to quit. Once the closing flag is set to True, the worker will return, ending the coroutine’s infinite while loop. How does threading work in Python? In the example above, we put an I/O-bound task into another thread. You may wonder if we can put all tasks into separate threads and let them run concurrently. Let’s try using threading instead of asyncio. Consider the code we have as shown below, where we create burgers concurrently with no limitation put in place: import asyncio import time async def make_burger(order_num):     print(f\"Preparing burger #{order_num}...\")     await asyncio.sleep(5) # time for making the burger     print(f\"Burger made #{order_num}\") async def main():     order_queue = []     for i in range(3):         order_queue.append(make_burger(i))     await asyncio.gather(*(order_queue)) if __name__ == \"__main__\":     s = time.perf_counter()     asyncio.run(main())     elapsed = time.perf_counter() - s     print(f\"Orders completed in {elapsed:0.2f} seconds.\") ``` Instead of creating async coroutines to make the burgers, we can just send functions down different threads like this: ``` import threading import time def make_burger(order_num):    print(f\"Preparing burger #{order_num}...\")    time.sleep(5) # time for making the burger    print(f\"Burger made #{order_num}\") def main():    order_queue = []    for i in range(3):        task = threading.Thread(target=make_burger, args=(i,))        order_queue.append(task)        task.start()    for task in order_queue:        task.join() if __name__ == \"__main__\":    s = time.perf_counter()    main()    elapsed = time.perf_counter() - s    print(f\"Orders completed in {elapsed:0.2f} seconds.\") In the first for loop in main, tasks are created in different threads and get a kickstart. The second for loop makes sure all the burgers are made before the program moves on (that is, before it returns to main). It is more complicated when we have only two staff members. Each member of the staff is represented with a thread, and they will take tasks from a normal list where they are all stored. import threading import time order_queue = [] def take_order():    for i in range(3):        order_queue.append(make_burger(i)) def make_burger(order_num):    def making_burger():        print(f\"Preparing burger #{order_num}...\")        time.sleep(5)  # time for making the burger        print(f\"Burger made #{order_num}\")    return making_burger def working():      while len(order_queue) \u003e 0:          print(f\"{threading.current_thread().name} is working...\")          task = order_queue.pop(0)          task()          print(f\"{threading.current_thread().name} finish task...\") def main():    take_order()    staff1 = threading.Thread(target=working, name=\"John\")    staff1.start()    staff2 = threading.Thread(target=working, name=\"Jane\")    staff2.start()    staff1.join()    staff2.join() if __name__ == \"__main__\":  s = time.perf_counter()  main()  elapsed = time.perf_counter() - s  print(f\"Orders completed in {elapsed:0.2f} seconds.\") When you run the code above, an error may occur in one of the threads, saying that it is trying to get a task from an empty list. You may wonder why this is the case, since we have a condition in the while loop that causes it to continue only if the task_queue is not empty. Nevertheless, we still get an error because we have encountered race conditions. Race conditions Race conditions can occur when multiple threads attempt to access the same resource or data at the same time and cause problems in the system. The timing and order of when the resource is accessed are important to the program logic, and unpredictable timing or the interleaving of multiple threads accessing and modifying shared data can cause errors. To solve the race condition in our program, we will deploy a lock to the task_queue: queue_lock = threading.Lock() For working, we need to make sure we have access rights to the queue when checking its length and getting tasks from it. While we have the rights, other threads cannot access the queue: def working():    while True:        with queue_lock:            if len(order_queue) == 0:                return            else:                task = order_queue.pop(0)        print(f\"{threading.current_thread().name} is working...\")        task()        print(f\"{threading.current_thread().name} finish task...\") ``` Based on what we have learned so far, we can complete our final code with threading like this: ``` import logging import threading import time logger = logging.getLogger(__name__) logging.basicConfig(filename=\"pyburger_threads.log\", level=logging.INFO) queue_lock = threading.Lock() task_queue = [] order_num = 0 closing = False def take_order():    global order_num, closing    try:        order_num += 1        logger.info(f\"Taking Order #{order_num:04d}...\")        print(f\"Order burger and fries for order #{order_num:04d}:\")        burger_num = input(\"Number of burgers:\")        for i in range(int(burger_num)):            with queue_lock:                task_queue.append(make_burger(f\"{order_num:04d}-burger{i:02d}\"))        fries_num = input(\"Number of fries:\")        for i in range(int(fries_num)):            with queue_lock:                task_queue.append(make_fries(f\"{order_num:04d}-fries{i:02d}\"))        logger.info(f\"Order #{order_num:04d} queued.\")        print(f\"Order #{order_num:04d} queued, please wait.\")        with queue_lock:            task_queue.append(take_order)    except ValueError:        print(\"Goodbye!\")        logger.info(\"Closing down... stop taking orders and finish all tasks.\")        closing = True def make_burger(order_num):    def making_burger():        logger.info(f\"Preparing burger #{order_num}...\")        time.sleep(5)  # time for making the burger        logger.info(f\"Burger made #{order_num}\")    return making_burger def make_fries(order_num):    def making_fries():        logger.info(f\"Preparing fried #{order_num}...\")        time.sleep(2)  # time for making fries        logger.info(f\"Fries made #{order_num}\")    return making_fries def working():    while True:        with queue_lock:            if len(task_queue) == 0:                if closing:                    return                else:                    task = None            else:                task = task_queue.pop(0)        if task:            logger.info(f\"{threading.current_thread().name} is working...\")            task()            logger.info(f\"{threading.current_thread().name} finish task...\")        else:            time.sleep(1)  # rest def main():    print(\"Welcome to Pyburger!\")    logger.info(\"Ready for business!\")    task_queue.append(take_order)    staff1 = threading.Thread(target=working, name=\"John\")    staff1.start()    staff2 = threading.Thread(target=working, name=\"Jane\")    staff2.start()    staff1.join()    staff2.join()    logger.info(\"All tasks finished. Closing now.\") if __name__ == \"__main__\":    s = time.perf_counter()    main()    elapsed = time.perf_counter() - s    logger.info(f\"Orders completed in {elapsed:0.2f} seconds.\") If you compare the two code snippets using asyncio and threading, they should have similar results. You may wonder which one is better and why you should choose one over the other. Practically, writing asyncio code is easier than multithreading because we don’t have to take care of potential race conditions and deadlocks by ourselves. Controls are passed around coroutines by default, so no locks are needed. However, Python threads do have the potential to run in parallel, just not most of the time with the GIL in place. We can revisit this when we talk about nogil (thread-free) Python in the next blog post. Benefiting from concurrency Why do we want to use concurrency in programming? There’s one main reason: speed. Like we have illustrated above, tasks can be completed faster if we can cut down the waiting time. There are different types of waiting in computing, and for each one, we tend to use different methods to save time. I/O-bound tasks A task or program is considered input/output (I/O) bound when its execution speed is primarily limited by the speed of I/O operations, such as reading from a file or network, or waiting for user input. I/O operations are generally slower than other CPU operations, and therefore, tasks that involve lots of them can take significantly more time. Typical examples of these tasks include reading data from a database, handling web requests, or working with large files. Using async/await concurrency can help optimize the waiting time during I/O-bound tasks by unblocking the processing sequence and letting other tasks be taken care of while waiting. Async/await concurrency is beneficial in many Python applications, such as web applications that involve a lot of communication with databases and handling web requests. GUIs (graphical user interfaces) can also benefit from async/await concurrency by allowing background tasks to be performed while the user is interacting with the application. CPU-bound tasks A task or program is considered CPU-bound when its execution speed is primarily limited by the speed of the CPU. Typical examples include image or video processing, like resizing or editing, and complex mathematical calculations, such as matrix multiplication or training machine learning models. Contrary to I/O-bound tasks, CPU-bound tasks can rarely be optimised by using async/await concurrency, as the CPU is already busy working on the tasks. If you have more than one CPU in your machine, or if you can offload some of these tasks to one or more GPUs, then CPU-bound tasks can be finished faster by creating more threads and performing multiprocessing. Multiprocessing can optimise how these CPUs and GPUs are used, which is also why many machine learning and AI models these days are trained on multiple GPUs. This, however, is tough to perform with pure Python code, as Python itself is designed to provide abstract layers so users do not have to control the lower-level computation processes. Moreover, Python’s GIL limits the sharing of Python resources across multiple threads on your computer. Recently, Python 3.13 made it possible to remove the GIL, allowing for true multithreading. We will discuss the GIL, and the ability to go without it, in the next blog post. Sometimes, none of the methods we mentioned above are able to speed up CPU-bound tasks sufficiently. When that is the case, the CPU-bound tasks may need to be broken into smaller ones so that they can be performed simultaneously over multiple threads, multiple processors, or even multiple machines. This is parallel processing, and you may have to rewrite your code completely to implement it. In Python, the multiprocessing package offers both local and remote concurrency, which can be used to work around the limitation of the GIL. We will also look at some examples of that in the next blog post. Debugging concurrent code in PyCharm Debugging async or concurrent code can be hard, as the program is not executed in sequence, meaning it is hard to see where and when the code is being executed. Many developers use print to help trace the flow of the code, but this approach is not recommended, as it is very clumsy and using it to investigate a complex program, like a concurrent one, isn’t easy. Plus, it is messy to tidy up after. Many IDEs provide debuggers, which are great for inspecting variables and the flow of the program. Debuggers also provide a clear stack trace across multiple threads. Let’s see how we can track the task_queue of our example restaurant simulation in PyCharm. First, we will put down some breakpoints in our code. You can do that by clicking the line number of the line where you want the debugger to pause. The line number will turn into a red dot, indicating that a breakpoint is set there. We will put breakpoints at lines 23, 27, and 65, where the task_queue is changed in different threads. Then we can run the program in debug mode by clicking the little bug icon in the top right. After clicking on the icon, the Debug window will open up. The program will run until it hits the first breakpoint highlighted in the code. Here we see the John thread is trying to pick up the task, and line 65 is highlighted. At this point, the highlighted line has not been executed yet. This is useful when we want to inspect the variables before entering the breakpoint. Let’s inspect what’s in the task_queue. You can do so simply by starting to type in the Debug window, as shown below. Select or type in “task_queue”, and then press Enter. You will see that the take_order task is in the queue. Now, let’s execute the breakpoint by clicking the Step in button, as shown below. After pressing that and inspecting the Special Variables window that pops up, we see that the task variable is now take_order in the John thread. When querying the task_queue again, we see that now the list is empty. Now let’s click the Resume Program button and let the program run. When the program hits the user input part, PyCharm will bring us to the Console window so we can provide the input. Let’s say we want two burgers. Type “2” and press Enter. Now we hit the second breakpoint. If we click on Threads \u0026 Variables to go back to that window, we’ll see that burger_num is two, as we entered. Now let’s step into the breakpoint and inspect the task_queue, just like we did before. We see that one make_burger task has been added. We let the program run again, and if we step into the breakpoint when it stops, we see that Jane is picking up the task. You can inspect the rest of the code yourself. When you are done, simply press the red Stop button at the top of the window. With the debugger in PyCharm, you can follow the execution of your program across different threads and inspect different variables very easily. Conclusion Now we have learned the basics of concurrency in Python, and I hope you will be able to master it with practice. In the next blog post, we will have a look at the Python GIL, the role it plays, and what changes when it is absent. PyCharm provides powerful tools for working with concurrent Python code. As demonstrated in this blog post, the debugger allows the step-by-step inspection of both async and threaded code, helping you track the execution flow, monitor shared resources, and detect issues. With intuitive breakpoints, real-time variable views, seamless console integration for user input, and robust logging support, PyCharm makes it easier to write, test, and debug applications with confidence and clarity. Subscribe to PyCharm Blog updates Discover more",
  "image": "https://blog.jetbrains.com/wp-content/uploads/2025/05/PC-social-BlogSocialShare-1280x720-2x-8.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n    \u003cdiv\u003e\n                        \u003ca href=\"https://blog.jetbrains.com/pycharm/\"\u003e\n                            \u003cimg src=\"https://blog.jetbrains.com/wp-content/uploads/2019/01/PyCharm-1.svg\" alt=\"Pycharm logo\"/\u003e\n                                                                                                \n                                                                                    \u003c/a\u003e\n                                                    \u003cp\u003eThe only Python IDE you need.\u003c/p\u003e\n                                            \u003c/div\u003e\n                            \u003csection data-clarity-region=\"article\"\u003e\n                \u003cdiv\u003e\n                    \t\t\t\t\u003cp\u003e\u003ca href=\"https://blog.jetbrains.com/pycharm/category/how-tos/\"\u003eHow-To\u0026#39;s\u003c/a\u003e\n\t\t\t\u003ca href=\"https://blog.jetbrains.com/pycharm/category/tutorials/\"\u003eTutorials\u003c/a\u003e\n\t\t\t\u003ca href=\"https://blog.jetbrains.com/pycharm/category/web-development/\"\u003eWeb Development\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"major-updates\"\u003eFaster Python: Concurrency in async/await and threading\u003c/h2\u003e                    \n                    \n\u003cfigure\u003e\u003cimg decoding=\"async\" fetchpriority=\"high\" width=\"2560\" height=\"1440\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/PC-social-BlogFeatured-1280x720-2x-14.png\" alt=\"Faster Python Concurrency in async/await and threading\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIf you have been coding with Python for a while, especially if you have been using frameworks and libraries such as Fast API and discord.py, then you have probably been using \u003ccode\u003easync/await\u003c/code\u003e or \u003ccode\u003easyncio\u003c/code\u003e. You may have heard statements like “multithreading in Python isn’t real”, and you may also know about the famous (or infamous) GIL in Python. In light of the denial about multithreading in Python, you might be wondering what the difference between \u003ccode\u003easync/await\u003c/code\u003e and multithreading actually is – especially in Python programming. If so, this is the blog post for you!\u003c/p\u003e\n\n\n\n\u003ch2 id=\"what-is-multithreading\"\u003eWhat is multithreading?\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn programming, multithreading refers to the ability of a program to execute multiple sequential tasks (called threads) concurrently. These threads can run on a single processor core or across multiple cores. However, due to the limitation of the Global Interpreter Lock (GIL), multithreading in Python is only processed on a single core. The exception is nogil (also called thread-free) Python, which removes the GIL and will be covered in part 2 of this series. For this blog post, we will assume that the GIL is always present.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"what-is-concurrency\"\u003eWhat is concurrency?\u003c/h2\u003e\n\n\n\n\u003cp\u003eConcurrency in programming means that the computer is doing more than one thing at a time, or seems to be doing more than one thing at a time, even if the different tasks are executed on a single processor. By managing resources and interactions between different parts of a program, different tasks are allowed to make progress independently and in overlapping time intervals.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"both-asyncio-and-threading-appear-concurrent-in-python\"\u003eBoth \u003ccode\u003easyncio\u003c/code\u003e and \u003ccode\u003ethreading\u003c/code\u003e appear concurrent in Python\u003c/h3\u003e\n\n\n\n\u003cp\u003eLoosely speaking, both the \u003ccode\u003easyncio\u003c/code\u003e and \u003ccode\u003ethreading\u003c/code\u003e Python libraries enable the appearance of concurrency. However, your CPUs are not doing multiple things at the exact same time. It just seems like they are.\u003c/p\u003e\n\n\n\n\u003cp\u003eImagine you are hosting a multi-course dinner for some guests. Some of the dishes take time to cook, for example, the pie that needs to be baked in the oven or the soup simmering on the stove. While we are waiting for those to cook, we do not just stand around and wait. We will do something else in the meantime. This is similar to concurrency in Python. Sometimes your Python process is waiting for something to get done. For example, some input/output (I/O) processes are being handled by the operating system, and in this time the Python process is just waiting. We can then use async to let another Python process run while it waits.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1600\" height=\"896\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-23.png\" alt=\"Python multithreading vs asyncio\"/\u003e\u003c/figure\u003e\n\n\n\n\u003ch3 id=\"the-difference-is-who-is-in-charge\"\u003eThe difference is who is in charge\u003c/h3\u003e\n\n\n\n\u003cp\u003eIf both \u003ccode\u003easyncio\u003c/code\u003e and \u003ccode\u003ethreading\u003c/code\u003e appear concurrent, what is the difference between them? Well, the main difference is a matter of who is in charge of which process is running and when. For \u003ccode\u003easync/await\u003c/code\u003e, the approach is sometimes called cooperative concurrency. A coroutine or future gives up its control to another coroutine or future to let others have a go. On the other hand, in \u003ccode\u003ethreading\u003c/code\u003e, the operating system’s manager will be in control of which process is running.\u003c/p\u003e\n\n\n\n\u003cp\u003eCooperative concurrency is like a meeting with a microphone being passed around for people to speak. Whoever has the microphone can talk, and when they are done or have nothing else to say, they will pass the microphone to the next person. In contrast, multithreading is a meeting where there is a chairperson who will determine who has the floor at any given time. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"writing-concurrent-code-in-python\"\u003eWriting concurrent code in Python\u003c/h2\u003e\n\n\n\n\u003cp\u003eLet’s have a look at how concurrency works in Python by writing some example code. We will create a fast food restaurant simulation using both \u003ccode\u003easyncio\u003c/code\u003e and \u003ccode\u003ethreading\u003c/code\u003e.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"how-async-await-works-in-python\"\u003eHow \u003ccode\u003easync/await\u003c/code\u003e works in Python\u003c/h3\u003e\n\n\n\n\u003cp\u003eThe \u003ccode\u003easyncio\u003c/code\u003e package was introduced in Python 3.4, while the \u003ccode\u003easync\u003c/code\u003e and \u003ccode\u003eawait\u003c/code\u003e keywords were introduced in Python 3.5. One of the main things that make \u003ccode\u003easync/await\u003c/code\u003e possible is the use of coroutines. Coroutines in Python are actually generators repurposed to be able to pause and pass back to the main function.\u003c/p\u003e\n\n\n\n\u003cp\u003eNow, imagine a burger restaurant where only one staff member is working. The orders are prepared according to a first-in-first-out queue, and no async operations can be performed:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport time\n\n\ndef make_burger(order_num):\n    print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n    time.sleep(5) # time for making the burger\n    print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\n\ndef main():\n    for i in range(3):\n        make_burger(i)\n\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n    s = time.perf_counter()\n    main()\n    elapsed = time.perf_counter() - s\n    print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\n\u003c/pre\u003e\n\n\n\n\u003cp\u003eThis will take a while to finish:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"raw\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003ePreparing burger #0...\n\nBurger made #0\n\nPreparing burger #1...\n\nBurger made #1\n\nPreparing burger #2...\n\nBurger made #2\n\nOrders completed in 15.01 seconds.\u003c/pre\u003e\n\n\n\n\u003cp\u003eNow, imagine the restaurant brings in more staff, so that it can perform work concurrently:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport asyncio\n\nimport time\n\nasync def make_burger(order_num):\n\n    print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n    await asyncio.sleep(5) # time for making the burger\n\n    print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\nasync def main():\n\n    order_queue = []\n\n    for i in range(3):\n\n        order_queue.append(make_burger(i))\n\n    await asyncio.gather(*(order_queue))\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n    s = time.perf_counter()\n\n    asyncio.run(main())\n\n    elapsed = time.perf_counter() - s\n\n    print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eWe see the difference between the two:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"raw\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003ePreparing burger #0...\n\nPreparing burger #1...\n\nPreparing burger #2...\n\nBurger made #0\n\nBurger made #1\n\nBurger made #2\n\nOrders completed in 5.00 seconds.\u003c/pre\u003e\n\n\n\n\u003cp\u003eUsing the functions provided by \u003ccode\u003easyncio\u003c/code\u003e, like \u003ccode\u003erun\u003c/code\u003e and \u003ccode\u003egather\u003c/code\u003e, and the keywords \u003ccode\u003easync\u003c/code\u003e and \u003ccode\u003eawait\u003c/code\u003e, we have created coroutines that can make burgers concurrently.\u003c/p\u003e\n\n\n\n\u003cp\u003eNow, let’s take a step further and create a more complicated simulation. Imagine we only have two workers, and we can only make two burgers at a time.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport asyncio\n\nimport time\n\norder_queue = asyncio.Queue()\n\ndef take_order():\n\n  for i in range(3):\n\n      order_queue.put_nowait(make_burger(i))\n\nasync def make_burger(order_num):\n\n  print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n  await asyncio.sleep(5)  # time for making the burger\n\n  print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\nclass Staff:\n\n  def __init__(self, name):\n\n      self.name = name\n\n  async def working(self):\n\n      while order_queue.qsize() \u0026gt; 0:\n\n          print(f\u0026#34;{self.name} is working...\u0026#34;)\n\n          task = await order_queue.get()\n\n          await task\n\n          print(f\u0026#34;{self.name} finished a task...\u0026#34;)\n\nasync def main():\n\n  staff1 = Staff(name=\u0026#34;John\u0026#34;)\n\n  staff2 = Staff(name=\u0026#34;Jane\u0026#34;)\n\n  take_order()\n\n  await asyncio.gather(staff1.working(), staff2.working())\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n  s = time.perf_counter()\n\n  asyncio.run(main())\n\n  elapsed = time.perf_counter() - s\n\n  print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eHere we will use a queue to hold the tasks, and the staff will pick them up.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"raw\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eJohn is working...\n\nPreparing burger #0...\n\nJane is working...\n\nPreparing burger #1...\n\nBurger made #0\n\nJohn finished a task...\n\nJohn is working...\n\nPreparing burger #2...\n\nBurger made #1\n\nJane finished a task...\n\nBurger made #2\n\nJohn finished a task...\n\nOrders completed in 10.00 seconds.\u003c/pre\u003e\n\n\n\n\u003cp\u003eIn this example, we use \u003ccode\u003easyncio.Queue\u003c/code\u003e to store the tasks, but it will be more useful if we have multiple types of tasks, as shown in the following example.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport asyncio\n\nimport time\n\ntask_queue = asyncio.Queue()\n\norder_num = 0\n\nasync def take_order():\n\n   global order_num\n\n   order_num += 1\n\n   print(f\u0026#34;Order burger and fries for order #{order_num:04d}:\u0026#34;)\n\n   burger_num = input(\u0026#34;Number of burgers:\u0026#34;)\n\n   for i in range(int(burger_num)):\n\n       await task_queue.put(make_burger(f\u0026#34;{order_num:04d}-burger{i:02d}\u0026#34;))\n\n   fries_num = input(\u0026#34;Number of fries:\u0026#34;)\n\n   for i in range(int(fries_num)):\n\n       await task_queue.put(make_fries(f\u0026#34;{order_num:04d}-fries{i:02d}\u0026#34;))\n\n   print(f\u0026#34;Order #{order_num:04d} queued.\u0026#34;)\n\n   await task_queue.put(take_order())\n\nasync def make_burger(order_num):\n\n   print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n   await asyncio.sleep(5)  # time for making the burger\n\n   print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\nasync def make_fries(order_num):\n\n   print(f\u0026#34;Preparing fries #{order_num}...\u0026#34;)\n\n   await asyncio.sleep(2)  # time for making fries\n\n   print(f\u0026#34;Fries made #{order_num}\u0026#34;)\n\nclass Staff:\n\n   def __init__(self, name):\n\n       self.name = name\n\n   async def working(self):\n\n       while True:\n\n           if task_queue.qsize() \u0026gt; 0:\n\n               print(f\u0026#34;{self.name} is working...\u0026#34;)\n\n               task = await task_queue.get()\n\n               await task\n\n               print(f\u0026#34;{self.name} finish task...\u0026#34;)\n\n           else:\n\n               await asyncio.sleep(1) #rest\n\nasync def main():\n\n   task_queue.put_nowait(take_order())\n\n   staff1 = Staff(name=\u0026#34;John\u0026#34;)\n\n   staff2 = Staff(name=\u0026#34;Jane\u0026#34;)\n\n   await asyncio.gather(staff1.working(), staff2.working())\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n   s = time.perf_counter()\n\n   asyncio.run(main())\n\n   elapsed = time.perf_counter() - s\n\n   print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eIn this example, there are multiple tasks, including making fries, which takes less time, and taking orders, which involves getting input from the user. \u003c/p\u003e\n\n\n\n\u003cp\u003eNotice that the program stops waiting for the user’s input, and even the other staff who are not taking the order stop working in the background. This is because the \u003ccode\u003einput\u003c/code\u003e function is not async and therefore is not awaited. Remember, control in async code is only released when it is awaited. To fix that, we can replace:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003einput(\u0026#34;Number of burgers:\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eWith \u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eawait asyncio.to_thread(input, \u0026#34;Number of burgers:\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eAnd we do the same for fries – see the code below. Note that now the program runs in an infinite loop. If we need to stop it, we can deliberately crash the program with an invalid input.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport asyncio\n\nimport time\n\ntask_queue = asyncio.Queue()\n\norder_num = 0\n\nasync def take_order():\n\n   global order_num\n\n   order_num += 1\n\n   print(f\u0026#34;Order burger and fries for order #{order_num:04d}:\u0026#34;)\n\n   burger_num = await asyncio.to_thread(input, \u0026#34;Number of burgers:\u0026#34;)\n\n   for i in range(int(burger_num)):\n\n       await task_queue.put(make_burger(f\u0026#34;{order_num:04d}-burger{i:02d}\u0026#34;))\n\n   fries_num = await asyncio.to_thread(input, \u0026#34;Number of fries:\u0026#34;)\n\n   for i in range(int(fries_num)):\n\n       await task_queue.put(make_fries(f\u0026#34;{order_num:04d}-fries{i:02d}\u0026#34;))\n\n   print(f\u0026#34;Order #{order_num:04d} queued.\u0026#34;)\n\n   await task_queue.put(take_order())\n\nasync def make_burger(order_num):\n\n   print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n   await asyncio.sleep(5)  # time for making the burger\n\n   print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\nasync def make_fries(order_num):\n\n   print(f\u0026#34;Preparing fries #{order_num}...\u0026#34;)\n\n   await asyncio.sleep(2)  # time for making fries\n\n   print(f\u0026#34;Fries made #{order_num}\u0026#34;)\n\nclass Staff:\n\n   def __init__(self, name):\n\n       self.name = name\n\n   async def working(self):\n\n       while True:\n\n           if task_queue.qsize() \u0026gt; 0:\n\n               print(f\u0026#34;{self.name} is working...\u0026#34;)\n\n               task = await task_queue.get()\n\n               await task\n\n               print(f\u0026#34;{self.name} finish task...\u0026#34;)\n\n           else:\n\n               await asyncio.sleep(1) #rest\n\nasync def main():\n\n   task_queue.put_nowait(take_order())\n\n   staff1 = Staff(name=\u0026#34;John\u0026#34;)\n\n   staff2 = Staff(name=\u0026#34;Jane\u0026#34;)\n\n   await asyncio.gather(staff1.working(), staff2.working())\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n   s = time.perf_counter()\n\n   asyncio.run(main())\n\n   elapsed = time.perf_counter() - s\n\n   print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eBy using \u003ccode\u003easyncio.to_thread\u003c/code\u003e, we have put the \u003ccode\u003einput\u003c/code\u003e function into a separate thread (\u003ca href=\"https://docs.python.org/3/library/asyncio-task.html#running-in-threads\" target=\"_blank\" rel=\"noopener\"\u003esee this reference\u003c/a\u003e). Do note, however, that this trick only unblocks I/O-bounded tasks if the Python GIL is present.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you run the code above, you may also see that the standard I/O in the terminal is scrambled. The user I/O and the record of what is happening should be separate. We can put the record into a log to inspect later. \u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport asyncio\n\nimport logging\n\nimport time\n\nlogger = logging.getLogger(__name__)\n\nlogging.basicConfig(filename=\u0026#39;pyburger.log\u0026#39;, level=logging.INFO)\n\ntask_queue = asyncio.Queue()\n\norder_num = 0\n\nclosing = False\n\nasync def take_order():\n\n   global order_num, closing\n\n   try:\n\n       order_num += 1\n\n       logger.info(f\u0026#34;Taking Order #{order_num:04d}...\u0026#34;)\n\n       print(f\u0026#34;Order burger and fries for order #{order_num:04d}:\u0026#34;)\n\n       burger_num = await asyncio.to_thread(input, \u0026#34;Number of burgers:\u0026#34;)\n\n       for i in range(int(burger_num)):\n\n           await task_queue.put(make_burger(f\u0026#34;{order_num:04d}-burger{i:02d}\u0026#34;))\n\n       fries_num = await asyncio.to_thread(input, \u0026#34;Number of fries:\u0026#34;)\n\n       for i in range(int(fries_num)):\n\n           await task_queue.put(make_fries(f\u0026#34;{order_num:04d}-fries{i:02d}\u0026#34;))\n\n       logger.info(f\u0026#34;Order #{order_num:04d} queued.\u0026#34;)\n\n       print(f\u0026#34;Order #{order_num:04d} queued, please wait.\u0026#34;)\n\n       await task_queue.put(take_order())\n\n   except ValueError:\n\n       print(\u0026#34;Goodbye!\u0026#34;)\n\n       logger.info(\u0026#34;Closing down... stop taking orders and finish all tasks.\u0026#34;)\n\n       closing = True\n\nasync def make_burger(order_num):\n\n   logger.info(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n   await asyncio.sleep(5)  # time for making the burger\n\n   logger.info(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\nasync def make_fries(order_num):\n\n   logger.info(f\u0026#34;Preparing fries #{order_num}...\u0026#34;)\n\n   await asyncio.sleep(2)  # time for making fries\n\n   logger.info(f\u0026#34;Fries made #{order_num}\u0026#34;)\n\nclass Staff:\n\n   def __init__(self, name):\n\n       self.name = name\n\n   async def working(self):\n\n       while True:\n\n           if task_queue.qsize() \u0026gt; 0:\n\n               logger.info(f\u0026#34;{self.name} is working...\u0026#34;)\n\n               task = await task_queue.get()\n\n               await task\n\n               task_queue.task_done()\n\n               logger.info(f\u0026#34;{self.name} finish task.\u0026#34;)\n\n           elif closing:\n\n               return\n\n           else:\n\n               await asyncio.sleep(1) #rest\n\nasync def main():\n\n   global task_queue\n\n   task_queue.put_nowait(take_order())\n\n   staff1 = Staff(name=\u0026#34;John\u0026#34;)\n\n   staff2 = Staff(name=\u0026#34;Jane\u0026#34;)\n\n   print(\u0026#34;Welcome to Pyburger!\u0026#34;)\n\n   logger.info(\u0026#34;Ready for business!\u0026#34;)\n\n   await asyncio.gather(staff1.working(), staff2.working())\n\n   logger.info(\u0026#34;All tasks finished. Closing now.\u0026#34;)\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n   s = time.perf_counter()\n\n   asyncio.run(main())\n\n   elapsed = time.perf_counter() - s\n\n   logger.info(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eIn this final code block, we have logged the simulation information in \u003ccode\u003epyburger.log\u003c/code\u003e and reserved the terminal for messages for customers. We also catch invalid input during the ordering process and switch a \u003ccode\u003eclosing\u003c/code\u003e flag to \u003ccode\u003eTrue\u003c/code\u003e if the input is invalid, assuming the user wants to quit. Once the \u003ccode\u003eclosing\u003c/code\u003e flag is set to \u003ccode\u003eTrue\u003c/code\u003e, the worker will \u003ccode\u003ereturn\u003c/code\u003e, ending the coroutine’s infinite \u003ccode\u003ewhile\u003c/code\u003e loop.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"how-does-threading-work-in-python\"\u003eHow does \u003ccode\u003ethreading\u003c/code\u003e work in Python?\u003c/h3\u003e\n\n\n\n\u003cp\u003eIn the example above, we put an I/O-bound task into another thread. You may wonder if we can put all tasks into separate threads and let them run concurrently. Let’s try using \u003ccode\u003ethreading\u003c/code\u003e instead of \u003ccode\u003easyncio\u003c/code\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eConsider the code we have as shown below, where we create burgers concurrently with no limitation put in place:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport asyncio\n\nimport time\n\nasync def make_burger(order_num):\n\n    print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n    await asyncio.sleep(5) # time for making the burger\n\n    print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\nasync def main():\n\n    order_queue = []\n\n    for i in range(3):\n\n        order_queue.append(make_burger(i))\n\n    await asyncio.gather(*(order_queue))\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n    s = time.perf_counter()\n\n    asyncio.run(main())\n\n    elapsed = time.perf_counter() - s\n\n    print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\n\n```\n\nInstead of creating async coroutines to make the burgers, we can just send functions down different threads like this:\n\n```\n\nimport threading\n\nimport time\n\ndef make_burger(order_num):\n\n   print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n   time.sleep(5) # time for making the burger\n\n   print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\ndef main():\n\n   order_queue = []\n\n   for i in range(3):\n\n       task = threading.Thread(target=make_burger, args=(i,))\n\n       order_queue.append(task)\n\n       task.start()\n\n   for task in order_queue:\n\n       task.join()\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n   s = time.perf_counter()\n\n   main()\n\n   elapsed = time.perf_counter() - s\n\n   print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eIn the first \u003ccode\u003efor\u003c/code\u003e loop in \u003ccode\u003emain\u003c/code\u003e, tasks are created in different threads and get a kickstart. The second \u003ccode\u003efor\u003c/code\u003e loop makes sure all the burgers are made before the program moves on (that is, before it returns to \u003ccode\u003emain\u003c/code\u003e).\u003c/p\u003e\n\n\n\n\u003cp\u003eIt is more complicated when we have only two staff members. Each member of the staff is represented with a thread, and they will take tasks from a normal list where they are all stored.\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003eimport threading\n\nimport time\n\norder_queue = []\n\ndef take_order():\n\n   for i in range(3):\n\n       order_queue.append(make_burger(i))\n\ndef make_burger(order_num):\n\n   def making_burger():\n\n       print(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n       time.sleep(5)  # time for making the burger\n\n       print(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\n   return making_burger\n\ndef working():\n\n     while len(order_queue) \u0026gt; 0:\n\n         print(f\u0026#34;{threading.current_thread().name} is working...\u0026#34;)\n\n         task = order_queue.pop(0)\n\n         task()\n\n         print(f\u0026#34;{threading.current_thread().name} finish task...\u0026#34;)\n\ndef main():\n\n   take_order()\n\n   staff1 = threading.Thread(target=working, name=\u0026#34;John\u0026#34;)\n\n   staff1.start()\n\n   staff2 = threading.Thread(target=working, name=\u0026#34;Jane\u0026#34;)\n\n   staff2.start()\n\n   staff1.join()\n\n   staff2.join()\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n s = time.perf_counter()\n\n main()\n\n elapsed = time.perf_counter() - s\n\n print(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eWhen you run the code above, an error may occur in one of the threads, saying that it is trying to get a task from an empty list. You may wonder why this is the case, since we have a condition in the \u003ccode\u003ewhile\u003c/code\u003e loop that causes it to continue only if the \u003ccode\u003etask_queue\u003c/code\u003e is not empty. Nevertheless, we still get an error because we have encountered race conditions.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"race-conditions\"\u003eRace conditions\u003c/h3\u003e\n\n\n\n\u003cp\u003eRace conditions can occur when multiple threads attempt to access the same resource or data at the same time and cause problems in the system. The timing and order of when the resource is accessed are important to the program logic, and unpredictable timing or the interleaving of multiple threads accessing and modifying shared data can cause errors.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo solve the race condition in our program, we will deploy a lock to the \u003ccode\u003etask_queue\u003c/code\u003e:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003equeue_lock = threading.Lock()\u003c/pre\u003e\n\n\n\n\u003cp\u003eFor working, we need to make sure we have access rights to the queue when checking its length and getting tasks from it. While we have the rights, other threads cannot access the queue:\u003c/p\u003e\n\n\n\n\u003cpre data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"\u003edef working():\n\n   while True:\n\n       with queue_lock:\n\n           if len(order_queue) == 0:\n\n               return\n\n           else:\n\n               task = order_queue.pop(0)\n\n       print(f\u0026#34;{threading.current_thread().name} is working...\u0026#34;)\n\n       task()\n\n       print(f\u0026#34;{threading.current_thread().name} finish task...\u0026#34;)\n\n```\n\nBased on what we have learned so far, we can complete our final code with threading like this:\n\n```\n\nimport logging\n\nimport threading\n\nimport time\n\nlogger = logging.getLogger(__name__)\n\nlogging.basicConfig(filename=\u0026#34;pyburger_threads.log\u0026#34;, level=logging.INFO)\n\nqueue_lock = threading.Lock()\n\ntask_queue = []\n\norder_num = 0\n\nclosing = False\n\ndef take_order():\n\n   global order_num, closing\n\n   try:\n\n       order_num += 1\n\n       logger.info(f\u0026#34;Taking Order #{order_num:04d}...\u0026#34;)\n\n       print(f\u0026#34;Order burger and fries for order #{order_num:04d}:\u0026#34;)\n\n       burger_num = input(\u0026#34;Number of burgers:\u0026#34;)\n\n       for i in range(int(burger_num)):\n\n           with queue_lock:\n\n               task_queue.append(make_burger(f\u0026#34;{order_num:04d}-burger{i:02d}\u0026#34;))\n\n       fries_num = input(\u0026#34;Number of fries:\u0026#34;)\n\n       for i in range(int(fries_num)):\n\n           with queue_lock:\n\n               task_queue.append(make_fries(f\u0026#34;{order_num:04d}-fries{i:02d}\u0026#34;))\n\n       logger.info(f\u0026#34;Order #{order_num:04d} queued.\u0026#34;)\n\n       print(f\u0026#34;Order #{order_num:04d} queued, please wait.\u0026#34;)\n\n       with queue_lock:\n\n           task_queue.append(take_order)\n\n   except ValueError:\n\n       print(\u0026#34;Goodbye!\u0026#34;)\n\n       logger.info(\u0026#34;Closing down... stop taking orders and finish all tasks.\u0026#34;)\n\n       closing = True\n\ndef make_burger(order_num):\n\n   def making_burger():\n\n       logger.info(f\u0026#34;Preparing burger #{order_num}...\u0026#34;)\n\n       time.sleep(5)  # time for making the burger\n\n       logger.info(f\u0026#34;Burger made #{order_num}\u0026#34;)\n\n   return making_burger\n\ndef make_fries(order_num):\n\n   def making_fries():\n\n       logger.info(f\u0026#34;Preparing fried #{order_num}...\u0026#34;)\n\n       time.sleep(2)  # time for making fries\n\n       logger.info(f\u0026#34;Fries made #{order_num}\u0026#34;)\n\n   return making_fries\n\ndef working():\n\n   while True:\n\n       with queue_lock:\n\n           if len(task_queue) == 0:\n\n               if closing:\n\n                   return\n\n               else:\n\n                   task = None\n\n           else:\n\n               task = task_queue.pop(0)\n\n       if task:\n\n           logger.info(f\u0026#34;{threading.current_thread().name} is working...\u0026#34;)\n\n           task()\n\n           logger.info(f\u0026#34;{threading.current_thread().name} finish task...\u0026#34;)\n\n       else:\n\n           time.sleep(1)  # rest\n\ndef main():\n\n   print(\u0026#34;Welcome to Pyburger!\u0026#34;)\n\n   logger.info(\u0026#34;Ready for business!\u0026#34;)\n\n   task_queue.append(take_order)\n\n   staff1 = threading.Thread(target=working, name=\u0026#34;John\u0026#34;)\n\n   staff1.start()\n\n   staff2 = threading.Thread(target=working, name=\u0026#34;Jane\u0026#34;)\n\n   staff2.start()\n\n   staff1.join()\n\n   staff2.join()\n\n   logger.info(\u0026#34;All tasks finished. Closing now.\u0026#34;)\n\nif __name__ == \u0026#34;__main__\u0026#34;:\n\n   s = time.perf_counter()\n\n   main()\n\n   elapsed = time.perf_counter() - s\n\n   logger.info(f\u0026#34;Orders completed in {elapsed:0.2f} seconds.\u0026#34;)\u003c/pre\u003e\n\n\n\n\u003cp\u003eIf you compare the two code snippets using \u003ccode\u003easyncio\u003c/code\u003e and \u003ccode\u003ethreading\u003c/code\u003e, they should have similar results. You may wonder which one is better and why you should choose one over the other.\u003c/p\u003e\n\n\n\n\u003cp\u003ePractically, writing \u003ccode\u003easyncio\u003c/code\u003e code is easier than multithreading because we don’t have to take care of potential race conditions and deadlocks by ourselves. Controls are passed around coroutines by default, so no locks are needed. However, Python threads do have the potential to run in parallel, just not most of the time with the GIL in place. We can revisit this when we talk about nogil (thread-free) Python in the next blog post.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"benefiting-from-concurrency\"\u003eBenefiting from concurrency\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhy do we want to use concurrency in programming? There’s one main reason: speed. Like we have illustrated above, tasks can be completed faster if we can cut down the waiting time. There are different types of waiting in computing, and for each one, we tend to use different methods to save time.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"i-o-bound-tasks\"\u003eI/O-bound tasks\u003c/h3\u003e\n\n\n\n\u003cp\u003eA task or program is considered input/output (I/O) bound when its execution speed is primarily limited by the speed of I/O operations, such as reading from a file or network, or waiting for user input. I/O operations are generally slower than other CPU operations, and therefore, tasks that involve lots of them can take significantly more time. Typical examples of these tasks include reading data from a database, handling web requests, or working with large files.\u003c/p\u003e\n\n\n\n\u003cp\u003eUsing \u003ccode\u003easync/await\u003c/code\u003e concurrency can help optimize the waiting time during I/O-bound tasks by unblocking the processing sequence and letting other tasks be taken care of while waiting.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ccode\u003eAsync/await\u003c/code\u003e concurrency is beneficial in many Python applications, such as web applications that involve a lot of communication with databases and handling web requests. GUIs (graphical user interfaces) can also benefit from \u003ccode\u003easync/await\u003c/code\u003e concurrency by allowing background tasks to be performed while the user is interacting with the application.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"cpu-bound-tasks\"\u003eCPU-bound tasks\u003c/h3\u003e\n\n\n\n\u003cp\u003eA task or program is considered CPU-bound when its execution speed is primarily limited by the speed of the CPU. Typical examples include image or video processing, like resizing or editing, and complex mathematical calculations, such as matrix multiplication or training machine learning models.\u003c/p\u003e\n\n\n\n\u003cp\u003eContrary to I/O-bound tasks, CPU-bound tasks can rarely be optimised by using \u003ccode\u003easync/await\u003c/code\u003e concurrency, as the CPU is already busy working on the tasks. If you have more than one CPU in your machine, or if you can offload some of these tasks to one or more GPUs, then CPU-bound tasks can be finished faster by creating more threads and performing multiprocessing. Multiprocessing can optimise how these CPUs and GPUs are used, which is also why many machine learning and AI models these days are trained on multiple GPUs.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis, however, is tough to perform with pure Python code, as Python itself is designed to provide abstract layers so users do not have to control the lower-level computation processes. Moreover, Python’s GIL limits the sharing of Python resources across multiple threads on your computer. Recently, Python 3.13 made it possible to remove the GIL, allowing for true multithreading. We will discuss the GIL, and the ability to go without it, in the next blog post.\u003c/p\u003e\n\n\n\n\u003cp\u003eSometimes, none of the methods we mentioned above are able to speed up CPU-bound tasks sufficiently. When that is the case, the CPU-bound tasks may need to be broken into smaller ones so that they can be performed simultaneously over multiple threads, multiple processors, or even multiple machines. This is parallel processing, and you may have to rewrite your code completely to implement it. In Python, the \u003ccode\u003emultiprocessing\u003c/code\u003e package offers both local and remote concurrency, which can be used to work around the limitation of the GIL. We will also look at some examples of that in the next blog post.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"debugging-concurrent-code-in-py-charm\"\u003eDebugging concurrent code in PyCharm\u003c/h2\u003e\n\n\n\n\u003cp\u003eDebugging async or concurrent code can be hard, as the program is not executed in sequence, meaning it is hard to see where and when the code is being executed. Many developers use \u003ccode\u003eprint\u003c/code\u003e to help trace the flow of the code, but this approach is not recommended, as it is very clumsy and using it to investigate a complex program, like a concurrent one, isn’t easy. Plus, it is messy to tidy up after.\u003c/p\u003e\n\n\n\n\u003cp\u003eMany IDEs provide debuggers, which are great for inspecting variables and the flow of the program. Debuggers also provide a clear stack trace across multiple threads. Let’s see how we can track the \u003ccode\u003etask_queue\u003c/code\u003e of our example restaurant simulation in \u003ca href=\"https://www.jetbrains.com/pycharm/\" data-type=\"link\" data-id=\"https://www.jetbrains.com/pycharm/data-science/\" target=\"_blank\" rel=\"noopener\"\u003ePyCharm\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eFirst, we will put down some breakpoints in our code. You can do that by clicking the line number of the line where you want the debugger to pause. The line number will turn into a red dot, indicating that a breakpoint is set there. We will put breakpoints at lines 23, 27, and 65, where the \u003ccode\u003etask_queue\u003c/code\u003e is changed in different threads.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1600\" height=\"720\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-8.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"554\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-9.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThen we can run the program in debug mode by clicking the little bug icon in the top right.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"860\" height=\"258\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-10.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eAfter clicking on the icon, the \u003cem\u003eDebug\u003c/em\u003e window will open up. The program will run until it hits the first breakpoint highlighted in the code.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"1002\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-11.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eHere we see the \u003ccode\u003eJohn\u003c/code\u003e thread is trying to pick up the task, and line 65 is highlighted. At this point, the highlighted line has not been executed yet. This is useful when we want to inspect the variables before entering the breakpoint.\u003c/p\u003e\n\n\n\n\u003cp\u003eLet’s inspect what’s in the \u003ccode\u003etask_queue\u003c/code\u003e. You can do so simply by starting to type in the \u003cem\u003eDebug\u003c/em\u003e window, as shown below.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"468\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-12.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eSelect or type in “task_queue”, and then press \u003cem\u003eEnter\u003c/em\u003e. You will see that the \u003ccode\u003etake_order\u003c/code\u003e task is in the queue.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"527\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-13.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eNow, let’s execute the breakpoint by clicking the \u003cem\u003eStep in\u003c/em\u003e button, as shown below.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1274\" height=\"488\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-14.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eAfter pressing that and inspecting the \u003cem\u003eSpecial Variables\u003c/em\u003e window that pops up, we see that the task variable is now \u003ccode\u003etake_order\u003c/code\u003e in the \u003ccode\u003eJohn\u003c/code\u003e thread.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"522\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-15.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWhen querying the \u003ccode\u003etask_queue\u003c/code\u003e again, we see that now the list is empty.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"451\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-16.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eNow let’s click the \u003cem\u003eResume Program\u003c/em\u003e button and let the program run.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"994\" height=\"610\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-17.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWhen the program hits the user input part, PyCharm will bring us to the \u003cem\u003eConsole \u003c/em\u003ewindow so we can provide the input. Let’s say we want two burgers. Type “2” and press \u003cem\u003eEnter\u003c/em\u003e.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1288\" height=\"616\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-18.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eNow we hit the second breakpoint. If we click on \u003cem\u003eThreads \u0026amp; Variables\u003c/em\u003e to go back to that window, we’ll see that \u003ccode\u003eburger_num\u003c/code\u003e is two, as we entered.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"1002\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-19.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eNow let’s step into the breakpoint and inspect the \u003ccode\u003etask_queue\u003c/code\u003e, just like we did before. We see that one \u003ccode\u003emake_burger\u003c/code\u003e task has been added.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"405\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-20.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWe let the program run again, and if we step into the breakpoint when it stops, we see that \u003ccode\u003eJane\u003c/code\u003e is picking up the task.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"1600\" height=\"1002\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-21.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eYou can inspect the rest of the code yourself. When you are done, simply press the red \u003cem\u003eStop \u003c/em\u003ebutton at the top of the window.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" loading=\"lazy\" width=\"848\" height=\"244\" src=\"https://blog.jetbrains.com/wp-content/uploads/2025/06/image-22.png\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWith the debugger in PyCharm, you can follow the execution of your program across different threads and inspect different variables very easily.\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\n\n\n\u003cp\u003eNow we have learned the basics of concurrency in Python, and I hope you will be able to master it with practice. In the next blog post, we will have a look at the Python GIL, the role it plays, and what changes when it is absent.\u003c/p\u003e\n\n\n\n\u003cp\u003ePyCharm provides powerful tools for working with concurrent Python code. As demonstrated in this blog post, the debugger allows the step-by-step inspection of both async and threaded code, helping you track the execution flow, monitor shared resources, and detect issues. With intuitive breakpoints, real-time variable views, seamless console integration for user input, and robust logging support, PyCharm makes it easier to write, test, and debug applications with confidence and clarity.\u003c/p\u003e\n\n\n    \n\n\n\n\n                    \n                                                                \n                                                                                                                                \u003cdiv\u003e\n                                \u003cdiv\u003e\n                                                                            \u003ch4\u003eSubscribe to PyCharm Blog updates\u003c/h4\u003e\n                                                                                                            \n                                \u003c/div\u003e\n                                \n                                \u003cp\u003e\u003cimg src=\"https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg\" alt=\"image description\"/\u003e\n                                                                    \u003c/p\u003e\n                            \u003c/div\u003e\n                                                            \u003c/div\u003e\n                \u003ca href=\"#\"\u003e\u003c/a\u003e\n                \n                \n            \u003c/section\u003e\n                    \u003cdiv\u003e\n                \u003cp\u003e\n                    \u003ch2\u003eDiscover more\u003c/h2\u003e\n                \u003c/p\u003e\n                \n            \u003c/div\u003e\n                \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "32 min read",
  "publishedTime": null,
  "modifiedTime": null
}
