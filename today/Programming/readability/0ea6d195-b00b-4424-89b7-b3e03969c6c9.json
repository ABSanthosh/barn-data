{
  "id": "0ea6d195-b00b-4424-89b7-b3e03969c6c9",
  "title": "Somebody is in the room — did we just interview ChatGPT?",
  "link": "https://engineering.prezi.com/somebody-is-in-the-room-did-we-just-interview-chatgpt-ab4e8dd5db28?source=rss----911e72786e31---4",
  "description": "",
  "author": "Máté Börcsök",
  "published": "Wed, 09 Jul 2025 12:24:04 GMT",
  "source": "https://engineering.prezi.com/feed",
  "categories": [
    "hiring",
    "interview",
    "ai",
    "software-engineering",
    "prezi"
  ],
  "byline": "Máté Börcsök",
  "length": 5092,
  "excerpt": "He did well! In fact, a little too well. Whatever we asked, he could answer in detail. Too many details. But there were clues that someone was actively listening in the room. One example: he…",
  "siteName": "Prezi Engineering",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*U0lNGgJfm0Qo1ZfYDS36KA.png",
  "text": "My team just had an interview this week. It was weird.He did well! In fact, a little too well. Whatever we asked, he could answer in detail. Too many details. But there were clues that someone was actively listening in the room.One example: he introduced a system they built. If certain conditions are met, the users of the platform can claim rewards. He said, they obviously chose the microservice architecture with a DDD approach. One service for authentication, one for users, one for rewards, etc.We had clarification questions whether having that many microservices was a good choice, did every service have its own database, how did they ensure transactions?The answer felt smart and pragmatic. Of course the microservices have separate databases! And to make sure that transactions work, they used the SAGA Pattern.Well, none of us heard about the SAGA pattern. I admitted that I wasn’t familiar with it, but instead of explaining the core idea or walking us through it, he just moved on. It felt like a missed opportunity, and overall, the answer was unexpected.If you ask me, I’d say that we didn’t need transactions across the services, or we only needed transaction when saving the reward, maybe we set up a queue, and process these rewards that way, ensuring consistency at that point.Zoom image will be displayedApproximate recreation of the candidate’s Zoom setupSo I replayed this part of the interview with ChatGPT, and guess what? It also suggested the SAGA pattern.This made me do the same exercise for other questions. Sometimes I got the same hallucination, the same words from ChatGPT that the candidate had used. I couldn’t understand on the spot how they were relevant in that context.The candidate seemed to have a professional setup, yet we still heard an echo. He was on speaker.His eye movement was weird, some of his answers felt like he was reading a screen.Sometimes his answers were very generic, but whatever we asked, he could go into the tiniest details. Oftentimes contradicting himself with previous answers.After the interview, this was the first message on Slack:is it me or i think this guy is using AI to answer our questions?In general, I don’t expect anything disingenuous from people. We didn’t call him out during the call.I wish I could share the Slack thread, everyone from the team could add a new clue, raising the suspicion more and more.We are in new territory, and this interview left us wondering: how do we evaluate authenticity in the age of AI?Personally, I don’t mind that we didn’t call out his suspected AI usage during the interview. And in fact, it doesn’t matter. The answers were about as great as unedited AI output without human oversight. The kind that sounds smart at first, until you realize it’s just a mashup of architecture buzzwords with no real insight.Detecting AI Answers: Practical Tips for InterviewersMy article sparked some discussions about the topic internally. I reached out to our Senior Tech Recruiter, Monika Fourie, to share some experience.I had some people using AI during calls and it was done in an excellent way, so I believe sometimes they add their experience first and on the speaker they wait for answers. With the smart use of AI, its difficult to detect that they are using it.I think the most important thing is to look at all of these signs as one — like diagnosing a disease — one symptom alone is sometimes not enough.Signs to look forSlight delays before respondingTheir eyes going in the same direction before the response, naturally we have directions where we look towards when we’re thinking creatively, solving problems and remembering, but consistently looking in the same direction on the screen usually hints that their answers appear thereOverly polished language, sophisticated words or oddly phrased responsesInability to go “off script” or rephrase ideasLack of deeper elaboration or personal experienceSlow, precise repetition of the question, spoken as if dictating it into a voice‑to‑text promptQuestions to askHuman answers are usually not very confident but more nuanced, asking examples “is there anything on this topic you feel less confident about” or “if you had more time what would you look into further and why”You used the term “Modular monolith” can you confirm what it does and what it means here?Another idea for interviews is having collaborative discussions whilst sharing a screen — this is more technical : ”Let’s solve this problem together — can you share your screen and walk me through your approach?”, or “Can you sketch a high-level architecture for that idea?”When you feel suspiciousCalling out AI usage is difficult if not done right. It can get us into difficult situations. I suggest to listen carefully, collect clues, use the techniques mentioned above. Only raise the issue if you’re absolutely certain, because doing so will likely end the interview right there.This was the first time our team encountered a situation like this. I’m sure it won’t be the last. As AI assistants continue to evolve, detecting their presence will only get harder.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*b3B3Jb8PtY-jm7_C5NcUng.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\" role=\"tooltip\"\u003e\u003ca href=\"https://medium.com/@bmateusz?source=post_page---byline--ab4e8dd5db28---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Máté Börcsök\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*es7QK9ezQmD9l3Mfr6OifA.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp id=\"2f94\"\u003eMy team just had an interview this week. It was weird.\u003c/p\u003e\u003cp id=\"4500\"\u003eHe did well! In fact, a little too well. Whatever we asked, he could answer in detail. Too many details. But there were clues that someone was actively listening in the room.\u003c/p\u003e\u003cp id=\"c9ab\"\u003eOne example: he introduced a system they built. If certain conditions are met, the users of the platform can claim rewards. He said, they obviously chose the microservice architecture with a DDD approach. One service for authentication, one for users, one for rewards, etc.\u003c/p\u003e\u003cp id=\"ae5d\"\u003eWe had clarification questions whether having that many microservices was a good choice, did every service have its own database, how did they ensure transactions?\u003c/p\u003e\u003cp id=\"75da\"\u003eThe answer felt smart and pragmatic. Of course the microservices have separate databases! And to make sure that transactions work, they used the SAGA Pattern.\u003c/p\u003e\u003cp id=\"3063\"\u003eWell, none of us heard about the SAGA pattern. I admitted that I wasn’t familiar with it, but instead of explaining the core idea or walking us through it, he just moved on. It felt like a missed opportunity, and overall, the answer was unexpected.\u003c/p\u003e\u003cp id=\"f162\"\u003eIf you ask me, I’d say that we didn’t need transactions across the services, or we only needed transaction when saving the reward, maybe we set up a queue, and process these rewards that way, ensuring consistency at that point.\u003c/p\u003e\u003cfigure\u003e\u003cdiv role=\"button\" tabindex=\"0\"\u003e\u003cp\u003e\u003cspan\u003eZoom image will be displayed\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003cfigcaption\u003eApproximate recreation of the candidate’s Zoom setup\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"e7c0\"\u003eSo I replayed this part of the interview with ChatGPT, and guess what? It also suggested the SAGA pattern.\u003c/p\u003e\u003cp id=\"a4de\"\u003eThis made me do the same exercise for other questions. Sometimes I got the same hallucination, the same words from ChatGPT that the candidate had used. I couldn’t understand on the spot how they were relevant in that context.\u003c/p\u003e\u003cp id=\"8a67\"\u003eThe candidate seemed to have a professional setup, yet we still heard an echo. He was on speaker.\u003c/p\u003e\u003cp id=\"548c\"\u003eHis eye movement was weird, some of his answers felt like he was reading a screen.\u003c/p\u003e\u003cp id=\"d21b\"\u003eSometimes his answers were very generic, but whatever we asked, he could go into the tiniest details. Oftentimes contradicting himself with previous answers.\u003c/p\u003e\u003cp id=\"9444\"\u003eAfter the interview, this was the first message on Slack:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"e869\"\u003eis it me or i think this guy is using AI to answer our questions?\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"8e4c\"\u003eIn general, I don’t expect anything disingenuous from people. We didn’t call him out during the call.\u003c/p\u003e\u003cp id=\"faeb\"\u003eI wish I could share the Slack thread, everyone from the team could add a new clue, raising the suspicion more and more.\u003c/p\u003e\u003cp id=\"ddbb\"\u003eWe are in new territory, and this interview left us wondering: how do we evaluate authenticity in the age of AI?\u003c/p\u003e\u003cp id=\"fabe\"\u003ePersonally, I don’t mind that we didn’t call out his suspected AI usage during the interview. And in fact, it doesn’t matter. The answers were about as great as unedited AI output without human oversight. The kind that sounds smart at first, until you realize it’s just a mashup of architecture buzzwords with no real insight.\u003c/p\u003e\u003ch2 id=\"e4ca\"\u003e\u003cstrong\u003eDetecting AI Answers: Practical Tips for Interviewers\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"de25\"\u003eMy article sparked some discussions about the topic internally. I reached out to our Senior Tech Recruiter, Monika Fourie, to share some experience.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"b557\"\u003eI had some people using AI during calls and it was done in an excellent way, so I believe sometimes they add their experience first and on the speaker they wait for answers. With the smart use of AI, its difficult to detect that they are using it.\u003c/p\u003e\u003cp id=\"27ae\"\u003eI think the most important thing is to look at all of these signs as one — like diagnosing a disease — one symptom alone is sometimes not enough.\u003c/p\u003e\u003c/blockquote\u003e\u003ch2 id=\"c998\"\u003eSigns to look for\u003c/h2\u003e\u003cul\u003e\u003cli id=\"3264\"\u003eSlight delays before responding\u003c/li\u003e\u003cli id=\"5d33\"\u003eTheir eyes going in the same direction before the response, naturally we have directions where we look towards when we’re thinking creatively, solving problems and remembering, but consistently looking in the same direction on the screen usually hints that their answers appear there\u003c/li\u003e\u003cli id=\"e0b5\"\u003eOverly polished language, sophisticated words or oddly phrased responses\u003c/li\u003e\u003cli id=\"69a9\"\u003eInability to go “off script” or rephrase ideas\u003c/li\u003e\u003cli id=\"3e63\"\u003eLack of deeper elaboration or personal experience\u003c/li\u003e\u003cli id=\"766d\"\u003eSlow, precise repetition of the question, spoken as if dictating it into a voice‑to‑text prompt\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"3246\"\u003eQuestions to ask\u003c/h2\u003e\u003cul\u003e\u003cli id=\"9c39\"\u003eHuman answers are usually not very confident but more nuanced, asking examples “is there anything on this topic you feel less confident about” or “if you had more time what would you look into further and why”\u003c/li\u003e\u003cli id=\"ab91\"\u003eYou used the term “Modular monolith” can you confirm what it does and what it means here?\u003c/li\u003e\u003cli id=\"4b28\"\u003eAnother idea for interviews is having collaborative discussions whilst sharing a screen — this is more technical : ”Let’s solve this problem together — can you share your screen and walk me through your approach?”, or “Can you sketch a high-level architecture for that idea?”\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"a6ad\"\u003eWhen you feel suspicious\u003c/h2\u003e\u003cp id=\"3fd6\"\u003eCalling out AI usage is difficult if not done right. It can get us into difficult situations. I suggest to listen carefully, collect clues, use the techniques mentioned above. Only raise the issue if you’re absolutely certain, because doing so will likely end the interview right there.\u003c/p\u003e\u003cp id=\"7856\"\u003eThis was the first time our team encountered a situation like this. I’m sure it won’t be the last. As AI assistants continue to evolve, detecting their presence will only get harder.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-07-09T12:24:04.082Z",
  "modifiedTime": null
}
