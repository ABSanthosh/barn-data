{
  "id": "e811ea89-3dc5-4d5a-982a-84731749ff25",
  "title": "How PyTorch powers AI training and inference",
  "link": "https://engineering.fb.com/2024/08/23/ml-applications/pytorch-ai-training-inference/",
  "description": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient [...] Read More... The post How PyTorch powers AI training and inference appeared first on Engineering at Meta.",
  "author": "",
  "published": "Fri, 23 Aug 2024 16:00:54 +0000",
  "source": "https://engineering.fb.com/feed/",
  "categories": [
    "AI Research",
    "ML Applications",
    "Open Source",
    "AI Infra @ Scale"
  ],
  "byline": "",
  "length": 719,
  "excerpt": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smotâ€¦",
  "siteName": "Engineering at Meta",
  "favicon": "",
  "text": "Learn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle. In this talk from AI Infra @ Scale 2024, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient fine-tuning, and on-device LLM capabilities. First, they cover the importance of memory-efficient fine-tuning and a few common architectural and algorithmic techniques to enable fine-tuning on consumer-grade hardware. Then they discuss the challenges of deploying large models for on-device deployment and how techniques such as quantization make these deployments possible.",
  "image": "https://engineering.fb.com/wp-content/uploads/2024/08/AI-@Scale-2024-YouTube-Thumbnail-WanchaoKimishEvan.webp",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle id=\"post-21568\"\u003e\n\n\t\n\n\t\t\t\u003cfigure id=\"post-feat-image-container\"\u003e\n\t\t\t\t\u003cimg width=\"1280\" height=\"720\" src=\"https://engineering.fb.com/wp-content/uploads/2024/08/AI-@Scale-2024-YouTube-Thumbnail-WanchaoKimishEvan.webp\" alt=\"\"/\u003e\t\t\t\t\t\t\u003c/figure\u003e\n\t\t\n\t\n\n\t\n\t\u003cdiv\u003e\n\n\t\t\u003cp\u003e\u003cspan\u003eLearn about new PyTorch advancements for LLMs and how PyTorch is enhancing every aspect of the LLM lifecycle.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eIn this talk from \u003c/span\u003e\u003ca href=\"https://atscaleconference.com/events/ai-infra-scale-2024/\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003eAI Infra @ Scale 2024\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, software engineers Wanchao Liang and Evan Smothers are joined by Meta research scientist Kimish Patel to discuss our newest features and tools that enable large-scale training, memory efficient fine-tuning, and on-device LLM capabilities.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eFirst, they cover the importance of memory-efficient fine-tuning and a few common architectural and algorithmic techniques to enable fine-tuning on consumer-grade hardware. Then they discuss the challenges of deploying large models for on-device deployment and how techniques such as quantization make these deployments possible.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003ciframe title=\"How Pytorch Powers Training Inference | Wanchao Liang, Kimish Patel, and Evan Smothers\" width=\"1778\" height=\"1000\" src=\"https://www.youtube.com/embed/96VIEJfhUBg?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\n\n\t\t\n\t\u003c/div\u003e\n\n\n\u003c/article\u003e\u003c/div\u003e",
  "readingTime": "Less than 1 min",
  "publishedTime": "2024-08-23T16:00:54Z",
  "modifiedTime": "2024-08-23T16:08:46Z"
}
