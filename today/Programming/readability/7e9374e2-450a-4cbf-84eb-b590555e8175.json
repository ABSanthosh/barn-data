{
  "id": "7e9374e2-450a-4cbf-84eb-b590555e8175",
  "title": "Inside GitHub: How we hardened our SAML implementation",
  "link": "https://github.blog/security/web-application-security/inside-github-how-we-hardened-our-saml-implementation/",
  "description": "Maintaining and developing complex and risky code is never easy. See how we addressed the challenges of securing our SAML implementation with this behind-the-scenes look at building trust in our systems. The post Inside GitHub: How we hardened our SAML implementation appeared first on The GitHub Blog.",
  "author": "Greg Ose",
  "published": "Tue, 27 May 2025 16:00:00 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "Security",
    "Web application security",
    "GitHub Security Lab",
    "SAML"
  ],
  "byline": "Greg Ose, Taylor Reis",
  "length": 28712,
  "excerpt": "See how we addressed the challenges of securing our SAML implementation with this behind-the-scenes look at building trust in our systems.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "For over a decade, GitHub has offered enterprise authentication using SAML (Security Assertion Markup Language), starting with our 2.0.0 release of GitHub Enterprise Server in November 2014. SAML single sign-on (SSO) allows enterprises to integrate their existing identity providers with a broad range of GitHub products, extend conditional access policies, and bring enterprise organization management to GitHub. To ship this feature, we had to build and maintain support for the SAML 2.0 specification, which defines how to perform authentication and establish trust between an identity provider and our products, the service provider. This involves generating SAML metadata for identity providers, generating SAML authentication requests as part of the service provider–initiated SSO flow, and most importantly, processing and validating SAML responses from an identity provider in order to authenticate users. These code paths are critical from a security perspective. Here’s why:  Any bug in how authentication is established and validated between the service and identity providers can lead to a bypass of authentication or impersonation of other users.  These areas of the codebase involve XML parsing and cryptography, and are dependent on complex specifications, such as the XML Signature, XML Encryption, and XML Schema standards.  The attack surface of SAML code is very broad, so the data that is validated for authentication and passed through users’ (and potential attackers’) browsers could be manipulated.  This combination of security criticality, complexity, and attack surface puts the implementation of SAML at a higher level of risk than most of the code we build and maintain. Background When we launched SAML support in 2014, there were few libraries available for implementing it. After experimenting initially with ruby-saml, we decided to create our own implementation to better suit our needs.  Over the years since, we have continually invested in hardening these authentication flows, including working with security researchers both internally and through our Security Bug Bounty to identify and fix vulnerabilities impacting our implementation.  However, for each vulnerability addressed, there remained lingering concerns given the breadth and complexity of root causes we identified. This is why we decided to take a step back and rethink how we could move forward in a more sustainable and holistic manner to secure our implementation. So, how do you build trust in a technology as complex and risky as SAML?  Last year, this is exactly the question our engineering team set out to answer. We took a hard look at our homegrown implementation and decided it was time for change. We spent time evaluating the previous bounties we’d faced and brainstormed new ideas on how to improve our SAML strategy. During this process, we identified several promising changes we could make to regain our confidence in SAML.  In this article, we’ll describe the four key steps we took to get there: Rethinking our library: Evaluating the ruby-saml library and auditing its implementation Validating the new library with A/B testing: Building a system where we could safely evaluate and observe changes to our SAML processing logic Schema validations and minimizing our attack surface: Reducing the complexity of input processing by tightening schema validation Limiting our vulnerability impact: Using multiple parsers to decrease risk Rethinking our library When we reviewed our internal implementation, we recognized the advantages of transitioning to a library with strong community support that we could contribute to alongside a broader set of developers.  After reviewing a number of ruby SAML libraries, we decided to focus again on utilizing the ruby-saml library maintained by Sixto Martín for a few reasons:  This library is used by a number of critical SaaS products, including broad adoption through its usage in omniauth-saml. Recent bugs and vulnerabilities were being reported and fixed in the library, showing active maintenance and security response.  These vulnerabilities and fixes were distributed through the GitHub Advisory Database and CVEs, and had updates pushed through Dependabot, which integrates well with our existing vulnerability management processes.  This support and automation is something we wouldn’t be able to benefit from with our own internal implementation. But moving away from our internal implementation wasn’t a simple decision. We had grown familiar with it, and had invested significant time and effort into identifying and addressing vulnerabilities. We didn’t want to have to retread the same vulnerabilities and issues we had with our own code.  With that concern, we set out to see what work across our security and engineering teams we could do to gain more confidence in this new library before making a potential switch. In collaboration with our bug bounty team and researchers, our product security team, and the GitHub Security Lab, we laid out a gauntlet of validation and testing activities. We spun up a number of security auditing activities, worked with our VIP bug bounty researchers (aka Hacktocats) who had expertise in this area (thanks @ahacker1) and researchers on the GitHub Security Lab team (thanks @p-) to perform in-depth code analysis and application security testing.  This work resulted in the identification of critical vulnerabilities in the ruby-saml library and highlighted areas for overall hardening that could be applied to the library to remove the possibility of classes of vulnerabilities in the code. But is security testing and auditing enough to confidently move to this new library? Even with this focus on testing, assessment, and vulnerability remediation, we knew from experience that we couldn’t just rely on this point-in-time analysis.  The underlying code paths are just too complex to hang our hat on any amount of time-bound code review. With that decision, we shifted our focus toward engineering efforts to validate the new library, identify edge cases, and limit the attack surface of our SAML code. Validating the new library with A/B testing GitHub.com processes around one million SAML payloads per business day, making it the most widely used form of external authentication that we support. Because this code is the front door for so many enterprise customers, any changes require a high degree of scrutiny and testing.  In order to preserve the stability of our SAML processing code while evaluating ruby-saml, we needed an abstraction that would give us the safety margins to experiment and iterate quickly.  There are several solutions for this type of problem, but at GitHub, we use a tool we have open sourced called Scientist. At its core, Scientist is a library that allows you to execute an experiment and compare two pieces of code: a control and a candidate. The result of the comparison is recorded so that you can monitor and debug differences between the two sources.  The beauty of Scientist is it always honors the result of the control, and isolates failures in your candidate, freeing you to truly experiment with your code in a safe way. This is useful for tasks like query performance optimization—or in our case, gaining confidence in and validating a new library. Applying Scientist to SAML GitHub supports configuring SAML against both organizations and enterprises. Each of these configurations is handled by a separate controller that implements support for SAML metadata, initiation of SAML authentication requests, and SAML response validation.  For the sake of building confidence, our primary focus was the code responsible for handling SAML response validation, also known as the Assertion Consumer Service (ACS) URL. This is the endpoint that does the heavy lifting to process the SAML response coming from the identity provider, represented in the SAML sequence diagram below as “Validate SAML Response.” Most importantly, this is where most vulnerabilities occur. In order to gain confidence in ruby-saml, we needed to validate that we could get the library to handle our existing traffic correctly.  To accomplish this, we applied Scientist experiments to the controller code responsible for consuming the SAML response and worked on the following three critical capabilities: Granular rollout gating: Scientist provides a percent-based control for enabling traffic on an experiment. Given the nature of this code path, we wanted an additional layer of feature flagging to ensure that we could send our own test accounts through the path before actual customer traffic Observability: GitHub has custom instrumentation for experiments, which sends metrics to Datadog. We leaned heavily on this for monitoring our progress, but also added supplemental logging to generate more granular validation data to help debug differences between libraries. Idempotency: There are pieces of state that are tracked during a SAML flow, such as tokens for CSRF, and we needed to ensure that our experiment did not modify them. Any changes must be clear of these code paths to prevent overwriting state. When all was said and done, our experiment looked something like the following: # gate the experiment by business, allowing us to run test account traffic through first if business.feature_enabled?(:run_consume_experiment) # auth_result is the result of `e.use` below auth_result = science \"consume_experiment\" do |e| # ensure that we isolate the raw response ahead of time, and scope the experiment to # just the validation portion of response processing e.use { consume_control_validation(raw_saml_response) } e.try { consume_candidate_validation(raw_saml_response) } # compare results and perform logging e.compare { |control, candidate| compare_and_log_results(control, candidate) } end end # deal with auth_result below... So, how did our experiments help us build confidence in ruby-saml?  For starters, we used them to identify configuration differences between implementations. This guided our integration with the library, ensuring it could handle traffic in a way that was behaviorally consistent.  As an example, in September 2024 we noticed in our logs that approximately 3% of mismatches were caused by SAML issuer validation discrepancies. Searching the logs, we found that ruby-saml validated the issuer against an empty string. This helped us identify that some SAML configurations had an issuer set to an empty string, rather than null in the database.  Given that GitHub has not historically required an issuer for all SAML configurations, if the value is blank or unset, we skip issuer validation in our implementation. To handle this legacy invariant, we shipped a change that prevented configuring ruby-saml with blank or null issuer values, allowing the validation to be skipped in the library.  The impact of this change can be seen in graph below: Once we set ruby-saml up correctly, our experiments allowed us to run all of our traffic through the library to observe how it would perform over an extended period of time. This was critical for building confidence that we had covered all edge cases. Most importantly, by identifying edge cases where the implementations handled certain inputs differently, we could investigate if any of these had security-relevant consequences.  By reviewing these exceptions, we were able to proactively identify incorrect behavior in either the new or old implementation. We also noticed during testing that ruby-saml rejected responses with multiple SAML assertions, while ours was more lenient.  While not completely wrong, we realized our implementation was trying to do too much. The information gained during this testing allowed us to safely augment our candidate code with new ideas and identify further areas of hardening like our next topic. Schema validations and minimizing our attack surface Before looking into stricter input validation, we first have to dive into what makes up the inputs we need to validate. Through our review of industry vulnerabilities, our implementation, and related research, we identified two critical factors that make parsing and validating this input particularly challenging:  The relationship between enveloped XML signatures and the document structure The SAML schema flexibility Enveloped XML Signatures A key component of SAML is the XML signatures specification, which provides a way to sign and verify the integrity of SAML data. There are multiple ways to use XML signatures to sign data, but SAML relies primarily on enveloped XML signatures, where the signature itself is embedded within the element it covers.  Here’s an example of a \u003cResponse\u003e element with an enveloped XML signature: \u003cResponse ID=\"1234\u003e \u003cSignature xmlns=\"http://www.w3.org/2000/09/xmldsig#\"\u003e \u003cSignedInfo\u003e \u003cCanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"\u003e\u003c/CanonicalizationMethod\u003e \u003cSignatureMethod Algorithm=\"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\"\u003e\u003c/SignatureMethod\u003e \u003cReference URI=\"#1234\"\u003e \u003cTransforms\u003e \u003cTransform Algorithm=\"http://www.w3.org/2000/09/xmldsig#enveloped-signature\"\u003e\u003c/Transform\u003e \u003cTransform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"\u003e\u003c/Transform\u003e \u003c/Transforms\u003e \u003cDigestMethod Algorithm=\"http://www.w3.org/2001/04/xmlenc#sha256\"\u003e\u003c/DigestMethod\u003e \u003cDigestValue\u003e...\u003c/DigestValue\u003e \u003c/Reference\u003e \u003c/SignedInfo\u003e \u003cSignatureValue\u003e...\u003c/SignatureValue\u003e \u003cKeyInfo\u003e \u003cX509Data\u003e \u003cX509Certificate\u003e...\u003c/X509Certificate\u003e \u003c/X509Data\u003e \u003c/KeyInfo\u003e \u003c/Signature\u003e \u003c/Response\u003e In order to verify this signature, we performed some version of the following high-level process: Find the signature: Locate the \u003cSignature\u003e element in the \u003cResponse\u003e element. Extract values: Get the \u003cSignatureValue\u003e and \u003cSignedInfo\u003e from the \u003cSignature\u003e. Extract reference and digest: From \u003cSignedInfo\u003e, extract the \u003cReference\u003e (a pointer to the signed part of the document—note the URI attribute and the associated ID attribute on \u003cResponse\u003e) and \u003cDigestValue\u003e (a hashed version of \u003cResponse\u003e, minus the \u003cSignature\u003e). Verify the digest: Apply the transformation instructions in the signature to the \u003cResponse\u003e element and compare the results to the \u003cDigestValue\u003e. Validate integrity: If the digest is valid, hash and encode \u003cSignedInfo\u003e using another algorithm, then use the configured public key (exchanged during SAML set up) to verify it against the \u003cSignatureValue\u003e. If we get through this list of steps and the signature is valid, we assume that the \u003cResponse\u003e element has not been tampered with. The interesting part about this is that to process the signature that legitimizes the \u003cResponse\u003e element’s contents, we had to parse the \u003cResponse\u003e element’s contents!  Put another way, the integrity of the SAML data is tied to its document structure, but that same document structure plays a critical role in how it is validated. Herein lies the crux of many SAML validation vulnerabilities. This troubling relationship between structure and integrity can be exploited, and has been many times. One of the more common classes of vulnerability is the XML signature wrapping attack, which involves tricking the library into trusting the wrong data.  SAML libraries typically deal with this by querying the document and rejecting unexpected or ambiguous input shapes. This strategy isn’t ideal because it still requires trusting the document before verifying its authenticity, so any small blunders can be targeted. Lax SAML schema definitions SAML responses must be valid against the SAML 2.0 XML schema definition (XSD). XSD files are used to define the structure of XML, creating a contract between the sender and receiver about the sequence of elements, data types, and attributes.  This is exactly what we would look for in creating a clear set of inputs that we can easily limit parsing and validation around! Unfortunately, the SAML schema is quite flexible in what it allows, providing many opportunities for a document structure that would never appear in typical SAML responses. For example, take a look at the SAML response below and notice the \u003cStatusDetail\u003e element. \u003cStatusDetail\u003e is one example in the spec that allows arbitrary data of any type and namespace to be added to the document. Consequently, including the elements \u003cFoo\u003e, \u003cBar\u003e, and \u003cBaz\u003e into \u003cStatusDetail\u003e below would be completely valid given the SAML 2.0 schema.  \u003cResponse xmlns=\"urn:oasis:names:tc:SAML:2.0:protocol\" Version=\"2.0\" ID=\"_\" IssueInstant=\"1970-01-01T00:00:00.000Z\"\u003e \u003cStatus\u003e \u003cStatusCode Value=\"urn:oasis:names:tc:SAML:2.0:status:Success\"/\u003e \u003cStatusDetail\u003e \u003cFoo\u003e \u003cBar\u003e \u003cBaz /\u003e \u003c/Bar\u003e \u003c/Foo\u003e \u003c/StatusDetail\u003e \u003c/Status\u003e \u003cAssertion xmlns=\"urn:oasis:names:tc:SAML:2.0:assertion\" Version=\"2.0\" ID=\"TEST\" IssueInstant=\"1970-01-01T00:00:00.000Z\"\u003e \u003cIssuer\u003eissuer\u003c/Issuer\u003e \u003cSignature xmlns=\"http://www.w3.org/2000/09/xmldsig#\"\u003e Omitted for Brevity... \u003c/Signature\u003e \u003cSubject\u003e \u003cNameID\u003e user@example.net \u003c/NameID\u003e \u003c/Subject\u003e \u003c/Assertion\u003e \u003c/Response\u003e Knowing that the signature verification process is sensitive to the document structure, this is problematic. These schema possibilities leave gaps that your code must check.  Consider an implementation that does not correctly associate signatures with signed data, only validating the first signature it finds because it assumes that the signature should always be in the \u003cResponse\u003e element (which encompasses the \u003cAssertion\u003e element), or in the \u003cAssertion\u003e element directly. This is where the signatures are located in the schema, after all.  To exploit this, replace the contents of our previous example with a piece of correctly signed SAML data from the identity provider (remember that the schema allows any type of data in \u003cStatusDetail\u003e). Since the library only cares about the first signature it finds, it never verifies the \u003cAssertion\u003e signature in the example below, allowing an attacker to modify its contents to gain system access. \u003cResponse xmlns=\"urn:oasis:names:tc:SAML:2.0:protocol\" Version=\"2.0\" ID=\"_\" IssueInstant=\"1970-01-01T00:00:00.000Z\"\u003e \u003cStatus\u003e \u003cStatusCode Value=\"urn:oasis:names:tc:SAML:2.0:status:Success\"/\u003e \u003cStatusDetail\u003e \u003cResponse Version=\"2.0\" ID=\"TEST\" IssueInstant=\"1970-01-01T00:00:00.000Z\"\u003e \u003cSignature xmlns=\"http://www.w3.org/2000/09/xmldsig#\"\u003e Omitted for Brevity... \u003c/Signature\u003e \u003c/Response\u003e \u003c/StatusDetail\u003e \u003c/Status\u003e \u003cAssertion xmlns=\"urn:oasis:names:tc:SAML:2.0:assertion\" Version=\"2.0\" ID=\"TEST\" IssueInstant=\"1970-01-01T00:00:00.000Z\"\u003e \u003cIssuer\u003eissuer\u003c/Issuer\u003e \u003cSignature xmlns=\"http://www.w3.org/2000/09/xmldsig#\"\u003e Omitted for Brevity... \u003c/Signature\u003e \u003cSubject\u003e \u003cNameID\u003e attacker-controller@example.net \u003c/NameID\u003e \u003c/Subject\u003e \u003c/Assertion\u003e \u003c/Response\u003e There are so many different permutations of vulnerabilities like this that depend on the loose SAML schema, including many that we have protected against in our internal implementation. Limiting the attack surface While we can’t change how SAML works or the schema that defines it, what if we change the schema we validate it against? By making a stricter schema, we could enforce exactly the structure we expect to process, thereby reducing the likelihood of signature processing mistakes. Doing this would allow us to rule out bad data shapes before ever querying the document. But in order to build a stricter schema, we first needed to confirm that the full SAML 2.0 schema wasn’t necessary. Our process began with bootstrapping: we gathered SAML responses from test accounts provided by our most widely integrated identity providers.  Starting small, we focused on Entra and Okta, which together accounted for nearly 85% of our SSO traffic volume. Using these responses, we crafted an initial schema based on real-world usage. Next, we used Scientist to validate the schemas against our vast amount of production traffic. We first A/B tested with the very restrictive “bootstrapped” schema and gradually added back in the parts of the schema that we saw in anonymized traffic.  This allowed us to define a minimal schema that only contained the structures we saw in real-world requests. The same tooling we used for A/B testing allowed us to craft a minimal schema by iterating on the failures we saw across millions of requests. How did the “strict” schema turn out based on our real-world validation from identity providers? Below are some of the key takeaways and schema restrictions we now enforce: Ensure Signature elements are only where you expect them  We expect at most two elements to be signed: the Response, and the Assertion, but we know the schema is more lenient. For example, we don’t expect the SubjectConfirmationData or Advice elements to contain a signature, yet the following is a valid structure: \u003csamlp:Response ID=\"response-id\" xmlns:samlp=\"urn:oasis:names:tc:SAML:2.0:protocol\"\u003e \u003csaml:Assertion ID=\"signed-assertion-id\"\u003e \u003cds:Signature\u003e \u003cds:SignedInfo\u003e \u003cds:Reference URI=\"#signed-assertion-id\" /\u003e ... \u003c/ds:SignedInfo\u003e \u003c/ds:Signature\u003e \u003csaml:Subject\u003e \u003csaml:NameID\u003elegitimate-user@example.com\u003c/saml:NameID\u003e \u003csaml:SubjectConfirmation\u003e \u003csaml:SubjectConfirmationData\u003e \u003cds:Signature\u003e...\u003c/ds:Signature\u003e \u003c/saml:SubjectConfirmationData\u003e \u003c/saml:SubjectConfirmation\u003e \u003c/saml:Subject\u003e \u003c/saml:Assertion\u003e These are ambiguous situations that we can prevent. By removing \u003cany\u003e type elements, we can prevent additional signatures from being added to the document, and reduce the risk of attacks targeting flaws in signature selection logic. It’s safe to enforce a single assertion in your response  The SAML spec allows for an unbounded number of assertions: \u003cchoice minOccurs=\"0\" maxOccurs=\"unbounded\"\u003e \u003celement ref=\"saml:Assertion\"/\u003e \u003celement ref=\"saml:EncryptedAssertion\"/\u003e \u003c/choice\u003e We expect exactly one assertion, and most SAML libraries account for this invariant by querying and rejecting documents with multiple assertions. By removing the minOccurs and maxOccurs attributes from the schema’s assertion choice, we can reject responses containing multiple assertions ahead of time.  This matters because multiple assertions in the document lead to structures that are vulnerable to XML signature wrapping attacks. Enforcing a single assertion removes structural ambiguity around the most important part of the document.  Remove additional elements and attributes that are unused in practice by your implementation  This is probably the least specific piece of advice, but important: Removing what you don’t support from the existing schema will reduce the risk of your application code handling that input incorrectly. For example, if you don’t support EncryptedAssertions, you should probably omit those definitions from your schema all together to prevent your code from touching data it doesn’t expect. It is safe to reject document type definitions (DTDs)  While not strictly XSD related, we felt this was an important callout. DTDs are an older and more limited alternative to XSDs that add an unnecessary attack vector. Given that SAML 2.0 relies on schema definition files for validation, DTDs are both outdated and unnecessary, so we felt it best to disallow them altogether. In the wild, we never saw DTDs being used by identity providers. The goal of a stricter SAML schema is to simplify working with SAML signatures and documents by removing ambiguity. By enforcing precise rules about where signatures should appear and their relationship to the data, validation becomes more straightforward and reliable.  While stricter schemas don’t eliminate all risks—since signature processing also depends on implementation—they significantly reduce the attack surface, enhancing overall security and minimizing the complex parsing we need to reason about for validation. Limiting our vulnerability impact At this point, we had made significant progress in addressing the risks associated with integrating ruby-saml and had restricted our critical inputs to a much smaller portion of the SAML schema.  By implementing safeguards, validating critical code paths, and taking a deliberate approach to testing, we mitigated many of the uncertainties inherent in adopting a new library and of SAML in general.  However, one fundamental truth remained: implementation vulnerabilities are inevitable, and we wanted to see what additional hardening we could apply to limit their impact. Considering a compromise Migrating to ruby-saml fully would mean embracing a more modern, actively maintained codebase that addresses known vulnerabilities. It would also position us for better long-term maintainability with broad community support: one of the primary motivators for this initiative.  However, replacing a core component like a SAML library isn’t without trade-offs. The risk of new vulnerabilities that weren’t surfaced during our work would always exist. With this in mind, we considered an alternative path: Instead of relying entirely on one library, why not use both? We took this idea and ran with it by implementing a dual-parsing strategy and running both libraries independently and in parallel, requiring them to agree on validation before accepting a result. It might sound redundant and inefficient, but here’s why it worked to harden our implementation: Defense in depth: The two libraries parse SAML differently. Exploiting both would require two independent vulnerabilities that work in unison—a much taller order than compromising just one. Built-in feedback: When they disagree, we are notified. This gives us the opportunity to identify and investigate potential security critical edge cases. We can then feed stricter validation logic from one library back into the other. No pressure to rush: Our original library is battle-tested and hardened. Using both together allows us to leverage its reliability while adopting the benefits of ruby-saml. We can always revisit this decision as we learn more about this strategy and its performance over time. With this approach, we recognize that keeping something that works—when paired with something new—can be more powerful than replacing it outright. Of course, there are still risks involved. But by having two parsers, we increase our exposure of implementation vulnerabilities in our XML parsing code: things like memory corruption or XML external entity vulnerabilities. We also increase the burden of having to maintain two libraries.  Despite this, we decided that this risk and time investment is worth the increased resilience to the complex validation logic that is the core to the historical and critical vulnerabilities we’ve seen.  Learn from our blueprint While our original goal was to “just” move to a new SAML library, we ended up taking the opportunity to reduce the risk profile of our entire SAML implementation.  By investing in upfront code review, security testing, and A/B testing and validation, we’ve gained confidence in the implementation of this new library. We then decreased the complexity of these code paths by restricting our allowed schema to one that is minimized using real world data. Finally, we’ve limited the impact of a single vulnerability found in either library by combining the strengths of both ruby-saml and our internal implementation. As this code continues to parse almost a million SAML responses per day, our robust logging and exception handling will provide us with the observability needed to adjust our strategy or identify new hardening opportunities.  This experience should provide any team with a great blueprint on how to approach other complex or dangerous parts of a codebase they may be tasked with maintaining or hardening—and a reminder that incremental, data-driven experiments and compromises can sometimes lead to unexpected outcomes. Written by Principal Product Security Engineer Software Engineer III",
  "image": "https://github.blog/wp-content/uploads/2024/09/Security-LightMode-2.png?fit=1200%2C630",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003eFor over a decade, GitHub has offered enterprise authentication using SAML (Security Assertion Markup Language), starting with our 2.0.0 release of GitHub Enterprise Server in November 2014. SAML single sign-on (SSO) allows enterprises to integrate their existing identity providers with a broad range of GitHub products, extend conditional access policies, and bring enterprise organization management to GitHub.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo ship this feature, we had to build and maintain support for the SAML 2.0 specification, which defines how to perform authentication and establish trust between an identity provider and our products, the service provider. This involves generating SAML metadata for identity providers, generating SAML authentication requests as part of the service provider–initiated SSO flow, and most importantly, processing and validating SAML responses from an identity provider in order to authenticate users.\u003c/p\u003e\n\n\n\n\u003cp\u003eThese code paths are critical from a security perspective. Here’s why: \u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eAny bug in how authentication is established and validated between the service and identity providers can lead to a bypass of authentication or impersonation of other users. \u003c/li\u003e\n\n\n\n\u003cli\u003eThese areas of the codebase involve XML parsing and cryptography, and are dependent on complex specifications, such as the XML Signature, XML Encryption, and XML Schema standards. \u003c/li\u003e\n\n\n\n\u003cli\u003eThe attack surface of SAML code is very broad, so the data that is validated for authentication and passed through users’ (and potential attackers’) browsers could be manipulated. \u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThis combination of security criticality, complexity, and attack surface puts the implementation of SAML at a higher level of risk than most of the code we build and maintain.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-background\"\u003eBackground\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhen we launched SAML support in 2014, there were few libraries available for implementing it. After experimenting initially with \u003ca href=\"https://github.com/SAML-Toolkits/ruby-saml\"\u003eruby-saml\u003c/a\u003e, we decided to create our own implementation to better suit our needs. \u003c/p\u003e\n\n\n\n\u003cp\u003eOver the years since, we have continually invested in hardening these authentication flows, including working with security researchers both internally and through our \u003ca href=\"https://bounty.github.com\"\u003eSecurity Bug Bounty\u003c/a\u003e to identify and fix vulnerabilities impacting our implementation. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, for each vulnerability addressed, there remained lingering concerns given the breadth and complexity of root causes we identified. This is why we decided to take a step back and rethink how we could move forward in a more sustainable and holistic manner to secure our implementation.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eSo, how do you build trust in a technology as complex and risky as SAML? \u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eLast year, this is exactly the question our engineering team set out to answer. We took a hard look at our homegrown implementation and decided it was time for change. We spent time evaluating the previous bounties we’d faced and brainstormed new ideas on how to improve our SAML strategy. During this process, we identified several promising changes we could make to regain our confidence in SAML. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn this article, we’ll describe the four key steps we took to get there:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eRethinking our library: \u003c/strong\u003eEvaluating the \u003ca href=\"https://github.com/SAML-Toolkits/ruby-saml\"\u003eruby-saml\u003c/a\u003e library and auditing its implementation\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eValidating the new library with A/B testing: \u003c/strong\u003eBuilding a system where we could safely evaluate and observe changes to our SAML processing logic\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eSchema validations and minimizing our attack surface: \u003c/strong\u003eReducing the complexity of input processing by tightening schema validation\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eLimiting our vulnerability impact: \u003c/strong\u003eUsing multiple parsers to decrease risk\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003ch2 id=\"h-rethinking-our-library\"\u003eRethinking our library\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhen we reviewed our internal implementation, we recognized the advantages of transitioning to a library with strong community support that we could contribute to alongside a broader set of developers. \u003c/p\u003e\n\n\n\n\u003cp\u003eAfter reviewing a number of ruby SAML libraries, we decided to focus again on utilizing the \u003ca href=\"https://github.com/SAML-Toolkits/ruby-saml\"\u003eruby-saml\u003c/a\u003e library maintained by \u003ca href=\"https://github.com/pitbulk\"\u003eSixto Martín\u003c/a\u003e for a few reasons: \u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eThis library is used by a number of critical SaaS products, including broad adoption through its usage in \u003ca href=\"https://github.com/omniauth/omniauth-saml\"\u003eomniauth-saml\u003c/a\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003eRecent bugs and vulnerabilities were being reported and fixed in the library, showing active maintenance and security response. \u003c/li\u003e\n\n\n\n\u003cli\u003eThese vulnerabilities and fixes were distributed through the \u003ca href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories\"\u003eGitHub Advisory Database\u003c/a\u003e and CVEs, and had updates pushed through \u003ca href=\"https://docs.github.com/en/code-security/getting-started/dependabot-quickstart-guide\"\u003eDependabot\u003c/a\u003e, which integrates well with our existing \u003ca href=\"https://github.blog/engineering/platform-security/how-we-use-dependabot-to-secure-github/\"\u003evulnerability management processes\u003c/a\u003e. \u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThis support and automation is something we wouldn’t be able to benefit from with our own internal implementation.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut moving away from our internal implementation wasn’t a simple decision. We had grown familiar with it, and had invested significant time and effort into identifying and addressing vulnerabilities. We didn’t want to have to retread the same vulnerabilities and issues we had with our own code. \u003c/p\u003e\n\n\n\n\u003cp\u003eWith that concern, we set out to see what work across our security and engineering teams we could do to gain more confidence in this new library before making a potential switch.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn collaboration with our bug bounty team and researchers, our product security team, and the GitHub Security Lab, we laid out a gauntlet of validation and testing activities. We spun up a number of security auditing activities, worked with our VIP bug bounty researchers (\u003ca href=\"https://github.blog/security/vulnerability-research/githubs-revamped-vip-bug-bounty-program/\"\u003eaka Hacktocats\u003c/a\u003e) who had expertise in this area (thanks \u003ca href=\"https://hackerone.com/ahacker1\"\u003e@ahacker1\u003c/a\u003e) and researchers on the GitHub Security Lab team (thanks \u003ca href=\"https://github.com/p-\"\u003e@p-\u003c/a\u003e) to perform in-depth code analysis and application security testing. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis work resulted in the identification of \u003ca href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/\"\u003ecritical vulnerabilities in the ruby-saml library\u003c/a\u003e and highlighted areas for overall hardening that could be applied to the library to remove the possibility of classes of vulnerabilities in the code.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut is security testing and auditing enough to confidently move to this new library? Even with this focus on testing, assessment, and vulnerability remediation, we knew from experience that we couldn’t just rely on this point-in-time analysis. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe underlying code paths are just too complex to hang our hat on any amount of time-bound code review. With that decision, we shifted our focus toward engineering efforts to validate the new library, identify edge cases, and limit the attack surface of our SAML code.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-validating-the-new-library-with-a-b-testing\"\u003eValidating the new library with A/B testing\u003c/h2\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eGitHub.com processes around one million SAML payloads per business day, making it the most widely used form of external authentication that we support\u003c/strong\u003e. Because this code is the front door for so many enterprise customers, any changes require a high degree of scrutiny and testing. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn order to preserve the stability of our SAML processing code while evaluating ruby-saml, we needed an abstraction that would give us the safety margins to experiment and iterate quickly. \u003c/p\u003e\n\n\n\n\u003cp\u003eThere are several solutions for this type of problem, but at GitHub, we use a tool we have open sourced called \u003ca href=\"https://github.blog/developer-skills/application-development/scientist/\"\u003eScientist\u003c/a\u003e. At its core, Scientist is a library that allows you to execute an experiment and compare two pieces of code: a control and a candidate. The result of the comparison is recorded so that you can monitor and debug differences between the two sources. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe beauty of Scientist is it always honors the result of the control, and isolates failures in your candidate, freeing you to truly \u003cem\u003eexperiment\u003c/em\u003e with your code in a safe way. This is useful for tasks like query performance optimization—or in our case, gaining confidence in and validating a new library.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-applying-scientist-to-saml\"\u003eApplying Scientist to SAML\u003c/h3\u003e\n\n\n\n\u003cp\u003eGitHub supports configuring SAML against both organizations and enterprises. Each of these configurations is handled by a separate controller that implements support for SAML metadata, initiation of SAML authentication requests, and SAML response validation. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor the sake of building confidence, our primary focus was the code responsible for handling SAML response validation, also known as the Assertion Consumer Service (ACS) URL. This is the endpoint that does the heavy lifting to process the SAML response coming from the identity provider, represented in the SAML sequence diagram below as “Validate SAML Response.” Most importantly, this is where most vulnerabilities occur.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" width=\"1999\" height=\"1390\" loading=\"lazy\" src=\"https://github.blog/wp-content/uploads/2025/05/image-1-saml-flow.png?resize=1999%2C1390\" alt=\"SAML sequence diagram\" srcset=\"https://github.blog/wp-content/uploads/2025/05/image-1-saml-flow.png?w=1999 1999w, https://github.blog/wp-content/uploads/2025/05/image-1-saml-flow.png?w=300 300w, https://github.blog/wp-content/uploads/2025/05/image-1-saml-flow.png?w=768 768w, https://github.blog/wp-content/uploads/2025/05/image-1-saml-flow.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/05/image-1-saml-flow.png?w=1536 1536w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIn order to gain confidence in ruby-saml, we needed to validate that we could get the library to handle our existing traffic correctly. \u003c/p\u003e\n\n\n\n\u003cp\u003eTo accomplish this, we applied Scientist experiments to the controller code responsible for consuming the SAML response and worked on the following three critical capabilities:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eGranular rollout gating: \u003c/strong\u003eScientist provides a percent-based control for enabling traffic on an experiment. Given the nature of this code path, we wanted an additional layer of feature flagging to ensure that we could send our own test accounts through the path before actual customer traffic\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eObservability: \u003c/strong\u003eGitHub has custom instrumentation for experiments, which sends metrics to Datadog. We leaned heavily on this for monitoring our progress, but also added supplemental logging to generate more granular validation data to help debug differences between libraries.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eIdempotency: \u003c/strong\u003eThere are pieces of state that are tracked during a SAML flow, such as tokens for CSRF, and we needed to ensure that our experiment did not modify them. Any changes must be clear of these code paths to prevent overwriting state.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eWhen all was said and done, our experiment looked something like the following:\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e# gate the experiment by business, allowing us to run test account traffic through first\nif business.feature_enabled?(:run_consume_experiment)\n  # auth_result is the result of `e.use` below\n  auth_result = science \u0026#34;consume_experiment\u0026#34; do |e|\n\n    # ensure that we isolate the raw response ahead of time, and scope the experiment to\n    # just the validation portion of response processing\n    e.use { consume_control_validation(raw_saml_response) }\n    e.try { consume_candidate_validation(raw_saml_response) }\n\n    # compare results and perform logging\n    e.compare { |control, candidate| compare_and_log_results(control, candidate) }\n  end\nend\n\n# deal with auth_result below...\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eSo, how did our experiments help us build confidence in ruby-saml?\u003c/strong\u003e \u003c/p\u003e\n\n\n\n\u003cp\u003eFor starters, we used them to identify configuration differences between implementations. This guided our integration with the library, ensuring it could handle traffic in a way that was behaviorally consistent. \u003c/p\u003e\n\n\n\n\u003cp\u003eAs an example, in September 2024 we noticed in our logs that approximately 3% of mismatches were caused by SAML issuer validation discrepancies. Searching the logs, we found that ruby-saml validated the issuer against an empty string. This helped us identify that some SAML configurations had an issuer set to an empty string, rather than null in the database. \u003c/p\u003e\n\n\n\n\u003cp\u003eGiven that GitHub has not historically required an issuer for all SAML configurations, if the value is blank or unset, we skip issuer validation in our implementation. To handle this legacy invariant, we shipped a change that prevented configuring ruby-saml with blank or null issuer values, allowing the validation to be skipped in the library. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe impact of this change can be seen in graph below:\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg data-recalc-dims=\"1\" decoding=\"async\" width=\"1999\" height=\"855\" loading=\"lazy\" src=\"https://github.blog/wp-content/uploads/2025/05/image-2-experiment-mismatch.png?resize=1999%2C855\" alt=\"Graph of SAML experiment mismatches over time highlighting 3% drop after fix\" srcset=\"https://github.blog/wp-content/uploads/2025/05/image-2-experiment-mismatch.png?w=1999 1999w, https://github.blog/wp-content/uploads/2025/05/image-2-experiment-mismatch.png?w=300 300w, https://github.blog/wp-content/uploads/2025/05/image-2-experiment-mismatch.png?w=768 768w, https://github.blog/wp-content/uploads/2025/05/image-2-experiment-mismatch.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/05/image-2-experiment-mismatch.png?w=1536 1536w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOnce we set ruby-saml up correctly, our experiments allowed us to run all of our traffic through the library to observe how it would perform over an extended period of time. This was critical for building confidence that we had covered all edge cases. Most importantly, by identifying edge cases where the implementations handled certain inputs differently, we could investigate if any of these had security-relevant consequences. \u003c/p\u003e\n\n\n\n\u003cp\u003eBy reviewing these exceptions, we were able to proactively identify incorrect behavior in either the new or old implementation. We also noticed during testing that ruby-saml rejected responses with multiple SAML assertions, while ours was more lenient. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile not completely wrong, we realized our implementation was trying to do too much. The information gained during this testing allowed us to safely augment our candidate code with new ideas and identify further areas of hardening like our next topic.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-schema-validations-and-minimizing-our-attack-surface\"\u003eSchema validations and minimizing our attack surface\u003c/h2\u003e\n\n\n\n\u003cp\u003eBefore looking into stricter input validation, we first have to dive into what makes up the inputs we need to validate. Through our review of industry vulnerabilities, our implementation, and related research, we identified two critical factors that make parsing and validating this input particularly challenging: \u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eThe relationship between enveloped XML signatures and the document structure\u003c/li\u003e\n\n\n\n\u003cli\u003eThe SAML schema flexibility\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch3 id=\"enveloped-xml-signatures\"\u003eEnveloped XML Signatures\u003c/h3\u003e\n\n\n\n\u003cp\u003eA key component of SAML is the \u003ca href=\"https://www.w3.org/TR/xmldsig-core1/\"\u003eXML signatures\u003c/a\u003e specification, which provides a way to sign and verify the integrity of SAML data. There are multiple ways to use XML signatures to sign data, but SAML relies primarily on \u003cstrong\u003eenveloped\u003c/strong\u003e XML signatures, where the signature itself is embedded within the element it covers. \u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s an example of a \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element with an enveloped XML signature:\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e\u0026lt;Response ID=\u0026#34;1234\u0026gt;\n   \u0026lt;Signature xmlns=\u0026#34;http://www.w3.org/2000/09/xmldsig#\u0026#34;\u0026gt;\n      \u0026lt;SignedInfo\u0026gt;\n         \u0026lt;CanonicalizationMethod Algorithm=\u0026#34;http://www.w3.org/2001/10/xml-exc-c14n#\u0026#34;\u0026gt;\u0026lt;/CanonicalizationMethod\u0026gt;\n         \u0026lt;SignatureMethod Algorithm=\u0026#34;http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\u0026#34;\u0026gt;\u0026lt;/SignatureMethod\u0026gt;\n         \u0026lt;Reference URI=\u0026#34;#1234\u0026#34;\u0026gt;\n            \u0026lt;Transforms\u0026gt;\n               \u0026lt;Transform Algorithm=\u0026#34;http://www.w3.org/2000/09/xmldsig#enveloped-signature\u0026#34;\u0026gt;\u0026lt;/Transform\u0026gt;\n               \u0026lt;Transform Algorithm=\u0026#34;http://www.w3.org/2001/10/xml-exc-c14n#\u0026#34;\u0026gt;\u0026lt;/Transform\u0026gt;\n            \u0026lt;/Transforms\u0026gt;\n            \u0026lt;DigestMethod Algorithm=\u0026#34;http://www.w3.org/2001/04/xmlenc#sha256\u0026#34;\u0026gt;\u0026lt;/DigestMethod\u0026gt;\n            \u0026lt;DigestValue\u0026gt;...\u0026lt;/DigestValue\u0026gt;\n         \u0026lt;/Reference\u0026gt;\n      \u0026lt;/SignedInfo\u0026gt;\n      \u0026lt;SignatureValue\u0026gt;...\u0026lt;/SignatureValue\u0026gt;\n      \u0026lt;KeyInfo\u0026gt;\n         \u0026lt;X509Data\u0026gt;\n            \u0026lt;X509Certificate\u0026gt;...\u0026lt;/X509Certificate\u0026gt;\n         \u0026lt;/X509Data\u0026gt;\n      \u0026lt;/KeyInfo\u0026gt;\n   \u0026lt;/Signature\u0026gt;\n\u0026lt;/Response\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eIn order to verify this signature, we performed some version of the following high-level process:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eFind the signature\u003c/strong\u003e: Locate the \u003ccode\u003e\u0026lt;Signature\u0026gt;\u003c/code\u003e element in the \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eExtract values\u003c/strong\u003e: Get the \u003ccode\u003e\u0026lt;SignatureValue\u0026gt;\u003c/code\u003e and \u003ccode\u003e\u0026lt;SignedInfo\u0026gt;\u003c/code\u003e from the \u003ccode\u003e\u0026lt;Signature\u0026gt;\u003c/code\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eExtract reference and digest\u003c/strong\u003e: From \u003ccode\u003e\u0026lt;SignedInfo\u0026gt;\u003c/code\u003e, extract the \u003ccode\u003e\u0026lt;Reference\u0026gt;\u003c/code\u003e (a pointer to the signed part of the document—note the URI attribute and the associated ID attribute on \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e) and \u003ccode\u003e\u0026lt;DigestValue\u0026gt;\u003c/code\u003e (a hashed version of \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e, minus the \u003ccode\u003e\u0026lt;Signature\u0026gt;\u003c/code\u003e).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eVerify the digest\u003c/strong\u003e: Apply the transformation instructions in the signature to the \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element and compare the results to the \u003ccode\u003e\u0026lt;DigestValue\u0026gt;\u003c/code\u003e.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eValidate integrity\u003c/strong\u003e: If the digest is valid, hash and encode \u003ccode\u003e\u0026lt;SignedInfo\u0026gt;\u003c/code\u003e using another algorithm, then use the configured public key (exchanged during SAML set up) to verify it against the \u003ccode\u003e\u0026lt;SignatureValue\u0026gt;\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eIf we get through this list of steps and the signature is valid, we assume that the \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element has not been tampered with. The interesting part about this is that to process the signature that legitimizes the \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element’s contents, we had to parse the \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element’s contents! \u003c/p\u003e\n\n\n\n\u003cp\u003ePut another way, \u003cstrong\u003ethe integrity of the SAML data is tied to its document structure, but that same document structure plays a critical role in how it is validated\u003c/strong\u003e. Herein lies the crux of many SAML validation vulnerabilities.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis troubling relationship between structure and integrity can be exploited, and has been many times. One of the more common classes of vulnerability is the XML signature wrapping attack, which involves tricking the library into trusting the wrong data. \u003c/p\u003e\n\n\n\n\u003cp\u003eSAML libraries typically deal with this by querying the document and rejecting unexpected or ambiguous input shapes. This strategy isn’t ideal because it still requires trusting the document before verifying its authenticity, so any small blunders can be targeted.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"lax-saml-schema-definitions\"\u003eLax SAML schema definitions\u003c/h3\u003e\n\n\n\n\u003cp\u003eSAML responses must be valid against the \u003ca href=\"https://docs.oasis-open.org/security/saml/v2.0/saml-schema-protocol-2.0.xsd\"\u003eSAML 2.0 XML schema definition (XSD)\u003c/a\u003e. XSD files are used to define the structure of XML, creating a contract between the sender and receiver about the sequence of elements, data types, and attributes. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis is exactly what we would look for in creating a clear set of inputs that we can easily limit parsing and validation around! Unfortunately, the SAML schema is quite flexible in what it allows, providing many opportunities for a document structure that would never appear in typical SAML responses.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor example, take a look at the SAML response below and notice the \u003ccode\u003e\u0026lt;StatusDetail\u0026gt;\u003c/code\u003e element. \u003ccode\u003e\u0026lt;StatusDetail\u0026gt;\u003c/code\u003e is one example in the spec that allows arbitrary data of any type and namespace to be added to the document. Consequently, including the elements \u003ccode\u003e\u0026lt;Foo\u0026gt;\u003c/code\u003e, \u003ccode\u003e\u0026lt;Bar\u0026gt;\u003c/code\u003e, and \u003ccode\u003e\u0026lt;Baz\u0026gt;\u003c/code\u003e into \u003ccode\u003e\u0026lt;StatusDetail\u0026gt;\u003c/code\u003e below would be completely valid given the SAML 2.0 schema. \u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e\u0026lt;Response xmlns=\u0026#34;urn:oasis:names:tc:SAML:2.0:protocol\u0026#34; Version=\u0026#34;2.0\u0026#34; ID=\u0026#34;_\u0026#34; IssueInstant=\u0026#34;1970-01-01T00:00:00.000Z\u0026#34;\u0026gt;\n  \u0026lt;Status\u0026gt;\n    \u0026lt;StatusCode Value=\u0026#34;urn:oasis:names:tc:SAML:2.0:status:Success\u0026#34;/\u0026gt;\n    \u0026lt;StatusDetail\u0026gt;\n      \u0026lt;Foo\u0026gt;\n        \u0026lt;Bar\u0026gt;\n          \u0026lt;Baz /\u0026gt;\n        \u0026lt;/Bar\u0026gt;\n      \u0026lt;/Foo\u0026gt;\n    \u0026lt;/StatusDetail\u0026gt;\n  \u0026lt;/Status\u0026gt;\n  \u0026lt;Assertion xmlns=\u0026#34;urn:oasis:names:tc:SAML:2.0:assertion\u0026#34; Version=\u0026#34;2.0\u0026#34; ID=\u0026#34;TEST\u0026#34; IssueInstant=\u0026#34;1970-01-01T00:00:00.000Z\u0026#34;\u0026gt;\n    \u0026lt;Issuer\u0026gt;issuer\u0026lt;/Issuer\u0026gt;\n    \u0026lt;Signature xmlns=\u0026#34;http://www.w3.org/2000/09/xmldsig#\u0026#34;\u0026gt;\n\tOmitted for Brevity...\n    \u0026lt;/Signature\u0026gt;\n    \u0026lt;Subject\u0026gt;\n      \u0026lt;NameID\u0026gt;\n        user@example.net\n      \u0026lt;/NameID\u0026gt;\n    \u0026lt;/Subject\u0026gt;\n  \u0026lt;/Assertion\u0026gt;\n\u0026lt;/Response\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eKnowing that the signature verification process is sensitive to the document structure, this is problematic. These schema possibilities leave gaps that your code must check. \u003c/p\u003e\n\n\n\n\u003cp\u003eConsider an implementation that does not correctly associate signatures with signed data, only validating the first signature it finds because it assumes that the signature should always be in the \u003ccode\u003e\u0026lt;Response\u0026gt;\u003c/code\u003e element (which encompasses the \u003ccode\u003e\u0026lt;Assertion\u0026gt;\u003c/code\u003e element), or in the \u003ccode\u003e\u0026lt;Assertion\u0026gt;\u003c/code\u003e element directly. This is where the signatures are located in the schema, after all. \u003c/p\u003e\n\n\n\n\u003cp\u003eTo exploit this, replace the contents of our previous example with a piece of correctly signed SAML data from the identity provider (remember that the schema allows any type of data in \u003ccode\u003e\u0026lt;StatusDetail\u0026gt;\u003c/code\u003e). Since the library only cares about the first signature it finds, it never verifies the \u003ccode\u003e\u0026lt;Assertion\u0026gt;\u003c/code\u003e signature in the example below, allowing an attacker to modify its contents to gain system access.\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e\u0026lt;Response xmlns=\u0026#34;urn:oasis:names:tc:SAML:2.0:protocol\u0026#34; Version=\u0026#34;2.0\u0026#34; ID=\u0026#34;_\u0026#34; IssueInstant=\u0026#34;1970-01-01T00:00:00.000Z\u0026#34;\u0026gt;\n  \u0026lt;Status\u0026gt;\n    \u0026lt;StatusCode Value=\u0026#34;urn:oasis:names:tc:SAML:2.0:status:Success\u0026#34;/\u0026gt;\n    \u0026lt;StatusDetail\u0026gt;\n    \t\u0026lt;Response Version=\u0026#34;2.0\u0026#34; ID=\u0026#34;TEST\u0026#34; IssueInstant=\u0026#34;1970-01-01T00:00:00.000Z\u0026#34;\u0026gt;\n        \u0026lt;Signature xmlns=\u0026#34;http://www.w3.org/2000/09/xmldsig#\u0026#34;\u0026gt;\n\t   Omitted for Brevity...\n        \u0026lt;/Signature\u0026gt;\n      \u0026lt;/Response\u0026gt;\n    \u0026lt;/StatusDetail\u0026gt;\n  \u0026lt;/Status\u0026gt;\n  \u0026lt;Assertion xmlns=\u0026#34;urn:oasis:names:tc:SAML:2.0:assertion\u0026#34; Version=\u0026#34;2.0\u0026#34; ID=\u0026#34;TEST\u0026#34; IssueInstant=\u0026#34;1970-01-01T00:00:00.000Z\u0026#34;\u0026gt;\n    \u0026lt;Issuer\u0026gt;issuer\u0026lt;/Issuer\u0026gt;\n    \u0026lt;Signature xmlns=\u0026#34;http://www.w3.org/2000/09/xmldsig#\u0026#34;\u0026gt;\n\tOmitted for Brevity...\n    \u0026lt;/Signature\u0026gt;\n    \u0026lt;Subject\u0026gt;\n      \u0026lt;NameID\u0026gt;\n        attacker-controller@example.net\n      \u0026lt;/NameID\u0026gt;\n    \u0026lt;/Subject\u0026gt;\n  \u0026lt;/Assertion\u0026gt;\n\u0026lt;/Response\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eThere are \u003cem\u003eso many\u003c/em\u003e \u003ca href=\"https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final91-8-23-12.pdf\"\u003edifferent permutations of vulnerabilities\u003c/a\u003e like this that depend on the loose SAML schema, including many that we have protected against in our internal implementation.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"limiting-the-attack-surface\"\u003eLimiting the attack surface\u003c/h3\u003e\n\n\n\n\u003cp\u003eWhile we can’t change how SAML works or the schema that defines it, what if we change the schema we validate it against? By making a stricter schema, we could enforce exactly the structure we expect to process, thereby reducing the likelihood of signature processing mistakes. Doing this would allow us to rule out bad data shapes before ever querying the document.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut in order to build a stricter schema, we first needed to confirm that the full SAML 2.0 schema wasn’t necessary. Our process began with bootstrapping: we gathered SAML responses from test accounts provided by our most widely integrated identity providers. \u003c/p\u003e\n\n\n\n\u003cp\u003eStarting small, we focused on Entra and Okta, which together accounted for nearly 85% of our SSO traffic volume. Using these responses, we crafted an initial schema based on real-world usage.\u003c/p\u003e\n\n\n\n\u003cp\u003eNext, we used Scientist to validate the schemas against our vast amount of production traffic. We first A/B tested with the very restrictive “bootstrapped” schema and gradually added back in the parts of the schema that we saw in anonymized traffic. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis allowed us to define a minimal schema that only contained the structures we saw in real-world requests. The same tooling we used for A/B testing allowed us to craft a minimal schema by iterating on the failures we saw across millions of requests.\u003c/p\u003e\n\n\n\n\u003cp\u003eHow did the “strict” schema turn out based on our real-world validation from identity providers? Below are some of the key takeaways and schema restrictions we now enforce:\u003c/p\u003e\n\n\n\n\u003ch4 id=\"h-ensure-signature-elements-are-only-where-you-expect-them-nbsp\"\u003eEnsure \u003ccode\u003eSignature\u003c/code\u003e elements are only where you expect them \u003c/h4\u003e\n\n\n\n\u003cp\u003eWe expect at most two elements to be signed: the \u003ccode\u003eResponse\u003c/code\u003e, and the \u003ccode\u003eAssertion\u003c/code\u003e, but we know the schema is more lenient. For example, we don’t expect the \u003ccode\u003eSubjectConfirmationData\u003c/code\u003e or \u003ccode\u003eAdvice\u003c/code\u003e elements to contain a signature, yet the following is a valid structure:\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e\u0026lt;samlp:Response ID=\u0026#34;response-id\u0026#34; xmlns:samlp=\u0026#34;urn:oasis:names:tc:SAML:2.0:protocol\u0026#34;\u0026gt;\n  \u0026lt;saml:Assertion ID=\u0026#34;signed-assertion-id\u0026#34;\u0026gt;\n    \u0026lt;ds:Signature\u0026gt;\n      \u0026lt;ds:SignedInfo\u0026gt;\n        \u0026lt;ds:Reference URI=\u0026#34;#signed-assertion-id\u0026#34; /\u0026gt;\n        ...\n      \u0026lt;/ds:SignedInfo\u0026gt;\n    \u0026lt;/ds:Signature\u0026gt;\n    \u0026lt;saml:Subject\u0026gt;\n      \u0026lt;saml:NameID\u0026gt;legitimate-user@example.com\u0026lt;/saml:NameID\u0026gt;\n      \u0026lt;saml:SubjectConfirmation\u0026gt;\n        \u0026lt;saml:SubjectConfirmationData\u0026gt;\n          \u0026lt;ds:Signature\u0026gt;...\u0026lt;/ds:Signature\u0026gt;\n        \u0026lt;/saml:SubjectConfirmationData\u0026gt;\n      \u0026lt;/saml:SubjectConfirmation\u0026gt;\n    \u0026lt;/saml:Subject\u0026gt;\n  \u0026lt;/saml:Assertion\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eThese are ambiguous situations that we can prevent. By removing \u003ccode\u003e\u0026lt;any\u0026gt;\u003c/code\u003e type elements, we can prevent additional signatures from being added to the document, and reduce the risk of attacks targeting flaws in signature selection logic.\u003c/p\u003e\n\n\n\n\u003ch4 id=\"its-safe-to-enforce-a-single-assertion-in-your-response\"\u003eIt’s safe to enforce a single assertion in your response \u003c/h4\u003e\n\n\n\n\u003cp\u003eThe SAML spec allows for an unbounded number of assertions:\u003c/p\u003e\n\n\n\n\u003cpre\u003e\u003ccode\u003e\u0026lt;choice minOccurs=\u0026#34;0\u0026#34; maxOccurs=\u0026#34;unbounded\u0026#34;\u0026gt;\n  \u0026lt;element ref=\u0026#34;saml:Assertion\u0026#34;/\u0026gt;\n  \u0026lt;element ref=\u0026#34;saml:EncryptedAssertion\u0026#34;/\u0026gt;\n\u0026lt;/choice\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\n\n\n\u003cp\u003eWe expect exactly one assertion, and most SAML libraries account for this invariant by querying and rejecting documents with multiple assertions. By removing the \u003ccode\u003eminOccurs\u003c/code\u003e and \u003ccode\u003emaxOccurs\u003c/code\u003e attributes from the schema’s assertion choice, we can reject responses containing multiple assertions ahead of time. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis matters because multiple assertions in the document lead to structures that are vulnerable to XML signature wrapping attacks. Enforcing a single assertion removes structural ambiguity around the most important part of the document. \u003c/p\u003e\n\n\n\n\u003ch4 id=\"remove-additional-elements-and-attributes-that-are-unused-in-practice-by-your-implementation\"\u003eRemove additional elements and attributes that are unused in practice by your implementation \u003c/h4\u003e\n\n\n\n\u003cp\u003eThis is probably the least specific piece of advice, but important: Removing what you don’t support from the existing schema will reduce the risk of your application code handling that input incorrectly. For example, if you don’t support \u003ccode\u003eEncryptedAssertions\u003c/code\u003e, you should probably omit those definitions from your schema all together to prevent your code from touching data it doesn’t expect.\u003c/p\u003e\n\n\n\n\u003ch4 id=\"it-is-safe-to-reject-document-type-definitions-dtds\"\u003eIt is safe to reject document type definitions (DTDs)\u003cstrong\u003e \u003c/strong\u003e\u003c/h4\u003e\n\n\n\n\u003cp\u003eWhile not strictly XSD related, we felt this was an important callout. DTDs are an older and more limited alternative to XSDs that add an unnecessary attack vector. Given that SAML 2.0 relies on schema definition files for validation, DTDs are both outdated and unnecessary, so we felt it best to disallow them altogether. In the wild, we never saw DTDs being used by identity providers.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe goal of a stricter SAML schema is to simplify working with SAML signatures and documents by removing ambiguity. By enforcing precise rules about where signatures should appear and their relationship to the data, validation becomes more straightforward and reliable. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhile stricter schemas don’t eliminate all risks—since signature processing also depends on implementation—they significantly reduce the attack surface, enhancing overall security and minimizing the complex parsing we need to reason about for validation.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"limiting-our-vulnerability-impact\"\u003eLimiting our vulnerability impact\u003c/h2\u003e\n\n\n\n\u003cp\u003eAt this point, we had made significant progress in addressing the risks associated with integrating ruby-saml and had restricted our critical inputs to a much smaller portion of the SAML schema. \u003c/p\u003e\n\n\n\n\u003cp\u003eBy implementing safeguards, validating critical code paths, and taking a deliberate approach to testing, we mitigated many of the uncertainties inherent in adopting a new library and of SAML in general. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, one fundamental truth remained: implementation vulnerabilities are inevitable, and we wanted to see what additional hardening we could apply to limit their impact.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"considering-a-compromise\"\u003eConsidering a compromise\u003c/h3\u003e\n\n\n\n\u003cp\u003eMigrating to ruby-saml fully would mean embracing a more modern, actively maintained codebase that addresses known vulnerabilities. It would also position us for better long-term maintainability with broad community support: one of the primary motivators for this initiative. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, replacing a core component like a SAML library isn’t without trade-offs. The risk of new vulnerabilities that weren’t surfaced during our work would always exist. With this in mind, we considered an alternative path: \u003cstrong\u003eInstead of relying entirely on one library, why not use both?\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eWe took this idea and ran with it by implementing a dual-parsing strategy and running both libraries independently and in parallel, requiring them to agree on validation before accepting a result. It might sound redundant and inefficient, but here’s why it worked to harden our implementation:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDefense in depth:\u003c/strong\u003e The two libraries parse SAML differently. Exploiting both would require two independent vulnerabilities that work in unison—a much taller order than compromising just one.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eBuilt-in feedback:\u003c/strong\u003e When they disagree, we are notified. This gives us the opportunity to identify and investigate potential security critical edge cases. We can then feed stricter validation logic from one library back into the other.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eNo pressure to rush:\u003c/strong\u003e Our original library is battle-tested and hardened. Using both together allows us to leverage its reliability while adopting the benefits of ruby-saml. We can always revisit this decision as we learn more about this strategy and its performance over time.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eWith this approach, we recognize that keeping something that works—when paired with something new—can be more powerful than replacing it outright. Of course, there are still risks involved. But by having two parsers, we increase our exposure of implementation vulnerabilities in our XML parsing code: things like memory corruption or \u003ca href=\"https://securitylab.github.com/research/restlet_xml_external_entity_expansion_CVE-2017-14868/\"\u003eXML external entity vulnerabilities\u003c/a\u003e. We also increase the burden of having to maintain two libraries. \u003c/p\u003e\n\n\n\n\u003cp\u003eDespite this, we decided that this risk and time investment is worth the increased resilience to the complex validation logic that is the core to the historical and critical vulnerabilities we’ve seen. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"learn-from-our-blueprint\"\u003eLearn from our blueprint\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile our original goal was to “just” move to a new SAML library, we ended up taking the opportunity to reduce the risk profile of our entire SAML implementation. \u003c/p\u003e\n\n\n\n\u003cp\u003eBy investing in upfront code review, security testing, and A/B testing and validation, we’ve gained confidence in the implementation of this new library. We then decreased the complexity of these code paths by restricting our allowed schema to one that is minimized using real world data. Finally, we’ve limited the impact of a single vulnerability found in either library by combining the strengths of both ruby-saml and our internal implementation.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs this code continues to parse almost a million SAML responses per day, our robust logging and exception handling will provide us with the observability needed to adjust our strategy or identify new hardening opportunities. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis experience should provide any team with a great blueprint on how to approach other complex or dangerous parts of a codebase they may be tasked with maintaining or hardening—and a reminder that incremental, data-driven experiments and compromises can sometimes lead to unexpected outcomes.\u003c/p\u003e\n\n\n\n\n\n\t\n\n\t\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tWritten by\t\u003c/h2\u003e\n\t\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/427255?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/427255?v=4\u0026amp;s=200\" alt=\"Greg Ose\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\t\t\t\t\n\t\t\t\t\t\u003cp\u003ePrincipal Product Security Engineer\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/76077878?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/76077878?v=4\u0026amp;s=200\" alt=\"Taylor Reis\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\t\t\t\t\n\t\t\t\t\t\u003cp\u003eSoftware Engineer III\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\u003c/div\u003e",
  "readingTime": "30 min read",
  "publishedTime": "2025-05-27T16:00:00Z",
  "modifiedTime": null
}
