{
  "id": "3e425fcf-a1fc-43f5-a6bd-95bb3f8daeb3",
  "title": "Open source AI is already finding its way into production",
  "link": "https://github.blog/ai-and-ml/generative-ai/open-source-ai-is-already-finding-its-way-into-production/",
  "description": "Open source AI models are in widespread use, enabling developers around the world to build custom AI solutions and host them where they choose. The post Open source AI is already finding its way into production appeared first on The GitHub Blog.",
  "author": "Klint Finley",
  "published": "Tue, 28 Jan 2025 17:00:38 +0000",
  "source": "https://github.blog/feed/",
  "categories": [
    "AI \u0026 ML",
    "Generative AI"
  ],
  "byline": "Klint Finley",
  "length": 7855,
  "excerpt": "Open source AI models are in widespread use, enabling developers around the world to build custom AI solutions and host them where they choose.",
  "siteName": "The GitHub Blog",
  "favicon": "https://github.blog/wp-content/uploads/2019/01/cropped-github-favicon-512.png?fit=192%2C192",
  "text": "Open source has long driven innovation and the adoption of cutting-edge technologies, from web interfaces to cloud-native computing. The same is true in the burgeoning field of open source artificial intelligence (AI). Open source AI models, and the tooling to build and use them, are multiplying, enabling developers around the world to build custom AI solutions and host them where they choose. It’s happening faster than you might realize. In our survey of 2,000 enterprise respondents on software development teams across the US, Germany, India, and Brazil, nearly everyone said they had experimented with open source AI models at some point. The survey didn’t specifically ask about generative AI models and large language models (LLM), so these results could include other types of AI and machine learning models. Notably, we conducted our survey before the Open Source Institute published their definition of open source AI. But the survey results suggest that the use of open source AI models is already surprisingly widespread—and this is expected to grow as more models proliferate and more use cases emerge. Let’s take a look at the rise of open source AI, from the increasing rise of smaller models to use cases in generative AI. In this article we will: Explore how and why companies are using open source AI models in production today. Learn how open source is changing the way developers use AI. Look ahead at how small, open source models might be used in the future. Why use smaller, more open models? Open, or at least less-proprietary, models like the DeepSeek models, Meta’s Llama models, or those from Mistral AI can generally be downloaded and run on your own devices and, depending on the license, you can study and change how they work. Many are trained on smaller, more focused data sets. These models are sometimes referred to as small language models (SLMs), and they’re beginning to rival the performance of LLMs in some scenarios. There are a number of benefits of working with these smaller models, explains Head of GitHub Next, Idan Gazit. They cost less to run and can be run in more places, including end-user devices. But perhaps most importantly, they’re easier to customize. While LLMs excel with general purpose chatbots that need to respond to a wide variety of questions, organizations tend to turn to smaller AI models when they need niche solutions, explains Hamel Husain, an AI consultant and former GitHub employee. For instance, with an open source LLM you can define a grammar and require that a model only outputs valid tokens according to that grammar. “Open models aren’t always better, but the more narrow your task, the more open models will shine because you can fine tune that model and really differentiate them,” says Husain. For example, an observability platform company hired Husain to help build a solution that could translate natural language into the company’s custom query language to make it easier for customers to craft queries without having to learn the ins-and-outs of the query language. This was a narrow use case—they only needed to generate their own query language and no others, and they needed to ensure it produced valid syntax. “Their query language is not something that is prevalent as let’s say Python, so the model hadn’t seen many examples,” Husain says. “That made fine tuning more helpful than it would have been with a less esoteric topic.” The company also wanted to maintain control over all data handled by the LLM without having to work with a third party. Husain ended up building a custom solution using the then-latest version of Mistral AI’s widely used open models. “I typically use popular models because they’ve generally been fine-tuned already and there’s usually a paved path towards implementing them,” he says. Open source brings structure to the world of LLMs One place you can see the rapid adoption of open source models is in tools designed to work with them. For example, Outlines is an increasingly popular tool for building custom LLM applications with both open source and proprietary models. It helps developers define structures for LLM outputs. You can use it, for example, to ensure an LLM outputs responses in JSON format. It was created in large part because of the need for finely tuned, task-specific AI applications. At a previous job, Outlines co-creator and maintainer Rémi Louf needed to extract some information from a large collection of documents and export it in JSON format. He and his colleague Brandon Willard tried using general purpose LLMs like ChatGPT for the task, but they had trouble producing well-structured JSON outputs. Louf and Willard both had a background in compilers and interpreters, and noticed a similarity between building compilers and structuring the output of LLMs. They built Outlines to solve their own problems. They posted the project to Hacker News and it took off quickly. “It turns out that a lot of other people were frustrated with not being able to use LLMs to output to a particular structure reliably,” Louf says. The team kept working on it, expanding its features and founding a startup. It now has more than 100 contributors and helped inspire OpenAI’s structured outputs feature. “I can’t give names, but some very large companies are using Outlines in production,” Louf says. What’s next There are, of course, downsides to building custom solutions with open source models. One of the biggest is the need to invest time and resources into prompt construction. And, depending on your application, you may need to stand up and manage the underlying infrastructure as well. All of that requires more engineering resources than using an API. “Sometimes organizations want more control over their infrastructure,” Husain says. “They want predictable costs and latency and are willing to make decisions about those tradeoffs themselves.” While open source AI models might not be a good fit for every problem, it’s still the early days. As small models continue to improve, new possibilities emerge, from running models on local hardware to embedding custom LLMs within existing applications. Fine-tuned small models can already outperform larger models for certain tasks. Gazit expects developers will combine different small, customized models together and use them to complete different tasks. For example, an application might route a prompt with a question about the best way to implement a database to one model, while routing a prompt for code completion to another. “The strengths of many Davids might be mightier than one Goliath,” he says. In the meantime, large, proprietary models will also keep improving, and you can expect both large and small model development to feed off of each other. “In the near term, there will be another open source revolution,” Louf says. “Innovation often comes from people who are resource constrained.” Ready to experiment with open source AI? GitHub Models offers a playground for both open source and proprietary models. You can use the public preview to prototype AI applications, conduct side-by-side comparisons, and more. Get started with GitHub Models for free. Just pick a model and click \u003e_ Playground to begin. Written by Explore more from GitHub Docs Everything you need to master GitHub, all in one place. Go to Docs GitHub Build what’s next on GitHub, the place for anyone from anywhere to build anything. Start building Customer stories Meet the companies and engineering teams that build with GitHub. Learn more Work at GitHub! Check out our current job openings. Apply now",
  "image": "https://github.blog/wp-content/uploads/2024/06/AI-DarkMode-4.png?fit=1200%2C630",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection\u003e\n\t\n\u003cp\u003eOpen source has long driven innovation and the adoption of cutting-edge technologies, from web interfaces to cloud-native computing. The same is true in the burgeoning field of open source artificial intelligence (AI). Open source AI models, and the tooling to build and use them, are multiplying, enabling developers around the world to build custom AI solutions and host them where they choose.\u003c/p\u003e\n\u003cp\u003eIt’s happening faster than you might realize. In our \u003ca href=\"https://github.blog/news-insights/research/survey-ai-wave-grows/\"\u003esurvey of 2,000 enterprise respondents on software development teams across the US, Germany, India, and Brazil\u003c/a\u003e, nearly everyone said they had experimented with open source AI models at some point. The survey didn’t specifically ask about generative AI models and large language models (LLM), so these results could include other types of AI and machine learning models. Notably, we conducted our survey before the Open Source Institute published their \u003ca href=\"https://opensource.org/ai/open-source-ai-definition\"\u003edefinition of open source AI\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBut the survey results suggest that the use of open source AI models is already surprisingly widespread—and this is expected to grow as more models proliferate and more use cases emerge. Let’s take a look at the rise of open source AI, from the increasing rise of smaller models to use cases in generative AI.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIn this article we will:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplore how and why companies are using open source AI models in production today.  \u003c/li\u003e\n\u003cli\u003eLearn how open source is changing the way developers use AI.  \u003c/li\u003e\n\u003cli\u003eLook ahead at how small, open source models might be used in the future.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"why-use-smaller-more-open-models\" id=\"why-use-smaller-more-open-models\"\u003eWhy use smaller, more open models?\u003ca href=\"#why-use-smaller-more-open-models\" aria-label=\"Why use smaller, more open models?\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOpen, or at least less-proprietary, models like the DeepSeek models, Meta’s Llama models, or those from Mistral AI can generally be downloaded and run on your own devices and, depending on the license, you can study and change how they work.  Many are trained on smaller, more focused data sets. These models are sometimes referred to as small language models (SLMs), and they’re beginning to rival the performance of LLMs in some scenarios.\u003c/p\u003e\n\n\u003cp\u003eThere are a number of benefits of working with these smaller models, explains Head of GitHub Next, Idan Gazit. They cost less to run and can be run in more places, including end-user devices. But perhaps most importantly, they’re easier to customize.\u003c/p\u003e\n\u003cp\u003eWhile LLMs excel with general purpose chatbots that need to respond to a wide variety of questions, organizations tend to turn to smaller AI models when they need niche solutions, explains Hamel Husain, an AI consultant and former GitHub employee. For instance, with an open source LLM you can define a  grammar and require that a model only outputs valid tokens according to that grammar.\u003c/p\u003e\n\u003cp\u003e“Open models aren’t always better, but the more narrow your task, the more open models will shine because you can fine tune that model and really differentiate them,” says Husain.\u003c/p\u003e\n\u003cp\u003eFor example, an observability platform company hired Husain to help build a solution that could translate natural language into the company’s custom query language to make it easier for customers to craft queries without having to learn the ins-and-outs of the query language.\u003c/p\u003e\n\u003cp\u003eThis was a narrow use case—they only needed to generate their own query language and no others, and they needed to ensure it produced valid syntax. “Their query language is not something that is prevalent as let’s say Python, so the model hadn’t seen many examples,” Husain says. “That made fine tuning more helpful than it would have been with a less esoteric topic.” The company also wanted to maintain control over all data handled by the LLM without having to work with a third party.\u003c/p\u003e\n\u003cp\u003eHusain ended up building a custom solution using the then-latest version of \u003ca href=\"https://github.com/marketplace?type=models\u0026amp;model_family=Mistral%20AI\"\u003eMistral AI’s widely used open models\u003c/a\u003e. “I typically use popular models because they’ve generally been fine-tuned already and there’s usually a paved path towards implementing them,” he says.\u003c/p\u003e\n\u003ch2 id=\"open-source-brings-structure-to-the-world-of-llms\" id=\"open-source-brings-structure-to-the-world-of-llms\"\u003eOpen source brings structure to the world of LLMs\u003ca href=\"#open-source-brings-structure-to-the-world-of-llms\" aria-label=\"Open source brings structure to the world of LLMs\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOne place you can see the rapid adoption of open source models is in tools designed to work with them. For example, \u003ca href=\"https://github.com/dottxt-ai/outlines\"\u003eOutlines\u003c/a\u003e is an increasingly popular tool for building custom LLM applications with both open source and proprietary models. It helps developers define structures for LLM outputs. You can use it, for example, to ensure an LLM outputs responses in JSON format. It was created in large part because of the need for finely tuned, task-specific AI applications.\u003c/p\u003e\n\u003cp\u003eAt a previous job, Outlines co-creator and maintainer Rémi Louf needed to extract some information from a large collection of documents and export it in JSON format. He and his colleague Brandon Willard tried using general purpose LLMs like ChatGPT for the task, but they had trouble producing well-structured JSON outputs. Louf and Willard both had a background in compilers and interpreters, and noticed a similarity between building compilers and structuring the output of LLMs. They built Outlines to solve their own problems.\u003c/p\u003e\n\u003cp\u003eThey posted the project to Hacker News and it took off quickly. “It turns out that a lot of other people were frustrated with not being able to use LLMs to output to a particular structure reliably,” Louf says. The team kept working on it, expanding its features and \u003ca href=\"https://techcrunch.com/2024/10/17/with-11-9-million-in-funding-dottxt-tells-ai-models-how-to-answer/?guccounter=1\"\u003efounding a startup\u003c/a\u003e. It now has more than 100 contributors and \u003ca href=\"https://openai.com/index/introducing-structured-outputs-in-the-api/\"\u003ehelped inspire OpenAI’s structured outputs feature\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e“I can’t give names, but some very large companies are using Outlines in production,” Louf says.\u003c/p\u003e\n\u003ch2 id=\"whats-next\" id=\"whats-next\"\u003eWhat’s next\u003ca href=\"#whats-next\" aria-label=\"What’s next\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThere are, of course, downsides to building custom solutions with open source models. One of the biggest is the need to invest time and resources into prompt construction. And, depending on your application, you may need to \u003ca href=\"https://opensauced.pizza/blog/how-we-saved-thousands-of-dollars-deploying-low-cost-open-source-ai-technologies\"\u003estand up and manage the underlying infrastructure\u003c/a\u003e as well. All of that requires more engineering resources than using an API.\u003c/p\u003e\n\u003cp\u003e“Sometimes organizations want more control over their infrastructure,” Husain says. “They want predictable costs and latency and are willing to make decisions about those tradeoffs themselves.”\u003c/p\u003e\n\u003cp\u003eWhile open source AI models might not be a good fit for every problem, it’s still the early days. As small models continue to improve, new possibilities emerge, from running models on local hardware to embedding custom LLMs within existing applications.\u003c/p\u003e\n\u003cp\u003eFine-tuned small models can already \u003ca href=\"https://www.nature.com/articles/s41746-024-01239-w\"\u003eoutperform larger models for certain tasks\u003c/a\u003e. Gazit expects developers will combine different small, customized models together and use them to complete different tasks. For example, an application might route a prompt with a question about the best way to implement a database to one model, while routing a prompt for code completion to another. “The strengths of many Davids might be mightier than one Goliath,” he says.\u003c/p\u003e\n\u003cp\u003eIn the meantime, large, proprietary models will also keep improving, and you can expect both large and small model development to feed off of each other. “In the near term, there will be another open source revolution,” Louf says. “Innovation often comes from people who are resource constrained.”\u003c/p\u003e\n\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eReady to experiment with open source AI?\u003c/strong\u003e GitHub Models offers a playground for both open source and proprietary models. You can use the public preview to prototype AI applications, conduct side-by-side comparisons, and more.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/marketplace/models\"\u003eGet started with GitHub Models for free\u003c/a\u003e. Just pick a model and click \u003ccode\u003e\u0026gt;_ Playground\u003c/code\u003e to begin.\u003c/p\u003e\n\u003c/div\u003e\n\n\t\t\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tWritten by\t\u003c/h2\u003e\n\t\n\t\t\t\u003carticle\u003e\n\t\u003cdiv\u003e\n\t\t\t\t\u003cpicture\u003e\n\t\t\t\t\t\u003csource srcset=\"https://avatars.githubusercontent.com/u/957053?v=4\u0026amp;s=200\" width=\"120\" height=\"120\" media=\"(min-width: 768px)\"/\u003e\n\t\t\t\t\t\u003cimg src=\"https://avatars.githubusercontent.com/u/957053?v=4\u0026amp;s=200\" alt=\"Klint Finley\" width=\"80\" height=\"80\" loading=\"lazy\" decoding=\"async\"/\u003e\n\t\t\t\t\u003c/picture\u003e\n\t\t\t\u003c/div\u003e\n\u003c/article\u003e\n\t\u003c/div\u003e\n\u003c/section\u003e\u003cdiv\u003e\n\t\u003ch2\u003e\n\t\tExplore more from GitHub\t\u003c/h2\u003e\n\t\u003cdiv\u003e\n\t\t\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon-Circle.svg\" width=\"44\" height=\"44\" alt=\"Docs\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tDocs\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eEverything you need to master GitHub, all in one place.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Go to Docs; ref_location:bottom recirculation;\" href=\"https://docs.github.com/\" target=\"_blank\" aria-label=\"Go to Docs\"\u003e\n\t\t\t\t\tGo to Docs\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon_95220f.svg\" width=\"44\" height=\"44\" alt=\"GitHub\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tGitHub\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eBuild what’s next on GitHub, the place for anyone from anywhere to build anything.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Start building; ref_location:bottom recirculation;\" href=\"https://github.blog/developer-skills/github/\" target=\"_blank\" aria-label=\"Start building\"\u003e\n\t\t\t\t\tStart building\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 16 16\" fill=\"none\"\u003e\u003cpath fill=\"currentColor\" d=\"M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z\"\u003e\u003c/path\u003e\u003cpath stroke=\"currentColor\" d=\"M1.75 8H11\" stroke-width=\"1.5\" stroke-linecap=\"round\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2024/07/Icon_da43dc.svg\" width=\"44\" height=\"44\" alt=\"Customer stories\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tCustomer stories\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eMeet the companies and engineering teams that build with GitHub.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Learn more; ref_location:bottom recirculation;\" href=\"https://github.com/customer-stories\" target=\"_blank\" aria-label=\"Learn more\"\u003e\n\t\t\t\t\tLearn more\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\u003cdiv\u003e\n\t\t\u003cp\u003e\u003cimg src=\"https://github.blog/wp-content/uploads/2022/05/careers.svg\" width=\"44\" height=\"44\" alt=\"Work at GitHub!\"/\u003e\u003c/p\u003e\u003ch3\u003e\n\t\t\tWork at GitHub!\t\t\u003c/h3\u003e\n\t\t\u003cp\u003eCheck out our current job openings.\u003c/p\u003e\n\t\t\t\t\t\u003cp\u003e\n\t\t\t\t\u003ca data-analytics-click=\"Blog, click on module, text: Apply now; ref_location:bottom recirculation;\" href=\"https://www.github.careers/careers-home\" target=\"_blank\" aria-label=\"Apply now\"\u003e\n\t\t\t\t\tApply now\t\t\t\t\t\t\t\t\t\t\t\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\"\u003e\u003cpath fill-rule=\"evenodd\" d=\"M10.604 1h4.146a.25.25 0 01.25.25v4.146a.25.25 0 01-.427.177L13.03 4.03 9.28 7.78a.75.75 0 01-1.06-1.06l3.75-3.75-1.543-1.543A.25.25 0 0110.604 1zM3.75 2A1.75 1.75 0 002 3.75v8.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 12.25v-3.5a.75.75 0 00-1.5 0v3.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-8.5a.25.25 0 01.25-.25h3.5a.75.75 0 000-1.5h-3.5z\"\u003e\u003c/path\u003e\u003c/svg\u003e\n\t\t\t\t\t\t\t\t\t\u003c/a\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\t\u003c/div\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-01-28T17:00:38Z",
  "modifiedTime": "2025-01-28T00:23:54Z"
}
