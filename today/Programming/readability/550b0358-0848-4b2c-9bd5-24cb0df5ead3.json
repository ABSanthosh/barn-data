{
  "id": "550b0358-0848-4b2c-9bd5-24cb0df5ead3",
  "title": "Gemini Embedding now generally available in the Gemini API",
  "link": "https://developers.googleblog.com/en/gemini-embedding-available-gemini-api/",
  "description": "The Gemini Embedding text model is now generally available in the Gemini API and Vertex AI. This versatile model has consistently ranked #1 on the MTEB Multilingual leaderboard since its experimental launch in March, supports over 100 languages, has a 2048 maximum input token length, and is priced at $0.15 per 1M input tokens.",
  "author": "",
  "published": "",
  "source": "http://feeds.feedburner.com/GDBcode",
  "categories": null,
  "byline": "Min Choi, Janie Zhang",
  "length": 4375,
  "excerpt": "The Gemini Embedding text model is now generally available in the Gemini API and Vertex AI. This versatile model has consistently ranked #1 on the MTEB Multilingual leaderboard since its experimental launch in March, supports over 100 languages, has a 2048 maximum input token length, and is priced at $0.15 per 1M input tokens.",
  "siteName": "",
  "favicon": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/meta/apple-touch-icon.png",
  "text": "Products More Solutions Events Learn Community Developer Program Blog We’re excited to announce that our first Gemini Embedding text model (gemini-embedding-001) is now generally available to developers in the Gemini API and Vertex AI.This embedding model has consistently held a top spot on the Massive Text Embedding Benchmark (MTEB) Multilingual leaderboard since the experimental launch in March.Surpassing both our previous text embedding models and external offerings in diverse tasks, from retrieval to classification, gemini-embedding-001 provides a unified cutting edge experience across domains, including science, legal, finance, and coding. Here is how Gemini Embedding compares to other commercially available proprietary models: *Legacy Google models are a combination of the highest scores from 3 Gemini API and VertexAI models: text-embedding-004, text-embedding-005, and text-multilingual-embedding-002 More detailed results are available in our technical report*.Model detailsAn incredibly versatile model, Gemini Embedding supports over 100 languages and has a 2048 maximum input token length.It also utilizes the Matryoshka Representation Learning (MRL) technique, which allows developers to scale the output dimensions down from the default 3072. This flexibility enables you to optimize for performance and storage costs to fit your specific needs. For the highest quality results, we recommend using 3072, 1536, or 768 output dimensions.Rate limits and pricingWe offer both free and paid tiers in the Gemini API, so you can experiment with gemini-embedding-001 at no cost, or ramp up with significantly higher limits for your production needs.The Gemini Embedding model is priced at $0.15 per 1M input tokens.Start building with Gemini EmbeddingDevelopers can now access the Gemini Embedding model (gemini-embedding-001) via the Gemini API, which you can start working with for free through Google AI Studio.It’s compatible with the existing embed_content endpoint. from google import genai client = genai.Client() result = client.models.embed_content( model=\"gemini-embedding-001\", contents=\"What is the meaning of life?\" ) print(result.embeddings) Python Copied To get started, check out the official developer documentation and cookbooks:Embeddings documentationQuickstart notebookIf you are using the experimental gemini-embedding-exp-03-07, you won’t need to re-embed your contents but it will no longer be supported by the Gemini API on August 14, 2025. Legacy models will also be deprecated in the coming months:embedding-001 on August 14, 2025 andtext-embedding-004 on January 14, 2026We highly recommend migrating your projects to our newest model as early as possible.We can't wait to see how Gemini Embedding unlocks new use cases that weren’t previously possible. In addition, we will have support for Gemini Embedding in the Batch API soon, which enables asynchronous processing of your data for lower costs.Keep an eye out for future announcements regarding embedding models with even broader modalities and capabilities!*MTEB benchmark results in the published paper reflect the experimental version of Gemini Embedding, launched in March 2025.",
  "image": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/unnamed_42.2e16d0ba.fill-1200x600.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\n        \n        \n        \n\n        \n\n\t\t\t\t\n        \n\n\n\n\n\u003cdiv top-level-nav=\"\"\u003e\n  \u003cnav aria-label=\"Side menu\"\u003e\n    \n    \u003cdiv\u003e\n        \u003cul\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/products\" data-label=\"Tab: Products\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Products\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \u003cspan tabindex=\"0\" data-label=\"More Products\"\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    More\n                  \u003c/span\u003e\n                  \u003cspan menu=\"Products\"\u003e\n                    \n                  \u003c/span\u003e\n                \u003c/span\u003e\n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/solutions/catalog\" data-label=\"Tab: Solutions\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Solutions\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/events\" data-label=\"Tab: Events\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Events\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/learn\" data-label=\"Tab: Learn\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Learn\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/community\" data-label=\"Tab: Community\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Community\n             \u003c/span\u003e\n            \u003c/a\u003e\n            \u003cul\u003e\n              \u003cli\u003e\n                \n              \u003c/li\u003e\n            \u003c/ul\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.google.com/profile/u/me\" data-label=\"Tab: Developer Program\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Developer Program\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n          \u003cli\u003e\n            \u003ca href=\"https://developers.googleblog.com/\" data-label=\"Tab: Blog\"\u003e\n              \u003cspan tooltip=\"\"\u003e\n                Blog\n             \u003c/span\u003e\n            \u003c/a\u003e\n          \u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/div\u003e\n  \u003c/nav\u003e\n  \u003c/div\u003e\n\n\n\n        \n  \u003cdiv\u003e\n\n    \n      \n    \n\n    \n\n    \n\n    \n\n    \n    \u003cdiv\u003e\n          \n\n\u003cdiv\u003e\n    \u003cp data-block-key=\"lztc3\"\u003eWe’re excited to announce that our first Gemini Embedding text model (\u003ccode\u003egemini-embedding-001\u003c/code\u003e) is now generally available to developers in the Gemini API and Vertex AI.\u003c/p\u003e\u003cp data-block-key=\"frsrq\"\u003eThis embedding model has consistently held a top spot on the Massive Text Embedding Benchmark (MTEB) Multilingual \u003ca href=\"https://huggingface.co/spaces/mteb/leaderboard\"\u003eleaderboard\u003c/a\u003e since the \u003ca href=\"https://developers.googleblog.com/en/gemini-embedding-text-model-now-available-gemini-api/\"\u003eexperimental launch\u003c/a\u003e in March.\u003c/p\u003e\u003cp data-block-key=\"31fe2\"\u003eSurpassing both our previous text embedding models and external offerings in diverse tasks, from retrieval to classification, \u003ccode\u003egemini-embedding-001\u003c/code\u003e provides a unified cutting edge experience across domains, including science, legal, finance, and coding. Here is how Gemini Embedding compares to other commercially available proprietary models:\u003c/p\u003e\n\u003c/div\u003e   \n\n\n    \n    \u003cdiv\u003e\n            \n                \u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EmbedingsChart_16x9_RD2-V01.original.jpg\" alt=\"Embedings Chart\"/\u003e\u003c/p\u003e\u003cp\u003e\n                        *Legacy Google models are a combination of the highest scores from 3 Gemini API and VertexAI models: text-embedding-004, text-embedding-005, and text-multilingual-embedding-002\n                    \u003c/p\u003e\n                \n            \n        \u003c/div\u003e\n  \u003cdiv\u003e\n    \u003cp data-block-key=\"lztc3\"\u003eMore detailed results are available in our \u003ca href=\"https://arxiv.org/abs/2503.07891\"\u003etechnical report\u003c/a\u003e*.\u003c/p\u003e\u003ch2 data-block-key=\"1touu\" id=\"model-details\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eModel details\u003c/h2\u003e\u003cp data-block-key=\"c0o4m\"\u003eAn incredibly versatile model, Gemini Embedding supports over 100 languages and has a 2048 maximum input token length.\u003c/p\u003e\u003cp data-block-key=\"8p364\"\u003eIt also utilizes the Matryoshka Representation Learning (MRL) technique, which allows developers to scale the output dimensions down from the default 3072. This flexibility enables you to optimize for performance and storage costs to fit your specific needs. For the highest quality results, we recommend using 3072, 1536, or 768 output dimensions.\u003c/p\u003e\u003ch2 data-block-key=\"oy255\" id=\"rate-limits-and-pricing\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eRate limits and pricing\u003c/h2\u003e\u003cp data-block-key=\"19mee\"\u003eWe offer both \u003ca href=\"https://ai.google.dev/gemini-api/docs/rate-limits\"\u003efree and paid tiers\u003c/a\u003e in the Gemini API, so you can experiment with \u003ccode\u003egemini-embedding-001\u003c/code\u003e at no cost, or ramp up with significantly higher limits for your production needs.\u003c/p\u003e\u003cp data-block-key=\"me2o\"\u003eThe Gemini Embedding model is \u003ca href=\"https://ai.google.dev/gemini-api/docs/pricing\"\u003epriced\u003c/a\u003e at \u003cb\u003e$0.15 per 1M input tokens\u003c/b\u003e.\u003c/p\u003e\u003ch2 data-block-key=\"tqq8w\" id=\"start-building-with-gemini-embedding\"\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eStart building with Gemini Embedding\u003c/h2\u003e\u003cp data-block-key=\"55ig6\"\u003eDevelopers can now access the Gemini Embedding model (\u003ccode\u003egemini-embedding-001\u003c/code\u003e) via the Gemini API, which you can start working with for free through \u003ca href=\"https://aistudio.google.com/\"\u003eGoogle AI Studio\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"cifn5\"\u003eIt’s compatible with the existing \u003ci\u003eembed_content\u003c/i\u003e endpoint.\u003c/p\u003e\n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cpre\u003e\u003ccode\u003efrom google import genai\n\nclient = genai.Client()\n\nresult = client.models.embed_content(\n        model=\u0026#34;gemini-embedding-001\u0026#34;,\n        contents=\u0026#34;What is the meaning of life?\u0026#34;\n)\n\nprint(result.embeddings)\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003e\n        Python\n    \u003c/p\u003e\n    \u003cp\u003e\u003cspan\u003eCopied\u003c/span\u003e\n        \n    \u003c/p\u003e\n    \n    \n\u003c/div\u003e  \u003cdiv\u003e\n    \u003cp data-block-key=\"lztc3\"\u003eTo get started, check out the official developer documentation and cookbooks:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"pvj5\"\u003e\u003ca href=\"https://ai.google.dev/gemini-api/docs/embeddings\"\u003eEmbeddings documentation\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"8fhm1\"\u003e\u003ca href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb\"\u003eQuickstart notebook\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"45hsk\"\u003eIf you are using the experimental \u003ci\u003egemini-embedding-exp-03-07,\u003c/i\u003e you won’t need to re-embed your contents but it will no longer be supported by the Gemini API on August 14, 2025. Legacy models will also be deprecated in the coming months:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"e9et4\"\u003e\u003ci\u003eembedding-001\u003c/i\u003e on August 14, 2025 and\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli data-block-key=\"6jo7l\"\u003e\u003ci\u003etext-embedding-004\u003c/i\u003e on January 14, 2026\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"a9kqa\"\u003eWe highly recommend migrating your projects to our newest model as early as possible.\u003c/p\u003e\u003cp data-block-key=\"3hn97\"\u003eWe can\u0026#39;t wait to see how Gemini Embedding unlocks new use cases that weren’t previously possible. In addition, we will have support for Gemini Embedding in the \u003ca href=\"https://developers.googleblog.com/en/scale-your-ai-workloads-batch-mode-gemini-api/\"\u003eBatch API\u003c/a\u003e soon, which enables asynchronous processing of your data for lower costs.\u003c/p\u003e\u003cp data-block-key=\"oriv\"\u003eKeep an eye out for future announcements regarding embedding models with even broader modalities and capabilities!\u003c/p\u003e\u003chr/\u003e\u003cp data-block-key=\"3v2m0\"\u003e*\u003csub\u003eMTEB benchmark results in the published paper reflect the experimental version of Gemini Embedding, launched in March 2025.\u003c/sub\u003e\u003c/p\u003e\n\u003c/div\u003e \n      \u003c/div\u003e\n    \n\n    \n\n    \n    \n    \n  \u003c/div\u003e\n\n\n\t\t\t\t\n\t\t\t\t\n\n\n\n\n\n        \n\t\t\t\t\n\n        \n        \n        \n        \n\n        \n\n        \n  \n  \n\n    \n\n\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-07-14T00:00:00Z",
  "modifiedTime": null
}
