{
  "id": "058dd07f-7fd3-498b-a92a-68da972be3f5",
  "title": "ByteDance’s Deepfake Tool Creates Convincing Videos From One Photo",
  "link": "https://petapixel.com/2025/02/05/bytedances-deepfake-tool-creates-convincing-videos-from-one-photo/",
  "description": "Watch the short talking head video below. Granted, it is in French, and close inspection of it may raise suspicions but perhaps caught unaware it could well fool people into believing it is a real video and not AI-generated. [Read More]",
  "author": "Matt Growcoot",
  "published": "Wed, 05 Feb 2025 17:10:46 +0000",
  "source": "https://petapixel.com/feed/",
  "categories": [
    "News",
    "Technology",
    "aivideo",
    "aivideogenerator",
    "bytedance",
    "deepfake",
    "generativeai",
    "tiktok"
  ],
  "byline": "Matt Growcoot",
  "length": 2886,
  "excerpt": "ByteDance is the company behind TikTok.",
  "siteName": "PetaPixel",
  "favicon": "https://petapixel.com/wp-content/themes/petapixel-2017/assets/prod/img/apple-touch-icon-180x180.png",
  "text": "A talking AI-generated Albert Einstein. Watch the short talking head video below. Granted, it is in French, and close inspection of it may raise suspicions but perhaps caught unaware it could well fool people into believing it is a real video and not AI-generated. The clip is from OmniHuman-1, an AI video system created by ByteDance — the Chinese company behind TikTok — which can deepfake a person using just one photo and one piece of audio. OmniHuman-1 is just a research paper, for now, but the demos ByteDance is showing off are mightily impressive and appear to be an improvement on other deepfake apps that suffer from uncanny valley syndrome. Tech Crunch reports that OmniHuman-1 has been trained on 19,000 hours of video content from “undisclosed sources” which you can guarantee means any video ByteDance found on the internet or any other platform — copyrighted or not. The AI tool can also edit existing videos and can change the movements of a person’s limbs. Tech Crunch calls the results “astonishing.” In the examples below, a woman giving a fake Ted Talk achieves a good level of verisimilitude while an AI Albert Einstein delivers a lecture in front of a chalkboard. “We propose an end-to-end multimodality-conditioned human video generation framework named OmniHuman, which can generate human videos based on a single human image and motion signals (e.g., audio only, video only, or a combination of audio and video),” the Bytedance researchers write. “In OmniHuman, we introduce a multimodality motion conditioning mixed training strategy, allowing the model to benefit from data scaling up of mixed conditioning. This overcomes the issue that previous end-to-end approaches faced due to the scarcity of high-quality data. OmniHuman significantly outperforms existing methods, generating extremely realistic human videos based on weak signal inputs, especially audio. It supports image inputs of any aspect ratio, whether they are portraits, half-body, or full-body images, delivering more lifelike and high-quality results across various scenarios.” Users of OmniHuman-1 will get better results if they use high-quality and high-resolution reference images. It even shared a series of videos showing deepfakes talking with their hands — a part of the body AI imagery notoriously struggles with. The onset of deepfake technology has worrying implications in the real world: malicious actors try and use AI video to sway voters in elections by posting fake endorsements or besmirching an opposing politician’s name. In February, a finance worker was scammed into paying $200 million Hong Kong dollars ($25.6 million) to criminals after a virtual meeting with a deepfake impersonator. PetaPixel articles may include affiliate links; if you buy something through such a link, PetaPixel may earn a commission.",
  "image": "https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\t\t\t\t\t\t\n\u003carticle data-post-id=\"778637\"\u003e\n\n    \u003cheader\u003e\n          \n    \n\n        \n  \u003c/header\u003e\n      \n  \n\n  \u003cdiv\u003e\n    \u003cdiv\u003e\n      \u003cfigure id=\"attachment_778644\" aria-describedby=\"caption-attachment-778644\"\u003e\u003ca href=\"https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein.jpg\" data-wpel-link=\"internal\"\u003e\u003cimg data-perfmatters-preload=\"\" fetchpriority=\"high\" decoding=\"async\" src=\"https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-800x420.jpg\" alt=\"\" width=\"800\" height=\"420\" srcset=\"https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-800x420.jpg 800w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-320x168.jpg 320w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-1536x806.jpg 1536w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-150x79.jpg 150w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-300x157.jpg 300w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-400x209.jpg 400w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein-550x288.jpg 550w, https://petapixel.com/assets/uploads/2025/02/AI-Albert-Einstein.jpg 1600w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003c/a\u003e\u003cfigcaption id=\"caption-attachment-778644\"\u003eA talking AI-generated Albert Einstein.\u003c/figcaption\u003e\u003c/figure\u003e \u003cp\u003eWatch the short talking head video below. Granted, it is in French, and close inspection of it may raise suspicions but perhaps caught unaware it could well fool people into believing it is a real video and not AI-generated.\u003c/p\u003e  \u003ccenter\u003e\u003cdiv\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/wlAxM8xKqVM?si=_S35pxgwsKDom_-G\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/div\u003e\u003c/center\u003e \u003cp\u003eThe clip is from OmniHuman-1, an AI video system created by ByteDance — the Chinese company behind TikTok — which can deepfake a person using just one photo and one piece of audio.\u003c/p\u003e \u003cp\u003eOmniHuman-1 is just a \u003ca href=\"https://arxiv.org/abs/2502.01061\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003eresearch paper\u003c/a\u003e, for now, but the demos ByteDance is showing off are mightily impressive and appear to be an improvement on other deepfake apps that suffer from uncanny valley syndrome.\u003c/p\u003e \u003cp\u003e\u003ca href=\"https://techcrunch.com/2025/02/04/deepfake-videos-are-getting-shockingly-good/\" data-wpel-link=\"external\" target=\"_blank\" rel=\"follow external noopener\"\u003e\u003cem\u003eTech Crunch\u003c/em\u003e reports\u003c/a\u003e that OmniHuman-1 has been trained on 19,000 hours of video content from “undisclosed sources” which you can guarantee means any video ByteDance found on the internet or any other platform — copyrighted or not. The AI tool can also edit existing videos and can change the movements of a person’s limbs. \u003cem\u003eTech Crunch\u003c/em\u003e calls the results “astonishing.”\u003c/p\u003e \u003cp\u003eIn the examples below, a woman giving a fake Ted Talk achieves a good level of verisimilitude while an AI Albert Einstein delivers a lecture in front of a chalkboard.\u003c/p\u003e\n \u003ccenter\u003e\u003cdiv\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/GGZ7FC97_LI?si=AiRtcAN73ueyDQGS\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/div\u003e\u003c/center\u003e \u003ccenter\u003e\u003cdiv\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/akAqsjHkB3M?si=652qraHLpxWUzfxs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/div\u003e\u003c/center\u003e \u003cp\u003e“We propose an end-to-end multimodality-conditioned human video generation framework named OmniHuman, which can generate human videos based on a single human image and motion signals (e.g., audio only, video only, or a combination of audio and video),” the Bytedance researchers write.\u003c/p\u003e \u003cp\u003e“In OmniHuman, we introduce a multimodality motion conditioning mixed training strategy, allowing the model to benefit from data scaling up of mixed conditioning. This overcomes the issue that previous end-to-end approaches faced due to the scarcity of high-quality data. OmniHuman significantly outperforms existing methods, generating extremely realistic human videos based on weak signal inputs, especially audio. It supports image inputs of any aspect ratio, whether they are portraits, half-body, or full-body images, delivering more lifelike and high-quality results across various scenarios.”\u003c/p\u003e \u003cp\u003eUsers of OmniHuman-1 will get better results if they use high-quality and high-resolution reference images. It even shared a series of videos showing deepfakes talking with their hands — a part of the body AI imagery \u003ca href=\"https://petapixel.com/2023/03/02/why-ai-image-generators-cant-get-hands-right/\" data-wpel-link=\"internal\"\u003enotoriously struggles with.\u003c/a\u003e\u003c/p\u003e \u003ccenter\u003e\u003cdiv\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/BUk6ZUt3XIA?si=ycOIptyk49z8usXW\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/div\u003e\u003c/center\u003e \u003ccenter\u003e\u003cdiv\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/4gG7kEUhcAU?si=KwRHh9rHPFAOwy_O\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/div\u003e\u003c/center\u003e\n \u003cp\u003eThe onset of deepfake technology has worrying implications in the real world: malicious actors try and use AI video to sway voters in elections by posting fake endorsements or besmirching an opposing politician’s name.\u003c/p\u003e \u003cp\u003eIn February, a finance worker was \u003ca href=\"https://petapixel.com/2024/02/05/financier-scammed-of-25-6-million-after-meeting-with-deepfakes/\" data-wpel-link=\"internal\"\u003escammed into paying $200 million Hong Kong dollars\u003c/a\u003e ($25.6 million) to criminals after a virtual meeting with a deepfake impersonator.\u003c/p\u003e      \u003c/div\u003e\n\n          \n      \n\n              \u003cdiv\u003e\n          \u003cp\u003ePetaPixel articles may include affiliate links; if you buy something through such a link, PetaPixel may earn a commission.\u003c/p\u003e\n        \u003c/div\u003e\n      \n    \n\n    \n          \n      \n\n\n\n\n    \n    \n    \n          \n      \u003c/div\u003e\n\u003c/article\u003e\n\t\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-02-05T17:10:46Z",
  "modifiedTime": "2025-02-05T17:25:08Z"
}
