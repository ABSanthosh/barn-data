{
  "id": "8b57e6ed-8912-48f4-989e-e1e84b081fa4",
  "title": "Will Embodied AI Make Prosthetics More Humane?",
  "link": "https://hackaday.com/2025/02/12/will-embodied-ai-make-prosthetics-more-humane/",
  "description": "Building a robotic arm and hand that matches human dexterity is tougher than it looks. We can create aesthetically pleasing ones, very functional ones, but the perfect mix of both? …read more",
  "author": "Heidi Ulrich",
  "published": "Wed, 12 Feb 2025 21:00:00 +0000",
  "source": "https://hackaday.com/blog/feed/",
  "categories": [
    "Artificial Intelligence",
    "Medical Hacks",
    "Robots Hacks",
    "ai",
    "artificial intelligence",
    "embodied ai",
    "limb",
    "prosthetic",
    "touch"
  ],
  "byline": "",
  "length": 1537,
  "excerpt": "Building a robotic arm and hand that matches human dexterity is tougher than it looks. We can create aesthetically pleasing ones, very functional ones, but the perfect mix of both? Still a work in …",
  "siteName": "Hackaday",
  "favicon": "https://hackaday.com/wp-content/themes/hackaday-2/img/hackaday-logo_1024x1024.png?v=3",
  "text": "Skip to content Building a robotic arm and hand that matches human dexterity is tougher than it looks. We can create aesthetically pleasing ones, very functional ones, but the perfect mix of both? Still a work in progress. Just ask [Sarah de Lagarde], who in 2022 literally lost an arm and a leg in a life-changing accident. In this BBC interview, she shares her experiences openly – highlighting both the promise and the limits of today’s prosthetics. The problem is that our hands aren’t just grabby bits. They’re intricate systems of nerves, tendons, and ridiculously precise motor control. Even the best AI-powered prosthetics rely on crude muscle signals, while dexterous robots struggle with the simplest things — like tying shoelaces or flipping a pancake without launching it into orbit. That doesn’t mean progress isn’t happening. Researchers are training robotic fingers with real-world data, moving from ‘oops’ to actual precision. Embodied AI, i.e. machines that learn by physically interacting with their environment, is bridging the gap. Soft robotics with AI-driven feedback loops mimic how our fingers instinctively adjust grip pressure. If haptics are your point of interest, we have posted about it before. The future isn’t just robots copying our movements, it’s about them understanding touch. Instead of machine learning, we might want to shift focus to human learning. If AI cracks that, we’re one step closer. Original photo by Marco Bianchetti on Unsplash",
  "image": "https://hackaday.com/wp-content/uploads/2023/02/ChatGPT-1.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"page\"\u003e\n    \n\n    \u003cp\u003e\u003ca href=\"#content\"\u003eSkip to content\u003c/a\u003e\u003c/p\u003e\n\n    \u003cdiv id=\"content\"\u003e\n        \u003cmain id=\"main\" role=\"main\"\u003e\n\n        \n            \n\u003carticle itemscope=\"\" itemtype=\"http://schema.org/Article\" id=\"post-758500\"\u003e\n    \n\n    \u003cdiv itemprop=\"articleBody\"\u003e\n        \u003cp data-start=\"113\" data-end=\"534\"\u003eBuilding a robotic arm and hand that matches human dexterity is tougher than it looks. We can create aesthetically pleasing ones, very functional ones, but the perfect mix of both? Still a work in progress. Just ask [Sarah de Lagarde], who in 2022 literally lost an arm and a leg in a life-changing accident. \u003ca href=\"https://www.bbc.com/future/article/20250121-why-hands-are-one-of-the-biggest-challenges-in-robotics\" target=\"_blank\" rel=\"noopener\" data-start=\"410\" data-end=\"428\" target=\"_blank\"\u003eIn this BBC interview\u003c/a\u003e, she shares her experiences openly – highlighting both the promise and the limits of today’s prosthetics.\u003c/p\u003e\n\u003cp data-start=\"679\" data-end=\"1021\"\u003eThe problem is that our hands aren’t just grabby bits. They’re intricate systems of nerves, tendons, and ridiculously precise motor control. Even the best AI-powered prosthetics rely on crude muscle signals, while dexterous robots struggle with the simplest things — like tying shoelaces or flipping a pancake without launching it into orbit.\u003c/p\u003e\n\u003cp data-start=\"1023\" data-end=\"1375\"\u003eThat doesn’t mean progress isn’t happening. Researchers are training robotic fingers with real-world data, moving from ‘oops’ to actual precision. Embodied AI, i.e. machines that learn by physically interacting with their environment, is bridging the gap. Soft robotics with AI-driven feedback loops mimic how our fingers instinctively adjust grip pressure. If haptics are your point of interest, \u003ca href=\"https://hackaday.com/2015/01/21/open-source-haptics-kit-aims-to-democratize-force-feedback/\"\u003ewe have posted about it before\u003c/a\u003e.\u003c/p\u003e\n\u003cp data-start=\"1377\" data-end=\"1574\"\u003eThe future isn’t just robots copying our movements, it’s about them \u003cem data-start=\"1444\" data-end=\"1459\"\u003eunderstanding\u003c/em\u003e touch. Instead of machine learning, we might want to shift focus to human learning. If AI cracks that, we’re one step closer.\u003c/p\u003e\n\u003cp data-start=\"1377\" data-end=\"1574\"\u003eOriginal photo by \u003ca href=\"https://unsplash.com/@marcobian?utm_content=creditCopyText\u0026amp;utm_medium=referral\u0026amp;utm_source=unsplash\" target=\"_blank\"\u003eMarco Bianchetti\u003c/a\u003e on \u003ca href=\"https://unsplash.com/photos/a-close-up-of-a-person-holding-a-wooden-object-fRon_XlZEbM?utm_content=creditCopyText\u0026amp;utm_medium=referral\u0026amp;utm_source=unsplash\" target=\"_blank\"\u003eUnsplash\u003c/a\u003e\u003c/p\u003e\n\n\t            \u003c/div\u003e\n    \u003cul\u003e\n    \t\t\t\t\t\u003cli\u003e\n    \t\t\t\t\u003ca href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fhackaday.com%2F2025%2F02%2F12%2Fwill-embodied-ai-make-prosthetics-more-humane%2F\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_face.png\"/\u003e \u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n                        \u003ca href=\"https://twitter.com/intent/tweet?text=Will%20Embodied%20AI%20Make%20Prosthetics%20More%20Humane?%20via%20@hackaday\u0026amp;url=https://hackaday.com/2025/02/12/will-embodied-ai-make-prosthetics-more-humane/\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_twitter.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n    \t\t\t\t\u003ca href=\"https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fhackaday.com%2F2025%2F02%2F12%2Fwill-embodied-ai-make-prosthetics-more-humane%2F\" target=\"_blank\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_in.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\t\t\u003cli\u003e\n                \u003ca href=\"mailto:?subject=Will+Embodied+AI+Make+Prosthetics+More+Humane%3F | Hackaday\u0026amp;body=https%3A%2F%2Fhackaday.com%2F2025%2F02%2F12%2Fwill-embodied-ai-make-prosthetics-more-humane%2F\"\u003e\n    \t\t\t\t\t\u003ci\u003e\u003cimg src=\"https://hackaday.com/wp-content/themes/hackaday-2/img/share_mail1.png\"/\u003e\u003c/i\u003e\n    \t\t\t\t\t\t\t\t\t\u003c/a\u003e\n    \t\t\t\u003c/li\u003e\n    \t\t\t\u003c/ul\u003e\n    \n\u003c/article\u003e\n\n            \t\n\t\n            \n\n            \n\n\n        \n        \n\n        \n        \n\n        \n        \u003c/main\u003e\n    \u003c/div\u003e\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": "2025-02-12T21:00:00Z",
  "modifiedTime": "2025-02-12T18:40:14Z"
}
