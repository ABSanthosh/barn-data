{
  "id": "66f70316-68dd-44d7-9552-4447b5caac13",
  "title": "OpenAI CEO Sam Altman says the company is 'out of GPUs'",
  "link": "https://finance.yahoo.com/news/openai-ceo-sam-altman-says-202110800.html",
  "description": "",
  "author": "",
  "published": "2025-02-27T20:21:10Z",
  "source": "https://www.yahoo.com/news/rss",
  "categories": null,
  "byline": "Kyle Wiggers",
  "length": 1223,
  "excerpt": "OpenAI CEO Sam Altman said that the company was forced to stagger the rollout of its newest model, GPT-4.5, because OpenAI is \"out of GPUs.\" In a post on X,...",
  "siteName": "Yahoo Finance",
  "favicon": "https://s.yimg.com/cv/apiv2/default/finance/favicon-180x180.png",
  "text": "OpenAI CEO Sam Altman said that the company was forced to stagger the rollout of its newest model, GPT-4.5, because OpenAI is \"out of GPUs.\" In a post on X, Altman said that GPT-4.5, which he described as \"giant\" and \"expensive,\" will require \"tens of thousands\" more GPUs before additional ChatGPT users can gain access. GPT-4.5 will come first to subscribers to ChatGPT Pro starting Thursday, followed by ChatGPT Plus customers next week. Perhaps in part due to its enormous size, GPT-4.5 is wildly expensive. OpenAI is charging $75 per million tokens (~750,000 words) fed into the model and $150 per million tokens generated by the model. That's 30x the input cost and 15x the output cost of OpenAI's workhorse GPT-4o model. \"We've been growing a lot and are out of GPUs,\" Altman wrote. \"We will add tens of thousands of GPUs next week and roll it out to the Plus tier then [...] This isn't how we want to operate, but it's hard to perfectly predict growth surges that lead to GPU shortages.\" Altman has previously said that a lack of computing capacity is delaying the company’s products. OpenAI hopes to combat this in the coming years by developing its own AI chips, and by building a massive network of datacenters.",
  "image": "https://s.yimg.com/ny/api/res/1.2/jb6YwVx211KTw5cyQdp56A--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD05MTc7Y2Y9d2VicA--/https://media.zenfs.com/en/techcrunch_350/dd8dfdfcb0b65d28aff7047848d0edc0",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e    \u003cp\u003eOpenAI CEO Sam Altman said that the company was forced to stagger the rollout of its newest model, \u003ca href=\"https://techcrunch.com/2025/02/27/openai-unveils-gpt-4-5-orion-its-largest-ai-model-yet/\" data-ylk=\"slk:GPT-4.5;elm:context_link;itc:0;sec:content-canvas\"\u003eGPT-4.5\u003c/a\u003e, because OpenAI is \u0026#34;out of GPUs.\u0026#34;\u003c/p\u003e \u003cp\u003eIn a \u003ca rel=\"nofollow noopener\" href=\"https://x.com/sama/status/1895203654103351462\" target=\"_blank\" data-ylk=\"slk:post on X;elm:context_link;itc:0;sec:content-canvas\"\u003epost on X\u003c/a\u003e, Altman said that GPT-4.5, which he described as \u0026#34;giant\u0026#34; and \u0026#34;expensive,\u0026#34; will require \u0026#34;tens of thousands\u0026#34; more GPUs before additional ChatGPT users can gain access. GPT-4.5 will come first to subscribers to ChatGPT Pro starting Thursday, followed by ChatGPT Plus customers next week.\u003c/p\u003e \u003cp\u003ePerhaps in part due to its enormous size, GPT-4.5 is wildly expensive. OpenAI is charging $75 per million tokens (~750,000 words) fed into the model and $150 per million tokens generated by the model. That\u0026#39;s 30x the input cost and 15x the output cost of OpenAI\u0026#39;s workhorse \u003ca href=\"https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/\" data-ylk=\"slk:GPT-4o;elm:context_link;itc:0;sec:content-canvas\"\u003eGPT-4o\u003c/a\u003e model.\u003c/p\u003e  \u003cp\u003e\u0026#34;We\u0026#39;ve been growing a lot and are out of GPUs,\u0026#34; Altman wrote. \u0026#34;We will add tens of thousands of GPUs next week and roll it out to the Plus tier then [...] This isn\u0026#39;t how we want to operate, but it\u0026#39;s hard to perfectly predict growth surges that lead to GPU shortages.\u0026#34;\u003c/p\u003e \u003cp\u003eAltman has \u003ca href=\"https://techcrunch.com/2024/10/31/openai-ceo-sam-altman-says-lack-of-compute-is-delaying-the-companys-products/\" data-ylk=\"slk:previously;elm:context_link;itc:0;sec:content-canvas\"\u003epreviously\u003c/a\u003e said that a lack of computing capacity is delaying the company’s products. OpenAI hopes to combat this in the coming years by \u003ca href=\"https://techcrunch.com/2024/10/29/openai-reportedly-planning-to-build-its-first-ai-chip-in-2026/\" data-ylk=\"slk:developing its own AI chips;elm:context_link;itc:0;sec:content-canvas\"\u003edeveloping its own AI chips\u003c/a\u003e, and by \u003ca href=\"https://techcrunch.com/2025/01/23/openai-and-softbank-are-reportedly-putting-19b-each-into-stargate/\" data-ylk=\"slk:building a massive network of datacenters;elm:context_link;itc:0;sec:content-canvas\"\u003ebuilding a massive network of datacenters\u003c/a\u003e.\u003c/p\u003e      \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": "2025-02-27T20:21:10Z",
  "modifiedTime": null
}
