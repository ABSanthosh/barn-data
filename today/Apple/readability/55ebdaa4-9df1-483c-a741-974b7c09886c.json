{
  "id": "55ebdaa4-9df1-483c-a741-974b7c09886c",
  "title": "Apple's numerous internal projects led to the upcoming API-powered Siri with AI",
  "link": "https://appleinsider.com/articles/24/11/06/apples-numerous-internal-projects-led-to-the-upcoming-api-powered-siri-with-ai?utm_medium=rss",
  "description": "Siri could soon be able to view and process on-screen content thanks to new developer APIs based on technologies leaked by AppleInsider prior to WWDC.Share content found on screen within apps with Apple Intelligence thanks to upcoming APIsOn Monday, Apple released new documentation to help developers prepare for the arrival of upcoming Siri and Apple Intelligence features. The company's latest developer API reveals that Siri will gain significant contextual awareness and that the virtual assistant will, at some point, be able to use information from the content currently on screen.Siri will undoubtedly become much more useful due to Apple's changes. The company provided a list of examples, which offer some insight as to exactly what the new-and-improved, AI-infused Siri will be able to do in the future. Continue Reading on AppleInsider | Discuss on our Forums",
  "author": "Marko Zivkovic",
  "published": "Wed, 06 Nov 2024 21:15:13 +0000",
  "source": "https://appleinsider.com/rss/news/",
  "categories": null,
  "byline": "Marko Zivkovic",
  "length": 3347,
  "excerpt": "Siri could soon be able to view and process on-screen content thanks to new developer APIs based on technologies leaked by AppleInsider prior to WWDC.",
  "siteName": "AppleInsider",
  "favicon": "https://photos5.appleinsider.com/v10/images/favicon-ai-144.png",
  "text": "Share content found on screen within apps with Apple Intelligence thanks to upcoming APIs Siri could soon be able to view and process on-screen content thanks to new developer APIs based on technologies leaked by AppleInsider prior to WWDC. On Monday, Apple released new documentation to help developers prepare for the arrival of upcoming Siri and Apple Intelligence features. The company's latest developer API reveals that Siri will gain significant contextual awareness and that the virtual assistant will, at some point, be able to use information from the content currently on screen. Siri will undoubtedly become much more useful due to Apple's changes. The company provided a list of examples, which offer some insight as to exactly what the new-and-improved, AI-infused Siri will be able to do in the future. Users will have the option to ask Siri questions about the web page they're currently viewing or about a specific object in a photo. The virtual assistant will also be able to summarize documents and emails upon request, or complete texts by adding more content. Note that some of these features were already made possible with the first iOS 18.2 developer beta, which introduced ChatGPT integration. Siri can forward a PDF, text document, or image to ChatGPT for certain actions, though only with the user's permission. The new developer API indicates that Apple wants to streamline this process further. Instead of the user asking Siri to send a document to ChatGPT, they will be able to ask direct questions about the page on screen or use information from it in some way. There's plenty of room for improvement here since ChatGPT can currently only access screenshots or documents manually provided by the user. Siri may soon gain the ability to use on-screen content. Apple's idea to have AI use on-screen information was apparent even before Apple Intelligence was announced at WWDC. The company's published research, particularly concerning the Ferret model, served as an indicator of Apple's plans in the area of artificial intelligence. Significant importance was placed on document analysis, document understanding, and AI-powered text generation. In one of our recent reports, AppleInsider outlined the various internal test applications used while Apple Intelligence was still in development. The test applications and environments, particularly the 1UP app, mirror many of the features currently possible via ChatGPT integration on iOS 18.2 beta. Apple also had a dedicated app for testing Smart Replies in Mail and Messages. Siri's new ability to complete and summarize texts, or answer questions about images, documents, and web pages was also revealed ahead of the official announcement. In our reports on the Ajax LLM, as well as the BlackPearl and Greymatter projects, we unveiled many of these features, explained how they would work, and even paraphrased Apple's AI prompts. It's apparent that the iPhone maker takes artificial intelligence quite seriously, given the amount of time, research, and effort that goes into its generative AI projects. Monday's developer API was only released to help developers prepare for new Siri features, which are rumored to make their debut in 2025 with the iOS 18.4 update.",
  "image": "https://photos5.appleinsider.com/gallery/61671-127546-On-screen-API-xl.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article-hero\" aria-labelledby=\"hero-cap\" role=\"figure\"\u003e\n                          \u003cp id=\"hero-cap\" title=\"Share content found on screen within apps with Apple Intelligence thanks to upcoming APIs\"\u003eShare content found on screen within apps with Apple Intelligence thanks to upcoming APIs\u003c/p\u003e\n                                    \u003cp\u003e\u003ca href=\"https://photos5.appleinsider.com/gallery/61671-127546-On-screen-API-xl.jpg\"\u003e\n              \u003cimg fetchpriority=\"high\" src=\"https://photos5.appleinsider.com/gallery/61671-127546-On-screen-API-xl.jpg\" alt=\"\"/\u003e\n            \u003c/a\u003e\n                      \u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\n          \u003cp\u003e\u003ca href=\"https://appleinsider.com/inside/siri\" title=\"Siri\" data-kpt=\"1\"\u003eSiri\u003c/a\u003e could soon be able to view and process on-screen content thanks to new developer APIs based on technologies leaked by AppleInsider prior to WWDC.\n\u003c/p\u003e\u003cp\u003eOn Monday, Apple released \u003ca href=\"https://developer.apple.com/documentation/appintents/making-onscreen-content-available-to-siri-and-apple-intelligence\"\u003enew documentation\u003c/a\u003e to help developers prepare for the arrival of upcoming Siri and \u003ca href=\"https://appleinsider.com/inside/apple-intelligence\" title=\"Apple Intelligence\" data-kpt=\"1\"\u003eApple Intelligence\u003c/a\u003e features. The company\u0026#39;s \u003ca href=\"https://appleinsider.com/articles/24/11/04/developers-can-begin-work-on-an-app-intent-system-that-will-make-siri-smarter-in-2025\"\u003elatest developer API\u003c/a\u003e reveals that Siri will gain significant contextual awareness and that the virtual assistant will, at some point, be able to use information from the content currently on screen.\n\u003c/p\u003e\u003cp\u003eSiri will undoubtedly become much more useful due to Apple\u0026#39;s changes. The company provided a list of examples, which offer some insight as to exactly what the new-and-improved, \u003ca href=\"https://appleinsider.com/articles/24/08/02/hands-on-siri-starts-to-get-better-thanks-to-apple-intelligence\"\u003eAI-infused Siri\u003c/a\u003e will be able to do in the future.\n\u003c/p\u003e\u003cp\u003eUsers will have the option to ask Siri questions about the web page they\u0026#39;re currently viewing or about a specific object in a photo. The virtual assistant will also be able to summarize documents and emails upon request, or complete texts by adding more content.\n\u003c/p\u003e\u003cp\u003eNote that some of these features were already made possible with the first \u003ca href=\"https://appleinsider.com/articles/24/10/23/hands-on-with-image-playground-chatgpt-and-genmoji-in-ios-182\"\u003eiOS 18.2\u003c/a\u003e developer beta, which introduced ChatGPT integration. Siri can forward a PDF, text document, or image to ChatGPT for certain actions, though only with the user\u0026#39;s permission.\n\u003c/p\u003e\u003cp\u003eThe new developer API indicates that Apple wants to streamline this process further. Instead of the user asking Siri to send a document to ChatGPT, they will be able to ask direct questions about the page on screen or use information from it in some way. There\u0026#39;s plenty of room for improvement here since ChatGPT can currently only access screenshots or documents manually provided by the user.\n\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://photos5.appleinsider.com/gallery/61671-127544-61151-126190-61128-126129-60285-123907-000-lead-New-Siri-xl-xl-xl-xl.jpg\" target=\"_blank\"\u003e\u003cimg src=\"https://photos5.appleinsider.com/gallery/61671-127544-61151-126190-61128-126129-60285-123907-000-lead-New-Siri-xl-xl-xl-xl.jpg\" alt=\"A hand holds a smartphone with various app icons displayed on its colorful screen.\" height=\"720\" loading=\"lazy\"/\u003e\u003c/a\u003e\n\u003c/p\u003e\u003cp\u003e\u003cspan\u003eSiri may soon gain the ability to use on-screen content.\u003c/span\u003e\u003c/p\u003e\n\u003c/div\u003e\u003cp\u003eApple\u0026#39;s idea to have AI use on-screen information was apparent even before Apple Intelligence was announced at \u003ca href=\"https://appleinsider.com/inside/wwdc\" title=\"WWDC\" data-kpt=\"1\"\u003eWWDC\u003c/a\u003e. The company\u0026#39;s published research, particularly concerning the \u003ca href=\"https://appleinsider.com/articles/23/12/24/apples-ferret-is-a-new-open-source-machine-learning-model\"\u003eFerret\u003c/a\u003e model, served as an indicator of Apple\u0026#39;s plans in the area of artificial intelligence.\n\u003c/p\u003e\u003cp\u003eSignificant importance was placed on document analysis, document understanding, and AI-powered text generation. In one of our recent reports, \u003cem\u003eAppleInsider\u003c/em\u003e \u003ca href=\"https://appleinsider.com/articles/24/10/24/apple-intelligence----the-test-applications-that-paved-the-way-for-apples-generative-ai\"\u003eoutlined\u003c/a\u003e the various internal test applications used while Apple Intelligence was still in development.\n\u003c/p\u003e\u003cp\u003eThe test applications and environments, particularly the 1UP app, mirror many of the features currently possible via ChatGPT integration on iOS 18.2 beta. Apple also had a dedicated app for testing \u003ca href=\"https://appleinsider.com/articles/24/06/11/apple-mail-in-ios-18-introduces-on-device-email-categorization-smart-replies-and-summaries\"\u003eSmart Replies\u003c/a\u003e in Mail and Messages.\n\u003c/p\u003e\u003cp\u003eSiri\u0026#39;s new ability to complete and summarize texts, or answer questions about images, documents, and web pages was also revealed ahead of the official announcement. In our reports on the \u003ca href=\"https://appleinsider.com/articles/24/05/03/siri-for-ios-18-to-gain-massive-ai-upgrade-via-apples-ajax-llm\"\u003eAjax\u003c/a\u003e LLM, as well as the \u003ca href=\"https://appleinsider.com/articles/24/06/06/ios-18-mail-app-will-get-huge-ai-enhancements-summarizations-with-project-blackpearl\"\u003eBlackPearl\u003c/a\u003e and \u003ca href=\"https://appleinsider.com/articles/24/05/30/ios-18-project-greymatter-will-use-ai-to-summarize-notifications-articles-and-much-more\"\u003eGreymatter\u003c/a\u003e projects, we unveiled many of these features, explained how they would work, and even paraphrased Apple\u0026#39;s \u003ca href=\"https://appleinsider.com/articles/24/08/06/discovered-apple-intelligence-prompts-show-apples-attempt-at-preventing-ai-disaster\"\u003eAI prompts\u003c/a\u003e.\n\u003c/p\u003e\u003cp\u003eIt\u0026#39;s apparent that the \u003ca href=\"https://appleinsider.com/inside/iphone\" title=\"iPhone\" data-kpt=\"1\"\u003eiPhone\u003c/a\u003e maker takes artificial intelligence quite seriously, given the amount of time, research, and effort that goes into its generative AI projects. Monday\u0026#39;s developer API was only released to help developers prepare for new Siri features, which are \u003ca href=\"https://appleinsider.com/articles/24/07/08/siri-improved-with-apple-intelligence-wont-roll-out-until-2025\"\u003erumored\u003c/a\u003e to make their debut in 2025 with the iOS 18.4 update.\n\u003c/p\u003e\n\n        \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2024-11-06T21:15:13Z",
  "modifiedTime": null
}
