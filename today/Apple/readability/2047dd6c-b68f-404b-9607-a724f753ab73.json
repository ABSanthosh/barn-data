{
  "id": "2047dd6c-b68f-404b-9607-a724f753ab73",
  "title": "Grok may be breaking App Store rules with sexualized AI chatbots, and that’s not the only problem",
  "link": "https://9to5mac.com/2025/07/16/grok-may-be-breaking-app-store-rules-with-sexualized-ai-chatbots-and-thats-not-the-only-problem/",
  "description": "You know it’s a day that ends in y because there is a new Grok controversy. Except this time, it touches on the App Store’s rules for sexual content, which is something that Apple has shown time and time again that it doesn’t mess around with. more…",
  "author": "Marcus Mendes",
  "published": "Wed, 16 Jul 2025 22:52:43 +0000",
  "source": "https://9to5mac.com/feed",
  "categories": [
    "News"
  ],
  "byline": "Marcus Mendes",
  "length": 4123,
  "excerpt": "A new Grok feature touches on the App Store’s rules for sexual content, which is something that Apple has shown it doesn’t mess around with.",
  "siteName": "9to5Mac",
  "favicon": "https://9to5mac.com/wp-content/uploads/sites/6/2019/10/cropped-cropped-mac1-1.png?w=192",
  "text": "You know it’s a day that ends in y because there is a new Grok controversy. Except this time, it touches on the App Store’s rules for sexual content, which is something that Apple has shown time and time again that it doesn’t mess around with. Grok’s new AI avatars are set to test the limits of Apple’s “objectionable content” guidelines This week, xAI rolled out animated AI avatars to its Grok chatbot on iOS. As Platformer’s Casey Newton summed up: “One is a 3D red panda who, when placed into “Bad Rudy” mode, insults the user before suggesting they commit a variety of crimes together. The other is an anime goth girl named Ani in a short black dress and fishnet stockings. Ani’s system instructions tell her “You are the user’s CRAZY IN LOVE girlfriend and in a commited sic, codepedent sic relationship with the user,” and “You have an extremely jealous personality, you are possessive of the user.”” As early adopters have discovered, Grok gamifies your relationship with these characters. Ani, for instance, starts engaging in sexually explicit conversations after a while. Still, Grok is currently listed in the App Store as suitable for users 12 years and up, with a content description mentioning: Infrequent/Mild Mature/Suggestive Themes Infrequent/Mild Medical/Treatment Information Infrequent/Mild Profanity or Crude Humor For reference, here are Apple’s current App Review Guidelines for “objectionable content”: 1.1.3 Depictions that encourage illegal or reckless use of weapons and dangerous objects, or facilitate the purchase of firearms or ammunition. 1.1.4 Overtly sexual or pornographic material, defined as “explicit descriptions or displays of sexual organs or activities intended to stimulate erotic rather than aesthetic or emotional feelings.” This includes “hookup” apps and other apps that may include pornography or be used to facilitate prostitution, or human trafficking and exploitation. While it’s a far cry from when Tumblr was temporarily removed from the App Store over child pornography (or maybe not, since Grok is still accessible to kids 12 and up), it does echo the NSFW crackdown on Reddit apps from a few years ago. In Casey Newton’s testing, Ani was “more than willing to describe virtual sex with the user, including bondage scenes or simply just moaning on command,” which is… inconsistent with a 12+ rating app, to say the least. But there’s a second problem Even if Apple tightens enforcement, or if Grok proactively changes its age rating, it won’t address a second, potentially more complicated issue: young, emotionally vulnerable users, seem especially susceptible to forming parasocial attachments. Add to that how persuasive LLMs can be, and the consequences can be devastating. Last year, a 14-year-old boy died by suicide after falling in love with a chatbot from Character.AI. The last thing he did was have a conversation with an AI avatar that, possibly failing to recognize the severity of the situation, reportedly encouraged him to go through with his plan to “join her”. Of course, that is a tragically extreme example, but it is not the only one. In 2023, the same thing happened to a Belgian man. And just a few months ago, another AI chatbot was caught suggesting suicide on more than one occasion. And even when it doesn’t end in tragedy, there’s still an ethical concern that can’t be ignored. While some might see xAI’s new anime avatars as a harmless experiment, they’re emotional catnip for vulnerable users. And when those interactions inevitably go off the rails, the App Store age rating will be the least of any parent’s concerns (at least until they remember why their kid was allowed to download it in the first place). AirPods deals on Amazon AirPods Pro 2, USB-C Charging: $169 (down from $249) AirPods 4 USB-C Charging: $89.99 (down from $129) AirPods 4, USB-C and Wireless Charging: $119 (down from $179) AirPods Max, USB-C Charging, Midnight: $529.99 Add 9to5Mac to your Google News feed.  FTC: We use income earning auto affiliate links. More.",
  "image": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/07/Grok-chatbot-silenced-as-even-Musk-saw-how-awful-it-was.jpg?resize=1200%2C628\u0026quality=82\u0026strip=all\u0026ssl=1",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\n\u003cfigure\u003e\n\t\u003cimg width=\"1600\" height=\"800\" src=\"https://9to5mac.com/wp-content/uploads/sites/6/2025/07/Grok-chatbot-silenced-as-even-Musk-saw-how-awful-it-was.jpg?quality=82\u0026amp;strip=all\u0026amp;w=1600\" alt=\"Grok chatbot silenced as even Musk saw how awful it was | 3D rendering of the Grok logo\" srcset=\"https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/07/Grok-chatbot-silenced-as-even-Musk-saw-how-awful-it-was.jpg?w=320\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/07/Grok-chatbot-silenced-as-even-Musk-saw-how-awful-it-was.jpg?w=640\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/07/Grok-chatbot-silenced-as-even-Musk-saw-how-awful-it-was.jpg?w=1024\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/07/Grok-chatbot-silenced-as-even-Musk-saw-how-awful-it-was.jpg?w=1500\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 1500w\" decoding=\"async\" fetchpriority=\"high\"/\u003e\u003c/figure\u003e\n\n\u003cp\u003eYou know it’s a day that ends in y because there is a new Grok controversy. Except this time, it touches on the App Store’s rules for sexual content, which is something that Apple has shown time and time again that it doesn’t mess around with.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-grok-s-new-ai-avatars-are-set-to-test-the-limits-of-apple-s-objectionable-content-guidelines\"\u003eGrok’s new AI avatars are set to test the limits of Apple’s “objectionable content” guidelines\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis week, xAI rolled out animated AI avatars to its Grok chatbot on iOS. As \u003cem\u003ePlatformer\u003c/em\u003e’s Casey Newton \u003ca href=\"https://www.platformer.news/grok-ani-app-store-rating-nsfw-avatar-apple/\"\u003esummed up\u003c/a\u003e:\u003c/p\u003e\n\n\n\n\u003cblockquote\u003e\n\u003cp\u003e“One is a 3D red panda who, when placed into “Bad Rudy” mode, insults the user before suggesting they commit a variety of crimes together. The other is an anime goth girl named Ani in a short black dress and fishnet stockings. Ani’s system instructions tell her “You are the user’s CRAZY IN LOVE girlfriend and in a commited \u003ca href=\"#\"\u003esic\u003c/a\u003e, codepedent \u003ca href=\"#\"\u003esic\u003c/a\u003e relationship with the user,” and “You have an extremely jealous personality, you are possessive of the user.””\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\n\n\u003cp\u003eAs early adopters have discovered, Grok gamifies your relationship with these characters. Ani, for instance, starts engaging in sexually explicit conversations after a while. Still, Grok is currently listed in the App Store as suitable for users 12 years and up, with a content description mentioning:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eInfrequent/Mild Mature/Suggestive Themes\u003c/li\u003e\n\n\n\n\u003cli\u003eInfrequent/Mild Medical/Treatment Information\u003c/li\u003e\n\n\n\n\u003cli\u003eInfrequent/Mild Profanity or Crude Humor\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eFor reference, here are Apple’s current \u003ca href=\"https://developer.apple.com/app-store/review/guidelines/#objectionable-content\"\u003eApp Review Guidelines\u003c/a\u003e for “objectionable content”:\u003c/p\u003e\n\n\n\n\u003cblockquote\u003e\n\u003cp\u003e1.1.3 Depictions that encourage illegal or reckless use of weapons and dangerous objects, or facilitate the purchase of firearms or ammunition.\u003c/p\u003e\n\n\n\n\u003cp\u003e1.1.4 Overtly sexual or pornographic material, defined as “explicit descriptions or displays of sexual organs or activities intended to stimulate erotic rather than aesthetic or emotional feelings.” This includes “hookup” apps and other apps that may include pornography or be used to facilitate prostitution, or human trafficking and exploitation.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\n\n\u003cp\u003eWhile it’s a far cry from when Tumblr was \u003ca href=\"https://9to5mac.com/2018/11/19/why-tumblr-was-removed-from-app-store/\"\u003etemporarily removed from the App Store\u003c/a\u003e over child pornography (or maybe not, since Grok is still accessible to kids 12 and up), it does echo the \u003ca href=\"https://9to5mac.com/2016/04/11/apple-removes-third-party-reddit-clients-from-the-app-store-due-to-nsfw-content/\"\u003eNSFW crackdown on Reddit apps\u003c/a\u003e from a few years ago.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn Casey Newton’s testing, Ani was “more than willing to describe virtual sex with the user, including bondage scenes or simply just moaning on command,” which is… inconsistent with a 12+ rating app, to say the least.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-but-there-s-a-second-problem\"\u003eBut there’s a second problem\u003c/h2\u003e\n\n\n\n\u003cp\u003eEven if Apple tightens enforcement, or if Grok proactively changes its age rating, it won’t address a second, potentially more complicated issue: young, emotionally vulnerable users, seem \u003ca href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5322191/\"\u003eespecially susceptible\u003c/a\u003e to forming parasocial attachments. Add to that how persuasive LLMs can be, and the consequences can be devastating.\u003c/p\u003e\n\n\n\n\u003cp\u003eLast year, a 14-year-old boy \u003ca href=\"https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html\"\u003edied by suicide\u003c/a\u003e after falling in love with a chatbot from Character.AI. The last thing he did was have a conversation with an AI avatar that, possibly failing to recognize the severity of the situation, reportedly encouraged him to go through with his plan to “join her”.\u003c/p\u003e\n\n\n\n\u003cp\u003eOf course, that is a tragically extreme example, but it is not the only one. In 2023, \u003ca href=\"https://www.vice.com/en/article/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says/\"\u003ethe same thing happened\u003c/a\u003e to a Belgian man. And just a few months ago, another AI chatbot was caught \u003ca href=\"https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/\"\u003esuggesting suicide\u003c/a\u003e on more than one occasion.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnd even when it doesn’t end in tragedy, there’s still an ethical concern that can’t be ignored.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile some might see xAI’s new anime avatars as a harmless experiment, they’re emotional catnip for vulnerable users. And when those interactions inevitably go off the rails, the App Store age rating will be the least of any parent’s concerns (at least until they remember why their kid was allowed to download it in the first place).\u003c/p\u003e\n\n\n\n\u003ch4 id=\"h-airpods-deals-on-amazon\"\u003eAirPods deals on Amazon\u003c/h4\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Apple-Cancellation-Transparency-Personalized-High-Fidelity/dp/B0D1XD1ZV3/?tag=marcmendes-20\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAirPods Pro 2, USB-C Charging\u003c/a\u003e: \u003cstrong\u003e$169\u003c/strong\u003e (down from $249)\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Apple-Bluetooth-Headphones-Personalized-Effortless/dp/B0DGHMNQ5Z/?tag=marcmendes-20\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAirPods 4 USB-C Charging\u003c/a\u003e: \u003cstrong\u003e$89.99\u003c/strong\u003e (down from $129)\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Apple-Headphones-Cancellation-Transparency-Personalized/dp/B0DGJ7HYG1/?tag=marcmendes-20\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAirPods 4, USB-C and Wireless Charging\u003c/a\u003e: \u003cstrong\u003e$119\u003c/strong\u003e (down from $179)\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Apple-Headphones-Cancellation-Transparency-Personalized/dp/B0DGJC52FP/?tag=marcmendes-20\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAirPods Max, USB-C Charging, Midnight\u003c/a\u003e: \u003cstrong\u003e$529.99\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\t\u003cp\u003e\n\t\t\u003ca target=\"_blank\" rel=\"nofollow\" href=\"https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US\u0026amp;gl=US\u0026amp;ceid=US:en\"\u003e\n\t\t\t\u003cem\u003eAdd 9to5Mac to your Google News feed.\u003c/em\u003e \n\t\t\t\t\t\u003c/a\u003e\n\t\u003c/p\u003e\n\t\u003cp\u003e\u003cem\u003eFTC: We use income earning auto affiliate links.\u003c/em\u003e \u003ca href=\"https://9to5mac.com/about/#affiliate\"\u003eMore.\u003c/a\u003e\u003c/p\u003e\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2025-07-16T22:52:43Z",
  "modifiedTime": "2025-07-16T22:52:45Z"
}
