{
  "id": "e6c20524-0a98-48a1-8d37-e1b9f231f291",
  "title": "★ Something Is Rotten in the State of Cupertino",
  "link": "https://daringfireball.net/2025/03/something_is_rotten_in_the_state_of_cupertino",
  "description": "Who decided these personalized Siri features should go in the WWDC keynote, with a promise they’d arrive in the coming year, when, at the time, they were in such an unfinished state they could not be demoed to the media even in a controlled environment? Three months later, who decided Apple should double down and advertise these features in a TV commercial, and promote them as a selling point of the iPhone 16 lineup?",
  "author": "John Gruber",
  "published": "2025-03-12T23:37:14Z",
  "source": "https://daringfireball.net/feeds/main",
  "categories": null,
  "byline": "Wednesday, 12 March 2025",
  "length": 22986,
  "excerpt": "Who decided these personalized Siri features should go in the WWDC keynote, with a promise they’d arrive in the coming year, when, at the time, they were in such an unfinished state they could not be demoed to the media even in a controlled environment? Three months later, who decided Apple should double down and advertise these features in a TV commercial, and promote them as a selling point of the iPhone 16 lineup?",
  "siteName": "Daring Fireball",
  "favicon": "https://daringfireball.net/graphics/apple-touch-icon.png",
  "text": "In the two decades I’ve been in this racket, I’ve never been angrier at myself for missing a story than I am about Apple’s announcement on Friday that the “more personalized Siri” features of Apple Intelligence, scheduled to appear between now and WWDC, would be delayed until “the coming year”. I should have my head examined. This announcement dropped as a surprise, and certainly took me by surprise to some extent, but it was all there from the start. I should have been pointing out red flags starting back at WWDC last year, and I am embarrassed and sorry that I didn’t see what should have been very clear to me from the start. How I missed this is twofold. First, I’d been lulled into complacency by Apple’s track record of consistently shipping pre-announced products and features. Their record in that regard wasn’t perfect, but the exceptions tended to be around the edges. (Nobody was particularly clamoring for Apple to make a multi-device inductive charging mat, so it never generated too much controversy when AirPower turned out to be a complete bust.) Second, I was foolishly distracted by the “Apple Intelligence” brand umbrella. It’s a fine idea for Apple to brand its AI features under an umbrella term like that, similar to how a bunch of disparate features that allow different Apple devices to interoperate are under the “Continuity” umbrella. But there’s no such thing, technically speaking, as “Continuity”. It’s not like there’s an Xcode project inside Apple named Continuity.xcodeproj, and all the code that supports everything from AirDrop to Sidecar to iPhone Mirroring to clipboard sharing is all implemented in the same framework of code. It’s a marketing term, but a useful one — it helps Apple explain the features, and helps users understand them. The same goes for “Apple Intelligence”. It doesn’t exist as a single thing or project. It’s a marketing term for a collection of features, apps, and services. Putting it all under a single obvious, easily remembered — and easily promoted — name makes it easier for users to understand that Apple is launching a new initiative. It also makes it easier for Apple to just say “These are the devices that qualify for all of these features, and other devices — older ones, less expensive ones — get none of them.” Let’s say Apple were to quietly abandon the dumb Image Playground app next year. It just disappears from iOS 19 and MacOS 16. That would just be Apple eliminating a silly app that almost no one uses or should use. That wouldn’t be a setback or rollback of “Apple Intelligence”. I would actually argue that axing Image Playground would improve Apple Intelligence; its mere existence greatly lowers the expectations for how good the whole thing is.1 What I mean by that is that it was clear to me from the WWDC keynote onward that some of the features and aspects of Apple Intelligence were more ambitious than others. Some were downright trivial; others were proposing to redefine how we will do our jobs and interact with our most-used devices. That was clear. But yet somehow I didn’t focus on it. Apple itself strongly hinted that the various features in Apple Intelligence wouldn’t all ship at the same time. What they didn’t spell out, but anyone could intuit, was that the more trivial features would ship first, and the more ambitious features later. That’s where the red flags should have been obvious to me. In broad strokes, there are four stages of “doneness” or “realness” to features announced by any company: Features that the company’s own product representatives will demo, themselves, in front of the media. Smaller, more personal demonstrations are more credible than on-stage demos. But the stakes for demo fail are higher in an auditorium full of observers. Features that the company will allow members of the media (or other invited outside observers and experts) to try themselves, for a limited time, under the company’s supervision and guidance. Vision Pro demos were like this at WWDC 2023. A bunch of us got to use pre-release hardware and in-progress software for 30 minutes. It wasn’t like free range “Do whatever you want” — it was a guided tour. But we were the ones actually using the product. Apple allowed hands-on demos for a handful of media (not me) at Macworld Expo back in 2007 with prototype original iPhones — some of the “apps” were just screenshots, but most of the iPhone actually worked. Features that are released as beta software for developers, enthusiasts, and the media to use on their own devices, without limitation or supervision. Features that actually ship to regular users, and hardware that regular users can just go out and buy. As of today — March 2025 — every feature in Apple Intelligence that has actually shipped was at level 1 back at WWDC. After the keynote, dozens of us in the press were invited to a series of small-group briefings where we got to watch Apple reps demo features like Writing Tools, Photos Clean Up, Genmoji, and more. We got to see predictive code completion in Xcode. What has shipped, as of today, they were able to show, in some functional state, in June. For example, there was a demo involving a draft email message on an iPad, and the Apple rep used Writing Tools to make it “more friendly”. I was in a group of just four or five other members of the media, watching this. As usual, we were encouraged to interrupt with questions. Knowing that LLMs are non-deterministic, I asked whether, as the Apple rep was performing this same demo for each successive group of media members, the “more friendly” result was exactly the same each time. He laughed and said no — that while the results are very similar each time, and he hopes they continue to be (hence the laughing), that there were subtle differences sometimes between different runs of the same demo. As I recall, he even used Undo to go back to the original message text, invoked Writing Tools to make it “more friendly” again, and we could see that a few of the word choices were slightly different. That answered both my explicit question and my implicit one: Writing Tools generates non-deterministic results, and, more importantly, what we were watching really was a live demo. We didn’t get to try any of the Apple Intelligence features ourselves. There was no Apple Intelligence “hands on”. But we did see a bunch of features demoed, live, by Apple folks. In my above hierarchy of realness, they were all at level 1. But we didn’t see all aspects of Apple Intelligence demoed. None of the “more personalized Siri” features, the ones that Apple, in its own statement announcing their postponement, described as having “more awareness of your personal context, as well as the ability to take action for you within and across your apps”. Those features encompass three main things: “Personal context” — Knowing details and information about you from a “semantic index”, built from the contents of your email, messages, files, contacts, and more. In theory, eventually, all the information on your device that you wish to share with Siri will be in this semantic index. If you can look it up on your device, Siri will be able to look it up on your device. “Onscreen awareness” — Giving Siri awareness of whatever is displayed on your screen. Apple’s own example usage: “If a friend texts you their new address, you can say ‘Add this address to their contact card,’ and Siri will take care of it.” “In-app actions” — Giving Siri the ability, through the App Intents framework, to do things in and across apps that you can do, the old fashioned way (yourself) in and across apps. Again, here’s Apple’s own example usage: You can make a request like “Send the email I drafted to April and Lilly” and Siri knows which email you’re referencing and which app it’s in. And Siri can take actions across apps, so after you ask Siri to enhance a photo for you by saying “Make this photo pop,” you can ask Siri to drop it in a specific note in the Notes app — without lifting a finger. There were no demonstrations of any of that. Those features were all at level 0 on my hierarchy. That level is called vaporware. They were features Apple said existed, which they claimed would be shipping in the next year, and which they portrayed, to great effect, in the signature “Siri, when is my mom’s flight landing?” segment of the WWDC keynote itself, starting around the 1h:22m mark. Apple was either unwilling or unable to demonstrate those features in action back in June, even with Apple product marketing reps performing the demos from a prepared script using prepared devices. This shouldn’t have just raised a concern in my head. It should have set off blinding red flashing lights and deafening klaxon alarms. Even the very engineers working on a project never know exactly how long something is going to take to complete. An outsider observing a scripted demo of incomplete software knows far less (than the engineers) just how much more work it needs. But you can make a rough judgment. And that’s where my aforementioned hierarchy of realness comes into play. Even outsiders can judge how close a public beta (stage 3) feels to readiness. A feature or product that Apple will allow the press to play with, hands-on (stage 2) is further along than a feature or product that Apple is only willing to demonstrate themselves (stage 1). But a feature or product that Apple is unwilling to demonstrate, at all, is unknowable. Is it mostly working, and close to, but not quite, demonstratable? Is it only kinda sorta working — partially functional, but far from being complete? Fully functional but prone to crashing — or in the case of AI, prone to hallucinations and falsehoods? Or is it complete fiction, just an idea at this point? What Apple showed regarding the upcoming “personalized Siri” at WWDC was not a demo. It was a concept video. Concept videos are bullshit, and a sign of a company in disarray, if not crisis. The Apple that commissioned the futuristic “Knowledge Navigator” concept video in 1987 was the Apple that was on a course to near-bankruptcy a decade later. Modern Apple — the post-NeXT-reunification Apple of the last quarter century — does not publish concept videos. They only demonstrate actual working products and features. Until WWDC last year, that is. My deeply misguided mental framework for “Apple Intelligence” last year at WWDC was something like this: Some of these features are further along than others, and Apple is showing us those features in action first, and they will surely be the features that ship first over the course of the next year. The other features must be coming to demonstratable status soon. But the mental framework I should have used was more like this: Some of these features are merely table stakes for generative AI in 2024, but others are ambitious, groundbreaking, and, given their access to personal data, potentially dangerous. Apple is only showing us the table-stakes features, and isn’t demonstrating any of the ambitious, groundbreaking, risky features. It gets worse. Come September, Apple held its annual big event at Apple Park to unveil the iPhone 16 lineup. Apple Intelligence features were highlighted in the announcement. Members of the media from around the world were gathered. That was a new opportunity, three months after WWDC, for Apple to demonstrate — or even better, offer hands-on access to the press to try themselves — the new personalized Siri features. They did not. No demos, at all. But they did promote them, once again, in the event keynote.2 But yet while Apple still wouldn’t demonstrate these features in person, they did commission and broadcast a TV commercial showing these purported features in action, presenting them as a reason to purchase a new iPhone — a commercial they pulled, without comment, from YouTube this week. Last week’s announcement — “It’s going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year” — was, if you think about it, another opportunity to demonstrate the current state of these features. Rather than simply issue a statement to the media, they could have invited select members of the press to Apple Park, or Apple’s offices in New York, or even just remotely over a WebEx conference call, and demonstrated the current state of these features live, on an actual device. That didn’t happen. If these features exist in any sort of working state at all, no one outside Apple has vouched for their existence, let alone for their quality. Duke Nukem Intelligence Why did Apple show these personalized Siri features at WWDC last year, and promise their arrival during the first year of Apple Intelligence? Why, for that matter, do they now claim to “anticipate rolling them out in the coming year” if they still currently do not exist in demonstratable form? (If they do exist today in demonstratable form, they should, you know, demonstrate them.) I’m not trying to be obtuse here. It’s obvious why some executives at Apple might have hoped they could promote features like these at WWDC last year. Generative AI is the biggest thing to happen in the computer industry since previous breakthroughs this century like mobile (starting with the iPhone, followed by Android), social media (Meta), and cloud computing (Microsoft, Google, and Amazon). Nobody knows where it’s going but wherever it’s heading, it’s going to be big, important, and perhaps profitable. Wall Street certainly noticed. And prior to WWDC last year, Apple wasn’t in the game. They needed to pitch their AI story. And a story that involved nothing but table-stakes AI features isn’t nearly as compelling a story as one that involves innovative, breakthrough, ambitious personal features. But while there’s an obvious appeal to Apple pitching the most compelling, most ambitious AI story possible, the only thing that was essential was telling a story that was true. If the truth was that Apple only had features ready to ship in the coming year that were table stakes compared to the rest of the industry, that’s the story they needed to tell. Put as good a spin on it as possible, but them’s the breaks when you’re late to the game. The fiasco here is not that Apple is late on AI. It’s also not that they had to announce an embarrassing delay on promised features last week. Those are problems, not fiascos, and problems happen. They’re inevitable. Leaders prove their mettle and create their legacies not by how they deal with successes but by how they deal with — how they acknowledge, understand, adapt, and solve — problems. The fiasco is that Apple pitched a story that wasn’t true, one that some people within the company surely understood wasn’t true, and they set a course based on that. The Apple of the Jobs exile years — the Sculley / Spindler / Amelio Apple of 1987–1997 — promoted all sorts of amazing concepts that were no more real than the dinosaurs of Jurassic Park, and promised all sorts of hardware and (especially) software that never saw the light of day. Promoting what you hope to be able to someday ship is way easier and more exciting than promoting what you know is actually ready to ship. However close to financial bankruptcy Apple was when Steve Jobs returned as CEO after the NeXT reunification, the company was already completely bankrupt of credibility. Apple today is the most profitable and financially successful company in the history of the world. Everyone notices such success, and the corresponding accumulation of great wealth. Less noticed, but to my mind the more impressive achievement, is that over the last three decades, the company also accumulated an abundant reserve of credibility. When Apple showed a feature, you could bank on that feature being real. When they said something was set to ship in the coming year, it would ship in the coming year. In the worst case, maybe that “year” would have to be stretched to 13 or 14 months. You can stretch the truth and maintain credibility, but you can’t maintain credibility with bullshit. And the “more personalized Siri” features, it turns out, were bullshit. Keynote by keynote, product by product, feature by feature, year after year after year, Apple went from a company that you couldn’t believe would even remain solvent, to, by far, the most credible company in tech. Apple remains at no risk of financial bankruptcy (and in fact remains the most profitable company in the world). But their credibility is now damaged. Careers will end before Apple might ever return to the level of “if they say it, you can believe it” credibility the company had earned at the start of June 2024. Damaged is arguably too passive. It was squandered. This didn’t happen to Apple. Decision makers within the company did it. Who decided these features should go in the WWDC keynote, with a promise they’d arrive in the coming year, when, at the time, they were in such an unfinished state they could not be demoed to the media even in a controlled environment? Three months later, who decided Apple should double down and advertise these features in a TV commercial, and promote them as a selling point of the iPhone 16 lineup — not just any products, but the very crown jewels of the company and the envy of the entire industry — when those features still remained in such an unfinished or perhaps even downright non-functional state that they still could not be demoed to the press? Not just couldn’t be shipped as beta software. Not just couldn’t be used by members of the press in a hands-on experience, but could not even be shown to work by Apple employees on Apple-controlled devices in an Apple-controlled environment? But yet they advertised them in a commercial for the iPhone 16, when it turns out they won’t ship, in the best case scenario, until months after the iPhone 17 lineup is unveiled? When that whole campaign of commercials appeared, I — along with many other observers — was distracted by the fact that none of the features in Apple Intelligence had yet shipped. It’s highly unusual, and arguably ill-considered, for Apple to advertise any features that haven’t yet shipped. But one of those commercials was not at all like the others. The other commercials featured Apple Intelligence features that were close to shipping. We know today they were close to shipping because they were either in the iOS 18.1 betas already, in September, or would soon appear in developer betas for iOS 18.2 and 18.3. Right now, today, they’ve all actually shipped and are in the hands of iPhone 16 users. But the “Siri, what’s the name of the guy I had a meeting with a couple of months ago at Cafe Grenel?” commercial was entirely based on a feature Apple still has never even demonstrated. Who said “Sure, let’s promise this” and then “Sure, let’s advertise it”? And who said “Are you crazy, this isn’t ready, this doesn’t work, we can’t promote this now?” And most important, who made the call which side to listen to? Presumably, that person was Tim Cook. Even with everything Apple overpromised (if not outright lied about) at the WWDC keynote, the initial takeaway from WWDC from the news media was wrongly focused on their partnership with OpenAI. The conventional wisdom coming out of the keynote was that Apple had just announced something called “Apple Intelligence” but it was powered by ChatGPT, when in fact, the story Apple told was that they — Apple — had built an entire system called Apple Intelligence, entirely powered by Apple’s own AI technology, and that it spanned from on-device execution all the way to a new Private Cloud Compute infrastructure they not only owned but are powering with their own custom-designed server hardware based on Apple Silicon chips. And that on top of all that, as a proverbial cherry on top, Apple also was adding an optional integration layer with ChatGPT. So, yes, given that the news media gave credit for Apple’s own actual announced achievements to OpenAI, Apple surely would have been given even less credit had they not announced the “more personalized Siri” features. It’s easy to imagine someone in the executive ranks arguing “We need to show something that only Apple can do.” But it turns out they announced something Apple couldn’t do. And now they look so out of their depth, so in over their heads, that not only are they years behind the state-of-the-art in AI, but they don’t even know what they can ship or when. Their headline features from nine months ago not only haven’t shipped but still haven’t even been demonstrated, which I, for one, now presume means they can’t be demonstrated because they don’t work. ‘So Why the Fuck Doesn’t It Do That?’ In May 2011, Fortune published an extraordinary look inside Apple by Adam Lashinsky, at what we now know to be the peak, and (alas) end, of the Steve Jobs era. The piece opens thus: Apple doesn’t often fail, and when it does, it isn’t a pretty sight at 1 Infinite Loop. In the summer of 2008, when Apple launched the first version of its iPhone that worked on third-generation mobile networks, it also debuted MobileMe, an e-mail system that was supposed to provide the seamless synchronization features that corporate users love about their BlackBerry smartphones. MobileMe was a dud. Users complained about lost e-mails, and syncing was spotty at best. Though reviewers gushed over the new iPhone, they panned the MobileMe service. Steve Jobs doesn’t tolerate duds. Shortly after the launch event, he summoned the MobileMe team, gathering them in the Town Hall auditorium in Building 4 of Apple’s campus, the venue the company uses for intimate product unveilings for journalists. According to a participant in the meeting, Jobs walked in, clad in his trademark black mock turtleneck and blue jeans, clasped his hands together, and asked a simple question: “Can anyone tell me what MobileMe is supposed to do?” Having received a satisfactory answer, he continued, “So why the fuck doesn’t it do that?” For the next half-hour Jobs berated the group. “You’ve tarnished Apple’s reputation,” he told them. “You should hate each other for having let each other down.” The public humiliation particularly infuriated Jobs. Walt Mossberg, the influential Wall Street Journal gadget columnist, had panned MobileMe. “Mossberg, our friend, is no longer writing good things about us,” Jobs said. On the spot, Jobs named a new executive to run the group. Tim Cook should have already held a meeting like that to address and rectify this Siri and Apple Intelligence debacle. If such a meeting hasn’t yet occurred or doesn’t happen soon, then, I fear, that’s all she wrote. The ride is over. When mediocrity, excuses, and bullshit take root, they take over. A culture of excellence, accountability, and integrity cannot abide the acceptance of any of those things, and will quickly collapse upon itself with the acceptance of all three.",
  "image": "https://daringfireball.net/graphics/df-wide-card.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"Box\"\u003e\n\n\n\n\u003cp\u003eIn the two decades I’ve been in this racket, I’ve never been angrier at myself for missing a story than I am about Apple’s \u003ca href=\"https://daringfireball.net/2025/03/apple_is_delaying_the_more_personalized_siri_apple_intelligence_features\"\u003eannouncement on Friday\u003c/a\u003e that the “more personalized Siri” features of Apple Intelligence, scheduled to appear between now and WWDC, would be delayed until “the coming year”.\u003c/p\u003e\n\n\u003cp\u003eI should have my head examined. \u003c/p\u003e\n\n\u003cp\u003eThis announcement dropped as a surprise, and certainly took me by surprise to some extent, but it was all there from the start. I should have been pointing out red flags starting back at WWDC last year, and I am embarrassed and sorry that I didn’t see what should have been very clear to me from the start.\u003c/p\u003e\n\n\u003cp\u003eHow I missed this is twofold. First, I’d been lulled into complacency by Apple’s track record of consistently shipping pre-announced products and features. Their record in that regard wasn’t perfect, but the exceptions tended to be around the edges. (Nobody was particularly clamoring for Apple to make a multi-device inductive charging mat, so it never generated too much controversy \u003ca href=\"https://daringfireball.net/2025/03/apple_is_delaying_the_more_personalized_siri_apple_intelligence_features#fn1-2025-03-07\"\u003ewhen AirPower turned out to be a complete bust\u003c/a\u003e.) Second, I was foolishly distracted by the “Apple Intelligence” brand umbrella. It’s a fine idea for Apple to brand its AI features under an umbrella term like that, similar to how a bunch of disparate features that allow different Apple devices to interoperate are under the “\u003ca href=\"https://www.apple.com/macos/continuity/\"\u003eContinuity\u003c/a\u003e” umbrella. But there’s no such thing, technically speaking, as “Continuity”. It’s not like there’s an Xcode project inside Apple named Continuity.xcodeproj, and all the code that supports everything from AirDrop to Sidecar to iPhone Mirroring to clipboard sharing is all implemented in the same framework of code. It’s a marketing term, but a useful one — it helps Apple explain the features, and helps users understand them.\u003c/p\u003e\n\n\u003cp\u003eThe same goes for “Apple Intelligence”. It doesn’t exist as a single thing or project. It’s a marketing term for a collection of features, apps, and services. Putting it all under a single obvious, easily remembered — and \u003ca href=\"https://www.creativebloq.com/design/print-design-publishing/apples-new-billboard-ads-are-um-not-great\"\u003eeasily promoted\u003c/a\u003e — name makes it easier for users to understand that Apple is launching a new initiative. It also makes it easier for Apple to just say “\u003cem\u003eThese are the devices that qualify for all of these features, and other devices — older ones, less expensive ones — get none of them.\u003c/em\u003e”\u003c/p\u003e\n\n\u003cp\u003eLet’s say Apple were to quietly abandon the dumb Image Playground app next year. It just disappears from iOS 19 and MacOS 16. That would just be Apple eliminating a silly app that almost no one uses or should use. That wouldn’t be a setback or rollback of “Apple Intelligence”. I would actually argue that axing Image Playground would improve Apple Intelligence; its mere existence greatly lowers the expectations for how good the whole thing is.\u003csup id=\"fnr1-2025-03-12\"\u003e\u003ca href=\"#fn1-2025-03-12\"\u003e1\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\n\u003cp\u003eWhat I mean by that is that it was clear to me from the WWDC keynote onward that some of the features and aspects of Apple Intelligence were more ambitious than others. Some were downright trivial; others were proposing to redefine how we will do our jobs and interact with our most-used devices. That was clear. But yet somehow I didn’t focus on it. Apple itself strongly hinted that the various features in Apple Intelligence wouldn’t all ship at the same time. What they didn’t spell out, but anyone could intuit, was that the more trivial features would ship first, and the more ambitious features later. That’s where the red flags should have been obvious to me.\u003c/p\u003e\n\n\u003cp\u003eIn broad strokes, there are four stages of “doneness” or “realness” to features announced by any company:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e\u003cp\u003eFeatures that the company’s own product representatives will demo, themselves, in front of the media. Smaller, more personal demonstrations are more credible than on-stage demos. But the stakes for demo fail are higher in an auditorium full of observers.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eFeatures that the company will allow members of the media (or other invited outside observers and experts) to try themselves, for a limited time, under the company’s supervision and guidance. Vision Pro demos were like this at WWDC 2023. A bunch of us got to use pre-release hardware and in-progress software for 30 minutes. It wasn’t like free range “Do whatever you want” — it was a guided tour. But we were the ones actually using the product. Apple allowed hands-on demos for a handful of media (not me) at Macworld Expo \u003ca href=\"https://www.macworld.com/article/186251/ihnatkoiphone.html\"\u003eback in 2007 with prototype original iPhones\u003c/a\u003e — some of the “apps” were just screenshots, but most of the iPhone actually worked.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eFeatures that are released as beta software for developers, enthusiasts, and the media to use on their own devices, without limitation or supervision.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eFeatures that actually ship to regular users, and hardware that regular users can just go out and buy.\u003c/p\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eAs of today — March 2025 — every feature in Apple Intelligence \u003ca href=\"https://9to5mac.com/2025/02/26/this-is-every-apple-intelligence-feature-thats-available-now/\"\u003ethat has actually shipped\u003c/a\u003e was at level 1 back at WWDC. After the keynote, dozens of us in the press were invited to a series of small-group briefings where we got to watch Apple reps demo features like Writing Tools, Photos Clean Up, Genmoji, and more. We got to see predictive code completion in Xcode. What has shipped, as of today, they were able to show, in some functional state, in June.\u003c/p\u003e\n\n\u003cp\u003eFor example, there was a demo involving a draft email message on an iPad, and the Apple rep used Writing Tools to make it “more friendly”. I was in a group of just four or five other members of the media, watching this. As usual, we were encouraged to interrupt with questions. Knowing that LLMs are non-deterministic, I asked whether, as the Apple rep was performing this same demo for each successive group of media members, the “more friendly” result was exactly the same each time. He laughed and said no — that while the results are very similar each time, and he hopes they continue to be (hence the laughing), that there were subtle differences sometimes between different runs of the same demo. As I recall, he even used Undo to go back to the original message text, invoked Writing Tools to make it “more friendly” again, and we could see that a few of the word choices were slightly different. That answered both my explicit question and my implicit one: Writing Tools generates non-deterministic results, and, more importantly, what we were watching really was a live demo.\u003c/p\u003e\n\n\u003cp\u003eWe didn’t get to try any of the Apple Intelligence features ourselves. There was no Apple Intelligence “hands on”. But we did see a bunch of features demoed, live, by Apple folks. In my above hierarchy of realness, they were all at level 1.\u003c/p\u003e\n\n\u003cp\u003eBut we didn’t see \u003cem\u003eall\u003c/em\u003e aspects of Apple Intelligence demoed. None of the “more personalized Siri” features, the ones that Apple, \u003ca href=\"https://daringfireball.net/2025/03/apple_is_delaying_the_more_personalized_siri_apple_intelligence_features\"\u003ein its own statement announcing their postponement\u003c/a\u003e, described as having “more awareness of your personal context, as well as the ability to take action for you within and across your apps”. Those features encompass three main things:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e“Personal context” — Knowing details and information about you from a “semantic index”, built from the contents of your email, messages, files, contacts, and more. In theory, eventually, all the information on your device that you wish to share with Siri will be in this semantic index. If you can look it up on your device, Siri will be able to look it up on your device.\u003c/li\u003e\n\u003cli\u003e“Onscreen awareness” — Giving Siri awareness of whatever is displayed on your screen. \u003ca href=\"https://www.apple.com/apple-intelligence/\"\u003eApple’s own example usage\u003c/a\u003e: “If a friend texts you their new address, you can say ‘Add this address to their contact card,’ and Siri will take care of it.”\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e“In-app actions” — Giving Siri the ability, through the App Intents framework, to do things in and across apps that \u003cem\u003eyou\u003c/em\u003e can do, the old fashioned way (yourself) in and across apps. Again, here’s Apple’s own example usage:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eYou can make a request like “Send the email I drafted to April and\nLilly” and Siri knows which email you’re referencing and which app\nit’s in. And Siri can take actions across apps, so after you ask\nSiri to enhance a photo for you by saying “Make this photo pop,”\nyou can ask Siri to drop it in a specific note in the Notes app — without lifting a finger.\u003c/p\u003e\n\u003c/blockquote\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThere were no demonstrations of \u003cem\u003eany\u003c/em\u003e of that. Those features were all at level 0 on my hierarchy. That level is called vaporware. They were features Apple \u003cem\u003esaid\u003c/em\u003e existed, which they \u003cem\u003eclaimed\u003c/em\u003e would be shipping in the next year, and which they \u003cem\u003eportrayed\u003c/em\u003e, to great effect, in the signature “Siri, when is my mom’s flight landing?” segment of the WWDC keynote itself, \u003ca href=\"https://www.youtube.com/live/RXeOiIDNNek?t=4934\"\u003estarting around the 1h:22m mark\u003c/a\u003e. Apple was either unwilling or unable to demonstrate those features in action back in June, even with Apple product marketing reps performing the demos from a prepared script using prepared devices.\u003c/p\u003e\n\n\u003cp\u003eThis shouldn’t have just raised a concern in my head. It should have set off blinding red flashing lights and deafening klaxon alarms.\u003c/p\u003e\n\n\u003cp\u003eEven the very engineers working on a project never know exactly how long something is going to take to complete. An outsider observing a scripted demo of incomplete software knows far less (than the engineers) just how much more work it needs. But you can make a rough judgment. And that’s where my aforementioned hierarchy of realness comes into play. Even outsiders can judge how close a public beta (stage 3) feels to readiness. A feature or product that Apple will allow the press to play with, hands-on (stage 2) is further along than a feature or product that Apple is only willing to demonstrate themselves (stage 1).\u003c/p\u003e\n\n\u003cp\u003eBut a feature or product that Apple is unwilling to demonstrate, at all, is unknowable. Is it mostly working, and close to, but not quite, demonstratable? Is it only kinda sorta working — partially functional, but far from being complete? Fully functional but prone to crashing — or in the case of AI, prone to hallucinations and falsehoods? Or is it complete fiction, just an idea at this point?\u003c/p\u003e\n\n\u003cp\u003eWhat Apple showed regarding the upcoming “personalized Siri” at WWDC was \u003cem\u003enot\u003c/em\u003e a demo. It was a concept video. Concept videos are bullshit, and a sign of a company in disarray, if not crisis. \u003ca href=\"https://daringfireball.net/2011/11/companies_that_publish_concept_videos\"\u003eThe Apple that commissioned the futuristic “Knowledge Navigator” concept video\u003c/a\u003e in 1987 was the Apple that was on a course to near-bankruptcy a decade later. Modern Apple — the post-NeXT-reunification Apple of the last quarter century — does not publish concept videos. They only demonstrate actual working products and features.\u003c/p\u003e\n\n\u003cp\u003eUntil WWDC last year, that is.\u003c/p\u003e\n\n\u003cp\u003eMy deeply misguided mental framework for “Apple Intelligence” last year at WWDC was something like this: \u003cem\u003eSome of these features are further along than others, and Apple is showing us those features in action first, and they will surely be the features that ship first over the course of the next year. The other features must be coming to demonstratable status soon.\u003c/em\u003e But the mental framework I should have used was more like this: \u003cem\u003eSome of these features are merely table stakes for generative AI in 2024, but others are ambitious, groundbreaking, and, given their access to personal data, potentially dangerous. Apple is only showing us the table-stakes features, and isn’t demonstrating any of the ambitious, groundbreaking, risky features.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eIt gets worse. Come September, Apple held its annual big event at Apple Park to unveil the iPhone 16 lineup. Apple Intelligence features were highlighted in the announcement. Members of the media from around the world were gathered. That was a new opportunity, three months after WWDC, for Apple to demonstrate — or even better, offer hands-on access to the press to try themselves — the new personalized Siri features. They did not. No demos, at all. But they did promote them, once again, in the event keynote.\u003csup id=\"fnr2-2025-03-12\"\u003e\u003ca href=\"#fn2-2025-03-12\"\u003e2\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\n\u003cp\u003eBut yet while Apple still wouldn’t demonstrate these features in person, they did commission and broadcast a TV commercial showing these purported features in action, presenting them as a reason to purchase a new iPhone — \u003ca href=\"https://daringfireball.net/linked/2025/03/08/apple-pulls-bella-ramsey-ad-that-promoted-vaporware-personalized-siri-feature\"\u003ea commercial they pulled, without comment, from YouTube this week\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eLast week’s announcement — “It’s going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year” — was, if you think about it, another opportunity to demonstrate the current state of these features. Rather than simply issue a statement to the media, they could have invited select members of the press to Apple Park, or Apple’s offices in New York, or even just remotely over a WebEx conference call, and demonstrated the current state of these features live, on an actual device. That didn’t happen. If these features exist in any sort of working state at all, no one outside Apple has vouched for their existence, let alone for their quality.\u003c/p\u003e\n\n\u003ch2\u003eDuke Nukem Intelligence\u003c/h2\u003e\n\n\u003cp\u003eWhy did Apple show these personalized Siri features at WWDC last year, and promise their arrival during the first year of Apple Intelligence? Why, for that matter, do they now claim to “anticipate rolling them out in the coming year” if they still currently do not exist in demonstratable form? (If they \u003cem\u003edo\u003c/em\u003e exist today in demonstratable form, they should, you know, \u003cem\u003edemonstrate them\u003c/em\u003e.)\u003c/p\u003e\n\n\u003cp\u003eI’m not trying to be obtuse here. It’s obvious why some executives at Apple might have \u003cem\u003ehoped\u003c/em\u003e they could promote features like these at WWDC last year. Generative AI is the biggest thing to happen in the computer industry since previous breakthroughs this century like mobile (starting with the iPhone, followed by Android), social media (Meta), and cloud computing (Microsoft, Google, and Amazon). Nobody knows where it’s going but wherever it’s heading, it’s going to be big, important, and perhaps profitable. Wall Street certainly noticed. And prior to WWDC last year, Apple wasn’t in the game. They needed to pitch their AI story. And a story that involved nothing but table-stakes AI features isn’t nearly as compelling a story as one that involves innovative, breakthrough, ambitious personal features.\u003c/p\u003e\n\n\u003cp\u003eBut while there’s an obvious appeal to Apple pitching the most compelling, most ambitious AI story possible, the only thing that was essential was telling a story that was true. If the truth was that Apple only had features ready to ship in the coming year that were table stakes compared to the rest of the industry, that’s the story they needed to tell. Put as good a spin on it as possible, but them’s the breaks when you’re late to the game.\u003c/p\u003e\n\n\u003cp\u003eThe fiasco here is not that Apple is late on AI. It’s also not that they had to announce an embarrassing delay on promised features last week. Those are problems, not fiascos, and problems happen. They’re inevitable. Leaders prove their mettle and create their legacies not by how they deal with successes but by how they deal with — how they acknowledge, understand, adapt, and solve — problems. The fiasco is that Apple pitched a story that wasn’t true, one that \u003cem\u003esome\u003c/em\u003e people within the company surely understood wasn’t true, and they set a course based on that. \u003c/p\u003e\n\n\u003cp\u003eThe Apple of the Jobs exile years — the Sculley / Spindler / Amelio Apple of 1987–1997 — promoted all sorts of amazing concepts that were no more real than the dinosaurs of \u003cem\u003eJurassic Park\u003c/em\u003e, and promised all sorts of hardware and (especially) software that never saw the light of day. Promoting what you \u003cem\u003ehope\u003c/em\u003e to be able to someday ship is way easier and more exciting than promoting what you \u003cem\u003eknow\u003c/em\u003e is actually ready to ship. However close to financial bankruptcy Apple was when Steve Jobs returned as CEO after the NeXT reunification, the company was already completely bankrupt of credibility. Apple today is the most profitable and financially successful company in the history of the world. Everyone notices such success, and the corresponding accumulation of great wealth. Less noticed, but to my mind the more impressive achievement, is that over the last three decades, the company \u003cem\u003ealso\u003c/em\u003e accumulated an abundant reserve of credibility. When Apple showed a feature, you could bank on that feature being real. When they said something was set to ship in the coming year, it would ship in the coming year. In the worst case, maybe that “year” would have to be stretched to 13 or 14 months. You can stretch the truth and maintain credibility, but you can’t maintain credibility with bullshit. And the “more personalized Siri” features, it turns out, were bullshit.\u003c/p\u003e\n\n\u003cp\u003eKeynote by keynote, product by product, feature by feature, year after year after year, Apple went from a company that you couldn’t believe would even remain solvent, to, by far, the most credible company in tech. Apple remains at no risk of financial bankruptcy (and in fact remains the most profitable company in the world). But their credibility is now damaged. Careers will end before Apple might ever return to the level of “if they say it, you can believe it” credibility the company had earned at the start of June 2024.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eDamaged\u003c/em\u003e is arguably too passive. It was \u003cem\u003esquandered\u003c/em\u003e. This didn’t happen to Apple. Decision makers within the company did it.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eWho\u003c/em\u003e decided these features should go in the WWDC keynote, with a promise they’d arrive in the coming year, when, at the time, they were in such an unfinished state they could not be demoed to the media even in a controlled environment? Three months later, who decided Apple should double down and advertise these features in a TV commercial, and promote them as a selling point of the iPhone 16 lineup — not just any products, but the very crown jewels of the company and the envy of the entire industry — when those features still remained in such an unfinished or perhaps even downright non-functional state that they \u003cem\u003estill\u003c/em\u003e could not be demoed to the press? Not just couldn’t be shipped as beta software. Not just couldn’t be used by members of the press in a hands-on experience, but could not even be shown to work by Apple employees on Apple-controlled devices in an Apple-controlled environment? But yet they advertised them in a commercial for the iPhone 16, when it turns out they won’t ship, in the best case scenario, until months after the iPhone 17 lineup is unveiled?\u003c/p\u003e\n\n\u003cp\u003eWhen that whole campaign of commercials appeared, I — along with many other observers — was distracted by the fact that \u003cem\u003enone\u003c/em\u003e of the features in Apple Intelligence had yet shipped. It’s highly unusual, and arguably ill-considered, for Apple to advertise \u003cem\u003eany\u003c/em\u003e features that haven’t yet shipped. But one of those commercials was not at all like the others. The other commercials featured Apple Intelligence features that were close to shipping. We know today they were close to shipping because they were either in the iOS 18.1 betas already, in September, or would soon appear in developer betas for iOS 18.2 and 18.3. Right now, today, they’ve all actually shipped and are in the hands of iPhone 16 users. But the “Siri, what’s the name of the guy I had a meeting with a couple of months ago at Cafe Grenel?” commercial was entirely based on a feature Apple still has never even demonstrated.\u003c/p\u003e\n\n\u003cp\u003eWho said “\u003cem\u003eSure, let’s promise this\u003c/em\u003e” and then “\u003cem\u003eSure, let’s advertise it\u003c/em\u003e”? And who said “\u003cem\u003eAre you crazy, this isn’t ready, this doesn’t work, we can’t promote this now?\u003c/em\u003e” And most important, who made the call which side to listen to? Presumably, that person was Tim Cook.\u003c/p\u003e\n\n\u003cp\u003eEven with everything Apple overpromised (if not outright lied about) at the WWDC keynote, the initial takeaway from WWDC from the news media was wrongly focused on their partnership with OpenAI. The conventional wisdom coming out of the keynote was that Apple had just announced something called “Apple Intelligence” but it was powered by ChatGPT, when in fact, the story Apple told was that they — Apple — had built an entire system called Apple Intelligence, entirely powered by Apple’s own AI technology, and that it spanned from on-device execution all the way to a new Private Cloud Compute infrastructure they not only owned but are powering with their own custom-designed server hardware based on Apple Silicon chips. And that on top of all that, as a proverbial cherry on top, Apple \u003cem\u003ealso\u003c/em\u003e was adding an optional integration layer with ChatGPT.\u003c/p\u003e\n\n\u003cp\u003eSo, yes, given that the news media gave credit for Apple’s own actual announced achievements to OpenAI, Apple surely would have been given even \u003cem\u003eless\u003c/em\u003e credit had they not announced the “more personalized Siri” features. It’s easy to imagine someone in the executive ranks arguing “\u003cem\u003eWe need to show something that only Apple can do.\u003c/em\u003e” But it turns out they announced something Apple \u003cem\u003ecouldn’t\u003c/em\u003e do. And now they look so out of their depth, so in over their heads, that not only are they years behind the state-of-the-art in AI, but they don’t even know \u003cem\u003ewhat\u003c/em\u003e they can ship or \u003cem\u003ewhen\u003c/em\u003e. Their headline features from nine months ago not only haven’t shipped but still haven’t even been demonstrated, which I, for one, now presume means they \u003cem\u003ecan’t\u003c/em\u003e be demonstrated \u003cem\u003ebecause they don’t work\u003c/em\u003e.\u003c/p\u003e\n\n\u003ch2\u003e‘So Why the Fuck Doesn’t It Do That?’\u003c/h2\u003e\n\n\u003cp\u003eIn May 2011, \u003ca href=\"https://fortune.com/article/inside-apple/\"\u003eFortune published an extraordinary look inside Apple by Adam Lashinsky\u003c/a\u003e, at what we now know to be the peak, and (alas) end, of the Steve Jobs era. The piece opens thus:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eApple doesn’t often fail, and when it does, it isn’t a pretty\nsight at 1 Infinite Loop. In the summer of 2008, when Apple\nlaunched the first version of its iPhone that worked on\nthird-generation mobile networks, it also debuted MobileMe, an\ne-mail system that was supposed to provide the seamless\nsynchronization features that corporate users love about their\nBlackBerry smartphones. MobileMe was a dud. Users complained about\nlost e-mails, and syncing was spotty at best. Though reviewers\ngushed over the new iPhone, they panned the MobileMe service.\u003c/p\u003e\n\n\u003cp\u003eSteve Jobs doesn’t tolerate duds. Shortly after the launch event,\nhe summoned the MobileMe team, gathering them in the Town Hall\nauditorium in Building 4 of Apple’s campus, the venue the company\nuses for intimate product unveilings for journalists. According to\na participant in the meeting, Jobs walked in, clad in his\ntrademark black mock turtleneck and blue jeans, clasped his hands\ntogether, and asked a simple question:\u003c/p\u003e\n\n\u003cp\u003e“Can anyone tell me what MobileMe is supposed to do?” Having\nreceived a satisfactory answer, he continued, “So why the fuck\ndoesn’t it do that?”\u003c/p\u003e\n\n\u003cp\u003eFor the next half-hour Jobs berated the group. “You’ve tarnished\nApple’s reputation,” he told them. “You should hate each other for\nhaving let each other down.” The public humiliation particularly\ninfuriated Jobs. Walt Mossberg, the influential Wall Street\nJournal gadget columnist, had panned MobileMe. “Mossberg, our\nfriend, is no longer writing good things about us,” Jobs said. On\nthe spot, Jobs named a new executive to run the group.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eTim Cook should have already held a meeting like that to address and rectify this Siri and Apple Intelligence debacle. If such a meeting hasn’t yet occurred or doesn’t happen soon, then, I fear, that’s all she wrote. The ride is over. When mediocrity, excuses, and bullshit take root, they take over. A culture of excellence, accountability, and integrity cannot abide the acceptance of any of those things, and will quickly collapse upon itself with the acceptance of all three.\u003c/p\u003e\n\n\n\n\n\n \n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "24 min read",
  "publishedTime": null,
  "modifiedTime": null
}
