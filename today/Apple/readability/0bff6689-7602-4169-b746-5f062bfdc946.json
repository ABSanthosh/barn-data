{
  "id": "0bff6689-7602-4169-b746-5f062bfdc946",
  "title": "The M3 Ultra Mac Studio for Local LLMs",
  "link": "https://www.macstories.net/linked/the-m3-ultra-mac-studio-for-local-llms/",
  "description": "Speaking of the new Mac Studio and Apple making the best computers for AI: this is a terrific overview by Max Weinbach about the new M3 Ultra chip and its real-world performance with various on-device LLMs: The Mac I’ve been using for the past few days is the Mac Studio with M3 Ultra SoC, 32-core […]",
  "author": "Federico Viticci",
  "published": "Tue, 11 Mar 2025 16:41:19 +0000",
  "source": "https://www.macstories.net/feed",
  "categories": [
    "Linked",
    "AI",
    "Apple Silicon",
    "artificial intelligence",
    "developer tools",
    "developers",
    "M3"
  ],
  "byline": "",
  "length": 2030,
  "excerpt": "Speaking of the new Mac Studio and Apple making the best computers for AI: this is a terrific overview by Max Weinbach about the new M3 Ultra chip and its real-world performance with various on-device LLMs: The Mac I’ve been using for the past few days is the Mac Studio with M3 Ultra SoC, 32-core",
  "siteName": "",
  "favicon": "https://www.macstories.net/app/themes/macstories4/images/apple-touch-icon-152x152-precomposed.png",
  "text": "Speaking of the new Mac Studio and Apple making the best computers for AI: this is a terrific overview by Max Weinbach about the new M3 Ultra chip and its real-world performance with various on-device LLMs: The Mac I’ve been using for the past few days is the Mac Studio with M3 Ultra SoC, 32-core CPU, 80-core GPU, 256GB Unified Memory (192GB usable for VRAM), and 4TB SSD. It’s the fastest computer I have. It is faster in my workflows for even AI than my gaming PC (which will be used for comparisons below; it has an Intel i9 13900K, RTX 5090, 64GB of DDR5, and a 2TB NVMe SSD). It’s a very technical read, but the comparison between the M3 Ultra and a vanilla (non-optimized) RTX 5090 is mind-blogging to me. According to Weinbach, it all comes down to Apple’s MLX framework: I’ll keep it brief; the LLM performance is essentially as good as you’ll get for the majority of models. You’ll be able to run better models faster with larger context windows on a Mac Studio or any Mac with Unified Memory than essentially any PC on the market. This is simply the inherent benefit of not only Apple Silicon but Apple’s MLX framework (the reason we can efficiently run the models without preloading KV Cache into memory, as well as generate tokens faster as context windows grow). In case you’re not familiar, MLX is Apple’s open-source framework that – I’m simplifying – optimizes training and serving models on Apple Silicon’s unified memory architecture. It is a wonderful project with over 1,600 community models available for download. As Weinbach concludes: I see one of the best combos any developer can do as: M3 Ultra Mac Studio with an Nvidia 8xH100 rented rack. Hopper and Blackwell are outstanding for servers, M3 Ultra is outstanding for your desk. Different machines for a different use, while it’s fun to compare these for sport, that’s not the reality.⁠⁠ There really is no competition for an AI workstation today. The reality is, the only option is a Mac Studio. Don’t miss the benchmarks in the story.",
  "image": "https://56243e3f6f46fe44a301-deabeb5f3878e3553d0b065ea974f9bf.ssl.cf1.rackcdn.com/256px.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle id=\"content\"\u003e\n\n    \n\n    \u003cdiv\u003e\n                        \u003cp id=\"p1\"\u003eSpeaking of the new Mac Studio and \u003ca href=\"https://www.macstories.net/linked/is-apple-shipping-the-best-ai-computers/\" rel=\"noopener noreferrer\"\u003eApple making the best computers for AI\u003c/a\u003e: this is \u003ca href=\"https://creativestrategies.com/mac-studio-m3-ultra-ai-workstation-review/\" rel=\"noopener noreferrer\"\u003ea terrific overview by Max Weinbach\u003c/a\u003e about the new M3 Ultra chip and its real-world performance with various on-device LLMs:\u003c/p\u003e\n\u003cblockquote id=\"blockquote2\"\u003e\u003cp\u003e\n  The Mac I’ve been using for the past few days is the Mac Studio with M3 Ultra SoC, 32-core CPU, 80-core GPU, 256GB Unified Memory (192GB usable for VRAM), and 4TB SSD. It’s the fastest computer I have. It is faster in my workflows for even AI than my gaming PC (which will be used for comparisons below; it has an Intel i9 13900K, RTX 5090, 64GB of DDR5, and a 2TB NVMe SSD).\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp id=\"p3\"\u003eIt’s a very technical read, but the comparison between the M3 Ultra and a vanilla (non-optimized) RTX 5090 is mind-blogging to me. According to Weinbach, it all comes down to Apple’s MLX framework:\u003c/p\u003e\n\u003cblockquote id=\"blockquote4\"\u003e\u003cp\u003e\n  I’ll keep it brief; the LLM performance is essentially as good as you’ll get for the majority of models. You’ll be able to run better models faster with larger context windows on a Mac Studio or any Mac with Unified Memory than essentially any PC on the market. This is simply the inherent benefit of not only Apple Silicon but Apple’s MLX framework (the reason we can efficiently run the models without preloading KV Cache into memory, as well as generate tokens faster as context windows grow).\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp id=\"p5\"\u003eIn case you’re not familiar, \u003ca href=\"https://opensource.apple.com/projects/mlx/\" rel=\"noopener noreferrer\"\u003eMLX\u003c/a\u003e is Apple’s \u003ca href=\"https://github.com/ml-explore/mlx\" rel=\"noopener noreferrer\"\u003eopen-source\u003c/a\u003e framework that – I’m simplifying – optimizes training and serving models on Apple Silicon’s unified memory architecture. It is a wonderful project with over 1,600 \u003ca href=\"https://huggingface.co/mlx-community\" rel=\"noopener noreferrer\"\u003ecommunity models\u003c/a\u003e available for download.\u003c/p\u003e\n\u003cp id=\"p6\"\u003eAs Weinbach concludes:\u003c/p\u003e\n\u003cblockquote id=\"blockquote7\"\u003e\u003cp\u003e\n  I see one of the best combos any developer can do as: M3 Ultra Mac Studio with an Nvidia 8xH100 rented rack. Hopper and Blackwell are outstanding for servers, M3 Ultra is outstanding for your desk. Different machines for a different use, while it’s fun to compare these for sport, that’s not the reality.⁠⁠\u003c/p\u003e\n\u003cp\u003e  \u003cstrong\u003eThere really is no competition for an AI workstation today. The reality is, the only option is a Mac Studio.\u003c/strong\u003e\n\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp id=\"p8\"\u003eDon’t miss \u003ca href=\"https://creativestrategies.com/mac-studio-m3-ultra-ai-workstation-review/\" rel=\"noopener noreferrer\"\u003ethe benchmarks in the story\u003c/a\u003e.\u003c/p\u003e\n            \u003c/div\u003e\n\n    \n        \n\n    \n    \n    \n\u003c/article\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-03-11T16:41:19-04:00",
  "modifiedTime": null
}
