{
  "id": "7c77516a-e855-45e8-8145-4cebe9d046be",
  "title": "Ray-Ban Meta smart glasses will soon identify songs with Shazam",
  "link": "https://9to5mac.com/2024/12/17/ray-ban-meta-shazam/",
  "description": "Meta this week announced new features coming to its smart glasses designed in partnership with Ray-Ban. will soon gain new AI capabilities as well as integration with Apple’s Shazam to identify songs. more…",
  "author": "Filipe Espósito",
  "published": "Tue, 17 Dec 2024 23:48:56 +0000",
  "source": "https://9to5mac.com/feed",
  "categories": [
    "News"
  ],
  "byline": "Filipe Espósito",
  "length": 2629,
  "excerpt": "Meta this week announced new features coming to its smart glasses designed in partnership with Ray-Ban. Ray-Ban Meta glasses will...",
  "siteName": "9to5Mac",
  "favicon": "https://9to5mac.com/wp-content/uploads/sites/6/2019/10/cropped-cropped-mac1-1.png?w=192",
  "text": "Meta this week announced new features coming to its smart glasses designed in partnership with Ray-Ban. Ray-Ban Meta glasses will soon gain new AI capabilities as well as integration with Apple’s Shazam to identify songs. As announced by the company, software update v11 for the Ray-Ban Meta adds integration with Shazam, Apple’s song identification app. Once available, users will be able to simply use their voice to say “Hey Meta, what is this song?” and the glasses will use Shazam to recognize the song and answer the question. “We all know the feeling: You’re out on the town when an absolute banger starts playing—but either it’s new, obscure, or even an old favorite whose track name or artist just happens to escape you at that particular moment. Now, your glasses can do the heavy lifting for you,” Meta said in a blog post. This comes after Meta added Apple Music integration to its Ray-Ban smart glasses earlier this year. With this integration, those who own the glasses can ask Meta’s virtual assistant to play a song, playlist, album, station, or even artist – all hands-free. In addition to Shazam integration, Ray-Ban Meta glasses will also receive some new AI features with the update. One of them is Live AI, which will let users share what they’re seeing with their glasses in real time so that Meta AI can help them with everyday activities. With Live AI, users can ask questions without having to say “Hey Meta” all the time. In addition, Meta is also bringing Live Translation to its smart glasses. When talking to someone in another language, you’ll hear what they’ve said in your language through the glasses’ speakers. The feature was teased live earlier this year by Meta CEO Mark Zuckerberg. According to Meta, the v11 software update will begin rolling out starting today to Ray-Ban Meta glasses users. However, the AI features will only be available in beta for those registered in Meta’s Early Access Program. If you own a Ray-Ban Meta, here’s how to upgrade your smart glasses: Open the Meta View app on your phone Tap the Settings menu Choose the Your Glasses option Tap Updates Make sure your glasses are nearby, paired to your phone, and recharged before installing an update. Read also Buy Ray-Ban Meta smartglasses Meta announces expansion of its AI features to 21 additional countries Meta’s new AR glasses are what I want for the future of Apple Vision Apple launches new internal study focused on building smart glasses Add 9to5Mac to your Google News feed.  FTC: We use income earning auto affiliate links. More.",
  "image": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/04/ray-ban-meta.jpg?resize=1200%2C628\u0026quality=82\u0026strip=all\u0026ssl=1",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\t\t\t\n\u003cfigure\u003e\n\t\u003cimg width=\"1600\" height=\"901\" src=\"https://9to5mac.com/wp-content/uploads/sites/6/2024/04/ray-ban-meta.jpg?quality=82\u0026amp;strip=all\u0026amp;w=1600\" alt=\"Ray Ban Meta\" srcset=\"https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/04/ray-ban-meta.jpg?w=320\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/04/ray-ban-meta.jpg?w=640\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/04/ray-ban-meta.jpg?w=1024\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/04/ray-ban-meta.jpg?w=1500\u0026amp;quality=82\u0026amp;strip=all\u0026amp;ssl=1 1500w\" decoding=\"async\" fetchpriority=\"high\"/\u003e\u003c/figure\u003e\n\n\u003cp\u003eMeta this week announced new features coming to its smart glasses designed in partnership with Ray-Ban. \u003ca href=\"https://amzn.to/4gCR4eG\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRay-Ban Meta glasses\u003c/a\u003e will soon gain new AI capabilities as well as integration with Apple’s Shazam to identify songs.\u003c/p\u003e\n\n\n\n\n\n\n\n\u003cp\u003eAs announced by the company, software update v11 for the \u003ca href=\"https://amzn.to/4gCR4eG\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRay-Ban Meta\u003c/a\u003e adds integration with Shazam, Apple’s song identification app. Once available, users will be able to simply use their voice to say “Hey Meta, what is this song?” and the glasses will use Shazam to recognize the song and answer the question.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We all know the feeling: You’re out on the town when an absolute banger starts playing—but either it’s new, obscure, or even an old favorite whose track name or artist just happens to escape you at that particular moment. Now, your glasses can do the heavy lifting for you,” \u003ca href=\"https://www.meta.com/blog/quest/ray-ban-meta-v11-software-update-live-ai-translation-shazam/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMeta said in a blog post\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis comes after \u003ca href=\"https://9to5mac.com/2024/04/22/ray-ban-meta-glasses-apple-music/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMeta added Apple Music integration to its Ray-Ban smart glasses\u003c/a\u003e earlier this year. With this integration, those who own the glasses can ask Meta’s virtual assistant to play a song, playlist, album, station, or even artist – all hands-free.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn addition to Shazam integration, \u003ca href=\"https://amzn.to/4gCR4eG\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRay-Ban Meta glasses\u003c/a\u003e will also receive some new AI features with the update. One of them is Live AI, which will let users share what they’re seeing with their glasses in real time so that Meta AI can help them with everyday activities. With Live AI, users can ask questions without having to say “Hey Meta” all the time.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn addition, Meta is also bringing Live Translation to its smart glasses. When talking to someone in another language, you’ll hear what they’ve said in your language through the glasses’ speakers. The feature was \u003ca href=\"https://youtu.be/I7JyydkqDeI?si=Blk7jYtVFbzw196E\u0026amp;t=1696\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eteased live earlier this year by Meta CEO Mark Zuckerberg\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eAccording to Meta, the v11 software update will begin rolling out starting today to \u003ca href=\"https://amzn.to/4gCR4eG\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRay-Ban Meta glasses\u003c/a\u003e users. However, the AI features will only be available in beta for those registered in Meta’s Early Access Program.\u003c/p\u003e\n\n\n\n\u003cp\u003eIf you own a Ray-Ban Meta, here’s how to upgrade your smart glasses:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eOpen the \u003cstrong\u003e\u003ca href=\"https://apps.apple.com/us/app/meta-view/id1558240027?l=pt-BR\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMeta View app\u003c/a\u003e\u003c/strong\u003e on your phone\u003c/li\u003e\n\n\n\n\u003cli\u003eTap the \u003cstrong\u003eSettings\u003c/strong\u003e menu\u003c/li\u003e\n\n\n\n\u003cli\u003eChoose the \u003cstrong\u003eYour Glasses\u003c/strong\u003e option\u003c/li\u003e\n\n\n\n\u003cli\u003eTap \u003cstrong\u003eUpdates\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eMake sure your glasses are nearby, paired to your phone, and recharged before installing an update.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-read-also\"\u003eRead also\u003c/h2\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://amzn.to/4gCR4eG\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eBuy Ray-Ban Meta smartglasses\u003c/a\u003e\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://9to5mac.com/2024/10/09/meta-ai-more-countries/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMeta announces expansion of its AI features to 21 additional countries\u003c/a\u003e\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://9to5mac.com/2024/09/25/meta-ar-glasses-future-apple-vision/\"\u003eMeta’s new AR glasses are what I want for the future of Apple Vision\u003c/a\u003e\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003ca href=\"https://9to5mac.com/2024/11/04/apple-study-smart-glasses/\"\u003eApple launches new internal study focused on building smart glasses\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\t\u003cp\u003e\n\t\t\u003ca target=\"_blank\" rel=\"nofollow\" href=\"https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US\u0026amp;gl=US\u0026amp;ceid=US:en\"\u003e\n\t\t\t\u003cem\u003eAdd 9to5Mac to your Google News feed.\u003c/em\u003e \n\t\t\t\t\t\u003c/a\u003e\n\t\u003c/p\u003e\n\t\u003cdiv\u003e\u003cp\u003e\u003cem\u003eFTC: We use income earning auto affiliate links.\u003c/em\u003e \u003ca href=\"https://9to5mac.com/about/#affiliate\"\u003eMore.\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://bit.ly/4eWBGsp\"\u003e\u003cimg src=\"https://9to5mac.com/wp-content/uploads/sites/6/2024/12/XGIMI-750-150.jpg?quality=82\u0026amp;strip=all\" alt=\"\" width=\"750\" height=\"150\"/\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\t\t\t\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2024-12-17T23:48:56Z",
  "modifiedTime": "2024-12-17T23:50:20Z"
}
