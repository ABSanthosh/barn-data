{
  "id": "de21cabf-c5a8-45cb-bfb4-5e1aa1e3ed37",
  "title": "ByteDance has been building an AI music beast… with a little help from The Beatles and Michael Jackson",
  "link": "https://www.musicbusinessworldwide.com/bytedance-has-been-building-an-ai-music-beast-with-a-little-help-from-the-beatles-and-michael-jackson/",
  "description": "ByteDance is fascinated with building music AI technologies... Source",
  "author": "Murray Stassen",
  "published": "Wed, 12 Feb 2025 19:37:19 +0000",
  "source": "https://www.musicbusinessworldwide.com/feed/",
  "categories": [
    "Analysis",
    "News"
  ],
  "byline": "Murray Stassen",
  "length": 11750,
  "excerpt": "ByteDance is fascinated with building music AI technologies…",
  "siteName": "Music Business Worldwide",
  "favicon": "https://www.musicbusinessworldwide.com/wp-content/themes/mb/assets/img/icons/favicon-192x192.png",
  "text": "TikTok’s $300 billion-valued parent company, ByteDance, is one of the world’s busiest AI developers. It plans to spend billions of dollars on AI chips this year, while its tech gives Sam Altman’s OpenAI a run for its money.ByteDance’s Duobao AI chatbot is currently the most popular AI assistant in China, with 78.6 million monthly active users as of January. This makes it the world’s second most-used AI app behind OpenAI’s ChatGPT (with 349.4 million MAUs). The recently released Doubao-1.5-pro is claimed to match the performance of OpenAI’s GPT-4o at a fraction of the cost.As Counterpoint Research notes in this breakdown of Duobao’s positioning and functionality, “much like its international rival ChatGPT, the cornerstone of Doubao’s appeal is its multimodality, offering advanced text, image, and audio processing capabilities”. It can also generate music.In September, ByteDance added an AI music generation function to the Duobao app, which apparently “supports more than ten types of music styles and allows you to write lyrics and compose music with one click”.This, though, isn’t the end of ByteDance’s fascination with building music AI technologies. On September 18, ByteDance’s Duobao Team announced the big launch of a suite of AI music models dubbed Seed-Music.Seed-Music, they claimed, would “empower people to explore more possibilities in music creation”.Established in 2023, the ByteDance Doubao (Seed) Team is “dedicated to building industry-leading AI foundation models”.According to the official launch announcement for Seed-Music in September, the AI music product “supports score-to-song conversion, controllable generation, music and lyrics editing, and low-threshold voice cloning”.It also claims that “it cleverly combines the strengths of language models and diffusion models and integrates them into the music composition workflow, making it suitable for different music creation scenarios for both beginners and professionals”.The official Seed-Music website contains a number of audio clips that demonstrate what it can do.You can hear some of that, below:More important, though, is how Seed-Music was built.Luckily, the Duobao Team has published a tech report that explains the inner workings of their Seed-Music project. MBW has read it cover to cover.In the introduction to ByteDance’s research paper, which you can read in full here, the company’s researchers state that, “music is deeply embedded in human culture” and that “throughout human history, vocal music has accompanied key moments in life and society: from love calls to seasonal harvests”.“Our goal is to leverage modern generative modeling technologies, not to replace human creativity, but to lower the barriers to music creation.”ByeDance research paper for Seed-MusicThe intro continues: “Today, vocal music remains central to global culture. However, creating vocal music is a complex, multi-stage process involving pre-production, writing, recording, editing, mixing, and mastering, making it challenging for most people.”“Our goal is to leverage modern generative modeling technologies, not to replace human creativity, but to lower the barriers to music creation. By offering interactive creation and editing tools, we aim to empower both novices and professionals to engage at different stages of the music production process.”How Seed-Music worksByteDance’s researchers explain that the “unified framework” behind Seed-Music “is built upon three fundamental representations: audio tokens, symbolic tokens, and vocoder latents”, which each correspond to “a generation pipeline.”The audio token-based pipeline, as illustrated in the chart below, works like this: “(1) Input embedders convert multi-modal controlling inputs, such as music style description, lyrics, reference audio, or music scores, into a prefix embedding sequence. (2) The auto-regressive LM generates a sequence of audio tokens. (3) The diffusion transformer model generates continuous vocoder latents. (4) The acoustic vocoder produces high-quality 44.1kHz stereo audio.”In contrast to the audio token-based pipeline, the symbolic token-based Generator, which you can see in the chart below, is “designed to predict symbolic tokens for better interpretability”, which the researchers state is “crucial for addressing musicians’ workflows in Seed-Music”.According to the research paper, “Symbolic representations, such as MIDI, ABC notation and MusicXML, are discrete and can be easily tokenized into a format compatible with LMs”.ByteDance’s researchers add in the paper: “Unlike audio tokens, symbolic representations are interpretable, allowing creators to read and modify them directly. However, their lack of acoustic details means the system has to rely heavily on the Renderer’s ability to generate nuanced acoustic characteristics for musical performance. Training such a Renderer requires large-scale datasets of paired audio and symbolic transcriptions, which are especially scarce for vocal music.”The obvious question…By now, you’re probably asking where The Beatles and Michael Jackson’s music come into all of this.We’re nearly there. First, we need to talk about MIRs.According to the Seed-Music research paper, “to extract the symbolic features from audio for training the above system,” the team behind the tech used various “in-house Music Information Retrieval (MIR) models”.According to this very clear explanation over at Dataloop, MIR “is a subcategory of AI models that focuses on extracting meaningful information from music data, such as audio signals, lyrics, and metadata”.Aka: It’s a metadata scraper. Stick a song into the jaws of a MIR model, and it will analyze, predict and present data that might include pitch, beats-per-minute (BPM), lyrics, chords, and more.Music Information Retrieval research first gained popularity over its ability to help with the digital classification of genres, moods, tempos, etc. – key building blocks for recommendation systems used by music streaming services.Now, though, leading generative AI music platforms are reportedly using MIR research to improve their product output.Can you see where this is going? Yes, of course.ByteDance’s research team has successfully built its own in-house MIR models, which have been used by the ByteDance team to “extract the symbolic features from audio” to build parts of its Seed-Music system. Those MIR models include:Beat tracking;Key and chord detection;Structural section segmentation;Five-instrument MIDI transcription (i.e., vocals, piano, guitar, bass, and drums) and;Singing lyrics transcription.AI, are you okay? Are you okay, AI?Taking a deeper dive into the research published by ByteDance for its Structural analysis-focused MIR model, we find a research paper titled:‘To catch a chorus, verse, intro, or anything else: Analyzing a song with structural functions’. It was published in 2022. You can read it here.According to the paper: “Conventional music structure analysis algorithms aim to divide a song into segments and to group them with abstract labels (e.g., ‘A’, ‘B’, and ‘C’).“However, explicitly identifying the function of each segment (e.g., ‘verse’ or ‘chorus’) is rarely attempted, but has many applications”.In this research paper, they “introduce a multi-task deep learning framework to model these structural semantic labels directly from audio by estimating ‘verseness,’ ‘chorusness,’ and so forth, as a function of time”.To conduct this research, the ByteDance team used four “public datasets”, including one called the ‘Isophonics’ dataset, which, it notes, “contains 277 songs from The Beatles, Carole King, Michael Jackson, and Queen.”The source of the Isophonics dataset used by ByteDance’s researchers appears to be Isophonics.net, described as the home for software and data resources from the Centre for Digital Music (C4DM) at Queen Mary, University of London.The Isophonics website notes that its “chord, onset, and segmentation annotations have been used by many researchers in the MIR community.”The website explains that “the annotations published here fall into four categories: chords, keys, structural segmentations, and beats/bars”.In 2022, ByteDance’s researchers published a video presentation of their, To catch a chorus, verse, intro, or anything else: Analyzing a song with structural functions paper for the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).You can see this presentation below.The video’s caption describes a “novel system/method that segments a song into sections such as chorus, verse, intro, outro, bridge, etc”.It demonstrates its findings related to songs by the Beatles, Michael Jackson, Avril Lavigne and other artists:We must be careful here over any suggestion that ByteDance’s AI music-generating technology may have been “trained” using songs by popular artists like the Beatles or Michael Jackson.Yet, as you can see, a dataset containing annotations of such songs has clearly been used as a part of a ByteDance research project in this field.Any analysis or reference to popular songs and their annotations in research conducted or funded by a multi-billion-dollar technology company will surely raise a number of questions for the music industry – especially those employed to protect its copyrights.“We firmly believe that AI technologies should support, not disrupt, the livelihoods of musicians and artists. AI should serve as a tool for artistic expression, as true art always stems from human intention.”ByteDance’s Seed-Music researchersThere is a section dedicated to Ethics and Safety at the bottom of ByteDance’s Seed-Music research paper.According to ByteDance’s researchers, they “firmly believe that AI technologies should support, not disrupt, the livelihoods of musicians and artists“.They add: “AI should serve as a tool for artistic expression, as true art always stems from human intention. Our goal is to present this technology as an opportunity to advance the music industry by lowering barriers to entry, offering smarter, faster editing tools, generating new and exciting sounds, and opening up new possibilities for artistic exploration.”The ByteDance researchers also outline ethical issues specifically: “We recognize that AI tools are inherently prone to bias, and our goal is to provide a tool that stays neutral and benefits everyone. To achieve this, we aim to offer a wide range of control elements that help minimize preexisting biases.“By returning artistic choices to users, we believe we can promote equality, preserve creativity, and enhance the value of their work. With these priorities in mind, we hope our breakthroughs in lead sheet tokens highlight our commitment to empowering musicians and fostering human creativity through AI.”In terms of Safety / ‘deepfake’ concerns, the researchers explain that, “in the case of vocal music, we recognize how the singing voice evokes one of the strongest expressions of individual identity”.They add: “To safeguard against the misuse of this technology in impersonating others, we adopt a process similar to the safety measures laid out in Seed-TTS. This involves a multistep verification method for spoken content and voice to ensure the enrollment of audio tokens contains only the voice of authorized users.“We also implement a multi-level water-marking scheme and duplication checks across the generative process. Modern systems for music generation may fundamentally reshape culture and the relationship between artistic creation and consumption.“We are confident that, with strong consensus between stakeholders, these technologies will and revolutionize music creation workflow and benefit music novices, professionals, and listeners alike.”Music Business Worldwide",
  "image": "https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eTikTok’s \u003cstrong\u003e$300 billion-\u003ca target=\"_blank\" href=\"https://www.reuters.com/technology/tiktok-parent-bytedances-valuation-hits-300-billion-amid-us-ban-uncertainty-wsj-2024-11-16/\" rel=\"noopener\"\u003evalued \u003c/a\u003eparent company\u003c/strong\u003e\u003cspan\u003e\u003cstrong\u003e, \u003c/strong\u003e\u003ca title=\"Companies \u0026gt; ByteDance [347 articles]\" href=\"https://www.musicbusinessworldwide.com/companies/bytedance/\"\u003eByteDance\u003c/a\u003e, is one of the world’s busiest AI developers. It plans to \u003ca href=\"https://www.musicbusinessworldwide.com/bytedance-eyes-12b-ai-chip-investment-this-year-amid-tiktok-uncertainty-report/\" target=\"_blank\" rel=\"noopener\"\u003espend billions\u003c/a\u003e of dollars on AI chips this year, while\u003c/span\u003e its tech gives Sam Altman’s OpenAI a run for its money.\u003c/p\u003e\u003cp\u003eByteDance’s\u003cstrong\u003e Duobao\u003c/strong\u003e AI chatbot is currently the most popular AI assistant in China\u003cspan\u003e, with \u003cstrong\u003e78.6 million\u003c/strong\u003e monthly active users as of January. \u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eThis\u003c/span\u003e \u003ca href=\"https://mp.weixin.qq.com/s/lWbzaiIm8hRMu9xgy5NFKg\" target=\"_blank\" rel=\"noopener\"\u003emakes it\u003c/a\u003e the world’s second most-used AI app behind OpenAI’s \u003cstrong\u003eChatGPT \u003c/strong\u003e(with\u003cstrong\u003e 349.4 million MAUs). \u003c/strong\u003eThe recently released Doubao-1.5-pro is \u003ca href=\"https://www.marktechpost.com/2025/01/25/bytedance-ai-introduces-doubao-1-5-pro-language-model-with-a-deep-thinking-mode-and-matches-gpt-4o-and-claude-3-5-sonnet-benchmarks-at-50x-cheaper/\" target=\"_blank\" rel=\"noopener\"\u003eclaimed\u003c/a\u003e to match the performance of OpenAI’s GPT-4o at a fraction of the cost.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eAs Counterpoint Research notes\u003ca href=\"https://www.counterpointresearch.com/insight/post-insight-research-notes-blogs-why-bytedances-doubao-is-1-chatbot-in-china\" target=\"_blank\" rel=\"noopener\"\u003e in this breakdown\u003c/a\u003e of \u003cstrong\u003eDuobao’s\u003c/strong\u003e positioning and functionality, “much like its international rival ChatGPT, the cornerstone of Doubao’s appeal is its multimodality, offering advanced text, image, and audio processing capabilities”. \u003c/span\u003e\u003c/p\u003e\u003cp\u003eIt can also \u003ca href=\"https://genaigazette.com/bytedances-doubao-unveils-ai-music-tool/\" target=\"_blank\" rel=\"noopener\"\u003egenerate music\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIn September, ByteDance added\u003cstrong\u003e an AI music generation function to the\u003ca href=\"https://apps.apple.com/cn/app/%E8%B1%86%E5%8C%85-%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E6%97%97%E4%B8%8Bai%E5%8A%A9%E6%89%8B/id6459478672\" target=\"_blank\" rel=\"noopener\"\u003e Duobao app\u003c/a\u003e, \u003c/strong\u003ewhich apparently \u003cstrong\u003e“\u003c/strong\u003esupports more than ten types of music styles and allows you to write lyrics and compose music with one click”.\u003c/p\u003e\u003cp\u003eThis, though, isn’t the end of \u003cstrong\u003eByteDance’s\u003c/strong\u003e fascination with building music AI technologies.\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09.jpg\"\u003e\n\n\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-80x29.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-80x29.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-160x59.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-320x118.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-418x154.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-648x238.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-836x307.jpg 836w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-80x29.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-80x29.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-160x59.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-320x118.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-418x154.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-648x238.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.06.09-836x307.jpg 836w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eOn September 18, ByteDance’s \u003cstrong\u003eDuobao Team\u003c/strong\u003e announced the\u003ca href=\"https://team.doubao.com/en/blog/seed-music-music-large-model-officially-released-exceling-in-both-music-generation-and-editing-covering-ten-types-of-creative-tasks-to-meet-diverse-needs?view_from=blog\" target=\"_blank\" rel=\"noopener\"\u003e big launch\u003c/a\u003e of a suite of\u003cstrong\u003e AI music models\u003c/strong\u003e dubbed \u003cstrong\u003eSeed-Music.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSeed-Music\u003c/strong\u003e, they claimed, would “empower people to explore more possibilities in music creation”.\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-80x48.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-80x48.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-160x96.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-320x191.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-418x250.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-648x387.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-836x499.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-1296x774.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-80x48.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-80x48.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-160x96.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-320x191.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-418x250.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-648x387.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-836x499.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.38.39-1296x774.jpg 1296w\"/\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eEstablished in 2023, the\u003cstrong\u003e ByteDance Doubao (Seed) Team\u003c/strong\u003e is “dedicated to building industry-leading AI foundation models”.\u003c/p\u003e\u003cp\u003eAccording to the official launch announcement for \u003cstrong\u003eSeed-Music\u003c/strong\u003e in September, the AI music product “supports score-to-song conversion, controllable generation, music and lyrics editing, and low-threshold voice cloning”.\u003c/p\u003e\u003cp\u003eIt also claims that “it cleverly combines the strengths of language models and diffusion models and integrates them into the music composition workflow, making it suitable for different music creation scenarios for both beginners and professionals”.\u003c/p\u003e\u003cp\u003eThe official \u003ca href=\"https://team.doubao.com/en/special/seed-music\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eSeed-Music \u003c/strong\u003ewebsite\u003c/a\u003e contains a number of audio clips that demonstrate what it can do.\u003c/p\u003e\u003cp\u003eYou can hear some of that, below:\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/8JwQvyKomE4?si=bWkWYJvLgv-GXs5x\" frameborder=\"0\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003cspan\u003eMore important, though, is \u003cem\u003ehow\u003c/em\u003e \u003cstrong\u003eSeed-Music\u003c/strong\u003e was built.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eLuckily, the \u003cstrong\u003eDuobao Team \u003c/strong\u003ehas published a tech report that explains the inner workings of their \u003cstrong\u003eSeed-Music \u003c/strong\u003eproject. \u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMBW\u003c/strong\u003e has read it cover to cover.\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-80x44.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-80x44.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-160x88.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-320x176.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-418x230.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-648x357.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-836x461.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-1296x714.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-80x44.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-80x44.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-160x88.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-320x176.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-418x230.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-648x357.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-836x461.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-14.46.40-1296x714.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003e\u003cspan\u003eIn the introduction to \u003cstrong\u003eByteDance’s\u003c/strong\u003e research paper, which you can \u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Seed-Music-A-Unified-Framework-for-High-Quality-and-Controlled-Music-Generation.pdf\"\u003eread in full here,\u003c/a\u003e the company’s researchers state that, “m\u003c/span\u003eusic is deeply embedded in human culture” and that “throughout human history, \u003cstrong\u003evocal music has accompanied key moments in life and society\u003c/strong\u003e: from love calls to seasonal harvests”.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e“Our goal is to leverage modern generative modeling technologies, not to replace human creativity, but to lower the barriers to music creation.”\u003c/p\u003e\u003cp\u003e\u003cspan\u003eByeDance research paper for Seed-Music\u003c/span\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eThe intro continues: “Today, vocal music remains central to global culture. However, creating vocal music is a complex, multi-stage process involving pre-production, writing, recording, editing, mixing, and mastering, \u003cstrong\u003emaking it challenging for most people\u003c/strong\u003e.”\u003c/p\u003e\u003cp\u003e“Our goal is to leverage modern generative modeling technologies, \u003cstrong\u003enot to replace human creativity, but to lower the barriers to music creation.\u003c/strong\u003e By offering interactive creation and editing tools, we aim to empower both novices and professionals to engage at different stages of the music production process.”\u003c/p\u003e\u003chr/\u003e\u003ch6\u003eHow Seed-Music works\u003c/h6\u003e\u003cp\u003eByteDance’s researchers explain that the “unified framework” behind Seed-Music “is built upon three fundamental representations: \u003cstrong\u003eaudio tokens, symbolic tokens, and vocoder latents”, \u003c/strong\u003ewhich each correspond to\u003cstrong\u003e “a generation pipeline.”\u003c/strong\u003e\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-80x36.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-80x36.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-160x73.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-320x145.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-418x189.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-648x294.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-836x379.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-1296x587.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-80x36.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-80x36.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-160x73.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-320x145.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-418x189.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-648x294.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-836x379.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-14.39.28-1296x587.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eThe \u003cstrong\u003eaudio token\u003c/strong\u003e-based pipeline, as illustrated in the chart below, works like this: “(1) Input embedders convert multi-modal controlling inputs, such as music style description, lyrics, reference audio, or music scores, into a prefix embedding sequence. (2) The auto-regressive LM generates a sequence of audio tokens. (3) The diffusion transformer model generates continuous vocoder latents. (4) The acoustic vocoder produces high-quality 44.1kHz stereo audio.”\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-80x22.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-80x22.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-160x44.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-320x88.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-418x114.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-648x177.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-836x229.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-1296x355.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-80x22.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-80x22.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-160x44.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-320x88.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-418x114.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-648x177.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-836x229.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.41.30-1296x355.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eIn contrast to the audio token-based pipeline, the \u003cstrong\u003esymbolic token\u003c/strong\u003e-based Generator, which you can see in the chart below, is “designed to predict symbolic tokens for better interpretability”, which the researchers state is “crucial for addressing musicians’ workflows in Seed-Music”.\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-80x14.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-80x14.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-160x28.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-320x56.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-418x73.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-648x113.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-836x146.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-1296x226.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-80x14.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-80x14.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-160x28.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-320x56.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-418x73.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-648x113.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-836x146.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-15.46.48-1296x226.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eAccording to the research paper, “Symbolic representations, such as \u003cstrong\u003eMIDI\u003c/strong\u003e, \u003cstrong\u003eABC\u003c/strong\u003e \u003cstrong\u003enotation\u003c/strong\u003e and \u003cstrong\u003eMusicXML\u003c/strong\u003e, are discrete and can be easily tokenized into a format compatible with LMs”.\u003c/p\u003e\u003cp\u003eByteDance’s researchers add in the paper: “Unlike audio tokens, symbolic representations are interpretable, \u003cstrong\u003eallowing creators to read and modify them directly\u003c/strong\u003e. However, their lack of acoustic details means the system has to rely heavily on the Renderer’s ability to generate nuanced acoustic characteristics for musical performance. Training such a Renderer requires\u003cstrong\u003e large-scale datasets of paired audio and symbolic transcriptions\u003c/strong\u003e, which are especially scarce for vocal music.”\u003c/p\u003e\u003chr/\u003e\u003ch6\u003eThe obvious question…\u003c/h6\u003e\u003cp\u003eBy now, you’re probably asking where \u003cstrong\u003eThe\u003c/strong\u003e \u003cstrong\u003eBeatles\u003c/strong\u003e and \u003cstrong\u003eMichael Jackson’s\u003c/strong\u003e music come into all of this.\u003c/p\u003e\u003cp\u003eWe’re nearly there. First, we need to talk about \u003cstrong\u003eMIRs\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eAccording to the \u003cstrong\u003eSeed-Music\u003c/strong\u003e research paper, “to extract the symbolic features from audio for training the above system,” the team behind the tech used various “in-house \u003cstrong\u003eMusic Information Retrieval\u003c/strong\u003e (MIR) models”.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eAccording to \u003ca href=\"https://dataloop.ai/library/model/subcategory/music_information_retrieval_2181/\" target=\"_blank\" rel=\"noopener\"\u003ethis very clear explanation\u003c/a\u003e over at Dataloop, \u003cstrong\u003eMIR\u003c/strong\u003e \u003cstrong\u003e“is a subcategory of AI models that focuses on extracting meaningful information from music data, such as audio signals, lyrics, and metadata”.\u003c/strong\u003e\u003c/span\u003e\u003c/p\u003e\u003cp\u003eAka: It’s a\u003cstrong\u003e metadata scraper\u003c/strong\u003e. Stick a song into the jaws of a MIR model, and it will analyze, predict and present data that might include \u003cstrong\u003epitch, beats-per-minute (BPM), lyrics, chords, and more.\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003e\u003cstrong\u003eMusic Information Retrieval\u003c/strong\u003e research first gained popularity over its ability to help with the digital classification of genres, moods, tempos, etc. – key building blocks for recommendation systems \u003ca href=\"https://www.gov.uk/government/publications/research-into-the-impact-of-streaming-services-algorithms-on-music-consumption/the-impact-of-algorithmically-driven-recommendation-systems-on-music-consumption-and-production-a-literature-review\" target=\"_blank\" rel=\"noopener\"\u003eused by music streaming services.\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\u003cp\u003eNow, though, leading \u003cstrong\u003egenerative AI music platforms\u003c/strong\u003e are reportedly\u003ca href=\"https://www.ircamamplify.io/blog/ai-generated-music-identification-journey\" target=\"_blank\" rel=\"noopener\"\u003e \u003c/a\u003e\u003cspan\u003e\u003ca href=\"https://www.ircamamplify.io/blog/ai-generated-music-identification-journey\" target=\"_blank\" rel=\"noopener\"\u003eusing MIR research\u003c/a\u003e to improve their product output\u003c/span\u003e.\u003c/p\u003e\u003chr/\u003e\u003cp\u003eCan you see where this is going? Yes, of course.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eByteDance’s\u003c/strong\u003e research team has successfully built its own in-house \u003cstrong\u003eMIR\u003c/strong\u003e models, which have been used by the \u003cstrong\u003eByteDance\u003c/strong\u003e team to “extract the symbolic features from audio” to build parts of its Seed-Music system. Those MIR models include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/pdf/2205.14701\" target=\"_blank\" rel=\"noopener\"\u003eBeat tracking\u003c/a\u003e;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/pdf/2110.09127\" target=\"_blank\" rel=\"noopener\"\u003eKey and chord detection\u003c/a\u003e;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/pdf/2205.14700\" target=\"_blank\" rel=\"noopener\"\u003eStructural section segmentation\u003c/a\u003e;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/pdf/2306.10785\" target=\"_blank\" rel=\"noopener\"\u003eFive-instrument MIDI transcription\u003c/a\u003e (i.e., vocals, piano, guitar, bass, and drums) and;\u003c/li\u003e\u003cli\u003eSinging lyrics transcription.\u003c/li\u003e\u003c/ul\u003e\u003chr/\u003e\u003ch6\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson.jpg\"\u003e\u003cimg data-srcset=\"https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-80x80.jpg 80w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-160x160.jpg 160w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-320x320.jpg 320w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-418x418.jpg 418w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-648x648.jpg 648w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-836x836.jpg 836w\" data-sizes=\"auto\" srcset=\"https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-80x80.jpg 80w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-160x160.jpg 160w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-320x320.jpg 320w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-418x418.jpg 418w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-648x648.jpg 648w, https://www.musicbusinessworldwide.com/files/2023/07/1.-Michael-Jackson-836x836.jpg 836w\"/\u003e\u003c/a\u003e\u003c/figure\u003eAI, are you okay? Are you okay, AI?\u003c/h6\u003e\u003cp\u003eTaking a deeper dive into the research published by ByteDance for its \u003ca href=\"https://arxiv.org/pdf/2205.14700\" target=\"_blank\" rel=\"noopener\"\u003eStructural analysis\u003c/a\u003e-focused \u003cstrong\u003eMIR model\u003c/strong\u003e, we find a research paper titled:\u003c/p\u003e\u003cp\u003e\u003cem\u003e\u003cstrong\u003e‘To catch a chorus, verse, intro, or anything else: Analyzing a song with structural functions’. \u003c/strong\u003e\u003c/em\u003e\u003c/p\u003e\u003cp\u003eIt was published in 2022. You \u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/catcha-chorus.pdf\" target=\"_blank\" rel=\"noopener\"\u003ecan read it here.\u003c/a\u003e\u003c/p\u003e\u003cp\u003eAccording to the paper: “Conventional music structure analysis algorithms aim to divide a song into segments and to group them with abstract labels (e.g., ‘A’, ‘B’, and ‘C’).\u003c/p\u003e\u003cp\u003e“However, explicitly identifying the function of each segment \u003cstrong\u003e(e.g., ‘verse’ or ‘chorus’)\u003c/strong\u003e is rarely attempted, but has many applications”.\u003c/p\u003e\u003cp\u003eIn this research paper, they “introduce a multi-task deep learning framework to model these structural semantic labels directly from audio by estimating\u003cstrong\u003e ‘verseness,’ ‘chorusness,’\u003c/strong\u003e and so forth, as a function of time”.\u003c/p\u003e\u003cp\u003eTo conduct this research, the ByteDance team used four “public datasets”, including one called the ‘\u003cstrong\u003eIsophonics’ \u003c/strong\u003edataset\u003cstrong\u003e, \u003c/strong\u003ewhich, it notes, “contains \u003cstrong\u003e277\u003c/strong\u003e songs from \u003cstrong\u003eThe Beatles\u003c/strong\u003e, \u003cstrong\u003eCarole\u003c/strong\u003e \u003cstrong\u003eKing\u003c/strong\u003e, \u003cstrong\u003eMichael\u003c/strong\u003e \u003cstrong\u003eJackson\u003c/strong\u003e, and \u003cstrong\u003eQueen\u003c/strong\u003e.”\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-80x45.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-80x45.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-160x90.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-320x179.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-418x234.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-648x363.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-836x468.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-1296x726.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-80x45.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-80x45.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-160x90.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-320x179.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-418x234.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-648x363.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-836x468.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.19.27-1296x726.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eThe source of the \u003cstrong\u003eIsophonics dataset\u003c/strong\u003e used by ByteDance’s researchers appears to be \u003ca href=\"https://isophonics.net/datasets\" target=\"_blank\" rel=\"noopener\"\u003e\u003cb\u003eIsophonics.net\u003c/b\u003e\u003c/a\u003e, described as the home for software and data resources from the Centre for Digital Music (C4DM) at Queen Mary, University of London.\u003c/p\u003e\u003cp\u003eThe Isophonics website notes that its “chord, onset, and segmentation \u003cstrong\u003eannotations\u003c/strong\u003e have been used by many researchers in the \u003cstrong\u003eMIR\u003c/strong\u003e community.”\u003c/p\u003e\u003cp\u003eThe website explains that “the annotations published here fall into four categories: chords, keys, structural segmentations, and beats/bars”.\u003c/p\u003e\u003cp\u003eIn 2022, ByteDance’s researchers published a video presentation of their, \u003cstrong\u003e\u003cem\u003eTo catch a chorus, verse, intro, or anything else: Analyzing a song with structural functions\u003c/em\u003e\u003c/strong\u003e paper for the International Conference on Acoustics, Speech, and Signal Processing (ICASSP).\u003c/p\u003e\u003cp\u003eYou can see this presentation below.\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003ciframe src=\"https://www.youtube.com/embed/WdP5R7Fg8to?si=rw29XPvb_g-GswYS\" frameborder=\"0\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003eThe video’s caption describes a “novel system/method that segments a song into sections such as chorus, verse, intro, outro, bridge, etc”.\u003c/p\u003e\u003cp\u003eIt demonstrates its findings related to songs by \u003cstrong\u003ethe Beatles, Michael Jackson, Avril Lavigne\u003c/strong\u003e and other artists:\u003c/p\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-80x44.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-80x44.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-160x88.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-320x176.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-418x230.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-648x357.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-836x461.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-1296x714.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-80x44.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-80x44.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-160x88.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-320x176.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-418x230.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-648x357.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-836x461.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-11-at-17.17.14-1296x714.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-80x45.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-80x45.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-160x90.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-320x180.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-418x235.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-648x364.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-836x470.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-1296x729.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-80x45.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-80x45.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-160x90.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-320x180.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-418x235.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-648x364.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-836x470.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.42.46-1296x729.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cfigure\u003e\u003ca href=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28.jpg\" target=\"_blank\" rel=\"noopener\"\u003e\u003cimg src=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-80x45.jpg\" data-srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-80x45.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-160x90.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-320x179.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-418x234.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-648x363.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-836x468.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-1296x725.jpg 1296w\" data-sizes=\"auto\" data-cfsrc=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-80x45.jpg\" srcset=\"https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-80x45.jpg 80w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-160x90.jpg 160w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-320x179.jpg 320w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-418x234.jpg 418w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-648x363.jpg 648w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-836x468.jpg 836w, https://www.musicbusinessworldwide.com/files/2025/02/Screenshot-2025-02-12-at-16.44.28-1296x725.jpg 1296w\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003chr/\u003e\u003cp\u003eWe must be careful here over any suggestion that \u003cstrong\u003eByteDance’s AI music-generating technology\u003c/strong\u003e may have been “trained” using songs by popular artists like the\u003cstrong\u003e Beatles\u003c/strong\u003e or \u003cstrong\u003eMichael Jackson\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eYet, as you can see, a \u003cstrong\u003edataset containing annotations of such songs\u003c/strong\u003e has clearly been used as a part of a \u003cstrong\u003eByteDance\u003c/strong\u003e research project in this field.\u003c/p\u003e\u003cp\u003eAny analysis or reference to popular songs and their annotations in research conducted or funded by a \u003cstrong\u003emulti-billion-dollar technology company\u003c/strong\u003e will surely raise a number of questions for the music industry – especially those employed to protect its copyrights.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e“We firmly believe that AI technologies should support, not disrupt, the livelihoods of musicians and artists. AI should serve as a tool for artistic expression, as true art always stems from human intention.”\u003c/p\u003e\u003cp\u003e\u003cspan\u003eByteDance’s \u003cstrong\u003eSeed-Music researchers\u003c/strong\u003e\u003c/span\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003chr/\u003e\u003cp\u003eThere is a section dedicated to Ethics and Safety at the bottom of ByteDance’s \u003cstrong\u003eSeed-Music\u003c/strong\u003e research paper.\u003c/p\u003e\u003cp\u003eAccording to \u003cstrong\u003eByteDance’s\u003c/strong\u003e researchers, they “firmly believe that AI technologies \u003cstrong\u003eshould support, not disrupt, the livelihoods of musicians and artists\u003c/strong\u003e“.\u003c/p\u003e\u003cp\u003eThey add: “AI should serve as a tool for artistic expression, as true art always stems from human intention. Our goal is to present this technology as \u003cstrong\u003ean opportunity to advance the music industry\u003c/strong\u003e by lowering barriers to entry, offering smarter, faster editing tools, generating new and exciting sounds, and opening up new possibilities for artistic exploration.”\u003c/p\u003e\u003cp\u003eThe \u003cstrong\u003eByteDance\u003c/strong\u003e researchers also outline ethical issues specifically: “We recognize that AI tools are inherently prone to bias, and our goal is to provide a tool that stays neutral and benefits everyone. To achieve this, we aim to offer a wide range of control elements that help minimize preexisting biases.\u003c/p\u003e\u003cp\u003e“By returning \u003cstrong\u003eartistic choices to users\u003c/strong\u003e, we believe we can promote equality, preserve creativity, and enhance the value of their work. With these priorities in mind, we hope our breakthroughs in lead sheet tokens highlight our commitment to empowering musicians and fostering human creativity through AI.”\u003c/p\u003e\u003chr/\u003e\u003cp\u003eIn terms of Safety / ‘deepfake’ concerns, the researchers explain that, “in the case of vocal music, we recognize how the \u003cstrong\u003esinging voice\u003c/strong\u003e evokes one of the strongest expressions of individual identity”.\u003c/p\u003e\u003cp\u003eThey add: “To safeguard against the misuse of this technology in impersonating others, we adopt a process similar to the safety measures laid out in \u003cstrong\u003eSeed-TTS\u003c/strong\u003e. This involves a multistep verification method for spoken content and voice to ensure the enrollment of audio tokens contains only the voice of authorized users.\u003c/p\u003e\u003cp\u003e“We also implement a multi-level water-marking scheme and duplication checks across the \u003cstrong\u003egenerative process\u003c/strong\u003e. Modern systems for music generation may fundamentally reshape culture and the relationship between artistic creation and consumption.\u003c/p\u003e\u003cp\u003e“We are confident that, with strong consensus between stakeholders, these technologies will and revolutionize music creation workflow and benefit music novices, professionals, and listeners alike.”\u003cspan\u003eMusic Business Worldwide\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2025-02-12T19:37:19Z",
  "modifiedTime": "2025-02-12T20:34:54Z"
}
