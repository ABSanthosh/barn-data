{
  "id": "581943f8-9bae-4cb1-985b-5b7173f97527",
  "title": "Efficient Render Passes — On Tile-Based Rendering Hardware",
  "link": "https://medium.com/androiddevelopers/efficient-render-passes-on-tile-based-rendering-hardware-621070158e40?source=rss----95b274b437c2---4",
  "description": "",
  "author": "Shahbaz Youssefi",
  "published": "Fri, 09 Aug 2024 19:43:41 GMT",
  "source": "https://medium.com/feed/androiddevelopers",
  "categories": [
    "opengl",
    "games",
    "android",
    "vulkan",
    "graphics-programming"
  ],
  "byline": "Shahbaz Youssefi",
  "length": 15765,
  "excerpt": "There are currently two major classes of GPU architectures: Immediate-Mode Rendering (IMR) and Tile-Based Rendering (TBR). The IMR architecture is older, somewhat simpler and more forgiving to…",
  "siteName": "Android Developers",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "OverviewThere are currently two major classes of GPU architectures: Immediate-Mode Rendering (IMR) and Tile-Based Rendering (TBR).The IMR architecture is older, somewhat simpler and more forgiving to inefficiently written applications, but it’s power hungry. Often found in desktop GPU cards, this architecture is known to provide high performance while consuming hundreds of watts of power.The TBR architecture on the other hand can be very energy efficient, as it can minimize access to RAM as a major source of energy draw in typical rendering. Often found in mobile and battery-powered devices, these GPUs could consume as little as single digit watts of power. However, this architecture’s performance heavily depends on correct application usage.In comparison with IMR GPUs, TBR GPUs have some advantages (such as efficient multisampling) and disadvantages (such as inefficient geometry and tessellation shaders). For more information, see this blog post. Some GPU vendors produce hybrid architectures, and some manage to consume little power with IMR hardware on mobile devices, but in most GPU architectures used in mobile devices, it’s the TBR features that make low power consumption possible.In this post, I’ll explain one of the most important features of TBR hardware, how it can be most efficiently used, how Vulkan makes it very easy to do that, and how OpenGL ES makes it so easy to ruin performance and what you can do to avoid that.Efficient Rendering on TBR HardwareWithout going into too much detail, TBR hardware operates on the concept of “render passes”. Each render pass is a set of draw calls to the same “framebuffer” with no interruptions. For example, say a render pass in the application issues 1000 draw calls.TBR hardware takes these 1000 draw calls, runs the pre-fragment shaders and figures out where each triangle falls in the framebuffer. It then divides the framebuffer in small regions (called tiles) and redraws the same 1000 draw calls in each of them separately (or rather, whichever triangles actually hit that tile).The tile memory is effectively a cache that you can’t get unlucky with. Unlike CPU and many other caches, where bad access patterns can cause thrashing, the tile memory is a cache that is loaded and stored at most once per render pass. As such, it is highly efficient.So, let’s put one tile into focus.Memory accesses between RAM, Tile Memory and shader cores. The Tile Memory is a form of fast cache that is (optionally) loaded or cleared on render pass start and (optionally) stored at render pass end. The shader cores only access this memory for framebuffer attachment output and input (through input attachments, otherwise known as framebuffer fetch).In the above diagram, there are a number of operations, each with a cost:Fragment shader invocation: This is the real cost of the application’s draw calls. The fragment shader may also access RAM for texture sampling etc, not shown in the diagram. While this cost is significant, it is irrelevant to this discussion.Fragment shader attachment access: Color and depth/stencil data is found on the tile memory, access to which is lightning fast and consumes very little power. This cost is also irrelevant to this discussion.Tile memory load: This costs time and energy, as accessing RAM is slow. Fortunately, TBR hardware has ways to avoid this cost:- Skip the load and leave the contents of the framebuffer on the tile memory undefined (for example because they are going to be completely overwritten)- Skip the load and clear the contents of the framebuffer on the tile memory directlyTile memory store: This is at least as costly as load. TBR hardware has ways to avoid this cost too:- Skip the store and drop the contents of the framebuffer on the tile memory (for example because that data is no longer needed)- Skip the store because the render pass did not modify the values that were previously loadedThe most important takeaway from the above is:Avoid load at all costsAvoid store at all costsThis is trivial with Vulkan, but easier said than done with OpenGL. If you are on the fence about moving to Vulkan, the extra work of managing descriptor sets, command buffers, etc will all be worth the tremendous gain from creating fewer render passes with the appropriate load and store ops.Render Passes in VulkanVulkan natively has a concept of render passes and load and store operations, directly mapping to the TBR features above. Take a set of attachments (some color, maybe a depth/stencil) in a render pass, they will have load ops (corresponding to “Tile memory load” as described in the section above) and store ops (corresponding to “Tile memory store”). Inside the render pass, only a few calls are allowed; notably calls that set state, bind resources and draw calls.You can create render passes with VK_KHR_dynamic_rendering (modern approach) or VkRenderPass objects (original approach). Either way, you can configure the load and store operations of each render pass attachment directly.Possible load ops are:LOAD_OP_CLEAR: This means that the attachment is to be cleared when the render pass starts. This is very cheap, as it is done directly on tile memory.LOAD_OP_LOAD: This means that the attachment contents are to be loaded from RAM. This is very slow.LOAD_OP_DONT_CARE: This means that the attachment is not loaded from RAM, and its contents are initially garbage. This has no cost.Possible store ops are:STORE_OP_STORE: This means that the attachment contents are to be stored to RAM. This is very slow.STORE_OP_DONT_CARE: This means that the attachment is not stored to RAM, and its contents are thrown away. This has no cost.STORE_OP_NONE: This means that the attachment is not stored to RAM because the render pass never wrote to the attachment at all. This has no cost.An ideal render pass could look like the following:Use LOAD_OP_CLEAR on all attachments (very cheap)Numerous draw callsUse STORE_OP_STORE on the primary color attachment, and STORE_OP_DONT_CARE on ancillary attachments (such as depth/stencil, g-buffers, etc) (minimum store cost)For multisampling, the ops are similar. See this blog post for further details regarding multisampling.You can achieve highly efficient rendering on TBR hardware with Vulkan by keeping the render passes as few as possible and avoiding unnecessary load and store operations.Mapping to OpenGLUnfortunately, OpenGL does not guide the application towards efficient rendering on TBR hardware (unlike Vulkan). As such, mobile drivers have accumulated a number of heroics to reorder the stream of operations issued by the applications as otherwise their performance would be abysmal. These heroics are the source of most corner case bugs you might have encountered in these drivers, and understandably so; they make the driver much more complicated.Do yourself a favor and upgrade to Vulkan!Still here? Alright, let’s see how we can make an OpenGL application issue calls that would lead to ideal render passes. The best way to understand that is actually by mapping a few key OpenGL calls to Vulkan concepts, as they match the hardware very well. So first, read the Render Passes in Vulkan section above!Now let’s see how to do that with OpenGL.Step 1: Do NOT Unnecessarily Break the Render PassThis is extremely important, and the number one source of inefficiency in apps and heroics in drivers. What does it mean to break the render pass? Take the ideal render pass in the previous section: what happens if in between the numerous draw calls, an action is performed that cannot be encoded in the render pass?Say out of 1000 draw calls needed for the scene, you’ve issued 600 of them and now need a quick clear of a placeholder texture to sample from in the next draw call. You bind that texture to a temp framebuffer, bind that framebuffer and clear it, then bind back the original framebuffer and issue the rest of the 400 draw calls. Real applications (plural) do this!But, the render pass cannot hold a clear command for an unrelated image (it can only do that for the render pass’s attachments). The result would be two render passes:(original render pass’s load ops)600 draw callsRender pass breaks: Use STORE_OP_STORE on all attachments (super expensive)Clear a tiny textureUse LOAD_OP_LOAD on all attachments (super expensive)400 draw calls(original render pass’s store ops)OpenGL drivers actually optimize this and shuffle the clear call before the render pass and avoid the render pass break … if you’re lucky.What causes a render pass to break? A number of things:The obvious: things that need the work to get to the GPU right now, such as glFinish(), glReadPixels(), glClientWaitSync(), eglSwapBuffers(), etc.Binding a different framebuffer (glBindFramebuffer()), or mutating the currently bound one (e.g. glFramebufferTexture2D()): This is the most common reason for render pass breaks. Very important not to unnecessarily do this. Please!Synchronization requirements: For example, glMapBufferRange() after writing to the buffer in the render pass, glDispatchCompute() writing to a resource that was used in the render pass, glGetQueryObjectuiv(GL_QUERY_RESULT) for a query used in the render pass, etc.Other possibly surprising reasons, such as enabling depth write to a depth/stencil attachment that was previously in a read-only feedback loop (i.e. simultaneously used for depth/stencil testing and sampled in a texture)!The best way to avoid render pass breaks is to model the OpenGL calls after the equivalent Vulkan application would have:Separate non-render-pass calls from render pass calls and do them before the draw calls.During the render pass, only bind things (NOT framebuffers), set state and issue draw calls. Nothing else!Step 2: Control the Load and Store OpsOpenGL has its roots in IMR hardware, where load and store ops effectively don’t exist (other than LOAD_OP_CLEAR of course). They are ignored in Vulkan implementations on IMR hardware today (again, other than LOAD_OP_CLEAR). As demonstrated above however, they are very important for TBR hardware, and unlucky for us, support for them was not directly added to OpenGL.Instead, there is a combination of two separate calls that controls load and store ops of a render pass attachment. You have to make these calls just before the render pass starts and just after the render pass ends, which as we saw above it is not at all obvious when it happens. Enter driver heroics to reorder app commands of course.The two calls are the following:glClear() and family: When this call is made before the render pass starts, it results in the corresponding attachment’s load op to become LOAD_OP_CLEAR.glInvalidateFramebuffer(): If this call is made before the render pass starts, it results in the corresponding attachment’s load op to become LOAD_OP_DONT_CARE. If this call is made after the render pass ends, the corresponding attachment’s store op may become STORE_OP_DONT_CARE (if the call is not made too late).Because the glClear() call is made before the render pass starts, and because applications make that call in really random places, mobile drivers go to great lengths to defer the clear call such that if and when a render pass starts with such an attachment, its load op can be turned into LOAD_OP_CLEAR. This means that generally the application can clear the attachments much earlier than the render pass starts and still get this good load op. Beware that scissored/masked clears and scissored render passes thwart all that however.For glInvalidateFramebuffer(), the driver tracks which subresources of the attachment have valid or invalid contents. When done earlier than the render pass starts, this can easily lead to the attachment’s load op to become LOAD_OP_DONT_CARE. To get the store op to become STORE_OP_DONT_CARE however, there is nothing the driver can do if the app makes the call at the wrong time.To get the ideal render pass then, the application would have to make the calls as such:glClear() or glClearBuffer*() or glInvalidateFramebuffer() (can be done earlier)Numerous draw callsglInvalidateFramebuffer() for ancillary attachments.It is of the utmost importance for the glInvalidateFramebuffer() call to be made right after the last draw call. Anything else happening in between may make it too late for the driver to adjust the store op of the attachments. There is a slight difference for multisampling, explained in this blog post.Step 3: Get Help From ANGLENow you’ve gone through the trouble of implementing all that in your application or game, but how do you know it’s actually working? Sure, FPS is doubled and battery lasts much longer, but are all optimizations working as expected?You can get help from a project called ANGLE (slated to be the future OpenGL ES driver on Android, already available in Android 15). ANGLE is an OpenGL layer on top of Vulkan (among other APIs, but that’s irrelevant here), which means that it’s an OpenGL driver that does all the same heroics as native drivers, except it produces Vulkan API calls and so is one driver that works on all GPUs.There are two things about ANGLE that make it very handy in optimizing OpenGL applications for TBR hardware.One is that its translation to Vulkan is user-visible. Since Vulkan render passes map perfectly to TBR hardware, by inspecting the generated Vulkan render passes one can determine whether their OpenGL code can be improved and how. My favorite way of doing that is taking a Vulkan RenderDoc capture of an OpenGL application running over ANGLE.Notice a LOAD_OP_LOAD that’s unnecessary? Clear the texture, or invalidate it!Notice a STORE_OP_STORE that’s unnecessary? Put a glInvalidateFramebuffer() at the right place.Is STORE_OP_STORE still there? That was not the right place!Have more render passes than you expected? See next point.The other is that it declares why a render pass has ended. In a RenderDoc capture, this shows up at the end of each render pass, which can be used to verify that the render pass break was intended. If it wasn’t intended, together with the API calls around the render pass break, the provided information can help you figure out what OpenGL call sequence has caused it. For example, in this capture of a unit test, the render pass is broken due to a call to glReadPixels() (as hinted at by the following vkCmdCopyImageToBuffer call):ANGLE can be instructed to include the OpenGL calls that lead to a given Vulkan call in the trace, which can make figuring things out easier. ANGLE is open source, feel free to inspect the code if that helps you understand the reason for render pass breaks more easily.While on this subject, you might find it helpful that ANGLE issues performance warnings when it detects inefficient use of OpenGL (in other scenarios unrelated to render passes). These warnings are reported through the GL_KHR_debug extension’s callback mechanism, are logged and also show up in a RenderDoc capture. You might very well find other OpenGL pitfalls you have fallen into.ConclusionVulkan may seem complicated at first, but it does one thing very well; it maps well to hardware. While an OpenGL application may be shorter in lines-of-code, in a way it’s more complicated to write a good OpenGL application especially for TBR hardware because of its lack of structure.Whether you end up upgrading to Vulkan or staying with OpenGL, you’d do very well to learn Vulkan. If nothing else, learning Vulkan will help you write better OpenGL code.If your future holds more OpenGL code, I sincerely hope that the above knowledge helps you produce OpenGL code that is not too much slower than the Vulkan equivalent would. And don’t hesitate to try ANGLE out to improve your performance, people who do have found great success with it!",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*lwikiSNGN5X2xyJRr1mZag.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ca rel=\"noopener follow\" href=\"https://medium.com/@syoussefi?source=post_page-----621070158e40--------------------------------\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Shahbaz Youssefi\" src=\"https://miro.medium.com/v2/da:true/resize:fill:88:88/0*1thOJ-DDFdofqivL\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003ca href=\"https://medium.com/androiddevelopers?source=post_page-----621070158e40--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Android Developers\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*4Tg6pPzer7cIarYaszIKaQ.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003ch2 id=\"1a0a\"\u003eOverview\u003c/h2\u003e\u003cp id=\"d473\"\u003eThere are currently two major classes of GPU architectures: Immediate-Mode Rendering (IMR) and Tile-Based Rendering (TBR).\u003c/p\u003e\u003cp id=\"5138\"\u003eThe IMR architecture is older, somewhat simpler and more forgiving to inefficiently written applications, but it’s power hungry. Often found in desktop GPU cards, this architecture is known to provide high performance while consuming hundreds of watts of power.\u003c/p\u003e\u003cp id=\"3b7d\"\u003eThe TBR architecture on the other hand can be \u003cstrong\u003every\u003c/strong\u003e energy efficient, as it can minimize access to RAM as a major source of energy draw in typical rendering. Often found in mobile and battery-powered devices, these GPUs could consume as little as single digit watts of power. However, this architecture’s performance heavily depends on correct application usage.\u003c/p\u003e\u003cp id=\"18bf\"\u003eIn comparison with IMR GPUs, TBR GPUs have some advantages (such as \u003ca rel=\"noopener\" href=\"https://medium.com/p/21794c479cb9\"\u003eefficient multisampling\u003c/a\u003e) and disadvantages (such as inefficient geometry and tessellation shaders). For more information, see \u003ca href=\"https://www.rastergrid.com/blog/gpu-tech/2021/07/gpu-architecture-types-explained/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethis blog post\u003c/a\u003e. Some GPU vendors produce hybrid architectures, and some manage to consume little power with IMR hardware on mobile devices, but in most GPU architectures used in mobile devices, it’s the TBR features that make low power consumption possible.\u003c/p\u003e\u003cp id=\"2d59\"\u003eIn this post, I’ll explain one of the most important features of TBR hardware, how it can be most efficiently used, how Vulkan makes it very easy to do that, and how OpenGL ES makes it so easy to ruin performance and what you can do to avoid that.\u003c/p\u003e\u003ch2 id=\"3aa9\"\u003eEfficient Rendering on TBR Hardware\u003c/h2\u003e\u003cp id=\"e9cc\"\u003eWithout going into too much detail, TBR hardware operates on the concept of “render passes”. Each render pass is a set of draw calls to the same “framebuffer” with no interruptions. For example, say a render pass in the application issues 1000 draw calls.\u003c/p\u003e\u003cp id=\"cdb1\"\u003eTBR hardware takes these 1000 draw calls, runs the pre-fragment shaders and figures out where each triangle falls in the framebuffer. It then divides the framebuffer in small regions (called \u003cem\u003etiles\u003c/em\u003e) and redraws the same 1000 draw calls in each of them separately (or rather, whichever triangles actually hit that tile).\u003c/p\u003e\u003cp id=\"d908\"\u003eThe tile memory is effectively a cache that you can’t get unlucky with. Unlike CPU and many other caches, where bad access patterns can cause thrashing, the tile memory is a cache that is loaded and stored at most once per render pass. As such, it is \u003cem\u003ehighly efficient\u003c/em\u003e.\u003c/p\u003e\u003cp id=\"0952\"\u003eSo, let’s put one tile into focus.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cem\u003eMemory accesses between RAM, Tile Memory and shader cores. The Tile Memory is a form of fast cache that is (optionally) loaded or cleared on render pass start and (optionally) stored at render pass end. The shader cores only access this memory for framebuffer attachment output and input (through input attachments, otherwise known as framebuffer fetch).\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"1f8c\"\u003eIn the above diagram, there are a number of operations, each with a cost:\u003c/p\u003e\u003cul\u003e\u003cli id=\"947a\"\u003eFragment shader invocation: This is the real cost of the application’s draw calls. The fragment shader may also access RAM for texture sampling etc, not shown in the diagram. While this cost is significant, it is irrelevant to this discussion.\u003c/li\u003e\u003cli id=\"531c\"\u003eFragment shader attachment access: Color and depth/stencil data is found on the tile memory, access to which is lightning fast and consumes very little power. This cost is also irrelevant to this discussion.\u003c/li\u003e\u003cli id=\"4c9a\"\u003eTile memory load: This costs time and energy, as accessing RAM is slow. Fortunately, TBR hardware has ways to avoid this cost:\u003cbr/\u003e- Skip the load and leave the contents of the framebuffer on the tile memory undefined (for example because they are going to be completely overwritten)\u003cbr/\u003e- Skip the load and clear the contents of the framebuffer on the tile memory directly\u003c/li\u003e\u003cli id=\"244e\"\u003eTile memory store: This is at least as costly as load. TBR hardware has ways to avoid this cost too:\u003cbr/\u003e- Skip the store and drop the contents of the framebuffer on the tile memory (for example because that data is no longer needed)\u003cbr/\u003e- Skip the store because the render pass did not modify the values that were previously loaded\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"56ff\"\u003eThe most important takeaway from the above is:\u003c/p\u003e\u003cul\u003e\u003cli id=\"4f8d\"\u003e\u003cstrong\u003eAvoid load at all costs\u003c/strong\u003e\u003c/li\u003e\u003cli id=\"9f19\"\u003e\u003cstrong\u003eAvoid store at all costs\u003c/strong\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"87bf\"\u003eThis is trivial with Vulkan, but easier said than done with OpenGL. \u003cem\u003eIf you are on the fence about moving to Vulkan, the extra work of managing descriptor sets, command buffers, etc will all be worth the tremendous gain from creating fewer render passes with the appropriate load and store ops\u003c/em\u003e.\u003c/p\u003e\u003ch2 id=\"8cc5\"\u003eRender Passes in Vulkan\u003c/h2\u003e\u003cp id=\"8af2\"\u003eVulkan natively has a concept of render passes and load and store operations, directly mapping to the TBR features above. Take a set of attachments (some color, maybe a depth/stencil) in a render pass, they will have \u003cstrong\u003eload ops\u003c/strong\u003e (corresponding to “Tile memory load” as described in the section above) and \u003cstrong\u003estore ops\u003c/strong\u003e (corresponding to “Tile memory store”). Inside the render pass, only a few calls are allowed; notably calls that set state, bind resources and draw calls.\u003c/p\u003e\u003cp id=\"2ab8\"\u003eYou can create render passes with \u003ccode\u003e\u003ca href=\"https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_dynamic_rendering.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eVK_KHR_dynamic_rendering\u003c/a\u003e\u003c/code\u003e (modern approach) or \u003ccode\u003e\u003ca href=\"https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/vkCreateRenderPass2.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eVkRenderPass\u003c/a\u003e\u003c/code\u003e\u003ca href=\"https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/vkCreateRenderPass2.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e objects\u003c/a\u003e (original approach). Either way, you can configure the load and store operations of each render pass attachment directly.\u003c/p\u003e\u003cp id=\"7c39\"\u003ePossible load ops are:\u003c/p\u003e\u003cul\u003e\u003cli id=\"a23e\"\u003e\u003ccode\u003e\u003cstrong\u003eLOAD_OP_CLEAR\u003c/strong\u003e\u003c/code\u003e: This means that the attachment is to be cleared when the render pass starts. \u003cstrong\u003eThis is very cheap\u003c/strong\u003e, as it is done directly on tile memory.\u003c/li\u003e\u003cli id=\"0b16\"\u003e\u003ccode\u003e\u003cstrong\u003eLOAD_OP_LOAD\u003c/strong\u003e\u003c/code\u003e: This means that the attachment contents are to be loaded from RAM. \u003cstrong\u003eThis is very slow\u003c/strong\u003e.\u003c/li\u003e\u003cli id=\"585a\"\u003e\u003ccode\u003e\u003cstrong\u003eLOAD_OP_DONT_CARE\u003c/strong\u003e\u003c/code\u003e: This means that the attachment is not loaded from RAM, and its contents are initially garbage. \u003cstrong\u003eThis has no cost\u003c/strong\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"9aee\"\u003ePossible store ops are:\u003c/p\u003e\u003cul\u003e\u003cli id=\"c584\"\u003e\u003ccode\u003e\u003cstrong\u003eSTORE_OP_STORE\u003c/strong\u003e\u003c/code\u003e: This means that the attachment contents are to be stored to RAM. \u003cstrong\u003eThis is very slow\u003c/strong\u003e.\u003c/li\u003e\u003cli id=\"2b54\"\u003e\u003ccode\u003e\u003cstrong\u003eSTORE_OP_DONT_CARE\u003c/strong\u003e\u003c/code\u003e: This means that the attachment is not stored to RAM, and its contents are thrown away. \u003cstrong\u003eThis has no cost\u003c/strong\u003e.\u003c/li\u003e\u003cli id=\"132b\"\u003e\u003ccode\u003e\u003cstrong\u003eSTORE_OP_NONE\u003c/strong\u003e\u003c/code\u003e: This means that the attachment is not stored to RAM because the render pass never wrote to the attachment at all. \u003cstrong\u003eThis has no cost\u003c/strong\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"ec76\"\u003eAn ideal render pass could look like the following:\u003c/p\u003e\u003cul\u003e\u003cli id=\"1b1b\"\u003eUse \u003ccode\u003eLOAD_OP_CLEAR\u003c/code\u003e on all attachments (\u003cstrong\u003every cheap\u003c/strong\u003e)\u003c/li\u003e\u003cli id=\"804f\"\u003eNumerous draw calls\u003c/li\u003e\u003cli id=\"a3af\"\u003eUse \u003ccode\u003eSTORE_OP_STORE\u003c/code\u003e on the primary color attachment, and \u003ccode\u003eSTORE_OP_DONT_CARE\u003c/code\u003e on ancillary attachments (such as depth/stencil, g-buffers, etc) (\u003cstrong\u003eminimum store cost\u003c/strong\u003e)\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"e7bb\"\u003eFor multisampling, the ops are similar. See \u003ca rel=\"noopener\" href=\"https://medium.com/p/21794c479cb9\"\u003ethis blog post\u003c/a\u003e for further details regarding multisampling.\u003c/p\u003e\u003cp id=\"bb7c\"\u003eYou can achieve highly efficient rendering on TBR hardware with Vulkan by keeping the render passes as few as possible and avoiding unnecessary load and store operations.\u003c/p\u003e\u003ch2 id=\"1e01\"\u003eMapping to OpenGL\u003c/h2\u003e\u003cp id=\"136f\"\u003eUnfortunately, OpenGL does not guide the application towards efficient rendering on TBR hardware (unlike Vulkan). As such, mobile drivers have accumulated a number of heroics to reorder the stream of operations issued by the applications as otherwise their performance would be abysmal. These heroics are the source of most corner case bugs you might have encountered in these drivers, and understandably so; they make the driver much more complicated.\u003c/p\u003e\u003cp id=\"2877\"\u003e\u003cstrong\u003eDo yourself a favor and upgrade to Vulkan!\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"5125\"\u003eStill here? Alright, let’s see how we can make an OpenGL application issue calls that would lead to ideal render passes. The best way to understand that is actually by mapping a few key OpenGL calls to Vulkan concepts, as they match the hardware very well. So first, read the \u003cem\u003eRender Passes in Vulkan\u003c/em\u003e section above!\u003c/p\u003e\u003cp id=\"7165\"\u003eNow let’s see how to do that with OpenGL.\u003c/p\u003e\u003ch2 id=\"2a75\"\u003eStep 1: Do NOT Unnecessarily Break the Render Pass\u003c/h2\u003e\u003cp id=\"5f26\"\u003e\u003cstrong\u003eThis is extremely important\u003c/strong\u003e, and the number one source of inefficiency in apps and heroics in drivers. What does it mean to break the render pass? Take the ideal render pass in the previous section: what happens if in between the numerous draw calls, an action is performed that cannot be encoded in the render pass?\u003c/p\u003e\u003cp id=\"ac0f\"\u003eSay out of 1000 draw calls needed for the scene, you’ve issued 600 of them and now need a quick clear of a placeholder texture to sample from in the next draw call. You bind that texture to a temp framebuffer, bind that framebuffer and clear it, then bind back the original framebuffer and issue the rest of the 400 draw calls. \u003cem\u003eReal applications (plural) do this!\u003c/em\u003e\u003c/p\u003e\u003cp id=\"73d8\"\u003eBut, the render pass cannot hold a clear command for an unrelated image (it can only do that for the render pass’s attachments). The result would be two render passes:\u003c/p\u003e\u003cul\u003e\u003cli id=\"41bc\"\u003e(original render pass’s load ops)\u003c/li\u003e\u003cli id=\"eef1\"\u003e600 draw calls\u003c/li\u003e\u003cli id=\"326c\"\u003eRender pass breaks: Use \u003ccode\u003eSTORE_OP_STORE\u003c/code\u003e on all attachments (\u003cstrong\u003esuper expensive\u003c/strong\u003e)\u003c/li\u003e\u003cli id=\"4140\"\u003eClear a tiny texture\u003c/li\u003e\u003cli id=\"f4f0\"\u003eUse \u003ccode\u003eLOAD_OP_LOAD\u003c/code\u003e on all attachments (\u003cstrong\u003esuper expensive\u003c/strong\u003e)\u003c/li\u003e\u003cli id=\"73e9\"\u003e400 draw calls\u003c/li\u003e\u003cli id=\"7f95\"\u003e(original render pass’s store ops)\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"5420\"\u003eOpenGL drivers actually optimize this and shuffle the clear call before the render pass and avoid the render pass break … \u003cstrong\u003eif you’re lucky\u003c/strong\u003e.\u003c/p\u003e\u003cp id=\"d05c\"\u003eWhat causes a render pass to break? A number of things:\u003c/p\u003e\u003cul\u003e\u003cli id=\"93ee\"\u003eThe obvious: things that need the work to get to the GPU right now, such as \u003ccode\u003eglFinish()\u003c/code\u003e, \u003ccode\u003eglReadPixels()\u003c/code\u003e, \u003ccode\u003eglClientWaitSync()\u003c/code\u003e, \u003ccode\u003eeglSwapBuffers()\u003c/code\u003e, etc.\u003c/li\u003e\u003cli id=\"7316\"\u003eBinding a different framebuffer (\u003ccode\u003eglBindFramebuffer()\u003c/code\u003e), or mutating the currently bound one (e.g. \u003ccode\u003eglFramebufferTexture2D()\u003c/code\u003e): \u003cstrong\u003eThis is the most common reason for render pass breaks. Very important not to unnecessarily do this. Please!\u003c/strong\u003e\u003c/li\u003e\u003cli id=\"e226\"\u003eSynchronization requirements: For example, \u003ccode\u003eglMapBufferRange()\u003c/code\u003e after writing to the buffer in the render pass, \u003ccode\u003eglDispatchCompute()\u003c/code\u003e writing to a resource that was used in the render pass, \u003ccode\u003eglGetQueryObjectuiv(GL_QUERY_RESULT)\u003c/code\u003e for a query used in the render pass, etc.\u003c/li\u003e\u003cli id=\"7373\"\u003eOther possibly surprising reasons, such as enabling depth write to a depth/stencil attachment that was previously in a read-only feedback loop (i.e. simultaneously used for depth/stencil testing and sampled in a texture)!\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"31a8\"\u003eThe best way to avoid render pass breaks is to model the OpenGL calls after the equivalent Vulkan application would have:\u003c/p\u003e\u003cul\u003e\u003cli id=\"aebb\"\u003eSeparate non-render-pass calls from render pass calls and do them before the draw calls.\u003c/li\u003e\u003cli id=\"460d\"\u003eDuring the render pass, only bind things (NOT framebuffers), set state and issue draw calls. Nothing else!\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"f1ff\"\u003eStep 2: Control the Load and Store Ops\u003c/h2\u003e\u003cp id=\"9c3d\"\u003eOpenGL has its roots in IMR hardware, where load and store ops effectively don’t exist (other than \u003ccode\u003eLOAD_OP_CLEAR\u003c/code\u003e of course). They are ignored in Vulkan implementations on IMR hardware today (again, other than \u003ccode\u003eLOAD_OP_CLEAR\u003c/code\u003e). As demonstrated above however, they are very important for TBR hardware, and unlucky for us, support for them was not directly added to OpenGL.\u003c/p\u003e\u003cp id=\"723c\"\u003eInstead, there is a combination of two separate calls that controls load and store ops of a render pass attachment. You have to make these calls just before the render pass starts and just after the render pass ends, which as we saw above it is not at all obvious when it happens. Enter driver heroics to reorder app commands of course.\u003c/p\u003e\u003cp id=\"2a89\"\u003eThe two calls are the following:\u003c/p\u003e\u003cul\u003e\u003cli id=\"a90a\"\u003e\u003ccode\u003eglClear()\u003c/code\u003e and family: When this call is made before the render pass starts, it results in the corresponding attachment’s load op to become \u003ccode\u003eLOAD_OP_CLEAR\u003c/code\u003e.\u003c/li\u003e\u003cli id=\"03b8\"\u003e\u003ccode\u003eglInvalidateFramebuffer()\u003c/code\u003e: If this call is made before the render pass starts, it results in the corresponding attachment’s load op to become \u003ccode\u003eLOAD_OP_DONT_CARE\u003c/code\u003e. If this call is made after the render pass ends, the corresponding attachment’s store op may become \u003ccode\u003eSTORE_OP_DONT_CARE\u003c/code\u003e (if the call is not made too late).\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"641c\"\u003eBecause the \u003ccode\u003eglClear()\u003c/code\u003e call is made before the render pass starts, and because applications make that call in really random places, mobile drivers go to great lengths to defer the clear call such that if and when a render pass starts with such an attachment, its load op can be turned into \u003ccode\u003eLOAD_OP_CLEAR\u003c/code\u003e. This means that generally the application can clear the attachments much earlier than the render pass starts and still get this good load op. Beware that scissored/masked clears and scissored render passes thwart all that however.\u003c/p\u003e\u003cp id=\"b381\"\u003eFor \u003ccode\u003eglInvalidateFramebuffer()\u003c/code\u003e, the driver tracks which subresources of the attachment have valid or invalid contents. When done earlier than the render pass starts, this can easily lead to the attachment’s load op to become \u003ccode\u003eLOAD_OP_DONT_CARE\u003c/code\u003e. To get the store op to become \u003ccode\u003eSTORE_OP_DONT_CARE\u003c/code\u003e however, there is nothing the driver can do if the app makes the call at the wrong time.\u003c/p\u003e\u003cp id=\"fbdb\"\u003eTo get the ideal render pass then, the application would have to make the calls as such:\u003c/p\u003e\u003cul\u003e\u003cli id=\"1bc5\"\u003e\u003ccode\u003eglClear()\u003c/code\u003e or \u003ccode\u003eglClearBuffer*()\u003c/code\u003e or \u003ccode\u003eglInvalidateFramebuffer()\u003c/code\u003e (can be done earlier)\u003c/li\u003e\u003cli id=\"fc89\"\u003eNumerous draw calls\u003c/li\u003e\u003cli id=\"89bc\"\u003e\u003ccode\u003eglInvalidateFramebuffer()\u003c/code\u003e for ancillary attachments.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"1df8\"\u003e\u003cstrong\u003eIt is of the utmost importance for the \u003c/strong\u003e\u003ccode\u003e\u003cstrong\u003eglInvalidateFramebuffer()\u003c/strong\u003e\u003c/code\u003e\u003cstrong\u003e call to be made right after the last draw call. Anything else happening in between may make it too late for the driver to adjust the store op of the attachments\u003c/strong\u003e. There is a slight difference for multisampling, explained in \u003ca rel=\"noopener\" href=\"https://medium.com/p/21794c479cb9\"\u003ethis blog post\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"7077\"\u003eStep 3: Get Help From ANGLE\u003c/h2\u003e\u003cp id=\"480d\"\u003eNow you’ve gone through the trouble of implementing all that in your application or game, but how do you know it’s actually working? Sure, FPS is doubled and battery lasts much longer, but are all optimizations working as expected?\u003c/p\u003e\u003cp id=\"da5d\"\u003e\u003cstrong\u003eYou can get help from a project called \u003c/strong\u003e\u003ca href=\"https://angleproject.org/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eANGLE\u003c/strong\u003e\u003c/a\u003e (slated to be the future OpenGL ES driver on Android, \u003ca href=\"https://developer.android.com/about/versions/15/features#modern-gpu-apis\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ealready available in Android 15\u003c/a\u003e). ANGLE is an OpenGL layer on top of Vulkan (among other APIs, but that’s irrelevant here), which means that it’s an OpenGL driver that does all the same heroics as native drivers, except it produces Vulkan API calls and so is one driver that works on all GPUs.\u003c/p\u003e\u003cp id=\"06f5\"\u003eThere are two things about ANGLE that make it very handy in optimizing OpenGL applications for TBR hardware.\u003c/p\u003e\u003cp id=\"d78e\"\u003e\u003cstrong\u003eOne is that its translation to Vulkan is user-visible\u003c/strong\u003e. Since Vulkan render passes map perfectly to TBR hardware, by inspecting the generated Vulkan render passes one can determine whether their OpenGL code can be improved and how. My favorite way of doing that is \u003ca href=\"https://chromium.googlesource.com/angle/angle/+/main/doc/DebuggingTips.md#running-angle-under-renderdoc\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etaking a Vulkan RenderDoc capture\u003c/a\u003e of an OpenGL application running over ANGLE.\u003c/p\u003e\u003cul\u003e\u003cli id=\"e4fe\"\u003eNotice a \u003ccode\u003eLOAD_OP_LOAD\u003c/code\u003e that’s unnecessary? Clear the texture, or invalidate it!\u003c/li\u003e\u003cli id=\"fecf\"\u003eNotice a \u003ccode\u003eSTORE_OP_STORE\u003c/code\u003e that’s unnecessary? Put a \u003ccode\u003eglInvalidateFramebuffer()\u003c/code\u003e at the right place.\u003c/li\u003e\u003cli id=\"2261\"\u003eIs \u003ccode\u003eSTORE_OP_STORE\u003c/code\u003e still there? That was not the right place!\u003c/li\u003e\u003cli id=\"baab\"\u003eHave more render passes than you expected? See next point.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"6809\"\u003e\u003cstrong\u003eThe other is that it declares why a render pass has ended\u003c/strong\u003e. In a RenderDoc capture, this shows up at the end of each render pass, which can be used to verify that the render pass break was intended. If it wasn’t intended, together with the API calls around the render pass break, the provided information can help you figure out what OpenGL call sequence has caused it. For example, in this capture of a unit test, the render pass is broken due to a call to \u003ccode\u003eglReadPixels()\u003c/code\u003e (as hinted at by the following \u003ccode\u003evkCmdCopyImageToBuffer\u003c/code\u003e call):\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"9feb\"\u003eANGLE \u003ca href=\"https://chromium.googlesource.com/angle/angle/+/main/doc/DebuggingTips.md#enabling-debug_utils-markers\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ecan be instructed\u003c/a\u003e to include the OpenGL calls that lead to a given Vulkan call in the trace, which can make figuring things out easier. ANGLE is open source, feel free to \u003ca href=\"https://source.chromium.org/chromium/chromium/src/+/main:third_party/angle/src/libANGLE/renderer/vulkan/vk_utils.h;l=1338;drc=d193d51bf88e2f5162672eff4c75b3bc3ada9ef6\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003einspect the code\u003c/a\u003e if that helps you understand the reason for render pass breaks more easily.\u003c/p\u003e\u003cp id=\"4fd7\"\u003eWhile on this subject, you might find it helpful that ANGLE issues performance warnings when it detects inefficient use of OpenGL (in other scenarios unrelated to render passes). These warnings are reported through the \u003ccode\u003eGL_KHR_debug\u003c/code\u003e extension’s callback mechanism, are logged and also show up in a RenderDoc capture. You might very well find other OpenGL pitfalls you have fallen into.\u003c/p\u003e\u003ch2 id=\"8f0b\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"fa72\"\u003eVulkan may seem complicated at first, but it does one thing very well; it maps well to hardware. While an OpenGL application may be shorter in lines-of-code, in a way it’s more complicated to write a \u003cem\u003egood\u003c/em\u003e OpenGL application especially for TBR hardware because of its lack of structure.\u003c/p\u003e\u003cp id=\"eeeb\"\u003eWhether you end up upgrading to Vulkan or staying with OpenGL, \u003cstrong\u003eyou’d do very well to learn Vulkan\u003c/strong\u003e. If nothing else, learning Vulkan will help you write better OpenGL code.\u003c/p\u003e\u003cp id=\"a332\"\u003eIf your future holds more OpenGL code, I sincerely hope that the above knowledge helps you produce OpenGL code that is not too much slower than the Vulkan equivalent would. And don’t hesitate to try ANGLE out to improve your performance, people who do have found great success with it!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "17 min read",
  "publishedTime": "2024-08-09T19:43:41.347Z",
  "modifiedTime": null
}
