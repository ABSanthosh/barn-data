{
  "id": "060d5a82-87e1-4645-a754-28de5498921a",
  "title": "Gemini Nano is now available on Android via experimental access",
  "link": "http://android-developers.googleblog.com/2024/10/gemini-nano-experimental-access-available-on-android.html",
  "description": "",
  "author": "Android Developers",
  "published": "2024-10-01T12:00:00.000-07:00",
  "source": "http://feeds.feedburner.com/blogspot/hsDu",
  "categories": [
    "#GenerativeAI",
    "Gemini",
    "Gemini Nano",
    "on-device"
  ],
  "byline": "",
  "length": 7400,
  "excerpt": "Gemini Nano with Multimodality, Google's on-device generative AI model offers privacy, offline functionality, integration guides, and more.",
  "siteName": "Android Developers Blog",
  "favicon": "",
  "text": "Posted by Taj Darra – Product Manager Gemini, introduced last year, is Google’s most capable family of models yet; designed for flexibility, it can run on everything from data centers to mobile devices. Since announcing Gemini Nano, our most efficient model built for on-device tasks, we've been working with a limited set of partners to support a range of use cases for their apps. Today, we’re opening up access to experiment with Gemini Nano to all Android developers with the AI Edge SDK via AICore. Developers will initially have access to experiment with text-to-text prompts on Pixel 9 series devices. Support for more devices and modalities will be added in the future. Check out our documentation and video to get started. Note that experimental access is for development purposes, and is not for production usage at this time. Fast, private and cost-effective on-device AI On-device generative AI processes prompts directly on your device without server calls. It offers many benefits: sensitive user data is processed locally on the device, full functionality without internet connectivity, and no additional monetary cost for each inference. Since on-device generative AI models run on devices with less computational power than cloud servers, they are significantly smaller and less generalized than their cloud-based equivalents. As a result, the model works best for tasks where the requests can be clearly specified rather than open-ended use cases such as chatbots. Here are some use cases you can try: Rephrasing - Rephrasing and rewriting text to change the tone to be more casual or formal. Smart reply - Given several chat messages in a thread, suggest the next likely response. Proofreading - Removing spelling or grammatical errors from text. Summarization - Generating a summary of a long document, either as a paragraph or as bullet points. Check out our prompting strategies to achieve best results when experimenting with the above use-cases. If you want to test your own use case, you can download our sample app for an easy way to start experimenting with Gemini Nano. Gemini Nano performance and usage Compared to its predecessor, the model being made available to developers today (referred to in the academic paper as “Nano 2”) delivers a substantial improvement in quality. At nearly twice the size of the predecessor (“Nano 1”), it excels in both academic benchmarks and real-world applications, offering capabilities that rival much larger models. MMLU (5-shot)* MATH (4-shot)* Paraphrasing** Smart Reply** Nano 1 46% 14% 44% 44% Nano 2 56% 23% 90% 82% ** Percentage of good answers measured on public datasets via an autorater powered by Gemini 1.5 Pro. Gemini Nano is already in use by Google apps. Pixel Screenshots, Talkback, Recorder and many more have leveraged Gemini Nano’s text and image understanding to deliver new experiences: Talkback - Android’s accessibility app leverages Gemini Nano’s multimodal capabilities to improve image descriptions for blind and low vision users. Pixel Recorder - Gemini Nano with Multimodality model enables support for longer recordings and higher quality summaries. Seamless model integration with AI Edge SDK using AICore Integrating generative AI models directly into mobile apps is challenging due to the significant computational resources and storage space they require. To address this challenge, we developed AICore, a new system service in Android. AICore allows you to benefit from AI running directly on the device without needing to distribute runtimes, models and other components yourself. To run inference with Gemini Nano in AICore, you use the AI Edge SDK. The AI Edge SDK enables developers to customize prompts and inference parameters to their specific needs, enabling greater control over each inference. To experiment with the AI Edge SDK, add the following to your apps’ dependency: implementation(\"com.google.ai.edge.aicore:aicore:0.0.1-exp01\") The AI Edge SDK allows you to customize inference parameters. Some of the more commonly-used parameters include: Temperature, which controls randomness. Higher values increase diversity and creativity of output. Top K, which specifies how many tokens from the highest-ranking ones are to be considered. Candidate count, which describes the maximum number of responses to return. Max output tokens, which is the length of the desired response. When you are ready to run the inference with your model, the AI Edge SDK offers an easy way to pass in multiple strings as input to accommodate long inference data. Here’s an example: scope.launch { // Single string input prompt val input = \"I want you to act as an English proofreader. I will provide you texts, and I would like you to review them for any spelling, grammar, or punctuation errors. Once you have finished reviewing the text, provide me with any necessary corrections or suggestions for improving the text: These arent the droids your looking for.\" val response = generativeModel.generateContent(input) print(response.text) // Or multiple strings as input val response = generativeModel.generateContent( content { text(\"I want you to act as an English proofreader.I will provide you texts and I would like you to review them for any spelling, grammar, or punctuation errors.\") text(\"Once you have finished reviewing the text, provide me with any necessary corrections or suggestions for improving the text:\") text(\"These arent the droids your looking for.\") } ) print(response.text) } Our integration guide has more information on the AI Edge SDK as well as detailed instructions to start your experimentation with Gemini Nano. To learn more about prompting, check out the Gemini prompting strategies. Get Started Learn more about Gemini Nano for app development by watching our video walkthrough, and try out Gemini Nano experimental access in your own app today. We are excited to see what you build and welcome your input as you evaluate this new technology for your use cases! Post your creations on social media and include the hashtag #AndroidAI to share what you build. To share your ideas and feedback for on-device GenAI and help shape our APIs, you can file a ticket. There’s a lot more that we’re covering this week for you to build great AI experiences on Android so be sure to check out the rest of the AI on Android Spotlight Week content!",
  "image": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxutgVcuY1fxk1tNiS-78vKbC_swceezRTpeoj7hNrR1_-xUa5OblQmOVV0RT3wDXMIiLsp5w28krwGBAii1QreRbxn40uVmp1xXghJ625u-qY1ec1a_SJxo7sB6kpPT2PuxUUEezTTijF9-he4gKBBgiE_cbVKXcnJ6CGle-WMRN5GSLzJVHIYi32fjA/w1200-h630-p-k-no-nu/Gemini-Nano-on-Android-Social.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\u003cmeta content=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxutgVcuY1fxk1tNiS-78vKbC_swceezRTpeoj7hNrR1_-xUa5OblQmOVV0RT3wDXMIiLsp5w28krwGBAii1QreRbxn40uVmp1xXghJ625u-qY1ec1a_SJxo7sB6kpPT2PuxUUEezTTijF9-he4gKBBgiE_cbVKXcnJ6CGle-WMRN5GSLzJVHIYi32fjA/s1600/Gemini-Nano-on-Android-Social.png\" name=\"twitter:image\"/\u003e\n\u003cp\u003e\n\n\u003cem\u003ePosted by Taj Darra – Product Manager\u003c/em\u003e\n\n\u003ca href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW_v6PdEkcKdIYGcJlt3Pj-xuMxwd8uDJA7LrrsxKLk5Bf-b2_cMs-H6pIp_rhA1ESVeIyVqfHJr0-fG8rrmQg51p5Ep6qmmsrYnjJ05fHqllzf7GB1AudjmtZ1xo8Tde49lIn174-5laJq0yW8mJR2eFoQrRjI4arvggUe7buzn7cF672Wo-mujhDFuk/s1600/AI-on-Android-Google-AI-Edge%20%286%29.png\"\u003e\u003cimg data-original-height=\"800\" data-original-width=\"100%\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW_v6PdEkcKdIYGcJlt3Pj-xuMxwd8uDJA7LrrsxKLk5Bf-b2_cMs-H6pIp_rhA1ESVeIyVqfHJr0-fG8rrmQg51p5Ep6qmmsrYnjJ05fHqllzf7GB1AudjmtZ1xo8Tde49lIn174-5laJq0yW8mJR2eFoQrRjI4arvggUe7buzn7cF672Wo-mujhDFuk/s1600/AI-on-Android-Google-AI-Edge%20%286%29.png\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://deepmind.google/technologies/gemini/\" target=\"_blank\"\u003eGemini\u003c/a\u003e, introduced last year, is Google’s most capable family of models yet; designed for flexibility, it can run on everything from data centers to mobile devices. Since announcing \u003ca href=\"https://developer.android.com/ai/aicore\" target=\"_blank\"\u003eGemini Nano\u003c/a\u003e, our most efficient model built for on-device tasks, we\u0026#39;ve been working with a limited set of partners to support a range of use cases for their apps.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eToday, we’re opening up access to experiment with Gemini Nano\u003c/b\u003e to all Android developers with the AI Edge SDK via AICore. Developers will initially have access to experiment with text-to-text prompts on Pixel 9 series devices. Support for more devices and modalities will be added in the future. Check out our \u003ca href=\"https://developer.android.com/ai/gemini-nano/experimental\" target=\"_blank\"\u003edocumentation\u003c/a\u003e and \u003ca href=\"https://youtu.be/EpKghZYqVW4\" target=\"_blank\"\u003evideo\u003c/a\u003e to get started. Note that experimental access is for development purposes, and is not for production usage at this time.\u003c/p\u003e\u003cbr/\u003e\n\n\u003ciframe allowfullscreen=\"\" youtube-src-id=\"EpKghZYqVW4\" width=\"100%\" height=\"398\" src=\"https://www.youtube.com/embed/EpKghZYqVW4\"\u003e\u003c/iframe\u003e\n\n\u003ch3\u003eFast, private and cost-effective on-device AI\u003c/h3\u003e\n\n\u003cp\u003eOn-device generative AI processes prompts directly on your device without server calls. It offers many benefits: sensitive user data is processed locally on the device, full functionality without internet connectivity, and no additional monetary cost for each inference.\u003c/p\u003e\n\n\u003cp\u003eSince on-device generative AI models run on devices with less computational power than cloud servers, they are significantly smaller and less generalized than their cloud-based equivalents. As a result, the model works best for tasks where the requests can be clearly specified rather than open-ended use cases such as chatbots. Here are some use cases you can try:\u003c/p\u003e\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eRephrasing\u003c/b\u003e - Rephrasing and rewriting text to change the tone to be more casual or formal.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eSmart reply\u003c/b\u003e - Given several chat messages in a thread, suggest the next likely response.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e \n\u003cli\u003e\u003cb\u003eProofreading\u003c/b\u003e - Removing spelling or grammatical errors from text.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eSummarization\u003c/b\u003e - Generating a summary of a long document, either as a paragraph or as bullet points.\u003c/li\u003e\n\u003c/ul\u003e\u003c/ul\u003e\n\n\u003cp\u003eCheck out our \u003ca href=\"https://ai.google.dev/gemini-api/docs/prompting-strategies\" target=\"_blank\"\u003eprompting strategies\u003c/a\u003e to achieve best results when experimenting with the above use-cases. If you want to test your own use case, you can download our \u003ca href=\"https://github.com/android/ai-samples\" target=\"_blank\"\u003esample app\u003c/a\u003e for an easy way to start experimenting with Gemini Nano.\u003c/p\u003e\u003cbr/\u003e\n\n\u003ch3\u003eGemini Nano performance and usage\u003c/h3\u003e\n\n\u003cp\u003eCompared to its predecessor, the model being made available to developers today (referred to in the \u003ca href=\"https://arxiv.org/pdf/2312.11805\" target=\"_blank\"\u003eacademic paper\u003c/a\u003e as “Nano 2”) delivers a substantial improvement in quality. At nearly twice the size of the predecessor (“Nano 1”), it excels in both academic benchmarks and real-world applications, offering capabilities that rival much larger models.\u003c/p\u003e\n\n\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eMMLU (5-shot)*\u003c/b\u003e\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eMATH (4-shot)*\u003c/b\u003e\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eParaphrasing**\u003c/b\u003e\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eSmart Reply**\u003c/b\u003e\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n            \u003c/tr\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\n                    \u003cb\u003eNano 1\n                \u003c/b\u003e\u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e46%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e14%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e44%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e44%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n            \u003c/tr\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cb\u003eNano 2\n                    \u003c/b\u003e\u003c/td\u003e\u003ctd\u003e\u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cspan\u003e56%\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e23%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e90%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n                \u003ctd\u003e\n                    \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e82%\u003c/span\u003e\u003c/p\u003e\n                \u003c/td\u003e\n            \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n\u003c/div\u003e\n\n\u003cp\u003e\u003ci\u003e** Percentage of good answers measured on public datasets via an autorater powered by Gemini 1.5 Pro.\u003c/i\u003e\u003c/p\u003e\n\n\n\u003cp\u003eGemini Nano is already in use by Google apps. Pixel Screenshots, Talkback, Recorder and many more have leveraged Gemini Nano’s text and image understanding to deliver new experiences:\u003c/p\u003e\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://android-developers.googleblog.com/2024/09/talkback-uses-gemini-nano-to-increase-low-vision-accessibility.html\" target=\"_blank\"\u003eTalkback\u003c/a\u003e - Android’s accessibility app leverages Gemini Nano’s multimodal capabilities to improve image descriptions for blind and low vision users.\u003c/li\u003e\u003c/ul\u003e\n  \n\u003cp\u003e\u003cimg alt=\"moving image of Talkback app UI highlighting improved image descriptions with multimodality model for users with low vision\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjX0yAAaKl4Z5FecqP-h6FiDfS2aqeSUsNTrQHaRUG0FOPkyIM5l4Z_V5RUgsXKvfXN1i9yLvKnE-7T1Yh3iawnG552ATln225N2SeeRSaQDbtboH_MxPXTqNlETbR59CyMjaZSTupKdajd3-Oj3_x984jmhZYNz54rfKhGnpnFAOVLzE0KYwW6ow67nv8/s16000/Nano-Talkback.gif\"/\u003e\u003c/p\u003e\u003cbr/\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://android-developers.googleblog.com/2024/08/recorder-app-on-pixel-sees-boost-in-engagement-with-gemini-nano.html\" target=\"_blank\"\u003ePixel Recorder\u003c/a\u003e - Gemini Nano with Multimodality model enables support for longer recordings and higher quality summaries.\u003c/li\u003e\n\u003c/ul\u003e\u003c/ul\u003e\n\n\u003cp\u003e\u003cimg alt=\"moving image of Talkback app UI highlighting improved image descriptions with multimodality model for users with low vision\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIHHaBqn4hL9C54peGuUeQFTOmwQUS0UsUXIVCcEf9Oe0eWqFVlp-ssiOnX7mzV8PbhkNhxmuqu84dx5j0XlFRHBwVjfYw0TP_Nf_InOQmuX_LWBJIj1G8JTINEauzYoFphdSC5bXlaH1n8pfKpB0gku1t_v1TvYytk2vs4MPPQMmozIQ0vGLo2Rq4ELc/s16000/Nano-Recorder.gif\"/\u003e\u003c/p\u003e\u003cbr/\u003e\n\n\u003ch3\u003eSeamless model integration with AI Edge SDK using AICore \u003c/h3\u003e\n\n\u003cp\u003eIntegrating generative AI models directly into mobile apps is challenging due to the significant computational resources and storage space they require. To address this challenge, we developed \u003ca href=\"https://developer.android.com/ai/aicore\" target=\"_blank\"\u003eAICore\u003c/a\u003e, a new system service in Android. AICore allows you to benefit from AI running directly on the device without needing to distribute runtimes, models and other components yourself.\u003c/p\u003e\n\n\u003cp\u003eTo run inference with Gemini Nano in AICore, you use the AI Edge SDK. The AI Edge SDK enables developers to customize prompts and inference parameters to their specific needs, enabling greater control over each inference.\u003c/p\u003e\n\n\u003cp\u003eTo experiment with the AI Edge SDK, add the following to your apps’ dependency:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003eimplementation(\u003cspan\u003e\u0026#34;com.google.ai.edge.aicore:aicore:0.0.1-exp01\u0026#34;\u003c/span\u003e)\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eThe AI Edge SDK allows you to customize \u003ca href=\"https://ai.google.dev/gemini-api/docs/models/generative-models#model-parameters\" target=\"_blank\"\u003einference parameters\u003c/a\u003e. Some of the more commonly-used parameters include:\u003c/p\u003e\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eTemperature\u003c/b\u003e, which controls randomness. Higher values increase diversity and creativity of output.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eTop K\u003c/b\u003e, which specifies how many tokens from the highest-ranking ones are to be considered.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eCandidate count\u003c/b\u003e, which describes the maximum number of responses to return.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003eMax output tokens\u003c/b\u003e, which is the length of the desired response.\u003c/li\u003e\n\u003c/ul\u003e\u003c/ul\u003e\n\n\u003cp\u003eWhen you are ready to run the inference with your model, the AI Edge SDK offers an easy way to pass in multiple strings as input to accommodate long inference data.\u003c/p\u003e\n  \n\u003cp\u003eHere’s an example:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003escope.launch {\n    \u003cspan\u003e// Single string input prompt\u003c/span\u003e\n    \u003cspan\u003eval\u003c/span\u003e input = \u003cspan\u003e\u0026#34;I want you to act as an English proofreader. I will \u003c/span\u003e\n    provide you texts, and I would like you to review them \u003cspan\u003efor\u003c/span\u003e any \n    spelling, grammar, or punctuation errors. Once you have finished \n    reviewing the text, provide me with any necessary corrections or \n    suggestions \u003cspan\u003efor\u003c/span\u003e improving the text: \n    These arent the droids your looking \u003cspan\u003efor\u003c/span\u003e.\u003cspan\u003e\u0026#34;\u003c/span\u003e\n    \u003cspan\u003eval\u003c/span\u003e response = generativeModel.generateContent(input)\n    print(response.text)\n\n    \u003cspan\u003e// Or multiple strings as input\u003c/span\u003e\n    \u003cspan\u003eval\u003c/span\u003e response = generativeModel.generateContent(\n        content {\n            text(\u003cspan\u003e\u0026#34;I want you to act as an English proofreader.I will \u003c/span\u003e\n            provide you texts and I would like you to review them \u003cspan\u003efor\u003c/span\u003e \n            any spelling, grammar, or punctuation errors.\u003cspan\u003e\u0026#34;)\u003c/span\u003e\n            text(\u003cspan\u003e\u0026#34;Once you have finished reviewing the text, \u003c/span\u003e\n            provide me with any necessary corrections or suggestions \n            \u003cspan\u003efor\u003c/span\u003e improving the text:\u003cspan\u003e\u0026#34;)\u003c/span\u003e\n            text(\u003cspan\u003e\u0026#34;These arent the droids your looking for.\u0026#34;\u003c/span\u003e)\n        }\n    )\n    print(response.text)\n}\n\u003c/pre\u003e\u003c/div\u003e\n\n\n\u003cp\u003eOur \u003ca href=\"https://developer.android.com/ai/gemini-nano/experimental\" target=\"_blank\"\u003eintegration guide\u003c/a\u003e has more information on the AI Edge SDK as well as detailed instructions to start your experimentation with Gemini Nano. To learn more about prompting, check out the \u003ca href=\"https://ai.google.dev/gemini-api/docs/prompting-strategies\" target=\"_blank\"\u003eGemini prompting strategies\u003c/a\u003e.\u003c/p\u003e\u003cbr/\u003e\n  \n\u003ch3\u003eGet Started\u003c/h3\u003e\n\n\u003cp\u003eLearn more about Gemini Nano for app development by watching our \u003ca href=\"https://youtu.be/EpKghZYqVW4\" target=\"_blank\"\u003evideo walkthrough\u003c/a\u003e, and \u003ca href=\"https://developer.android.com/ai/gemini-nano/experimental\" target=\"_blank\"\u003etry out Gemini Nano experimental access\u003c/a\u003e in your own app today.\u003c/p\u003e\n\n\u003cp\u003eWe are excited to see what you build and welcome your input as you evaluate this new technology for your use cases! Post your creations on social media and include the hashtag #AndroidAI to share what you build. To share your ideas and feedback for on-device GenAI and help shape our APIs, you can \u003ca href=\"https://issuetracker.google.com/issues/new?component=1657650\u0026amp;template=0\u0026amp;pli=1\" target=\"_blank\"\u003efile a ticket\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eThere’s a lot more that we’re covering this week for you to build great AI experiences on Android so be sure to \u003ca href=\"https://android-developers.googleblog.com/2024/09/welcome-to-ai-on-android-spotlight-week.html\" target=\"_blank\"\u003echeck out the rest of the AI on Android Spotlight Week content\u003c/a\u003e! \u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": null,
  "modifiedTime": null
}
