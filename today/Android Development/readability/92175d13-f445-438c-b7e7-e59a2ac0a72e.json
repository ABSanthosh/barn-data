{
  "id": "92175d13-f445-438c-b7e7-e59a2ac0a72e",
  "title": "Common media processing operations with Jetpack Media3 Transformer",
  "link": "http://android-developers.googleblog.com/2025/03/media-processing-performance-jetpack-media3-transformer.html",
  "description": "",
  "author": "Android Developers",
  "published": "2025-03-05T12:00:00.000-08:00",
  "source": "http://feeds.feedburner.com/blogspot/hsDu",
  "categories": [
    "#Android",
    "#Editing",
    "#FFmpeg",
    "#Media",
    "#Media3",
    "#transformer"
  ],
  "byline": "",
  "length": 8726,
  "excerpt": "Learn how to use Jetpack Media3 Transformer APIs effectively for common media editing operations like transcoding, trimming, muting, and resizing.",
  "siteName": "Android Developers Blog",
  "favicon": "",
  "text": "Posted by Nevin Mital – Developer Relations Engineer, and Kristina Simakova – Engineering Manager Android users have demonstrated an increasing desire to create, personalize, and share video content online, whether to preserve their memories or to make people laugh. As such, media editing is a cornerstone of many engaging Android apps, and historically developers have often relied on external libraries to handle operations such as Trimming and Resizing. While these solutions are powerful, integrating and managing external library dependencies can introduce complexity and lead to challenges with managing performance and quality. The Jetpack Media3 Transformer APIs offer a native Android solution that streamline media editing with fast performance, extensive customizability, and broad device compatibility. In this blog post, we’ll walk through some of the most common editing operations with Transformer and discuss its performance. Getting set up with Transformer To get started with Transformer, check out our Getting Started documentation for details on how to add the dependency to your project and a basic understanding of the workflow when using Transformer. In a nutshell, you’ll: Create one or many MediaItem instances from your video file(s), then Apply item-specific edits to them by building an EditedMediaItem for each MediaItem, Create a Transformer instance configured with settings applicable to the whole exported video, and finally start the export to save your applied edits to a file. Aside: You can also use a CompositionPlayer to preview your edits before exporting, but this is out of scope for this blog post, as this API is still a work in progress. Please stay tuned for a future post! Here’s what this looks like in code: val mediaItem = MediaItem.Builder().setUri(mediaItemUri).build() val editedMediaItem = EditedMediaItem.Builder(mediaItem).build() val transformer = Transformer.Builder(context) .addListener(/* Add a Transformer.Listener instance here for completion events */) .build() transformer.start(editedMediaItem, outputFilePath) Transcoding, Trimming, Muting, and Resizing with the Transformer API Let’s now take a look at four of the most common single-asset media editing operations, starting with Transcoding. Transcoding is the process of re-encoding an input file into a specified output format. For this example, we’ll request the output to have video in HEVC (H265) and audio in AAC. Starting with the code above, here are the lines that change: val transformer = Transformer.Builder(context) .addListener(...) .setVideoMimeType(MimeTypes.VIDEO_H265) .setAudioMimeType(MimeTypes.AUDIO_AAC) .build() Many of you may already be familiar with FFmpeg, a popular open-source library for processing media files, so we’ll also include FFmpeg commands for each example to serve as a helpful reference. Here’s how you can perform the same transcoding with FFmpeg: $ ffmpeg -i $inputVideoPath -c:v libx265 -c:a aac $outputFilePath The next operation we’ll try is Trimming. Specifically, we’ll set Transformer up to trim the input video from the 3 second mark to the 8 second mark, resulting in a 5 second output video. Starting again from the code in the “Getting set up” section above, here are the lines that change: // Configure the trim operation by adding a ClippingConfiguration to // the media item val clippingConfiguration = MediaItem.ClippingConfiguration.Builder() .setStartPositionMs(3000) .setEndPositionMs(8000) .build() val mediaItem = MediaItem.Builder() .setUri(mediaItemUri) .setClippingConfiguration(clippingConfiguration) .build() // Transformer also has a trim optimization feature we can enable. // This will prioritize Transmuxing over Transcoding where possible. // See more about Transmuxing further down in this post. val transformer = Transformer.Builder(context) .addListener(...) .experimentalSetTrimOptimizationEnabled(true) .build() With FFmpeg: $ ffmpeg -ss 00:00:03 -i $inputVideoPath -t 00:00:05 $outputFilePath Next, we can mute the audio in the exported video file. val editedMediaItem = EditedMediaItem.Builder(mediaItem) .setRemoveAudio(true) .build() The corresponding FFmpeg command: $ ffmpeg -i $inputVideoPath -c copy -an $outputFilePath And for our final example, we’ll try resizing the input video by scaling it down to half its original height and width. val scaleEffect = ScaleAndRotateTransformation.Builder() .setScale(0.5f, 0.5f) .build() val editedMediaItem = EditedMediaItem.Builder(mediaItem) .setEffects( /* audio */ Effects(emptyList(), /* video */ listOf(scaleEffect)) ) .build() An FFmpeg command could look like this: $ ffmpeg -i $inputVideoPath -filter:v scale=w=trunc(iw/4)*2:h=trunc(ih/4)*2 $outputFilePath Of course, you can also combine these operations to apply multiple edits on the same video, but hopefully these examples serve to demonstrate that the Transformer APIs make configuring these edits simple. Transformer API Performance results Here are some benchmarking measurements for each of the 4 operations taken with the Stopwatch API, running on a Pixel 9 Pro XL device: (Note that performance for operations like these can depend on a variety of reasons, such as the current load the device is under, so the numbers below should be taken as rough estimates.) Input video format: 10s 720p H264 video with AAC audio Transcoding to H265 video and AAC audio: ~1300ms Trimming video to 00:03-00:08: ~2300ms Muting audio: ~200ms Resizing video to half height and width: ~1200ms Input video format: 25s 360p VP8 video with Vorbis audio Transcoding to H265 video and AAC audio: ~3400ms Trimming video to 00:03-00:08: ~1700ms Muting audio: ~1600ms Resizing video to half height and width: ~4800ms Input video format: 4s 8k H265 video with AAC audio Transcoding to H265 video and AAC audio: ~2300ms Trimming video to 00:03-00:08: ~1800ms Muting audio: ~2000ms Resizing video to half height and width: ~3700ms One technique Transformer uses to speed up editing operations is by prioritizing transmuxing for basic video edits where possible. Transmuxing refers to the process of repackaging video streams without re-encoding, which ensures high-quality output and significantly faster processing times. When not possible, Transformer falls back to transcoding, a process that involves first decoding video samples into raw data, then re-encoding them for storage in a new container. Here are some of these differences: Transmuxing Transformer’s preferred approach when possible - a quick transformation that preserves elementary streams. Only applicable to basic operations, such as rotating, trimming, or container conversion. No quality loss or bitrate change. Transcoding Transformer's fallback approach in cases when Transmuxing isn't possible - Involves decoding and re-encoding elementary streams. More extensive modifications to the input video are possible. Loss in quality due to re-encoding, but can achieve a desired bitrate target. We are continuously implementing further optimizations, such as the recently introduced experimentalSetTrimOptimizationEnabled setting that we used in the Trimming example above. A trim is usually performed by re-encoding all the samples in the file, but since encoded media samples are stored chronologically in their container, we can improve efficiency by only re-encoding the group of pictures (GOP) between the start point of the trim and the first keyframes at/after the start point, then stream-copying the rest. Since we only decode and encode a fixed portion of any file, the encoding latency is roughly constant, regardless of what the input video duration is. For long videos, this improved latency is dramatic. The optimization relies on being able to stitch part of the input file with newly-encoded output, which means that the encoder's output format and the input format must be compatible. If the optimization fails, Transformer automatically falls back to normal export. What’s next? As part of Media3, Transformer is a native solution with low integration complexity, is tested on and ensures compatibility with a wide variety of devices, and is customizable to fit your specific needs. To dive deeper, you can explore Media3 Transformer documentation, run our sample apps, or learn how to complement your media editing pipeline with Jetpack Media3. We’ve already seen app developers benefit greatly from adopting Transformer, so we encourage you to try them out yourself to streamline your media editing workflows and enhance your app’s performance!",
  "image": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifgV_wUMIzInKtKXR9FyNh7h00qDygaA6fRVDMqMxht68oPNmrAJfZtM_Vf6-3VD8FVGKoSoljaILjtn7ygMwCdBcXPJAvH3fUWiw2LfZBHh4qFSrMvOZLqlDiPVILmiBBo8jKZb0izoq0jxA1tFR9MKf5tDr112svVgsIhdxNnQTK8xf1n7GyduQYT9Q/w1200-h630-p-k-no-nu/Jetpack-Media3-Processing.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\u003cmeta content=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifgV_wUMIzInKtKXR9FyNh7h00qDygaA6fRVDMqMxht68oPNmrAJfZtM_Vf6-3VD8FVGKoSoljaILjtn7ygMwCdBcXPJAvH3fUWiw2LfZBHh4qFSrMvOZLqlDiPVILmiBBo8jKZb0izoq0jxA1tFR9MKf5tDr112svVgsIhdxNnQTK8xf1n7GyduQYT9Q/s1600/Jetpack-Media3-Processing.png\" name=\"twitter:image\"/\u003e\n\u003cp\u003e\n\n\u003cem\u003ePosted by Nevin Mital – Developer Relations Engineer, and Kristina Simakova – Engineering Manager\u003c/em\u003e\n\n\u003ca href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiJNdGSk1eFCtZbcQJl7Tj-8Adto42Rn6bHT2EOkkRFVKklpyoZmZHtUkACfnbIbSotZv2oyJwSiMCrM2KJ5e_OyqwWMbXyTxuWoht755j540OGyWthdBM2PQBsFs12X9cVk9OiASFgfRgDCfRn6R-hTrB7st-V5wUqlmUi15THdsRXAtUWtWAY1vonyI/s1600/Jetpack-Media3-Processing%20%281%29.png\"\u003e\u003cimg data-original-height=\"800\" data-original-width=\"100%\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiJNdGSk1eFCtZbcQJl7Tj-8Adto42Rn6bHT2EOkkRFVKklpyoZmZHtUkACfnbIbSotZv2oyJwSiMCrM2KJ5e_OyqwWMbXyTxuWoht755j540OGyWthdBM2PQBsFs12X9cVk9OiASFgfRgDCfRn6R-hTrB7st-V5wUqlmUi15THdsRXAtUWtWAY1vonyI/s1600/Jetpack-Media3-Processing%20%281%29.png\"/\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003eAndroid users have demonstrated an increasing desire to create, personalize, and share video content online, whether to preserve their memories or to make people laugh. As such, media editing is a cornerstone of many engaging Android apps, and historically developers have often relied on external libraries to handle operations such as Trimming and Resizing. While these solutions are powerful, integrating and managing external library dependencies can introduce complexity and lead to challenges with managing performance and quality.\u003c/p\u003e\n\n\u003cp\u003eThe Jetpack Media3 Transformer APIs offer a native Android solution that streamline media editing with fast performance, extensive customizability, and broad device compatibility. In this blog post, we’ll walk through some of the most common editing operations with Transformer and discuss its performance.\u003c/p\u003e\n\n\u003ch2\u003e\u003cspan\u003eGetting set up with Transformer\u003c/span\u003e\u003c/h2\u003e\n\n\u003cp\u003eTo get started with Transformer, check out our \u003ca href=\"https://developer.android.com/media/media3/transformer/getting-started\" target=\"_blank\"\u003eGetting Started\u003c/a\u003e documentation for details on how to add the dependency to your project and a basic understanding of the workflow when using Transformer. In a nutshell, you’ll:\u003c/p\u003e\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003eCreate one or many \u003cspan\u003e\u003ca href=\"https://developer.android.com/reference/androidx/media3/common/MediaItem\" target=\"_blank\"\u003eMediaItem\u003c/a\u003e\u003c/span\u003e instances from your video file(s), then\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003eApply item-specific edits to them by building an \u003cspan\u003e\u003ca href=\"https://developer.android.com/reference/androidx/media3/transformer/EditedMediaItem\" target=\"_blank\"\u003eEditedMediaItem\u003c/a\u003e\u003c/span\u003e for each \u003cspan\u003eMediaItem\u003c/span\u003e,\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003eCreate a \u003cspan\u003e\u003ca href=\"https://developer.android.com/reference/androidx/media3/transformer/Transformer\" target=\"_blank\"\u003eTransformer\u003c/a\u003e\u003c/span\u003e instance configured with settings applicable to the whole exported video,\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n\u003cli\u003eand finally start the \u003ca href=\"https://developer.android.com/reference/androidx/media3/transformer/Transformer#start%28androidx.media3.transformer.EditedMediaItem,java.lang.String%29\" target=\"_blank\"\u003eexport\u003c/a\u003e to save your applied edits to a file.\n\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\n\n\u003cblockquote\u003e\u003cb\u003eAside:\u003c/b\u003e You can also use a \u003cspan\u003e\u003ca href=\"https://github.com/androidx/media/blob/release/libraries/transformer/src/main/java/androidx/media3/transformer/CompositionPlayer.java\" target=\"_blank\"\u003eCompositionPlayer\u003c/a\u003e\u003c/span\u003e to preview your edits before exporting, but this is out of scope for this blog post, as this API is still a work in progress. Please stay tuned for a future post!\u003c/blockquote\u003e\n\n\u003cp\u003eHere’s what this looks like in code:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003eval\u003c/span\u003e mediaItem = MediaItem.Builder().setUri(mediaItemUri).build()\n\u003cspan\u003eval\u003c/span\u003e editedMediaItem = EditedMediaItem.Builder(mediaItem).build()\n\u003cspan\u003eval\u003c/span\u003e transformer = \n  Transformer.Builder(context)\n    .addListener(\u003cspan\u003e/* Add a Transformer.Listener instance here for completion events */\u003c/span\u003e)\n    .build()\ntransformer.start(editedMediaItem, outputFilePath)\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003ch2\u003e\u003cspan\u003eTranscoding, Trimming, Muting, and Resizing with the Transformer API\u003c/span\u003e\u003c/h2\u003e\n\n\u003cp\u003eLet’s now take a look at four of the most common single-asset media editing operations, starting with \u003ci\u003eTranscoding\u003c/i\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eTranscoding\u003c/b\u003e is the process of re-encoding an input file into a specified output format. For this example, we’ll request the output to have video in HEVC (H265) and audio in AAC. Starting with the code above, here are the lines that change:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003eval\u003c/span\u003e transformer = \n  Transformer.Builder(context)\n    .addListener(...)\n    .\u003cb\u003esetVideoMimeType(MimeTypes.VIDEO_H265)\n    .setAudioMimeType(MimeTypes.AUDIO_AAC)\u003c/b\u003e\n    .build()\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eMany of you may already be familiar with \u003ca href=\"https://www.ffmpeg.org/\" target=\"_blank\"\u003eFFmpeg\u003c/a\u003e, a popular open-source library for processing media files, so we’ll also include FFmpeg commands for each example to serve as a helpful reference. Here’s how you can perform the same transcoding with FFmpeg:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e$ ffmpeg \u003cspan\u003e-\u003c/span\u003ei \u003cspan\u003e$inputVideoPath\u003c/span\u003e \u003cb\u003e\u003cspan\u003e-\u003c/span\u003ec\u003cspan\u003e:\u003c/span\u003ev libx265 \u003cspan\u003e-\u003c/span\u003ec\u003cspan\u003e:\u003c/span\u003ea aac\u003c/b\u003e \u003cspan\u003e$outputFilePath\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eThe next operation we’ll try is \u003cb\u003eTrimming\u003c/b\u003e.\u003c/p\u003e\n\n\u003cp\u003eSpecifically, we’ll set Transformer up to trim the input video from the 3 second mark to the 8 second mark, resulting in a 5 second output video. Starting again from the code in the “Getting set up” section above, here are the lines that change:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003e// Configure the trim operation by adding a ClippingConfiguration to\u003c/span\u003e\n\u003cspan\u003e// the media item\u003c/span\u003e\n\u003cspan\u003eval\u003c/span\u003e \u003cb\u003eclippingConfiguration =\n   MediaItem.ClippingConfiguration.Builder()\n     .setStartPositionMs(\u003cspan\u003e3000\u003c/span\u003e)\n     .setEndPositionMs(\u003cspan\u003e8000\u003c/span\u003e)\n     .build()\u003c/b\u003e\n\u003cspan\u003eval\u003c/span\u003e mediaItem =\n   MediaItem.Builder()\n     .setUri(mediaItemUri)\n     .\u003cb\u003esetClippingConfiguration(clippingConfiguration)\u003c/b\u003e\n     .build()\n\n\u003cspan\u003e// Transformer also has a trim optimization feature we can enable.\u003c/span\u003e\n\u003cspan\u003e// This will prioritize Transmuxing over Transcoding where possible.\u003c/span\u003e\n\u003cspan\u003e// See more about Transmuxing further down in this post.\u003c/span\u003e\n\u003cspan\u003eval\u003c/span\u003e transformer = \n  Transformer.Builder(context)\n    .addListener(...)\n    \u003cb\u003e.experimentalSetTrimOptimizationEnabled(\u003cspan\u003etrue\u003c/span\u003e)\u003c/b\u003e\n    .build()\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eWith FFmpeg:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e$ ffmpeg \u003cb\u003e\u003cspan\u003e-\u003c/span\u003ess \u003cspan\u003e00:00:03\u003c/span\u003e\u003c/b\u003e \u003cspan\u003e-\u003c/span\u003ei \u003cspan\u003e$inputVideoPath\u003c/span\u003e \u003cb\u003e\u003cspan\u003e-\u003c/span\u003et \u003cspan\u003e00:00:05\u003c/span\u003e\u003c/b\u003e \u003cspan\u003e$outputFilePath\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eNext, we can \u003cb\u003emute\u003c/b\u003e the audio in the exported video file.\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003eval\u003c/span\u003e editedMediaItem = \n  EditedMediaItem.Builder(mediaItem)\n    \u003cb\u003e.setRemoveAudio(\u003cspan\u003etrue\u003c/span\u003e)\u003c/b\u003e\n    .build()\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eThe corresponding FFmpeg command:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e$ ffmpeg \u003cspan\u003e-\u003c/span\u003ei \u003cspan\u003e$inputVideoPath\u003c/span\u003e \u003cb\u003e\u003cspan\u003e-\u003c/span\u003ec copy \u003cspan\u003e-\u003c/span\u003ean\u003c/b\u003e \u003cspan\u003e$outputFilePath\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eAnd for our final example, we’ll try \u003cb\u003eresizing\u003c/b\u003e the input video by scaling it down to half its original height and width.\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e\u003cspan\u003eval\u003c/span\u003e \u003cb\u003escaleEffect = \n  ScaleAndRotateTransformation.Builder()\n    .setScale(\u003cspan\u003e0.5f\u003c/span\u003e, \u003cspan\u003e0.5f\u003c/span\u003e)\n    .build()\u003c/b\u003e\n\u003cspan\u003eval\u003c/span\u003e editedMediaItem =\n  EditedMediaItem.Builder(mediaItem)\n    \u003cb\u003e.setEffects(\n      \u003cspan\u003e/* audio */\u003c/span\u003e Effects(emptyList(), \n      \u003cspan\u003e/* video */\u003c/span\u003e listOf(scaleEffect))\u003c/b\u003e\n    )\n    .build()\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eAn FFmpeg command could look like this:\u003c/p\u003e\n\n\u003cdiv\u003e\u003cpre\u003e$ ffmpeg \u003cspan\u003e-\u003c/span\u003ei \u003cspan\u003e$inputVideoPath\u003c/span\u003e \u003cb\u003e\u003cspan\u003e-\u003c/span\u003efilter\u003cspan\u003e:\u003c/span\u003ev scale\u003cspan\u003e=\u003c/span\u003ew\u003cspan\u003e=\u003c/span\u003etrunc(iw\u003cspan\u003e/4\u003c/span\u003e)\u003cspan\u003e*2:\u003c/span\u003eh\u003cspan\u003e=\u003c/span\u003etrunc(ih\u003cspan\u003e/4\u003c/span\u003e)\u003cspan\u003e*2\u003c/span\u003e\u003c/b\u003e \u003cspan\u003e$outputFilePath\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eOf course, you can also combine these operations to apply multiple edits on the same video, but hopefully these examples serve to demonstrate that the Transformer APIs make configuring these edits simple.\u003c/p\u003e\n\n\n\u003ch2\u003e\u003cspan\u003eTransformer API Performance results\u003c/span\u003e\u003c/h2\u003e\n\n\u003cp\u003eHere are some benchmarking measurements for each of the 4 operations taken with the Stopwatch API, running on a Pixel 9 Pro XL device:\u003c/p\u003e\n\u003cp\u003e\u003ci\u003e(Note that performance for operations like these can depend on a variety of reasons, such as the current load the device is under, so the numbers below should be taken as rough estimates.)\u003c/i\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cb\u003eInput video format:\u003c/b\u003e \u003ca href=\"https://storage.googleapis.com/exoplayer-test-media-1/mp4/android-screens-10s.mp4\" target=\"_blank\"\u003e10s 720p H264 video with AAC audio\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cb\u003eTranscoding\u003c/b\u003e to H265 video and AAC audio: ~1300ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eTrimming\u003c/b\u003e video to 00:03-00:08: ~2300ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eMuting\u003c/b\u003e audio: ~200ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eResizing\u003c/b\u003e video to half height and width: ~1200ms\u003c/li\u003e\n\u003c/ul\u003e\n  \n\u003cp\u003e\u003cb\u003eInput video format:\u003c/b\u003e \u003ca href=\"https://html5demos.com/assets/dizzy.webm\" target=\"_blank\"\u003e25s 360p VP8 video with Vorbis audio\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cb\u003eTranscoding\u003c/b\u003e to H265 video and AAC audio: ~3400ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eTrimming\u003c/b\u003e video to 00:03-00:08: ~1700ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eMuting\u003c/b\u003e audio: ~1600ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eResizing\u003c/b\u003e video to half height and width: ~4800ms\u003c/li\u003e\n\u003c/ul\u003e\n  \n\u003cp\u003e\u003cb\u003eInput video format:\u003c/b\u003e \u003ca href=\"https://storage.googleapis.com/exoplayer-test-media-1/mp4/8k24fps_4s.mp4\" target=\"_blank\"\u003e4s 8k H265 video with AAC audio\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cb\u003eTranscoding\u003c/b\u003e to H265 video and AAC audio: ~2300ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eTrimming\u003c/b\u003e video to 00:03-00:08: ~1800ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eMuting\u003c/b\u003e audio: ~2000ms\u003c/li\u003e\n\u003cli\u003e\u003cb\u003eResizing\u003c/b\u003e video to half height and width: ~3700ms\u003c/li\u003e\n\u003c/ul\u003e\u003c/blockquote\u003e\n\n\u003cp\u003eOne technique Transformer uses to speed up editing operations is by prioritizing \u003ci\u003etransmuxing\u003c/i\u003e for basic video edits where possible. \u003cb\u003eTransmuxing\u003c/b\u003e refers to the process of repackaging video streams without re-encoding, which ensures high-quality output and significantly faster processing times.\u003c/p\u003e\n\n\u003cp\u003eWhen not possible, Transformer falls back to transcoding, a process that involves first decoding video samples into raw data, then re-encoding them for storage in a new container. Here are some of these differences:\u003c/p\u003e\n\n\u003ch3\u003e\u003cspan\u003eTransmuxing\u003c/span\u003e\u003c/h3\u003e\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003eTransformer’s preferred approach when possible - a quick transformation that preserves elementary streams.\u003c/li\u003e\n\u003cli\u003eOnly applicable to basic operations, such as rotating, trimming, or container conversion.\u003c/li\u003e\n\u003cli\u003eNo quality loss or bitrate change.\u003c/li\u003e\n\u003c/ul\u003e\u003c/ul\u003e\n\n\u003cp\u003e\u003cimg alt=\"Transmux\" height=\"270\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxEs9EHg4t55AflszVIYehD8KQlxwybUsBxnxeJSTtvRf3zNaJaCOUi8dHnk9AeFskl2dtrzky6U95sXC2iRXWs7Poj63ftEOHv3ZwpfTJfh5iP5N-DINuq8FB0lbZPA4x9XzqBeCgXXrmmW3I6PSPfRn2g0fk4dHIzKLd5JUiMJVK5-IVJcRh3AN1XKg/w640-h270/Transmux-Jetpack-Media3-Transformer.png\" width=\"75%\"/\u003e\u003c/p\u003e\n  \n\u003ch3\u003e\u003cspan\u003eTranscoding\u003c/span\u003e\u003c/h3\u003e\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003eTransformer\u0026#39;s fallback approach in cases when Transmuxing isn\u0026#39;t possible - Involves decoding and re-encoding elementary streams.\u003c/li\u003e\n\u003cli\u003eMore extensive modifications to the input video are possible.\u003c/li\u003e\n\u003cli\u003eLoss in quality due to re-encoding, but can achieve a desired bitrate target.\u003c/li\u003e\n\u003c/ul\u003e\u003c/ul\u003e\n\n\u003cp\u003e\u003cimg alt=\"Transcode\" height=\"506\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg6-v9kxnkd__no1qV3cklVNvDPoYZCCrD6PTYyHSMUtRBhg-FI0SvfZ2G0dlJHyKZtAzjbcMO43uQWuY2SDO9_gN_RhKDDjvxgiLcDt8Dsj2W0el759D8kD_bqy0TXX-Ty9TGkBmurJgvhI_KB2qCR6fX-9P9gi_eS1kmTsjxh0f8ZzLuRBajHmzq3Wxk/w640-h506/Transcoding-jetpack-media3-processing.png\" width=\"75%\"/\u003e\u003c/p\u003e\n\n\u003cp\u003eWe are continuously implementing further optimizations, such as the recently introduced \u003cspan\u003e\u003ca href=\"https://developer.android.com/reference/androidx/media3/transformer/Transformer.Builder#experimentalSetTrimOptimizationEnabled%28boolean%29\" target=\"_blank\"\u003eexperimentalSetTrimOptimizationEnabled\u003c/a\u003e\u003c/span\u003e setting that we used in the Trimming example above.\u003c/p\u003e\n\n\u003cp\u003eA trim is usually performed by re-encoding all the samples in the file, but since encoded media samples are stored chronologically in their container, we can improve efficiency by only re-encoding the \u003ci\u003egroup of pictures\u003c/i\u003e (GOP) between the start point of the trim and the first keyframes at/after the start point, then stream-copying the rest.\u003c/p\u003e\n\n\u003cp\u003eSince we only decode and encode a fixed portion of any file, the encoding latency is roughly constant, regardless of what the input video duration is. For long videos, this improved latency is dramatic. The optimization relies on being able to stitch part of the input file with newly-encoded output, which means that the encoder\u0026#39;s output format and the input format must be compatible.\u003c/p\u003e\n\n\u003cp\u003eIf the optimization fails, Transformer automatically falls back to normal export.\u003c/p\u003e\n\n\u003ch3\u003eWhat’s next?\u003c/h3\u003e\n\n\u003cp\u003eAs part of Media3, Transformer is a native solution with low integration complexity, is tested on and ensures compatibility with a wide variety of devices, and is customizable to fit your specific needs.\u003c/p\u003e\n\n\u003cp\u003eTo dive deeper, you can explore \u003ca href=\"https://developer.android.com/media/media3/transformer\" target=\"_blank\"\u003eMedia3 Transformer documentation\u003c/a\u003e, run our \u003ca href=\"https://github.com/androidx/media/tree/release/demos/transformer\" target=\"_blank\"\u003esample apps\u003c/a\u003e, or learn how to \u003ca href=\"https://www.youtube.com/watch?v=7vmiYP4vNUE\" target=\"_blank\"\u003ecomplement your media editing pipeline with Jetpack Media3\u003c/a\u003e. We’ve already seen \u003ca href=\"https://www.youtube.com/watch?v=nWXmrY8J_nY\u0026amp;list=PLWz5rJ2EKKc8EtnBH3NwEIbPJaawDjNHv\" target=\"_blank\"\u003eapp developers benefit greatly from adopting Transformer\u003c/a\u003e, so we encourage you to try them out yourself to streamline your media editing workflows and enhance your app’s performance!\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": null,
  "modifiedTime": null
}
