{
  "id": "77309c6a-72b8-4f1d-88db-3c636151e2be",
  "title": "Improving performance with background data prefetching",
  "link": "https://instagram-engineering.com/improving-performance-with-background-data-prefetching-b191acb39898?source=rss----37dc2a3034f2--android",
  "description": "",
  "author": "Instagram Engineering",
  "published": "Thu, 02 Nov 2017 18:09:21 GMT",
  "source": "https://instagram-engineering.com/feed/tagged/android",
  "categories": [
    "instagram",
    "android"
  ],
  "byline": "Instagram Engineering",
  "length": 15077,
  "excerpt": "The Instagram community is bigger and more diverse than ever before. 800m people now visit every month, 80% of whom are outside of the United States. As the community grows, it becomes more and more…",
  "siteName": "Instagram Engineering",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "The Instagram community is bigger and more diverse than ever before. 800m people now visit every month, 80% of whom are outside of the United States. As the community grows, it becomes more and more important that our app can withstand diverse network conditions, a growing variety of devices, and non-traditional usage patterns. The client performance team at Instagram New York is focused on making Instagram fast and performant, no matter where someone is using it. Specifically, our team prioritizes instantaneous content delivery, zero wasted bytes over the network, and zero wasted bytes on disk. We recently decided to focus on effective background prefetching as a way to break the dependency of Instagram usability from network availability and a user’s data plan.ConditionsNetwork availabilityMost of the world does not have enough network connectivity. Michael Midling, our data scientist, put together this map to represent the average network bandwidth while using Instagram in different countries around the world. Darker green regions, like Canada, have somewhere around 4+Mbps, vs. lighter green areas like India, which have an average network bandwidth of 1Mbps.We cannot assume that media will be available to watch when a user opens Instagram and starts watching stories or scrolling through feed. If you want to build a fast media app in India, where network availability is not rich and a round-trip time could be above two seconds, you need to come up with a different strategy than fetching resources in realtime. If we want everyone to be able to access Instagram and see videos and photos from their closest friends and interests, we have to be able to react to different network bandwidth speeds. Building apps that adapt to these network conditions has its challenges.Data sensitivityOne of our solutions was to add the user’s connection type into our logging events. This allowed us to observe the different usage patterns divided by connection type, which helped us adapt. We strive to be respectful of people’s data plans and try to maximize the data sourced over unmetered connections.The graph shows how Instagrammers around the world access our app. For example, we need to adapt to the network patterns in Indonesia where people are switching from one SIM card to another as soon as they run out of data and mainly access the app on cellular connection. On the other hand, people in Brazil mostly use our app over wifi.Network failureWhat if the network fails all together? Historically we would display a screen with grey boxes and hope for the user to come back and retry when they had a better connection. But this isn’t a good experience.Sporadic network connection and cellular network congestion are also concerns. When we’re in one of the light green areas of the map above, where network bandwidth is low, we need to find a way to shorten or eliminate people’s wait time. Our goal is for people to perceive no network connection as being online, but there is no one-size-fits-all solution for this. Below are some of the techniques we apply to adapt the offline experience to different types of usage in different conditions.SolutionsWe came up with a series of strategies. First, we focused on building the Offline Mode experience. With this experience we unlocked the possibility to deliver the content from disk as if it is coming from network. Second, leveraging this cache infrastructure, we built a centralized background prefetching framework, to populate this cache with unseen content.Offline principlesThrough data analysis and user research, we’ve come up with a few principles that represent the major pain points and areas for improvement:Offline is a status, not an errorThe offline experience is seamlessBuild trust through clear communicationYou can see how this was implemented in the video:Decoupling network availability and app usabilityUsing the response store, image and video cache, we can deliver content to the UI screen when it’s not retrieved from the network, which simulates a successful network call. There are three main components: the device screen, the device network layer that composes the HttpRequests, and the device network engine that takes care of delivering our network requests to the server. After building the ability to deliver content from disk, we noticed improvements to how people used Instagram in high-growth markets. We decided to cache the content after downloading from the network with the belief that seeing older content would be better than seeing gray boxes and white screens. But the ideal solution was still showing new content. That’s where background prefetching came in.FrameworkAt Instagram one of our engineering values is “do the simple thing first,” so our first approach was not to build the perfect background prefetching framework. The first prototype just prefetched data when the app got backgrounded, if and only if the user was under wifi connection. This BackgroundPrefetcher iterated through a list of runnables, executing one by one. This first prototype allowed us to:Iterate on kinds of content to prefetchAnalyze the actual effects of delivering unseen cached content on the user experienceBenchmark final framework (stability)public void registerJob(Runnable job) { mBackgroundJobs.add(job);}@Overridepublic void onAppBackgrounded() { if (NetworkUtil.isConnectedWifi(AppContext.getContext())) { while (!mBackgroundJobs.isEmpty()){ mSerialExecutor.execute(mBackgroundJobs.poll()); } }}The reality is that apps are complex, and so are people! When it comes to deciding what type of media to prefetch, you have to carefully analyze usage patterns. For example, some people may use some features more than others.Our home screen has a great diversity of items, from the Stories tray to individual stories media. We could also prefetch photos and videos for feed, the messages that you have pending, items for you to browse in Explore, or your most recent notifications. In our case we started simple, only prefetching some media for Explore, Stories and main feed. Building a centralized framework that is flexible enough to adapt to different use cases helps us maintain efficiency and scale properly. Apart from the ability to schedule the jobs in our framework that prefetched data with no control on the background, we added extra logic on top. Centralizing the logic for background prefetching to a single point made it possible to apply rules and verify that certain conditions are met, like:Control connection type -\u003e unmeteredJobCancellation -\u003e if conditions change or app gets foregrounded, we want to be able to cancel whatever work we were doingBatching requests together, and prefetching only once, at the most optimal time, in between sessionsCollect Metrics → how long does it take for all the work to be finished? How successful are we at scheduling and running the background prefetching jobs?WorkflowLet’s take a look at the workflow for our background prefetching strategy on Android:When the main activity starts (meaning that the app gets foregrounded), we instantiate our BackgroundWifiPrefetcherScheduler. We also enable what type of jobs will be run.This instance registers itself as a BackgroundDetectorListener. For context, we have implemented a structure that will tell us every time that the app gets backgrounded in case we want to do something before the app gets killed (like sending analytics to the server).When the BackgroundWifiPrefetcherScheduler gets notified, it calls our home-made AndroidJobScheduler to schedule the background prefetching work. It will pass in the JobInfo. This JobInfo contains information about what service to launch, and what conditions need to be met in order for this work to get kicked off.Our main conditions are latency and unmetered connections. Depending on the Android OS, we may take other things into consideration, like if power saving mode is enabled or not. We have experimented with different values of latency, and we are still working to provide a personalized experience. Currently we prefetch on background only once in between sessions. To decide at what time we will do this after you background the app, we compute your average time in between sessions (how often do you access Instagram?) and remove outliers using the standard deviation (to not to take into account those times where you might not access the app because you went to sleep if you are a frequent user). We aim to prefetch right before your average time.After that time has passed by, we check if the connection conditions met our requirement (unmetered/wifi). If this is the case, we will launch the BackgroundPrefetcherJobService. If not, this will be pending until the connection condition is met. (Or device is not in battery saving mode if applicable).BackgroundService will create a serialExecutor to run every background job in a serial fashion. However, after obtaining the http response, we prefetch media in an asynchronous manner.After all the work is done, we notify the OS so our process can be killed and we optimize for memory/battery life. Killing this running service on Android is important to release memory resources that will not be used anymore.All of this is user scoped. We need to be able to address when someone logs out or the user switches. If the user logs out, we will cancel the scheduled work to avoid waking up the service unnecessarily.IgJobSchedulerFor Android specifically, we:Looked for an effective way to schedule jobs on background so we could persist data across sessions and specify network requirements.Analyzed how many users were under Lollipop (Android OS released on 2014) as the APIs for Android JobScheduler interface were only available starting on this OS. Turned out this was a case we could not skip…. we needed a compatible version for people using Lollipop.Researched to find an open source/existing solution to schedule jobs on Android for older OS versions. Despite of finding great libraries, none of them fit our use case, as they pulled a dependency on Google Play Service. For context, on Instagram we believe on maintaining our first in class position in terms of APK size.Finally, we ended up building a custom-performant compatible solution for Android JobScheduler APIs.MeasurementAt Instagram we are very data driven and rigorously measure the impact of the systems that we build. That is why when we were designing our background prefetching framework we were also thinking about what metrics should be in place to get the proper feedback. The fact that we count with a centralized framework also helps us collect metrics at a higher level. We thought that it was very important to accurately evaluate the trade-offs and be able to answer questions about how many prefetched bytes were unused or what global CPU regressions were caused.One thing that helped us a lot is that we mark/associate a network request policy to every network request to indicate its behavior and type. This was already built into the app but we leveraged it to slice our prefetching metrics. We attach a request policy to the http request fired and specify if the request is a prefetch request. Another thing that we specify in the policy is the requestType. A request can be specific for Image, Video, API, analytics, etc. This will help us with:Request prioritizationBetter analyze trade offs by dimensiom like global CPU regression, data usage, and cache efficiency/** * The policy behavior describes whether the associated request is needed to render something * on the screen, or not (e.g. prefetch). */public enum Behavior { Undefined(-1), OffScreen(0), OnScreen(1), ; int weight; Behavior(int weight) { this.weight = weight; }}Here we can see a snapshot of that requestPolicy object as defined in our Android codebase. We define a request to be “on screen” when the request belongs to a content that the user is waiting for. offScreen requests have a probability \u003e 1% of the user not interacting with this data requested.Cache efficiency loggerWe wanted to know how many of our prefetched bytes were actually used, so we looked into how items placed in the cache were being used. We built our entire cache logger in a way that met the following specs:Be scalable. It should be able to support new added caches instances through its API.Be fault tolerant and robust. It should tolerate cache failures (no logging action) or inconsistencies across timestamps.Be reliable. It should persist data across sessions.Use minimal disk and latency on logging. Cache reads/writes happen very often, therefore we want to add minimal overhead. The logging during cache reads/writes can lead to more crashes and higher latency.We also wanted to know how much data we used when we added a new background prefetch request. We have a layered base network engine on the device, and as we mentioned, we attach a requestPolicy to every network request. This makes it super easy for us to track data usage in our app, and observe how much data we consume downloading images, videos, JSON responses, etc. We also wanted to analyze how the data usage gets distributed between data usage over wifi vs. data usage over cellular. This unlocked the possibility of experimenting with different prefetching patterns.Other benefitsWhat other benefits can background prefetching give you beyond breaking the dependency on network availability and reducing cellular data usage? If we reduce the sheer number of requests made, we reduce overall network traffic. And by being able to bundle future requests together, we can save overhead and battery life.Preventing regressionSomething that we took into account before implementing background prefetching is the potential risk of causing global CPU regression. And how can you cause regression? Let me give you an example. Imagine our endpoint that serves the API to get your Instagram main feed. Person A’s device will make a call to the main feed API every time person A opens Instagram to get the latest feed first page. This API has several heavy computational operations like ranking and categorizing content based on seen state. If we then do background prefetching every time in between sessions, we would be increasing the load considerably, right? In an attempt to minimize the server side regression, for our first version of the background prefetcher system, an engineer on the feed team, Fei Huang, opened up a different endpoint for background prefetching. This one just fetches new feed posts that are not in view state and return the newest N=20 items.ConclusionThis was our workflow process when building our system. Our team did not open the API to other engineers until we could ensure the quality of the framework and the benefit to the user.As more people join Instagram, this work only becomes more important. We look forward to keep making Instagram more efficient and performant for everyone around the world.Lola Priego is a software engineer on the client performance team at Instagram New York.",
  "image": "https://miro.medium.com/v2/resize:fit:688/1*PBdWAki8iEpmu9td-oZmuQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ca href=\"https://medium.com/@InstagramEng?source=post_page-----b191acb39898--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Instagram Engineering\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*8x_1IP3b75o5u9M4LgFBig.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003ca href=\"https://instagram-engineering.com/?source=post_page-----b191acb39898--------------------------------\" rel=\"noopener  ugc nofollow\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Instagram Engineering\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*CPgwLHR6jno_tOmF0--7eg.jpeg\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv id=\"0dd5\"\u003e\u003cp\u003eThe Instagram community is bigger and more diverse than ever before. 800m people now visit every month, 80% of whom are outside of the United States. As the community grows, it becomes more and more important that our app can withstand diverse network conditions, a growing variety of devices, and non-traditional usage patterns. The client performance team at Instagram New York is focused on making Instagram fast and performant, no matter where someone is using it. \u003c/p\u003e\u003cp\u003e Specifically, our team prioritizes instantaneous content delivery, zero wasted bytes over the network, and zero wasted bytes on disk. We recently decided to focus on effective background prefetching as a way to break the dependency of Instagram usability from network availability and a user’s data plan.\u003c/p\u003e\u003c/div\u003e\u003ch2 id=\"2d4b\"\u003eConditions\u003c/h2\u003e\u003ch2 id=\"cd3e\"\u003e\u003cstrong\u003eNetwork availability\u003c/strong\u003e\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"bae6\"\u003eMost of the world does not have enough network connectivity. Michael Midling, our data scientist, put together this map to represent the average network bandwidth while using Instagram in different countries around the world. Darker green regions, like Canada, have somewhere around 4+Mbps, vs. lighter green areas like India, which have an average network bandwidth of 1Mbps.\u003c/p\u003e\u003cp id=\"9287\"\u003eWe cannot assume that media will be available to watch when a user opens Instagram and starts watching stories or scrolling through feed. If you want to build a fast media app in India, where network availability is not rich and a round-trip time could be above two seconds, you need to come up with a different strategy than fetching resources in realtime. If we want everyone to be able to access Instagram and see videos and photos from their closest friends and interests, we have to be able to react to different network bandwidth speeds. Building apps that adapt to these network conditions has its challenges.\u003c/p\u003e\u003ch2 id=\"aa60\"\u003e\u003cstrong\u003eData sensitivity\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"0d88\"\u003eOne of our solutions was to add the user’s connection type into our logging events. This allowed us to observe the different usage patterns divided by connection type, which helped us adapt. We strive to be respectful of people’s data plans and try to maximize the data sourced over unmetered connections.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"7cf3\"\u003eThe graph shows how Instagrammers around the world access our app. For example, we need to adapt to the network patterns in Indonesia where people are switching from one SIM card to another as soon as they run out of data and mainly access the app on cellular connection. On the other hand, people in Brazil mostly use our app over wifi.\u003c/p\u003e\u003ch2 id=\"66ec\"\u003e\u003cstrong\u003eNetwork failure\u003c/strong\u003e\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"0a5c\"\u003eWhat if the network fails all together? Historically we would display a screen with grey boxes and hope for the user to come back and retry when they had a better connection. But this isn’t a good experience.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cdiv id=\"17a1\"\u003e\u003cp\u003eSporadic network connection and cellular network congestion are also concerns. When we’re in one of the light green areas of the map above, where network bandwidth is low, we need to find a way to shorten or eliminate people’s wait time. \u003c/p\u003e\u003cp\u003e Our goal is for people to perceive no network connection as being online, but there is no one-size-fits-all solution for this. Below are some of the techniques we apply to adapt the offline experience to different types of usage in different conditions.\u003c/p\u003e\u003c/div\u003e\u003ch2 id=\"eba1\"\u003eSolutions\u003c/h2\u003e\u003cp id=\"155b\"\u003eWe came up with a series of strategies. First, we focused on building the Offline Mode experience. With this experience we unlocked the possibility to deliver the content from disk as if it is coming from network. Second, leveraging this cache infrastructure, we built a centralized background prefetching framework, to populate this cache with unseen content.\u003c/p\u003e\u003ch2 id=\"76fe\"\u003e\u003cstrong\u003eOffline principles\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"8427\"\u003eThrough data analysis and user research, we’ve come up with a few principles that represent the major pain points and areas for improvement:\u003c/p\u003e\u003col\u003e\u003cli id=\"e7c5\"\u003eOffline is a status, not an error\u003c/li\u003e\u003cli id=\"7200\"\u003eThe offline experience is seamless\u003c/li\u003e\u003cli id=\"8c49\"\u003eBuild trust through clear communication\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"025c\"\u003eYou can see how this was implemented in the video:\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"ef33\"\u003e\u003cstrong\u003eDecoupling network availability and app usability\u003c/strong\u003e\u003c/h2\u003e\u003cdiv id=\"20b6\"\u003e\u003cp\u003eUsing the response store, image and video cache, we can deliver content to the UI screen when it’s not retrieved from the network, which simulates a successful network call. \u003c/p\u003e\u003cp\u003e There are three main components: the device screen, the device network layer that composes the HttpRequests, and the device network engine that takes care of delivering our network requests to the server. \u003c/p\u003e\u003cp\u003e After building the ability to deliver content from disk, we noticed improvements to how people used Instagram in high-growth markets. We decided to cache the content after downloading from the network with the belief that seeing older content would be better than seeing gray boxes and white screens. But the ideal solution was still showing new content. That’s where background prefetching came in.\u003c/p\u003e\u003c/div\u003e\u003ch2 id=\"78ba\"\u003eFramework\u003c/h2\u003e\u003cdiv id=\"83aa\"\u003e\u003cp\u003eAt Instagram one of our engineering values is “do the simple thing first,” so our first approach was not to build the perfect background prefetching framework. The first prototype just prefetched data when the app got backgrounded, if and only if the user was under wifi connection. This BackgroundPrefetcher iterated through a list of runnables, executing one by one.\u003c/p\u003e\u003cp\u003e  This first prototype allowed us to:\u003c/p\u003e\u003c/div\u003e\u003col\u003e\u003cli id=\"8c8e\"\u003eIterate on kinds of content to prefetch\u003c/li\u003e\u003cli id=\"52b2\"\u003eAnalyze the actual effects of delivering unseen cached content on the user experience\u003c/li\u003e\u003cli id=\"8be2\"\u003eBenchmark final framework (stability)\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003cspan id=\"a0e3\"\u003epublic void registerJob(Runnable job) {\u003cbr/\u003e  mBackgroundJobs.add(job);\u003cbr/\u003e}\u003c/span\u003e\u003cspan id=\"bb37\"\u003e@Override\u003cbr/\u003epublic void onAppBackgrounded() {\u003cbr/\u003e  if (NetworkUtil.isConnectedWifi(AppContext.getContext())) {\u003cbr/\u003e    while (!mBackgroundJobs.isEmpty()){   \u003cbr/\u003e    \u003cstrong\u003emSerialExecutor.execute(mBackgroundJobs.poll());\u003cbr/\u003e  \u003c/strong\u003e}\u003cbr/\u003e }\u003cbr/\u003e}\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"c0fa\"\u003eThe reality is that apps are complex, and so are people! When it comes to deciding what type of media to prefetch, you have to carefully analyze usage patterns. For example, some people may use some features more than others.\u003c/p\u003e\u003cdiv id=\"01f8\"\u003e\u003cp\u003eOur home screen has a great diversity of items, from the Stories tray to individual stories media. We could also prefetch photos and videos for feed, the messages that you have pending, items for you to browse in Explore, or your most recent notifications. In our case we started simple, only prefetching some media for Explore, Stories and main feed.\u003c/p\u003e\u003cp\u003e Building a centralized framework that is flexible enough to adapt to different use cases helps us maintain efficiency and scale properly. \u003c/p\u003e\u003cp\u003e Apart from the ability to schedule the jobs in our framework that prefetched data with no control on the background, we added extra logic on top. Centralizing the logic for background prefetching to a single point made it possible to apply rules and verify that certain conditions are met, like:\u003c/p\u003e\u003c/div\u003e\u003cul\u003e\u003cli id=\"d1c2\"\u003eControl connection type -\u0026gt; unmetered\u003c/li\u003e\u003cli id=\"d5c8\"\u003eJobCancellation -\u0026gt; if conditions change or app gets foregrounded, we want to be able to cancel whatever work we were doing\u003c/li\u003e\u003cli id=\"3a07\"\u003eBatching requests together, and prefetching only once, at the most optimal time, in between sessions\u003c/li\u003e\u003cli id=\"3dac\"\u003eCollect Metrics → how long does it take for all the work to be finished? How successful are we at scheduling and running the background prefetching jobs?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"1e65\"\u003e\u003cstrong\u003eWorkflow\u003c/strong\u003e\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"b77b\"\u003eLet’s take a look at the workflow for our background prefetching strategy on Android:\u003c/p\u003e\u003cul\u003e\u003cli id=\"f344\"\u003eWhen the main activity starts (meaning that the app gets foregrounded), we instantiate our BackgroundWifiPrefetcherScheduler. We also enable what type of jobs will be run.\u003c/li\u003e\u003cli id=\"9271\"\u003eThis instance registers itself as a BackgroundDetectorListener. For context, we have implemented a structure that will tell us every time that the app gets backgrounded in case we want to do something before the app gets killed (like sending analytics to the server).\u003c/li\u003e\u003cli id=\"7142\"\u003eWhen the BackgroundWifiPrefetcherScheduler gets notified, it calls our home-made AndroidJobScheduler to schedule the background prefetching work. It will pass in the JobInfo. This JobInfo contains information about what service to launch, and what conditions need to be met in order for this work to get kicked off.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"68bb\"\u003eOur main conditions are latency and unmetered connections. Depending on the Android OS, we may take other things into consideration, like if power saving mode is enabled or not. We have experimented with different values of latency, and we are still working to provide a personalized experience. Currently we prefetch on background only once in between sessions. To decide at what time we will do this after you background the app, we compute your average time in between sessions (how often do you access Instagram?) and remove outliers using the standard deviation (to not to take into account those times where you might not access the app because you went to sleep if you are a frequent user). We aim to prefetch right before your average time.\u003c/p\u003e\u003cul\u003e\u003cli id=\"bb0b\"\u003eAfter that time has passed by, we check if the connection conditions met our requirement (unmetered/wifi). If this is the case, we will launch the BackgroundPrefetcherJobService. If not, this will be pending until the connection condition is met. (Or device is not in battery saving mode if applicable).\u003c/li\u003e\u003cli id=\"290c\"\u003eBackgroundService will create a serialExecutor to run every background job in a serial fashion. However, after obtaining the http response, we prefetch media in an asynchronous manner.\u003c/li\u003e\u003cli id=\"c03b\"\u003eAfter all the work is done, we notify the OS so our process can be killed and we optimize for memory/battery life. Killing this running service on Android is important to release memory resources that will not be used anymore.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"5246\"\u003eAll of this is user scoped. We need to be able to address when someone logs out or the user switches. If the user logs out, we will cancel the scheduled work to avoid waking up the service unnecessarily.\u003c/p\u003e\u003ch2 id=\"8090\"\u003e\u003cstrong\u003eIgJobScheduler\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"8be4\"\u003eFor Android specifically, we:\u003c/p\u003e\u003col\u003e\u003cli id=\"3e3a\"\u003eLooked for an effective way to schedule jobs on background so we could persist data across sessions and specify network requirements.\u003c/li\u003e\u003cli id=\"c9c5\"\u003eAnalyzed how many users were under Lollipop (Android OS released on 2014) as the APIs for Android JobScheduler interface were only available starting on this OS. Turned out this was a case we could not skip…. we needed a compatible version for people using Lollipop.\u003c/li\u003e\u003cli id=\"bc53\"\u003eResearched to find an open source/existing solution to schedule jobs on Android for older OS versions. Despite of finding great libraries, none of them fit our use case, as they pulled a dependency on Google Play Service. For context, on Instagram we believe on maintaining our first in class position in terms of APK size.\u003c/li\u003e\u003cli id=\"14e5\"\u003eFinally, we ended up building a custom-performant compatible solution for Android JobScheduler APIs.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"b9a5\"\u003e\u003cstrong\u003eMeasurement\u003c/strong\u003e\u003c/h2\u003e\u003cdiv id=\"2fe2\"\u003e\u003cp\u003eAt Instagram we are very data driven and rigorously measure the impact of the systems that we build. That is why when we were designing our background prefetching framework we were also thinking about what metrics should be in place to get the proper feedback.\u003c/p\u003e\u003cp\u003e The fact that we count with a centralized framework also helps us collect metrics at a higher level. We thought that it was very important to accurately evaluate the trade-offs and be able to answer questions about how many prefetched bytes were unused or what global CPU regressions were caused.\u003c/p\u003e\u003c/div\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"7ce4\"\u003eOne thing that helped us a lot is that we mark/associate a network request policy to every network request to indicate its behavior and type. This was already built into the app but we leveraged it to slice our prefetching metrics. We attach a request policy to the http request fired and specify if the request is a prefetch request. Another thing that we specify in the policy is the requestType. A request can be specific for Image, Video, API, analytics, etc. This will help us with:\u003c/p\u003e\u003cul\u003e\u003cli id=\"28d4\"\u003eRequest prioritization\u003c/li\u003e\u003cli id=\"e4c3\"\u003eBetter analyze trade offs by dimensiom like global CPU regression, data usage, and cache efficiency\u003c/li\u003e\u003c/ul\u003e\u003cpre\u003e\u003cspan id=\"8bd6\"\u003e\u003cem\u003e/**\u003cbr/\u003e * The policy behavior describes whether the associated request is  \u003cbr/\u003eneeded to render something\u003cbr/\u003e * on the screen, or not (e.g. prefetch).\u003cbr/\u003e */\u003cbr/\u003e\u003c/em\u003epublic enum Behavior {\u003cbr/\u003e \u003cem\u003eUndefined\u003c/em\u003e(-1),\u003cbr/\u003e \u003cem\u003eOffScreen\u003c/em\u003e(0),\u003cbr/\u003e \u003cem\u003eOnScreen\u003c/em\u003e(1),\u003cbr/\u003e ;\u003c/span\u003e\u003cspan id=\"37ac\"\u003e int weight;\u003c/span\u003e\u003cspan id=\"85e7\"\u003e Behavior(int weight) {\u003cbr/\u003e  this.weight = weight;\u003cbr/\u003e }\u003cbr/\u003e}\u003c/span\u003e\u003c/pre\u003e\u003cp id=\"8b09\"\u003eHere we can see a snapshot of that requestPolicy object as defined in our Android codebase. We define a request to be “on screen” when the request belongs to a content that the user is waiting for. offScreen requests have a probability \u0026gt; 1% of the user not interacting with this data requested.\u003c/p\u003e\u003ch2 id=\"95f5\"\u003e\u003cstrong\u003eCache efficiency logger\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"aa34\"\u003eWe wanted to know how many of our prefetched bytes were actually used, so we looked into how items placed in the cache were being used. We built our entire cache logger in a way that met the following specs:\u003c/p\u003e\u003cul\u003e\u003cli id=\"b91b\"\u003eBe scalable. It should be able to support new added caches instances through its API.\u003c/li\u003e\u003cli id=\"b93f\"\u003eBe fault tolerant and robust. It should tolerate cache failures (no logging action) or inconsistencies across timestamps.\u003c/li\u003e\u003cli id=\"f883\"\u003eBe reliable. It should persist data across sessions.\u003c/li\u003e\u003cli id=\"5d7f\"\u003eUse minimal disk and latency on logging. Cache reads/writes happen very often, therefore we want to add minimal overhead. The logging during cache reads/writes can lead to more crashes and higher latency.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cdiv id=\"9209\"\u003e\u003cp\u003eWe also wanted to know how much data we used when we added a new background prefetch request. We have a layered base network engine on the device, and as we mentioned, we attach a requestPolicy to every network request. This makes it super easy for us to track data usage in our app, and observe how much data we consume downloading images, videos, JSON responses, etc. \u003c/p\u003e\u003cp\u003e We also wanted to analyze how the data usage gets distributed between data usage over wifi vs. data usage over cellular. This unlocked the possibility of experimenting with different prefetching patterns.\u003c/p\u003e\u003c/div\u003e\u003ch2 id=\"e72e\"\u003e\u003cstrong\u003eOther benefits\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"54df\"\u003eWhat other benefits can background prefetching give you beyond breaking the dependency on network availability and reducing cellular data usage? If we reduce the sheer number of requests made, we reduce overall network traffic. And by being able to bundle future requests together, we can save overhead and battery life.\u003c/p\u003e\u003ch2 id=\"3958\"\u003e\u003cstrong\u003ePreventing regression\u003c/strong\u003e\u003c/h2\u003e\u003cdiv id=\"3f00\"\u003e\u003cp\u003eSomething that we took into account before implementing background prefetching is the potential risk of causing global CPU regression.\u003c/p\u003e\u003cp\u003e And how can you cause regression? Let me give you an example. Imagine our endpoint that serves the API to get your Instagram main feed. Person A’s device will make a call to the main feed API every time person A opens Instagram to get the latest feed first page. This API has several heavy computational operations like ranking and categorizing content based on seen state. If we then do background prefetching every time in between sessions, we would be increasing the load considerably, right?\u003c/p\u003e\u003cp\u003e In an attempt to minimize the server side regression, for our first version of the background prefetcher system, an engineer on the feed team, Fei Huang, opened up a different endpoint for background prefetching. This one just fetches new feed posts that are not in view state and return the newest N=20 items.\u003c/p\u003e\u003c/div\u003e\u003ch2 id=\"5878\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"86a5\"\u003eThis was our workflow process when building our system. Our team did not open the API to other engineers until we could ensure the quality of the framework and the benefit to the user.\u003c/p\u003e\u003cp id=\"4093\"\u003eAs more people join Instagram, this work only becomes more important. We look forward to keep making Instagram more efficient and performant for everyone around the world.\u003c/p\u003e\u003cp id=\"d00a\"\u003e\u003cem\u003eLola Priego is a software engineer on the client performance team at Instagram New York.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": "2017-11-02T18:09:19.778Z",
  "modifiedTime": null
}
