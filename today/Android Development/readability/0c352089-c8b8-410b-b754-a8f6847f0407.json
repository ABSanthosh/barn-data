{
  "id": "0c352089-c8b8-410b-b754-a8f6847f0407",
  "title": "Better Android Testing at Airbnb, Part 5",
  "link": "https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-661a554a8c8b?source=rss----53c7c27702d5--android",
  "description": "",
  "author": "Eli Hart",
  "published": "Mon, 23 Dec 2019 16:37:09 GMT",
  "source": "https://medium.com/feed/airbnb-engineering/tagged/android",
  "categories": [
    "android",
    "mobile",
    "testing"
  ],
  "byline": "Eli Hart",
  "length": 10852,
  "excerpt": "In the fifth part of our series on Android Testing at Airbnb, we take a close look at the architecture of our integration testing framework.",
  "siteName": "The Airbnb Tech Blog",
  "favicon": "https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png",
  "text": "In the fifth part of our series on Android Testing at Airbnb, we take a close look at the architecture of our integration testing framework.In previous installments of this series we laid out our state mocking system, and how we built UI integration testing on top of it. In this article we go into depth on how the system is architected, how idle detection is approached, and how errors are gracefully handled.This includes a fair amount of implementation depth, with the goal of providing enough detail so that others could recreate a similar system while avoiding much of the trouble we encountered.Architecture of the Test FrameworkOur integration tests are run with Espresso, but have a fairly complex test harness built on top. This is because we need to be able to easily setup fragments, manipulate their views, and tear them down, which is difficult to do via direct Espresso API’s. We also don’t make normal JUnit or Espresso assertions in our tests, but instead take screenshots, programmatically click through the view hierarchy, and upload report files.Leveraging a Base ActivityWe use a custom Activity (named IntegrationTestActivity) to run the tests, which lives in a library module in our app. This gives it direct access to manipulate Fragments during the test. The module is included as a test dependency so it isn’t shipped to production.On the JUnit side, a single test launches the IntegrationTestActivity with a Fragment name as a String extra. The activity uses the Fragment name to reflectively access mocks declared for that Fragment. The Activity then runs through all mocks, setting each one up, applying some action to it (such as screenshotting it), and then tearing it down and going on to the next. After all mocks are processed the Activity cleans itself up and marks its IdlingResource as idle.IntegrationTestActivity is an abstract class that does the work of managing the mocks. It also overrides all of the activity functions to prevent them from being invoked by a Fragment under test (as mentioned in the previous article about interaction testing). Subclasses simply implement a function to run validations on the mock, such as taking a screenshot or executing the interaction testing.For example, our activity that takes screenshots of each Fragment mock is just the following code.Similarly, our interaction testing activity is another simple subclass.Note how these leverage the mock framework to consume each Fragment in its mocked state, without having to worry about setting up the fragment, waiting for the view to be stable, tearing down the UI, or any other tedium that is normally inherent to integration tests.Additionally, we can very easily create new subclasses to process these mocks with any other checks we may want to make.Running the Test ActivityWhile one of these activities runs, the JUnit test waits and listens for when the Activity is done so that JUnit can finish the test. This is achieved with a custom Espresso IdlingResource declared in the IntegrationTestActivity’s module. It is through this idler that the JUnit test and the Activity can communicate.The Idler is registered with Espresso in a custom JUnit TestRule, and we leverage Espresso to wait for it. Normally this is done by invoking a view assertion, but since we don’t use Espresso assertions we instead tell Espresso explicitly to wait for Idlers by calling Espresso.onIdle().On the JUnit side our test then looks roughly like this:Notice how the test declaration for each Fragment is a single line. You’ll see how we automatically generate this for each Fragment later.In review, the benefits of this single Activity hosting approach are:Directly manipulate Fragments and views for screenshot and interaction testsBlocking function calls to the Activity, such as finish, so Fragments under test can’t unwittingly affect the test frameworkProvides mocked Fragments via a generic base class, which can be subclassed for specific test needsHowever, there are also challenges with this approach, which require some complexity to work around.Idle DetectionNormally Espresso handles idle detection automatically. For example, an Espresso ViewAssertion call waits until the UI is idle before making the assertion. In our custom test activity we aren’t making assertions via Espresso, and also don’t have access to Espresso’s underlying API’s to get callbacks on idle.However, IntegrationTestActivity needs to show a Fragment and reliably know when it is fully laid out so that our tests can run on it. This means we needed to build our own implementation of idle detection. This is tricky for a few reasons:Accounting for all sources of asynchronously running code is like playing whack-a-mole, and may not even be possible if a feature runs custom async code that the test harness doesn’t know aboutNot accounting for all async code can lead to test flakinessBeing overly defensive, and waiting for too long, can unnecessarily extend test times, or even make tests time outFortunately, our task is simplified because our Fragment data is completely mocked out. We don’t need to worry about waiting for network requests or database queries. We simply need to make sure that we wait for anything that may affect the UI.The most important aspect to this is waiting for the main thread to be idle, since that is what processes UI updates. Conveniently, Handler exposes an API to allow us to do just that!Handler().looper.queue.isIdleWe could simply poll this function until the queue is idle. However, there is a problem with this approach. The Handler’s queue may report being idle while the last Runnable is still being run. That is, a runnable is dequeued and then run, so we can tell when the queue is empty, but can’t know whether the last Runnable has finished being run.Instead we post our own Runnable to the Handler, and when it is run we check whether the queue is empty. This lets us flush the queue before checking its status. A basic approach looks like this:This conveys the basic idea, but a few things should be added to make it production ready:The post loop inside HandlerIdleDetector must be canceled once you are done with it to avoid it continuing indefinitelyInstead of polling, a callback system can be used along with coroutines to gracefully sleep while we wait for idlenessA timeout system can be added to provide a more robust error message if the Loopers never go idleThis cannot be run on a thread included by one of the Loopers, since they would be competing to run on the same threadIt generally isn’t enough to just wait until all threads are idle. Notably, some view updates, like animations, are posted to the next animation frame. Make sure the loopers all stay idle for at least one frame (~16ms).We also use Epoxy extensively in our UI, which does some processing on a background thread. In fact, it is quite common for RecyclerView setups to use an asynchronous thread to handle diffing of RecyclerView changes, so this will be a common use case for many people. We built our idle detection to take a list of Loopers to watch, and return when they are all idle. This makes it easy to add new threads to the list.One caveat to this approach is that any Runnable posted to a later time with postDelayed is not accounted for (Espresso cannot account for these either). To prevent flakiness from these we don’t allow these calls in our Fragments. If a Fragment needs to delay a Runnable (mainly for animation purposes) then we have a utility function to wrap the call, which forces the delay to zero in test builds.Error HandlingIf a test throws an exception, our goal (as creators of a test framework) is to present that exception to the end developer as clearly as easily possible. Developers shouldn’t have to dig through logs, understand code in the test framework, or otherwise deal with any overhead in understanding the root cause of a crash. We’ve done a few things to make this easier for them.First, if a crash happens off the main thread, say in some async task, then the test runner normally reports a generic message:Test failed to run to completion. Reason: ‘Instrumentation run failed due to Process crashed.’. Check device logcat for detailsThis is unhelpful, and forces extra work on the developer. Instead, we use a test rule to register a default exception handler for all threads, including RxJava and coroutines. This handler passes the exception along to the main thread so that Espresso can handle it and properly display the error as the test failure message.Even if the correct error message is provided, an engineer might have trouble debugging it without the context of what was happening when it was thrown. A single test can cover many mocks, so it is difficult to tell which mock was being test. One could dig into the test logs, but we wanted to make this easier. For example, we can provide information about which mock was set on the Fragment, which View was being clicked, or any other pertinent information about what the test framework was doing when the exception was thrown.To accomplish this we maintain a stack of Strings representing “test context”. The framework can push any String onto the stack it wants, and pop it when that phase is over. For example, the stack may have these two strings:Loaded ‘failure state’ for BookingFragmentClicking ‘book_button’ viewThen, since we already have a system in place to catch thrown exceptions, we can wrap the exceptions to provide our context to the developer.These techniques have made it easier for developers to address errors in their code, and to be more independent. As a maintainer of the test framework this is important in reducing the number of times I get directly messaged to help somebody debug their test failure.The last piece of our error handling approach relates to how failures are surfaced to a PR on Github. This is covered in detail in a later article about CI.Next: Obstacles to Consistent MockingThis article detailed the implementation of our test framework, issues we ran into, and design decisions we made to make the system robust and scalable.In the next article we will look at common reasons the test framework may be flaky, and how we can solve them at the root.Series IndexThis is a seven part article series on testing at Airbnb.Part 1 — Testing Philosophy and a Mocking SystemPart 2 — Screenshot Testing with MvRx and HappoPart 3 — Automated Interaction TestingPart 4 — A Framework for Unit Testing ViewModelsPart 5 (This article) — Architecture of our Automated Testing FrameworkPart 6 — Obstacles to Consistent MockingPart 7 — Test Generation and CI ConfigurationWe’re Hiring!Want to work with us on these and other Android projects at scale? Airbnb is hiring for several Android engineer positions across the company! See https://careers.airbnb.com for current openings.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*GS7H3FnyoSev8zyIiprObg.jpeg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ca rel=\"noopener follow\" href=\"https://medium.com/@konakid?source=post_page-----661a554a8c8b--------------------------------\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"Eli Hart\" src=\"https://miro.medium.com/v2/resize:fill:88:88/2*qR91fuLzUz5PI59hjTTcRQ.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003ca href=\"https://medium.com/airbnb-engineering?source=post_page-----661a554a8c8b--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003cp\u003e\u003cimg alt=\"The Airbnb Tech Blog\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*MlNQKg-sieBGW5prWoe9HQ.jpeg\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cp id=\"4fcb\"\u003e\u003cem\u003eIn the fifth part of our series on Android Testing at Airbnb, we take a close look at the architecture of our integration testing framework.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"68a8\"\u003eIn \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-part-4-testing-viewmodels-550d929126c8\"\u003eprevious installments\u003c/a\u003e of this series we laid out our state mocking system, and how we built UI integration testing on top of it. In this article we go into depth on how the system is architected, how idle detection is approached, and how errors are gracefully handled.\u003c/p\u003e\u003cp id=\"fd83\"\u003eThis includes a fair amount of implementation depth, with the goal of providing enough detail so that others could recreate a similar system while avoiding much of the trouble we encountered.\u003c/p\u003e\u003ch2 id=\"6a7d\"\u003eArchitecture of the Test Framework\u003c/h2\u003e\u003cp id=\"64cc\"\u003eOur integration tests are run with Espresso, but have a fairly complex test harness built on top. This is because we need to be able to easily setup fragments, manipulate their views, and tear them down, which is difficult to do via direct Espresso API’s. We also don’t make normal JUnit or Espresso assertions in our tests, but instead take screenshots, programmatically click through the view hierarchy, and upload report files.\u003c/p\u003e\u003ch2 id=\"9cc9\"\u003eLeveraging a Base Activity\u003c/h2\u003e\u003cp id=\"1aa8\"\u003eWe use a custom Activity (named \u003cstrong\u003e\u003cem\u003eIntegrationTestActivity\u003c/em\u003e\u003c/strong\u003e) to run the tests, which lives in a library module in our app. This gives it direct access to manipulate Fragments during the test. The module is included as a test dependency so it isn’t shipped to production.\u003c/p\u003e\u003cp id=\"5955\"\u003eOn the JUnit side, a single test launches the \u003cstrong\u003e\u003cem\u003eIntegrationTestActivity\u003c/em\u003e\u003c/strong\u003e with a Fragment name as a String extra. The activity uses the Fragment name to reflectively access mocks declared for that Fragment. The Activity then runs through all mocks, setting each one up, applying some action to it (such as screenshotting it), and then tearing it down and going on to the next. After all mocks are processed the Activity cleans itself up and marks its IdlingResource as idle.\u003c/p\u003e\u003cp id=\"e87e\"\u003e\u003cstrong\u003e\u003cem\u003eIntegrationTestActivity\u003c/em\u003e\u003c/strong\u003e is an abstract class that does the work of managing the mocks. It also overrides all of the activity functions to prevent them from being invoked by a Fragment under test (as mentioned in \u003ca rel=\"noopener\" href=\"https://medium.com/p/1d1e91e489b4\"\u003ethe previous article about interaction testing\u003c/a\u003e). Subclasses simply implement a function to run validations on the mock, such as taking a screenshot or executing the interaction testing.\u003c/p\u003e\u003cp id=\"b87a\"\u003eFor example, our activity that takes screenshots of each Fragment mock is just the following code.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"f93b\"\u003eSimilarly, our interaction testing activity is another simple subclass.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"1578\"\u003eNote how these leverage the mock framework to consume each Fragment in its mocked state, without having to worry about setting up the fragment, waiting for the view to be stable, tearing down the UI, or any other tedium that is normally inherent to integration tests.\u003c/p\u003e\u003cp id=\"6763\"\u003eAdditionally, we can very easily create new subclasses to process these mocks with any other checks we may want to make.\u003c/p\u003e\u003ch2 id=\"6851\"\u003eRunning the Test Activity\u003c/h2\u003e\u003cp id=\"5fed\"\u003eWhile one of these activities runs, the JUnit test waits and listens for when the Activity is done so that JUnit can finish the test. This is achieved with a custom Espresso IdlingResource declared in the IntegrationTestActivity’s module. It is through this idler that the JUnit test and the Activity can communicate.\u003c/p\u003e\u003cp id=\"869a\"\u003eThe Idler is registered with Espresso in a custom JUnit TestRule, and we leverage Espresso to wait for it. Normally this is done by invoking a view assertion, but since we don’t use Espresso assertions we instead tell Espresso explicitly to wait for Idlers by calling \u003cstrong\u003e\u003cem\u003eEspresso.onIdle()\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\u003cp id=\"6c8c\"\u003eOn the JUnit side our test then looks roughly like this:\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"c90b\"\u003eNotice how the test declaration for each Fragment is a single line. You’ll see how we automatically generate this for each Fragment later.\u003c/p\u003e\u003cp id=\"ee0e\"\u003eIn review, the benefits of this single Activity hosting approach are:\u003c/p\u003e\u003cul\u003e\u003cli id=\"6f6c\"\u003eDirectly manipulate Fragments and views for screenshot and interaction tests\u003c/li\u003e\u003cli id=\"9f33\"\u003eBlocking function calls to the Activity, such as \u003cstrong\u003e\u003cem\u003efinish\u003c/em\u003e\u003c/strong\u003e, so Fragments under test can’t unwittingly affect the test framework\u003c/li\u003e\u003cli id=\"8632\"\u003eProvides mocked Fragments via a generic base class, which can be subclassed for specific test needs\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"999c\"\u003eHowever, there are also challenges with this approach, which require some complexity to work around.\u003c/p\u003e\u003ch2 id=\"43d5\"\u003eIdle Detection\u003c/h2\u003e\u003cp id=\"9a05\"\u003eNormally Espresso handles idle detection automatically. For example, an Espresso ViewAssertion call waits until the UI is idle before making the assertion. In our custom test activity we aren’t making assertions via Espresso, and also don’t have access to Espresso’s underlying API’s to get callbacks on idle.\u003c/p\u003e\u003cp id=\"445b\"\u003eHowever, \u003cstrong\u003e\u003cem\u003eIntegrationTestActivity\u003c/em\u003e\u003c/strong\u003e needs to show a Fragment and reliably know when it is fully laid out so that our tests can run on it. This means we needed to build our own implementation of idle detection. This is tricky for a few reasons:\u003c/p\u003e\u003cul\u003e\u003cli id=\"8b63\"\u003eAccounting for all sources of asynchronously running code is like playing whack-a-mole, and may not even be possible if a feature runs custom async code that the test harness doesn’t know about\u003c/li\u003e\u003cli id=\"4702\"\u003eNot accounting for all async code can lead to test flakiness\u003c/li\u003e\u003cli id=\"5988\"\u003eBeing overly defensive, and waiting for too long, can unnecessarily extend test times, or even make tests time out\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"2bdf\"\u003eFortunately, our task is simplified because our Fragment data is completely mocked out. We don’t need to worry about waiting for network requests or database queries. We simply need to make sure that we wait for anything that may affect the UI.\u003c/p\u003e\u003cp id=\"d56e\"\u003eThe most important aspect to this is waiting for the main thread to be idle, since that is what processes UI updates. Conveniently, Handler exposes an API to allow us to do just that!\u003c/p\u003e\u003cp id=\"5fd0\"\u003e\u003cstrong\u003e\u003cem\u003eHandler().looper.queue.isIdle\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"de14\"\u003eWe could simply poll this function until the queue is idle. However, there is a problem with this approach. The Handler’s queue may report being idle while the last Runnable is still being run. That is, a runnable is dequeued and then run, so we can tell when the queue is empty, but can’t know whether the last Runnable has finished being run.\u003c/p\u003e\u003cp id=\"8124\"\u003eInstead we post our own Runnable to the Handler, and when it is run we check whether the queue is empty. This lets us flush the queue before checking its status. A basic approach looks like this:\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"e833\"\u003eThis conveys the basic idea, but a few things should be added to make it production ready:\u003c/p\u003e\u003cul\u003e\u003cli id=\"bd9b\"\u003eThe post loop inside HandlerIdleDetector must be canceled once you are done with it to avoid it continuing indefinitely\u003c/li\u003e\u003cli id=\"c17c\"\u003eInstead of polling, a callback system can be used along with coroutines to gracefully sleep while we wait for idleness\u003c/li\u003e\u003cli id=\"d101\"\u003eA timeout system can be added to provide a more robust error message if the Loopers never go idle\u003c/li\u003e\u003cli id=\"a455\"\u003eThis cannot be run on a thread included by one of the Loopers, since they would be competing to run on the same thread\u003c/li\u003e\u003cli id=\"682f\"\u003eIt generally isn’t enough to just wait until all threads are idle. Notably, some view updates, like animations, are posted to the next animation frame. Make sure the loopers all stay idle for at least one frame (~16ms).\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"1355\"\u003eWe also use Epoxy extensively in our UI, which does some processing on a background thread. In fact, it is quite common for RecyclerView setups to use an asynchronous thread to handle diffing of RecyclerView changes, so this will be a common use case for many people. We built our idle detection to take a list of Loopers to watch, and return when they are all idle. This makes it easy to add new threads to the list.\u003c/p\u003e\u003cp id=\"61b8\"\u003eOne caveat to this approach is that any \u003cstrong\u003e\u003cem\u003eRunnable\u003c/em\u003e\u003c/strong\u003e posted to a later time with \u003cstrong\u003e\u003cem\u003epostDelayed\u003c/em\u003e\u003c/strong\u003e is not accounted for (Espresso cannot account for these either). To prevent flakiness from these we don’t allow these calls in our Fragments. If a Fragment needs to delay a Runnable (mainly for animation purposes) then we have a utility function to wrap the call, which forces the delay to zero in test builds.\u003c/p\u003e\u003ch2 id=\"f340\"\u003eError Handling\u003c/h2\u003e\u003cp id=\"ddee\"\u003eIf a test throws an exception, our goal (as creators of a test framework) is to present that exception to the end developer as clearly as easily possible. Developers shouldn’t have to dig through logs, understand code in the test framework, or otherwise deal with any overhead in understanding the root cause of a crash. We’ve done a few things to make this easier for them.\u003c/p\u003e\u003cp id=\"0294\"\u003eFirst, if a crash happens off the main thread, say in some async task, then the test runner normally reports a generic message:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"70cf\"\u003eTest failed to run to completion. Reason: ‘Instrumentation run failed due to Process crashed.’. Check device logcat for details\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"771f\"\u003eThis is unhelpful, and forces extra work on the developer. Instead, we use a test rule to register a default exception handler for all threads, including RxJava and coroutines. This handler passes the exception along to the main thread so that Espresso can handle it and properly display the error as the test failure message.\u003c/p\u003e\u003cp id=\"e54c\"\u003eEven if the correct error message is provided, an engineer might have trouble debugging it without the context of what was happening when it was thrown. A single test can cover many mocks, so it is difficult to tell which mock was being test. One could dig into the test logs, but we wanted to make this easier. For example, we can provide information about which mock was set on the Fragment, which View was being clicked, or any other pertinent information about what the test framework was doing when the exception was thrown.\u003c/p\u003e\u003cp id=\"30e0\"\u003eTo accomplish this we maintain a stack of Strings representing “test context”. The framework can push any String onto the stack it wants, and pop it when that phase is over. For example, the stack may have these two strings:\u003c/p\u003e\u003cul\u003e\u003cli id=\"7de8\"\u003eLoaded ‘failure state’ for BookingFragment\u003c/li\u003e\u003cli id=\"86c8\"\u003eClicking ‘book_button’ view\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"159a\"\u003eThen, since we already have a system in place to catch thrown exceptions, we can wrap the exceptions to provide our context to the developer.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"4c99\"\u003eThese techniques have made it easier for developers to address errors in their code, and to be more independent. As a maintainer of the test framework this is important in reducing the number of times I get directly messaged to help somebody debug their test failure.\u003c/p\u003e\u003cp id=\"0293\"\u003eThe last piece of our error handling approach relates to how failures are surfaced to a PR on Github. This is covered in detail in a later article about CI.\u003c/p\u003e\u003ch2 id=\"2d46\"\u003eNext: Obstacles to Consistent Mocking\u003c/h2\u003e\u003cp id=\"340f\"\u003eThis article detailed the implementation of our test framework, issues we ran into, and design decisions we made to make the system robust and scalable.\u003c/p\u003e\u003cp id=\"4948\"\u003eIn \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-a11f6832773f\"\u003ethe next article\u003c/a\u003e we will look at common reasons the test framework may be flaky, and how we can solve them at the root.\u003c/p\u003e\u003ch2 id=\"9786\"\u003eSeries Index\u003c/h2\u003e\u003cp id=\"18cd\"\u003eThis is a seven part article series on testing at Airbnb.\u003c/p\u003e\u003cp id=\"c733\"\u003ePart 1 — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-3f5b90b9c40a\"\u003eTesting Philosophy and a Mocking System\u003c/a\u003e\u003c/p\u003e\u003cp id=\"22e7\"\u003ePart 2 — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-a77ac9531cab\"\u003eScreenshot Testing with MvRx and Happo\u003c/a\u003e\u003c/p\u003e\u003cp id=\"bd08\"\u003ePart 3 — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-1d1e91e489b4\"\u003eAutomated Interaction Testing\u003c/a\u003e\u003c/p\u003e\u003cp id=\"f90f\"\u003ePart 4 — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-part-4-testing-viewmodels-550d929126c8\"\u003eA Framework for Unit Testing ViewModels\u003c/a\u003e\u003c/p\u003e\u003cp id=\"39ee\"\u003e\u003cstrong\u003ePart 5 (This article)\u003c/strong\u003e — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-661a554a8c8b\"\u003eArchitecture of our Automated Testing Framework\u003c/a\u003e\u003c/p\u003e\u003cp id=\"7128\"\u003ePart 6 — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-a11f6832773f\"\u003eObstacles to Consistent Mocking\u003c/a\u003e\u003c/p\u003e\u003cp id=\"461f\"\u003ePart 7 — \u003ca rel=\"noopener\" href=\"https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-eacec3a8a72f\"\u003eTest Generation and CI Configuration\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"1e01\"\u003eWe’re Hiring!\u003c/h2\u003e\u003cp id=\"e896\"\u003eWant to work with us on these and other Android projects at scale? Airbnb is hiring for several Android engineer positions across the company! See \u003ca href=\"https://careers.airbnb.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://careers.airbnb.com\u003c/a\u003e for current openings.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2019-12-23T16:37:09.099Z",
  "modifiedTime": null
}
