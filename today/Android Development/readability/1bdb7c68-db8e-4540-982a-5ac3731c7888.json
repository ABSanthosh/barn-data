{
  "id": "1bdb7c68-db8e-4540-982a-5ac3731c7888",
  "title": "Welcome to AI on Android Spotlight Week",
  "link": "http://android-developers.googleblog.com/2024/09/welcome-to-ai-on-android-spotlight-week.html",
  "description": "",
  "author": "Android Developers",
  "published": "2024-09-30T09:00:00.000-07:00",
  "source": "http://feeds.feedburner.com/blogspot/hsDu",
  "categories": [
    "#GenerativeAI",
    "AndroidAI",
    "Gemini"
  ],
  "byline": "",
  "length": 13531,
  "excerpt": "We're highlighting the core technologies driving AI experiences on Android, including on-device generative AI capabilities with Gemini Nano, and more.",
  "siteName": "Android Developers Blog",
  "favicon": "",
  "text": "Posted by Joseph Lewis – Technical Writer, Android AI AI on Android Spotlight Week this year runs September 30th to October 4th! As part of the Android “Spotlight Weeks” series, this week’s content and updates are your gateway to understanding how to integrate cutting-edge AI into your Android apps. Whether you're a seasoned Android developer, an AI enthusiast, or just starting out on your development journey, get ready for a week filled with insightful sessions, practical demos, and inspiring success stories that'll help you build intuitive and powerful AI integrations. Throughout the week, we'll dive into the core technologies driving AI experiences on Android. This blog will be updated throughout the week with links to new announcements and resources, so check back here daily for updates! Monday: Getting started with AI September 30, 2024Learn how to begin with AI on Android development. Understand which AI models and versions you can work with. Learn about developer tools to help you start building features empowered with AI. We'll guide you through the differences between traditional programming and machine learning, and contrast traditional machine learning with generative AI. The post explains large language models (LLMs), the transformer architecture, and key concepts like context windows and embeddings. It also touches on fine-tuning and the future of LLMs on Android. Read the blog post: A quick introduction to large language models for Android Developers A quick introduction to large language models for Android DevelopersExplore key concepts and understand the differences between traditional ML and generative AI; discover resources to integrate gen AI into your apps. We'll then provide a look behind the scenes at our work improving developer productivity with Gemini in Android Studio. We'll discuss Studio's new AI code completion feature, how we've been working to improve the accuracy and quality of suggested code, and how this feature can benefit your workflow. Read the blog post: Gemini in Android Studio: Code Completion gains powerful model improvements Generate useful prompts for app development in Android StudioThe Android Studio team has been experimenting with several enhancements to code completion, resulting in a 40% relative increase in acceptance rate. Tuesday: On-device AI capabilities with Gemini Nano October 1, 2024We're excited to offer developers experimental access to the latest version of Gemini Nano starting with the Pixel 9 series devices. Access to experiment with Gemini Nano gives you the ability to test on-device integrations with your apps. Note that experimental access is for development purposes, and is not for production usage at this time. Read the Gemini Nano experimental access blog post and developer guide. Gemini Nano is now available on Android via experimental accessGemini Nano with Multimodality, Google's on-device generative AI model offers privacy, offline functionality, integration guides, and more. As we bring powerful AI capabilities to your Android devices, we're equally committed to building privacy and safety into every interaction. Read our blog post for an intro into privacy and safety for Gemini Nano. It provides an introductory look into how Gemini Nano and AICore work together to deliver powerful on-device GenAI capabilities while prioritizing users’ privacy and safety. Read the blog post: An Introduction to Privacy and Safety for Gemini Nano An Introduction to Privacy and Safety for Gemini NanoGemini Nano and AICore work together to enable on-device generative AI while preserving user privacy and safety. Ready to dive into the technical side of things? This video walks you through the process of accessing and utilizing Gemini Nano's capabilities, and how you can use open models on Android-powered devices. Discover how to integrate this cutting-edge technology into your own applications and unlock the potential of on-device AI. Whether you're a seasoned developer or just starting your AI journey, this video provides valuable insights and practical knowledge. Watch the video: A Walkthrough for Android’s on-device GenAI solutions Wednesday: On-device AI with custom models October 2, 2024On Wednesday, we'll help you understand how to bring your own AI model to Android devices, and how you can integrate tools and technologies from Google and other sources. The ability to run sophisticated AI models directly on devices – whether it's a smartphone, tablet, or embedded system – opens up exciting possibilities for better performance, privacy, usability, and cost efficiency. Read the blog post: How to bring your own AI model to Android devices How to bring your own AI model to Android devicesBring your AI models to Android devices using Google's AI Edge platform, with tools and frameworks for building, deploying, and optimizing AI models. We'll also give you a detailed walkthrough of how Android developers can leverage Google AI Edge Torch to convert PyTorch machine learning models for on-device execution, using the LiteRT and MediaPipe Tasks libraries. This walkthrough includes code examples and explanations for converting a MobileViT model for image classification and a DIS model for segmentation, and highlights the steps involved in preparing these models for seamless integration into Android applications. By following this guide, developers can harness PyTorch models to enhance their Android apps with advanced machine learning capabilities. Read the blog post: PyTorch Machine Learning Models on Android PyTorch Machine Learning Models on AndroidUse Google AI Edge Torch to convert PyTorch models for use on Android devices. Convert a MobileViT model for image classification and add metadata. Thursday: Access cloud models with Android SDKs October 3, 2024Tap into the boundless potential of Gemini 1.5 Pro and Gemini 1.5 Flash, the revolutionary generative AI models that are redefining the capabilities of Android apps. With Gemini 1.5 Pro and 1.5 Flash, you'll have the tools you need to create apps that are truly intelligent and interactive. On Thursday, we'll give you a codelab that'll help you understand how to integrate the Gemini API capabilities into your Android projects. We'll guide you through crafting effective prompts and integrate Vertex AI in Firebase. By the end of this hands-on tutorial, you'll be able to implement features like text summarization in your own app all powered by the cutting-edge Gemini models. Try the codelab: Add Gemini capabilities to your Android app Add Gemini capabilities to your Android appLearn how to add a simple Gemini API feature to an Android app with Vertex AI for Firebase. We'll publish a blog post exploring the potential of the Gemini API with case studies. We'll delve into how Android developers are leveraging generative AI capabilities in innovative ways, showcasing real-world examples of apps that have successfully integrated the Gemini API. From meal planning to journaling and personalized user experiences, the article highlights examples of how Android developers are already taking advantage of Gemini transformative capabilities in their apps. Read the blog: Gemini API in Action: Showcase of Innovative Android apps Gemini API in action: showcase of innovative Android appsEnhance user experience in your app with features like meal planning, journaling, and username generation by leveraging the power of generative AI. We've recorded a podcast episode with Jomin George from the team behind Life, a journaling app that integrated the Gemini API. Jomin shared his experience building a chatbot with Vertex AI in Firebase. Listen to the podcast: Integrating Gemini API in Android or watch the video version. Android Build Time with Christopher CartlandWelcome to Android Build Time! Listen to this episode to learn more about how you can leverage Gemini API in your app. We'll also share with you examples of advanced features of the Gemini API to go beyond simple text prompting. You'll learn how system instructions can shape the model behavior, how JSON support streamlines development, and how multimodal capabilities and function calling can unlock exciting new use cases for your apps. Read the blog: Advanced capabilities of the Gemini API for Android developers Advanced capabilities of the Gemini API for Android developersDevelopers can leverage advanced features of the Gemini API, like JSON support and function calling, to build generative AI features into their apps. Friday: Build with AI on Android and beyond October 4, 2024As the capstone for AI on Android Spotlight Week, we'll host a discussion with Kateryna Semenova, Oli Gaymond, Miguel Ramos, and Khanh LeViet to talk about building with AI on Android. We'll explore the latest AI advancements tailored for Android engineers, showcasing how these technologies can elevate your app development game. Through engaging discussions and real-world examples, we will unveil the potential of AI, from fast, private on-device solutions using Gemini Nano to the powerful capabilities of Gemini 1.5 Flash and Pro. We'll discuss building generative AI solutions rapidly using Vertex AI in Firebase. And we'll dive into harnessing the power of AI with safety and privacy in mind. Watch the video: Build with AI on Android and beyond Work with Gemini beyond Android As we wrap things up for AI on Android Spotlight Week, know that we're striving to provide comprehensive AI solutions for cross-platform Gemini development. The AI capabilities showcased during Android AI Week can extend to other platforms, such as built-in AI in Chrome. Web developers can leverage similar tools and techniques to create web experiences enhanced by AI. Developers can run Gemini Pro in the cloud for natural language processing and other complex user journeys. Or, you explore the benefits of performing AI inferenceclient-side, with Gemini Nano in Chrome. Build with usability and privacy in mind As you embark on your AI development journey, we want you to keep in mind a few important considerations: Privacy: Prioritize user privacy and data security when implementing AI features, especially when handling sensitive user information. When it becomes available, opt for on-device AI solutions like Gemini Nano whenever possible to minimize data exposure. Seamless user experience: Ensure that AI features seamlessly integrate into your app's overall user experience. AI should enhance the user experience, not disrupt it. Ethical considerations: AI technologies are developed and deployed in a way that benefits society while minimizing potential harm. By considering fairness, transparency, privacy, accountability, and societal impact, developers can play a vital role in creating a future where AI serves humanity's best interests. Be mindful of the ethical implications of AI, such as potential biases in your AI models. Strive to create AI-powered features that are fair and inclusive. That's a wrap Android AI Spotlight Week 2024 is an opportunity to explore the latest in AI and its potential for Android app development. We encourage you to delve into the wealth of resources shared during the week and begin experimenting with AI in your own projects. The future of Android is rooted in AI and machine learning, and with the tools and knowledge shared during Android AI Week, developers are well-equipped to build the next generation of AI-powered apps. Next Steps If you are building generative AI features we would love to have a conversation with you! Complete this form to keep in touch. Follow Android Developers on X and Android Developers at LinkedIn, and remember to use the hashtag #AndroidAI to share your AI-powered Android creations, and join the vibrant community of developers pushing the boundaries of mobile AI.",
  "image": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgl2z6mznKp6_3BKARaqDZOCmOjW1nx0VvNJBbIdt2aR-qQCJe_jqSxGFOyMQs2Qr3HYFM2Uy_oF9FPyFhSSsyTUn5GOGHLgeuUvJLfGzwA4syrkL6j2Eaq54I9WC-VXlTSdXIEvyGHXw2s5pvAVhPGp_2iCGXV5uAkHrJrJMvQuSRoXsAcDH2eHKEWNDM/w1200-h630-p-k-no-nu/AIonAndroid_SpotlightWeek_1600x873.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\u003cmeta content=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgl2z6mznKp6_3BKARaqDZOCmOjW1nx0VvNJBbIdt2aR-qQCJe_jqSxGFOyMQs2Qr3HYFM2Uy_oF9FPyFhSSsyTUn5GOGHLgeuUvJLfGzwA4syrkL6j2Eaq54I9WC-VXlTSdXIEvyGHXw2s5pvAVhPGp_2iCGXV5uAkHrJrJMvQuSRoXsAcDH2eHKEWNDM/s1600/AIonAndroid_SpotlightWeek_1600x873.png\" name=\"twitter:image\"/\u003e\n\u003cp\u003e\n\n\u003cem\u003ePosted by Joseph Lewis – Technical Writer, Android AI\u003c/em\u003e\n\n\u003ca href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-Yj-KyVX8Uvzp5qoUSO26HqpHuVoJhlv1BUdOeAnJhY2MwhUTx7XX6ihGKqAa-dL0Fr3VnqrxLUdS3OMS8jkkNG_Ef1j1MyfFwmB7E__tBYgYKxTAmdoQqo-3zFucCriD9aL_F52yRcIOsNQ6BLc0yhhp11nBB5CDOwZNtIUIRK17dF457hRYxoT6dP8/s1600/AIonAndroid_SpotlightWeek_BlogHeader_4209x1253.png\"\u003e\u003cimg data-original-height=\"800\" data-original-width=\"100%\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-Yj-KyVX8Uvzp5qoUSO26HqpHuVoJhlv1BUdOeAnJhY2MwhUTx7XX6ihGKqAa-dL0Fr3VnqrxLUdS3OMS8jkkNG_Ef1j1MyfFwmB7E__tBYgYKxTAmdoQqo-3zFucCriD9aL_F52yRcIOsNQ6BLc0yhhp11nBB5CDOwZNtIUIRK17dF457hRYxoT6dP8/s1600/AIonAndroid_SpotlightWeek_BlogHeader_4209x1253.png\"/\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eAI on Android Spotlight Week this year runs September 30th to October 4th! As part of the Android “Spotlight Weeks” series, this week’s content and updates are your gateway to understanding how to integrate cutting-edge AI into your Android apps. Whether you\u0026#39;re a seasoned Android developer, an AI enthusiast, or just starting out on your development journey, get ready for a week filled with insightful sessions, practical demos, and inspiring success stories that\u0026#39;ll help you build intuitive and powerful AI integrations.\u003c/p\u003e\u003cbr/\u003e\n\n\u003ciframe height=\"398\" src=\"https://www.youtube.com/embed/0aX0mcw-eWI\" width=\"100%\" youtube-src-id=\"0aX0mcw-eWI\"\u003e\u003c/iframe\u003e\n\n\u003cp\u003eThroughout the week, we\u0026#39;ll dive into the core technologies driving AI experiences on Android. This blog will be updated throughout the week with links to new announcements and resources, so check back here daily for updates!\u003c/p\u003e\u003cbr/\u003e\n\n\u003ch4\u003e\u003cspan\u003e\u003cb\u003eMonday: Getting started with AI\u003c/b\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ci\u003eSeptember 30, 2024\u003c/i\u003e\u003c/p\u003e\u003cp\u003eLearn how to begin with AI on Android development. Understand which AI models and versions you can work with. Learn about developer tools to help you start building features empowered with AI.\u003c/p\u003e\n\n\u003cp\u003eWe\u0026#39;ll guide you through the differences between traditional programming and machine learning, and contrast traditional machine learning with generative AI. The post explains large language models (LLMs), the transformer architecture, and key concepts like context windows and embeddings. It also touches on fine-tuning and the future of LLMs on Android.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the blog post: \u003ca href=\"https://android-developers.googleblog.com/2024/09/introduction-to-large-language-models-for-android-developers.html\" target=\"_blank\"\u003eA quick introduction to large language models for Android Developers\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://android-developers.googleblog.com/2024/09/introduction-to-large-language-models-for-android-developers.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of a smartphone with a blank screen, set against a dark background. There is a blue speech bubble icon on the screen and a white speech bubble with ellipses above the phone. The design also incorporates blue and green lines and shapes.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWNLcken_pDkd2yzqcQX0QN7lGnMv-Pv1sAUMwFrkqFdA3HuVU-NshHGL87nn1eQtrFmEl_QWmUbAitr_NECTBafiTG5UVgkt26S2gdSLlaZw4bfAPFOmamZpx-uk73Lah66nnSPgD4GIZdI2baBMACEAhx2H82QwkJMLBsuIDM30yc49GgIkJLwmka7U/s1600/Large-Language-Models-Android-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eA quick introduction to large language models for Android Developers\u003c/b\u003eExplore key concepts and understand the differences between traditional ML and generative AI; discover resources to integrate gen AI into your apps.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\n\n\u003cp\u003eWe\u0026#39;ll then provide a look behind the scenes at our work improving developer productivity with Gemini in Android Studio. We\u0026#39;ll discuss Studio\u0026#39;s new AI code completion feature, how we\u0026#39;ve been working to improve the accuracy and quality of suggested code, and how this feature can benefit your workflow.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the blog post: \u003ca href=\"https://android-developers.googleblog.com/2024/09/gemini-android-studio-code-completion-model-improvements.html\" target=\"_blank\"\u003eGemini in Android Studio: Code Completion gains powerful model improvements\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://android-developers.googleblog.com/2024/09/gemini-android-studio-code-completion-model-improvements.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of a web browser window with the Android Studio logo in the bottom right corner. The background is dark with blue and green lines and shapes.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEikFIJcygIrGJJy0Mb-13Tn9-rk8d29RvMenYTGJj11JZVUr2nt0ZqC1xvElwyVuE_EL3JklDjn-b3muY58rCDXzM-NtSprpY3hAuvlHejDFepHbA39v2TijL-ZNcqqB9jm08Sn-rEZj2eg1Kl22IETuvqr6M9LdG02OMSxmDwCPJRCsWWtWRGUsSNxDjI/s1600/Android-Studio-Social%20%281%29.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eGenerate useful prompts for app development in Android Studio\u003c/b\u003eThe Android Studio team has been experimenting with several enhancements to code completion, resulting in a 40% relative increase in acceptance rate.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\u003cbr/\u003e\n\n\u003ch4\u003e\u003cspan\u003e\u003cb\u003eTuesday: On-device AI capabilities with Gemini Nano\u003c/b\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ci\u003eOctober 1, 2024\u003c/i\u003e\u003c/p\u003e\u003cp\u003eWe\u0026#39;re excited to offer \u003ca href=\"https://android-developers.googleblog.com/2024/10/gemini-nano-experimental-access-available-on-android.html\" target=\"_blank\"\u003edevelopers experimental access to the latest version of Gemini Nano\u003c/a\u003e starting with the Pixel 9 series devices. Access to experiment with Gemini Nano gives you the ability to test on-device integrations with your apps. Note that experimental access is for development purposes, and is not for production usage at this time.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the \u003ca href=\"https://android-developers.googleblog.com/2024/10/gemini-nano-experimental-access-available-on-android.html\" target=\"_blank\"\u003eGemini Nano experimental access blog post\u003c/a\u003e and \u003ca href=\"https://developer.android.com/ai/gemini-nano/experimental\" target=\"_blank\"\u003edeveloper guide\u003c/a\u003e.\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://android-developers.googleblog.com/2024/10/gemini-nano-experimental-access-available-on-android.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of the Android bot and a smartphone on a dark background with glowing blue and green lines and shapes.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTWRyvFxxrWXwsdZ6zk36pYHfUDHPmyik_VXXjNDpWHb2O-eiY3YKsjjHtboL8qNHY0mNousOjLZGNVOk0WfxpZlLXVMP1ZahBAgnfGZ0R7K5jN55a45QXY1BVfM00Pmi8Zgi6aMMpz1WPyWDEysMoW6Cqtl5h6q4danLO16GIoVFv4Upq96tfh-i57CI/s16000/Gemini-Nano-on-Android-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eGemini Nano is now available on Android via experimental access\u003c/b\u003eGemini Nano with Multimodality, Google\u0026#39;s on-device generative AI model offers privacy, offline functionality, integration guides, and more.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\n\u003cp\u003eAs we bring powerful AI capabilities to your Android devices, we\u0026#39;re equally committed to building privacy and safety into every interaction. Read our blog post for an intro into privacy and safety for Gemini Nano. It provides an introductory look into how Gemini Nano and AICore work together to deliver powerful on-device GenAI capabilities while prioritizing users’ privacy and safety.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the blog post: \u003ca href=\"https://android-developers.googleblog.com/2024/10/introduction-to-privacy-and-safety-gemini-nano.html\" target=\"_blank\"\u003eAn Introduction to Privacy and Safety for Gemini Nano\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://android-developers.googleblog.com/2024/10/introduction-to-privacy-and-safety-gemini-nano.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of a smartphone on a dark background with a shield icon and a graphic that looks like a molecule, along with green lines and shapes.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiimih6eDFrWJt-Nk3j34jTscTM8ww3rqgUc9tQp0_zHJsCu2zTl4yREFvczPa1XK0ON8FzghbSv20_DlzSD_C3svtiX9Sgh8WMap5nceKdakEYKCnJxnglyESlTBH_S0GJRaZGTFodUt-LNDwBj97ysyQNNdJjQmBVpNmo4wzqEt79_yiGZk06I3YbUXQ/s1600/OnDeviceTrust-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eAn Introduction to Privacy and Safety for Gemini Nano\u003c/b\u003eGemini Nano and AICore work together to enable on-device generative AI while preserving user privacy and safety.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\n\u003cp\u003eReady to dive into the technical side of things? This video walks you through the process of accessing and utilizing Gemini Nano\u0026#39;s capabilities, and how you can use open models on Android-powered devices. Discover how to integrate this cutting-edge technology into your own applications and unlock the potential of on-device AI. Whether you\u0026#39;re a seasoned developer or just starting your AI journey, this video provides valuable insights and practical knowledge.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eWatch the video: \u003ca href=\"https://youtu.be/EpKghZYqVW4\" target=\"_blank\"\u003eA Walkthrough for Android’s on-device GenAI solutions\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ciframe allowfullscreen=\"\" height=\"398\" src=\"https://www.youtube.com/embed/EpKghZYqVW4\" width=\"100%\" youtube-src-id=\"EpKghZYqVW4\"\u003e\u003c/iframe\u003e\u003cbr/\u003e\n\n\n\n\u003ch4\u003e\u003cspan\u003e\u003cb\u003eWednesday: On-device AI with custom models\u003c/b\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ci\u003eOctober 2, 2024\u003c/i\u003e\u003c/p\u003e\u003cp\u003eOn Wednesday, we\u0026#39;ll help you understand how to bring your own AI model to Android devices, and how you can integrate tools and technologies from Google and other sources. The ability to run sophisticated AI models directly on devices – whether it\u0026#39;s a smartphone, tablet, or embedded system – opens up exciting possibilities for better performance, privacy, usability, and cost efficiency.\n\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the blog post: \u003ca href=\"https://android-developers.googleblog.com/2024/10/bring-your-ai-model-to-android-devices.html\" target=\"_blank\"\u003eHow to bring your own AI model to Android devices\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\" https://android-developers.googleblog.com/2024/10/bring-your-ai-model-to-android-devices.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of the metallic Android bot standing to the left of the MediaPipe and LiteRT logos.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNs9EPwnkUin85xb7EVpVKQXG3_fHTxSLFwUMiBpnfqZsdZQw-bOG6bv_ZHy9f3cRItTMRLnS_viRQXDRi2FPECNRdmSg01hHUFK-Q6WA64bx5YtBf6q1UDX1qALig8YIPmw2D6fY3oMltfqTjtPl7Qu7wtuMrLnDbfM5e8OmBa3q4R_uOmvY892SHQx8/s1600/AI-on-Android-MediaPipe-LiteRT-Social%20%281%29.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eHow to bring your own AI model to Android devices\u003c/b\u003eBring your AI models to Android devices using Google\u0026#39;s AI Edge platform, with tools and frameworks for building, deploying, and optimizing AI models.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\n\n\u003cp\u003eWe\u0026#39;ll also give you a detailed walkthrough of how Android developers can leverage Google AI Edge Torch to convert PyTorch machine learning models for on-device execution, using the LiteRT and MediaPipe Tasks libraries. This walkthrough includes code examples and explanations for converting a MobileViT model for image classification and a DIS model for segmentation, and highlights the steps involved in preparing these models for seamless integration into Android applications. By following this guide, developers can harness PyTorch models to enhance their Android apps with advanced machine learning capabilities.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the blog post: \u003ca href=\"https://android-developers.googleblog.com/2024/10/pytorch-machine-learning-models-on-android.html\" target=\"_blank\"\u003ePyTorch Machine Learning Models on Android\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\" https://android-developers.googleblog.com/2024/10/pytorch-machine-learning-models-on-android.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of the Android bot, with a colorful, iridescent finish, standing to the right. The Google AI Edge logo is in the center, with a chat bubble on the left\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZjxrgmFgqtFucZ9AOr-KC-kNPi_JJoZVAOHolxpuJkhA3wzmxmxV8wi-bkxEzlggzJ8Wjk_oPl40ljl5BD3-EqIT2iQUlXRnIWGI-rlX65bPE6p9HHm1LAp4ovJ05F_OzBhPyiqpOL0BN1QLEQg-SnY5Aie3phGU76QXEjEs5_KuaaKTA6vcEUbUQdnM/s1600/AI-on-Android-Google-AI-Edge-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003ePyTorch Machine Learning Models on Android\u003c/b\u003eUse Google AI Edge Torch to convert PyTorch models for use on Android devices. Convert a MobileViT model for image classification and add metadata.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\u003ch4\u003e\u003cspan\u003e\u003cb\u003eThursday: Access cloud models with Android SDKs\u003c/b\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ci\u003eOctober 3, 2024\u003c/i\u003e\u003c/p\u003e\u003cp\u003eTap into the boundless potential of Gemini 1.5 Pro and Gemini 1.5 Flash, the revolutionary generative AI models that are redefining the capabilities of Android apps. With Gemini 1.5 Pro and 1.5 Flash, you\u0026#39;ll have the tools you need to create apps that are truly intelligent and interactive.\u003c/p\u003e\n\n\u003cp\u003eOn Thursday, we\u0026#39;ll give you a codelab that\u0026#39;ll help you understand how to integrate the Gemini API capabilities into your Android projects. We\u0026#39;ll guide you through crafting effective prompts and integrate Vertex AI in Firebase. By the end of this hands-on tutorial, you\u0026#39;ll be able to implement features like text summarization in your own app all powered by the cutting-edge Gemini models.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eTry the codelab: \u003ca href=\"https://developer.android.com/codelabs/gemini-summarize#0\" target=\"_blank\"\u003eAdd Gemini capabilities to your Android app\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\" https://developer.android.com/codelabs/gemini-summarize#0\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"Three side by side screenshots show the Jetnews application on device, including the home screen, a screen listing articles related to Android development, and an article view.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1_QRbh_Wa5oNxlIxOIh8m6UjsVVe_hwC6vy4dPf4KNZGNQOILGWTGbE-0M1sQkQ_Uh-808L7WwEurteyQ2OkTdneX5OvzQQnvX1NUSBSHb7HMkvwCcnMU-mLhvrtu0BHR23G-NCYXHJ0lJQi4-eI1X7oxcMAcNYlpezFSJ736OzVUgt5dkh7HPttc42E/s1600/Compose-Samples-Jetnews.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eAdd Gemini capabilities to your Android app\u003c/b\u003eLearn how to add a simple Gemini API feature to an Android app with Vertex AI for Firebase.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\u003cp\u003eWe\u0026#39;ll publish a blog post exploring the potential of the Gemini API with case studies. We\u0026#39;ll delve into how Android developers are leveraging generative AI capabilities in innovative ways, showcasing real-world examples of apps that have successfully integrated the Gemini API. From meal planning to journaling and personalized user experiences, the article highlights examples of how Android developers are already taking advantage of Gemini transformative capabilities in their apps. \u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eRead the blog: \u003ca href=\"https://android-developers.googleblog.com/2024/10/gemini-api-showcase-of-innovative-android-apps.html\" target=\"_blank\"\u003eGemini API in Action: Showcase of Innovative Android apps\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://android-developers.googleblog.com/2024/10/gemini-api-showcase-of-innovative-android-apps.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of a smartphone with a blank screen, set against a dark background. There is a blue speech bubble icon on the screen and a white speech bubble with ellipses above the phone. The design also incorporates blue and green lines and shapes.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWNLcken_pDkd2yzqcQX0QN7lGnMv-Pv1sAUMwFrkqFdA3HuVU-NshHGL87nn1eQtrFmEl_QWmUbAitr_NECTBafiTG5UVgkt26S2gdSLlaZw4bfAPFOmamZpx-uk73Lah66nnSPgD4GIZdI2baBMACEAhx2H82QwkJMLBsuIDM30yc49GgIkJLwmka7U/s1600/Large-Language-Models-Android-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eGemini API in action: showcase of innovative Android apps\u003c/b\u003eEnhance user experience in your app with features like meal planning, journaling, and username generation by leveraging the power of generative AI.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\u003cp\u003eWe\u0026#39;ve recorded a podcast episode with Jomin George from the team behind Life, a journaling app that integrated the Gemini API. Jomin shared his experience building a chatbot with Vertex AI in Firebase.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eListen to the podcast: \u003ca href=\"https://androidbuildtime.libsyn.com/integrating-the-gemini-api-in-android\" target=\"_blank\"\u003eIntegrating Gemini API in Android\u003c/a\u003e or \u003ca href=\"https://www.youtube.com/watch?v=DDN2pJ0SzNw\" target=\"_blank\"\u003ewatch the video version\u003c/a\u003e.\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://androidbuildtime.libsyn.com/integrating-the-gemini-api-in-android\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of  The Android bot, wearing black headphones, peeks over the top of text that reads \u0026#39;Android Build Time\u0026#39;.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPpAuQo2ZDRti5RfDZ5HUgCA42c8pccprGisP9misBfRPx_yrbkIdtbbWw-fwcwDZaLXLclj3tgO8p16xOBZVlaKoDV5IWhrQJ6M_uHO-h4gX51AXOF5EyStAPsJSyYqZ4CGEii7f58J7tW0rto6_txRhX0SwS3vzCjiGiwtk2aZNQ5B8Qi6W8DnixejU/s1600/Android-Build-Time-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eAndroid Build Time with Christopher Cartland\u003c/b\u003eWelcome to Android Build Time! Listen to this episode to learn more about how you can leverage Gemini API in your app. \u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\u003cbr/\u003e\n\n\u003ciframe allowfullscreen=\"\" height=\"398\" src=\"https://www.youtube.com/embed/DDN2pJ0SzNw\" width=\"100%\" youtube-src-id=\"DDN2pJ0SzNw\"\u003e\u003c/iframe\u003e\n\n\n\u003cp\u003eWe\u0026#39;ll also share with you examples of  advanced features of the Gemini API to go beyond simple text prompting. You\u0026#39;ll learn how system instructions can shape the model behavior, how JSON support streamlines development, and how multimodal capabilities and function calling can unlock exciting new use cases for your apps.\u003c/p\u003e \n\n\u003cp\u003e\u003cb\u003eRead the blog: \u003ca href=\"https://android-developers.googleblog.com/2024/10/advanced-capabilities-of-gemini-api-for-android-developers.html\" target=\"_blank\"\u003eAdvanced capabilities of the Gemini API for Android developers\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n\n\u003ca href=\"https://android-developers.googleblog.com/2024/10/advanced-capabilities-of-gemini-api-for-android-developers.html\" target=\"_blank\"\u003e\u003cdiv\u003e\n    \u003ctable\u003e\n        \u003ctbody\u003e\n            \u003ctr\u003e\n                \u003ctd\u003e\u003cbr/\u003e\n                \u003cimg alt=\"An illustration of a smartphone with a blank screen, set against a dark background. There is a blue speech bubble icon on the screen and a white speech bubble with ellipses above the phone. The design also incorporates blue and green lines and shapes.\" id=\"imgCaption\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiWNLcken_pDkd2yzqcQX0QN7lGnMv-Pv1sAUMwFrkqFdA3HuVU-NshHGL87nn1eQtrFmEl_QWmUbAitr_NECTBafiTG5UVgkt26S2gdSLlaZw4bfAPFOmamZpx-uk73Lah66nnSPgD4GIZdI2baBMACEAhx2H82QwkJMLBsuIDM30yc49GgIkJLwmka7U/s1600/Large-Language-Models-Android-Social.png\"/\u003e\n              \u003c/td\u003e\n                \u003ctd\u003e\n                  \u003cp\u003e\u003cspan face=\"Arial,sans-serif\"\u003e\u003cb\u003eAdvanced capabilities of the Gemini API for Android developers\u003c/b\u003eDevelopers can leverage advanced features of the Gemini API, like JSON support and function calling, to build generative AI features into their apps.\u003c/span\u003e\u003c/p\u003e\n                  \u003c/td\u003e\n              \u003c/tr\u003e\n        \u003c/tbody\u003e\n    \u003c/table\u003e\n  \u003c/div\u003e\u003c/a\u003e\n\u003cbr/\u003e\n  \n\u003ch4\u003e\u003cspan\u003e\u003cb\u003eFriday: Build with AI on Android and beyond\u003c/b\u003e\u003c/span\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ci\u003eOctober 4, 2024\u003c/i\u003e\u003c/p\u003e\u003cp\u003eAs the capstone for AI on Android Spotlight Week, we\u0026#39;ll host a discussion with \u003ca href=\"https://x.com/SKateryna\" target=\"_blank\"\u003eKateryna Semenova\u003c/a\u003e, \u003ca href=\"https://x.com/ogaymond\" target=\"_blank\"\u003eOli Gaymond\u003c/a\u003e, \u003ca href=\"https://x.com/MiguelRamosPM\" target=\"_blank\"\u003eMiguel Ramos\u003c/a\u003e, and \u003ca href=\"https://x.com/khanhlvg\" target=\"_blank\"\u003eKhanh LeViet\u003c/a\u003e to talk about building with AI on Android. We\u0026#39;ll explore the latest AI advancements tailored for Android engineers, showcasing how these technologies can elevate your app development game. Through engaging discussions and real-world examples, we will unveil the potential of AI, from fast, private on-device solutions using Gemini Nano to the powerful capabilities of Gemini 1.5 Flash and Pro. We\u0026#39;ll discuss building generative AI solutions rapidly using Vertex AI in Firebase. And we\u0026#39;ll dive into harnessing the power of AI with safety and privacy in mind.\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eWatch the video: \u003ca href=\"https://youtu.be/o1wY5vnNVCc?si=FQbKfGdJdbTwnjJP\" target=\"_blank\"\u003eBuild with AI on Android and beyond\u003c/a\u003e\u003c/b\u003e\u003c/p\u003e\n  \n\u003ciframe allowfullscreen=\"\" height=\"398\" src=\"https://www.youtube.com/embed/o1wY5vnNVCc\" width=\"100%\" youtube-src-id=\"o1wY5vnNVCc\"\u003e\u003c/iframe\u003e\u003cbr/\u003e\n\n  \n\n\u003ch3\u003eWork with Gemini beyond Android\u003c/h3\u003e\n\n\u003cp\u003eAs we wrap things up for AI on Android Spotlight Week, know that we\u0026#39;re striving to provide comprehensive AI solutions for cross-platform Gemini development. The AI capabilities showcased during Android AI Week can extend to other platforms, such as \u003ca href=\"https://developer.chrome.com/docs/ai/built-in\" target=\"_blank\"\u003ebuilt-in AI in Chrome\u003c/a\u003e. Web developers can leverage similar tools and techniques to create web experiences enhanced by AI. Developers can run Gemini Pro in the cloud for natural language processing and other complex user journeys. Or, you explore the benefits of \u003ca href=\"https://developer.chrome.com/docs/ai/client-side\" target=\"_blank\"\u003eperforming AI inferenceclient-side\u003c/a\u003e, with Gemini Nano in Chrome.\u003c/p\u003e\n\n\u003ch4\u003e\u003cspan\u003e\u003cb\u003eBuild with usability and privacy in mind\u003c/b\u003e\u003c/span\u003e\u003c/h4\u003e\n\n\u003cp\u003eAs you embark on your AI development journey, we want you to keep in mind a few important considerations:\u003c/p\u003e\n\n\u003cul\u003e\u003cul\u003e\n\u003cli\u003e\u003cb\u003ePrivacy:\u003c/b\u003e Prioritize user privacy and data security when implementing AI features, especially when handling sensitive user information. When it becomes available, opt for on-device AI solutions like Gemini Nano whenever possible to minimize data exposure.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n  \n\u003cli\u003e\u003cb\u003eSeamless user experience:\u003c/b\u003e Ensure that AI features seamlessly integrate into your app\u0026#39;s overall user experience. AI should enhance the user experience, not disrupt it.\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\n  \n\u003cli\u003e\u003cb\u003eEthical considerations:\u003c/b\u003e AI technologies are developed and deployed in a way that benefits society while minimizing potential harm. By considering fairness, transparency, privacy, accountability, and societal impact, developers can play a vital role in creating a future where AI serves humanity\u0026#39;s best interests. Be mindful of the ethical implications of AI, such as potential biases in your AI models. Strive to create AI-powered features that are fair and inclusive.\u003c/li\u003e\n\u003c/ul\u003e\u003c/ul\u003e\n\n\n\n\u003ch3\u003eThat\u0026#39;s a wrap\u003c/h3\u003e\n\n\u003cp\u003eAndroid AI Spotlight Week 2024 is an opportunity to explore the latest in AI and its potential for Android app development. We encourage you to delve into the wealth of resources shared during the week and begin experimenting with AI in your own projects. The future of Android is rooted in AI and machine learning, and with the tools and knowledge shared during Android AI Week, developers are well-equipped to build the next generation of AI-powered apps.\u003c/p\u003e\u003cbr/\u003e\n\n\u003ch3\u003eNext Steps\u003c/h3\u003e\n\n\u003cp\u003eIf you are building generative AI features we would love to have a conversation with you! \u003ca href=\"https://docs.google.com/forms/d/e/1FAIpQLScE3qCIyJm6FanJP-dDKYutt1nAwmneK-viBrRh5v5UdtXGjw/viewform\" target=\"_blank\"\u003eComplete this form\u003c/a\u003e to keep in touch.\u003c/p\u003e\n\n\u003cp\u003eFollow \u003ca href=\"https://x.com/Android\" target=\"_blank\"\u003eAndroid Developers on X\u003c/a\u003e and \u003ca href=\"https://www.linkedin.com/showcase/androiddev/\" target=\"_blank\"\u003eAndroid Developers at LinkedIn\u003c/a\u003e, and remember to use the hashtag \u003cb\u003e#AndroidAI\u003c/b\u003e to share your AI-powered Android creations, and join the vibrant community of developers pushing the boundaries of mobile AI.\u003c/p\u003e\n\n\n\n\n\n\n  \n\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "15 min read",
  "publishedTime": null,
  "modifiedTime": null
}
