{
  "id": "db735e0c-3908-49a1-a5da-38f63fbe8ffd",
  "title": "The Present Should Be Signed",
  "link": "https://fabisevi.ch/2023/08/09/the-present-should-be-signed/",
  "description": "When I wrote The Future Will Be Signed almost six years ago the latest in AI advancements was Google Duplex. If you're like me and have never used Google Duplex, it's a feature of Google Assistant that could make calls on behalf of a person and automatically perform a task, such as booking restaurant tables. While you may have never heard of Google Duplex there's a good chance you've used a generative AI tool like ChatGPT, Midjourney, or GitHub Copilot. Authenticity Weâ€™re going to need a way to prove the authenticity of a piece of digital content, everywhere, in a simple manner. This is where public key cryptography comes in. Our current solutions are noble efforts, but remain too complex. It's quite an understatement to say that AI has come a long way since 2018, and yet the blog post's core thesis is even stronger today than when it was written. At the time I was concerned about a future where deepfakes, audio manipulation, and text generation spread across the internet. We're now living in the beginning of that future, this is our present. It has never been faster or easier to generate inorganic content, the tools to do so are more usable and accessible than ever. AI already has us questioning what we see on the internet, and the problem isn't going away. Fake news articles are being written by ChatGPT, fake books are being written with ChatGPT, and of course fake reviews made up by ChatGPT are being used to sell all of this.",
  "author": "Joe Fabisevich",
  "published": "Wed, 09 Aug 2023 00:00:00 GMT",
  "source": "https://www.fabisevi.ch/feed.xml",
  "categories": null,
  "byline": "",
  "length": 5929,
  "excerpt": "When I wrote The Future Will Be Signed almost six years ago the latest in AI advancements was Google Duplex. If you're like me and have never used Google Duplex, it's a feature of Google Assistant that could make calls on behalf of a person and automatically perform a task, such as booking restaurant tables. While you may have never heard of Google Duplex there's a good chance you've used a generative AI tool like ChatGPT, Midjourney, or GitHub Copilot. Authenticity Weâ€™re going to need a way to prove the authenticity of a piece of digital content, everywhere, in a simple manner. This is where public key cryptography comes in. Our current solutions are noble efforts, but remain too complex. It's quite an understatement to say that AI has come a long way since 2018, and yet the blog post's core thesis is even stronger today than when it was written. At the time I was concerned about a future where deepfakes, audio manipulation, and text generation spread across the internet. We're now living in the beginning of that future, this is our present. It has never been faster or easier to generate inorganic content, the tools to do so are more usable and accessible than ever. AI already has us questioning what we see on the internet, and the problem isn't going away. Fake news articles are being written by ChatGPT, fake books are being written with ChatGPT, and of course fake reviews made up by ChatGPT are being used to sell all of this.",
  "siteName": "",
  "favicon": "https://fabisevi.ch/icons/icon-512x512.png?v=b60b950dc439294a707fb76cdaca4274",
  "text": "When I wrote The Future Will Be Signed almost six years ago the latest in AI advancements was Google Duplex. If you're like me and have never used Google Duplex, it's a feature of Google Assistant that could make calls on behalf of a person and automatically perform a task, such as booking restaurant tables. While you may have never heard of Google Duplex there's a good chance you've used a generative AI tool like ChatGPT, Midjourney, or GitHub Copilot. Authenticity Weâ€™re going to need a way to prove the authenticity of a piece of digital content, everywhere, in a simple manner. This is where public key cryptography comes in. Our current solutions are noble efforts, but remain too complex. It's quite an understatement to say that AI has come a long way since 2018, and yet the blog post's core thesis is even stronger today than when it was written. At the time I was concerned about a future where deepfakes, audio manipulation, and text generation spread across the internet. We're now living in the beginning of that future, this is our present. It has never been faster or easier to generate inorganic content, the tools to do so are more usable and accessible than ever. AI already has us questioning what we see on the internet, and the problem isn't going away. Fake news articles are being written by ChatGPT, fake books are being written with ChatGPT, and of course fake reviews made up by ChatGPT are being used to sell all of this. Trust This infrastructure is going to have to be baked directly into the software that developers build, in a way that is transparent to the end user. A politician (or anyone) needs to be able to sign a tweet, audio recording, or video clip to prove authenticity of what they are saying. With the creation and fabrication of content being so easy, weâ€™re going to need a model where the person creating the content can prove it is trustworthy, and otherwise it should be treated as inauthentic. When I worked on Twitter's Societal Health team I spent a lot of time thinking about misinformation, disinformation, abuse, harassment, and civic integrity. These issues often took the form of coordinated inauthentic behavior by large groups of people trying to manipulate people and the public conversation. The scale of the problem seemed enormous, now it's larger than ever, and only getting bigger. We still need tools to help us differentiate authentic and inauthentic behavior or content, but there haven't been many meaningful efforts to build authenticity into the products people use. Arguably the largest advancements have come from a technology I personally have few positive feelings about, cryptocurrencies. When you believe everyone is an adversary then you need to build systems for trust. Bitcoin, Ethereum, and other crypto projects have shown that you can build a system based on public key cryptography that ensures a sense of truth. You may not like what that truth is, and it's easy to do so because of all the \"Web3\" that have been hilariously misused and abused in a seemingly unending amount of ways. I'm not pinning my hopes to the blockchain solving our trust problem, but I appreciate that much better user experience paradigms for trustless systems have emerged over the last five years because they were necessary for crypto to succeed. Scale In some ways the problems are actually worse than ever. Anyone can buy verification on X Twitter and impersonate their favorite brand. People have grown hostile and are treating platforms as adversaries because platforms no longer care about the people using their product. Platforms are even stealing usernames from active users, how can anyone trust what they read online when they donâ€™t know whoâ€™s writing it? Platforms are treating their users as adversaries as well. If you get locked out of your Google account you might as well consider your digital life gone. A company like Google doesn't and can't scale support to the level of personal help we've historically been accustomed to in common society. Protecting user safety means support agents must assume that someone writing them for help is a scammer, fraudster, or hacker trying to break into someone else's account. The incentive structures for helping people are all backwards because the risk of Google turning over someone's Gmail account to the wrong person far outweighs the positives of helping thousands of people. This may only affect 1/100,000 people, but when you're that 1 person, losing your entire digital identity is horribly destructive experience. People need a sense of trust, some shared truth, and we're still in search of that online. As more of our lives happen on an inherently untrustworthy internet the status quo becomes more and more untenable, something has to give. Things will either get better or they will get worse, and based our approach of trying nothing and being all out of ideas, they are likely to get worse. The guardrails are coming off the system, if we wait too long then trust in our systems online and offline may fully erode. It's discouraging that we can't figure out a way to solve the problems we have today, but an even bigger repudiation of the status quo is that we don't even talk about this large systemic risk, and probably won't until it's too late.Joe Fabisevich is an indie developer creating software at Red Panda Club Inc. while writing about design, development, and building a company. Formerly an iOS developer working on societal issues @Twitter. These days I don't tweet, but I do post on Threads.Like my writing? You can keep up with it in your favorite RSS reader, or get posts emailed in newsletter form. I promise to never spam you or send you anything other than my posts, it's just a way for you to read my writing wherever's most comfortable for you.If you'd like to know more, wanna talk, or need some advice, feel free to sign up for office hours, I'm very friendly. ðŸ™‚",
  "image": "https://fabisevi.ch/static/pic-f5999ef8dd476bfbf9d65ddbace7e387.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003eWhen I wrote \u003ca href=\"https://fabisevi.ch/2018/01/16/the-future-will-be-signed/\"\u003eThe Future Will Be Signed\u003c/a\u003e almost six years ago the latest in AI advancements was Google Duplex. If you\u0026#39;re like me and have never used Google Duplex, it\u0026#39;s a feature of Google Assistant that could make calls on behalf of a person and automatically perform a task, such as booking restaurant tables. While you may have never heard of Google Duplex there\u0026#39;s a good chance you\u0026#39;ve used a generative AI tool like ChatGPT, Midjourney, or GitHub Copilot.\u003c/p\u003e\n\u003ch3 id=\"authenticity\"\u003e\u003ca href=\"#authenticity\" aria-label=\"authenticity permalink\"\u003e\u003c/a\u003eAuthenticity\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWeâ€™re going to need a way to prove the authenticity of a piece of digital content, everywhere, in a simple manner. This is where public key cryptography comes in. Our current solutions are noble efforts, but remain too complex.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIt\u0026#39;s quite an understatement to say that AI has come a long way since 2018, and yet the blog post\u0026#39;s core thesis is even stronger today than when it was written. At the time I was concerned about a future where deepfakes, audio manipulation, and text generation spread across the internet. We\u0026#39;re now living in the beginning of that future, this is our present. It has never been faster or easier to generate inorganic content, the tools to do so are more usable and accessible than ever.\u003c/p\u003e\n\u003cp\u003eAI already has us questioning what we see on the internet, and the problem isn\u0026#39;t going away. Fake news articles are \u003ca href=\"https://www.theguardian.com/commentisfree/2023/apr/06/ai-chatgpt-guardian-technology-risks-fake-article\"\u003ebeing written by ChatGPT\u003c/a\u003e, fake books are being \u003ca href=\"https://www.nytimes.com/2023/08/05/travel/amazon-guidebooks-artificial-intelligence.html\"\u003ewritten with ChatGPT\u003c/a\u003e, and of course \u003ca href=\"https://www.spiceworks.com/tech/artificial-intelligence/guest-article/how-chatgpt-could-spread-disinformation-via-fake-reviews/\"\u003efake reviews made up by ChatGPT\u003c/a\u003e are being used to sell all of this.\u003c/p\u003e\n\n\u003ch3 id=\"trust\"\u003e\u003ca href=\"#trust\" aria-label=\"trust permalink\"\u003e\u003c/a\u003eTrust\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThis infrastructure is going to have to be baked directly into the software that developers build, in a way that is transparent to the end user. A politician (or anyone) needs to be able to sign a tweet, audio recording, or video clip to prove authenticity of what they are saying. With the creation and fabrication of content being so easy, weâ€™re going to need a model where the person creating the content can prove it is trustworthy, and otherwise it should be treated as inauthentic.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWhen I worked on Twitter\u0026#39;s Societal Health team I spent a lot of time thinking about misinformation, disinformation, abuse, harassment, and civic integrity. These issues often took the form of coordinated inauthentic behavior by large groups of people trying to manipulate people and the public conversation. The scale of the problem seemed enormous, now it\u0026#39;s larger than ever, and only getting bigger. We still need tools to help us differentiate authentic and inauthentic behavior or content, but there haven\u0026#39;t been many meaningful efforts to build authenticity into the products people use.\u003c/p\u003e\n\u003cp\u003eArguably the largest advancements have come from a technology I personally have few positive feelings about, cryptocurrencies. When you believe everyone is an adversary then you need to build \u003cem\u003esystems\u003c/em\u003e for trust. Bitcoin, Ethereum, and other crypto projects have shown that you can build a system based on public key cryptography that ensures a sense of truth. You may not like what that truth is, and it\u0026#39;s easy to do so because of all the \u0026#34;Web3\u0026#34; that have been \u003ca href=\"https://web3isgoinggreat.com/\"\u003ehilariously misused and abused\u003c/a\u003e in a seemingly unending amount of ways. I\u0026#39;m not pinning my hopes to the blockchain solving our trust problem, but I appreciate that much better user experience paradigms for trustless systems have emerged over the last five years because they were necessary for crypto to succeed.\u003c/p\u003e\n\u003ch3 id=\"scale\"\u003e\u003ca href=\"#scale\" aria-label=\"scale permalink\"\u003e\u003c/a\u003eScale\u003c/h3\u003e\n\u003cp\u003eIn some ways the problems are actually worse than ever. Anyone can buy verification on \u003cdel\u003eX\u003c/del\u003e Twitter and \u003ca href=\"https://www.nytimes.com/2022/11/11/technology/twitter-blue-fake-accounts.html\"\u003eimpersonate their favorite brand\u003c/a\u003e. People have grown hostile and are treating platforms as adversaries because platforms \u003ca href=\"https://www.wired.com/story/the-reddit-blackout-is-breaking-reddit\"\u003eno longer care about the people using their product\u003c/a\u003e. Platforms are even \u003ca href=\"https://www.npr.org/2023/07/29/1190891082/twitter-x-account-owner-gene-hwang-elon-musk\"\u003estealing usernames\u003c/a\u003e \u003ca href=\"https://www.rollingstone.com/culture/culture-news/twitter-seizes-music-handle-1234801321/\"\u003efrom active users\u003c/a\u003e, how can anyone trust what they read online when they donâ€™t know whoâ€™s writing it?\u003c/p\u003e\n\u003cp\u003ePlatforms are \u003ca href=\"https://janefriedman.com/i-would-rather-see-my-books-pirated\"\u003etreating their users as adversaries\u003c/a\u003e as well. If you get locked out of your Google account you might as well consider your digital life gone. A company like Google doesn\u0026#39;t and can\u0026#39;t scale support to the level of personal help we\u0026#39;ve historically been accustomed to in common society. Protecting user safety means support agents must assume that someone writing them for help is a scammer, fraudster, or hacker trying to break into someone else\u0026#39;s account. The incentive structures for helping people are all backwards because the risk of Google turning over someone\u0026#39;s Gmail account to the wrong person far outweighs the positives of helping thousands of people. This may only affect 1/100,000 people, but when you\u0026#39;re that 1 person, losing your entire digital identity is horribly destructive experience.\u003c/p\u003e\n\u003cp\u003ePeople need a sense of trust, some shared truth, and we\u0026#39;re still in search of that online. As more of our lives happen on an inherently untrustworthy internet the status quo becomes more and more untenable, something has to give. Things will either get better or they will get worse, and based our approach of \u003ca href=\"https://www.youtube.com/watch?v=lHkWea5ppxE\"\u003etrying nothing and being all out of ideas\u003c/a\u003e, they are likely to get worse. The guardrails are coming off the system, if we wait too long then trust in our systems online and offline may fully erode.\u003c/p\u003e\n\u003cp\u003eIt\u0026#39;s discouraging that we can\u0026#39;t figure out a way to solve the problems we have today, but an even bigger repudiation of the status quo is that we don\u0026#39;t even talk about this large systemic risk, and probably won\u0026#39;t until it\u0026#39;s too late.\u003c/p\u003e\u003c/div\u003e\u003cp\u003eJoe Fabisevich is an indie developer creating software at \u003ca href=\"https://redpanda.club\"\u003eRed Panda Club Inc.\u003c/a\u003e while writing about design, development, and building a company. Formerly an iOS developer working on societal issues \u003ca href=\"https://threads.net/mergesort\"\u003e@Twitter\u003c/a\u003e. These days I don\u0026#39;t tweet, but I do post on \u003ca href=\"https://threads.net/mergesort\"\u003eThreads\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eLike my writing? You can keep up with it in your favorite \u003ca href=\"https://fabisevi.ch/feed.xml\"\u003eRSS\u003c/a\u003e reader, or get posts \u003ca href=\"https://mailchi.mp/3237be1819ae/fabisevich-blog-posts\"\u003eemailed\u003c/a\u003e in newsletter form. I promise to never spam you or send you anything other than my posts, it\u0026#39;s just a way for you to read my writing wherever\u0026#39;s most comfortable for you.\u003c/p\u003e\u003cp\u003eIf you\u0026#39;d like to know more, wanna talk, or need some advice, feel free to sign up for \u003ca href=\"https://cal.com/mergesort/office-hours\"\u003eoffice hours\u003c/a\u003e, I\u0026#39;m very friendly. ðŸ™‚\u003c/p\u003e\u003c/div\u003e\u003c/article\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": null,
  "modifiedTime": null
}
