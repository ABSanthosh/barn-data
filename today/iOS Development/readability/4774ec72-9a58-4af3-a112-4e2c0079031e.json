{
  "id": "4774ec72-9a58-4af3-a112-4e2c0079031e",
  "title": "Interactive Presentation Slides at 360iDev",
  "link": "https://atomicbird.com/blog/interactive-presentation-slides-at-360idev/",
  "description": "This is a story of how a trip to a karaoke bar led to me writing my own app to display presentation slides. Of how a user interface that allows live smartass comments led to me being completely nerd sniped until I was able to do something I’ve never seen in a conference session– however silly the result was. In the end audience members could send Emoji and other images directly to the slides during the session, which ended up looking like this.",
  "author": "",
  "published": "Tue, 28 Jan 2020 00:00:00 +0000",
  "source": "https://atomicbird.com/index.xml",
  "categories": null,
  "byline": "",
  "length": 9044,
  "excerpt": "This is a story of how a trip to a karaoke bar led to me writing my own app to display presentation slides. Of how a user interface that allows live smartass comments led to me being completely nerd sniped until I was able to do something I’ve never seen in a conference session– however silly the result was. In the end audience members could send Emoji and other images directly to the slides during the session, which ended up looking like this.",
  "siteName": "Title",
  "favicon": "https://atomicbird.com/apple-touch-icon-144-precomposed.png",
  "text": "This is a story of how a trip to a karaoke bar led to me writing my own app to display presentation slides. Of how a user interface that allows live smartass comments led to me being completely nerd sniped until I was able to do something I’ve never seen in a conference session– however silly the result was. In the end audience members could send Emoji and other images directly to the slides during the session, which ended up looking like this. The Innocent Beginning: 360iDev 2018 At 360iDev a few years ago, Jean MacDonald suggested an unofficial group outing. How about a group of us have a karaoke night? VoiceBox Karaoke wasn’t far from the conference, and they had private karaoke rooms. It’d be just the 360iDev group in their own room. I found the idea of karaoke to be, well, terrifying. So naturally I was in. VoiceBox has a fun thing where people in your private room can use their phones to post comments that overlay the lyrics. This led to a lot of fun friendly jokes on song lyrics and people’s singing. Usually a few words, or sometimes an Emoji. The Nerd Sniping: Summer 2019 For the past few years at 360iDev I’ve hosted a session called Stump 360. It started as something ripped off inspired by the “Stump the Experts” session that used to happen at WWDC. It’s a sort of combination game show and panel discussion. As with the original, obscure technical questions are the excuse for the session, but having fun is more important than actually knowing things. It’s not quite like a usual conference session. Partly because it’s held after hours, offsite at a nearby bar (even though it’s an official conference event). Partly because audience participation is more than encouraged, it’s pretty much necessary. It does have presentation slides, though, which is important for this post. My friend Shane Cowherd helps out a lot with the planning. He also comes up with fun and sometimes weird technical ideas. And so one day Shane said, wouldn’t it be awesome if the slides at Stump 360 could do something like the lyrics screen at VoiceBox? People could use their phones to add their own commentary to slides, live, during the session. I knew I had to make it work. Somehow. So I wrote a custom presentation slide app… I wondered how the slides could do this. I realized that every presentation slide app was out, because most presentations don’t include bizarre ideas like this. So I’d have to go for a custom slide app of some kind. I experimented with a fully custom presentation app, with its own scheme for designing and presenting slides. Like most presentations, my slides tend to stick to a few basic layouts. Slide headings, bullet lists, images, and so on, nothing complex. With a little autolayout magic, I could get all of those working. Well probably. I think. It might have worked. But I had an absolute deadline. Stump 360 was on August 26th, and this was a spare time project. Eventually I passed on this idea and left the slide design to the experts. Instead I went with using DeckSet to do my slides, as usual. I couldn’t present with DeckSet, so I’d export the slides to PDF, and write a custom app that would display them with PDFKit. That I could get working before the session. Making Slides Interactive With a custom slide app I could add extra UI to show messages from the audience. But how could I get those messages? And what kind of messages should I plan on? Since 360iDev is an iOS developer conference, I knew that everyone would have an iOS device handy. Probably a small fleet of them, really. So what could be better than MultiPeerConnectivity? It would work on everyone’s device, and the peer-to-peer communication would mean that bad Wifi or mobile network trouble didn’t matter. Awesome! Except… That means everyone would need to install a client app to interact. I could write that easily enough but I’d have to deliver it. Maybe via Testflight? But I didn’t want to have to deal with app review, or start off by trying to convince audience members to download an app. I was working with kind of a weird idea and I needed it to be as easy as possible to participate. Reluctantly, I decided that I’d be better off with a web page as the audience app. Then I could just put a short URL on my slides, and anyone who wanted to play could dive right in. If network conditions were bad, it might not work very well. But I decided that making it easy to get involved outweighed that risk. The Client Web App I used glitch.com for the client web app, since it’s an incredibly convenient way to get something like this running quickly. I wouldn’t have to figure out the technical requirements for the server side (probably not much but I’m not a web developer). The in-browser editor works well, and their concept of remixing existing projects (a bit like a GitHub fork) makes it easy to adapr existing code. For messaging I went with Firebase real-time database. I don’t know if it’s the best choice for this, but I knew it and was under time pressure, and it did the job. The requirements are pretty simple. The client app would send short text messages by creating new entries in the database. The slide app would monitor the database to find new messages as they came in. That’s all, a simple one way, many-to-one messaging system. The Firebase data ended up looking like this: To keep things moving, Shane and I decided on a sort of Emoji keyboard for the client UI. Typing messages would distract too much. Instead people could just tap (or repeatedly mash) and Emoji to send a single-character message. With a bunch of help from Shane, the UI ended up looking like this: I added a couple of non-Emoji images related to the conference, in the top row in this screenshot. Showing Emoji over Slides Listening for incoming messages in the slide app is a pretty straightfoward application of listening for snapshot updates from Firebase’s real time database. All it takes is initializing Firebase and listening for new messages at the right database location. FirebaseApp.configure() var ref: DatabaseReference = Database.database().reference() var postListRef: DatabaseReference = ref.child(\"/stumps/\") postListRef.observe(.childAdded) { (snapshot) in guard let stumpEntry = snapshot.value as? [String:Any] else { return } guard let messageTimestampMs = stumpEntry[\"messageDate\"] as? Double else { return } guard (messageTimestampMs/1000 \u003e self.startDate.timeIntervalSince1970) else { return } guard let message = stumpEntry[\"message\"] as? String else { return } self.stumpmojiReceived?(message) } When the app launches, Firebase’s observe starts by replaying all of the entries so far. History doesn’t matter to this app, so I added the timestamp check to filter out anything from before the current app launch. After that it’s just a matter of taking new incoming messages and passing them to the UI. To show the incoming Emoji and images, I added a custom view that overlaid the main PDF view showing the slides. Incoming messages are displayed in a UILabel within this view, initially at a random point on the top edge of the screen. For Emoji I just use the incoming text directly, and for the custom images I look up corresponding images in the app. let messageInitialXPosition = CGFloat.random(in: 20...frame.maxX-20) let messageView: UIView = { let view = UILabel(frame: CGRect(x: messageInitialXPosition, y: 0, width: 100, height: 100)) view.text = message view.font = UIFont.systemFont(ofSize: 60, weight: .heavy) view.sizeToFit() view.backgroundColor = .clear return view }() addSubview(messageView) Non-Emoji buttons used a slightly different approach, using images in the app instead of text. The labels than animate downward while slowly spinning and fading out. let messageFinalXPosition = CGFloat.random(in: 20...frame.maxX-20) let messageFinalYPosition = CGFloat.random(in: frame.maxY ... 1.25*frame.maxY) let animationTime = TimeInterval.random(in: 5...15) let animationRotation = CGFloat.random(in: -8*CGFloat.pi...8*CGFloat.pi) UIView.animate(withDuration: animationTime, animations: { messageView.frame.origin.y = messageFinalYPosition messageView.frame.origin.x = messageFinalXPosition messageView.alpha = 0 messageView.transform = CGAffineTransform(scaleX: 0.5, y: 0.5).concatenating(CGAffineTransform(rotationAngle: animationRotation)) }) { (_) in messageView.removeFromSuperview() } As with pretty much every part of this project, I wasn’t sure if the code was all that great but didn’t have a lot of time to think about it. It worked, so I went with it. More to Come After Stump 360 I went back and added some of the things I wanted but didn’t have time for. I plan on doing this again in the future, and I’m not on a tight deadline now. Things like Better PDF handling, including some tricks for slide thumbnails. Simple sate restoration, so I don’t lose my page. A remote control app so I could change slides from my iPhone. I’ll have some followup posts to look at these in more detail.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n    \u003cp\u003eThis is a story of how a trip to a karaoke bar led to me writing my own app to display presentation slides. Of how a user interface that allows live smartass comments led to me being completely \u003ca href=\"https://www.xkcd.com/356/\"\u003enerd sniped\u003c/a\u003e until I was able to do something I’ve never seen in a conference session– however silly the result was.\u003c/p\u003e\n\u003cp\u003eIn the end audience members could send Emoji and other images directly to the slides during the session, which ended up looking like this.\u003c/p\u003e\n\u003cp\u003e\u003ciframe src=\"https://player.vimeo.com/video/387766799?title=0\u0026amp;byline=0\u0026amp;portrait=0\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\n\u003ch3 id=\"the-innocent-beginning-360idev-2018\"\u003eThe Innocent Beginning: 360iDev 2018\u003c/h3\u003e\n\u003cp\u003eAt \u003ca href=\"https://360iDev.com/\"\u003e360iDev\u003c/a\u003e a few years ago, \u003ca href=\"https://twitter.com/macgenie\"\u003eJean MacDonald\u003c/a\u003e suggested an unofficial group outing. How about a group of us have a karaoke night? \u003ca href=\"https://voiceboxkaraoke.com/locations/rino-denver/\"\u003eVoiceBox Karaoke\u003c/a\u003e wasn’t far from the conference, and they had private karaoke rooms. It’d be just the 360iDev group in their own room.\u003c/p\u003e\n\u003cp\u003eI found the idea of karaoke to be, well, terrifying. So naturally I was in.\u003c/p\u003e\n\u003cp\u003eVoiceBox has a fun thing where people in your private room can use their phones to post comments that overlay the lyrics. This led to a lot of fun friendly jokes on song lyrics and people’s singing. Usually a few words, or sometimes an Emoji.\u003c/p\u003e\n\u003ch3 id=\"the-nerd-sniping-summer-2019\"\u003eThe Nerd Sniping: Summer 2019\u003c/h3\u003e\n\u003cp\u003eFor the past few years at 360iDev I’ve hosted a session called \u003ca href=\"https://atomicbird.com/blog/stump-360-iii/\"\u003eStump 360\u003c/a\u003e. It started as something \u003cdel\u003eripped off\u003c/del\u003e inspired by the \u003ca href=\"https://en.everybodywiki.com/Stump_the_Experts\"\u003e“Stump the Experts”\u003c/a\u003e session that used to happen at WWDC. It’s a sort of combination game show and panel discussion. As with the original, obscure technical questions are the excuse for the session, but  having fun is more important than actually knowing things.\u003c/p\u003e\n\u003cp\u003eIt’s not quite like a usual conference session. Partly because it’s held after hours, offsite at a nearby bar (even though it’s an official conference event). Partly because audience participation is more than encouraged, it’s pretty much necessary. It does have presentation slides, though, which is important for this post.\u003c/p\u003e\n\u003cp\u003eMy friend \u003ca href=\"https://twitter.com/shanecowherd\"\u003eShane Cowherd\u003c/a\u003e helps out a lot with the planning. He also comes up with fun and sometimes weird technical ideas. And so one day Shane said, \u003cem\u003ewouldn’t it be awesome if the slides at Stump 360 could do something like the lyrics screen at VoiceBox? People could use their phones to add their own commentary to slides, live, during the session.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eI knew I had to make it work. Somehow.\u003c/p\u003e\n\u003ch3 id=\"so-i-wrote-a-custom-presentation-slide-app\"\u003eSo I wrote a custom presentation slide app…\u003c/h3\u003e\n\u003cp\u003eI wondered how the slides could do this. I realized that every presentation slide app was out, because most presentations don’t include bizarre ideas like this. So I’d have to go for a custom slide app of some kind.\u003c/p\u003e\n\u003cp\u003eI experimented with a fully custom presentation app, with its own scheme for designing and presenting slides. Like most presentations, my slides tend to stick to a few basic layouts. Slide headings, bullet lists, images, and so on, nothing complex. With a little autolayout magic, I could get all of those working. Well probably. I think.\u003c/p\u003e\n\u003cp\u003eIt might have worked. But I had an absolute deadline. Stump 360 was on August 26th, and this was a spare time project. Eventually I passed on this idea and left the slide design to the experts.\u003c/p\u003e\n\u003cp\u003eInstead I went with using \u003ca href=\"https://www.deckset.com/\"\u003eDeckSet\u003c/a\u003e to do my slides, as usual. I couldn’t present with DeckSet, so I’d export the slides to PDF, and write a custom app that would display them with \u003ccode\u003ePDFKit\u003c/code\u003e. \u003cem\u003eThat\u003c/em\u003e I could get working before the session.\u003c/p\u003e\n\u003ch3 id=\"making-slides-interactive\"\u003eMaking Slides Interactive\u003c/h3\u003e\n\u003cp\u003eWith a custom slide app I could add extra UI to show messages from the audience. But how could I get those messages? And what kind of messages should I plan on?\u003c/p\u003e\n\u003cp\u003eSince 360iDev is an iOS developer conference, I knew that everyone would have an iOS device handy. Probably a small fleet of them, really. So what could be better than \u003ca href=\"https://developer.apple.com/documentation/multipeerconnectivity\"\u003eMultiPeerConnectivity\u003c/a\u003e? It would work on everyone’s device, and the peer-to-peer communication would mean that bad Wifi or mobile network trouble didn’t matter. Awesome!\u003c/p\u003e\n\u003cp\u003eExcept… That means everyone would need to install a client app to interact. I could write that easily enough but I’d have to deliver it. Maybe via Testflight? But I didn’t want to have to deal with app review, or start off by trying to convince audience members to download an app. I was working with kind of a weird idea and I needed it to be as easy as possible to participate.\u003c/p\u003e\n\u003cp\u003eReluctantly, I decided that I’d be better off with a web page as the audience app. Then I could just put a short URL on my slides, and anyone who wanted to play could dive right in. If network conditions were bad, it might not work very well. But I decided that making it easy to get involved outweighed that risk.\u003c/p\u003e\n\u003ch3 id=\"the-client-web-app\"\u003eThe Client Web App\u003c/h3\u003e\n\u003cp\u003eI used \u003ca href=\"https://glitch.com/\"\u003eglitch.com\u003c/a\u003e for the client web app, since it’s an incredibly convenient way to get something like this running quickly. I wouldn’t have to figure out the technical requirements for the server side (probably not much but I’m not a web developer). The in-browser editor works well, and their concept of remixing existing projects (a bit like a GitHub fork) makes it easy to adapr existing code.\u003c/p\u003e\n\u003cp\u003eFor messaging I went with \u003ca href=\"https://firebase.google.com/\"\u003eFirebase\u003c/a\u003e real-time database. I don’t know if it’s the best choice for this, but I knew it and was under time pressure, and it did the job. The requirements are pretty simple.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe client app would send short text messages by creating new entries in the database.\u003c/li\u003e\n\u003cli\u003eThe slide app would monitor the database to find new messages as they came in.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThat’s all, a simple one way, many-to-one messaging system. The Firebase data ended up looking like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://atomicbird.com/blog/interactive-presentation-slides-at-360idev/firebase-data.png#center50\" alt=\"Sample Firebase data\"/\u003e\u003c/p\u003e\n\u003cp\u003eTo keep things moving, Shane and I decided on a sort of Emoji keyboard for the client UI. Typing messages would distract too much. Instead people could just tap (or repeatedly mash) and Emoji to send a single-character message.\u003c/p\u003e\n\u003cp\u003eWith a bunch of help from Shane, the UI ended up looking like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://atomicbird.com/blog/interactive-presentation-slides-at-360idev/glitch-client.jpg#center50\" alt=\"Glitch page displayed on an iPhone XS\"/\u003e\u003c/p\u003e\n\u003cp\u003eI added a couple of non-Emoji images related to the conference, in the top row in this screenshot.\u003c/p\u003e\n\u003ch3 id=\"showing-emoji-over-slides\"\u003eShowing Emoji over Slides\u003c/h3\u003e\n\u003cp\u003eListening for incoming messages in the slide app is a pretty straightfoward application of listening for snapshot updates from Firebase’s real time database. All it takes is initializing Firebase and listening for new messages at the right database location.\u003c/p\u003e\n\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"swift\"\u003e\u003cspan\u003e\u003cspan\u003eFirebaseApp.configure()\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003evar\u003c/span\u003e ref: DatabaseReference = Database.database().reference()\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003evar\u003c/span\u003e postListRef: DatabaseReference = ref.child(\u003cspan\u003e\u0026#34;/stumps/\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003epostListRef.observe(.childAdded) { (snapshot) \u003cspan\u003ein\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003eguard\u003c/span\u003e \u003cspan\u003elet\u003c/span\u003e stumpEntry = snapshot.value \u003cspan\u003eas\u003c/span\u003e? [String:Any] \u003cspan\u003eelse\u003c/span\u003e { \u003cspan\u003ereturn\u003c/span\u003e }\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003eguard\u003c/span\u003e \u003cspan\u003elet\u003c/span\u003e messageTimestampMs = stumpEntry[\u003cspan\u003e\u0026#34;messageDate\u0026#34;\u003c/span\u003e] \u003cspan\u003eas\u003c/span\u003e? Double \u003cspan\u003eelse\u003c/span\u003e { \u003cspan\u003ereturn\u003c/span\u003e }\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003eguard\u003c/span\u003e (messageTimestampMs\u003cspan\u003e/\u003c/span\u003e\u003cspan\u003e1000\u003c/span\u003e \u003cspan\u003e\u0026gt;\u003c/span\u003e \u003cspan\u003eself\u003c/span\u003e.startDate.timeIntervalSince1970) \u003cspan\u003eelse\u003c/span\u003e { \u003cspan\u003ereturn\u003c/span\u003e }\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003eguard\u003c/span\u003e \u003cspan\u003elet\u003c/span\u003e message = stumpEntry[\u003cspan\u003e\u0026#34;message\u0026#34;\u003c/span\u003e] \u003cspan\u003eas\u003c/span\u003e? String \u003cspan\u003eelse\u003c/span\u003e { \u003cspan\u003ereturn\u003c/span\u003e }\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003eself\u003c/span\u003e.stumpmojiReceived?(message)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWhen the app launches, Firebase’s \u003ccode\u003eobserve\u003c/code\u003e starts by replaying all of the entries so far. History doesn’t matter to this app, so I added the timestamp check to filter out anything from before the current app launch. After that it’s just a matter of taking new incoming messages and passing them to the UI.\u003c/p\u003e\n\u003cp\u003eTo show the incoming Emoji and images, I added a custom view that overlaid the main PDF view showing the slides. Incoming messages are displayed in a \u003ccode\u003eUILabel\u003c/code\u003e within this view, initially at a random point on the top edge of the screen. For Emoji I just use the incoming text directly, and for the custom images I look up corresponding images in the app.\u003c/p\u003e\n\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"swift\"\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003elet\u003c/span\u003e messageInitialXPosition = CGFloat.random(\u003cspan\u003ein\u003c/span\u003e: \u003cspan\u003e20.\u003c/span\u003e..frame.maxX\u003cspan\u003e-\u003c/span\u003e\u003cspan\u003e20\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003elet\u003c/span\u003e messageView: UIView = {\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003elet\u003c/span\u003e view = UILabel(frame: CGRect(x: messageInitialXPosition, y: \u003cspan\u003e0\u003c/span\u003e, width: \u003cspan\u003e100\u003c/span\u003e, height: \u003cspan\u003e100\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    view.text = message\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    view.font = UIFont.systemFont(ofSize: \u003cspan\u003e60\u003c/span\u003e, weight: .heavy)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    view.sizeToFit()\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    view.backgroundColor = .clear\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    \u003cspan\u003ereturn\u003c/span\u003e view\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e}()\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003eaddSubview(messageView)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNon-Emoji buttons used a slightly different approach, using images in the app instead of text.\u003c/p\u003e\n\u003cp\u003eThe labels than animate downward while slowly spinning and fading out.\u003c/p\u003e\n\u003cdiv\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode data-lang=\"swift\"\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003elet\u003c/span\u003e messageFinalXPosition = CGFloat.random(\u003cspan\u003ein\u003c/span\u003e: \u003cspan\u003e20.\u003c/span\u003e..frame.maxX\u003cspan\u003e-\u003c/span\u003e\u003cspan\u003e20\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003elet\u003c/span\u003e messageFinalYPosition = CGFloat.random(\u003cspan\u003ein\u003c/span\u003e: frame.maxY ... \u003cspan\u003e1.25\u003c/span\u003e\u003cspan\u003e*\u003c/span\u003eframe.maxY)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003elet\u003c/span\u003e animationTime = TimeInterval.random(\u003cspan\u003ein\u003c/span\u003e: \u003cspan\u003e5.\u003c/span\u003e..\u003cspan\u003e15\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\u003cspan\u003elet\u003c/span\u003e animationRotation = CGFloat.random(\u003cspan\u003ein\u003c/span\u003e: \u003cspan\u003e-\u003c/span\u003e\u003cspan\u003e8\u003c/span\u003e\u003cspan\u003e*\u003c/span\u003eCGFloat.pi...\u003cspan\u003e8\u003c/span\u003e\u003cspan\u003e*\u003c/span\u003eCGFloat.pi)\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003eUIView.animate(withDuration: animationTime, animations: {\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    messageView.frame.origin.y = messageFinalYPosition\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    messageView.frame.origin.x = messageFinalXPosition\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    messageView.alpha = \u003cspan\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    messageView.transform = CGAffineTransform(scaleX: \u003cspan\u003e0.5\u003c/span\u003e, y: \u003cspan\u003e0.5\u003c/span\u003e).concatenating(CGAffineTransform(rotationAngle: animationRotation))\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e}) { (\u003cspan\u003e_\u003c/span\u003e) \u003cspan\u003ein\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e    messageView.removeFromSuperview()\n\u003c/span\u003e\u003c/span\u003e\u003cspan\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAs with pretty much every part of this project, I wasn’t sure if the code was all that great but didn’t have a lot of time to think about it. It worked, so I went with it.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://atomicbird.com/blog/interactive-presentation-slides-at-360idev/worst-code.jpg#center\" alt=\"\"/\u003e\u003c/p\u003e\n\u003ch3 id=\"more-to-come\"\u003eMore to Come\u003c/h3\u003e\n\u003cp\u003eAfter Stump 360 I went back and added some of the things I wanted but didn’t have time for. I plan on doing this again in the future, and I’m not on a tight deadline now. Things like\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://atomicbird.com/blog/pdfkit-basics\"\u003eBetter PDF handling\u003c/a\u003e, including \u003ca href=\"https://atomicbird.com/blog/pdfkit-thumbnails\"\u003esome tricks for slide thumbnails\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eSimple sate restoration, so I don’t lose my page.\u003c/li\u003e\n\u003cli\u003eA remote control app so I could change slides from my iPhone.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI’ll have some followup posts to look at these in more detail.\u003c/p\u003e\n\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2020-01-28T00:00:00Z",
  "modifiedTime": "2020-01-28T00:00:00Z"
}
