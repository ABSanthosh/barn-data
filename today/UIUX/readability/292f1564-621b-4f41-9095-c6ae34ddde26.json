{
  "id": "292f1564-621b-4f41-9095-c6ae34ddde26",
  "title": "Designing Respectful Tech: What is your relationship with technology?",
  "link": "https://boxesandarrows.com/designing-respectful-tech-what-is-your-relationship-with-technology/",
  "description": "You’ve been there before. You thought you could trust someone with a secret. You thought it would be safe, but found out later that they blabbed to everyone. Or, maybe they didn’t share it, but the way they used it felt manipulative. You gave more than you got and it didn’t feel fair. But now that it’s out there, do you even have control anymore? Ok. Now imagine that person was your supermarket.  Or your doctor.  Or your boss. Do The post Designing Respectful Tech: What is your relationship with technology? appeared first on Boxes and Arrows.",
  "author": "Noreen Whysel",
  "published": "Thu, 24 Feb 2022 12:00:00 +0000",
  "source": "http://boxesandarrows.com/rss/",
  "categories": [
    "Foundational Thinking",
    "Social UX",
    "UX Design",
    "privacy",
    "safety"
  ],
  "byline": "Noreen Whysel",
  "length": 10047,
  "excerpt": "You’ve been there before. You thought you could trust someone with a secret. You thought it would be safe, but found out later that they blabbed to everyone. Or, maybe they didn’t share it, but the way they used it felt manipulative. You gave more than you got and it didn’t feel fair. But now that it’s out there, do you even have control anymore? Ok. Now imagine that person was your supermarket. Or your doctor. Or your boss. Do",
  "siteName": "Boxes and Arrows",
  "favicon": "",
  "text": "You’ve been there before. You thought you could trust someone with a secret. You thought it would be safe, but found out later that they blabbed to everyone. Or, maybe they didn’t share it, but the way they used it felt manipulative. You gave more than you got and it didn’t feel fair. But now that it’s out there, do you even have control anymore? Ok. Now imagine that person was your supermarket.  Or your doctor.  Or your boss. Do you have a personal relationship with technology? According to research at the Me2B Alliance, people do feel they have a relationship with technology. It’s emotional. It’s embodied. And it’s very personal. How personal is it? Think about what it would be like if you placed an order at a cafe and they already knew your name, your email, your gender, your physical location, what you read, who you are dating, and that, maybe, you’ve been thinking of breaking up. Source: “If your shop assistant was an app (hidden camera),” Forbrugerrådet Tænk (Danish Consumer Council), December 2014 (YouTube). We don’t approve of gossipy behavior in our human relationships. So why do we accept it with technology? Sure, we get back some time and convenience, but in many ways it can feel locked in and unequal. The Me2B Relationship Model At the Me2B Alliance, we are studying digital relationships to answer questions like “Do people have a relationship with technology?” (They feel that they do). “What does that relationship feel like?” (It’s complicated). And “Do people understand the commitments that they are making when they explore, enter into and dissolve these relationships?” (They really don’t). It may seem silly or awkward to think about our dealings with technology as a relationship, but like messy human relationships there are parallels. The Me2BA commitment arc with a digital technology resembles German psychologist George Levenger’s ABCDE relationship model 1, shown by the Orange icons in the image below. As with human relationships, we move through states of discovery, commitment and breakup with digital applications, too. Source: Me2B Alliance, 2021 Our assumptions about our technology relationships are similar to the ones we have about our human ones. We assume when we first meet someone there is a clean slate, but this isn’t always true. There may be gossip about you ahead of your meeting. The other person may have looked you up on LinkedIn. With any technology, information about you may be known already, and sharing that data starts well before you sign up for an account. The Invisible Parallel Dataverse Today’s news frequently covers stories of personal and societal harm caused by digital media manipulation, dark patterns and personal data mapping. Last year, Facebook whistleblower Frances Hauser exposed how the platform promotes content that they know from their own research causes depression and self-harm in teenage girls. They know this because they know what teenage girls click, post and share. Technology enables data sharing at every point of the relationship arc, including after you stop using it. Worryingly, even our more trusted digital relationships may not be safe. The Me2B Alliance uncovered privacy violations in K-12 software, and described how abandoned website domains put children and families at risk when their schools forget to renew them.  Most of the technologies that you (and your children) use have relationships with third party data brokers and others with whom they share your data. Each privacy policy, cookie consent and terms of use document on every website or mobile app you use defines a legal relationship, whether you choose to opt in or are locked in by some other process. That means you have a legal relationship with each of these entities from the moment you accessed the app or website, and in most cases, it’s one that you initiated and agreed to. All the little bits of our digital experiences are floating out there and will stay out there unless we have the agency to set how that data can be used or shared and when it should be deleted. The Me2B Alliance has developed Rules of Engagement for respectful technology relationships and a Digital Harms Dictionary outlining types of violations, such as: Collecting information without the user’s awareness or consent; contracts of adhesion, where users are forced to agree with terms of use (often implicitly) when they engage with the content; Loss or misuse of personally identifiable information; and Unclear or non-transparent information describing the technology’s policies or even what Me2B Deal they are getting. Source: Noreen Whysel, Me2B Alliance 2021. Image (right): Pixabay Respectful technology relationships begin with minimizing the amount of data that is collected in the first place. Data minimization reduces the harmful effects of sensitive data getting into the wrong hands.  Next, we should give people agency and control. Individual control over one’s data is a key part of local and international privacy laws like GDPR in Europe, and similar laws in California, Colorado and Virginia, which give consumers the right to consent to data collection, to know what data of theirs is collected and to request to view the data that was collected, correct it, or to have it permanently deleted. Three Laws of Safe and Respectful Design In his short story, I, Robot, Isaac Asimov introduced the famous “Three Laws of Robotics,” an ethical framework to avoid harmful consequences of machine activity. Today, IAs, programmers and other digital creators make what are essentially robots that help users do work and share information. Much of this activity is out of sight and mind, which is in fact how we, the digital technology users, like it.  But what of the risks? It is important as designers of these machines to consider the consequences of the work we put into the world. I have proposed the following corollary to Asimov’s robotics laws: First Law: A Digital Creator may not injure a human being or, through inaction, allow a human being to come to harm.Second Law: A Digital Creator must obey the orders given by other designers, clients, product managers, etc. except where such orders would conflict with the First Law.Third Law: A Digital Creator must protect its own existence as long as such protection does not conflict with the First or Second Law.1 Mike Monteiro in his well-known 2014 talk at An Event Apart on How Designers are Destroying the World discusses the second and third law a lot. While we take orders from the stakeholders of our work—the client, the marketers and the shareholders we design for—we have an equal and greater responsibility to understand and mitigate design decisions that have negative effects. A Specification for Safe and Respectful Technology The Me2B Alliance is working on a specification for safe and respectfully designed digital technologies—technologies that Do No Harm. These product integrity tests are conducted by a UX Expert and applied to each commitment stage that a person enters. These stages range from first-open, location awareness, cookie consent, promotional and loyalty commitments, and account creation, as well as the termination of the relationship. Abby Covert’s IA Principles—particularly Findable, Accessible, Clear, Communicative and Controllable—are remarkably appropriate tests for ensuring that the people who use digital technologies have agency and control over the data they entrust to these products: Findable: Are the legal documents that govern the technology relationship easy to find? What about support services for when I believe my data is incorrect, or being used inappropriately? Can I find a way to delete my account or delete my data? Accessible: Are these resources easy to access by both human and machine readers and assistive devices? Are they hidden behind some “data paywall” such as a process that requires a change of commitment state, i.e. a data toll, to access? Clear: Can the average user read and understand the information that explains what data is required for what purpose? Is this information visible or accessible when it is relevant? Communicative: Does the technology inform the user when the commitment status changes? For example, does it communicate when it needs to access my location or other personal information like age, gender, medical conditions? Does it explain why it needs my data and how to revoke data access when it is no longer necessary? Controllable: How much control do I have as a user? Can I freely enter into a Me2B Commitment or am I forced to give up some data just to find out what the Me2B Deal is in the first place?  Abby’s other IA principles flow from the above considerations. A Useful product is one that does what it claims to do and communicates the deal you get clearly and accessibly. A Credible product is one that treats the user with respect and communicates its value. With user Control over data sharing and a clear understanding of the service being offered, the true Value of the service is apparent. Over time the user will come to expect notice of potential changes to commitment states and will have agency over making that choice. These “Helpful Patterns”—clear and discoverable notice of state changes and opt-in commitments—build trust and loyalty, leading to a Delightful, or at least a reassuring, experience for your users. What I’ve learned from working in the standards world is that Information Architecture Principles provide a solid framework for understanding digital relationships as well as structuring meaning. Because we aren’t just designing information spaces. We’re designing healthy relationships. 1 Levinger, G. (1983). “Development and change.” In H.H. Kelley et al. (Eds.), Close relationships (315–359). New York: W. H. Freeman and Company. https://www.worldcat.org/title/close-relationships/oclc/470636389 2  Asimov, I. (1950). I, Robot. Gnome Press.",
  "image": "https://boxesandarrows.com/wp-content/uploads/2022/02/Whysel-Dark-Patterns-Dandelion-Cover.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n\t\t\n\u003cp\u003eYou’ve been there before. You thought you could trust someone with a secret. You thought it would be safe, but found out later that they blabbed to everyone. Or, maybe they didn’t share it, but the way they used it felt manipulative. You gave more than you got and it didn’t feel fair. But now that it’s out there, do you even have control anymore?\u003c/p\u003e\n\n\n\n\u003cp\u003eOk. Now imagine that person was your supermarket. \u003c/p\u003e\n\n\n\n\u003cp\u003eOr your doctor. \u003c/p\u003e\n\n\n\n\u003cp\u003eOr your boss.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"do-you-have-a-personal-relationship-with-technology\"\u003eDo you have a personal relationship with technology?\u003c/h3\u003e\n\n\n\n\u003cp\u003eAccording to \u003ca href=\"https://ooqc943yvdw4abzes1q1ezta-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/abstract-1.pdf\"\u003eresearch at the Me2B Alliance\u003c/a\u003e, people do feel they have a relationship with technology. It’s emotional. It’s embodied. And it’s very personal.\u003c/p\u003e\n\n\n\n\u003cp\u003eHow personal is it? Think about what it would be like if you placed an order at a cafe and they already knew your name, your email, your gender, your physical location, what you read, who you are dating, and that, maybe, you’ve been thinking of breaking up.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003ca href=\"https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant.png\"\u003e\u003cimg decoding=\"async\" width=\"1024\" height=\"768\" src=\"https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant-1024x768.png\" alt=\"\" srcset=\"https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant-1024x768.png 1024w, https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant-300x225.png 300w, https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant-768x576.png 768w, https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant-1536x1152.png 1536w, https://boxesandarrows.com/wp-content/uploads/2022/02/Shop-Assistant.png 2048w\" sizes=\"(max-width: 1024px) 100vw, 1024px\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e\u003ca href=\"https://www.youtube.com/watch?v=xYZtHIPktQg\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSource\u003c/a\u003e: “If your shop assistant was an app (hidden camera),” Forbrugerrådet Tænk (Danish Consumer Council), December 2014 (YouTube).\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWe don’t approve of gossipy behavior in our human relationships. So why do we accept it with technology? Sure, we get back some time and convenience, but in many ways it can feel locked in and unequal.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"the-me2b-relationship-model\"\u003eThe Me2B Relationship Model\u003c/h3\u003e\n\n\n\n\u003cp\u003eAt the Me2B Alliance, we are studying \u003ca href=\"https://me2ba.org/flash-guide-4-introduction-to-me2b-relationships-and-me2b-deals/\"\u003edigital relationships\u003c/a\u003e to answer questions like “Do people have a relationship with technology?” (They feel that they do). “What does that relationship feel like?” (It’s complicated). And “Do people understand the commitments that they are making when they explore, enter into and dissolve these relationships?” (They really don’t).\u003c/p\u003e\n\n\n\n\u003cp\u003eIt may seem silly or awkward to think about our dealings with technology as a relationship, but like messy human relationships there are parallels. The Me2BA commitment arc with a digital technology resembles German psychologist George Levenger’s ABCDE relationship model \u003csup\u003e1\u003c/sup\u003e, shown by the Orange icons in the image below. As with human relationships, we move through states of discovery, commitment and breakup with digital applications, too.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003ca href=\"https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow.png\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"568\" src=\"https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow-1024x568.png\" alt=\"\" srcset=\"https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow-1024x568.png 1024w, https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow-300x166.png 300w, https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow-768x426.png 768w, https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow-1536x852.png 1536w, https://boxesandarrows.com/wp-content/uploads/2022/02/Dig-Me2B-Lifecycle-Inv-Dataflow-2048x1136.png 2048w\" sizes=\"(max-width: 1024px) 100vw, 1024px\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eSource: Me2B Alliance, 2021\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOur assumptions about our technology relationships are similar to the ones we have about our human ones. We assume when we first meet someone there is a clean slate, but this isn’t always true. There may be gossip about you ahead of your meeting. The other person may have looked you up on LinkedIn. With any technology, information about you may be known already, and sharing that data starts well before you sign up for an account.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"the-invisible-parallel-dataverse\"\u003eThe Invisible Parallel Dataverse\u003c/h3\u003e\n\n\n\n\u003cp\u003eToday’s news frequently covers stories of personal and societal harm caused by digital media manipulation, \u003ca href=\"https://darkpatterns.org\"\u003edark patterns\u003c/a\u003e and personal data mapping. Last year, Facebook \u003ca href=\"https://www.nytimes.com/2021/10/03/technology/whistle-blower-facebook-frances-haugen.html?referringSource=articleShare\"\u003ewhistleblower\u003c/a\u003e Frances Hauser exposed how the platform promotes content that they know from their own research causes depression and self-harm in teenage girls. They know this because they know what teenage girls click, post and share.\u003c/p\u003e\n\n\n\n\u003cp\u003eTechnology enables data sharing at every point of the relationship arc, including after you stop using it. Worryingly, even our more trusted digital relationships may not be safe. The Me2B Alliance uncovered \u003ca href=\"https://me2ba.org/did-you-know-which-is-leakier/\"\u003eprivacy violations in K-12 software\u003c/a\u003e, and described how abandoned website domains put \u003ca href=\"https://me2ba.org/dangling-domain-from-sdk-installed-in-150-apple-apps-putting-kids-families-and-crypto-traders-at-risk/\"\u003echildren and families at risk\u003c/a\u003e when their schools forget to renew them. \u003c/p\u003e\n\n\n\n\u003cp\u003eMost of the technologies that you (and your children) use have relationships with third party data brokers and others with whom they share your data. Each privacy policy, cookie consent and terms of use document on every website or mobile app you use defines a legal relationship, whether you choose to opt in or are locked in by some other process. That means you have a legal relationship with each of these entities from the moment you accessed the app or website, and in most cases, \u003cstrong\u003eit’s one that you initiated and agreed to.\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eAll the little bits of our digital experiences are floating out there and will stay out there unless we have the agency to set how that data can be used or shared and when it should be deleted. The Me2B Alliance has developed \u003ca href=\"https://me2ba.org/flash-guide-3-the-me2b-rules-of-engagement-our-ethical-foundation/\"\u003eRules of Engagement\u003c/a\u003e for respectful technology relationships and a \u003ca href=\"https://me2ba.org/library/\"\u003eDigital Harms Dictionary\u003c/a\u003e outlining types of violations, such as:\u003c/p\u003e\n\n\n\n\u003cul\u003e\u003cli\u003eCollecting information without the user’s awareness or consent; \u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.law.cornell.edu/wex/adhesion_contract_%28contract_of_adhesion%29\"\u003econtracts of adhesion\u003c/a\u003e, where users are forced to agree with terms of use (often implicitly) when they engage with the content; \u003c/li\u003e\u003cli\u003eLoss or misuse of personally identifiable information; and \u003c/li\u003e\u003cli\u003eUnclear or non-transparent information describing the technology’s policies or even what \u003ca href=\"https://me2ba.org/flash-guide-5-online-me2b-deals-currencies-in-the-digital-world-and-the-price-of-free/\"\u003eMe2B Deal\u003c/a\u003e they are getting.\u003c/li\u003e\u003c/ul\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://boxesandarrows.com/wp-content/uploads/2022/02/respectful.png\" alt=\"Respectful relationships. Data minimization includes: No gossip, no eavesdropping, no stalking. Individual control and autonomy includes: No manipulation, no coercion. Respectful defaults includes Progressive Consent.\"/\u003e\u003cfigcaption\u003eSource: Noreen Whysel, Me2B Alliance 2021. Image (right): \u003ca href=\"https://pixabay.com/service/license/\"\u003ePixabay\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eRespectful technology relationships begin with minimizing the amount of data that is collected in the first place. \u003ca href=\"https://www.trendmicro.com/vinfo/us/security/definition/Data-Minimization\"\u003eData minimization\u003c/a\u003e reduces the harmful effects of sensitive data getting into the wrong hands. \u003c/p\u003e\n\n\n\n\u003cp\u003eNext, we should give people agency and control. Individual control over one’s data is a key part of local and international privacy laws like GDPR in Europe, and similar laws in \u003ca href=\"https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375\"\u003eCalifornia\u003c/a\u003e, \u003ca href=\"https://legiscan.com/CO/drafts/SB190/2021\"\u003eColorado\u003c/a\u003e and \u003ca href=\"https://law.lis.virginia.gov/vacodepopularnames/personal-information-privacy-act/\"\u003eVirginia\u003c/a\u003e, which give consumers the right to consent to data collection, to know what data of theirs is collected and to request to view the data that was collected, correct it, or to have it permanently deleted.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"three-laws-of-safe-and-respectful-design\"\u003eThree Laws of Safe and Respectful Design\u003c/h3\u003e\n\n\n\n\u003cp\u003eIn his short story, \u003cem\u003eI, Robot\u003c/em\u003e, Isaac Asimov introduced the famous “Three Laws of Robotics,” an ethical framework to avoid harmful consequences of machine activity. Today, IAs, programmers and other digital creators make what are essentially robots that help users do work and share information. Much of this activity is out of sight and mind, which is in fact how we, the digital technology users, like it. \u003c/p\u003e\n\n\n\n\u003cp\u003eBut what of the risks? It is important as designers of these machines to consider the consequences of the work we put into the world. I have proposed the following corollary to Asimov’s robotics laws:\u003c/p\u003e\n\n\n\n\u003cul\u003e\u003cli\u003e\u003cstrong\u003eFirst Law\u003c/strong\u003e: A Digital Creator may not injure a human being or, through inaction, allow a human being to come to harm.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSecond Law\u003c/strong\u003e: A Digital Creator must obey the orders given by other designers, clients, product managers, etc. except where such orders would conflict with the First Law.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eThird Law\u003c/strong\u003e: A Digital Creator must protect its own existence as long as such protection does not conflict with the First or Second Law.\u003csup\u003e1\u003c/sup\u003e\u003c/li\u003e\u003c/ul\u003e\n\n\n\n\u003cp\u003eMike Monteiro in his well-known 2014 talk at An Event Apart on \u003ca href=\"https://vimeo.com/122022963\"\u003eHow Designers are Destroying the World\u003c/a\u003e discusses the second and third law a lot. While we take orders from the stakeholders of our work—the client, the marketers and the shareholders we design for—we have an equal and greater responsibility to understand and mitigate design decisions that have negative effects.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"a-specification-for-safe-and-respectful-technology\"\u003eA Specification for Safe and Respectful Technology\u003c/h3\u003e\n\n\n\n\u003cp\u003eThe Me2B Alliance is working on a \u003ca href=\"https://me2ba.org/library/recommendation-attributes-of-safe-respectful-me2b-commitments/\"\u003especification for safe and respectfully designed digital technologies\u003c/a\u003e—technologies that Do No Harm. These product integrity tests are conducted by a UX Expert and applied to each \u003ca href=\"https://me2ba.org/flash-guide-8-digital-me2b-commitments-deals/\"\u003ecommitment stage\u003c/a\u003e that a person enters. These stages range from first-open, location awareness, cookie consent, promotional and loyalty commitments, and account creation, as well as the termination of the relationship.\u003c/p\u003e\n\n\n\n\u003cp\u003eAbby Covert’s \u003ca href=\"https://www.slideshare.net/AbbyCovert/information-architecture-heuristics/10-10_Heuristic_IA_Principles\"\u003eIA Principles\u003c/a\u003e—particularly Findable, Accessible, Clear, Communicative and Controllable—are remarkably appropriate tests for ensuring that the people who use digital technologies have agency and control over the data they entrust to these products:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eFindable\u003c/strong\u003e: Are the legal documents that govern the technology relationship easy to find? What about support services for when I believe my data is incorrect, or being used inappropriately? Can I find a way to delete my account or delete my data?\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eAccessible\u003c/strong\u003e: Are these resources easy to access by both human and machine readers and assistive devices? Are they hidden behind some “data paywall” such as a process that requires a change of commitment state, i.e. a data toll, to access?\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eClear\u003c/strong\u003e: Can the average user read and understand the information that explains what data is required for what purpose? Is this information visible or accessible when it is relevant?\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eCommunicative\u003c/strong\u003e: Does the technology inform the user when the commitment status changes? For example, does it communicate when it needs to access my location or other personal information like age, gender, medical conditions? Does it explain why it needs my data and how to revoke data access when it is no longer necessary?\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eControllable\u003c/strong\u003e: How much control do I have as a user? Can I freely enter into a Me2B Commitment or am I forced to give up some data just to find out what the Me2B Deal is in the first place? \u003c/p\u003e\n\n\n\n\u003cp\u003eAbby’s other IA principles flow from the above considerations. A \u003cstrong\u003eUseful\u003c/strong\u003e product is one that does what it claims to do and communicates the deal you get clearly and accessibly. A \u003cstrong\u003eCredible\u003c/strong\u003e product is one that treats the user with respect and communicates its value. With user \u003cstrong\u003eControl\u003c/strong\u003e over data sharing and a clear understanding of the service being offered, the true \u003cstrong\u003eValue\u003c/strong\u003e of the service is apparent.\u003c/p\u003e\n\n\n\n\u003cp\u003eOver time the user will come to expect notice of potential changes to commitment states and will have agency over making that choice. These “Helpful Patterns”—clear and discoverable notice of state changes and opt-in commitments—build trust and loyalty, leading to a \u003cstrong\u003eDelightful\u003c/strong\u003e, or at least a reassuring, experience for your users.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhat I’ve learned from working in the standards world is that Information Architecture Principles provide a solid framework for understanding digital relationships as well as structuring meaning. Because we aren’t just designing information spaces. We’re designing healthy relationships.\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\n\n\n\u003cp\u003e\u003csup\u003e1\u003c/sup\u003e Levinger, G. (1983). “Development and change.” In H.H. Kelley et al. (Eds.), \u003cem\u003eClose relationships (315–359). New York: W. H. Freeman and Company. \u003c/em\u003ehttps://www.worldcat.org/title/close-relationships/oclc/470636389\u003c/p\u003e\n\n\n\n\u003cp\u003e2  Asimov, I. (1950). \u003cem\u003eI, Robot\u003c/em\u003e. Gnome Press.\u003c/p\u003e\n\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2022-02-24T12:00:00Z",
  "modifiedTime": "2022-02-24T15:47:46Z"
}
