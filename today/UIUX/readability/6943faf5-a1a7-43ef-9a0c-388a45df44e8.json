{
  "id": "6943faf5-a1a7-43ef-9a0c-388a45df44e8",
  "title": "UX Strategies for Complex-Application Design",
  "link": "https://www.nngroup.com/articles/strategies-complex-application-design/?utm_source=rss\u0026utm_medium=feed\u0026utm_campaign=rss-syndication",
  "description": "UX in complex, specialized domains requires adapting familiar methods across the design lifecycle to address domain constraints and expert-user needs.",
  "author": "Kate Kaplan",
  "published": "Fri, 25 Jul 2025 17:00:00 +0000",
  "source": "https://www.nngroup.com/feed/rss/",
  "categories": [
    "Article"
  ],
  "byline": "Kate Kaplan",
  "length": 12894,
  "excerpt": "UX in complex, specialized domains requires adapting familiar methods across the design lifecycle to address domain constraints and expert-user needs.",
  "siteName": "Nielsen Norman Group",
  "favicon": "",
  "text": "Summary:  UX in complex, specialized domains requires adapting familiar methods across the design lifecycle to address domain constraints and expert-user needs. Complex applications — like those used in specialized domains such as healthcare, finance, or logistics — support nonlinear workflows, expert users, and high-stakes decisions. Designing them introduces new challenges for conventional UX methods, which remain valuable but often require thoughtful adaptation. Effective UX in complex domains depends on subtle, deliberate adjustments throughout the design process. The Design Lifecycle: A Quick Overview Understand Phase: Researching the Work, Not Just the User Explore Phase: Generating and Prototyping Ideas Within Constraints Materialize Phase: Testing and Refining in the Real World The Design Lifecycle: A Quick Overview The design-thinking process organizes product work into three high-level phases. Though these stages are cyclical and often overlapping, they provide a helpful structure for understanding where and how to adapt UX for complex applications: Understand: Investigate the problem space. Empathize with users, observe their environment, and define their needs within context. Explore: Generate ideas and translate them into early solutions. Brainstorm potential approaches and prototype quickly to test assumptions. Materialize: Refine and implement the best ideas. Test with users, iterate based on feedback, and guide the solution into real-world use. This article examines each phase through the lens of complex systems and specialized domains, offering practical strategies and examples to help teams design usable, resilient tools in high-stakes environments. Understand Phase: Researching the Work, Not Just the User In this first phase, we aim to empathize with users and define their needs. That goal becomes more complex when users are experts working within layered systems — where their decisions are shaped not only by personal goals but by institutional policies, specialized tools, and domain-specific reasoning. One of the central challenges is developing a deep understanding of the domain itself, not just the people in it. Many UX practitioners are trained to study users’ goals and behaviors, but in specialized domains, those behaviors are shaped by layers of jargon, constraints, and institutional logic. These factors, combined with limited access to expert users in regulated or high-pressure environments, make it difficult to form a complete picture through conventional research alone. A richer understanding of the work itself is required, which requires time, contextual immersion, and partnerships. Understand Phase: Strategies and Examples 1. Study the domain independent of the application or tasks. Before investigating how users interact with a particular system, step back and understand the broader domain in which that system operates. In complex environments, tools don’t exist in isolation. They support nuanced, often recursive decision making that’s deeply embedded in professional practice. Getting a handle on the goals, terminology, roles, and constraints of the domain creates a foundation for meaningful insights. For example, a practitioner designing software for hospital staff could incorporate discovery research centered on learning about hospital operations, clinical workflows, and medical protocols, before designing any specific features or flows. This might include shadowing nurses or attending clinical team meetings to understand how care decisions are made, what documentation is prioritized, and how people navigate institutional rules. 2. Conduct studies in the work environment. Understanding how users interact with a tool in isolation can leave important contextual gaps. Real-world conditions — such as environmental constraints, interruptions, shared equipment, or cross-team coordination — shape how systems are actually used. Observing work in its natural setting reveals these contextual factors and uncovers design considerations that might otherwise go unnoticed. For example, a practitioner designing a warehouse-management system could observe operations during active shifts to understand how workers move through space, operate handheld devices on the go, and coordinate across teams in loud, fast-paced environments. These details may directly influence design choices such as interface layout, notification timing, or visibility in variable lighting, that are difficult to anticipate from lab-based testing. 3. Combine multiple methods and involve additional key actors. In complex systems, no single person has the full picture. Effective research in these domains requires triangulating insight across methods (e.g., interviews, workflow mapping, observations) and roles (e.g., frontline users, supervisors, adjacent teams). This approach reveals not only how individuals interact with a system but also how work moves across people, tools, and organizational boundaries. For example, a designer working on a logistics platform might interview drivers to uncover field-level challenges and survey dispatchers to understand coordination workflows. They might also run a journey-mapping workshop with operations managers to visualize systemic pain points. Each role contributes a distinct view, and layering these perspectives helps uncover insights that might otherwise remain hidden. Explore Phase: Generating and Prototyping Ideas Within Constraints In the Explore phase, we begin to generate and shape design ideas. But for UX practitioners working on complex applications, this creative process can be unusually constrained. Unlike consumer-facing tools, complex systems often require compliance and deep integration with additional tools and domain-specific workflows. This makes ideation more difficult: Teams may hesitate to think broadly for fear of proposing something infeasible or unsafe. Prototyping is also more difficult: it’s rarely possible to simulate a real environment or build interactive models of full data-rich systems on a short timeline. And aligning stakeholders — especially when domain experts, product owners, and designers speak different languages — requires extra nuance. Strategies and Examples 1. Frame ideation with real-world constraints. Creative thinking is still critical in complex domains, but it thrives best when grounded in reality. Instead of treating constraints as obstacles, bring them into the ideation process as generative boundaries. Explicitly define what makes a solution viable (e.g., regulatory considerations, workflow integration, risk tolerance, and data needs) so teams can focus their creativity in the right direction. For example, a team designing a clinical decision-support tool might begin a design workshop by outlining key constraints drawn from medical guidelines, patient-privacy regulations, and documentation workflows. Framing the session this way helps generate ideas that are both creative and feasible, such as ways to surface critical alerts without causing alarm fatigue or to visualize diagnostic options without overwhelming the interface. 2. Prototype at the right level of fidelity. High-fidelity prototypes are often impractical during early concepting in complex systems. Instead, choose prototype forms that help answer your current questions without overcommitting to pixel-perfect designs. Sketches, storyboards, and clickable wireframes can be just as effective (or more so) for testing early assumptions. For example, when designing a dashboard for cybersecurity analysts, it may not be feasible to prototype live-data interactions early in the process. Instead, low-fidelity mockups can be used to simulate alert-escalation paths or triage workflows, allowing domain experts to walk through hypothetical scenarios. This approach helps refine how system signals are interpreted and how decisions are made without requiring a fully functional product or prototype. 3. Cocreate with domain experts. Bring domain experts into the design process. Domain experts can evaluate early ideas, spot gaps in logic, and validate whether proposed solutions support real tasks. Cocreation builds mutual understanding and helps ensure that your designs support the actual complexities of the work. For example, during the redesign of a supply-chain analytics tool, a team might hold a collaborative sketching session with a senior planner. The planner could be asked to diagram their current process, highlight points of friction, and respond to early design concepts. Their feedback might reveal, for instance, that a minor tweak to a data visualization could significantly reduce decision time. Materialize Phase: Testing and Refining in the Real World In the Materialize phase, we test our designs and begin implementation. But for complex applications, this step often reveals a gap between how we evaluate usability in theory and how systems are used in practice. One key challenge is recognizing domain-specific usability issues. Subtleties in how expert users interact with a system can be difficult to recognize without deep domain knowledge, even when issues appear during testing. Compounding this, traditional evaluation methods (like task-based usability testing) weren’t built for the complex, highly variable, cognitively demanding work of expert users. It can be difficult to both observe and understand the work. Finally, recruiting expert users for testing is a consistent barrier, as these users are often in high-demand roles and have limited availability. Strategies and Examples 1. Adapt existing evaluation methods. Methods like task-based usability testing are still valuable, but they may need small adaptations. In complex domains, evaluations may benefit from methods that uncover reasoning and judgment, such as enhanced discussion between the researcher and user, scenario-based interviews, or longer contextual-observation sessions. The goal is to assess not just usability but usefulness and alignment with domain expectations. For example, a team working on a financial-risk-analysis tool might present users with a real-world scenario — such as evaluating a high-risk loan or responding to market volatility — and ask them to walk through how they would interpret and act on the data presented. Rather than focusing on whether users complete a task correctly, the team observes how the users reason through the decision, what cues they rely on, and whether the interface supports that thinking. This approach can uncover mismatches between the system’s structure and how domain experts actually make decisions. 2. Elicit domain expertise through collaboration. Practitioners don’t need to become domain experts, but they do need partners bringing domain expertise into the process. Expert users and domain partners can collaborate in cocreation and evaluation, helping interpret edge cases, flag unseen risks, or point out opportunities. This doesn't always mean formal testing; it could involve review sessions, workshops, or informal feedback loops. For example, when testing a scientific modeling interface, the team might invite a principal investigator to review how workflows are represented in the prototype. They may highlight crucial steps that are underrepresented or point out how their team’s mental models differ from what the UI assumes. Even short conversations with domain experts can prevent flawed assumptions from reaching production. 3. Break traditional testing rules when necessary. When recruiting expert users is difficult, be pragmatic. While standard usability guidance cautions against testing with internal staff or people who are overly knowledgeable about the system, these participants can provide valuable early-stage input, so long as their limitations are acknowledged and their feedback is later validated with actual end users when possible. For example, when building a command-line interface for DevOps engineers, a team might begin testing with internal technical staff who share relevant experience. Alternatively, a training session can double as an opportunity for structured feedback. These approaches may not offer perfect fidelity, but they can reveal foundational issues and opportunities for iteration. Conclusion Working on complex applications doesn’t require inventing a new UX process; it just requires refining the one you already have. Across all phases of the design lifecycle, the most effective teams adapt familiar methods to suit the realities of their domain by: Grounding research in real-world work Generating and shaping ideas within meaningful constraints Tailoring evaluation methods to reveal expert needs and reasoning Small but strategic shifts can help practitioners create usable, valuable, and trusted tools in even the most demanding environments.",
  "image": "https://media.nngroup.com/media/articles/opengraph_images/ComplexApps-Strategies_Opengraph_copy_9.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp\u003e\u003cspan\u003e\n                  Summary: \n                \u003c/span\u003eUX in complex, specialized domains requires adapting familiar methods across the design lifecycle to address domain constraints and expert-user needs.\n              \u003c/p\u003e\u003cdiv\u003e\n              \u003cp\u003e\u003ca href=\"https://www.nngroup.com/articles/complex-application-design-framework/\"\u003eComplex applications\u003c/a\u003e — like those used in specialized domains such as healthcare, finance, or logistics — support nonlinear workflows, expert users, and high-stakes decisions. Designing them introduces new challenges for conventional \u003ca href=\"https://www.nngroup.com/articles/research-methods-glossary/\"\u003eUX methods\u003c/a\u003e, which remain valuable but often require thoughtful adaptation. Effective UX in complex domains depends on subtle, deliberate adjustments throughout the design process.\u003c/p\u003e\n\u003cdiv\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-the-design-lifecycle-a-quick-overview-1\"\u003eThe Design Lifecycle: A Quick Overview\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-understand-phase-researching-the-work-not-just-the-user-2\"\u003eUnderstand Phase: Researching the Work, Not Just the User\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-explore-phase-generating-and-prototyping-ideas-within-constraints-3\"\u003eExplore Phase: Generating and Prototyping Ideas Within Constraints\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-materialize-phase-testing-and-refining-in-the-real-world-4\"\u003eMaterialize Phase: Testing and Refining in the Real World\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003ch2 id=\"toc-the-design-lifecycle-a-quick-overview-1\"\u003eThe Design Lifecycle: A Quick Overview\u003c/h2\u003e\n\u003cp\u003eThe \u003ca href=\"https://www.nngroup.com/articles/design-thinking/\"\u003edesign-thinking process\u003c/a\u003e organizes product work into three high-level phases. Though these stages are cyclical and often overlapping, they provide a helpful structure for understanding where and how to adapt UX for complex applications:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003cem\u003eUnderstand\u003c/em\u003e\u003c/strong\u003e\u003cstrong\u003e:\u003c/strong\u003e Investigate the problem space. Empathize with users, observe their environment, and define their needs within context.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003cem\u003eExplore\u003c/em\u003e\u003c/strong\u003e\u003cstrong\u003e:\u003c/strong\u003e Generate ideas and translate them into early solutions. Brainstorm potential approaches and prototype quickly to test assumptions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003cem\u003eMaterialize\u003c/em\u003e\u003c/strong\u003e\u003cstrong\u003e:\u003c/strong\u003e Refine and implement the best ideas. Test with users, iterate based on feedback, and guide the solution into real-world use.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis article examines each phase through the lens of complex systems and specialized domains, offering practical strategies and examples to help teams design usable, resilient tools in high-stakes environments.\u003c/p\u003e\n\u003ch2 id=\"toc-understand-phase-researching-the-work-not-just-the-user-2\"\u003eUnderstand Phase: Researching the Work, Not Just the User\u003c/h2\u003e\n\u003cp\u003eIn this first phase, we aim to empathize with users and define their needs. That goal becomes more complex when users are experts working within layered systems — where their decisions are shaped not only by personal goals but by institutional policies, specialized tools, and domain-specific reasoning. One of the central challenges is developing a deep understanding of the domain itself, not just the people in it.\u003c/p\u003e\n\u003cp\u003eMany UX practitioners are trained to study users’ goals and behaviors, but in specialized domains, those behaviors are shaped by layers of jargon, constraints, and institutional logic. These factors, combined with limited access to expert users in regulated or high-pressure environments, make it difficult to form a complete picture through conventional research alone. A richer understanding of the work itself is required, which requires time, contextual immersion, and partnerships.\u003c/p\u003e\n\u003ch3\u003eUnderstand Phase: Strategies and Examples\u003c/h3\u003e\n\u003ch4\u003e1. Study the domain independent of the application or tasks.\u003c/h4\u003e\n\u003cp\u003eBefore investigating how users interact with a particular system, step back and understand the broader domain in which that system operates. In complex environments, tools don’t exist in isolation. They support nuanced, often recursive decision making that’s deeply embedded in professional practice. Getting a handle on the goals, terminology, roles, and constraints of the domain creates a foundation for meaningful insights.\u003c/p\u003e\n\u003cp\u003eFor example,\u003cstrong\u003e \u003c/strong\u003ea practitioner designing software for hospital staff could incorporate discovery research centered on learning about hospital operations, clinical workflows, and medical protocols, before designing any specific features or flows. This might include shadowing nurses or attending clinical team meetings to understand how care decisions are made, what documentation is prioritized, and how people navigate institutional rules.\u003c/p\u003e\n\u003ch4\u003e2. Conduct studies in the work environment.\u003c/h4\u003e\n\u003cp\u003eUnderstanding how users interact with a tool in isolation can leave important contextual gaps. Real-world conditions — such as environmental constraints, interruptions, shared equipment, or cross-team coordination — shape how systems are actually used. Observing work in its natural setting reveals these contextual factors and uncovers design considerations that might otherwise go unnoticed.\u003c/p\u003e\n\u003cp\u003eFor example, a practitioner designing a warehouse-management system could observe operations during active shifts to understand how workers move through space, operate handheld devices on the go, and coordinate across teams in loud, fast-paced environments. These details may directly influence design choices such as interface layout, notification timing, or visibility in variable lighting, that are difficult to anticipate from lab-based testing.\u003c/p\u003e\n\u003ch4\u003e3. Combine multiple methods and involve additional key actors.\u003c/h4\u003e\n\u003cp\u003eIn complex systems, no single person has the full picture. Effective research in these domains requires triangulating insight across methods (e.g., interviews, workflow mapping, observations) and roles (e.g., frontline users, supervisors, adjacent teams). This approach reveals not only how individuals interact with a system but also how work moves across people, tools, and organizational boundaries.\u003c/p\u003e\n\u003cp\u003eFor example, a designer working on a logistics platform might interview drivers to uncover field-level challenges and survey dispatchers to understand coordination workflows. They might also run a \u003ca href=\"https://www.nngroup.com/articles/journey-mapping-workshop/\"\u003ejourney-mapping workshop\u003c/a\u003e with operations managers to visualize systemic pain points. Each role contributes a distinct view, and layering these perspectives helps uncover insights that might otherwise remain hidden.\u003c/p\u003e\n\u003ch2 id=\"toc-explore-phase-generating-and-prototyping-ideas-within-constraints-3\"\u003eExplore Phase: Generating and Prototyping Ideas Within Constraints\u003c/h2\u003e\n\u003cp\u003eIn the \u003cem\u003eExplore\u003c/em\u003e phase, we begin to generate and shape design ideas. But for UX practitioners working on complex applications, this creative process can be unusually constrained. Unlike consumer-facing tools, complex systems often require compliance and deep integration with additional tools and domain-specific workflows.\u003c/p\u003e\n\u003cp\u003eThis makes \u003ca href=\"https://www.nngroup.com/articles/ux-ideation/\"\u003eideation\u003c/a\u003e more difficult: Teams may hesitate to think broadly for fear of proposing something infeasible or unsafe. \u003ca href=\"https://www.nngroup.com/topic/prototyping/\"\u003ePrototyping\u003c/a\u003e is also more difficult: it’s rarely possible to simulate a real environment or build interactive models of full data-rich systems on a short timeline. And \u003ca href=\"https://www.nngroup.com/courses/stakeholder-relationships/\"\u003ealigning stakeholders\u003c/a\u003e — especially when domain experts, product owners, and designers speak different languages — requires extra nuance.\u003c/p\u003e\n\u003ch3\u003eStrategies and Examples\u003c/h3\u003e\n\u003ch4\u003e\u003cstrong\u003e1. Frame ideation with real-world constraints.\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eCreative thinking is still critical in complex domains, but it thrives best when grounded in reality. Instead of treating \u003ca href=\"https://www.nngroup.com/videos/positive-constraints-in-ux-work/\"\u003econstraints\u003c/a\u003e as obstacles, bring them into the ideation process as generative boundaries. Explicitly define what makes a solution viable (e.g., regulatory considerations, workflow integration, risk tolerance, and data needs) so teams can focus their creativity in the right direction.\u003c/p\u003e\n\u003cp\u003eFor example, a team designing a clinical decision-support tool might begin a design workshop by outlining key constraints drawn from medical guidelines, patient-privacy regulations, and documentation workflows. Framing the session this way helps generate ideas that are both creative and feasible, such as ways to surface critical alerts without causing alarm fatigue or to visualize diagnostic options without overwhelming the interface.\u003c/p\u003e\n\u003ch4\u003e\u003cstrong\u003e2. Prototype at the right level of fidelity.\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/articles/ux-prototype-hi-lo-fidelity/\"\u003eHigh-fidelity prototypes\u003c/a\u003e are often impractical during early concepting in complex systems. Instead, choose prototype forms that help answer your current questions without overcommitting to pixel-perfect designs. \u003ca href=\"https://www.nngroup.com/articles/how-to-get-stakeholders-to-sketch/\"\u003eSketches\u003c/a\u003e, \u003ca href=\"https://www.nngroup.com/articles/storyboards-visualize-ideas/\"\u003estoryboards\u003c/a\u003e, and clickable \u003ca href=\"https://www.nngroup.com/articles/draw-wireframe-even-if-you-cant-draw/\"\u003ewireframes\u003c/a\u003e can be just as effective (or more so) for testing early assumptions.\u003c/p\u003e\n\u003cp\u003eFor example, when designing a dashboard for cybersecurity analysts, it may not be feasible to prototype live-data interactions early in the process. Instead, low-fidelity mockups can be used to simulate alert-escalation paths or triage workflows, allowing domain experts to walk through hypothetical scenarios. This approach helps refine how system signals are interpreted and how decisions are made without requiring a fully functional product or prototype.\u003c/p\u003e\n\u003ch4\u003e\u003cstrong\u003e3. Cocreate with domain experts.\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eBring domain experts into the design process. Domain experts can evaluate early ideas, spot gaps in logic, and validate whether proposed solutions support real tasks. Cocreation builds mutual understanding and helps ensure that your designs support the actual complexities of the work.\u003c/p\u003e\n\u003cp\u003eFor example, during the redesign of a supply-chain analytics tool, a team might hold a collaborative sketching session with a senior planner. The planner could be asked to diagram their current process, highlight points of friction, and respond to early design concepts. Their feedback might reveal, for instance, that a minor tweak to a data visualization could significantly reduce decision time.\u003c/p\u003e\n\u003ch2 id=\"toc-materialize-phase-testing-and-refining-in-the-real-world-4\"\u003eMaterialize Phase: Testing and Refining in the Real World\u003c/h2\u003e\n\u003cp\u003eIn the \u003cem\u003eMaterialize\u003c/em\u003e phase, we test our designs and begin implementation. But for complex applications, this step often reveals a gap between how we evaluate \u003ca href=\"https://www.nngroup.com/videos/usability-101/\"\u003eusability\u003c/a\u003e in theory and how systems are used in practice.\u003c/p\u003e\n\u003cp\u003eOne key challenge is recognizing domain-specific usability issues. Subtleties in how expert users interact with a system can be difficult to recognize without deep domain knowledge, even when issues appear during testing. Compounding this, traditional evaluation methods (like \u003ca href=\"https://www.nngroup.com/articles/usability-testing-101/\"\u003etask-based usability testing\u003c/a\u003e) weren’t built for the complex, highly variable, cognitively demanding work of expert users. It can be difficult to both observe and understand the work.\u003c/p\u003e\n\u003cp\u003eFinally, \u003ca href=\"https://www.nngroup.com/videos/recruiting-expert-users-usability-study-participants/\"\u003erecruiting expert users\u003c/a\u003e for testing is a consistent barrier, as these users are often in high-demand roles and have limited availability.\u003c/p\u003e\n\u003ch3\u003eStrategies and Examples\u003c/h3\u003e\n\u003ch4\u003e1. Adapt existing evaluation methods.\u003c/h4\u003e\n\u003cp\u003eMethods like task-based usability testing are still valuable, but they may need small adaptations. In complex domains, evaluations may benefit from methods that uncover reasoning and judgment, such as enhanced discussion between the researcher and user, scenario-based interviews, or longer \u003ca href=\"https://www.nngroup.com/articles/contextual-inquiry/\"\u003econtextual-observation\u003c/a\u003e sessions. The goal is to assess not just usability but usefulness and alignment with domain expectations.\u003c/p\u003e\n\u003cp\u003eFor example, a team working on a financial-risk-analysis tool might present users with a real-world scenario — such as evaluating a high-risk loan or responding to market volatility — and ask them to walk through how they would interpret and act on the data presented. Rather than focusing on whether users complete a task correctly, the team observes how the users reason through the decision, what cues they rely on, and whether the interface supports that thinking. This approach can uncover mismatches between the system’s structure and how domain experts actually make decisions.\u003c/p\u003e\n\u003ch4\u003e2. Elicit domain expertise through collaboration.\u003c/h4\u003e\n\u003cp\u003ePractitioners don’t need to become domain experts, but they do need partners bringing domain expertise into the process. Expert users and domain partners can collaborate in cocreation and evaluation, helping interpret edge cases, flag unseen risks, or point out opportunities. This doesn\u0026#39;t always mean formal testing; it could involve review sessions, workshops, or informal feedback loops.\u003c/p\u003e\n\u003cp\u003eFor example, when testing a scientific modeling interface, the team might invite a principal investigator to review how workflows are represented in the prototype. They may highlight crucial steps that are underrepresented or point out how their team’s \u003ca href=\"https://www.nngroup.com/articles/mental-models/\"\u003emental models\u003c/a\u003e differ from what the UI assumes. Even short conversations with domain experts can prevent flawed assumptions from reaching production.\u003c/p\u003e\n\u003ch4\u003e3. Break traditional testing rules when necessary.\u003c/h4\u003e\n\u003cp\u003eWhen recruiting expert users is difficult, be pragmatic. While standard usability guidance cautions against \u003ca href=\"https://www.nngroup.com/articles/testing-expert-users/\"\u003etesting with internal staff\u003c/a\u003e or people who are overly knowledgeable about the system, these participants can provide valuable early-stage input, so long as their limitations are acknowledged and their feedback is later validated with actual end users when possible.\u003c/p\u003e\n\u003cp\u003eFor example, when building a command-line interface for DevOps engineers, a team might begin testing with internal technical staff who share relevant experience. Alternatively, a training session can double as an opportunity for structured feedback. These approaches may not offer perfect fidelity, but they can reveal foundational issues and opportunities for iteration.\u003c/p\u003e\n\u003ch3\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eWorking on complex applications doesn’t require inventing a new UX process; it just requires refining the one you already have. Across all phases of the design lifecycle, the most effective teams adapt familiar methods to suit the realities of their domain by:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGrounding research in real-world work\u003c/li\u003e\n\u003cli\u003eGenerating and shaping ideas within meaningful constraints\u003c/li\u003e\n\u003cli\u003eTailoring evaluation methods to reveal expert needs and reasoning\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSmall but strategic shifts can help practitioners create usable, valuable, and trusted tools in even the most demanding environments.\u003c/p\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "14 min read",
  "publishedTime": "2025-07-25T17:00:00Z",
  "modifiedTime": null
}
