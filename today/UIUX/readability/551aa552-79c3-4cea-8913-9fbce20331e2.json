{
  "id": "551aa552-79c3-4cea-8913-9fbce20331e2",
  "title": "Screening Participants for User-Research Studies",
  "link": "https://www.nngroup.com/articles/screening-participants/",
  "description": "Well-written screeners ensure that your study participants are appropriate for your research goals, improve data quality, save resources, and reduce bias.",
  "author": "Maddie Brown",
  "published": "Fri, 01 Nov 2024 17:00:00 +0000",
  "source": "https://www.nngroup.com/feed/rss/",
  "categories": [
    "Article"
  ],
  "byline": "Maddie Brown",
  "length": 12063,
  "excerpt": "Well-written screeners ensure that your study participants are appropriate for your research goals, improve data quality, save resources, and reduce bias.",
  "siteName": "Nielsen Norman Group",
  "favicon": "",
  "text": "Summary:  Well-written screeners ensure that your study participants are appropriate for your research goals, improve data quality, save resources, and reduce bias. There is no worse feeling for a researcher than realizing in the middle of a research session that the data is invalid because the participant is a bad match. Avoid this disaster by using a screener to recruit the right participants for your study. What Is a Screener? Benefits of a Research Screener Best Practices for Creating Effective Screeners Common Mistakes A Note on Synchronous Screeners What Is a Screener? Conducting user research is one of the most effective ways to ensure that the solution you’re designing will serve the needs of the end users. However, it works only if you can find the right test participants. By “right test participants,” I mean actual users of your product or representative users who mimic the demographic and behavioral characteristics of your users. Using a screener is the best and easiest way to ensure that you are conducting research with the right users. A screener is a set of questions, typically delivered verbally or via written questionnaire, used to establish that a prospective participant is a good fit for a given research project. Benefits of a Research Screener Utilizing a research screener every time you conduct user research will yield several valuable benefits. Screeners Ensure Relevance You want to be designing for the right audience. Whether you are designing an airplane cockpit or a user dashboard for a mortgage-lending app, the content and functionality should be customized to suit your end users’ unique needs and preferences. For that reason, it is almost never appropriate to conduct testing with “just anyone,” as the results of that research will not be relevant to the product in question. Screeners ensure that users involved in research are relevant to your product and research questions, which, in turn, ensures that the findings are valid. Screeners Ensure Data Quality Some individuals are excellent research participants. They are forthcoming with their thoughts and opinions, skilled at articulating complex reactions, and eager to help you find answers to your research questions. Others are not. A participant who provides only one-word responses, shrugging their way through interviews and speeding through tasks in order to reach the finish line as quickly as possible will not provide you with valuable or high-quality data. A well-designed screener can weed out some of these participants. Screeners Save Time and Money Without a screener, a researcher will find out if the participant is right for their study only after the study session has started. A well-designed screener prevents wasted time and resources. Screeners Reduce Bias Without an effective screener, research is open to various forms of bias. For example, the audience of people who voluntarily join a research panel (like those accessible through UserTesting.com or User Interviews) tends to include many IT professionals and other individuals who are significantly more web-savvy than the average person. Testing exclusively with these participants can lead to bias and yield incorrect insights. Best Practices for Creating Effective Screeners The following best practices ensure a representative participant sample in your user research. 1. Define Inclusion and Exclusion Criteria The first step in creating any research screener is to define your goals. Who do you want to include in your research? And, just as importantly, who do you not want to include? Think of both inclusion criteria (factors that would make someone a good fit for a study), and exclusion criteria (disqualifying factors) The more narrowly you define your participant pool, the harder it will be to find the right people, so focus on the attributes that are critical to getting reliable answers to your research questions. Typically, behavioral and demographic characteristics will be the most important to consider. Behavioral characteristics: Consider your target users. What behaviors do they have in common? What do they do? What are their common interests and passions? What are their shopping or media-consumption habits? Make a list of the behavioral traits most relevant to your research questions. Demographic characteristics: Demographic characteristics are typically less important than behavioral characteristics but are still worth considering. If there are demographic traits that describe your target audience (e.g., senior citizens), add those to your list as well. Additionally, in studies that test a particular user interface, we often exclude people working in UX, marketing, or IT (as these people could be experts at analyzing user interfaces and, thus, not representative of your target users). Other factors to keep in mind include: Technology ownership and usage: Are you planning on testing a native Android app? A Mac app? A Chrome extension? Recruit participants who regularly use the technology or device in question. Past research participation: Using the same research participants in multiple studies might lead to biased results. (There are a few exceptions — for example, if you are following the behaviors of the same cohort over time.) Additionally, avoid using “professional testers” — people who make their living by participating in research studies. These people are frequently found in research panels and tend to behave differently than the general population. 2. Focus on Past Behaviors, Not Predictions When conducting user research, we often want to find people who would use a product or service that does not currently exist. It can be tempting, therefore, to ask directly, “Would you use product X?” Avoid this temptation. Users are notoriously unreliable at predicting their future behaviors. They may be inaccurate for a number of reasons, including a genuine misestimation, an attempt to flatter the researcher, or an attempt to lie their way into a paid research opportunity. Instead, focus on relevant past behaviors. Rather than asking whether they would use a product in the future, ask whether they’ve used a similar product in the past. 3. Avoid Yes/No Questions Many prospective participants want to be part of the study and may be willing to lie to get there. They may try to guess the purpose of the study and answer your screener so that they seem to match it. In particular, the intent behind Yes/no questions is usually easy to guess. For example, imagine you are recruiting Amazon shoppers for a study. Consider the following suboptimal screener question: ❌ Do you shop at Amazon? Yes (accept) No (reject) A prospective participant could reasonably assume that researchers are recruiting Amazon shoppers, and respond Yes, whether or not that was honest. Consider this alternative series of questions. How many times have you shopped online in the past month? 0 times (reject) 1-5 times (proceed to Q2) 6-10 times (proceed to Q2) 11+ times (proceed to Q2) Which of the following sites have you used to shop online in the past month? (select all that apply) Zappos (may select) eBay (may select) Shein (may select) Amazon (must select) Temu (may select) None of the above (reject)  With such two-question series, it is much more difficult to game the screener and falsify answers. 4. Avoid Leading Questions Leading questions favor a particular response and, thus, produce inaccurate data. In screeners, they can also reveal the purpose of the research, and participants may use this information to consciously game the screener (and, if recruited, to even modify their behavior during the study to match their mental model for the study) . Consider leveraging the funnel technique to avoid inadvertently revealing the study purpose. Start with the broadest, least revealing questions before asking specific questions that may reveal some of the researchers’ intent. ❌ Leading Question ✅ Funnel Technique How often do you use our app’s new health-tracking features to improve your fitness? What apps or tools do you currently use to track your fitness or health? Which features in these apps do you find most helpful for tracking your progress? Have you used our app’s health-tracking features? If so, how have they worked for you? 5. Consider Including a Few Open-Ended Questions While you should be cautious about overusing open-ended questions in surveys because they can increase the time and effort required from respondents, they serve a valuable purpose in a screener. Open-ended questions have two benefits. First, open-ended questions provide rich responses, giving the researcher a better picture of the respondents and enabling them to select good fits. Second, open-ended questions can be an indicator of the effort that participants will apply to testing. If a participant responds to open-ended questions with nondescript, single-word responses, they might do so in a research setting, too. 6. Pilot Your Screener As with any survey, always pilot your screener prior to launching it. Testing your screener with a few individuals will typically catch a few issues ranging from typos, confusing/ambiguous wording, and issues with skip logic. Common Mistakes Overscreening It can be tempting to search for the perfect participant who matches every single behavioral and demographic characteristic of your target audience. In most cases, doing so will result in an overly restrictive screener that nobody will be able to pass. Remember, screen only for the criteria likely to impact your research questions. Use of Jargon or Overly Complex Language You and your colleagues are not the target audience for your screener. Avoid the use of jargon or other potentially confusing language. ❌ Do you have experience conducting ethnographic research for product ideation? ✅ In the past 12 months, how many times have you observed or interviewed people in their real-life settings to get ideas for new products? Ignoring Diversity in Demographics If you test only with able-bodied and neurotypical people who are tech-savvy and literate, you will likely be overlooking issues that affect a significant portion of the population. Consider screening for and including participants who are disabled, neurodiverse, have low literacy or low tech-savviness in order to ensure your product will be usable by your entire target audience, A Note on Synchronous Screeners Most screeners are delivered via a written, online survey. These are convenient, as they can easily be linked to from websites, emails, online ads, and social-media posts. Written screeners are often sufficient to filter out participants who don't meet basic criteria. However, a second screening step over the phone can be highly beneficial, particularly for questions that might reveal the purpose of the study or when assessing qualities that are hard to capture in writing. Since all questions in a written screener are typically visible upfront, participants may guess the purpose of the study and tailor their responses to fit. This can lead to biased participant selection. Over-the-phone screeners provide an opportunity to ask potentially revealing questions in a more conversational, indirect manner, reducing the chances that participants can guess the study’s intent and manipulate their answers. Additionally, over-the-phone screeners offer the advantage of assessing the participant’s communication style, which might affect the success of a research session. For example, if you need participants to clearly articulate their thoughts or provide detailed verbal feedback, a phone screener can ensure that a participant's communication style is a good match for the study. Keep phone screeners very short (2–5 minutes), as you will typically not compensate respondents for their time. Spend that time having them elaborate on their responses provided in the written screener and using your judgment to determine honesty and fit.",
  "image": "https://media.nngroup.com/media/articles/opengraph_images/Social-Card-Screening-opengraph.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp\u003e\u003cspan\u003e\n                  Summary: \n                \u003c/span\u003eWell-written screeners ensure that your study participants are appropriate for your research goals, improve data quality, save resources, and reduce bias.\n            \u003c/p\u003e\u003cdiv\u003e\n                \u003cp\u003eThere is no worse feeling for a researcher than realizing in the middle of a research session that the data is invalid because the participant is a bad match. Avoid this disaster by \u003ca href=\"https://www.nngroup.com/articles/screening-questions-select-research-participants/\"\u003eusing a screener\u003c/a\u003e to \u003ca href=\"https://www.nngroup.com/articles/recruiting-screening-research-candidates/\"\u003erecruit\u003c/a\u003e the right participants for your study.\u003c/p\u003e\n\u003cdiv\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-what-is-a-screener-1\"\u003eWhat Is a Screener?\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-benefits-of-a-research-screener-2\"\u003eBenefits of a Research Screener\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-best-practices-for-creating-effective-screeners-3\"\u003eBest Practices for Creating Effective Screeners\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-common-mistakes-4\"\u003eCommon Mistakes\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-a-note-on-synchronous-screeners-5\"\u003eA Note on Synchronous Screeners\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003ch2 id=\"toc-what-is-a-screener-1\"\u003eWhat Is a Screener?\u003c/h2\u003e\n\u003cp\u003eConducting user research is one of the most effective ways to ensure that the solution you’re designing will serve the needs of the end users. However, it works only if you can \u003cstrong\u003efind the right test participants.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eBy “right test participants,” I mean \u003cem\u003eactual\u003c/em\u003e users of your product or \u003cem\u003erepresentative \u003c/em\u003eusers who mimic the demographic and behavioral characteristics of your users. Using a screener is the best and easiest way to ensure that you are conducting research with the right users.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA \u003cstrong\u003escreener \u003c/strong\u003eis a set of questions, typically delivered verbally or via written questionnaire, used to establish that a prospective participant is a good fit for a given research project.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"toc-benefits-of-a-research-screener-2\"\u003eBenefits of a Research Screener\u003c/h2\u003e\n\u003cp\u003eUtilizing a research screener every time you conduct user research will yield several valuable benefits.\u003c/p\u003e\n\u003ch3\u003eScreeners Ensure Relevance\u003c/h3\u003e\n\u003cp\u003eYou want to be designing for the right audience. Whether you are designing an airplane cockpit or a user dashboard for a mortgage-lending app, the content and functionality should be customized to suit your end users’ unique needs and preferences.\u003c/p\u003e\n\u003cp\u003eFor that reason, it is almost never appropriate to conduct testing with “just anyone,” as the results of that research will not be relevant to the product in question. Screeners ensure that users involved in research are relevant to your product and research questions, which, in turn, ensures that the findings are valid.\u003c/p\u003e\n\u003ch3\u003eScreeners Ensure Data Quality\u003c/h3\u003e\n\u003cp\u003eSome individuals are excellent research participants. They are forthcoming with their thoughts and opinions, skilled at articulating complex reactions, and eager to help you find answers to your research questions. Others are not. A participant who provides only one-word responses, shrugging their way through interviews and speeding through tasks in order to reach the finish line as quickly as possible will not provide you with valuable or high-quality data. A well-designed screener can weed out some of these participants.\u003c/p\u003e\n\u003ch3\u003eScreeners Save Time and Money\u003c/h3\u003e\n\u003cp\u003eWithout a screener, a researcher will find out if the participant is right for their study only after the study session has started. A well-designed screener prevents wasted time and resources.\u003c/p\u003e\n\u003ch3\u003eScreeners Reduce Bias\u003c/h3\u003e\n\u003cp\u003eWithout an effective screener, research is open to various forms of bias. For example, the audience of people who voluntarily join a research panel (like those accessible through UserTesting.com or User Interviews) tends to include many IT professionals and other individuals who are significantly more web-savvy than the average person. Testing exclusively with these participants can lead to bias and yield incorrect insights.\u003c/p\u003e\n\u003ch2 id=\"toc-best-practices-for-creating-effective-screeners-3\"\u003eBest Practices for Creating Effective Screeners\u003c/h2\u003e\n\u003cp\u003eThe following best practices ensure a representative participant sample in your user research.\u003c/p\u003e\n\u003ch3\u003e1. Define Inclusion and Exclusion Criteria\u003c/h3\u003e\n\u003cp\u003eThe first step in creating any research screener is to define your goals. Who do you want to include in your research? And, just as importantly, who do you \u003cem\u003enot\u003c/em\u003e want to include? Think of both \u003cstrong\u003einclusion criteria\u003c/strong\u003e (factors that would make someone a good fit for a study), and \u003cstrong\u003eexclusion criteria\u003c/strong\u003e (disqualifying factors)\u003c/p\u003e\n\u003cp\u003eThe more narrowly you define your participant pool, the harder it will be to find the right people, so focus on the attributes that are critical to getting reliable answers to your research questions.\u003c/p\u003e\n\u003cp\u003eTypically, behavioral and demographic characteristics will be the most important to consider.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBehavioral characteristics:\u003c/strong\u003e Consider your target users. What behaviors do they have in common? What do they do? What are their common interests and passions? What are their shopping or media-consumption habits? Make a list of the behavioral traits most relevant to your research questions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDemographic characteristics: \u003c/strong\u003eDemographic characteristics are typically less important than behavioral characteristics but are still worth considering. If there are demographic traits that describe your target audience (e.g., senior citizens), add those to your list as well. Additionally, in studies that test a particular user interface, we often exclude people working in UX, marketing, or IT (as these people could be experts at analyzing user interfaces and, thus, not representative of your target users).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOther factors to keep in mind include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTechnology ownership and usage: \u003c/strong\u003eAre you planning on testing a native Android app? A Mac app? A Chrome extension? Recruit participants who regularly use the technology or device in question.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePast research participation:\u003c/strong\u003e Using the same research participants in multiple studies might lead to biased results. (There are a few exceptions — for example, if you are following the behaviors of the same cohort over time.) Additionally, avoid using “professional testers” — people who make their living by participating in research studies. These people are frequently found in research panels and tend to behave differently than the general population.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2. Focus on Past Behaviors, Not Predictions\u003c/h3\u003e\n\u003cp\u003eWhen conducting user research, we often want to find people who would use a product or service that does not currently exist. It can be tempting, therefore, to ask directly, “Would you use product X?”\u003c/p\u003e\n\u003cp\u003eAvoid this temptation. \u003ca href=\"https://www.nngroup.com/articles/first-rule-of-usability-dont-listen-to-users/\"\u003eUsers are notoriously unreliable at predicting their future behaviors.\u003c/a\u003e They may be inaccurate for a number of reasons, including a genuine misestimation, an attempt to flatter the researcher, or an attempt to lie their way into a paid research opportunity.\u003c/p\u003e\n\u003cp\u003eInstead, focus on relevant past behaviors. Rather than asking whether they \u003cem\u003ewould\u003c/em\u003e use a product in the future, ask whether they’ve used a similar product in the past.\u003c/p\u003e\n\u003ch3\u003e3. Avoid \u003cem\u003eYes/No\u003c/em\u003e Questions\u003c/h3\u003e\n\u003cp\u003eMany prospective participants want to be part of the study and may be willing to lie to get there. They may try to guess the purpose of the study and answer your screener so that they seem to match it.\u003c/p\u003e\n\u003cp\u003eIn particular, the intent behind \u003cem\u003eYes/no\u003c/em\u003e questions is usually easy to guess.\u003c/p\u003e\n\u003cp\u003eFor example, imagine you are recruiting Amazon shoppers for a study. Consider the following suboptimal screener question:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e❌ Do you shop at Amazon?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYes (accept)\u003c/li\u003e\n\u003cli\u003eNo (reject)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eA prospective participant could reasonably assume that researchers are recruiting Amazon shoppers, and respond \u003cem\u003eYes\u003c/em\u003e, whether or not that was honest.\u003c/p\u003e\n\u003cp\u003eConsider this alternative series of questions.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eHow many times have you shopped online in the past month?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e0 times (reject)\u003c/li\u003e\n\u003cli\u003e1-5 times (proceed to Q2)\u003c/li\u003e\n\u003cli\u003e6-10 times (proceed to Q2)\u003c/li\u003e\n\u003cli\u003e11+ times (proceed to Q2)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhich of the following sites have you used to shop online in the past month? (select all that apply)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eZappos (may select)\u003c/li\u003e\n\u003cli\u003eeBay (may select)\u003c/li\u003e\n\u003cli\u003eShein (may select)\u003c/li\u003e\n\u003cli\u003eAmazon (must select)\u003c/li\u003e\n\u003cli\u003eTemu (may select)\u003c/li\u003e\n\u003cli\u003eNone of the above (reject) \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWith such two-question series, it is much more difficult to game the screener and falsify answers.\u003c/p\u003e\n\u003ch3\u003e4. Avoid Leading Questions\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/articles/leading-questions/\"\u003eLeading questions favor a particular response and, thus, produce inaccurate data.\u003c/a\u003e In screeners, they can also reveal the purpose of the research, and participants may use this information to consciously game the screener (and, if recruited, to even modify their behavior during the study to match their \u003ca href=\"https://www.nngroup.com/articles/mental-models/\"\u003emental model\u003c/a\u003e for the study) .\u003c/p\u003e\n\u003cp\u003eConsider leveraging the \u003ca href=\"https://www.nngroup.com/articles/the-funnel-technique-in-qualitative-user-research/\"\u003efunnel technique\u003c/a\u003e to avoid inadvertently revealing the study purpose. Start with the broadest, least revealing questions before asking specific questions that may reveal some of the researchers’ intent.\u003c/p\u003e\n\u003ctable\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003e❌ Leading Question\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003e✅ Funnel Technique\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\n\u003cp\u003eHow often do you use our app’s new health-tracking features to improve your fitness?\u003c/p\u003e\n\n\u003c/td\u003e\n\u003ctd\u003e\n\u003cp\u003eWhat apps or tools do you currently use to track your fitness or health?\u003c/p\u003e\n\n\u003cp\u003eWhich features in these apps do you find most helpful for tracking your progress?\u003c/p\u003e\n\n\u003cp\u003eHave you used our app’s health-tracking features? If so, how have they worked for you?\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003ch3\u003e5. Consider Including a Few Open-Ended Questions\u003c/h3\u003e\n\u003cp\u003eWhile you should be cautious about overusing \u003ca href=\"https://www.nngroup.com/articles/open-ended-questions/\"\u003eopen-ended questions\u003c/a\u003e in surveys because they can increase the time and effort required from respondents, they serve a valuable purpose in a screener.\u003c/p\u003e\n\u003cp\u003eOpen-ended questions have two benefits. First, open-ended questions \u003cstrong\u003eprovide rich responses\u003c/strong\u003e, giving the researcher a better picture of the respondents and enabling them to select good fits.\u003c/p\u003e\n\u003cp\u003eSecond, open-ended questions can be an indicator of \u003cstrong\u003ethe effort that participants will apply to testing\u003c/strong\u003e. If a participant responds to open-ended questions with nondescript, single-word responses, they might do so in a research setting, too.\u003c/p\u003e\n\u003ch3\u003e6. Pilot Your Screener\u003c/h3\u003e\n\u003cp\u003eAs with any survey, always \u003ca href=\"https://www.nngroup.com/articles/pilot-testing/\"\u003epilot\u003c/a\u003e your screener prior to launching it. Testing your screener with a few individuals will typically catch a few issues ranging from typos, confusing/ambiguous wording, and issues with skip logic.\u003c/p\u003e\n\u003ch2 id=\"toc-common-mistakes-4\"\u003eCommon Mistakes\u003c/h2\u003e\n\u003ch3\u003eOverscreening\u003c/h3\u003e\n\u003cp\u003eIt can be tempting to search for the perfect participant who matches every single behavioral and demographic characteristic of your target audience.\u003c/p\u003e\n\u003cp\u003eIn most cases, doing so will result in an overly restrictive screener that nobody will be able to pass. Remember, screen only for the criteria likely to impact your research questions.\u003c/p\u003e\n\u003ch3\u003eUse of Jargon or Overly Complex Language\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/articles/false-consensus/\"\u003eYou and your colleagues are not the target audience\u003c/a\u003e for your screener. Avoid the use of \u003ca href=\"https://www.nngroup.com/articles/technical-jargon/\"\u003ejargon\u003c/a\u003e or other potentially confusing language.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e❌ Do you have experience conducting ethnographic research for product ideation?\u003c/p\u003e\n\u003cp\u003e✅ In the past 12 months, how many times have you observed or interviewed people in their real-life settings to get ideas for new products?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eIgnoring Diversity in Demographics\u003c/h3\u003e\n\u003cp\u003eIf you test only with able-bodied and neurotypical people who are tech-savvy and literate, you will likely be overlooking issues that affect a significant portion of the population.\u003c/p\u003e\n\u003cp\u003eConsider screening for and including participants who are disabled, neurodiverse, have low literacy or low tech-savviness in order to ensure your product will be usable by your entire target audience,\u003c/p\u003e\n\u003ch2 id=\"toc-a-note-on-synchronous-screeners-5\"\u003eA Note on Synchronous Screeners\u003c/h2\u003e\n\u003cp\u003eMost screeners are delivered via a written, online survey. These are convenient, as they can easily be linked to from websites, emails, online ads, and social-media posts. Written screeners are often sufficient to filter out participants who don\u0026#39;t meet basic criteria.\u003c/p\u003e\n\u003cp\u003eHowever, a second screening step over the phone can be highly beneficial, particularly for questions that might reveal the purpose of the study or when assessing qualities that are hard to capture in writing. Since all questions in a written screener are typically visible upfront, participants may guess the purpose of the study and tailor their responses to fit. This can lead to biased participant selection.\u003c/p\u003e\n\u003cp\u003eOver-the-phone screeners provide an opportunity to ask potentially revealing questions in a more conversational, indirect manner, reducing the chances that participants can guess the study’s intent and manipulate their answers.\u003c/p\u003e\n\u003cp\u003eAdditionally, over-the-phone screeners offer the advantage of assessing the participant’s communication style, which might affect the success of a research session. For example, if you need participants to clearly articulate their thoughts or provide detailed verbal feedback, a phone screener can ensure that a participant\u0026#39;s communication style is a good match for the study.\u003c/p\u003e\n\u003cp\u003eKeep phone screeners very short (2–5 minutes), as you will typically not compensate respondents for their time. Spend that time having them elaborate on their responses provided in the written screener and using your judgment to determine honesty and fit.\u003c/p\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2024-11-01T17:00:00Z",
  "modifiedTime": null
}
