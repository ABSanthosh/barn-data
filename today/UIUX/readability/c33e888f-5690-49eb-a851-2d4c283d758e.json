{
  "id": "c33e888f-5690-49eb-a851-2d4c283d758e",
  "title": "AI Is Here — Where Is Seaman?",
  "link": "https://uxdesign.cc/ai-is-here-where-is-seaman-cf548ca1b454?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Ben Hickman",
  "published": "Thu, 19 Jun 2025 11:50:01 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "creativity",
    "ai",
    "design",
    "gaming",
    "ux"
  ],
  "byline": "Ben Hickman",
  "length": 15144,
  "excerpt": "Before the panic about AI became an ambient hum in our daily lives, it arrived in stranger, funnier, more unsettling form. Before voice assistants became household fixtures and AI crept into the…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "AI is here — so where is Seaman?We need software and stories and tools that don’t promise utility but deliver unease.Image AI Generated (Midjourney)Before the panic about AI became an ambient hum in our daily lives, it arrived in stranger, funnier, more unsettling form. Before voice assistants became household fixtures and AI crept into the rhythms of our daily lives, long before Siri chimed in from the kitchen counter or Alexa responded to timers and trivia, a creature with the bored expression of a man trapped in a fish’s body invited you into a kind of relationship that felt, in its way, profoundly human in 1999.Then out of nowhere, he’d stare straight through you with the bemused detachment of a Lovecraftian therapist, asking why you’re still single, or whether you’re really happy with how your life is turning out.You adjusted water levels. You fed it crickets. You waited. And waited. There was a lot of waiting. Then out of nowhere, he’d stare straight through you with the bemused detachment of a Lovecraftian therapist, asking why you’re still single, or whether you’re really happy with how your life is turning out. It asked questions you weren’t ready to answer. One moment, it was inquiring whether you considered yourself a good parent; the next, it was interrupting your contemplative pause with a withering, “That hesitation says a lot.” All of a sudden you weren’t just playing a game anymore. You were having a conversation with something that looked like it had better things to do. The deeper you went, the weirder it got. It asked if you’d ever cheated on a test. If you asked it a philosophical question, it might redirect with a tone that wasn’t dodging the question so much as challenging your right to ask it in the first place — “Let’s not pretend you’ve thought that through.” The thing would even accuse you of being selfish or lazy, depending on how consistently you fed it. One player reported asking it if it believed in God, only for it to pause and respond: “I think that’s your problem, not mine.”Seman’s loading image and title artwork. Screencaptured from the Longplay YouTube video by MKM FeaturesThis was a game, this thing, was Seaman. The Sega DreamCast launch title asked you to raise a sort of aquatic homunculus from a gelatinous, fungal mass; the engagement didn’t come from spectacle, but from curiosity. The interactions felt banal — yet invasive, so — and by any standard, the game itself was undeniably dull and irritating, but in wholly unique ways. In 1999, just the concept of raising something so interactive felt groundbreaking, or at least strange — even in 1999 the experience felt painfully slow, a clunky novelty that felt both oddly intimate and hopelessly analog — like attending a weeklong couples retreat with a Magic 8-Ball. You could speak into a microphone, and Seaman would respond — docilely moving his oddly manlike face, causing his limp fish proboscis to drift in the water with his indifference. Sometimes Seaman would remember what you said, sometimes not, and that felt fitting. Storing details about your birthday or your habits, and calling them back days later in ways that felt unnervingly personal. The actual experience often felt like watching paint dry, but that was the point: the mundanity was the game. You had to feed it, clean the tank, and show up every day.Like an underwhlemed priest officiating your strange little ceremony of emotional projection, he’d guide you through something absurd, unsettling, and oddly touching.A mid-stage Seaman. Screencaptured from the Longplay YouTube video by MKM FeaturesWithout those rituals, the creature would weaken or die. And in a subtle, unspoken way, you would lose. Seaman wasn’t trying to thrill you. It was modeling something else entirely: the way real connection often grows not from excitement or novelty, but from shared routine. Research in the California Management Review (“Empowering AI Companions for Enhanced Relationship Marketing”) proves this out, how routine and predictability nurture our sense of closeness with AI. Seaman demonstrated that intimacy may take root in silence, awkwardness, and the slow accretion of moments. With Seaman, those moments were almost always unremarkable, but maybe that wasn’t his fault; he was stuck in a gaming system with less processing power than a first-generation Apple Watch.What if we brought Seaman’s scaffolding forward? With today’s language models — capable of tracking context, recalling past interactions, inferring intent with eerie precision — how much deeper might that companionship feel shaped by the wry detachment and bemused scrutiny of that amphibious curmudgeon? Imagine Seaman with a longer context window. Imagine it picking up on not just what you say, but how you say it — your hesitations, your habits, your moods. Imagine that voice interface no longer tethered to a toy microphone, but woven into the natural rhythms of your speech. The technology, at the time, was a limitation. But the emotional blueprint was already there floating behind Seaman’s dull, bored eyes. Would Seaman’s insights sharpen with time? Would his observations lean more toward the unsettling precision of a Hannibal Lecter type, or the blunt, earnest charm of a colleague whose honesty outpaces their social finesse? We may never know, and that’s a real shame.We need software and stories and tools that don’t promise utility but deliver unease.Screencaptured from the Longplay YouTube video by MKM FeaturesToday, we’d call it “artificial intimacy.” In the late ’90s, it was just weird — ’90s Japanese weird, which is a kind of S-tier weirdness all its own. Players projected emotional depth onto Seaman with surprising ease, responding with frustration, affection, even guilt. Sanders et al. (2024) show how that would resonate today, as people are quick to assign human traits to AI agents. That might have been Seaman’s masterstroke: tricking players into caring — it could have been the first game to be deeply engaging without being fun. Imagine Nimoy’s narration today — already tinged with gravitas and mischief — powered by a generative AI script, constantly adapting and reshaping itself to reflect Seaman’s wry, human-amphibious persona, reforming itself thousands of times a second, perceiving changes in how you speak and act, like an underwhlemed priest officiating your strange little ceremony of emotional projection, he’d guide you through something absurd, unsettling, and oddly touching, a smudged funhouse mirror held up to the way we reach out — to machines, but more accurately, to ourselves.Screencaptured from the Longplay YouTube video by MKM FeaturesWhat’s surprising is that Seaman hasn’t re-emerged — not as a rebooted game, but as an AI assistant visualization. It’s hard to imagine a more fitting avatar for the millennial condition: sarcastic, semi-capable, quietly falling apart. In an era when digital nostalgia sells everything from Tamagotchis to trauma-informed Slack bots, Seaman feels conspicuously absent. And yet, he embodies many of the qualities research now shows foster deeper emotional engagement with AI. Pataranutaporn et al. (2023) found that user trust and empathy are highly susceptible to framing — what’s called priming — and Seaman framed himself as fragile and worthy of care. The interface invited projection. Like the original ELIZA, it generated depth by daring users to imagine it. Lee et al. (2024) show that emotional ambiguity — that feeling of never quite knowing what the AI thinks — actually increases attachment. Seaman was built on ambiguity. He wasn’t smart. He was weird, needy, and occasionally rude. But in that friction, users found feeling. Zhu et al. (2023) call this the “uncanny emotional zone,” where an assistant is just realistic enough to connect, but odd enough to disturb. Most modern AI visualizations aim for the opposite: polished, pleasant, sterile. But Seaman thrived in the mess. In a world of ambient optimization and synthetic competence, maybe that’s why he deserves a second life — not as a mascot, but as a counterweight. A reminder that the best AI sometimes makes you feel a little worse, and remember it more.Yoot Saito, Photo by Kevin Krejci, Creative Commons LicenceBig Tech is not in danger of accidentally building the AI from Her. That’s not the real risk. The risk is that we’ve stopped building anything like Seaman — because we’ve grown too allergic to failure. Back in 1999, Seaman launched on the Dreamcast, blinked weirdly at players, and faded into obscurity just as quickly. Its creator, Yoot Saito, didn’t become a Twitter cautionary tale or the subject of a teardown on a growth podcast. Instead, he went on to make Odama — a tactical pinball game powered by voice commands — and Aero Porter, a baggage puzzle simulator with the soul of an air traffic controller. None of them were hits. But they weren’t meant to be. They were meant to be possible.That was Seaman. A digital amphibian therapist that somehow made you feel watched, judged, and weirdly understood.Today, a project like Seaman would be ridiculed before it even shipped — picked apart in pre-launch forums, roasted in hot takes, and dissected by product managers with too much time and not enough imagination before it shipped. We’d see Medium essays about “What Seaman’s Failure Teaches Us,” armchair critiques on product-market fit, and LinkedIn threads unraveling its failure like a case study. The bar for trying something weird has moved so high, and the margin for error so narrow, that the truly strange ideas rarely make it off the whiteboard. And yet, we need them. We need software and stories and tools that don’t promise utility but deliver unease. Experiences that aren’t optimized for frictionless outcomes but for emotional whiplash — the kind that makes you laugh, then squirm, then wonder what it all meant. That was Seaman. A digital amphibian therapist that somehow made you feel watched, judged, and weirdly understood. This article isn’t just nostalgia for a cult classic. It’s a critique of a culture that conflates durability with value and assumes that anything short-lived wasn’t worth making. But some work isn’t supposed to last. Some of it is meant to flicker for a moment, make us feel something new, then disappear — like a dream you can’t quite explain, but keep thinking about all day.A fully grown Seaman. Screencaptured from the Longplay YouTube video by MKM FeaturesWe’re in an age when AI can autocomplete your emails, mimic your voice, even spit out a decent haiku. These AI experiences are directed by product and marketing teams that go to great lengths not to unsettle their users. But how many of these AIs make you pause — not because they’re broken, but because they’re weird? That’s the bar Seaman set. Not competence, but presence. Not efficiency, but personality. If we want AI that resonates — deeply, uncomfortably, memorably — we have to let it be strange. Let it fail. Let it say the wrong thing. Let it ask for your birthday in a voice that sounds suspiciously like Spock then be oddly fixated on it.Today’s AI assistants are expected to behave like idealized coworkers — blandly helpful, perpetually upbeat, as if auditioning to be the ship’s computer on Star Trek or Scarlett Johansson in Her. But Seaman was never built to be likable. It was awkward, stilted, often accidentally insulting. It didn’t care if you felt heard. And yet, in the graveyard of defunct virtual assistants, Seaman’s headstone is better attended than Clippy’s. Maybe that says something uncomfortable. Maybe we don’t want the assistant who knows everything, won’t die, and can disarm a meeting with a dad joke. Maybe we don’t want to be the second most capable presence when we’re alone in a room — professionally or interpersonally. Gimmie the all-knowing AI, and I’ll try to take credit for its work in a product brief. But at speed dating? I want to follow Seaman. Seaman is just getting by, hanging on to survival by a thread, and too dumb to know it. He sucks. And somehow, that makes me feel better.I see a version of this play out with my six-year-old son. He’s just starting to realize that being capable is something people notice — and not being capable is something they really notice. When he can’t do something, it rattles him. Not because he expects to be perfect, but because he’s beginning to map his identity to his abilities. And it’s stressful, even at six. That same discomfort lingers in our relationship with AI. The boundary between our competence and the model’s is blurry and porous, where we end and it begins is sometimes hard to tell. But not with Seaman. Seaman never challenges our self-perception of value. He doesn’t threaten our relevance or question our value. The border between his abilities and ours is perfectly clear. Maybe that’s why we remember him so fondly. He gave us just enough weirdness to feel like we were talking to something other, without ever making us doubt who the real intelligence in the room was.Screencaptured from the Longplay YouTube video by MKM FeaturesCitationsChaturvedi, R., Verma, S., \u0026 Srivastava, V. (2023). Empowering AI Companions for Enhanced Relationship Marketing. California Management Review, 66(2), 65–90. https://doi.org/10.1177/00081256231215838 (Original work published 2024)Sanders, T., Li, M., \u0026 Ortega, R. (2024). Anthropomorphism and Empathy in AI-Driven Interfaces. Computers in Human Behavior. https://doi.org/10.1016/j.chb.2023.107765Pataranutaporn, P., Liu, R., Finn, E., \u0026 Maes, P. (2023). Influencing human–AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness. Nature Machine Intelligence, 5(10), 1076–1086. https://doi.org/10.1038/s42256-023-00720-7Lee, J., Kim, M., \u0026 Park, S. (2024). Emotional ambiguity and attachment in human–AI interactions: The paradox of uncertainty. Journal of Social and Personal Relationships. https://doi.org/10.1177/02654075241269688Zhu, H., Müller, V. C., Han, S., \u0026 Tu, J. (2023). When empathy backfires: The uncanny emotional zone in human-AI interaction. Proceedings of the 56th Hawaii International Conference on System Sciences. https://scholarspace.manoa.hawaii.edu/items/212bb300-c252-4441-aaaf-cb2951bb1943AcknowledgmentsThis article was shaped by a mix of personal reflection and discussions with colleagues, as well as sources from around the web. While I haven’t directly quoted from them, their efforts and perspective made this article possible:Sam Byford’s 2019 Verge article, “Seaman creator Yoot Saito on the fishy Dreamcast AI that was way ahead of its time: ‘A concept that was universally strange for men and women’”The Wikipedia entry on Yoot Saito, which provided background on his body of work beyond SeamanThe legendary Angry Video Game Nerd’s “Seaman (Dreamcast) — Angry Video Game Nerd (AVGN),” from 2015. A video essay by Cinemassacre, which helped capture the game’s surreal interface and enduring weirdnessAnd finally, a nostalgic conversation with my colleague Adam Lopez, who helped me remember just how unique and wonderful Seaman really was",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*K8Ibucwuxh8nb-X47G92eQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ch2 id=\"e823\" data-testid=\"storyTitle\"\u003eAI is here — so where is Seaman?\u003c/h2\u003e\u003c/p\u003e\u003cdiv\u003e\u003ch2 id=\"8e37\"\u003eWe need software and stories and tools that don’t promise utility but deliver unease.\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@benhickmandesign?source=post_page---byline--cf548ca1b454---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Ben Hickman\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*Lxx2XcAoDC4xYVAGt9cv3g.jpeg\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cfigure\u003e\u003cfigcaption\u003eImage AI Generated (Midjourney)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"0b0e\"\u003eBefore the panic about AI became an ambient hum in our daily lives, it arrived in stranger, funnier, more unsettling form. Before voice assistants became household fixtures and AI crept into the rhythms of our daily lives, long before Siri chimed in from the kitchen counter or Alexa responded to timers and trivia, a creature with the bored expression of a man trapped in a fish’s body invited you into a kind of relationship that felt, in its way, profoundly human in 1999.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"5d1a\"\u003eThen out of nowhere, he’d stare straight through you with the bemused detachment of a Lovecraftian therapist, asking why you’re still single, or whether you’re really happy with how your life is turning out.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"002f\"\u003eYou adjusted water levels. You fed it crickets. You waited. And waited. There was a lot of waiting. Then out of nowhere, he’d stare straight through you with the bemused detachment of a Lovecraftian therapist, asking why you’re still single, or whether you’re really happy with how your life is turning out. It asked questions you weren’t ready to answer. One moment, it was inquiring whether you considered yourself a good parent; the next, it was interrupting your contemplative pause with a withering, “That hesitation says a lot.” All of a sudden you weren’t just playing a game anymore. You were having a conversation with something that looked like it had better things to do. The deeper you went, the weirder it got. It asked if you’d ever cheated on a test. If you asked it a philosophical question, it might redirect with a tone that wasn’t dodging the question so much as challenging your right to ask it in the first place — “Let’s not pretend you’ve thought that through.” The thing would even accuse you of being selfish or lazy, depending on how consistently you fed it. One player reported asking it if it believed in God, only for it to pause and respond: “I think that’s your problem, not mine.”\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eSeman’s loading image and title artwork. Screencaptured from the\u003ca href=\"https://www.youtube.com/watch?v=Oq-SbNG4sy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e Longplay YouTube video\u003c/a\u003e by \u003ca href=\"https://www.youtube.com/@mkmfeatures\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMKM Features\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"ff07\"\u003eThis was a game, this thing, was \u003cem\u003eSeaman\u003c/em\u003e. The Sega DreamCast launch title asked you to raise a sort of aquatic homunculus from a gelatinous, fungal mass; the engagement didn’t come from spectacle, but from curiosity. The interactions felt banal — yet invasive, so — and by any standard, the game itself was undeniably dull and irritating, but in wholly unique ways. In 1999, just the concept of raising something so interactive felt groundbreaking, or at least strange — even in 1999 the experience felt painfully slow, a clunky novelty that felt both oddly intimate and hopelessly analog — like attending a weeklong couples retreat with a Magic 8-Ball. You could speak into a microphone, and Seaman would respond — docilely moving his oddly manlike face, causing his limp fish proboscis to drift in the water with his indifference. Sometimes Seaman would remember what you said, sometimes not, and that felt fitting. Storing details about your birthday or your habits, and calling them back days later in ways that felt unnervingly personal. The actual experience often felt like watching paint dry, but that was the point: the mundanity was the game. You had to feed it, clean the tank, and show up every day.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"6884\"\u003eLike an underwhlemed priest officiating your strange little ceremony of emotional projection, he’d guide you through something absurd, unsettling, and oddly touching.\u003c/p\u003e\u003c/blockquote\u003e\u003cfigure\u003e\u003cfigcaption\u003eA mid-stage Seaman. Screencaptured from the\u003ca href=\"https://www.youtube.com/watch?v=Oq-SbNG4sy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e Longplay YouTube video\u003c/a\u003e by \u003ca href=\"https://www.youtube.com/@mkmfeatures\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMKM Features\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"3a3f\"\u003eWithout those rituals, the creature would weaken or die. And in a subtle, unspoken way, you would lose. \u003cem\u003eSeaman\u003c/em\u003e wasn’t trying to thrill you. It was modeling something else entirely: the way real connection often grows not from excitement or novelty, but from shared routine. Research in the \u003cem\u003eCalifornia Management Review\u003c/em\u003e (“\u003ca href=\"https://journals.sagepub.com/doi/10.1177/00081256231215838\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eEmpowering AI Companions for Enhanced Relationship Marketing\u003c/a\u003e”) proves this out, how routine and predictability nurture our sense of closeness with AI. \u003cem\u003eSeaman\u003c/em\u003e demonstrated that intimacy may take root in silence, awkwardness, and the slow accretion of moments. With Seaman, those moments were almost always unremarkable, but maybe that wasn’t his fault; he was stuck in a gaming system with less processing power than a first-generation Apple Watch.\u003c/p\u003e\u003cp id=\"c126\"\u003eWhat if we brought Seaman’s scaffolding forward? With today’s language models — capable of tracking context, recalling past interactions, inferring intent with eerie precision — how much deeper might that companionship feel shaped by the wry detachment and bemused scrutiny of that amphibious curmudgeon? Imagine \u003cem\u003eSeaman\u003c/em\u003e with a longer context window. Imagine it picking up on not just what you say, but how you say it — your hesitations, your habits, your moods. Imagine that voice interface no longer tethered to a toy microphone, but woven into the natural rhythms of your speech. The technology, at the time, was a limitation. But the emotional blueprint was already there floating behind \u003cem\u003eSeaman’s\u003c/em\u003e dull, bored eyes. Would \u003cem\u003eSeaman’s\u003c/em\u003e insights sharpen with time? Would his observations lean more toward the unsettling precision of a Hannibal Lecter type, or the blunt, earnest charm of a colleague whose honesty outpaces their social finesse? We may never know, and that’s a real shame.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"a652\"\u003eWe need software and stories and tools that don’t promise utility but deliver unease.\u003c/p\u003e\u003c/blockquote\u003e\u003cfigure\u003e\u003cfigcaption\u003eScreencaptured from the\u003ca href=\"https://www.youtube.com/watch?v=Oq-SbNG4sy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e Longplay YouTube video\u003c/a\u003e by \u003ca href=\"https://www.youtube.com/@mkmfeatures\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMKM Features\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"59da\"\u003eToday, we’d call it “artificial intimacy.” In the late ’90s, it was just weird — ’90s Japanese weird, which is a kind of S-tier weirdness all its own. Players projected emotional depth onto Seaman with surprising ease, responding with frustration, affection, even guilt. Sanders et al. (2024) \u003ca href=\"https://doi.org/10.1016/j.chb.2023.107765\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eshow how that would resonate today\u003c/a\u003e, as people are quick to assign human traits to AI agents. That might have been \u003cem\u003eSeaman\u003c/em\u003e’s masterstroke: tricking players into caring — it could have been the first game to be deeply engaging without being fun. Imagine Nimoy’s narration today — already tinged with gravitas and mischief — powered by a generative AI script, constantly adapting and reshaping itself to reflect Seaman’s wry, human-amphibious persona, reforming itself thousands of times a second, perceiving changes in how you speak and act, like an underwhlemed priest officiating your strange little ceremony of emotional projection, he’d guide you through something absurd, unsettling, and oddly touching, a smudged funhouse mirror held up to the way we reach out — to machines, but more accurately, to ourselves.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eScreencaptured from the\u003ca href=\"https://www.youtube.com/watch?v=Oq-SbNG4sy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e Longplay YouTube video\u003c/a\u003e by \u003ca href=\"https://www.youtube.com/@mkmfeatures\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMKM Features\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"79bb\"\u003eWhat’s surprising is that Seaman hasn’t re-emerged — not as a rebooted game, but as an AI assistant visualization. It’s hard to imagine a more fitting avatar for the millennial condition: sarcastic, semi-capable, quietly falling apart. In an era when digital nostalgia sells everything from Tamagotchis to trauma-informed Slack bots, Seaman feels conspicuously absent. And yet, he embodies many of the qualities research now shows foster deeper emotional engagement with AI. \u003ca href=\"https://www.nature.com/articles/s42256-023-00720-7\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePataranutaporn et al. (2023)\u003c/a\u003e found that user trust and empathy are highly susceptible to framing — what’s called \u003cem\u003epriming\u003c/em\u003e — and Seaman framed himself as fragile and worthy of care. The interface invited projection. Like the original ELIZA, it generated depth by daring users to imagine it. \u003ca href=\"https://doi.org/10.1177/02654075241269688\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLee et al. (2024)\u003c/a\u003e show that emotional ambiguity — that feeling of never quite knowing what the AI thinks — actually increases attachment. Seaman was built on ambiguity. He wasn’t smart. He was weird, needy, and occasionally rude. But in that friction, users found feeling. \u003ca href=\"https://scholarspace.manoa.hawaii.edu/items/212bb300-c252-4441-aaaf-cb2951bb1943\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eZhu et al. (2023)\u003c/a\u003e call this the “uncanny emotional zone,” where an assistant is just realistic enough to connect, but odd enough to disturb. Most modern AI visualizations aim for the opposite: polished, pleasant, sterile. But Seaman thrived in the mess. In a world of ambient optimization and synthetic competence, maybe that’s why he deserves a second life — not as a mascot, but as a counterweight. A reminder that the best AI sometimes makes you feel a little worse, and remember it more.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eYoot Saito, Photo by \u003ca href=\"https://www.flickr.com/photos/kevinkrejci/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKevin Krejci\u003c/a\u003e, \u003ca href=\"https://creativecommons.org/licenses/by/2.0/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCreative Commons Licence\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"3fad\"\u003eBig Tech is not in danger of accidentally building the AI from \u003cem\u003eHer\u003c/em\u003e. That’s not the real risk. The risk is that we’ve stopped building anything like \u003cem\u003eSeaman\u003c/em\u003e — because we’ve grown too allergic to failure. Back in 1999, \u003cem\u003eSeaman\u003c/em\u003e launched on the Dreamcast, blinked weirdly at players, and faded into obscurity just as quickly. Its creator, Yoot Saito, didn’t become a Twitter cautionary tale or the subject of a teardown on a growth podcast. Instead, he went on to make \u003cem\u003eOdama\u003c/em\u003e — a tactical pinball game powered by voice commands — and \u003cem\u003eAero Porter\u003c/em\u003e, a baggage puzzle simulator with the soul of an air traffic controller. None of them were hits. But they weren’t meant to be. They were meant to be \u003cem\u003epossible\u003c/em\u003e.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"3279\"\u003eThat was \u003cem\u003eSeaman\u003c/em\u003e. A digital amphibian therapist that somehow made you feel watched, judged, and weirdly understood.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"afb8\"\u003eToday, a project like \u003cem\u003eSeaman\u003c/em\u003e would be ridiculed before it even shipped — picked apart in pre-launch forums, roasted in hot takes, and dissected by product managers with too much time and not enough imagination before it shipped. We’d see Medium essays about “What Seaman’s Failure Teaches Us,” armchair critiques on product-market fit, and LinkedIn threads unraveling its failure like a case study. The bar for trying something weird has moved so high, and the margin for error so narrow, that the truly strange ideas rarely make it off the whiteboard. And yet, we need them. We need software and stories and tools that don’t promise utility but deliver unease. Experiences that aren’t optimized for frictionless outcomes but for emotional whiplash — the kind that makes you laugh, then squirm, then wonder what it all meant. That was \u003cem\u003eSeaman\u003c/em\u003e. A digital amphibian therapist that somehow made you feel watched, judged, and weirdly understood. This article isn’t just nostalgia for a cult classic. It’s a critique of a culture that conflates durability with value and assumes that anything short-lived wasn’t worth making. But some work isn’t supposed to last. Some of it is meant to flicker for a moment, make us feel something new, then disappear — like a dream you can’t quite explain, but keep thinking about all day.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eA fully grown Seaman. Screencaptured from the\u003ca href=\"https://www.youtube.com/watch?v=Oq-SbNG4sy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e Longplay YouTube video\u003c/a\u003e by \u003ca href=\"https://www.youtube.com/@mkmfeatures\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMKM Features\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"004a\"\u003eWe’re in an age when AI can autocomplete your emails, mimic your voice, even spit out a decent haiku. These AI experiences are directed by product and marketing teams that go to great lengths not to unsettle their users. But how many of these AIs make you pause — not because they’re broken, but because they’re \u003cem\u003eweird\u003c/em\u003e? That’s the bar \u003cem\u003eSeaman\u003c/em\u003e set. Not competence, but presence. Not efficiency, but personality. If we want AI that resonates — deeply, uncomfortably, memorably — we have to let it be strange. Let it fail. Let it say the wrong thing. Let it ask for your birthday in a voice that sounds suspiciously like Spock then be oddly fixated on it.\u003c/p\u003e\u003cp id=\"97eb\"\u003eToday’s AI assistants are expected to behave like idealized coworkers — blandly helpful, perpetually upbeat, as if auditioning to be the ship’s computer on \u003cem\u003eStar Trek\u003c/em\u003e or Scarlett Johansson in \u003cem\u003eHer\u003c/em\u003e. But Seaman was never built to be likable. It was awkward, stilted, often accidentally insulting. It didn’t care if you felt heard. And yet, in the graveyard of defunct virtual assistants, \u003cem\u003eSeaman’s\u003c/em\u003e headstone is better attended than Clippy’s. Maybe that says something uncomfortable. Maybe we \u003cem\u003edon’t\u003c/em\u003e want the assistant who knows everything, won’t die, and can disarm a meeting with a dad joke. Maybe we don’t want to be the second most capable presence when we’re alone in a room — professionally or interpersonally. Gimmie the all-knowing AI, and I’ll try to take credit for its work in a product brief. But at speed dating? I want to follow Seaman. Seaman is just getting by, hanging on to survival by a thread, and too dumb to know it. He sucks. And somehow, that makes me feel better.\u003c/p\u003e\u003cp id=\"c7c6\"\u003eI see a version of this play out with my six-year-old son. He’s just starting to realize that being capable is something people notice — and not being capable is something they \u003cem\u003ereally\u003c/em\u003e notice. When he can’t do something, it rattles him. Not because he expects to be perfect, but because he’s beginning to map his identity to his abilities. And it’s stressful, even at six. That same discomfort lingers in our relationship with AI. The boundary between our competence and the model’s is blurry and porous, where we end and it begins is sometimes hard to tell. But not with Seaman. Seaman never challenges our self-perception of value. He doesn’t threaten our relevance or question our value. The border between his abilities and ours is perfectly clear. Maybe that’s why we remember him so fondly. He gave us just enough weirdness to feel like we were talking to something \u003cem\u003eother\u003c/em\u003e, without ever making us doubt who the real intelligence in the room was.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eScreencaptured from the\u003ca href=\"https://www.youtube.com/watch?v=Oq-SbNG4sy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e Longplay YouTube video\u003c/a\u003e by \u003ca href=\"https://www.youtube.com/@mkmfeatures\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMKM Features\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2 id=\"2fc1\"\u003eCitations\u003c/h2\u003e\u003cp id=\"16cb\"\u003eChaturvedi, R., Verma, S., \u0026amp; Srivastava, V. (2023). Empowering AI Companions for Enhanced Relationship Marketing. \u003cem\u003eCalifornia Management Review\u003c/em\u003e, \u003cem\u003e66\u003c/em\u003e(2), 65–90. \u003ca href=\"https://doi.org/10.1177/00081256231215838\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://doi.org/10.1177/00081256231215838\u003c/a\u003e (Original work published 2024)\u003c/p\u003e\u003cp id=\"cd87\"\u003eSanders, T., Li, M., \u0026amp; Ortega, R. (2024). \u003cem\u003eAnthropomorphism and Empathy in AI-Driven Interfaces\u003c/em\u003e. \u003cem\u003eComputers in Human Behavior\u003c/em\u003e. \u003ca href=\"https://doi.org/10.1016/j.chb.2023.107765\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://doi.org/10.1016/j.chb.2023.107765\u003c/a\u003e\u003c/p\u003e\u003cp id=\"2cfa\"\u003ePataranutaporn, P., Liu, R., Finn, E., \u0026amp; Maes, P. (2023). \u003cem\u003eInfluencing human–AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness\u003c/em\u003e. Nature Machine Intelligence, 5(10), 1076–1086. \u003ca href=\"https://doi.org/10.1038/s42256-023-00720-7\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://doi.org/10.1038/s42256-023-00720-7\u003c/a\u003e\u003c/p\u003e\u003cp id=\"9ad3\"\u003eLee, J., Kim, M., \u0026amp; Park, S. (2024). \u003cem\u003eEmotional ambiguity and attachment in human–AI interactions: The paradox of uncertainty\u003c/em\u003e. Journal of Social and Personal Relationships. \u003ca href=\"https://doi.org/10.1177/02654075241269688\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://doi.org/10.1177/02654075241269688\u003c/a\u003e\u003c/p\u003e\u003cp id=\"80b3\"\u003eZhu, H., Müller, V. C., Han, S., \u0026amp; Tu, J. (2023). \u003cem\u003eWhen empathy backfires: The uncanny emotional zone in human-AI interaction\u003c/em\u003e. Proceedings of the 56th Hawaii International Conference on System Sciences. \u003ca href=\"https://scholarspace.manoa.hawaii.edu/items/212bb300-c252-4441-aaaf-cb2951bb1943\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ehttps://scholarspace.manoa.hawaii.edu/items/212bb300-c252-4441-aaaf-cb2951bb1943\u003c/a\u003e\u003c/p\u003e\u003ch2 id=\"153a\"\u003eAcknowledgments\u003c/h2\u003e\u003cp id=\"f338\"\u003eThis article was shaped by a mix of personal reflection and discussions with colleagues, as well as sources from around the web. While I haven’t directly quoted from them, their efforts and perspective made this article possible:\u003c/p\u003e\u003cp id=\"4ff4\"\u003eSam Byford’s 2019 \u003cem\u003eVerge\u003c/em\u003e article, \u003cstrong\u003e“\u003c/strong\u003e\u003ca href=\"https://www.theverge.com/2019/9/6/20850674/yoot-saito-interview-seaman-sega-dreamcast-ai-20th-anniversary\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eSeaman creator Yoot Saito on the fishy Dreamcast AI that was way ahead of its time: ‘A concept that was universally strange for men and women\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e’”\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"5d03\"\u003eThe \u003ca href=\"https://en.wikipedia.org/wiki/Yoot_Saito\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eWikipedia entry on Yoot Saito\u003c/a\u003e, which provided background on his body of work beyond \u003cem\u003eSeaman\u003c/em\u003e\u003c/p\u003e\u003cp id=\"77f6\"\u003eThe legendary Angry Video Game Nerd’s \u003cstrong\u003e“\u003c/strong\u003e\u003ca href=\"https://www.youtube.com/watch?v=-IV8hCvsXy0\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eSeaman (Dreamcast) — Angry Video Game Nerd (AVGN)\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e,”\u003c/strong\u003e from 2015. A video essay by Cinemassacre, which helped capture the game’s surreal interface and enduring weirdness\u003c/p\u003e\u003cp id=\"cd36\"\u003eAnd finally, a nostalgic conversation with my colleague \u003ca href=\"https://www.linkedin.com/in/rectiform/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAdam Lopez\u003c/a\u003e, who helped me remember just how unique and wonderful \u003cem\u003eSeaman\u003c/em\u003e really was\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": "2025-06-17T11:01:40.668Z",
  "modifiedTime": null
}
