{
  "id": "16666570-d62b-4046-9793-df3cd1315933",
  "title": "Shaping minds: how first impressions drive AI adoption",
  "link": "https://uxdesign.cc/shaping-minds-how-first-impressions-drive-ai-adoption-632dd4c3e48c?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Tetiana Sydorenko",
  "published": "Wed, 15 Jan 2025 21:14:16 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "ai",
    "product-design",
    "ux",
    "artificle-intelligence",
    "marketing"
  ],
  "byline": "Tetiana Sydorenko",
  "length": 15682,
  "excerpt": "It takes only 10 seconds for someone to decide whether a website is worth their time or not. And while there is a wealth of resources on designing user-centered products, far fewer focus on how to…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Make-or-break moments. The first interaction with an AI system — whether it’s a website, landing page, or demo — shapes the mental model of the system. This, in turn, determines whether it will be adopted or not. Are these decisions driven by emotion or logic? Here’s how Technology Adoption Theory unpacks the mechanisms of technology acceptance, with insights applied to AI systems.By Katie Metz, sourceIt takes only 10 seconds for someone to decide whether a website is worth their time or not. And while there is a wealth of resources on designing user-centered products, far fewer focus on how to communicate their value during those pivotal first moments — the initial touchpoints that shape a user’s mental model of the system. This challenge is especially true for AI systems, which are often technically complex and hard to simplify. I’ve seen talented teams build extraordinary, user-focused solutions, only to struggle with conveying their true value in a way that’s clear, engaging, and instantly meaningful.This article delves into the psychological barriers to accepting and adopting new technologies, offering insights on how to highlight your product’s value and transform first impressions into lasting connections.New tech, old habitsHave you heard of Khanmigo? It’s an AI-driven teaching assistant from Khan Academy, designed to guide students through their learning journey with engaging, conversational interactions. It’s empathetic, engaging, and patient. Make a mistake? No problem. It’ll gently explain what went wrong and how to fix it, creating a learning experience that feels less like being corrected and more like growing together. It’s a glimpse into how AI can reinvent old patterns, making interactions more personal, more flexible, and, dare I say, more human.Of course, kids are a relatively easy audience for Khanmigo, as they are naturally open to such innovations. They don’t carry years of “learning fatigue,” forged by sitting through endless lectures and associating study time with boredom. AI meets them where they are, unspoiled and eager.Now imagine a different scenario: a car equipped with AI that tracks your facial expressions and eyelid movements to detect when you’re too tired to drive safely. It suggests, perhaps with a subtle alarm, that you pull over for a rest. Tell that to my grandpa, though, and he’d probably chuckle at the idea that a camera could know better than he does when he needs a break. There will always be early adopters — those eager to embrace the new and exciting — and those who resist, for reasons that may be logical or deeply personal. For instance, some might worry that AI will take their job, while others may mistrust the technology purely because it feels unfamiliar or intrusive. Understanding and addressing these perspectives is the first step towards designing AI systems that can bridge the gap between skepticism and acceptance.The good news? This isn’t a new challenge. Humanity has faced it during every industrial revolution, each time adapting its thinking to a new normal. While I won’t delve into all of these transformative eras — or the ongoing Fourth Industrial Revolution — I’d like to focus on the most recent completed one. Let’s rewind to the Third Industrial Revolution — the dawn of the computer and internet age in the late 20th century — and explore its key ideas of facilitating system adoption.When computers met humanityThe 1980s marked a significant turning point in the study of technology adoption, spurred by the rapid rise of personal computers and the challenge of integrating these new tools into everyday life. Researchers quickly recognized the need to focus on factors like user involvement in the design and implementation of information systems. This emphasis acknowledged a simple truth: technology is only as effective as its ability to meet the needs of the people who use it.1983, sourceOn the practical side, industry practitioners concentrated on developing and refining system designs, aiming to make them more user-friendly and effective. My favorite example is research at Xerox PARC (Palo Alto Research Center), where researchers closely observed office workers’ behaviors and workflows. Their insights led to the creation of the desktop metaphor, introducing familiar concepts like files, folders, and a workspace that mirrored physical desks. This innovation revolutionized graphical user interfaces (GUIs), laying the foundation for systems like Apple’s Macintosh and Microsoft Windows. The Dream Machine by M. Mitchell Waldrop or Dealers of Lightning by Michael Hiltzik share more details about history and impact of Xerox PARC.These parallel efforts — academic research and hands-on development — led to the creation of numerous theories and frameworks to better understand and guide technology adoption. Among these frameworks, the Technology Acceptance Model (TAM) stands out as one of the most influential.Technology Acceptance ModelBack in 1986, Fred Davis created it to answer a simple but pivotal question: why do some people adopt new technology while others resist? TAM was designed to measure this adoption process by focusing on customer attitudes — specifically, whether the technology feels useful and easy to use. These two factors form the foundation of the model, offering a lens to understand how people decide to embrace (or avoid) new tools and systems.The first factor, perceived usefulness — is how much a user believes the technology will improve their performance or productivity. It’s outcome-oriented, zeroing in on whether the tool helps users achieve their goals, complete tasks faster, or deliver better results.The second factor of TAM is perceived ease of use — the belief that using the technology will be simple and free of unnecessary effort. While usefulness might get a user’s attention, ease of use determines whether they’ll stick with it. If a system feels complicated, clunky, or overly technical, even its benefits might not be enough to win users over. People naturally gravitate toward tools that feel intuitive.Adapted from the Technology Acceptance Model (Davis, 1986), sourceIn 2000, Venkatesh and Davis expanded the original TAM model to dig deeper into what shapes Perceived Usefulness and people’s intentions to use technology. They introduced two key influences: social influence — how the opinions of others and societal norms impact adoption — and cognitive instrumental processes, which focus on how users mentally evaluate and connect with a system. Let’s unpack these factors and explore how they can help shape a mental model of an AI system that fosters adoption.Perceived UsefulnessPerceived Usefulness doesn’t exist in a vacuum. One of the social factors is subjective norm, or the pressure we feel from others to use (or not use) a particular technology. This ties closely to image, the way adopting a tool might enhance someone’s status or reputation — think of design influencers after attending Config, dissecting the latest features and showcasing their expertise.But subjective norm doesn’t impact everyone the same way. Experience can dull its influence. For those just starting with a new system, social pressure often holds more weight — unsure of their footing, they look to others for guidance. As they grow more comfortable, though, external opinions start to matter less, and their own evaluation takes over. Voluntariness also changes the game. When adoption is a choice, users are less swayed by others’ opinions. But when it’s required — whether by a workplace mandate or social obligation — subjective norm has a much stronger pull.On the cognitive side, job relevance plays a big role. Users ask, Does this technology actually help me in my specific role? If the answer is no, it’s unlikely they’ll see it as useful. Similarly, output quality — whether the system delivers results that meet or exceed expectations — reinforces its value. Finally, there’s result demonstrability, or how clearly the benefits of the technology can be observed and communicated. The easier it is to see and measure the impact, the more likely users are to view it as useful.Adapted from Technology Acceptance Model (TAM 2) by Venkatesh and Davis, 2000. sourceWhile product design can’t directly influence subjective norm, it often plays a role in shaping image — how people perceive themselves or imagine others will see them when they adopt the technology. It’s not so much about the product itself, but what using it says about the individual. By focusing on the right narrative from the very first touchpoint, some applications make it easy for users to see how adopting the tool reflects positively on them.Take folk.app, for instance. Instead of just listing features, it focuses on solving specific pain points, framing the app as a tool for staying organized and professional. The messages feels personal and practical. For example, a section title like “Sales research, done for you” suggests that without any additional effort, users will have valuable insights at their fingertips. It’s not just about solving a problem; it’s about positioning the user as more prepared, professional, and efficient.Braintrust takes a different angle. They highlight glowing media endorsements, signaling that the platform is widely recognised. It’s not just about saying that app works; it’s about creating a sense that using it puts you on the cutting edge, part of a forward-thinking community. This builds image, making users feel like adopting the technology aligns with innovation and success.Perceived Ease of UseIf perceived usefulness answers the question, “Will this technology help me?”, then perceived ease of use asks an equally important question: “Will it be easy to figure out?” Research shows that this perception is influenced by two main groups of factors — anchors and adjustments.Anchors serve as the starting point for a user’s judgment of ease. They include internal traits and predispositions, such as computer self-efficacy — a user’s confidence in their ability to use technology — and perceptions of external control, or the belief that support and resources are available if needed. Another anchor is computer playfulness, which reflects a user’s natural tendency to explore and experiment with technology. This sense of curiosity can make systems feel more approachable, even when they’re complex. On the flip side, computer anxiety, or a fear of engaging with technology, can act as a barrier, making systems seem more difficult than they really are. When applying these principles to AI systems, we see a new form of apprehension emerging: AI anxiety.Once users begin interacting with a system, adjustments come into play. Unlike anchors, which are deeply rooted in a user’s pre-existing traits and beliefs, adjustments are dynamic — they refine or reshape initial perceptions of ease of use based on real-world experience with the system.One key adjustment is perceived enjoyment, which asks whether the act of using the system is inherently satisfying or even delightful. This concept is closely tied to User delight, where interactions go beyond pure functionality to create moments of joy or surprise. Have you ever searched for “cat” in Google and noticed a yellow button with a paw? That’s delight. It’s unexpected, playful, and entirely unnecessary for functionality — but it sticks with you.Another adjustment is objective usability — the system’s actual performance as observed during use. Before interacting with the system, a user might assume it will be complex or difficult. But as they engage with the AI, accurate and intuitive responses can shift this perception, reinforcing the idea that the system is not only functional but easy to use.Adapted from Technology Acceptance Model (TAM 3) by Venkatesh and Bala, 2008.Computer self-efficacy — a user’s confidence in their ability to use technology — can’t be controlled directly, but it can definitely be nudged in the right direction. The secret lies in making the application feel approachable, so users believe they’re capable of mastering it.One way to do this is by showcasing the experiences of others. Highlighting user reviews or testimonials isn’t just about marketing — it taps into the idea of Bandura’s Social Cognitive Theory. When people see others successfully using a tool, they start to think, “If they can handle it, why can’t I?” It’s not just about proof; it’s about planting the seed of possibility.Another approach is helping users form a mental map of how the technology works. GitBook, for example, pairs feature descriptions with skeleton-state interface snippets — clean, minimalist snapshots that give users just enough information to understand the basics without overwhelming them. Animations guide their focus, while interactive elements bring in a subtle gamification layer, making learning feel less like a chore and more like discovery. It’s user-centric design done right — a confidence boost, one step at a time.Slite provides an example of how the ‘job relevance’ factor can make a product introduction resonate right from the first page. One of the challenges in introducing a knowledge base is resistance to sharing information. Studies reveal that 60% of employees struggle to obtain critical information from colleagues, often due to a phenomenon known as ‘knowledge hiding’ — the deliberate withholding or concealing of information. This behavior stems from fears like losing status or job security, creating barriers to collaboration and productivity.Slite tackles this challenge head-on with a playful, relatable touch, wrapping it in humor: ‘The knowledge base even [Name] from [one of 6 target industries] wants to use.’ This subtle nod to targeted pain points highlights its key differentiators: beautiful documentation, hassle-free adoption, and AI-powered search from day one, emphasizing perceived enjoyment — after all, who doesn’t love beautiful, effortless solutions?It’s not just about functionality; it’s about creating a product so intuitive and engaging that it minimizes resistance and inspires adoption, transforming apprehension into enthusiasm.Final thoughtsThe Technology Acceptance Model, while valuable, is not a universal solution but rather a framework — a lens through which we can examine and interpret the dynamics of technology adoption. Since its introduction over a quarter-century ago, it has illuminated patterns in how users perceive and engage with technology. However, it can also risk being overly generalizable, glossing over the nuanced and context-specific factors that shape user behavior. Rooted in the psychological theories of reasoned action and planned behavior, TAM serves as a navigator — helping us better understand and adapt to the complexities of human affective reasoning. By recognizing its strengths and limitations, it can be used as a guide to create technology experiences truly resonate with the people they are designed to serve.Additional resources:“Get Your Product Used: Adoption and Appropriation” is a course from IxDF by Alan Dix, one of the authors of my work Bible, “Human-Computer Interaction.”“How To Measure Product Adoption (Metrics \u0026 Tools)” provides a solid overview of metrics that can help grasp the current state of product adoption“Increasing the Adoption of UX and the Products You Design” (Parts 1 and 2) are articles by Chris Kiess that provide a breakdown of the Diffusion of Innovations theory and Cooper’s Model of User Distribution, and relevance of Jakob Nielsen’s 5 components of usability.Have ideas, thoughts, or experiences to share? Leave your insights in the comments!",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*xvopGBLaaNGyFHHBiu_8qA.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"6df0\"\u003eMake-or-break moments. The first interaction with an AI system — whether it’s a website, landing page, or demo — shapes the mental model of the system. This, in turn, determines whether it will be adopted or not. Are these decisions driven by emotion or logic? Here’s how Technology Adoption Theory unpacks the mechanisms of technology acceptance, with insights applied to AI systems.\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://tetiana-sydorenko.medium.com/?source=post_page---byline--632dd4c3e48c--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Tetiana Sydorenko\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*aX8kGJpvWmlzEgOzsjW_uA.png\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--632dd4c3e48c--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cfigure\u003e\u003cfigcaption\u003eBy \u003cem\u003eKatie Metz, \u003c/em\u003e\u003ca href=\"https://blog.adrianalacyconsulting.com/managing-your-ai-job-anxiety/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003esource\u003c/em\u003e\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"65e5\"\u003eIt takes \u003ca href=\"https://www.nngroup.com/articles/how-long-do-users-stay-on-web-pages/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eonly 10 seconds\u003c/a\u003e for someone to decide whether a website is worth their time or not. And while there is a wealth of resources on \u003ca href=\"https://www.interaction-design.org/literature/topics/user-centered-design?srsltid=AfmBOoo3-Ad-SYR8yC1NELNFnYdfsvbhEqW60QsEtdQ6Nwr-eMSV9CBF\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edesigning user-centered products\u003c/a\u003e, far fewer focus on how to communicate their value during those pivotal first moments — the initial touchpoints that shape a user’s mental model of the system. This challenge is especially true for AI systems, which are often technically complex and hard to simplify. I’ve seen talented teams build extraordinary, user-focused solutions, only to struggle with conveying their true value in a way that’s clear, engaging, and instantly meaningful.\u003c/p\u003e\u003cp id=\"b01d\"\u003eThis article delves into the psychological barriers to accepting and adopting new technologies, offering insights on how to highlight your product’s value and transform first impressions into lasting connections.\u003c/p\u003e\u003ch2 id=\"e370\"\u003eNew tech, old habits\u003c/h2\u003e\u003cp id=\"d04f\"\u003eHave you heard of \u003ca href=\"https://www.khanmigo.ai/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKhanmigo\u003c/a\u003e? It’s an AI-driven teaching assistant from \u003ca href=\"https://fr.khanacademy.org/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eKhan Academy\u003c/a\u003e, designed to guide students through their learning journey with engaging, conversational interactions. It’s empathetic, engaging, and patient. Make a mistake? No problem. It’ll gently explain what went wrong and how to fix it, creating a learning experience that feels less like being corrected and more like growing together. It’s a glimpse into how AI can reinvent old patterns, making interactions more personal, more flexible, and, dare I say, more human.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"635e\"\u003eOf course, kids are a relatively easy audience for Khanmigo, as they \u003ca href=\"https://psycnet.apa.org/record/2012-00588-001\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eare naturally open to such innovations\u003c/a\u003e. They don’t carry years of “\u003ca href=\"https://www.linkedin.com/pulse/why-learning-fatigue-real-how-overcome-elevatearabia-jaa9f/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003elearning fatigue\u003c/a\u003e,” forged by sitting through endless lectures and associating study time with boredom. AI meets them where they are, unspoiled and eager.\u003c/p\u003e\u003cp id=\"3513\"\u003eNow imagine a different scenario: \u003ca href=\"https://fineeng.eu/how-in-cabin-ai-transforms-vehicles-for-a-safer-and-smarter-future/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ea car equipped with AI that tracks your facial expressions and eyelid movements\u003c/a\u003e to detect when you’re too tired to drive safely. It suggests, perhaps with a subtle alarm, that you pull over for a rest. Tell that to my grandpa, though, and he’d probably chuckle at the idea that a camera could know better than he does when he needs a break. There will always be early adopters — those eager to embrace the new and exciting — and those who resist, for reasons that may be logical or deeply personal. For instance, \u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/precisely-when-and-how-you-will-be-replaced-by-ai-b4554da44391\"\u003esome might worry that AI will take their job\u003c/a\u003e, while others may mistrust the technology purely because it feels unfamiliar or intrusive. Understanding and addressing these perspectives is the first step towards designing AI systems that can bridge the gap between skepticism and acceptance.\u003c/p\u003e\u003cp id=\"fb2c\"\u003eThe good news? This isn’t a new challenge. Humanity has faced it during \u003ca href=\"https://www.linkedin.com/pulse/evolution-industry-comprehensive-look-four-industrial-ahmad-malik/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eevery industrial revolution\u003c/a\u003e, each time adapting its thinking to a new normal. While I won’t delve into all of these transformative eras — or the ongoing \u003ca href=\"https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-industry-4-0-the-fourth-industrial-revolution-and-4ir\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFourth Industrial Revolution\u003c/a\u003e — I’d like to focus on the most recent completed one. Let’s rewind to the Third Industrial Revolution — the dawn of the computer and internet age in the late 20th century — and explore its key ideas of facilitating system adoption.\u003c/p\u003e\u003ch2 id=\"2abf\"\u003eWhen computers met humanity\u003c/h2\u003e\u003cp id=\"e80e\"\u003eThe 1980s marked a significant turning point in the study of technology adoption, spurred by the rapid rise of personal computers and the challenge of integrating these new tools into everyday life. Researchers quickly recognized the need to focus on factors like user involvement in the design and implementation of information systems. This emphasis acknowledged a simple truth: technology is only as effective as its ability to meet the needs of the people who use it.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e1983, \u003ca href=\"https://www.alamy.com/processor-for-word-processing-september-1-1983-computers-innovations-exhibitions-the-netherlands-20th-century-press-agency-photo-news-to-remember-documentary-historic-photography-1945-1990-visual-stories-human-history-of-the-twentieth-century-capturing-moments-in-time-image428969295.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esource\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"a678\"\u003eOn the practical side, industry practitioners concentrated on developing and refining system designs, aiming to make them more user-friendly and effective. My favorite example is research at Xerox PARC (Palo Alto Research Center), where researchers closely observed office workers’ behaviors and workflows. Their insights led to the creation of the desktop metaphor, introducing familiar concepts like files, folders, and a workspace that mirrored physical desks. This innovation revolutionized graphical user interfaces (GUIs), laying the foundation for systems like Apple’s Macintosh and Microsoft Windows. \u003ca href=\"https://www.amazon.fr/The-Dream-Machine/dp/1732265119\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eThe Dream Machine\u003c/em\u003e by M. Mitchell Waldrop\u003c/a\u003e or \u003ca href=\"https://www.amazon.fr/Dealers-Lightning-Xerox-PARC-Computer/dp/0887308910\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eDealers of Lightning\u003c/em\u003e by Michael Hiltzik\u003c/a\u003e share more details about history and impact of Xerox PARC.\u003c/p\u003e\u003cp id=\"2f64\"\u003eThese parallel efforts — academic research and hands-on development — led to the creation of numerous theories and frameworks to better understand and guide technology adoption. Among these frameworks, the \u003ca href=\"https://en.wikipedia.org/wiki/Technology_acceptance_model\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTechnology Acceptance Model (TAM)\u003c/a\u003e stands out as one of the most influential.\u003c/p\u003e\u003ch2 id=\"3c8c\"\u003eTechnology Acceptance Model\u003c/h2\u003e\u003cp id=\"3643\"\u003eBack in 1986, Fred Davis created it to answer a simple but pivotal question: \u003cem\u003ewhy do some people adopt new technology while others resist?\u003c/em\u003e TAM was designed to measure this adoption process by focusing on customer attitudes — specifically, whether the technology feels \u003cem\u003euseful\u003c/em\u003e and \u003cem\u003eeasy to use\u003c/em\u003e. These two factors form the foundation of the model, offering a lens to understand how people decide to embrace (or avoid) new tools and systems.\u003c/p\u003e\u003cp id=\"7174\"\u003eThe first factor, \u003cstrong\u003eperceived usefulness \u003c/strong\u003e— is how much a user believes the technology will improve their performance or productivity. It’s outcome-oriented, zeroing in on whether the tool helps users achieve their goals, complete tasks faster, or deliver better results.\u003c/p\u003e\u003cp id=\"c243\"\u003eThe second factor of TAM is \u003cstrong\u003eperceived ease of use \u003c/strong\u003e— the belief that using the technology will be simple and free of unnecessary effort. While usefulness might get a user’s attention, ease of use determines whether they’ll stick with it. If a system feels complicated, clunky, or overly technical, even its benefits might not be enough to win users over. People naturally gravitate toward tools that feel intuitive.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003eAdapted from the Technology Acceptance Model (Davis, 1986), \u003ca href=\"https://www.researchgate.net/publication/35465050_A_Technology_Acceptance_Model_for_Empirically_Testing_New_End-User_Information_Systems\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esource\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"ed54\"\u003e\u003ca href=\"https://www.researchgate.net/publication/227447282_A_Theoretical_Extension_of_the_Technology_Acceptance_Model_Four_Longitudinal_Field_Studies\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIn 2000, Venkatesh and Davis expanded the original TAM model\u003c/a\u003e to dig deeper into what shapes Perceived Usefulness and people’s intentions to use technology. They introduced two key influences: \u003cstrong\u003esocial influence\u003c/strong\u003e — how the opinions of others and societal norms impact adoption — and \u003cstrong\u003ecognitive instrumental processes\u003c/strong\u003e, which focus on how users mentally evaluate and connect with a system. Let’s unpack these factors and explore how they can help shape a mental model of an AI system that fosters adoption.\u003c/p\u003e\u003ch2 id=\"e2c9\"\u003ePerceived Usefulness\u003c/h2\u003e\u003cp id=\"12a4\"\u003ePerceived Usefulness doesn’t exist in a vacuum. One of the social factors is \u003cstrong\u003esubjective norm\u003c/strong\u003e, or the pressure we feel from others to use (or not use) a particular technology. This ties closely to \u003cstrong\u003eimage\u003c/strong\u003e, the way adopting a tool might enhance someone’s status or reputation — think of design influencers after attending Config, dissecting the latest features and showcasing their expertise.\u003c/p\u003e\u003cp id=\"c3eb\"\u003eBut subjective norm doesn’t impact everyone the same way. \u003cstrong\u003eExperience\u003c/strong\u003e can dull its influence. For those just starting with a new system, social pressure often holds more weight — unsure of their footing, they look to others for guidance. As they grow more comfortable, though, external opinions start to matter less, and their own evaluation takes over. \u003cstrong\u003eVoluntariness\u003c/strong\u003e also changes the game. When adoption is a choice, users are less swayed by others’ opinions. But when it’s required — whether by a workplace mandate or social obligation — subjective norm has a much stronger pull.\u003c/p\u003e\u003cp id=\"4018\"\u003eOn the cognitive side, \u003cstrong\u003ejob relevance\u003c/strong\u003e plays a big role. Users ask, \u003cem\u003eDoes this technology actually help me in my specific role?\u003c/em\u003e If the answer is no, it’s unlikely they’ll see it as useful. Similarly, \u003cstrong\u003eoutput quality\u003c/strong\u003e — whether the system delivers results that meet or exceed expectations — reinforces its value. Finally, there’s \u003cstrong\u003eresult demonstrability\u003c/strong\u003e, or how clearly the benefits of the technology can be observed and communicated. The easier it is to see and measure the impact, the more likely users are to view it as useful.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003eAdapted from Technology Acceptance Model (TAM 2) by Venkatesh and Davis, 2000. \u003ca href=\"https://www.researchgate.net/figure/Technology-Acceptance-Model-TAM-2-Venkatesh-and-Davis-2000_fig8_317412296\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esource\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"3b15\"\u003eWhile product design can’t directly influence \u003cstrong\u003e\u003cem\u003esubjective norm\u003c/em\u003e\u003c/strong\u003e, it often plays a role in shaping \u003cstrong\u003e\u003cem\u003eimage\u003c/em\u003e\u003c/strong\u003e — how people perceive themselves or imagine others will see them when they adopt the technology. It’s not so much about the product itself, but what using it says about the individual. By focusing on the right narrative from the very first touchpoint, some applications make it easy for users to see how adopting the tool reflects positively on them.\u003c/p\u003e\u003cp id=\"81fe\"\u003eTake \u003ca href=\"https://www.folk.app/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003efolk.app\u003c/a\u003e, for instance. Instead of just listing features, it focuses on solving specific pain points, framing the app as a tool for staying organized and professional. The messages feels personal and practical. For example, a section title like “Sales research, done for you” suggests that without any additional effort, users will have valuable insights at their fingertips. It’s not just about solving a problem; it’s about positioning the user as more prepared, professional, and efficient.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"c2e1\"\u003e\u003ca href=\"https://www.usebraintrust.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBraintrust\u003c/a\u003e takes a different angle. They highlight glowing media endorsements, signaling that the platform is widely recognised. It’s not just about saying that app works; it’s about creating a sense that using it puts you on the cutting edge, part of a forward-thinking community. This builds \u003cem\u003eimage\u003c/em\u003e, making users feel like adopting the technology aligns with innovation and success.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2 id=\"c417\"\u003e\u003cstrong\u003ePerceived Ease of Use\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"6eec\"\u003eIf \u003cstrong\u003eperceived usefulness\u003c/strong\u003e answers the question, \u003cem\u003e“Will this technology help me?”\u003c/em\u003e, then \u003cstrong\u003eperceived ease of use\u003c/strong\u003e asks an equally important question: \u003cem\u003e“Will it be easy to figure out?”\u003c/em\u003e Research shows that this perception is influenced by two main groups of factors — anchors and adjustments.\u003c/p\u003e\u003cp id=\"a205\"\u003eAnchors serve as the starting point for a user’s judgment of ease. They include internal traits and predispositions, such as \u003cstrong\u003ecomputer self-efficacy\u003c/strong\u003e — a user’s confidence in their ability to use technology — and \u003cstrong\u003eperceptions of external control\u003c/strong\u003e, or the belief that support and resources are available if needed. Another anchor is \u003cstrong\u003ecomputer playfulness\u003c/strong\u003e, which reflects a user’s natural tendency to explore and experiment with technology. This sense of curiosity can make systems feel more approachable, even when they’re complex. On the flip side, \u003cstrong\u003ecomputer anxiety\u003c/strong\u003e, or a fear of engaging with technology, can act as a barrier, making systems seem more difficult than they really are. When applying these principles to AI systems, we see a new form of apprehension emerging: \u003ca href=\"https://tetiana-sydorenko.medium.com/ai-anxiety-and-how-to-design-for-it-resources-and-best-practices-7387d340d9a4\" rel=\"noopener\"\u003eAI anxiety.\u003c/a\u003e\u003c/p\u003e\u003cp id=\"99df\"\u003eOnce users begin interacting with a system, \u003cstrong\u003eadjustments\u003c/strong\u003e come into play. Unlike anchors, which are deeply rooted in a user’s pre-existing traits and beliefs, adjustments are dynamic — they refine or reshape initial perceptions of ease of use based on real-world experience with the system.\u003c/p\u003e\u003cp id=\"c7f0\"\u003eOne key adjustment is \u003cstrong\u003eperceived enjoyment\u003c/strong\u003e, which asks whether the act of using the system is inherently satisfying or even delightful. This concept is closely tied to \u003ca href=\"https://www.nngroup.com/articles/pillars-user-delight/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUser delight\u003c/a\u003e, where interactions go beyond pure functionality to create moments of joy or surprise. Have you ever searched for “cat” in Google and noticed a yellow button with a paw? That’s delight. It’s unexpected, playful, and entirely unnecessary for functionality — but it sticks with you.\u003c/p\u003e\u003cp id=\"c8b3\"\u003eAnother adjustment is \u003cstrong\u003eobjective usability\u003c/strong\u003e — the system’s actual performance as observed during use. Before interacting with the system, a user might assume it will be complex or difficult. But as they engage with the AI, accurate and intuitive responses can shift this perception, reinforcing the idea that the system is not only functional but easy to use.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003eAdapted from Technology Acceptance Model (TAM 3) by Venkatesh and Bala, 2008.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"bef2\"\u003e\u003cstrong\u003eComputer self-efficacy\u003c/strong\u003e — a user’s confidence in their ability to use technology — can’t be controlled directly, but it can definitely be nudged in the right direction. The secret lies in making the application feel approachable, so users believe they’re capable of mastering it.\u003c/p\u003e\u003cp id=\"1c1d\"\u003eOne way to do this is by showcasing the experiences of others. Highlighting user reviews or testimonials isn’t just about marketing — it taps into the idea of \u003ca href=\"https://www.simplypsychology.org/social-cognitive-theory.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBandura’s Social Cognitive Theory\u003c/a\u003e. When people see others successfully using a tool, they start to think, \u003cem\u003e“If they can handle it, why can’t I?”\u003c/em\u003e It’s not just about proof; it’s about planting the seed of possibility.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"21b4\"\u003eAnother approach is helping users form a mental map of how the technology works. \u003cstrong\u003eGitBook\u003c/strong\u003e, for example, pairs feature descriptions with skeleton-state interface snippets — clean, minimalist snapshots that give users just enough information to understand the basics without overwhelming them. Animations guide their focus, while interactive elements bring in a subtle gamification layer, making learning feel less like a chore and more like discovery. It’s user-centric design done right — a confidence boost, one step at a time.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"67e6\"\u003e\u003ca href=\"https://slite.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSlite\u003c/a\u003e provides an example of how the ‘job relevance’ factor can make a product introduction resonate right from the first page. One of the challenges in introducing a knowledge base is resistance to sharing information. Studies reveal that\u003ca href=\"https://hbr.org/2019/11/why-withholding-information-at-work-wont-give-you-an-advantage\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e 60% of employees struggle to obtain critical information from colleagues\u003c/a\u003e, often due to a phenomenon known as ‘\u003ca href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/job.737\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eknowledge hiding\u003c/a\u003e’ — the deliberate withholding or concealing of information. This behavior stems from fears like losing status or job security, creating barriers to collaboration and productivity.\u003c/p\u003e\u003cp id=\"3c91\"\u003eSlite tackles this challenge head-on with a playful, relatable touch, wrapping it in humor: ‘The knowledge base even [Name] from [one of 6 target industries] wants to use.’ This subtle nod to targeted pain points highlights its key differentiators: beautiful documentation, hassle-free adoption, and AI-powered search from day one, emphasizing \u003cstrong\u003eperceived enjoyment\u003cem\u003e \u003c/em\u003e\u003c/strong\u003e— after all, who doesn’t love beautiful, effortless solutions?\u003c/p\u003e\u003cp id=\"43ec\"\u003eIt’s not just about functionality; it’s about creating a product so intuitive and engaging that it minimizes resistance and inspires adoption, transforming apprehension into enthusiasm.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2 id=\"6c39\"\u003eFinal thoughts\u003c/h2\u003e\u003cp id=\"d6c5\"\u003eThe Technology Acceptance Model, while valuable, is not a universal solution but rather a framework — a lens through which we can examine and interpret the dynamics of technology adoption. Since its introduction over a quarter-century ago, it has illuminated patterns in how users perceive and engage with technology. However, it can also risk being overly generalizable, glossing over the nuanced and context-specific factors that shape user behavior. Rooted in the psychological theories of \u003ca href=\"https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/theory-of-reasoned-action#:~:text=The%20Theory%20of%20Reasoned%20Action%20(TRA)%20suggests%20that%20a%20person\u0026#39;s,Fishbein%20%26%20Ajzen%2C%201975).\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ereasoned action\u003c/a\u003e and \u003ca href=\"https://en.wikipedia.org/wiki/Theory_of_planned_behavior\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eplanned behavior\u003c/a\u003e, TAM serves as a navigator — helping us better understand and adapt to the complexities of human affective reasoning. By recognizing its strengths and limitations, it can be used as a guide to create technology experiences truly resonate with the people they are designed to serve.\u003c/p\u003e\u003cp id=\"baf3\"\u003e\u003cstrong\u003eAdditional resources:\u003c/strong\u003e\u003c/p\u003e\u003cul\u003e\u003cli id=\"0a1b\"\u003e\u003ca href=\"https://www.interaction-design.org/courses/get-your-product-used-adoption-and-appropriation?srsltid=AfmBOopMXSQF6MDq0LDxSataxsaxYTgdktN6pzroEms8TZKwg04BZ64i\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003e\u003cem\u003e“Get Your Product Used: Adoption and Appropriation”\u003c/em\u003e\u003c/strong\u003e\u003c/a\u003e is a course from IxDF by Alan Dix, one of the authors of my work Bible, \u003ca href=\"https://www.amazon.com/Human-Computer-Interaction-3rd-Alan-Dix/dp/0130461091\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e“Human-Computer Interaction.”\u003c/a\u003e\u003c/li\u003e\u003cli id=\"36db\"\u003e\u003ca href=\"https://uxcam.com/blog/how-to-measure-product-adoption/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003e\u003cem\u003e“How To Measure Product Adoption (Metrics \u0026amp; Tools)”\u003c/em\u003e\u003c/strong\u003e\u003c/a\u003e provides a solid overview of metrics that can help grasp the current state of product adoption\u003c/li\u003e\u003cli id=\"bc5a\"\u003e\u003cstrong\u003e\u003cem\u003e“Increasing the Adoption of UX and the Products You Design”\u003c/em\u003e\u003c/strong\u003e (\u003ca href=\"https://blog.prototypr.io/increasing-the-adoption-of-ux-and-the-products-you-design-part-1-8871cf8368d6\" rel=\"noopener\" target=\"_blank\"\u003eParts 1\u003c/a\u003e and \u003ca href=\"https://blog.prototypr.io/increasing-the-adoption-of-ux-and-the-products-you-design-part-2-85e23c207316\" rel=\"noopener\" target=\"_blank\"\u003e2\u003c/a\u003e) are articles by \u003ca href=\"https://chriskiess.medium.com/\" rel=\"noopener\"\u003eChris Kiess\u003c/a\u003e that provide a breakdown of the \u003ca href=\"https://en.wikipedia.org/wiki/Diffusion_of_innovations\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDiffusion of Innovations theory\u003c/a\u003e and \u003ca href=\"https://www.amazon.com/About-Face-Essentials-Interaction-Design/dp/1118766571/ref=sr_1_1?ie=UTF8\u0026amp;qid=1537831256\u0026amp;sr=8-1\u0026amp;keywords=About+Face%3A+The+Essentials+of+Interaction+Design\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCooper’s Model of User Distribution\u003c/a\u003e, and relevance of \u003ca href=\"https://www.sciencedirect.com/topics/computer-science/usability-attribute#:~:text=Usability%20has%20multiple%20components%20and,%2C%20errors%2C%20and%20subjective%20satisfaction.\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJakob Nielsen’s 5 components of usability\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"49c4\"\u003e\u003cem\u003eHave ideas, thoughts, or experiences to share? Leave your insights in the comments!\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/article\u003e\u003c/div\u003e",
  "readingTime": "17 min read",
  "publishedTime": "2025-01-15T21:14:16.216Z",
  "modifiedTime": null
}
