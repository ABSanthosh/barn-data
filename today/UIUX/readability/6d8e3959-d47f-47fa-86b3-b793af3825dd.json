{
  "id": "6d8e3959-d47f-47fa-86b3-b793af3825dd",
  "title": "Collected consciousness: AI product design for empowering human creativity",
  "link": "https://uxdesign.cc/collected-consciousness-ai-product-design-for-empowering-human-creativity-dcc62100a7a4?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Brandon Harwood",
  "published": "Sat, 01 Feb 2025 18:25:02 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "ai",
    "ux",
    "creativity",
    "product-design",
    "ethics"
  ],
  "byline": "Brandon Harwood",
  "length": 38707,
  "excerpt": "However, if you’re unfamiliar with it, consider the content of the painting, read into the details, and build a story about it. On April 26th, 1937, about 6 weeks before the painting was unveiled at…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Before we begin, I want you to consume this painting.If you know the story, the details might already scream at you.However, if you’re unfamiliar with it, consider the content of the painting, read into the details, and build a story about it.Try to understand why Picasso painted this.Guernica, the town, Euskadi.eusThe painting is named after Guernica, the Basque town in Northern Spain, pictured above.On April 26th, 1937, about 6 weeks before the painting was unveiled at the Paris International Exposition, the population was about 7000.In addition to the local civilian population, the town housed a communications center for the antifascist Spanish Republic during the Spanish Civil War, and so it was bombed by Nazi Germany and Fascist Italy — an intentional attack on not just the military forces, but the civilians that inhabited the town, to send a message.Scroll back up and look at the painting again.When you’re done, come back here.If you didn’t know the story of this painting beforehand, now you do, and it might strike a different chord, if just slightly. The details of the painting now have the context that shows us what Picasso was thinking when he painted Guernica. The strained expression on the horse. The cold stare of the bull. The fallen soldier below the crying mother holding her dead child. The people of Guernica hold a candle that sheds a small ray of hope and growth for their fellow citizens while the light bulb, emitting no light, observes.It’s this kind of context that drives meaning in art. Guernica is not just a painting. It’s communication. It’s a very human way to express the feelings, experiences, and politics Picasso intended to express behind it. It’s a vessel of meaning built through words, actions, and paint. It's not just the product of a paintbrush hitting a canvas, but the product of a complex series of events and decisions made by its creator. This is why Guernica has become such a protected piece of art, and why we still know its story today.And one day, that story will be lost to time. And, if for some reason, the painting has survived past its story, the people in this future can only speculate about what it means. But the details will be there, and the choices made by Picasso, expressed through those details, will guide the viewers to try and help them understand his feelings, experiences, and politics.But this isn’t an essay about art. It’s about technology, and what it can and cannot do in art.I started with this message because so much of our creative communication as human beings so deeply depends on the emotion, connection, and meaningful context created and consumed between the creator and consumer. If I (Brandon) tell you (the reader) I love you, that’s very different from someone you actually care about, someone you have a history with telling you they love you. Real, true communication between people, especially through art, requires emotion, connection, context, and meaning.Unfortunately for some, but to the benefit of the rest of us, those are all things that artificial intelligence lacks within the content it generates.The aesthetic of communicationRed and Blue Macaw, Allen \u0026 Ginter, 1889If the above is an example of why people can generate content that communicates meaning and intention, I think it’s important to distinguish why AI-generated content cannot.Generative AI models are pattern visualization machines. LLMs process the words provided to them by computing an analysis of the relationships of those words, how often they appear together, and the different contexts they appear together within the collected data it’s trained on. These relationships are what inform the probability of the next word or token in a sequence of words or tokens.Temperature: 1Temperature: 2This is why temperature is such an important factor in getting AI systems to generate anything we perceive as meaningful. A lower temperature instructs the model to generate tokens that have a higher probability of coming after the tokens provided, which more often looks like what we might see as an elaborate, well-thought-out response.However, decreasing the probability of the next token with a higher temperature more often generates content we might see as nonsensical because they’re “further apart” in the training data and aren’t as statistically related to the words input.Midjourney Prompt: “A scene indicative of the horrors of war, in the style of Pablo Picasso”Another way to visualize this concept is by highlighting bias in AI-generated images.When we ask Midjourney to interpret and produce an image representative of the vague notion of “the horrors of war,” it doesn’t understand what I might mean by that. It associates horror with skeletons, war with soldiers in uniforms and helmets, Picasso with cubist aesthetic style, and Picasso+War+Horror with horses, because those are elements present in Guernica. There are also noticeable influences from other artists with horror styles, like colors and compositional elements you might see from Goya or Beksinski.When we discuss bias in AI, the focus is usually on a model's inability to accurately represent the world because the data it’s trained on lacks information representative of the real world. Some of the most abhorrent examples are also the most obvious; when we rely on AI to represent people through generated images. It often defaults to stereotypes (because the training data says white men are a closer probabilistic image to wealth, and black people are closer to service work).Generated with Canva Magic Media February 2024The images are racist and sexist because it’s a visualization of data that is racist and sexist. There are efforts to reduce this kind of representational bias in generated images of people, for example, through prompt injection. When you provide a vague prompt for a “fast food worker” it will add details to your prompt around race/age/gender etc. before generating the image to add a level of variety to the more socially “risky” aspects of the image.“A fast food worker cleaning a table” generated with Canva Magic Media January 2025But do you notice anything else in these images that points to other, more subtle visualizations of bias?The colors, the composition of the images, and the metal reflective tables.Demographics are only one of countless pattern associations in the training data. Prompt injection is a response to the outcry of people (rightfully) calling AI companies out for using racist and sexist data, but it’s just a band-aid solution. It ignores the underlying fact that the architecture of GenAI models doesn’t produce biased content merely due to a lack of data, but because AI-generated content is just data visualization of bias, period.“A city road at night” generated with Canva Magic Media. Notice the patterns in composition, color, visual elements, etc.This is why it’s easier to prompt for a particular style or subject than fine-controlled content. GenAI doesn’t think about the image it’s producing, the form, content, or anything. It’s just math synthesizing meaningful content to mimic the general aesthetic of meaningful content.It doesn’t know a human is providing input (or anything else), and it doesn’t take into account what they think about during the creative process. It simply generates text based on patterns of what a conversation looks like (or painting, or photograph, or voice, or…), without a true understanding of the meaning behind the words it generates. Yes, even GPT-o1 doesn’t think through or truly understand anything, it merely generates aesthetic text that mimics an internal dialogue, to generate more aesthetic text that mimics external words that come after internal dialogue.Bender et al. call these models “stochastic parrots” for this reason (and Hicks et al. call them “bullshit”, claiming that the term ‘hallucinations’ is not only incorrect but misleading, as it implies mistakenly incorrect text generated with the intention to tell the truth on part of the AI).There is no intention behind AI-generated text, no regard for the truth — just a likely (or unlikely) next string of data. In the Frankfurtian sense, it truly is bullshit content.(Note: Hicks et al. call ChatGPT bullshit specifically, but I think it’s important to note that it’s not just one model or even the models in general that are bullshit, that’s also anthropomorphizing them. It’s the content produced that is bullshit, as it is content generated without regard for truth or meaning.)“ChatGPT does not communicate meaning — we infer it.”— Indi YoungThis is a fundamental flaw in the reliance on generative AI alone as a means to produce anything creative. Any AI-generated content produced without human input and/or iteration is just weighed averages of collected data points that represent the output of conscious human thought processes — our text, our photographs, our paintings, our music — and reduces them to their aesthetics without regard for the truthful context or meaning we as humans try to convey through these creative or documentative mediums. It’s like a search engine for generalities.And because it’s limited to producing only generalities, it cannot learn or understand the contextual gaps in data as we can. It cannot make creative decisions, or appreciate them. It can only highlight patterns in the noise that make statistical sense to highlight given what comes before, leaving us only to judge those patterns.When we read human-written text, there is deeper thought, feeling, and intention present. The words do not always represent the writer's deeper thoughts/feelings/intentions, but this is part of what makes great artists or communicators — the ability to articulate those deeper parts of the self and communicate with people directly or indirectly through the artifacts they build.But not everyone is an artist, and few people are great at communicating, despite the fact that they have those same kinds of thoughts, feelings, and intentions behind the text they write and the art they produce.Indi Young touches on this through the lens of user research. When we interview people or read their reviews, the users are trying to convey their thoughts and opinions about an application. We record these thoughts, and when we play them back we often need to work through and interpret them to truly understand what they meant. People say things but mean other things way more often than we’d like to admit.This is why the concept of synthetic users or “user research without the users” just doesn’t work as a means to replace humans — the text built out of user interviews is merely an end-product of the nuanced lived experiences of people. It’s hard work to read through text or interview transcripts and build a meaningful understanding of the context or reasoning behind what’s recorded, and that context and reasoning are completely absent in AI training.When we talk about the aesthetics of communication, we’re talking about the patterns present in recorded content without the knowledge or understanding of how those patterns came to be in the first place. If generative AI is only able to synthesize and generate the aesthetics of communication, then it ultimately fails to capture the richness, nuance, and intent behind human expression.Beyond the fundamental limitations of AI as pattern visualization, I also want to acknowledge that a large number of these models are built by training on vast collections works without consent or compensation. The same artists, writers, and musicians whose work these tools aim to replace, have had their own creative output scraped and used to train these systems. We’re replacing artists' work and perspective with soulless, perspectiveless synthetic malappropriations of their work. Some companies are building models that exclusively use content they have the rights to (e.g. Pleias recently released a few models trained “exclusively on data that are either non-copyrighted or are published under a permissible license.”) but regardless, the data sourcing of these models needs reform, and the tools built from them need to understand not only that they cannot replace artists work, but it’s poor design to try.Artists share with each other, directly and indirectly. They are informed and inspired by one another. Directly, they talk with and learn from each other. Indirectly, they use each other's works as references for their own works. This indirect sharing and consuming of open knowledge is extremely important for building a larger cultural sphere of communication and influence for artists that space and time.Extending this knowledge-sharing gives us a framework for how we might design useful products for creative contexts. The patterns and insights that emerge from data synthesis provide utility— not as replacements for human creativity, but as tools that can highlight new directions, validate assumptions, or spark creative exploration.The problem isn’t with the technology itself or its use in creative contexts. The problem is that most applications built on GenAI try to replace creative people with poor simulacrums of their own work, rather than helping them harness these rich, implicit knowledge patterns to reach new creative heights.This is a common pattern in design for emergent technology.Designing around the MachinePunctuation Personified, John Harris, 1824Quite often, “AI solutions” are built as a result of the technology being merely available to build with and an opportunity to be had, and not as a means to solve a problem that the technology is particularly good at solving. We’re designing around the machine, not the context.This isn’t a bad thing on its own — speculative design can lead to useful insights about potential futures, and reflecting on these experiments helps us understand what problems a new technology is good at solving, and what it’s not.The problem is the disconnect between the motivations and intentions between research institutions and startups. When we build these experiments and call them products without carefully involving and learning from the people we’ve supposedly designed them for, and with the pressure of tight turnarounds for profit and risk-taking, the solutions become just that; experiments. We’re not considering the people we build for; we’re building something for ourselves and marketing it as the next big thing. It’s costly when it fails, and harmful before it does.The large majority of attempts to inject AI into creative spaces, while marketed as tools for artists, writers, or musicians, are in reality just attempts to replace them because we don’t consider the actual needs or mental models of creative people. In art especially, the people building these experiments are often not artists themselves. They’re building experiments that help people to avoid becoming artists. They don’t see or care about what artists do, or how they do it, they care about the end product of their work. Then they use AI to build a shortcut to that end product because that’s what they see it produce — an aesthetic of an end product without the understanding of how the work it imitates comes to be in the first place.Unsurprisingly, the end products of AI tools built this way usually end up replaceable, uninspiring, or boring because AI alone produces content that is kitsch. It doesn’t make the kinds of decisions artists make, and when we rely on AI to “do creativity” for us, it generates something that is particularly and specifically not creative, something that doesn’t tell a story or connect with the human experience. It’s just data visualization.So what do we do with content that doesn’t tell a story, but looks like one?What can we do with images or text or audio produced with no true meaning or understanding of the context surrounding intention?What is bullshit useful for?I’m reminded of my work facilitating design thinking and ideation workshops.When facilitating people to think creatively, we solve a problem sourced from the limitations of working in and understanding contexts. Facilitation helps folks think outside their normal modes of thinking by providing means to consider their limited context from a new angle.As facilitators, we don’t need to understand that context ourselves, nor do we need to have the niche expertise or knowledge our participants have. We just need to be able to get their knowledge out in the open, within a limited context, to help them reflect on it and find the connections, insights, and observations that help them expand their thinking about that context.Sometimes, that means interpreting complex topics and asking the obvious beginner questions, or making confidently wrong assumptions. Sometimes it means saying bullshit you know nothing about, not so you provide some grand insight, but so the participants, who do know a thing or two, can respond appropriately and say “Wait what? No, that’s not it, but it reminds me of this thing.” It begins arguments, inspires discussion, or starts new trains of thought because you’re coming in and participating without understanding the full context.As I said earlier, while Generative AI can synthesize its training data into images, it does not inherently understand human desires, needs, or goals. But does providing a window into those insights for humans to summon and observe solve the same problem? Does it help them to gain inspiration, make more informed and creative decisions, or build meaning themselves?When I started working on interaction design for human-AI co-creativity, I worked with IBM Research to explore the question: “How might we help users form accurate mental models of Generative AI in co-creative contexts to build effective human-AI collaboration.” This research has mostly taken place within the realm of co-creation and design thinking, but over time, as I’ve run workshops, experimented with AI, and gathered the opinions and insights I covered in the previous section, I’ve come to abstract the way people interact with information and content as a medium for personal thought, regardless of the source of that content. I started to see the connections between these different modes of interacting with information, and the question for my personal research became: “How might we ensure human agency and intent when introducing artificial perspective \u0026 bias within creative contexts?”When we consume AI-generated content, it can become a way to navigate weird, vague, cloud-like collections of patterns in human thought and expression, and despite (or perhaps because of) the lack of meaning behind these generations, we are presented with raw material to build new meaning from. Meaning that can help us shape how we move forward in the real world. This hollow simulacrum of communication now becomes an interface to capture, understand, shape, and represent our creative intentions, goals, thoughts, and feelings.However, it’s important to note that the concept of gaining creative inspiration and building personal meaning from what is essentially random or pseudorandom information is not a new idea; it is, in fact, a very ancient one. To consider how AI can be useful in creativity, we need to consider where else we build meaning with information, and what AI actually does when we interact with it creatively.Let’s cover this through two concepts.Meaning MachinesThe Sun, Pamela Colman Smith, 1909Chris Noessel has been thinking about the question of “How do you think new things?” for a long time.In the talk linked above, Chris describes “Meaning Machines” as mechanisms for noodling semantically, (or changing your frame of mind on a thing by intentionally skewing the semantics of that thing). He gives Tarot as an example, as well as I Ching, Haruspicy, other esoteric practices, and more modern tools for spiritual fulfillment, like Mad Libs. Please go watch the talk, it’s super interesting.Meaning Machines are, at their core, “signifiers, randomized into a fixed grammar, and read for new meaning.”Let’s consider the Tarot example for a second, and more importantly, let’s examine the interaction design of Tarot: Each card in the deck is a symbol (the signifier) with meaning assigned to it. We randomize the cards by shuffling them, place them on the mat, and interpret them. Depending on how they fall, their placements relative to one another, their direction, etc. we react to and reflect on these symbols as they relate to our life.And so, we build personal meaning.This is a creative act! We create meaning and intention for future decisions or outlooks on life out of what is essentially random data presented and interpreted within the context we set and are set within.Within the context of strictly creative work, a more practical “analog” example meaning machine is Brian Eno \u0026 Peter Schmidt’s “Oblique Strategies” — a deck of cards containing cryptic or ambiguous phrases intended to be shuffled and pulled at random to provoke creative thinking and break a creative block. Intuití is another, inspired by tarot and using gestalt principles, these cards are intended to help the player better understand their creativity, and inspire the performance of creative acts.Products of Place by SPACE10 and oioBringing this concept into the digital world, the prototype above was developed by the creative agency OiO, in partnership with the now-closed IKEA R\u0026D Lab SPACE10. It’s an interface where you choose any point in the world, and an AI system identifies and generates a summary of materials that are abundant in that location, often waste material, which can be used or recycled to create new things, like plates!The core of the problem I highlighted earlier about AI is that too often we view the output of an AI system as the final product, something to be consumed or distributed as a means to avoid doing the important work. But a more useful application of these artifacts is to incorporate them as materials for use within larger scopes of work. AI systems can become a new kind of meaning machine — a way to add interactivity and deeper, more complex variability to otherwise static signifiers, like cards.When we employ AI like this, we begin to see how we might use it to enhance creative ideation and help people explore creative domains in ways they might not have considered before, rather than relying on the generated content as the final product we push into the world.In this general context then, the randomized signifiers are the contextual data surrounding our creative pursuit, the data the AI is trained on, and the relationships built on that data through its training. These signifiers, the data, are then placed into a fixed grammar through agentive interaction and/or agentic actions, and the user can then interpret the result to stimulate their creativity, build new meaning, or explore ideas they might not have considered before.When we consider the utility of AI in creativity as a feature that helps us create meaning instead of consuming content, it provides a means for us to frame how we build tools that act as collaborative partners in creative work and stimulate our creative action.So, when building creative tools with this in mind, what should the actual interaction design between humans and AI look like?Co-creative AI rolesIn a previous article, I broke down the utility of Generative AI within creative domains into three roles: The Puller, the Pusher, and the Producer. I’ll cover them below just briefly.The Puller: The AI system gathers information about the context the user is working in through active question generation and passive information collection on the works.Example: Pulpo — a GPT that takes notes about your ideas through interviewThe Pusher: The AI system uses some/none of this context to synthesize considerations for the user to employ throughout their creative journey.Example: An AI Chatbot that redesigns its interface at your commandThe Producer: The AI system creates artifacts for use as elements of the users’ larger creative output. Example: A contextually informed sticky note content generator(The examples provided show all roles in play because they depend on one another to build a complete AI experience, but are intended to highlight the specific role they’re attached to.)Informed by aesthetic patterns in its training data rather than informed opinion, the AI system can synthesize questions, observations, assumptions, and potentially useful artifacts in response to the users’ expressed/gathered context, goals, needs, thoughts, feelings, and actions.These actions of “pulling context” to generate “pushed suggestions” provide the user with information that doesn’t require the AI system to have a deeper understanding of their historical context or knowledge around the creative pursuit, but acts as a naive sounding board for them to respond to in reflection of their progress. “Pushing” provides a means for the user to consider new paths, challenging them through artificial assumptions about their work, with the ability to highlight gaps, acting as a kind of meaning machine for facilitating new ideas in context.(One note on the Pusher role: It’s important to ensure push systems are designed to make the user feel comfortable rejecting the propositions from the AI— conversational AI “characters” encourage anthropomorphizing the AI, and enforce a subtle power dynamic over the user where there doesn’t need to be one.)Where the Pusher role provokes the user to create their creative ideas or artifacts, the “Producer” role uses GenAI to produce creative artifacts for use. It’s important to consider how we might design our systems to produce artifacts here, rather than “full works.” This ensures our users’ creative process holds agency rather than simply assuming their intended output. An example of this might be an AI-enabled rapid UI prototyping tool that builds web components based on an established design system, or a lighting simulator to move through options for a film set for technicians to consider and plan before setting up equipment. Generative fill is an example of productive co-creative AI.One big point I want to make about these roles is that they intentionally don’t frame generative AI as the product, but instead frame it as features. None of the examples provided work as full products, but components that provide value within larger flows of creativity. As designers, the solutions we create must be holistically useful to our users, and so far, AI seems only to provide useful features that fit neatly within larger solutions. Call them agents or call them bots, they are just tools.Designing co-creative AI solution conceptsLet’s get into it.In this section, I’ll build on the concepts described above to walk through a framework that can act as a basis for setting direction through a workshop (along with an example workshop case study) or framing longer-form user research and AI Interaction design processes. This is intended to help designers or product teams quickly come together to align on a robust design concept for an AI solution informed by creative user needs and intended to understand, react to, and empower creative processes, rather than replace them.Designing AI systems that complement rather than replace creative functions is difficult, but dealing with the consequences of betting on AI to be able to do the work of creatives is harder.Creativity is something people enjoy doing, and we’ve already seen why they’re better at it than machines. When designing systems meant to complement creative processes, it’s important to understand the nuanced aspects of what people do that build up creative action, why we enjoy doing it, how we move through creativity in our real, human lives, and where we seek help throughout creative journeys.As I’ve considered where AI might fit within creative domains, where it helps, and where it hurts, I’ve built a framework that I believe can help others think through co-creative human-AI systems. I’ve provided an outline of the framework below:Part 1: modeling creativity in contextThe first step involves building an understanding of creativity in context and how creative people move through creative work. To do this, we can build a mental model of their creative flow and environment, the processes they move through, their goals, and the actions they work through.To do this, choose a primary creative persona to focus on, and, ideally by talking with them, map out the following:What modalities do they work in? (e.g. audio, visual, text, concepts, ideas, material, etc.) and when?What actions do they perform when being creative? (e.g. ideating, sketching, experimenting etc.) Start at a high level and break these tasks down, placing them in order.To perform these actions, what key concepts \u0026 principles guide their creative practice? (e.g., inspiration, feedback, iteration)Where might our persona struggle, or benefit from outside help along this creative process? Where is the tedium in this process? How could that tedium be useful for them, even indirectly?Example:At the STRAT 2024 conference I ran a short workshop walking the participants through this framework to see if we could build a solution that uses AI in a way that enhances creativity, and within a few hours we conceptualized a rough idea for something I think we were all excited about: a tool to help designers create documentation more efficiently. I’ll outline out process as we move through the framework.As this was an educational workshop for designers, performed by designers, we started by roughly mapping out these categories on sticky notes that focus on the modalities, actions, concepts, principles, and struggles designers face as a whole, so we could narrow down the use case.Here’s a summary of what we worked through:Modalities: Conceptual (User Journeys, Psychology, Information Architecture etc.) Visual (Graphic Design, Interfaces, Branding etc.)Interactive (Accessibility, Usability, Design Systems etc.)Actions, concepts, \u0026 principles: Conceptualize / Define / Plan / Develop / Research / Iterate / Experiment / Develop / Simplify / Annotate / Decide / Prioritize / Document / (and much more)Struggles: Prioritizing \u0026 Understanding Project Needs / Documenting Decisions / Communicating Reasoning / Reconciling \u0026 Articulating User and Business Needs / Feedback Without Context / Lack of Data / Ethical Decision Making / Understanding Long-term Implications.After mapping these out, we played it back and talked through where in the process of design we’d really love some help, and landed on documenting data used for design decisions, and documenting design reasoning. We ended this part of the workshop aligning on the following context to design a solution for:Designers Tasked with Design Documentation really struggle through the tedium of capturing, formatting, and sharing the reasoning and historical decisions of their design process, especially when they don’t have the time or resources to format it properly. This affects their relationships with developers, business stakeholders, and future designers iterating on their work. Designers in the workshop also agreed that while they understood the utility of documentation, they just didn’t enjoy they process, making it a good target for creating a system that eases their workload.Part 2: mapping contextual dataIn this step, identify and map the data surrounding these creative tasks, categorizing them into what AI can pull, push, or produce.First, gather the types of Input, Output, and Contextual information/data/artifacts involved in the mental model we built. Consider:What might our persona need, use, observe, or consume as part of their creative process? (e.g., reference images, past work, market trends)What might our persona create, and what are the artifacts produced? (e.g., sketches, drafts, final products)What contextual information is relevant to our persona's creative task? (e.g., mindset, beliefs, political climate, project constraints)Then, consider the most useful information, data \u0026 artifacts our AI could pull, push, or produce for our persona, asking questions like:Pull: What can/should be gathered from our persona or other various sources to inform the larger creative context? (e.g. reasoning, info about the work, outside inspiration)Push: Where can AI most usefully generate suggestions, insights, or new ideas in the process? (e.g. creative directions, variations of work, material recommendations)Produce: What content or artifacts might AI produce directly that are useful to, but don’t replace our user's final output? (e.g. prototypes, elements, color palettes, code snippets)ExampleMapping out data designers work with during documentation, what they produce as a result, and the contextual data surrounding documentation, some examples of what we ended up with included: Input Data: Product requirements / The “why” / Stakeholder input / User Personas / The “where” / Modality of contentOutput Data: Wireframes / prototypes / mockups / Annotations / Design iterations / Design system components / Instructions / TokensContextual Data: Brand / Time constraints / Developer capabilities / Budget constraints / Designer limitations / Origins of decision reasoningThen we mapped this data to that which AI might most usefully push, pull, and produce to make documentation easier for designers.Pull: Product requirements / User Input / Annotations / Clarification of reasoning / design versions / Connections to Brand SystemPush: Reasoning summariesProduce: Formatted Documentation Data / Historical Captures of Reasoning / Audience-adapted ExplanationsWorkshop part 3: human/AI interaction designWith our context in mind and the necessary components in place, determine the interaction design and task assignments for our System, Persona, and AI, and what the result of this interaction will look like. In this step, it’s important to consider the specific, tangible capabilities AI can perform while interacting with a user or system.A very useful resource for thinking about discrete GenAI Capabilities is Designing With: A New Educational Module to Integrate Artificial Intelligence, Machine Learning and Data Visualization in Design CurriculaFirst, using the mental model, data categories, and AI capabilities; outline key tasks throughout the creative process you’re examining:Human Tasks: What should remain human-centric due to the need for judgment, intuition, emotional intelligence, or simply because people enjoy doing it?AI Tasks: Review the AI Capabilities List. How might the AI help our user through their creative journey? Hint: Consider explicitly highlighting both the capability and data/output e.g. “Summarize rough notes into formatted documentation”System Tasks: What roles or tasks does the broader system play out to support the interaction? (e.g., storing data, managing data flow, communicating, committing)Then, review your work so far. Map out how your persona, AI, and System interact. Include:Data Categories \u0026 Examples: Clearly mark input, output, and contextual data points.Task Assignments: Use distinct symbols or colors to differentiate between human, AI, and system tasks.Interactions \u0026 Flows: Draw lines/arrows to show how data \u0026 tasks interact, illustrating the flow of the creative process.Feedback Loops: Highlight any iterative steps or feedback loops that influence the process.Example:In the end, we outlined a system intended to recognize patterns in documentation artifacts, supplement them by identifying gaps, posing clarifying questions, re-framing design decisions to fit the context alongside historical reasoning, and format everything to system standards. The result was a collaborative system where designers remain in control while AI assists in enhancing clarity and completeness, building more robust documentation while easing the process for the designer.’’Here’s another example of an interaction design flow that could be built as a result of this framework:This is an outline for an AI system that gathers information about a user's dream, tracks the symbols and themes, curates information, and forms connections that provide them the tools to interpret and analyze their dreams at a deeper level (rather than relying on the AI to act as an authority and analyze their dreams for them).Example of how this could be articulated through a UI beyond a chatbot.ConclusionRemember Guernica. When we look at it, we don’t just see patterns of paint on canvas — we see Picasso’s horror at civilian bombing, his protest against fascism, and his attempt to communicate profound human suffering. AI can analyze Guernica’s composition, mimic its cubist style, or generate images that look superficially similar, but it cannot understand why Picasso painted it, cannot feel what he felt, and cannot intend to communicate meaning as he did.Humans are creative beings. While AI can have a place in our creativity, that doesn’t mean it should replace it. The framing for it to be a powerful creative tool is there, and I hope the information above helps distinguish that. I hope the larger community engages and calls me out for any gaps or inconsistencies I’ve missed when working through this — I’m sure there are many, and I’d love a larger dialogue to form out of this.To summarize everything:Generative AI produces content without regard for truth or meaning.AI-generated content merely highlights patterns found in data without genuine understanding or regard for truth. It doesn’t think, feel, or understand, it employs the aesthetics of thought, feeling, and understanding.We build meaning creatively by reflecting on what is generated.When we interact with AI-generated content, we imbue it with meaning. By manipulating this content correctly, AI can become a tool to enhance creative processes.Pull, Push, Produce.Design AI systems to gather the context of a creative pursuit. Use this context to prompt users to think and act more creatively, and guide AI to generate content that aligns more closely with the user’s vision.Model creative processes, map contextual data, and assign the right tasks.Understand the environment your user works within and the struggles they face. Create a balance between the human and the AI that supports and nurtures the user's creative goals, rather than simply automating it with AI.Consider all of the Human.Generally, even outside creative realms, I hope this article helps those who build things to think more deeply about the relationship between humans and technology, why we build things using technology, and why we don’t.Thanks y’all. I love you.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*gG-e4hWrPZJtxgpbSXCBvQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@bharwood?source=post_page---byline--dcc62100a7a4--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Brandon Harwood\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*zF7YrKoE7zO_00WeU9EOzw.jpeg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--dcc62100a7a4--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"a3a1\"\u003eBefore we begin, I want you to consume this painting.\u003c/p\u003e\u003cp id=\"f4c4\"\u003eIf you know the story, the details might already scream at you.\u003c/p\u003e\u003cp id=\"ddec\"\u003eHowever, if you’re unfamiliar with it, consider the content of the painting, read into the details, and build a story about it.\u003c/p\u003e\u003cp id=\"ddca\"\u003eTry to understand why Picasso painted this.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eGuernica, the town, \u003ca href=\"https://apps.euskadi.eus/en/top-experiences/guernica-air-raid-shelter-route/aa30-12375/en/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eEuskadi.eus\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"97f6\"\u003eThe painting is named after Guernica, the Basque town in Northern Spain, pictured above.\u003c/p\u003e\u003cp id=\"0f57\"\u003eOn April 26th, 1937, about 6 weeks before the painting was unveiled at the Paris International Exposition, the population was about 7000.\u003c/p\u003e\u003cp id=\"4347\"\u003eIn addition to the local civilian population, the town housed a communications center for the antifascist Spanish Republic during the Spanish Civil War, and so it was bombed by Nazi Germany and Fascist Italy — an intentional attack on not just the military forces, but the civilians that inhabited the town, to send a message.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"ca11\"\u003eScroll back up and look at the painting again.\u003c/p\u003e\u003cp id=\"e2c6\"\u003eWhen you’re done, come back here.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp id=\"de4c\"\u003eIf you didn’t know the story of this painting beforehand, now you do, and it might strike a different chord, if just slightly. The details of the painting now have the context that shows us what Picasso was thinking when he painted Guernica. The strained expression on the horse. The cold stare of the bull. The fallen soldier below the crying mother holding her dead child. The people of Guernica hold a candle that sheds a small ray of hope and growth for their fellow citizens while the light bulb, emitting no light, observes.\u003c/p\u003e\u003cp id=\"60ef\"\u003e\u003cstrong\u003eIt’s \u003cem\u003ethis kind of context\u003c/em\u003e that drives meaning in art. \u003c/strong\u003eGuernica is not just a painting. It’s communication. It’s a very human way to express the feelings, experiences, and politics Picasso intended to express behind it. It’s a vessel of meaning built through words, actions, and paint. It\u0026#39;s not just the product of a paintbrush hitting a canvas, but the product of a complex series of events and decisions made by its creator. \u003cem\u003eThis \u003c/em\u003eis why Guernica has become such a protected piece of art, and why we still know its story today.\u003c/p\u003e\u003cp id=\"10ab\"\u003eAnd one day, that story will be lost to time. And, if for some reason, the painting has survived past its story, the people in this future can only speculate about what it means. But the details will be there, and the choices made by Picasso, expressed through those details, will guide the viewers to try and help them understand his feelings, experiences, and politics.\u003c/p\u003e\u003cp id=\"d153\"\u003e\u003cstrong\u003eBut this isn’t an essay about art. It’s about technology, and what it can and cannot do in art.\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"0c01\"\u003eI started with this message because so much of our creative communication as human beings so deeply depends on the emotion, connection, and meaningful context created and consumed between the creator and consumer. If I (Brandon) tell you (the reader) I love you, that’s very different from someone you actually care about, someone you have a history with telling you \u003cem\u003ethey\u003c/em\u003e love you. Real, true communication between people, especially through art, requires emotion, connection, context, and meaning.\u003c/p\u003e\u003cp id=\"10b0\"\u003eUnfortunately for some, but to the benefit of the rest of us, those are all things that artificial intelligence lacks within the content it generates.\u003c/p\u003e\u003ch2 id=\"95e3\"\u003eThe aesthetic of communication\u003c/h2\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003eRed and Blue Macaw\u003c/strong\u003e, Allen \u0026amp; Ginter, 1889\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"0822\"\u003eIf the above is an example of why people can generate content that communicates meaning and intention, I think it’s important to distinguish why AI-generated content cannot.\u003c/p\u003e\u003cp id=\"5791\"\u003eGenerative AI models are pattern visualization machines. LLMs process the words provided to them by computing an analysis of the relationships of those words, how often they appear together, and the different contexts they appear together within the collected data it’s trained on. These relationships are what inform the probability of the next word or token in a sequence of words or tokens.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003eTemperature: 1\u003c/strong\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003eTemperature: 2\u003c/strong\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"a063\"\u003eThis is why \u003ca href=\"https://ai.stackexchange.com/questions/32477/what-is-the-temperature-in-the-gpt-models\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003etemperature\u003c/a\u003e is such an important factor in getting AI systems to generate anything we perceive as meaningful. A lower temperature instructs the model to generate tokens that have a higher probability of coming after the tokens provided, which more often \u003cem\u003elooks \u003c/em\u003elike what we might see as an elaborate, well-thought-out response.\u003c/p\u003e\u003cp id=\"cf96\"\u003eHowever, decreasing the probability of the next token with a higher temperature more often generates content we might see as nonsensical because they’re “further apart” in the training data and aren’t as statistically related to the words input.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003eMidjourney Prompt: \u003c/strong\u003e“A scene indicative of the horrors of war, in the style of Pablo Picasso”\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"4c1b\"\u003eAnother way to visualize this concept is by highlighting bias in AI-generated images.\u003c/p\u003e\u003cp id=\"e954\"\u003eWhen we ask \u003ca href=\"https://www.midjourney.com/home\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eMidjourney\u003c/a\u003e to interpret and produce an image representative of the vague notion of “the horrors of war,” it doesn’t understand what I might mean by that. It associates horror with skeletons, war with soldiers in uniforms and helmets, Picasso with cubist aesthetic style, and Picasso+War+Horror with horses, because those are elements present in Guernica. There are also noticeable influences from other artists with horror styles, like colors and compositional elements you might see from \u003ca href=\"https://www.wikiart.org/en/francisco-goya\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGoya\u003c/a\u003e or \u003ca href=\"https://www.wikiart.org/en/zdzislaw-beksinski\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBeksinski\u003c/a\u003e.\u003c/p\u003e\u003cp id=\"5ecf\"\u003eWhen we discuss bias in AI, the focus is usually on a model\u0026#39;s inability to accurately represent the world because the data it’s trained on lacks information representative of the real world. Some of the most abhorrent examples are also the most obvious; when we rely on AI to represent people through generated images. It often defaults to stereotypes (because the training data says white men are a closer probabilistic image to wealth, and black people are closer to service work).\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003eGenerated with Canva Magic Media February 2024\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"a0b7\"\u003eThe images are racist and sexist because it’s a visualization of data that is racist and sexist. There are efforts to reduce this kind of representational bias in generated images of people, for example, through prompt injection. When you provide a vague prompt for a “fast food worker” it will add details to your prompt around race/age/gender etc. before generating the image to add a level of variety to the more socially “risky” aspects of the image.\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003e“A fast food worker cleaning a table” generated with Canva Magic Media January 2025\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"ae64\"\u003eBut do you notice anything else in these images that points to other, more subtle visualizations of bias?\u003c/p\u003e\u003cp id=\"cae0\"\u003eThe colors, the composition of the images, and the metal reflective tables.\u003c/p\u003e\u003cp id=\"848a\"\u003eDemographics are only one of countless pattern associations in the training data. Prompt injection is a response to the outcry of people (rightfully) calling AI companies out for using racist and sexist data, but it’s just a band-aid solution. It ignores the underlying fact that the architecture of GenAI models doesn’t produce biased content merely due to a lack of data, but because \u003cstrong\u003eAI-generated content is just data visualization of bias, period.\u003c/strong\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cfigcaption\u003e“A city road at night” generated with Canva Magic Media. Notice the patterns in composition, color, visual elements, etc.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"2e22\"\u003eThis is why it’s easier to prompt for a particular style or subject than fine-controlled content. GenAI doesn’t think about the image it’s producing, the form, content, or anything. It’s just math synthesizing meaningful content to mimic\u003cem\u003e the general aesthetic \u003c/em\u003eof meaningful content.\u003c/p\u003e\u003cp id=\"46af\"\u003eIt doesn’t know a human is providing input (or anything else), and it doesn’t take into account what they think about during the creative process. It simply generates text based on patterns of what a conversation looks like (or painting, or photograph, or voice, or…), without a true understanding of the meaning behind the words it generates. Yes, even \u003ca href=\"https://openai.com/o1/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGPT-o1\u003c/a\u003e doesn’t think through or truly understand anything, it merely generates aesthetic text that mimics an internal dialogue, to generate more aesthetic text that mimics external words that come after internal dialogue.\u003c/p\u003e\u003cp id=\"ff36\"\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eBender et al.\u003c/a\u003e call these models “stochastic parrots” for this reason (and \u003ca href=\"https://link.springer.com/article/10.1007/s10676-024-09775-5\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHicks et al.\u003c/a\u003e call them “bullshit”, claiming that the term ‘hallucinations’ is not only incorrect but misleading, as it implies mistakenly incorrect text generated with the intention to tell the truth on part of the AI).\u003c/p\u003e\u003cp id=\"c4ba\"\u003eThere is no intention behind AI-generated text, no regard for the truth — just a likely (or unlikely) next string of data. In the Frankfurtian sense, it truly is bullshit content.\u003c/p\u003e\u003cp id=\"396f\"\u003e\u003cem\u003e(Note: Hicks et al. call ChatGPT bullshit specifically, but I think it’s important to note that it’s not just one model or even the models in general that are bullshit, that’s also anthropomorphizing them. It’s the content produced that is bullshit, as it is content generated without regard for truth or meaning.)\u003c/em\u003e\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"0607\"\u003e“ChatGPT does not communicate meaning — we infer it.”\u003c/p\u003e\u003cp id=\"ec80\"\u003e— Indi Young\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"b7e3\"\u003eThis is a fundamental flaw in the reliance on generative AI alone as a means to produce anything creative. Any AI-generated content produced without human input and/or iteration is just weighed averages of collected data points that represent the output of conscious human thought processes — our text, our photographs, our paintings, our music — and reduces them to their aesthetics without regard for the truthful context or meaning we as humans try to convey through these creative or documentative mediums. It’s like a search engine for generalities.\u003c/p\u003e\u003cp id=\"2664\"\u003eAnd because it’s limited to producing only generalities, it cannot learn or understand the contextual gaps in data as we can. It cannot make creative decisions, or appreciate them. It can only highlight patterns in the noise that make statistical sense to highlight given what comes before, leaving us only to judge those patterns.\u003c/p\u003e\u003cp id=\"1afd\"\u003eWhen we read human-written text, there is deeper thought, feeling, and intention present. The words do not always represent the writer\u0026#39;s deeper thoughts/feelings/intentions, but this is part of what makes great artists or communicators — the ability to articulate those deeper parts of the self and communicate with people directly or indirectly through the artifacts they build.\u003c/p\u003e\u003cp id=\"82c5\"\u003eBut not everyone is an artist, and few people are great at communicating, despite the fact that they have those same kinds of thoughts, feelings, and intentions behind the text they write and the art they produce.\u003c/p\u003e\u003cp id=\"ba78\"\u003e\u003ca href=\"https://medium.com/inclusive-software/insta-personas-synthetic-users-fc6e9cd1c301\" rel=\"noopener\"\u003eIndi Young touches on this\u003c/a\u003e through the lens of user research. When we interview people or read their reviews, the users are trying to convey their thoughts and opinions about an application. We record these thoughts, and when we play them back we often need to work through and interpret them to truly understand what they meant. People say things but mean other things \u003cem\u003eway\u003c/em\u003e more often than we’d like to admit.\u003c/p\u003e\u003cp id=\"8d2f\"\u003eThis is why the concept of \u003ca href=\"https://www.nngroup.com/articles/synthetic-users/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003esynthetic users\u003c/a\u003e or “user research without the users” just doesn’t work as a means to replace humans — the text built out of user interviews is merely an end-product of the nuanced lived experiences of people. It’s hard work to read through text or interview transcripts and build a meaningful understanding of the context or reasoning behind what’s recorded, and that context and reasoning are \u003cem\u003ecompletely\u003c/em\u003e absent in AI training.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"f3f4\"\u003eWhen we talk about the aesthetics of communication, we’re talking about the patterns present in recorded content without the knowledge or understanding of how those patterns came to be in the first place. If generative AI is only able to synthesize and generate the aesthetics of communication, then it ultimately fails to capture the richness, nuance, and intent behind human expression.\u003c/p\u003e\u003cp id=\"c97f\"\u003eBeyond the fundamental limitations of AI as pattern visualization, I also want to acknowledge that a large number of these models are built by training on vast collections works without consent or compensation. The same artists, writers, and musicians whose work these tools aim to replace, have had their own creative output scraped and used to train these systems. We’re replacing artists\u0026#39; work and perspective with soulless, perspectiveless synthetic malappropriations of their work. Some companies are building models that exclusively use content they have the rights to (e.g. Pleias \u003ca href=\"https://huggingface.co/blog/Pclanglais/common-models\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003erecently released\u003c/a\u003e a few models trained “exclusively on data that are either non-copyrighted or are published under a permissible license.”) but regardless, the data sourcing of these models needs reform, and the tools built from them need to understand not only that they \u003cem\u003ecannot\u003c/em\u003e replace artists work, but it’s poor design to try.\u003c/p\u003e\u003cp id=\"d9fe\"\u003eArtists share with each other, directly and indirectly. They are informed and inspired by one another. Directly, they talk with and learn from each other. Indirectly, they use each other\u0026#39;s works as references for their own works. This indirect sharing and consuming of open knowledge is extremely important for building a larger cultural sphere of communication and influence for artists that space and time.\u003c/p\u003e\u003cp id=\"7371\"\u003eExtending this knowledge-sharing gives us a framework for how we might design useful products for creative contexts. The patterns and insights that emerge from data synthesis provide utility— not as replacements for human creativity, but as tools that can highlight new directions, validate assumptions, or spark creative exploration.\u003c/p\u003e\u003cp id=\"6a8d\"\u003eThe problem isn’t with the technology itself or its use in creative contexts. The problem is that most applications built on GenAI try to replace creative people with poor simulacrums of their own work, rather than helping them harness these rich, implicit knowledge patterns to reach new creative heights.\u003c/p\u003e\u003cp id=\"ba63\"\u003eThis is a common pattern in design for emergent technology.\u003c/p\u003e\u003ch2 id=\"db17\"\u003e\u003cstrong\u003eDesigning around the Machine\u003c/strong\u003e\u003c/h2\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003ePunctuation Personified\u003c/strong\u003e, John Harris, 1824\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"cabf\"\u003eQuite often, “AI solutions” are built as a result of the technology being merely available to build with and an opportunity to be had, and not as a means to solve a problem that the technology is particularly good at solving. We’re designing around the machine, not the context.\u003c/p\u003e\u003cp id=\"e1f5\"\u003eThis isn’t a bad thing on its own — speculative design can lead to useful insights about potential futures, and reflecting on these experiments helps us understand what problems a new technology is good at solving, and what it’s not.\u003c/p\u003e\u003cp id=\"63ea\"\u003eThe problem is the disconnect between the motivations and intentions between research institutions and startups. When we build these experiments and call them products without carefully involving and learning from the people we’ve supposedly designed them for, and with the pressure of tight turnarounds for profit and risk-taking, the solutions become just that; experiments. We’re not considering the people we build for; we’re building something for ourselves and marketing it as the next big thing. It’s costly when it fails, and harmful before it does.\u003c/p\u003e\u003cp id=\"11ef\"\u003eThe large majority of attempts to inject AI into creative spaces, while marketed as tools for artists, writers, or musicians, are in reality just attempts to replace them because we don’t consider the actual needs or mental models of creative people. In art especially, the people building these experiments are often not artists themselves. They’re building experiments that help people to \u003cem\u003eavoid \u003c/em\u003ebecoming artists. They don’t see or care about what artists \u003cem\u003edo\u003c/em\u003e, or \u003cem\u003ehow\u003c/em\u003e they do it, they care about the end product of their work. Then they use AI to build a shortcut to that end product because that’s what they see it produce — an aesthetic of an end product without the understanding of how the work it imitates comes to be in the first place.\u003c/p\u003e\u003cp id=\"af49\"\u003eUnsurprisingly, the end products of AI tools built this way usually end up replaceable, uninspiring, or boring because \u003ca href=\"https://ia.net/topics/ai-and-the-beauty-of-human-flaws\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eAI alone produces content that is kitsch\u003c/a\u003e. It doesn’t make the kinds of decisions artists make, and when we rely on AI to “do creativity” for us, it generates something that is particularly and specifically \u003cem\u003enot\u003c/em\u003e creative, something that doesn’t tell a story or connect with the human experience. It’s just data visualization.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"3d0a\"\u003e\u003cstrong\u003eSo what do we do with content that doesn’t tell a story, but looks like one?\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"2858\"\u003eWhat \u003cem\u003ecan\u003c/em\u003e we do with images or text or audio produced with no true meaning or understanding of the context surrounding intention?\u003c/p\u003e\u003cp id=\"defe\"\u003eWhat is bullshit useful for?\u003c/p\u003e\u003cp id=\"20e7\"\u003eI’m reminded of my work facilitating design thinking and ideation workshops.\u003c/p\u003e\u003cp id=\"a4a8\"\u003eWhen facilitating people to think creatively, we solve a problem sourced from the limitations of working in and understanding contexts. Facilitation helps folks think outside their normal modes of thinking by providing means to consider their limited context from a new angle.\u003c/p\u003e\u003cp id=\"0d54\"\u003eAs facilitators, we don’t need to understand that context ourselves, nor do we need to have the niche expertise or knowledge our participants have. We just need to be able to get their knowledge out in the open, within a limited context, to help them reflect on it and find the connections, insights, and observations that help them expand their thinking about that context.\u003c/p\u003e\u003cp id=\"766f\"\u003eSometimes, that means interpreting complex topics and asking the obvious beginner questions, or making confidently wrong assumptions. Sometimes it means saying bullshit you know nothing about, not so you provide some grand insight, but so the participants, who do know a thing or two, can respond appropriately and say “Wait what? No, that’s not it, but it reminds me of this thing.” It begins arguments, inspires discussion, or starts new trains of thought \u003cem\u003ebecause \u003c/em\u003eyou’re coming in and participating without understanding the full context.\u003c/p\u003e\u003cp id=\"27fe\"\u003eAs I said earlier, while Generative AI can synthesize its training data into images, it does not inherently understand human desires, needs, or goals. But does providing a window into those insights for humans to summon and observe solve the same problem? Does it help them to gain inspiration, make more informed and creative decisions, or build meaning themselves?\u003c/p\u003e\u003cp id=\"85d0\"\u003eWhen I started working on interaction design for human-AI co-creativity, I worked with IBM Research to explore the question: \u003cem\u003e“How might we help users form accurate mental models of Generative AI in co-creative contexts to build effective human-AI collaboration.”\u003c/em\u003e This research has mostly taken place within the realm of \u003ca href=\"https://www.bah.design/collab-canvas\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eco-creation and design thinking\u003c/a\u003e, but over time, as I’ve run workshops, experimented with AI, and gathered the opinions and insights I covered in the previous section, I’ve come to abstract the way people interact with information and content as a medium for personal thought, regardless of the source of that content. I started to see the connections between these different modes of interacting with information, and the question for my personal research became: “How might we ensure \u003cem\u003ehuman agency and intent\u003c/em\u003e when introducing \u003cem\u003eartificial perspective \u0026amp; bias\u003c/em\u003e within creative contexts?”\u003c/p\u003e\u003cp id=\"49a6\"\u003eWhen we consume AI-generated content, it can become a way to navigate weird, vague, cloud-like collections of patterns in human thought and expression, and despite (or perhaps because of) the lack of meaning behind these generations, we are presented with raw material to build new meaning from. Meaning that can help us shape how we move forward in the real world. This hollow simulacrum of communication now becomes an interface to capture, understand, shape, and represent our creative intentions, goals, thoughts, and feelings.\u003c/p\u003e\u003cp id=\"1f9c\"\u003eHowever, it’s important to note that the concept of gaining creative inspiration and building personal meaning from what is essentially random or pseudorandom information is not a new idea; it is, in fact, a very ancient one. To consider how AI can be useful in creativity, we need to consider where else we build meaning with information, and what AI actually does when we interact with it creatively.\u003c/p\u003e\u003cp id=\"d071\"\u003eLet’s cover this through two concepts.\u003c/p\u003e\u003ch2 id=\"fe86\"\u003eMeaning Machines\u003c/h2\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003cstrong\u003eThe Sun\u003c/strong\u003e, Pamela Colman Smith, 1909\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"a480\"\u003eChris Noessel has been thinking about the question of “\u003ca href=\"https://www.youtube.com/watch?v=x8n74greYFE\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow do you think new things?\u003c/a\u003e” for a long time.\u003c/p\u003e\u003cp id=\"349e\"\u003eIn the talk linked above, Chris describes “Meaning Machines” as mechanisms for noodling semantically, (or changing your frame of mind on a thing by intentionally skewing the semantics of that thing). He gives Tarot as an example, as well as \u003ca href=\"https://en.wikipedia.org/wiki/I_Ching\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eI Ching\u003c/a\u003e, \u003ca href=\"https://en.wikipedia.org/wiki/Haruspex\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHaruspicy\u003c/a\u003e, other esoteric practices, and more modern tools for spiritual fulfillment, like Mad Libs. Please go watch the talk, it’s super interesting.\u003c/p\u003e\u003cp id=\"65f6\"\u003eMeaning Machines are, at their core, \u003cem\u003e“signifiers, randomized into a fixed grammar, and read for new meaning.”\u003c/em\u003e\u003c/p\u003e\u003cp id=\"dc46\"\u003eLet’s consider the Tarot example for a second, and more importantly, let’s examine the interaction design of Tarot: Each card in the deck is a symbol (the signifier) with meaning assigned to it. We randomize the cards by shuffling them, place them on the mat, and interpret them. Depending on how they fall, their placements relative to one another, their direction, etc. we react to and reflect on these symbols \u003cem\u003eas they relate to our life\u003c/em\u003e.\u003c/p\u003e\u003cp id=\"0d08\"\u003eAnd so, we build personal meaning.\u003c/p\u003e\u003cp id=\"7006\"\u003eThis is a creative act! We create meaning and intention for future decisions or outlooks on life out of what is essentially random data presented and interpreted within the context we set and are set within.\u003c/p\u003e\u003cp id=\"d19b\"\u003eWithin the context of strictly creative work, a more practical “analog” example meaning machine is Brian Eno \u0026amp; Peter Schmidt’s “\u003ca href=\"https://www.enoshop.co.uk/product/oblique-strategies.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eOblique Strategies\u003c/a\u003e” — a deck of cards containing cryptic or ambiguous phrases intended to be shuffled and pulled at random to provoke creative thinking and break a creative block. \u003ca href=\"https://sefirot.it/intuiti-creative-cards\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eIntuití\u003c/a\u003e is another, inspired by tarot and using gestalt principles, these cards are intended to help the player better understand their creativity, and inspire the performance of creative acts.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://space10.com/projects/products-of-place\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003eProducts of Place\u003c/strong\u003e\u003c/a\u003e by SPACE10 and oio\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"138b\"\u003eBringing this concept into the digital world, the prototype above was developed by the creative agency \u003ca href=\"https://oio.studio/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eOiO\u003c/a\u003e, in partnership with the now-closed IKEA R\u0026amp;D Lab \u003ca href=\"https://space10.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSPACE10\u003c/a\u003e. It’s an interface where you choose any point in the world, and an AI system identifies and generates a summary of materials that are abundant in that location, often waste material, which can be used or recycled to create new things, like plates!\u003c/p\u003e\u003cp id=\"bcdd\"\u003e\u003cstrong\u003eThe core of the problem I highlighted earlier about AI is that too often we view the output of an AI system as the final product, something to be consumed or distributed as a means to avoid doing the important work. But a more useful application of these artifacts is to incorporate them as materials for use within larger scopes of work. AI systems can become a new kind of meaning machine — a way to add interactivity and deeper, more complex variability to otherwise static signifiers, like cards.\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"dc6b\"\u003eWhen we employ AI like this, we begin to see how we might use it to enhance creative ideation and help people explore creative domains in ways they might not have considered before, rather than relying on the generated content as the final product we push into the world.\u003c/p\u003e\u003cp id=\"3757\"\u003eIn this general context then, the randomized signifiers are the contextual data surrounding our creative pursuit, the data the AI is trained on, and the relationships built on that data through its training. These signifiers, the data, are then placed into a fixed grammar through \u003ca href=\"https://medium.com/@christophernoessel/agentive-tech-and-agentic-ai-cousins-not-adversaries-2a2fa37c3134\" rel=\"noopener\"\u003eagentive interaction and/or agentic actions\u003c/a\u003e, and the user can then interpret the result to stimulate their creativity, build new meaning, or explore ideas they might not have considered before.\u003c/p\u003e\u003cp id=\"0f9f\"\u003eWhen we consider the utility of AI in creativity as a feature that helps us create meaning instead of consuming content, it provides a means for us to frame how we build tools that act as collaborative partners in creative work and stimulate our creative action.\u003c/p\u003e\u003cp id=\"f7ac\"\u003eSo, when building creative tools with this in mind, what should the actual interaction design between humans and AI look like?\u003c/p\u003e\u003ch2 id=\"7695\"\u003e\u003cem\u003eCo-creative AI roles\u003c/em\u003e\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"24d6\"\u003eIn a \u003ca href=\"https://medium.com/@bharwood/ai-as-an-interface-for-creativity-part-1-e3e7462db49c\" rel=\"noopener\"\u003eprevious article\u003c/a\u003e, I broke down the utility of Generative AI within creative domains into three roles: The Puller, the Pusher, and the Producer. I’ll cover them below just briefly.\u003c/p\u003e\u003cp id=\"ad08\"\u003e\u003cstrong\u003eThe Puller: \u003c/strong\u003eThe AI system gathers information about the context the user is working in through active question generation and passive information collection on the works.\u003cbr/\u003e\u003cem\u003eExample: \u003c/em\u003e\u003ca href=\"https://chatgpt.com/g/g-s6EbUJXfK-pulpo\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003ePulpo — a GPT that takes notes about your ideas through interview\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"5fbe\"\u003e\u003cstrong\u003eThe Pusher:\u003c/strong\u003e The AI system uses some/none of this context to synthesize considerations for the user to employ throughout their creative journey.\u003cbr/\u003e\u003cem\u003eExample: \u003c/em\u003e\u003ca href=\"https://designmyui-ee6fa6cec437.herokuapp.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eAn AI Chatbot that redesigns its interface at your command\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"77a6\"\u003e\u003cstrong\u003eThe Producer:\u003c/strong\u003e The AI system creates artifacts for use as elements of the users’ larger creative output. \u003cbr/\u003e\u003cem\u003eExample: \u003c/em\u003e\u003ca href=\"https://www.bah.design/ai/empathy-map\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eA contextually informed sticky note content generator\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\u003cp id=\"fb26\"\u003e\u003cem\u003e(The examples provided show all roles in play because they depend on one another to build a complete AI experience, but are intended to highlight the specific role they’re attached to.)\u003c/em\u003e\u003c/p\u003e\u003cp id=\"bd0e\"\u003eInformed by aesthetic patterns in its training data rather than informed opinion, the AI system can synthesize questions, observations, assumptions, and potentially useful artifacts in response to the users’ expressed/gathered context, goals, needs, thoughts, feelings, and actions.\u003c/p\u003e\u003cp id=\"6019\"\u003eThese actions of “pulling context” to generate “pushed suggestions” provide the user with information that doesn’t require the AI system to have a deeper understanding of their historical context or knowledge around the creative pursuit, but acts as a naive sounding board for them to respond to in reflection of their progress. “Pushing” provides a means for the user to consider new paths, challenging them through artificial assumptions about their work, with the ability to highlight gaps, acting as a kind of meaning machine for facilitating new ideas in context.\u003c/p\u003e\u003cp id=\"c6ba\"\u003e\u003cem\u003e(One note on the Pusher role: It’s important to ensure push systems are designed to make the user feel comfortable rejecting the propositions from the AI— conversational AI “characters” encourage anthropomorphizing the AI, and enforce a subtle power dynamic over the user where there doesn’t need to be one.)\u003c/em\u003e\u003c/p\u003e\u003cp id=\"e34c\"\u003eWhere the Pusher role provokes the user to create their creative ideas or artifacts, the “Producer” role uses GenAI to produce creative artifacts for use. It’s important to consider how we might design our systems to produce \u003cem\u003eartifacts\u003c/em\u003e here, rather than “full works.” This ensures our users’ creative \u003cem\u003eprocess\u003c/em\u003e holds agency rather than simply assuming their intended output. An example of this might be an AI-enabled rapid UI prototyping tool that builds web components based on an established design system, or a lighting simulator to move through options for a film set for technicians to consider and plan before setting up equipment. \u003ca href=\"https://www.adobe.com/products/photoshop/generative-fill.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eGenerative fill\u003c/a\u003e is an example of productive co-creative AI.\u003c/p\u003e\u003cp id=\"bad3\"\u003eOne big point I want to make about these roles is that they intentionally don’t frame generative AI as \u003cem\u003ethe product\u003c/em\u003e, but instead frame it as \u003cem\u003efeatures. \u003c/em\u003eNone of the examples provided work as full products, but components that provide value within larger flows of creativity. As designers, the solutions we create must be holistically useful to our users, and so far, AI seems only to provide useful features that fit neatly within larger solutions. Call them agents or call them bots, they are just tools.\u003c/p\u003e\u003ch2 id=\"9c14\"\u003eDesigning co-creative AI solution concepts\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"a7fb\"\u003eLet’s get into it.\u003c/p\u003e\u003cp id=\"66a5\"\u003eIn this section, I’ll build on the concepts described above to walk through a framework that can act as a basis for setting direction through a workshop (along with an example workshop case study) or framing longer-form user research and AI Interaction design processes. This is intended to help designers or product teams quickly come together to align on a robust design concept for an AI solution informed by creative user needs and intended to understand, react to, and empower creative processes, rather than replace them.\u003c/p\u003e\u003cp id=\"ba49\"\u003eDesigning AI systems that complement rather than replace creative functions is difficult, but dealing with the consequences of betting on AI to be able to do the work of creatives is harder.\u003c/p\u003e\u003cp id=\"ae3a\"\u003eCreativity is something people \u003cem\u003eenjoy\u003c/em\u003e doing, and we’ve already seen why they’re \u003cem\u003ebetter at it \u003c/em\u003ethan machines. When designing systems meant to complement creative processes, it’s important to understand the nuanced aspects of what people \u003cem\u003edo\u003c/em\u003e that build up creative action, \u003cem\u003ewhy \u003c/em\u003ewe enjoy doing it, \u003cem\u003ehow\u003c/em\u003e we move through creativity in our real, human lives, and \u003cem\u003ewhere\u003c/em\u003e we seek help throughout creative journeys.\u003c/p\u003e\u003cp id=\"696f\"\u003eAs I’ve considered where AI might fit within creative domains, where it helps, and where it hurts, I’ve built a framework that I believe can help others think through co-creative human-AI systems. I’ve provided an outline of the framework below:\u003c/p\u003e\u003ch2 id=\"3685\"\u003ePart 1: modeling creativity in context\u003c/h2\u003e\u003cp id=\"e85f\"\u003eThe first step involves building an understanding of creativity in context and how creative people move through creative work. To do this, we can build a mental model of their creative flow and environment, the processes they move through, their goals, and the actions they work through.\u003c/p\u003e\u003cp id=\"a5b8\"\u003e\u003cstrong\u003eTo do this, choose a primary creative persona to focus on, and, ideally by talking with them, map out the following:\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli id=\"21db\"\u003eWhat \u003cstrong\u003emodalities\u003c/strong\u003e do they work in? \u003cem\u003e(e.g. audio, visual, text, concepts, ideas, material, etc.) \u003c/em\u003eand when?\u003c/li\u003e\u003cli id=\"2f97\"\u003eWhat \u003cstrong\u003eactions\u003c/strong\u003e do they perform when being creative? \u003cem\u003e(e.g. ideating, sketching, experimenting etc.) \u003c/em\u003eStart at a high level and break these tasks down, placing them in order.\u003c/li\u003e\u003cli id=\"87d3\"\u003eTo perform these actions, what key \u003cstrong\u003econcepts \u0026amp; principles\u003c/strong\u003e guide their creative practice? \u003cem\u003e(e.g., inspiration, feedback, iteration)\u003c/em\u003e\u003c/li\u003e\u003cli id=\"0309\"\u003eWhere might our persona \u003cstrong\u003estruggle\u003c/strong\u003e, or benefit from outside help along this creative process? Where is the tedium in this process? How could that tedium be useful for them, even indirectly?\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"ca04\"\u003eExample:\u003c/h2\u003e\u003cblockquote\u003e\u003cp id=\"924c\"\u003eAt the \u003ca href=\"https://strat.events/usa/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSTRAT 2024 conference\u003c/a\u003e I ran a short workshop walking the participants through this framework to see if we could build a solution that uses AI in a way that enhances creativity, and within a few hours we conceptualized a rough idea for something I think we were all excited about: a tool to help designers create documentation more efficiently. I’ll outline out process as we move through the framework.\u003c/p\u003e\u003cp id=\"4508\"\u003eAs this was an educational workshop for designers, performed by designers, we started by roughly mapping out these categories on sticky notes that focus on \u003cstrong\u003ethe modalities, actions, concepts, principles, and struggles designers face as a whole\u003c/strong\u003e, so we could narrow down the use case.\u003c/p\u003e\u003cp id=\"5a03\"\u003eHere’s a summary of what we worked through:\u003c/p\u003e\u003cp id=\"fe5b\"\u003e\u003cstrong\u003e\u003cem\u003eModalities:\u003c/em\u003e\u003c/strong\u003e\u003cem\u003e \u003cbr/\u003eConceptual (User Journeys, Psychology, Information Architecture etc.) \u003cbr/\u003eVisual (Graphic Design, Interfaces, Branding etc.)\u003cbr/\u003eInteractive (Accessibility, Usability, Design Systems etc.)\u003c/em\u003e\u003c/p\u003e\u003cp id=\"4bd3\"\u003e\u003cstrong\u003e\u003cem\u003eActions, concepts, \u0026amp; principles: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eConceptualize / Define / Plan / Develop / Research / Iterate / Experiment / Develop / Simplify / Annotate / Decide / Prioritize / Document / (and much more)\u003c/em\u003e\u003c/p\u003e\u003cp id=\"7ed1\"\u003e\u003cstrong\u003e\u003cem\u003eStruggles:\u003c/em\u003e\u003c/strong\u003e\u003cem\u003e Prioritizing \u0026amp; Understanding Project Needs / Documenting Decisions / Communicating Reasoning / Reconciling \u0026amp; Articulating User and Business Needs / Feedback Without Context / Lack of Data / Ethical Decision Making / Understanding Long-term Implications.\u003c/em\u003e\u003c/p\u003e\u003cp id=\"7f7a\"\u003eAfter mapping these out, we played it back and talked through where in the process of design we’d really love some help, and landed on documenting data used for design decisions, and documenting design reasoning. We ended this part of the workshop aligning on the following context to design a solution for:\u003c/p\u003e\u003cp id=\"522e\"\u003e\u003cstrong\u003e\u003cem\u003eDesigners Tasked with Design Documentation \u003c/em\u003e\u003c/strong\u003e\u003cem\u003ereally struggle through the tedium of capturing, formatting, and sharing the reasoning and historical decisions of their design process, especially when they don’t have the time or resources to format it properly. This affects their relationships with developers, business stakeholders, and future designers iterating on their work. Designers in the workshop also agreed that while they understood the utility of documentation, they just didn’t \u003c/em\u003eenjoy\u003cem\u003e they process, making it a good target for creating a system that eases their workload.\u003c/em\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003ch2 id=\"b9dc\"\u003ePart 2: mapping contextual data\u003c/h2\u003e\u003cp id=\"5478\"\u003e\u003cstrong\u003eIn this step, identify and map the data surrounding these creative tasks, categorizing them into what AI can pull, push, or produce.\u003c/strong\u003e\u003c/p\u003e\u003cp id=\"5bbc\"\u003e\u003cstrong\u003eFirst, gather the types of Input, Output, and Contextual information/data/artifacts involved in the mental model we built. Consider:\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli id=\"7133\"\u003eWhat might our persona \u003cstrong\u003eneed, use, observe, or consume\u003c/strong\u003e as part of their creative process? \u003cem\u003e(e.g., reference images, past work, market trends)\u003c/em\u003e\u003c/li\u003e\u003cli id=\"39e9\"\u003eWhat might our persona \u003cstrong\u003ecreate\u003c/strong\u003e, and what are the artifacts produced? \u003cem\u003e(e.g., sketches, drafts, final products)\u003c/em\u003e\u003c/li\u003e\u003cli id=\"d7d0\"\u003eWhat \u003cstrong\u003econtextual information\u003c/strong\u003e is relevant to our persona\u0026#39;s creative task? \u003cem\u003e(e.g., mindset, beliefs, political climate, project constraints)\u003c/em\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"a9a8\"\u003e\u003cstrong\u003eThen, consider the most useful information, data \u0026amp; artifacts our AI could pull, push, or produce for our persona, asking questions like:\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli id=\"9a63\"\u003e\u003cstrong\u003ePull:\u003c/strong\u003e What can/should be gathered from our persona or other various sources to inform the larger creative context? \u003cem\u003e(e.g. reasoning, info about the work, outside inspiration)\u003c/em\u003e\u003c/li\u003e\u003cli id=\"16b4\"\u003e\u003cstrong\u003ePush:\u003c/strong\u003e Where can AI most usefully generate suggestions, insights, or new ideas in the process? \u003cem\u003e(e.g. creative directions, variations of work, material recommendations)\u003c/em\u003e\u003c/li\u003e\u003cli id=\"316a\"\u003e\u003cstrong\u003eProduce:\u003c/strong\u003e What content or artifacts might AI produce directly that are useful to, but don’t replace our user\u0026#39;s final output? \u003cem\u003e(e.g. prototypes, elements, color palettes, code snippets)\u003c/em\u003e\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"6ae7\"\u003eExample\u003c/h2\u003e\u003cblockquote\u003e\u003cp id=\"5018\"\u003eMapping out data designers work with during documentation, what they produce as a result, and the contextual data surrounding documentation, some examples of what we ended up with included:\u003cem\u003e\u003cbr/\u003e \u003c/em\u003e\u003cbr/\u003e\u003cstrong\u003e\u003cem\u003eInput Data: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eProduct requirements / The “why” / Stakeholder input / User Personas / The “where” / Modality of content\u003c/em\u003e\u003cstrong\u003e\u003cem\u003eOutput Data: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eWireframes / prototypes / mockups / Annotations / Design iterations / Design system components / Instructions / Tokens\u003c/em\u003e\u003cstrong\u003e\u003cem\u003eContextual Data: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eBrand / Time constraints / Developer capabilities / Budget constraints / Designer limitations / Origins of decision reasoning\u003c/em\u003e\u003c/p\u003e\u003cp id=\"104e\"\u003eThen we mapped this data to that which AI might most usefully push, pull, and produce to make documentation easier for designers.\u003c/p\u003e\u003cp id=\"3743\"\u003e\u003cstrong\u003e\u003cem\u003ePull: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eProduct requirements / User Input / Annotations / Clarification of reasoning / design versions / Connections to Brand System\u003c/em\u003e\u003c/p\u003e\u003cp id=\"e8f3\"\u003e\u003cstrong\u003e\u003cem\u003ePush: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eReasoning summaries\u003c/em\u003e\u003c/p\u003e\u003cp id=\"a14f\"\u003e\u003cstrong\u003e\u003cem\u003eProduce: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eFormatted Documentation Data / Historical Captures of Reasoning / Audience-adapted Explanations\u003c/em\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003ch2 id=\"762d\"\u003eWorkshop part 3: human/AI interaction design\u003c/h2\u003e\u003cp id=\"7a15\"\u003eWith our context in mind and the necessary components in place, determine the interaction design and task assignments for our System, Persona, and AI, and what the result of this interaction will look like. In this step, it’s important to consider the specific, tangible capabilities AI can perform while interacting with a user or system.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003e\u003ca href=\"https://designingwithai.ch/ai-for-designers\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cstrong\u003e\u003cem\u003eA very useful resource for thinking about discrete GenAI Capabilities is Designing With: \u003c/em\u003e\u003c/strong\u003e\u003cem\u003eA New Educational Module to Integrate Artificial Intelligence, Machine Learning and Data Visualization in Design Curricula\u003c/em\u003e\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"b816\"\u003e\u003cstrong\u003eFirst, using the mental model, data categories, and AI capabilities; outline key tasks throughout the creative process you’re examining:\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli id=\"be57\"\u003e\u003cstrong\u003eHuman Tasks: \u003c/strong\u003eWhat should remain human-centric due to the need for judgment, intuition, emotional intelligence, or simply because people enjoy doing it?\u003c/li\u003e\u003cli id=\"de3c\"\u003e\u003cstrong\u003eAI Tasks: \u003c/strong\u003eReview the AI Capabilities List. How might the AI help our user through their creative journey? \u003cem\u003e\u003cbr/\u003eHint: Consider explicitly highlighting both the capability and data/output e.g. “Summarize rough notes into formatted documentation”\u003c/em\u003e\u003c/li\u003e\u003cli id=\"90ff\"\u003e\u003cstrong\u003eSystem Tasks: \u003c/strong\u003eWhat roles or tasks does the broader system play out to support the interaction? (e.g., storing data, managing data flow, communicating, committing)\u003c/li\u003e\u003c/ol\u003e\u003cp id=\"13fc\"\u003e\u003cstrong\u003eThen, review your work so far. Map out how your persona, AI, and System interact. Include:\u003c/strong\u003e\u003c/p\u003e\u003col\u003e\u003cli id=\"27cf\"\u003e\u003cstrong\u003eData Categories \u0026amp; Examples:\u003c/strong\u003e Clearly mark input, output, and contextual data points.\u003c/li\u003e\u003cli id=\"7fdd\"\u003e\u003cstrong\u003eTask Assignments:\u003c/strong\u003e Use distinct symbols or colors to differentiate between human, AI, and system tasks.\u003c/li\u003e\u003cli id=\"dd36\"\u003e\u003cstrong\u003eInteractions \u0026amp; Flows: \u003c/strong\u003eDraw lines/arrows to show how data \u0026amp; tasks interact, illustrating the flow of the creative process.\u003c/li\u003e\u003cli id=\"eabf\"\u003e\u003cstrong\u003eFeedback Loops: \u003c/strong\u003eHighlight any iterative steps or feedback loops that influence the process.\u003c/li\u003e\u003c/ol\u003e\u003ch2 id=\"5321\"\u003eExample:\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cblockquote\u003e\u003cp id=\"06e8\"\u003e\u003cem\u003eIn the end, we outlined a system intended to recognize patterns in documentation artifacts, supplement them by identifying gaps, posing clarifying questions, re-framing design decisions to fit the context alongside historical reasoning, and format everything to system standards. The result was a collaborative system where designers remain in control while AI assists in enhancing clarity and completeness, building more robust documentation while easing the process for the designer.’’\u003c/em\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"497d\"\u003e\u003cstrong\u003eHere’s another example of an interaction design flow that could be built as a result of this framework:\u003c/strong\u003e\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"7bb7\"\u003eThis is an outline for an AI system that gathers information about a user\u0026#39;s dream, tracks the symbols and themes, curates information, and forms connections that provide them the tools to interpret and analyze their dreams at a deeper level (rather than relying on the AI to act as an authority and analyze their dreams for them).\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eExample of how this could be articulated through a UI beyond a chatbot.\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"4a89\"\u003eConclusion\u003c/h2\u003e\u003cp id=\"8169\"\u003eRemember Guernica. When we look at it, we don’t just see patterns of paint on canvas — we see Picasso’s horror at civilian bombing, his protest against fascism, and his attempt to communicate profound human suffering. AI can analyze Guernica’s composition, mimic its cubist style, or generate images that look superficially similar, but it cannot understand why Picasso painted it, cannot feel what he felt, and cannot intend to communicate meaning as he did.\u003c/p\u003e\u003cp id=\"2fbf\"\u003eHumans are creative beings. While AI can have a place in our creativity, that doesn’t mean it should replace it. The framing for it to be a powerful creative tool is there, and I hope the information above helps distinguish that. I hope the larger community engages and calls me out for any gaps or inconsistencies I’ve missed when working through this — I’m sure there are many, and I’d love a larger dialogue to form out of this.\u003c/p\u003e\u003ch2 id=\"10cc\"\u003eTo summarize everything:\u003c/h2\u003e\u003cp id=\"bfdb\"\u003e\u003cstrong\u003eGenerative AI produces content without regard for truth or meaning.\u003c/strong\u003e\u003cbr/\u003eAI-generated content merely highlights patterns found in data without genuine understanding or regard for truth. It doesn’t think, feel, or understand, it employs the aesthetics of thought, feeling, and understanding.\u003c/p\u003e\u003cp id=\"3559\"\u003e\u003cstrong\u003eWe build meaning creatively by reflecting on what is generated.\u003c/strong\u003e\u003cbr/\u003eWhen we interact with AI-generated content, we imbue it with meaning. By manipulating this content correctly, AI can become a tool to enhance creative processes.\u003c/p\u003e\u003cp id=\"ac20\"\u003e\u003cstrong\u003ePull, Push, Produce.\u003c/strong\u003e\u003cbr/\u003eDesign AI systems to gather the context of a creative pursuit. Use this context to prompt users to think and act more creatively, and guide AI to generate content that aligns more closely with the user’s vision.\u003c/p\u003e\u003cp id=\"8f91\"\u003e\u003cstrong\u003eModel creative processes, map contextual data, and assign the right tasks.\u003c/strong\u003e\u003cbr/\u003eUnderstand the environment your user works within and the struggles they face. Create a balance between the human and the AI that supports and nurtures the user\u0026#39;s creative goals, rather than simply automating it with AI.\u003c/p\u003e\u003cp id=\"50f7\"\u003e\u003cstrong\u003eConsider all of the Human.\u003cbr/\u003e\u003c/strong\u003eGenerally, even outside creative realms, I hope this article helps those who build things to think more deeply about the relationship between humans and technology, \u003cem\u003ewhy\u003c/em\u003e we build things using technology, and why we don’t.\u003c/p\u003e\u003cp id=\"ffca\"\u003eThanks y’all. I love you.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "41 min read",
  "publishedTime": "2025-01-27T22:57:00.195Z",
  "modifiedTime": null
}
