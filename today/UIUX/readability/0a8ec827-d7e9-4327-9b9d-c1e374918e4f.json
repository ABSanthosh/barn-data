{
  "id": "0a8ec827-d7e9-4327-9b9d-c1e374918e4f",
  "title": "Kick-start your continuous user research in 5 steps",
  "link": "https://uxdesign.cc/kick-start-your-continuous-user-research-in-5-steps-5713228bfccf?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Audrey Hacq",
  "published": "Thu, 06 Feb 2025 23:22:13 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "continuous-research",
    "user-research",
    "feedback",
    "product",
    "discovery"
  ],
  "byline": "Audrey Hacq",
  "length": 10547,
  "excerpt": "It’s been a while since I last wrote an article, and I must admit I’ve missed sharing what I learn daily with the design community ❤. For this one, I want to walk you through how my team and I set up…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Identify and map your key user feedback sources to streamline your research process and maximize impact!It’s been a while since I last wrote an article, and I must admit I’ve missed sharing what I learn daily with the design community ❤.For this one, I want to walk you through how my team and I set up a Continuous Research process at OpenClassrooms, and how it helped us deliver better insights to feed the roadmaps and ultimately improve our users’ experience.By the end of this article, you should be able to do the same for your product!Let’s dive in!But wait! Before starting: why should we do this?You’re right to ask that question! :)One of my core beliefs is that User Research should have a strong impact within a company while remaining efficient and time-effective. Unfortunately, this is not always the case: in some companies, user research can slow down decision-making or lead to poor strategic choices.The main objectives of Continuous Research are:Regularly and easily gathering user feedback on strategic parts of the productConsolidating knowledge about usersEnabling fast and user-centric decision-makingCollecting user feedback continuously helps prioritize the roadmap, improve user experience, and speed up iteration cycles.Step 1: Identify Existing Feedback SourcesHave you ever noticed that User Research is very similar to data analysis? Just like with data, structuring and cleaning your sources before extracting valuable and actionable insights is crucial.You can collect feedback from various sources (Trustpilot, Appstore, Zendesk, Surveys…)To start your Continuous Research process, here are the questions you need to ask yourself:Who in the company already has regular contact with users? (e.g., Sales, Customer Success)Do they already collect regular feedback and how? (e.g., surveys, CSAT, calls)How do these sources perform? (e.g., number of monthly responses)Is this feedback regularly analyzed and by whom?What is the purpose of these feedback sources?What kind of insights do they generate?From these sources, identify the ones relevant for Continuous Research, eliminate duplicates, and remove those that don’t provide real value. Favor sources that will bring relevant insights over the long term.Clean up redundant or low-value feedback sources that lack clear ownership or objectives.Step 2: Map the Feedback SourcesNow that you identified the most relevant feedback sources, you can start mapping them on every stage of the User Journey to have a good overall vision of what’s available. You might also need to create new feedback sources as strategic touchpoint for business objectives that are not yet covered. Anyway, I really recommend starting small and complete your mapping one step at a time.At OpenClassrooms, we categorized different types of sources feeding Continuous Research:Different types of users feedback sourcesStep Experience Surveys — Feedback on a User Journey stepThese are the primary feedback sources for squads’ Continuous Research. We have one survey at the end of each step, composed of three main parts:1. CSAT — Customer Satisfaction It measures satisfaction on specific parts of the user experience.The question is “How satisfied are you with the [Step Name] process?”.2. CES — Customer Effort It measures the effort required for specific actions.The question is “Completing this [Action or Step] seemed: very easy to very difficult”.3. Qualitative feedbackThis open question provides context for the ratings, helping us understand the “why” behind user scores and gather improvement ideas.We add a question at the end to collect emails from users interested in improving the product, creating a user pool for testing and interviews!Recently, we tested adding a question about step clarity to assess whether the available information is clear and useful. This will help us measure the impact of Content Design more precisely.NPS surveys — Feedback on the global ExperienceNet Promoter Score (NPS) measures customer loyalty toward the Brand. The qualitative feedback informs the company about users’ main concerns and expectations regarding their global experience with the product or service. The question is “Would you recommend [Name of the company]?”.NPS is widely debated as it provides broad feedback that is not always directly actionable. However, categorizing responses into themes allows us to the monitor changes in user satisfaction and dissatisfaction over time and better understand why.Temporary sources — Feedback pre- or post-releaseThese are temporary sources, launched for a specific purpose and having having a lifetime of 1 to 6 months. They include surveys, user tests, and interviews that help gather feedback on a particular topic.Example of specific survey for the Matching step — Illustration by Fabien GoubyExternal sourcesThese are third-party sources like App Store reviews, Google ratings, or Trustpilot. While you don’t control them, analyzing them helps validate insights and spot trends that align — or not — with your own insights.Example of external feedback source — TrustpilotGet more information on Continuous Research in this article.Step 3: Document Feedback SourcesNow that you’ve started mapping your sources, you can take it a step further by documenting each one more precisely:Objective: What do we want to measure? How does this feed into our strategy and inform decisions?Source: Where is it stored? In which tool?Format: How is feedback collected? (e.g., in-product, email, call)Trigger: At what stage is feedback requested? Is there a specific trigger?Filter: Are specific user segments targeted?Number: How many responses are received monthly? Is the source performing well?Card template to map your feedback sourcesIt makes it easy for everyone on the team to understand what sources exist and what they are used for.Clarifying this information helps teams understand existing sources and their purposes while ensuring easy access to raw data if needed. It also prevents redundant surveys that ask similar questions — And your users will thank you for that! :)I strongly encourage you to do this in collaboration with other teams (e.g., marketing, support, sales, …). This mapping should also belong to them, and they should be able to help you update and improve it.Step 4: Analyze Feedback RegularlyYou now have feedback sources that are relevant, mapped, and documented: well done!But unanalyzed feedback has no value, agree? Now, you need to ensure this material is analyzed regularly without overwhelming teams. At OpenClassrooms, we review feedback monthly, typically at the end of each month.All feedback is automatically stored in a dedicated folder in our Research Repository:List of continuous research projectsWe can import multiple sources into the same folder, allowing us to cross-analyze user interviews, Step Experience surveys, and external sources. This enhances the reliability of insights by merging different perspectives.Product Designers analyze feedback within their scope, tagging and categorizing it appropriately:Feedback analysis in our Research RepositoryThis ensures Designers and Product Managers gain a deeper understanding of users’ concerns while keeping the process efficient.But this process of tagging content can be time-consuming. To optimize it further, we’re experimenting with AI to assist in analyzing and automatically categorizing feedback. If you’re interested in our first tests, check out this article:Step 5: Present Insights and Drive DecisionsThese regular analyses help us generate valuable insights into user pain points and closely monitor satisfaction and effort over time.Each month, Product Designers present their findings, combining them with Product Managers’ insights and data. This forms what we call the “Squad’s Monthly Reports”, which help prioritize roadmap topics based on criticality and business objectives.Findings are widely shared with the squads, stakeholders and leadership members.Depending on the objectives, we can present results in different ways:Categorized feedback by userSplit of categories regarding our Alumni’ feedbackThis allows teams to quickly identify patterns and trends. By comparing the proportion of different feedback themes, we can prioritize the most critical user concerns and ensure that decision-making is data-driven. It can impact the roadmap of all teams across the company, not just the Product team (e.g., Learning team, Mentorship team, Student Success team).Top three pain points for a given step3 main user pain points for the Application stepThis can directly help prioritize the squad roadmap and identify key pain points that require deeper analysis or further exploration in the next product discovery phase.Evolution of Satisfaction and Effort over timeThis allows us to correlate user satisfaction with business objectives. For example, if application rates drop, we can examine the Satisfaction and Effort scores for this step and analyze qualitative feedback to identify potential causes.It also helps us assess the impact of new releases. For example, whenever we make a change to the funnel, we analyze our “Application Experience KPI” to determine whether it reduces effort and enhances satisfaction.We can now track this evolution across all squads and have begun setting teams goals based on those scores:Exemple of Satisfaction evolution over time for 3 squadsWhat’s next?When launching your first surveys, you’ll likely find some ineffective. Some may not receive enough responses, while others may provide non-actionable feedback. This is normal — you won’t get everything right on the first try! :)You will need to regularly iterate on your feedback sources: add new ones, remove ineffective ones, and adjust placement, channels, or questions as needed.At OpenClassrooms, we continuously monitor Feedback sources performance and refine our approach accordingly.Impact of Continuous Research on Product StrategyTime-saving: Collecting and analyzing feedback becomes easier. Teams no longer have to start from scratch.Deeper user insights: Ongoing analysis enhances user understanding and empathy.Cross-team impact: Insights influence not only product roadmaps but also Customer Success, Sales, and Marketing.Proactive issue detection: Monitoring scores helps identify trends and take corrective action before problems escalate.Key numbers10+ Continuous research folders created900+ Feedback pieces analyzed monthly20+ Actionable insights generated each month, directly influencing product strategy",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*eNPKZ9hRmnjdTYVH7IWwcw.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003ch2 id=\"2ebf\"\u003eIdentify and map your key user feedback sources to streamline your research process and maximize impact!\u003c/h2\u003e\u003cdiv\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://audreyhacq.medium.com/?source=post_page---byline--5713228bfccf--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Audrey Hacq\" src=\"https://miro.medium.com/v2/resize:fill:88:88/0*geIfMVXr31AXmuFT.jpg\" width=\"44\" height=\"44\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003cdiv aria-hidden=\"false\"\u003e\u003ca href=\"https://uxdesign.cc/?source=post_page---byline--5713228bfccf--------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"UX Collective\" src=\"https://miro.medium.com/v2/resize:fill:48:48/1*mDhF9X4VO0rCrJvWFatyxg.png\" width=\"24\" height=\"24\" loading=\"lazy\" data-testid=\"publicationPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"c853\"\u003eIt’s been a while since I last wrote an article, and I must admit I’ve missed sharing what I learn daily with the design community ❤.\u003c/p\u003e\u003cp id=\"9a6f\"\u003eFor this one, I want to walk you through how my team and I set up a Continuous Research process at OpenClassrooms, and how it helped us deliver better insights to feed the roadmaps and ultimately improve our users’ experience.\u003c/p\u003e\u003cp id=\"c6e8\"\u003eBy the end of this article, you should be able to do the same for your product!\u003c/p\u003e\u003cp id=\"6f16\"\u003eLet’s dive in!\u003c/p\u003e\u003ch2 id=\"5dcd\"\u003eBut wait! Before starting: why should we do this?\u003c/h2\u003e\u003cp id=\"3905\"\u003eYou’re right to ask that question! :)\u003c/p\u003e\u003cp id=\"284f\"\u003eOne of my core beliefs is that User Research should have a strong impact within a company while remaining efficient and time-effective. Unfortunately, this is not always the case: in some companies, user research can slow down decision-making or lead to poor strategic choices.\u003c/p\u003e\u003cp id=\"45da\"\u003eThe main objectives of Continuous Research are:\u003c/p\u003e\u003cul\u003e\u003cli id=\"3b3d\"\u003eRegularly and easily gathering user feedback on strategic parts of the product\u003c/li\u003e\u003cli id=\"5477\"\u003eConsolidating knowledge about users\u003c/li\u003e\u003cli id=\"c6e9\"\u003eEnabling fast and user-centric decision-making\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"ba33\"\u003eCollecting user feedback continuously helps prioritize the roadmap, improve user experience, and speed up iteration cycles.\u003c/p\u003e\u003ch2 id=\"c6fd\"\u003eStep 1: Identify Existing Feedback Sources\u003c/h2\u003e\u003cp id=\"ea25\"\u003eHave you ever noticed that User Research is very similar to data analysis? Just like with data, structuring and cleaning your sources before extracting valuable and actionable insights is crucial.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eYou can collect feedback from various sources (Trustpilot, Appstore, Zendesk, Surveys…)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"d605\"\u003eTo start your Continuous Research process, here are the questions you need to ask yourself:\u003c/p\u003e\u003cul\u003e\u003cli id=\"d76a\"\u003eWho in the company already has regular contact with users? (e.g., Sales, Customer Success)\u003c/li\u003e\u003cli id=\"68c8\"\u003eDo they already collect regular feedback and how? (e.g., surveys, CSAT, calls)\u003c/li\u003e\u003cli id=\"3bf0\"\u003eHow do these sources perform? (e.g., number of monthly responses)\u003c/li\u003e\u003cli id=\"edd7\"\u003eIs this feedback regularly analyzed and by whom?\u003c/li\u003e\u003cli id=\"2a32\"\u003eWhat is the purpose of these feedback sources?\u003c/li\u003e\u003cli id=\"3867\"\u003eWhat kind of insights do they generate?\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"c3c9\"\u003eFrom these sources, identify the ones relevant for Continuous Research, eliminate duplicates, and remove those that don’t provide real value. Favor sources that will bring relevant insights over the long term.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"1b98\"\u003eClean up redundant or low-value feedback sources that lack clear ownership or objectives.\u003c/p\u003e\u003c/blockquote\u003e\u003ch2 id=\"4ef9\"\u003eStep 2: Map the Feedback Sources\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"1888\"\u003eNow that you identified the most relevant feedback sources, you can start mapping them on every stage of the User Journey to have a good overall vision of what’s available. You might also need to create new feedback sources as strategic touchpoint for business objectives that are not yet covered. Anyway, I really recommend starting small and complete your mapping one step at a time.\u003c/p\u003e\u003cp id=\"5d93\"\u003eAt OpenClassrooms, we categorized different types of sources feeding Continuous Research:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eDifferent types of users feedback sources\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"e2fe\"\u003e\u003cstrong\u003eStep Experience Surveys — Feedback on a User Journey step\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"c432\"\u003eThese are the primary feedback sources for squads’ Continuous Research. We have one survey at the end of each step, composed of three main parts:\u003c/p\u003e\u003cul\u003e\u003cli id=\"63ff\"\u003e\u003cstrong\u003e1. CSAT — Customer Satisfaction \u003c/strong\u003e\u003cbr/\u003eIt measures satisfaction on specific parts of the user experience.\u003cbr/\u003eThe question is “\u003cem\u003eHow satisfied are you with the [Step Name] process?\u003c/em\u003e”.\u003c/li\u003e\u003cli id=\"1da6\"\u003e\u003cstrong\u003e2. CES — Customer Effort \u003c/strong\u003e\u003cbr/\u003eIt measures the effort required for specific actions.\u003cbr/\u003eThe question is “\u003cem\u003eCompleting this [Action or Step] seemed: very easy to very difficult\u003c/em\u003e”.\u003c/li\u003e\u003cli id=\"5b07\"\u003e\u003cstrong\u003e3. Qualitative feedback\u003c/strong\u003e\u003cbr/\u003eThis open question provides context for the ratings, helping us understand the “why” behind user scores and gather improvement ideas.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"0cfc\"\u003eWe add a question at the end to collect emails from users interested in improving the product, creating a user pool for testing and interviews!\u003c/p\u003e\u003cp id=\"f3ea\"\u003eRecently, we tested adding a question about step clarity to assess whether the available information is clear and useful. This will help us measure the impact of Content Design more precisely.\u003c/p\u003e\u003ch2 id=\"12d0\"\u003e\u003cstrong\u003eNPS surveys\u003c/strong\u003e — Feedback on the global Experience\u003c/h2\u003e\u003cp id=\"df38\"\u003eNet Promoter Score (NPS) measures customer loyalty toward the Brand. The qualitative feedback informs the company about users’ main concerns and expectations regarding their global experience with the product or service.\u003cbr/\u003e The question is “\u003cem\u003eWould you recommend [Name of the company]?\u003c/em\u003e”.\u003c/p\u003e\u003cp id=\"86d5\"\u003eNPS is widely debated as it provides broad feedback that is not always directly actionable. However, categorizing responses into themes allows us to the monitor changes in user satisfaction and dissatisfaction over time and better understand why.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"a357\"\u003eTemporary sources — Feedback pre- or post-release\u003c/h2\u003e\u003cp id=\"4689\"\u003eThese are temporary sources, launched for a specific purpose and having having a lifetime of 1 to 6 months. They include surveys, user tests, and interviews that help gather feedback on a particular topic.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eExample of specific survey for the Matching step — Illustration by \u003ca href=\"https://www.behance.net/fabiengouby?locale=fr_FR\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFabien Gouby\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"6f9f\"\u003e\u003cstrong\u003eExternal sources\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"41ff\"\u003eThese are third-party sources like App Store reviews, Google ratings, or Trustpilot. While you don’t control them, analyzing them helps validate insights and spot trends that align — or not — with your own insights.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eExample of external feedback source — Trustpilot\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"bf05\"\u003eGet more information on Continuous Research in \u003ca href=\"https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethis article\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"604b\"\u003eStep 3: Document Feedback Sources\u003c/h2\u003e\u003cp id=\"2980\"\u003eNow that you’ve started mapping your sources, you can take it a step further by documenting each one more precisely:\u003c/p\u003e\u003cul\u003e\u003cli id=\"f4cb\"\u003e\u003cstrong\u003eObjective:\u003c/strong\u003e What do we want to measure? How does this feed into our strategy and inform decisions?\u003c/li\u003e\u003cli id=\"191b\"\u003e\u003cstrong\u003eSource: \u003c/strong\u003eWhere is it stored? In which tool?\u003c/li\u003e\u003cli id=\"fba5\"\u003e\u003cstrong\u003eFormat:\u003c/strong\u003e How is feedback collected? (e.g., in-product, email, call)\u003c/li\u003e\u003cli id=\"5385\"\u003e\u003cstrong\u003eTrigger: \u003c/strong\u003eAt what stage is feedback requested? Is there a specific trigger?\u003c/li\u003e\u003cli id=\"a0ad\"\u003e\u003cstrong\u003eFilter: \u003c/strong\u003eAre specific user segments targeted?\u003c/li\u003e\u003cli id=\"a50b\"\u003e\u003cstrong\u003eNumber:\u003c/strong\u003e How many responses are received monthly? Is the source performing well?\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003cfigcaption\u003eCard template to map your feedback sources\u003c/figcaption\u003e\u003c/figure\u003e\u003cblockquote\u003e\u003cp id=\"c368\"\u003eIt makes it easy for everyone on the team to understand what sources exist and what they are used for.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"2f15\"\u003eClarifying this information helps teams understand existing sources and their purposes while ensuring easy access to raw data if needed. It also prevents redundant surveys that ask similar questions — And your users will thank you for that! :)\u003c/p\u003e\u003cp id=\"97e4\"\u003eI strongly encourage you to do this in collaboration with other teams (e.g., marketing, support, sales, …). This mapping should also belong to them, and they should be able to help you update and improve it.\u003c/p\u003e\u003ch2 id=\"bf34\"\u003e\u003cstrong\u003eStep 4: \u003c/strong\u003eAnalyze Feedback Regularly\u003c/h2\u003e\u003cp id=\"f367\"\u003eYou now have feedback sources that are relevant, mapped, and documented: well done!\u003c/p\u003e\u003cp id=\"7369\"\u003eBut unanalyzed feedback has no value, agree? Now, you need to ensure this material is analyzed regularly without overwhelming teams. At OpenClassrooms, we review feedback monthly, typically at the end of each month.\u003c/p\u003e\u003cp id=\"47ee\"\u003eAll feedback is automatically stored in a dedicated folder in our \u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/how-we-started-our-user-research-repository-at-openclassrooms-d8a6536f22e1\"\u003eResearch Repository\u003c/a\u003e:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eList of continuous research projects\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"3beb\"\u003eWe can import multiple sources into the same folder, allowing us to cross-analyze user interviews, Step Experience surveys, and external sources. This enhances the reliability of insights by merging different perspectives.\u003c/p\u003e\u003cp id=\"fe9e\"\u003eProduct Designers analyze feedback within their scope, tagging and categorizing it appropriately:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eFeedback analysis in our Research Repository\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"f2db\"\u003eThis ensures Designers and Product Managers gain a deeper understanding of users’ concerns while keeping the process efficient.\u003c/p\u003e\u003cp id=\"e12e\"\u003eBut this process of tagging content can be time-consuming. To optimize it further, we’re experimenting with AI to assist in analyzing and automatically categorizing feedback. If you’re interested in our first tests, check out \u003ca href=\"https://www.notion.so/AI-prompt-Analyse-user-feedback-18294fc59c0380a2b834e850e44b12da\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ethis article\u003c/a\u003e:\u003c/p\u003e\u003ch2 id=\"d37d\"\u003eStep 5: Present Insights and Drive Decisions\u003c/h2\u003e\u003cp id=\"a5c8\"\u003eThese regular analyses help us generate valuable insights into user pain points and closely monitor satisfaction and effort over time.\u003c/p\u003e\u003cp id=\"28ee\"\u003eEach month, Product Designers present their findings, combining them with Product Managers’ insights and data. This forms what we call the “Squad’s Monthly Reports”, which help prioritize roadmap topics based on criticality and business objectives.\u003c/p\u003e\u003cp id=\"3fae\"\u003eFindings are widely shared with the squads, stakeholders and leadership members.\u003c/p\u003e\u003cp id=\"4188\"\u003eDepending on the objectives, we can present results in different ways:\u003c/p\u003e\u003ch2 id=\"76bd\"\u003eCategorized feedback by user\u003c/h2\u003e\u003cfigure\u003e\u003cfigcaption\u003eSplit of categories regarding our Alumni’ feedback\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"7efb\"\u003eThis allows teams to quickly identify patterns and trends. By comparing the proportion of different feedback themes, we can prioritize the most critical user concerns and ensure that decision-making is data-driven. It can impact the roadmap of all teams across the company, not just the Product team (e.g., Learning team, Mentorship team, Student Success team).\u003c/p\u003e\u003ch2 id=\"efbf\"\u003e\u003cstrong\u003eTop three pain points for a given step\u003c/strong\u003e\u003c/h2\u003e\u003cfigure\u003e\u003cfigcaption\u003e3 main user pain points for the Application step\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"981d\"\u003eThis can directly help prioritize the squad roadmap and identify key pain points that require deeper analysis or further exploration in the next product discovery phase.\u003c/p\u003e\u003ch2 id=\"0cc8\"\u003eEvolution\u003cstrong\u003e of Satisfaction and Effort \u003c/strong\u003eover time\u003c/h2\u003e\u003cfigure\u003e\u003c/figure\u003e\u003cp id=\"fa83\"\u003eThis allows us to correlate user satisfaction with business objectives. For example, if application rates drop, we can examine the Satisfaction and Effort scores for this step and analyze qualitative feedback to identify potential causes.\u003c/p\u003e\u003cp id=\"5f5c\"\u003eIt also helps us assess the impact of new releases. For example, whenever we make a change to the funnel, we analyze our “Application Experience KPI” to determine whether it reduces effort and enhances satisfaction.\u003c/p\u003e\u003cp id=\"936a\"\u003eWe can now track this evolution across all squads and have begun setting teams goals based on those scores:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eExemple of Satisfaction evolution over time for 3 squads\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"cf48\"\u003eWhat’s next?\u003c/h2\u003e\u003cp id=\"d39f\"\u003eWhen launching your first surveys, you’ll likely find some ineffective. Some may not receive enough responses, while others may provide non-actionable feedback. This is normal — you won’t get everything right on the first try! :)\u003c/p\u003e\u003cp id=\"647c\"\u003eYou will need to regularly iterate on your feedback sources: add new ones, remove ineffective ones, and adjust placement, channels, or questions as needed.\u003c/p\u003e\u003cp id=\"f360\"\u003eAt OpenClassrooms, we continuously monitor Feedback sources performance and refine our approach accordingly.\u003c/p\u003e\u003ch2 id=\"a2bc\"\u003eImpact of Continuous Research on Product Strategy\u003c/h2\u003e\u003cul\u003e\u003cli id=\"6670\"\u003e\u003cstrong\u003eTime-saving\u003c/strong\u003e: Collecting and analyzing feedback becomes easier. Teams no longer have to start from scratch.\u003c/li\u003e\u003cli id=\"4adc\"\u003e\u003cstrong\u003eDeeper user insights:\u003c/strong\u003e Ongoing analysis enhances user understanding and empathy.\u003c/li\u003e\u003cli id=\"17bd\"\u003e\u003cstrong\u003eCross-team impact:\u003c/strong\u003e Insights influence not only product roadmaps but also Customer Success, Sales, and Marketing.\u003c/li\u003e\u003cli id=\"59fa\"\u003e\u003cstrong\u003eProactive issue detection:\u003c/strong\u003e Monitoring scores helps identify trends and take corrective action before problems escalate.\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"211f\"\u003eKey numbers\u003c/h2\u003e\u003cul\u003e\u003cli id=\"d77e\"\u003e\u003cstrong\u003e10+\u003c/strong\u003e Continuous research folders created\u003c/li\u003e\u003cli id=\"702d\"\u003e\u003cstrong\u003e900+\u003c/strong\u003e Feedback pieces analyzed monthly\u003c/li\u003e\u003cli id=\"2627\"\u003e\u003cstrong\u003e20+\u003c/strong\u003e Actionable insights generated each month, directly influencing product strategy\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2025-02-04T14:32:42.486Z",
  "modifiedTime": null
}
