{
  "id": "a432653f-1554-41a3-b2d5-052acf50ab10",
  "title": "3 Design Processes for High Usability: Iterative Design, Parallel Design, and Competitive Testing",
  "link": "https://www.nngroup.com/articles/parallel-and-iterative-design/",
  "description": "3 methods for increasing UX quality by exploring and testing diverse design ideas work even better when you use them together.",
  "author": "Therese Fessenden",
  "published": "Tue, 03 Dec 2024 22:00:00 +0000",
  "source": "https://www.nngroup.com/feed/rss/",
  "categories": [
    "Article"
  ],
  "byline": "Therese Fessenden",
  "length": 11839,
  "excerpt": "3 methods for increasing UX quality by exploring and testing diverse design ideas work even better when you use them together.",
  "siteName": "Nielsen Norman Group",
  "favicon": "",
  "text": "Summary:  3 methods for increasing UX quality by exploring and testing diverse design ideas work even better when you use them together.  This is an updated version of an article written by Jakob Nielsen in 2011. There's no one perfect user-interface design, and you can't get good usability by simply shipping your one best idea. You have to try (and test) multiple design ideas. Iterative design, parallel design, and competitive testing are three different ways to consider design alternatives. While each of them independently can improve a design’s usability, combining them enables you to explore the best ideas at a lower cost than sticking to a single approach. Iterative Design Parallel Design Competitive Testing Exploring Design Diversity Produces Better UX Iterative Design Iterative design utilizes discount usability-inspection methods and user testing to identify key issues with each version of a design. Once these issues are identified, a new version of the design gets created.  An “iteration” is an intentional repetition of a step in the design process with the goal of improving the design at that stage. For each version of the design, you conduct a usability evaluation (such as user testing or heuristic evaluation) and revise the next version based on the usability findings. Iterative design is the: simplest process model (a linear progression) oldest foundation for user-centered design (UCD) cheapest (you often can iterate in a few hours) most progressive because you can keep incrementally improving for as many iterations as your budget allows (competitive and parallel testing are usually one-shot components of a design project) How Many Iterations? We recommend at least 2 iterations. These 2 iterations correspond to 3 versions: the first draft design (which we know is never good enough), followed by 2 redesigns. However, it’s better to incorporate 5–10 iterations or more, particularly when testing weekly. Of course, one iteration (that is, a single redesign, for a total of 2 design versions) is still better than shipping your best guess without usability-derived improvements. Experience shows that the first redesign will have many remaining usability problems, which is why it's best to plan for at least two iterations. More iterations are better: you’ll be hard-pressed to find anyone who has iterated so much that there were no usability improvements to be had from the last iterations. Our study in 1993 demonstrated measured usability improvements by 38% per iteration. These metrics came from traditional application development; if we look at websites, improvements are typically bigger. In one case study, the targeted KPI improved by 233% across 6 iterations (7 design versions = 6 iterations between versions), corresponding to 22% per iteration. The key lesson from this latter case study is that it's best to keep iterating, because you can keep piling on the gains. To get many iterations within a limited budget and timeline, you can use discount usability methods: create paper prototypes for the early design versions, planning about one day per iteration. In later versions, you can gradually proceed to higher-fidelity renderings of the user interface, but there's no reason to worry about fine details of the graphics in early stages, especially when you're likely to rip the entire workflow apart between versions. Simple user testing (5 users or less) will suffice because you'll conduct additional testing for later iterations. Limitations of Iterative Design A classic critique of iterative design is that it might encourage “hill-climbing” — that is, working toward a local maximum rather than discovering a superior solution in a completely different design space. While iterative design is a highly effective technique to create usability gains, it's true that it limits us to improving a single solution. If you start out in the wrong part of the design space, you might not end up where you'd really like to go. While the criticism is valid, the vast majority of user-interface design projects typically employ components or features that already have established, well-documented best practices. Of course, superior solutions that exceed current best practices are possible; after all, we haven't seen the perfect user interface yet. But most designers would be happy to nearly double their business metrics. Simply polishing a design's usability through an iterative design has extremely high ROI, and is often preferable to the larger investment needed for higher gains. That said, to avoid this problem of fixation on a single design solution, it may help to start with a parallel-design step before proceeding with iterative design. Parallel Design During parallel design, you create multiple alternative designs at the same time. These designs could be produced by either a single designer or by multiple designers who are assigned different design directions and generate each one draft design. The parallel-design process is distinguished by the creation of multiple different designs. Each of these designs is evaluated, and the best aspects of each design get carried over into a single merged design (which can then go through the iterative-design process for further improvement). In any case, to stay within a reasonable budget, all parallel versions should be created quickly and cheaply. They don't need to embody a complete design of all features and pages. Instead, for a website or intranet, you can design a few key pages and, for an application, you can design just the top features. Ideally, you should spend just a few days designing each version and refine them only to the level of rough wireframes. Although you should create a minimum of 3 different design alternatives, it's not worth the effort to design many more. 5 is probably the maximum. Once you have all the parallel versions, subject them to user testing. Each test participant can test 2 or 3 versions. Any more and users get fatigued and can't articulate the differences. Of course, you should alternate which version they test first because users are fresh (and unbiased) only on their first attempt. When they try the second or third UI that solves the same problem, people inevitably transfer their experience from using the previous version(s). Still, it's worth having users try a few versions so that they can do a compare-and-contrast at the end of the session. Unlike with A/B or multivariate testing, the goal of testing with parallel design is not necessarily to identify \"a winner\" from the parallel designs. Instead, the goal is to create a single merged design that uses the best ideas from each of the parallel versions. Finally, proceed with iterative design (as above) to further refine the merged design. In 1996, we conducted a research study of parallel design, in which we evaluated 3 different approaches: Out of 4 parallel versions, simply pick the best one and iterate on it. This approach resulted in measured usability 56% higher than the average of the original 4 designs. Follow the recommended process and use a merged design, instead of picking a winner. Here, measured usability was 70% higher, giving us an additional 14% gain from including the best ideas of the \"losing\" designs. Continue iterating from the merged design. After one iteration, measured usability was 152% higher than the average of the original designs. (So, an extra iteration added 48% usability to the merged design — calculated as 2.52/1.70. This is within the expected range of gains from iterative design.) Of course, there is no empirical reason to stop with one iteration after the merged design, but budget constraints will often dictate how many iterations are possible. As stated above, we still recommend at least 2–3 iterations to ensure measurable usability improvements. Competitive Testing In a competitive usability study, you test your own design and 3–4 designs from your competitors. The process looks the same as for parallel design, except that the original design alternatives are preexisting sites or apps as opposed to wireframes you create specifically for the study. Competitive testing is not the same as a competitive review. While both are forms of competitive evaluation, competitive testing requires that designs be tested with actual users. The benefit of competitive testing is also the same as that of parallel design: you gain insight into user behaviors with a broad range of design options before you commit to a design that you'll refine through iterative design. Similar to parallel design, competitive testing evaluates the merits (and pitfalls) of competing designs and yields insights that can inform better design iterations. Competitive testing is also advantageous in that you don't spend resources creating early design alternatives. For example, when designing a website, you can simply pick from among the ones available on the web. Competitive testing doesn't work as well for intranets and other domains where you can't easily access other companies' designs. Just as with parallel design, a competitive test shouldn't simply be a benchmark to anoint a \"winner.\" Sure, it can get the competitive juices stewing in most companies to learn that a hated competitor scores, say, 45% higher on key usability metrics. Such numbers can spur executive action, but quantitative measurements provide weaker insights than qualitative research, and they can often be more costly to obtain, given the need for larger sample sizes. A more profitable goal for competitive studies is to understand how users behave and why; learn what features they like or find confusing across a range of currently popular designs; and discover opportunities to serve unmet needs. Many design teams skip competitive testing because of the added expense of testing several sites. But this step is well worth the cost because it's the best way to gain deep insights into users' needs before you attempt to design something to address these needs. Competitive testing is particularly important if you're using an Agile development methodology because you often won't have time for deep explorations during individual sprints. You can do the competitive study before starting your development project because you're testing existing sites instead of new designs. You can later reach back to the insights when you need to make fast decisions during a sprint. Insights from competitive testing thus serve as money in the bank that you can withdraw when you're in a pinch. Exploring Design Diversity Produces Better UX All 3 methods — iterative, parallel, and competitive — work for the same reason: Instead of being limited to your one best idea, you try a range of designs and see which ones work with your customers in user testing. The methods represent different ways of exploring diverse ideas and progressing your designs in different directions. This is important because there are so many dimensions in interaction design that the resulting design space is incredibly vast. In the ideal process, you'd first conduct competitive testing to get deep insights into user needs and behaviors with the class of functionality you're designing. Next, you'd proceed to parallel design to explore a wide range of solutions to this design problem. Finally, you'd go through many rounds of iterative design to polish your chosen solution to a high level of user experience quality. And, at each step, you should be sure to judge the designs based on empirical observations of real user behavior instead of your own preferences. (Remember: “You are not the user.”) Combining these 3 methods prevents you from being stuck with your best idea and maximizes your chances of finding even something better.",
  "image": "https://media.nngroup.com/media/articles/opengraph_images/Slide27articlesparallel-and-iterative-design.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp\u003e\u003cspan\u003e\n                  Summary: \n                \u003c/span\u003e3 methods for increasing UX quality by exploring and testing diverse design ideas work even better when you use them together.\n              \u003c/p\u003e\u003cdiv\u003e\n              \u003cp\u003e\u003cem\u003e This is an updated version of \u003ca href=\"https://www.nngroup.com/articles/parallel-and-iterative-design/2011/\"\u003ean article written by Jakob Nielsen in 2011\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThere\u0026#39;s no one perfect user-interface design,\u003c/strong\u003e and you can\u0026#39;t get good usability by simply shipping your one best idea. You have to \u003cstrong\u003etry (and test) multiple design ideas\u003c/strong\u003e. Iterative design, parallel design, and competitive testing are three different ways to consider design alternatives. While each of them independently can improve a design’s usability, combining them enables you to explore the best ideas at a lower cost than sticking to a single approach.\u003c/p\u003e\n\u003cdiv\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-iterative-design-1\"\u003eIterative Design\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-parallel-design-2\"\u003eParallel Design\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-competitive-testing-3\"\u003eCompetitive Testing\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-exploring-design-diversity-produces-better-ux-4\"\u003eExploring Design Diversity Produces Better UX\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003ch2 id=\"toc-iterative-design-1\"\u003e\u003cstrong\u003eIterative Design\u003c/strong\u003e\u003c/h2\u003e\n\u003cfigure\u003e\u003cimg alt=\"A diagram of the iterative design process. It depicts multiple iterations at three stages: low-fidelity wireframe (V1 to V3), interactive prototype (V4 to V6), and visual design (V7 to V9), with user testing conducted between stages to refine the designs.\" height=\"582\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2024/11/12/iterative-design.png\" width=\"692\"/\u003e\n\u003cfigcaption\u003e\u003cstrong\u003e\u003cem\u003eIterative design\u003c/em\u003e\u003c/strong\u003e\u003cem\u003e utilizes discount usability-inspection methods and user testing to identify key issues with each version of a design. Once these issues are identified, a new version of the design gets created. \u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003e\u003cstrong\u003eAn “iteration” is an intentional repetition of a step in the design process\u003c/strong\u003e with the goal of improving the design at that stage. For each version of the design, you conduct a usability evaluation (such as \u003ca href=\"https://www.nngroup.com/articles/usability-testing-101/\"\u003e\u003cu\u003euser testing\u003c/u\u003e\u003c/a\u003e or \u003ca href=\"https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/\"\u003e\u003cu\u003eheuristic evaluation\u003c/u\u003e\u003c/a\u003e) and revise the next version based on the usability findings.\u003c/p\u003e\n\u003cp\u003eIterative design is the:\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\"\u003e\u003cstrong\u003esimplest \u003c/strong\u003eprocess model (a linear progression)\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cstrong\u003eoldest \u003c/strong\u003efoundation for user-centered design (UCD)\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cstrong\u003echeapest \u003c/strong\u003e(you often can iterate in a few hours)\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cstrong\u003emost progressive\u003c/strong\u003e because you can keep incrementally improving for as many iterations as your budget allows (competitive and parallel testing are usually one-shot components of a design project)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003cstrong\u003eHow Many Iterations?\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eWe recommend \u003cstrong\u003eat least 2 iterations\u003c/strong\u003e. These 2 iterations correspond to 3 versions: the first draft design (which we know is never good enough), followed by 2 redesigns. However, it’s better to incorporate \u003cstrong\u003e5–10 iterations \u003c/strong\u003eor more, particularly when testing weekly.\u003c/p\u003e\n\u003cp\u003eOf course, one iteration (that is, a single redesign, for a total of 2 design versions) is still better than \u003ca href=\"https://www.nngroup.com/articles/the-myth-of-the-genius-designer/\"\u003e\u003cu\u003eshipping your best guess\u003c/u\u003e\u003c/a\u003e without usability-derived improvements. Experience shows that the first redesign will have many remaining usability problems, which is why it\u0026#39;s best to plan for at least two iterations.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMore iterations are better:\u003c/strong\u003e you’ll be hard-pressed to find anyone who has iterated so much that there were no usability improvements to be had from the last iterations. Our study in 1993 demonstrated \u003cstrong\u003emeasured usability improvements by 38% per iteration\u003c/strong\u003e. These metrics came from traditional application development; if we look at websites, improvements are typically bigger. In one case study, the targeted \u003ca href=\"https://www.nngroup.com/articles/testing-decreased-support/\"\u003e\u003cu\u003eKPI improved by 233% across 6 iterations\u003c/u\u003e\u003c/a\u003e (7 design versions = 6 iterations between versions), corresponding to \u003cstrong\u003e22% per iteration\u003c/strong\u003e. The key lesson from this latter case study is that it\u0026#39;s best to keep iterating, because you can keep piling on the gains.\u003c/p\u003e\n\u003cp\u003eTo get many iterations within a limited budget and timeline, you can use \u003ca href=\"https://www.nngroup.com/articles/discount-usability-20-years/\"\u003e\u003cu\u003ediscount usability\u003c/u\u003e\u003c/a\u003e methods: create \u003ca href=\"https://www.nngroup.com/videos/paper-prototyping-tutorial/\"\u003e\u003cu\u003epaper prototypes\u003c/u\u003e\u003c/a\u003e for the early design versions, planning about one day per iteration. In later versions, you can gradually \u003cstrong\u003eproceed to higher-fidelity\u003c/strong\u003e renderings of the user interface, but there\u0026#39;s no reason to worry about fine details of the graphics in early stages, especially when you\u0026#39;re likely to rip the entire workflow apart between versions.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/\"\u003e\u003cu\u003eSimple user testing\u003c/u\u003e\u003c/a\u003e (5 users or less) will suffice because you\u0026#39;ll conduct additional testing for later iterations.\u003c/p\u003e\n\u003ch3\u003e\u003cstrong\u003eLimitations of Iterative Design\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eA classic critique of iterative design is that it might \u003cstrong\u003eencourage “hill-climbing” \u003c/strong\u003e— that is, working toward a local maximum rather than discovering a superior solution in a completely different design space. While iterative design is a highly effective technique to create usability gains, it\u0026#39;s true that it limits us to improving a single solution. If you start out in the wrong part of the design space, you might not end up where you\u0026#39;d really like to go. While the criticism is valid, the vast majority of user-interface design projects typically employ components or features that already have established, \u003cstrong\u003ewell-documented best practices.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eOf course, superior solutions that exceed current best practices are possible; after all, we haven\u0026#39;t seen the perfect user interface yet. But most designers would be happy to nearly \u003ca href=\"https://www.nngroup.com/articles/usability-roi-declining-but-still-strong/\"\u003e\u003cu\u003edouble their business metrics\u003c/u\u003e\u003c/a\u003e. Simply polishing a design\u0026#39;s usability through an iterative design has extremely high \u003ca href=\"http://www.nngroup.com/reports/usability-return-on-investment-roi/\"\u003e\u003cu\u003eROI\u003c/u\u003e\u003c/a\u003e, and is often preferable to the larger investment needed for higher gains.\u003c/p\u003e\n\u003cp\u003eThat said, to avoid this problem of fixation on a single design solution, it may help to start with a parallel-design step before proceeding with iterative design.\u003c/p\u003e\n\u003ch2 id=\"toc-parallel-design-2\"\u003e\u003cstrong\u003eParallel Design\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eDuring parallel design, you create \u003cstrong\u003emultiple alternative designs\u003c/strong\u003e at the same time. These designs could be produced by either a single designer or by multiple designers who are assigned different design directions and generate each one draft design.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"A diagram illustrating the parallel design process. It shows three wireframes (A, B, C) created simultaneously. After user testing, the best design ideas are merged into one wireframe or prototype, which undergoes iterative design (V1 to V3) and further user testing.\" height=\"490\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2024/11/12/parallel-design.png\" width=\"692\"/\u003e\n\u003cfigcaption\u003e\u003cem\u003eThe parallel-design process is distinguished by the creation of multiple different designs. Each of these designs is evaluated, and the best aspects of each design get carried over into a single merged design (which can then go through the iterative-design process for further improvement).\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eIn any case, to stay within a reasonable budget, all parallel versions should be created quickly and cheaply. They don\u0026#39;t need to embody a complete design of all features and pages. Instead, for a website or intranet, you can design a few key pages and, for an application, you can design just the \u003ca href=\"https://www.nngroup.com/articles/top-tasks/\"\u003e\u003cu\u003etop features\u003c/u\u003e\u003c/a\u003e. Ideally, you should spend just a few days designing each version and refine them only to the level of \u003ca href=\"https://www.nngroup.com/articles/draw-wireframe-even-if-you-cant-draw/\"\u003e\u003cu\u003erough wireframes.\u003c/u\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAlthough you should create a minimum of \u003cstrong\u003e3 different design alternatives\u003c/strong\u003e, it\u0026#39;s not worth the effort to design many more. 5 is probably the maximum.\u003c/p\u003e\n\u003cp\u003eOnce you have all the parallel versions, subject them to user testing. Each test participant can test 2 or 3 versions. Any more and users get fatigued and can\u0026#39;t articulate the differences. \u003ca href=\"https://www.nngroup.com/articles/between-within-subjects/\"\u003e\u003cu\u003eOf course, you should alternate which version they test first\u003c/u\u003e\u003c/a\u003e because users are fresh (and unbiased) only on their first attempt. When they try the second or third UI that solves the same problem, people inevitably transfer their experience from using the previous version(s). Still, it\u0026#39;s worth having users try a few versions so that they can do a compare-and-contrast at the end of the session.\u003c/p\u003e\n\u003cp\u003eUnlike with \u003ca href=\"https://www.nngroup.com/articles/putting-ab-testing-in-its-place/\"\u003e\u003cu\u003eA/B\u003c/u\u003e\u003c/a\u003e or \u003ca href=\"https://www.nngroup.com/articles/multivariate-testing/\"\u003e\u003cu\u003emultivariate testing\u003c/u\u003e\u003c/a\u003e, the goal of testing with parallel design is not necessarily to identify \u0026#34;a winner\u0026#34; from the parallel designs. Instead, the goal is to \u003cstrong\u003ecreate a single merged design\u003c/strong\u003e that uses the best ideas from each of the parallel versions. Finally, \u003cstrong\u003eproceed with iterative design \u003c/strong\u003e(as above) to further refine the merged design.\u003c/p\u003e\n\u003cp\u003eIn 1996, we conducted a \u003ca href=\"https://www.nngroup.com/articles/parallel-design/\"\u003e\u003cu\u003eresearch study of parallel design\u003c/u\u003e\u003c/a\u003e, in which we evaluated 3 different approaches:\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\"\u003eOut of 4 parallel versions, simply \u003cstrong\u003epick the best one\u003c/strong\u003e and iterate on it. This approach resulted in measured usability \u003cstrong\u003e56% higher\u003c/strong\u003e than the average of the original 4 designs.\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003eFollow the recommended process and \u003cstrong\u003euse a merged design\u003c/strong\u003e, instead of picking a winner. Here, measured usability was \u003cstrong\u003e70% higher\u003c/strong\u003e, giving us an additional 14% gain from including the best ideas of the \u0026#34;losing\u0026#34; designs.\u003c/li\u003e\n\u003cli aria-level=\"1\"\u003e\u003cstrong\u003eContinue iterating \u003c/strong\u003efrom the merged design. After one iteration, measured usability was\u003cstrong\u003e 152% higher \u003c/strong\u003ethan the average of the original designs. (So, an \u003cstrong\u003eextra iteration added 48% usability\u003c/strong\u003e to the merged design — calculated as 2.52/1.70. This is within the expected range of gains from iterative design.)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOf course, there is no empirical reason to stop with one iteration after the merged design, but budget constraints will often dictate how many iterations are possible. As stated above, we still recommend at least 2–3 iterations to ensure measurable usability improvements.\u003c/p\u003e\n\u003ch2 id=\"toc-competitive-testing-3\"\u003e\u003cstrong\u003eCompetitive Testing\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eIn a competitive usability study, you \u003cstrong\u003etest your own design and 3–4 designs from your competitors\u003c/strong\u003e. The process looks the same as for parallel design, except that the original design alternatives are preexisting sites or apps as opposed to wireframes you create specifically for the study.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCompetitive testing is not the same as a competitive review.\u003c/strong\u003e While both are forms of \u003ca href=\"https://www.nngroup.com/articles/competitive-usability-evaluations/\"\u003e\u003cu\u003ecompetitive evaluation\u003c/u\u003e\u003c/a\u003e, competitive testing requires that designs be tested with actual users.\u003c/p\u003e\n\u003cp\u003eThe benefit of competitive testing is also the same as that of parallel design: you gain insight into user behaviors with a broad range of design options before you commit to a design that you\u0026#39;ll refine through iterative design.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"A diagram explaining competitive testing. It compares your design with four competitors\u0026#39; designs (A to D). After user testing, the best ideas are merged into one design, which undergoes an iterative process with multiple refinements.\" height=\"1031\" loading=\"lazy\" src=\"https://media.nngroup.com/media/editor/2024/11/20/competitive-testing.png\" width=\"1385\"/\u003e\n\u003cfigcaption\u003e\u003cem\u003eSimilar to parallel design, competitive testing evaluates the merits (and pitfalls) of competing designs and yields insights that can inform better design iterations.\u003c/em\u003e\u003c/figcaption\u003e\n\u003c/figure\u003e\n\u003cp\u003eCompetitive testing is also advantageous in that you don\u0026#39;t spend resources creating early design alternatives. For example, when designing a website, you can simply pick from among the ones available on the web. Competitive testing doesn\u0026#39;t work as well for intranets and other domains where you can\u0026#39;t easily access other companies\u0026#39; designs.\u003c/p\u003e\n\u003cp\u003eJust as with parallel design, a competitive test shouldn\u0026#39;t simply be a benchmark to anoint a \u0026#34;winner.\u0026#34; Sure, it can get the competitive juices stewing in most companies to learn that a hated competitor scores, say, 45% higher on key usability metrics. Such numbers can spur executive action, but \u003ca href=\"https://www.nngroup.com/articles/risks-of-quantitative-studies/\"\u003e\u003cu\u003equantitative measurements provide weaker insights\u003c/u\u003e\u003c/a\u003e than qualitative research, and they can often be more costly to obtain, given the need for larger sample sizes. A more profitable goal for competitive studies is to understand \u003cstrong\u003ehow\u003c/strong\u003e \u003cstrong\u003eusers\u003c/strong\u003e \u003cstrong\u003ebehave\u003c/strong\u003e \u003cstrong\u003eand why\u003c/strong\u003e; learn what features they like or find confusing across a range of currently popular designs; and discover opportunities to serve unmet needs.\u003c/p\u003e\n\u003cp\u003eMany design teams skip competitive testing because of the added expense of testing several sites. But this step is well worth the cost because it\u0026#39;s the best way to\u003cstrong\u003e \u003c/strong\u003egain deep insights into users\u0026#39; needs \u003cstrong\u003ebefore\u003c/strong\u003e you attempt to design something to address these needs.\u003c/p\u003e\n\u003cp\u003eCompetitive testing is particularly important if you\u0026#39;re using an \u003ca href=\"https://www.nngroup.com/articles/lean-ux-agile-study-guide/\"\u003e\u003cu\u003eAgile development methodology\u003c/u\u003e\u003c/a\u003e because you often won\u0026#39;t have time for deep explorations during individual sprints. You can do the competitive study before starting your development project because you\u0026#39;re testing existing sites instead of new designs. You can later reach back to the insights when you need to make fast decisions during a sprint. Insights from competitive testing thus serve as money in the bank that you can withdraw when you\u0026#39;re in a pinch.\u003c/p\u003e\n\u003ch2 id=\"toc-exploring-design-diversity-produces-better-ux-4\"\u003e\u003cstrong\u003eExploring Design Diversity Produces Better UX\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eAll 3 methods — iterative, parallel, and competitive — work for the same reason: Instead of being limited to your one best idea, you \u003cstrong\u003etry a range of designs \u003c/strong\u003eand see which ones \u003cstrong\u003ework with your customers\u003c/strong\u003e in user testing. The methods represent different ways of exploring diverse ideas and progressing your designs in different directions. This is important because there are so many dimensions in interaction design that the resulting design space is incredibly vast.\u003c/p\u003e\n\u003cp\u003eIn the ideal process, you\u0026#39;d first conduct competitive testing to get deep insights into user needs and behaviors with the class of functionality you\u0026#39;re designing. Next, you\u0026#39;d proceed to parallel design to explore a wide range of solutions to this design problem. Finally, you\u0026#39;d go through many rounds of iterative design to polish your chosen solution to a high level of user experience quality. And, at each step, you should be sure to \u003cstrong\u003ejudge the designs based on empirical observations\u003c/strong\u003e of real \u003ca href=\"https://www.nngroup.com/articles/guesses-vs-data/\"\u003e\u003cu\u003euser behavior instead of your own preferences\u003c/u\u003e\u003c/a\u003e. (Remember: “\u003ca href=\"https://www.nngroup.com/articles/false-consensus/\"\u003e\u003cu\u003eYou are not the user.\u003c/u\u003e\u003c/a\u003e”)\u003c/p\u003e\n\u003cp\u003eCombining these 3 methods prevents you from being stuck with your best idea and maximizes your chances of finding even something better.\u003c/p\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2024-12-03T22:00:00Z",
  "modifiedTime": null
}
