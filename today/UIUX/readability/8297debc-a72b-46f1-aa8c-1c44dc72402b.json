{
  "id": "8297debc-a72b-46f1-aa8c-1c44dc72402b",
  "title": "AI transparency framework",
  "link": "https://uxdesign.cc/ai-transparency-framework-cf89fa61dc1b?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Josh LaMar",
  "published": "Fri, 31 Jan 2025 21:48:22 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "ai",
    "ux",
    "ethics",
    "design",
    "human-centered-ai"
  ],
  "byline": "Josh LaMar",
  "length": 14810,
  "excerpt": "As AI continues to automate more tasks, it reshapes how we work and create. With tools like ChatGPT and Claude, content creation has become faster and easier, but this shift raises two important…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "Applying the framework to content creationI believe human/AI collaboration is a 1+1=3. We create better products faster by taking advantage of AI-based tools responsibly and ethically. The next step is to be more transparent about our use.In order to demonstrate the application of the framework, let’s use the example of using AI for content creation. The level of AI involvement assigned will depend on the kind of content, the context, the goal, and most importantly, how AI was used (or not) throughout the process.Before going deeper into the scale itself, there are a few other clarifications about the framework to take note of first.Speed and efficiencyAI increases speed and efficiency as you move up the scale from Level 1 (no AI) to Level 5 (fully AI-driven). For example, in academia, Level 1 (fully human-driven) may currently be the only acceptable level of AI use, but this expectation will likely evolve, much like the once-rigid rules around using the internet for research.Doing things \"the old way,\" the way we did it before the introduction of AI, will take longer. But it will have an authenticity and a humanness to it that at least for right now, AI has a difficult time achieving. At the same time, while AI is progressing rapidly, it will be less and less obvious to tell if something is AI-generated. This is where transparency about the use of AI can help us to better identify and acknowledge its use.Appropriate useFully automated tools categorized at Level 5 are still valid — but I argue that the use of AI should be openly disclosed. It’s about being transparent about how AI-based tools are being used, not judging whether it’s an appropriate use.Of course, there will be much discussion about \"Appropriate use,\" my hope is that this transparency framework will give us a set of tools to have that discussion in a more open and constructive way.Visual representationThe scale is visually represented with a rainbow gradient, reflecting nuance in AI use. However, I do not encourage interpreting these colors as value judgments.For instance, red typically signals danger, so I have chosen orange instead of red for Level 5 to help avoid this interpretation. Level 5 is not \"Bad,\" it's just that orange better emphasizes the caution needed when fully outsourcing intellectual work to AI. And we should exercise caution here.In contrast, green for Level 3, representing collaboration, highlights how human-AI partnerships can enhance creativity and output when done responsibly and ethically. This doesn't mean green is \"Good\" or \"the Best,\" or even \"Optimal,\" it just refers to a balanced use of AI to support the process. An equilibrium.Disclosing levels of AI involvementUsing content creation as the application of the framework, following is a discussion of each level along with benefits and risks.Level 1: Fully human-driven; No use of AIAI is not used in any capacity for the creation of this work. The benefits of Level 1 include complete originality and unassisted creativity. However, it may sacrifice efficiency and miss opportunities to gain deeper insights or broader perspectives that AI tools can provide. This could result in slower workflows or less effective solutions (How generative AI can boost highly skilled workers' productivity).My hunch is that in the future, this is the realm of pure artists, writers, poets, and academics (I know, even that word sounded like a judgement). Maybe we need some new terms here. Just as the internet sped up the access to information, I imagine that use of AI will take much of what currently happens here in Level 1 and it will move to AI-assisted Level 2 or Balanced use Level 3.Level 2: Human-centric creation; AI supported researchHere, AI is used only for minor background research or reference checks, with humans retaining control of content, ideas, and critical thinking. This level allows AI to support human creativity passively, but over-reliance on AI research can lead to oversimplification, missed nuances, or a failure to leverage AI’s organizational strengths.Level 3: Balanced collaboration between humans and AILevel 3 represents a partnership between humans and AI that enhances efficiency while preserving originality.AI supports research, organizes ideas, and clarifies content while humans drive critical thinking, creativity, and intent. Humans remain responsible for ethical oversight and ensuring transparency. Additional benefits include:Creativity: AI supports innovation and creativity by organizing complex ideas and offering clarity, but humans retain control over originality and vision.Avoiding bias: Balances the power of AI with human judgment to avoid bias, misrepresentation, and ethical pitfalls.Level 4: AI-driven content; Human oversightAI takes on a significant role in research, development, and some critical thinking, with humans providing oversight through review and refinement.This greatly increases efficiency and scalability, reducing the time required to perform certain tasks. However, an over-reliance on AI risks diminishing human creativity and contextual understanding. Limited oversight can also allow unverified biases or inaccuracies to slip through if not caught in a human review.Currently, I see a lot of marketing automation that falls into this bucket and (in less-effective implementations), Level 5.Level 5: Fully AI-driven; Minimal human oversightAI did almost 100% of the work, from research to ideation, with minimal human input. While this maximizes speed and volume, allowing for rapid content generation or decision-making.However, it raises concerns about originality, accountability, and trust. Outputs may perpetuate bias, inaccuracies, or ethical lapses, and presenting AI work as human-generated risks eroding integrity.When you see something that's obviously AI-generated, irrelevant, and tone deaf, perhaps you're like me and you completely ignore it. Generating sales emails might allow you to spam millions of people, but the backlash is coming and authenticity will become more and more valued in the future.Unintended implicationsIt's important to acknowledge that being more transparent about our use of AI may have some unintended consequences.Risk of normalizing over-reliance on AIAs AI-based tools evolve, it's easy to start defaulting to their use. While they may help in many ways, it doesn't replace the cognitive work of a human brain.Just recently, my friend Sam Ladner shared a study showing a strong negative correlation between cognitive offloading and critical thinking.Cognitive offloading, image from Sam Ladner; Full studyThat's right, over-reliance on AI can reduce our critical thinking!We must not depend on AI-based tools, we must integrate them thoughtfully. AI should enhance our capabilities, not replace the cognitive effort required to come up with new ideas, develop intellection, and hone our craft.While I discuss Level 3 as a collaboration and a balanced use of AI, I should also caution the habitual or \"default\" to using AI to replace our human cognitive thinking (or \"Cognitive offloading, as the study calls it), even at a balanced use of Level 3.If human-AI collaboration is seen as an ideal, we may end up disincentivizing people from pushing their own cognitive and creative boundaries. And then we all miss out on the beauty and brilliance that comes from deep work.Risk of perception shiftsTransparency is not judgement in and of itself. However, providing additional transparency about the use of AI in the context of a work does not mean that audiences may still decide to judge the content differently due to the disclosure of the use of AI.When we engage with content (or a product), we make assumptions about its origin and how we should interpret it. When we disclose that that content was produced with AI in some form, it begins to challenge traditional ideas of creativity and what a creative output is or should be like.If you know an article was created with the assistance of AI, how would you perceive it? What if that article was fully-AI generated? What if it was fully-human generated? How does your response change in each of these scenarios?Some potential responses include:Resetting expectations — of what the content is and should be doing… or just how we should approach interpreting it in the first place.Engage differently — How might we read or engage with it differently because we know that AI was involved? Are we more or less critical of the article that was human-driven or the one that was AI-driven?Devaluing the article more based on more use of AI — for example, Level 1 articles are inherently better or more valuable than Level 5 articles.Eroding trust — if the article used the assistance of AI, can it still be trusted or should we be more critical because AI tends to oversimplify and introduce bias?There's an interesting parallel with food labeling: if you know that a product was genetically modified, does that change your perception of the product? Do you make a different purchasing decision? Is it better to know that the product is genetically modified (GMO)? Should we label genetically modified food? How should it be labeled?By using food labeling as a parallel, perhaps you're thinking, \"Of course we should label genetically modified food!\"Are you also thinking, \"Of course we should label AI-assisted involvement in our products and services!\" as well?Your response to these two questions is worth reflecting on.Additional applications of the frameworkThis framework applies beyond content creation. It can be applied across other disciplines and industries to guide transparent AI use in.In the examples below, I'll define Levels 1, 3, and 5 separately, however, in each case:Level 2 can be defined as \"Mostly human with some AI.\"Level 3 is a balanced integration of the two ends of the scaleLevel 4 as \"Mostly AI with some human oversight.\"Product developmentLevel 1: Manual prototyping without AI involvement.Level 3: AI assists in analyzing user feedback or generating design variants, with humans making final decisions.Level 5: The entire design process is AI-automated, with minimal human input.Reflection: Are we using AI to complement human creativity, or automating decisions that require empathy and context?UX ResearchLevel 1: Data collection and analysis are entirely manual and human-driven. AI was not used to assist in the process at all.Level 3: AI identifies trends, but researchers interpret findings to ensure meaningful insights.Level 5: AI conducts research and analysis without human involvement, risking oversimplification of user experiences.Reflection: Is AI helping uncover meaningful insights, or oversimplifying complex user experiences?Decision-makingLevel 1: Decisions rely solely on human expertise.Level 3: AI provides insights or simulations, but humans retain decision-making authority.Level 5: Decisions are fully automated by AI, potentially compromising empathy and ethical judgment.Reflection: Are we using AI insights to enhance decisions, or surrendering judgment to the algorithm?Hiring \u0026 HR decisionsShould AI-assisted hiring disclose when a résumé was screened by an algorithm? Are AI-assisted screening processes biased?By contrast, should candidates disclose if AI helped them write their application? Is a grammar check the same as using a LLM?Legal \u0026 Healthcare fieldsShould doctors and lawyers disclose AI-assisted decisions?If an AI-assisted medical diagnosis is given, should patients know exactly what role AI played?From hiring decisions to legal opinions, AI-driven processes are changing industries. Applying this framework in fields like HR, healthcare, and law can ensure informed decision-making and ethical accountability.It is my hope that we can build out our thinking about transparent use of AI together over time and that the Transparency Framework for the levels of AI involvement can become part of a new discourse on our intentional use of AI.Encouraging reflectionFinally, the framework can also be used to reflect on one or many of the following areas:General reflection: Does this level of AI use enhance or compromise the quality and integrity of the work?Intentionality: Am I being intentional about my use of AI or am I defaulting to a certain level of use?Creativity: Is AI amplifying creativity or stifling originality?Learning and growth: How does the use of AI impact my skill development and craftsmanship?Inclusivity and bias: Is AI helping to amplify diverse perspectives, or reinforcing harmful generalizations?Accountability: Can I clearly articulate which parts of the work were AI-generated versus human-driven?Human flourishing: Does the use of AI affect my personal sense of purpose, fulfillment, and meaning?The goal of transparencyAI-based tools are already shaping our present reality. The question is not whether we use AI, but how we disclose, govern, and apply it responsibly.Transparency is not about restriction — it is about trust. By adopting AI transparency as a standard, we shape the ethical and philosophical foundation of how AI integrates into our work, our industries, and our daily lives. This is our opportunity to lead, before regulation forces its own outcome.This approach doesn’t aim to dictate a “correct” level of AI involvement but instead encourages openness about the choices made in the creative and decision-making process.If your reflection raises concerns, reconsider whether AI is being used responsibly and intentionally… and respond accordingly.As we evolve with AI, our goal should always be to ensure it works for us, enhances human flourishing, and promotes purpose, creativity, and equity for all.Full circle with full disclosureI believe this article represents AI Transparency Level 3. The framework is wholly mine, but I used ChatGPT to refine some wording and perform some background research to think through the implications and ensure I haven't missed anything important. I also had feedback and help from my colleague Katie Trocin.Learn moreThis article doesn't exist in isolation but is the natural outcome of two other recently published articles:Human flourishing in the age of AI — if you are looking for reference articles and sources cited, this is the place to start. With an extensive appendix and sources cited throughout, this article is a treasure trove of references and a synthesis of current thinking on human flourishing and AI.The human-centered AI manifesto — the manifesto is based on the initial human flourishing article as a summary of principles of human-centered AI and commitments to action. If you are so moved, there's a link to a change.org petition you can sign to show your support and stand up for the responsible design and development of human-centered AI-based products and services.",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*JKT3eoFI7HUspqBn3E2zKQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"b19f\"\u003eApplying the framework to content creation\u003c/h2\u003e\u003cp id=\"8ee8\"\u003eI believe human/AI collaboration is a 1+1=3. We create better products faster by taking advantage of AI-based tools responsibly and ethically. The next step is to be more transparent about our use.\u003c/p\u003e\u003cp id=\"14fa\"\u003eIn order to demonstrate the application of the framework, let’s use the example of using AI for content creation. The level of AI involvement assigned will depend on the kind of content, the context, the goal, and most importantly, how AI was used (or not) throughout the process.\u003c/p\u003e\u003cp id=\"db59\"\u003eBefore going deeper into the scale itself, there are a few other clarifications about the framework to take note of first.\u003c/p\u003e\u003ch2 id=\"d35b\"\u003eSpeed and efficiency\u003c/h2\u003e\u003cp id=\"4ee2\"\u003eAI increases speed and efficiency as you move up the scale from \u003cstrong\u003eLevel 1 (no AI)\u003c/strong\u003e to \u003cstrong\u003eLevel 5 (fully AI-driven). \u003c/strong\u003eFor example, in academia, \u003cstrong\u003eLevel 1 \u003c/strong\u003e(fully human-driven) may currently be the only acceptable level of AI use, but this expectation will likely evolve, much like the once-rigid rules around using the internet for research.\u003c/p\u003e\u003cp id=\"68a0\"\u003eDoing things \u0026#34;the old way,\u0026#34; the way we did it before the introduction of AI, will take longer. But it will have an authenticity and a humanness to it that at least for right now, AI has a difficult time achieving. At the same time, while AI is progressing rapidly, it will be less and less obvious to tell if something is AI-generated. This is where transparency about the use of AI can help us to better identify and acknowledge its use.\u003c/p\u003e\u003ch2 id=\"6bad\"\u003eAppropriate use\u003c/h2\u003e\u003cp id=\"d353\"\u003eFully automated tools categorized at \u003cstrong\u003eLevel 5 \u003c/strong\u003eare still valid — but I argue that the use of AI should be openly disclosed. It’s about being transparent about \u003cem\u003ehow\u003c/em\u003e AI-based tools are being used, not judging whether it’s an appropriate use.\u003c/p\u003e\u003cp id=\"81a3\"\u003eOf course, there will be much discussion about \u0026#34;Appropriate use,\u0026#34; my hope is that this transparency framework will give us a set of tools to have that discussion in a more open and constructive way.\u003c/p\u003e\u003ch2 id=\"e38f\"\u003eVisual representation\u003c/h2\u003e\u003cp id=\"4f7b\"\u003eThe scale is visually represented with a rainbow gradient, reflecting nuance in AI use. However, I do not encourage interpreting these colors as value judgments.\u003c/p\u003e\u003cp id=\"9d84\"\u003eFor instance, \u003cstrong\u003ered\u003c/strong\u003e typically signals danger, so I have chosen \u003cstrong\u003eorange\u003c/strong\u003e instead of red for \u003cstrong\u003eLevel 5\u003c/strong\u003e to help avoid this interpretation. Level 5 is not \u0026#34;Bad,\u0026#34; it\u0026#39;s just that orange better emphasizes the caution needed when fully outsourcing intellectual work to AI. And we should exercise caution here.\u003c/p\u003e\u003cp id=\"4e40\"\u003eIn contrast, \u003cstrong\u003egreen \u003c/strong\u003efor\u003cstrong\u003e Level 3\u003c/strong\u003e, representing collaboration, highlights how human-AI partnerships can enhance creativity and output when done responsibly and ethically. This doesn\u0026#39;t mean green is \u0026#34;Good\u0026#34; or \u0026#34;the Best,\u0026#34; or even \u0026#34;Optimal,\u0026#34; it just refers to a balanced use of AI to support the process. An equilibrium.\u003c/p\u003e\u003ch2 id=\"cf2e\"\u003eDisclosing levels of AI involvement\u003c/h2\u003e\u003cp id=\"28fb\"\u003eUsing content creation as the application of the framework, following is a discussion of each level along with benefits and risks.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"59b0\"\u003e\u003cstrong\u003eLevel 1: Fully human-driven; No use of AI\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"8e1e\"\u003eAI is not used in \u003cem\u003eany\u003c/em\u003e capacity for the creation of this work. The benefits of Level 1 include complete originality and unassisted creativity. However, it may sacrifice efficiency and miss opportunities to gain deeper insights or broader perspectives that AI tools can provide. This could result in slower workflows or less effective solutions (\u003ca href=\"https://mitsloan.mit.edu/ideas-made-to-matter/how-generative-ai-can-boost-highly-skilled-workers-productivity\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHow generative AI can boost highly skilled workers\u0026#39; productivity\u003c/a\u003e).\u003c/p\u003e\u003cp id=\"6a43\"\u003eMy hunch is that in the future, this is the realm of \u003cem\u003epure\u003c/em\u003e artists, writers, poets, and academics (I know, even that word sounded like a judgement). Maybe we need some new terms here. Just as the internet sped up the access to information, I imagine that use of AI will take much of what currently happens here in Level 1 and it will move to AI-assisted Level 2 or Balanced use Level 3.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"1fcc\"\u003e\u003cstrong\u003eLevel 2: Human-centric creation; AI supported research\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"d780\"\u003eHere, AI is used only for minor background research or reference checks, with humans retaining control of content, ideas, and critical thinking. This level allows AI to support human creativity passively, but over-reliance on AI research can \u003ca href=\"https://casmi.northwestern.edu/news/articles/2024/the-ai-summarization-dilemma-when-good-enough-isnt-enough.html\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003elead to oversimplification, missed nuances\u003c/a\u003e, or a failure to leverage AI’s organizational strengths.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"e853\"\u003e\u003cstrong\u003eLevel 3: Balanced collaboration between humans and AI\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"a923\"\u003eLevel 3 represents a partnership between humans and AI that enhances efficiency while preserving originality.\u003c/p\u003e\u003cp id=\"c9a0\"\u003eAI supports research, organizes ideas, and clarifies content while humans drive critical thinking, creativity, and intent. Humans remain responsible for ethical oversight and ensuring transparency. Additional benefits include:\u003c/p\u003e\u003cul\u003e\u003cli id=\"3e32\"\u003e\u003cstrong\u003eCreativity\u003c/strong\u003e: AI supports innovation and \u003ca href=\"https://medium.com/@paul.k.pallaghy/creativity-was-another-of-chatgpts-conquests-here-s-why-it-s-more-computable-than-we-think-fb1e9b382ab2\" rel=\"noopener\"\u003ecreativity\u003c/a\u003e by organizing complex ideas and offering clarity, but humans retain control over originality and vision.\u003c/li\u003e\u003cli id=\"1341\"\u003e\u003cstrong\u003eAvoiding bias\u003c/strong\u003e: Balances the power of AI with human judgment to \u003ca href=\"https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eavoid bias, misrepresentation, and ethical pitfalls\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"c3e3\"\u003e\u003cstrong\u003eLevel 4: AI-driven content; Human oversight\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"e187\"\u003eAI takes on a significant role in research, development, and some critical thinking, with humans providing oversight through review and refinement.\u003c/p\u003e\u003cp id=\"fc97\"\u003eThis greatly increases efficiency and scalability, reducing the time required to perform certain tasks. However, an over-reliance on AI risks \u003ca href=\"https://insight.kellogg.northwestern.edu/article/will-ai-kill-human-creativity\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ediminishing human creativity\u003c/a\u003e and \u003ca href=\"https://cacm.acm.org/opinion/the-context-problem-in-artificial-intelligence/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003econtextual understanding\u003c/a\u003e. \u003ca href=\"https://www.ibm.com/think/topics/ai-governance\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLimited oversight can also allow unverified biases or inaccuracies to slip through\u003c/a\u003e if not caught in a human review.\u003c/p\u003e\u003cp id=\"03b4\"\u003eCurrently, I see a lot of marketing automation that falls into this bucket and (in less-effective implementations), Level 5.\u003c/p\u003e\u003cfigure\u003e\u003c/figure\u003e\u003ch2 id=\"d7cd\"\u003e\u003cstrong\u003eLevel 5: Fully AI-driven; Minimal human oversight\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"1e7b\"\u003eAI did almost 100% of the work, from research to ideation, with minimal human input. While this maximizes speed and volume, allowing for rapid content generation or decision-making.\u003c/p\u003e\u003cp id=\"ce26\"\u003eHowever, it raises concerns about originality, accountability, and trust. Outputs may \u003ca href=\"https://www.revelo.com/blog/ai-bias\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eperpetuate bias, inaccuracies, or ethical lapses\u003c/a\u003e, and presenting AI work as human-generated risks eroding integrity.\u003c/p\u003e\u003cp id=\"8fd4\"\u003eWhen you see something that\u0026#39;s \u003cem\u003eobviously \u003c/em\u003eAI-generated, irrelevant, and tone deaf, perhaps you\u0026#39;re like me and you completely ignore it. Generating sales emails might allow you to spam millions of people, but the backlash is coming and \u003ca href=\"https://www.linkedin.com/pulse/authenticity-age-ai-why-connection-matters-more-than-ever-jenna-lange-qx8vc/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eauthenticity will become more and more valued\u003c/a\u003e in the future.\u003c/p\u003e\u003ch2 id=\"1ad5\"\u003eUnintended implications\u003c/h2\u003e\u003cp id=\"7d49\"\u003eIt\u0026#39;s important to acknowledge that being more transparent about our use of AI may have some unintended consequences.\u003c/p\u003e\u003ch2 id=\"9ef5\"\u003eRisk of normalizing over-reliance on AI\u003c/h2\u003e\u003cp id=\"cc68\"\u003eAs AI-based tools evolve, it\u0026#39;s easy to start defaulting to their use. While they may help in many ways, it doesn\u0026#39;t replace the cognitive work of a human brain.\u003c/p\u003e\u003cp id=\"df86\"\u003eJust recently, my friend \u003ca href=\"https://www.linkedin.com/posts/sladner_the-more-a-person-uses-ai-the-less-critical-activity-7284944351158247425-C_3u?utm_source=share\u0026amp;utm_medium=member_desktop\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSam Ladner\u003c/a\u003e shared a \u003ca href=\"https://www.mdpi.com/2075-4698/15/1/6\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003estudy\u003c/a\u003e showing a strong negative correlation between cognitive offloading and critical thinking.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eCognitive offloading, image from \u003ca href=\"https://www.linkedin.com/posts/sladner_the-more-a-person-uses-ai-the-less-critical-activity-7284944351158247425-C_3u?utm_source=share\u0026amp;utm_medium=member_desktop\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSam Ladner\u003c/a\u003e; \u003ca href=\"https://www.mdpi.com/2075-4698/15/1/6\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eFull study\u003c/a\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"7a44\"\u003eThat\u0026#39;s right, over-reliance on AI can \u003cem\u003ereduce\u003c/em\u003e our critical thinking!\u003c/p\u003e\u003cp id=\"257a\"\u003eWe must not \u003cem\u003edepend\u003c/em\u003e on AI-based tools, we must integrate them thoughtfully. AI should enhance our capabilities, not replace the cognitive effort required to come up with new ideas, develop intellection, and hone our craft.\u003c/p\u003e\u003cp id=\"6d20\"\u003eWhile I discuss Level 3 as a collaboration and a balanced use of AI, I should also caution the habitual or \u0026#34;default\u0026#34; to using AI to replace our human cognitive thinking (or \u0026#34;Cognitive offloading, as the study calls it), \u003cem\u003eeven\u003c/em\u003e at a balanced use of Level 3.\u003c/p\u003e\u003cp id=\"7731\"\u003eIf human-AI collaboration is seen as an \u003cem\u003eideal\u003c/em\u003e, we may end up disincentivizing people from pushing their own cognitive and creative boundaries. And then we all miss out on the beauty and brilliance that comes from \u003ca href=\"https://calnewport.com/deep-work-rules-for-focused-success-in-a-distracted-world/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003edeep work\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"57d7\"\u003eRisk of perception shifts\u003c/h2\u003e\u003cp id=\"4404\"\u003eTransparency is not judgement in and of itself. However, providing additional transparency about the use of AI in the context of a work does not mean that \u003cem\u003eaudiences\u003c/em\u003e may still decide to judge the content differently due to the disclosure of the use of AI.\u003c/p\u003e\u003cp id=\"fc60\"\u003eWhen we engage with content (or a product), we make assumptions about its origin and \u003cem\u003ehow \u003c/em\u003ewe should interpret it. When we disclose that that content was produced with AI in some form, it begins to challenge traditional ideas of creativity and what a creative output is or should be like.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"ec72\"\u003eIf you know an article was created with the assistance of AI, how would you perceive it? What if that article was fully-AI generated? What if it was fully-human generated? How does your response change in each of these scenarios?\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"bc2b\"\u003eSome potential responses include:\u003c/p\u003e\u003cul\u003e\u003cli id=\"8d1f\"\u003e\u003cstrong\u003eResetting expectations — \u003c/strong\u003eof what the content is and should be doing… or just how we should approach interpreting it in the first place.\u003c/li\u003e\u003cli id=\"d205\"\u003e\u003cstrong\u003eEngage differently\u003c/strong\u003e — How might we read or engage with it differently because we know that AI was involved? Are we more or less critical of the article that was human-driven or the one that was AI-driven?\u003c/li\u003e\u003cli id=\"1373\"\u003e\u003cstrong\u003eDevaluing\u003c/strong\u003e the article more based on more use of AI — for example, Level 1 articles are inherently better or more valuable than Level 5 articles.\u003c/li\u003e\u003cli id=\"ccbf\"\u003e\u003cstrong\u003eEroding trust \u003c/strong\u003e— if the article used the assistance of AI, can it still be trusted or should we be more critical because AI tends to oversimplify and introduce bias?\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"6760\"\u003eThere\u0026#39;s an interesting parallel with \u003cstrong\u003efood labeling\u003c/strong\u003e: if you know that a product was genetically modified, does that change your perception of the product? Do you make a different purchasing decision? Is it better to know that the product is genetically modified (GMO)? Should we label genetically modified food? How should it be labeled?\u003c/p\u003e\u003cp id=\"17d1\"\u003eBy using food labeling as a parallel, perhaps you\u0026#39;re thinking, \u0026#34;\u003cem\u003eOf course\u003c/em\u003e we should label genetically modified food!\u0026#34;\u003c/p\u003e\u003cp id=\"b014\"\u003eAre you also thinking, \u0026#34;\u003cem\u003eOf course\u003c/em\u003e we should label AI-assisted involvement in our products and services!\u0026#34; as well?\u003c/p\u003e\u003cp id=\"e28e\"\u003eYour response to these two questions is worth reflecting on.\u003c/p\u003e\u003ch2 id=\"c2c0\"\u003e\u003cstrong\u003eAdditional applications of the framework\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"8173\"\u003eThis framework applies beyond content creation. It can be applied across other disciplines and industries to guide transparent AI use in.\u003c/p\u003e\u003cp id=\"81c1\"\u003eIn the examples below, I\u0026#39;ll define Levels 1, 3, and 5 separately, however, in each case:\u003c/p\u003e\u003cul\u003e\u003cli id=\"4f8b\"\u003eLevel 2 can be defined as \u0026#34;Mostly human with some AI.\u0026#34;\u003c/li\u003e\u003cli id=\"42c6\"\u003eLevel 3 is a balanced integration of the two ends of the scale\u003c/li\u003e\u003cli id=\"6912\"\u003eLevel 4 as \u0026#34;Mostly AI with some human oversight.\u0026#34;\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"f089\"\u003e\u003cstrong\u003eProduct development\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli id=\"451c\"\u003eLevel 1: Manual prototyping without AI involvement.\u003c/li\u003e\u003cli id=\"809f\"\u003eLevel 3: AI assists in analyzing user feedback or generating design variants, with humans making final decisions.\u003c/li\u003e\u003cli id=\"8090\"\u003eLevel 5: The entire design process is AI-automated, with minimal human input.\u003c/li\u003e\u003cli id=\"03b1\"\u003eReflection: Are we using AI to complement human creativity, or automating decisions that require empathy and context?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"6c8a\"\u003e\u003cstrong\u003eUX Research\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli id=\"e311\"\u003eLevel 1: Data collection and analysis are entirely manual and human-driven. AI was not used to assist in the process at all.\u003c/li\u003e\u003cli id=\"128b\"\u003eLevel 3: AI identifies trends, but researchers interpret findings to ensure meaningful insights.\u003c/li\u003e\u003cli id=\"f559\"\u003eLevel 5: AI conducts research and analysis without human involvement, risking oversimplification of user experiences.\u003c/li\u003e\u003cli id=\"b018\"\u003eReflection: Is AI helping uncover meaningful insights, or oversimplifying complex user experiences?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"85ad\"\u003e\u003cstrong\u003eDecision-making\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli id=\"ca24\"\u003eLevel 1: Decisions rely solely on human expertise.\u003c/li\u003e\u003cli id=\"6621\"\u003eLevel 3: AI provides insights or simulations, but humans retain decision-making authority.\u003c/li\u003e\u003cli id=\"4f53\"\u003eLevel 5: Decisions are fully automated by AI, potentially compromising empathy and ethical judgment.\u003c/li\u003e\u003cli id=\"4ad8\"\u003eReflection: Are we using AI insights to enhance decisions, or surrendering judgment to the algorithm?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"6a85\"\u003e\u003cstrong\u003eHiring \u0026amp; HR decisions\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli id=\"54d4\"\u003eShould AI-assisted hiring disclose when a résumé was screened by an algorithm? Are AI-assisted screening processes biased?\u003c/li\u003e\u003cli id=\"ccc7\"\u003eBy contrast, should candidates disclose if AI helped them write their application? Is a grammar check the same as using a LLM?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"24a4\"\u003e\u003cstrong\u003eLegal \u0026amp; Healthcare fields\u003c/strong\u003e\u003c/h2\u003e\u003cul\u003e\u003cli id=\"3b6d\"\u003eShould doctors and lawyers disclose AI-assisted decisions?\u003c/li\u003e\u003cli id=\"8267\"\u003eIf an AI-assisted medical diagnosis is given, should patients know exactly what role AI played?\u003c/li\u003e\u003c/ul\u003e\u003cp id=\"dde0\"\u003eFrom hiring decisions to legal opinions, AI-driven processes are changing industries. Applying this framework in fields like HR, healthcare, and law can ensure informed decision-making and ethical accountability.\u003c/p\u003e\u003cp id=\"7cfb\"\u003eIt is my hope that we can build out our thinking about transparent use of AI together over time and that the Transparency Framework for the levels of AI involvement can become part of a new discourse on our intentional use of AI.\u003c/p\u003e\u003ch2 id=\"5300\"\u003e\u003cstrong\u003eEncouraging reflection\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"6325\"\u003eFinally, the framework can also be used to reflect on one or many of the following areas:\u003c/p\u003e\u003cul\u003e\u003cli id=\"a945\"\u003e\u003cstrong\u003eGeneral reflection\u003c/strong\u003e: Does this level of AI use enhance or compromise the quality and integrity of the work?\u003c/li\u003e\u003cli id=\"65f1\"\u003e\u003cstrong\u003eIntentionality: \u003c/strong\u003eAm I being intentional about my use of AI or am I defaulting to a certain level of use?\u003c/li\u003e\u003cli id=\"e1a0\"\u003e\u003cstrong\u003eCreativity\u003c/strong\u003e: Is AI amplifying creativity or stifling originality?\u003c/li\u003e\u003cli id=\"d0c9\"\u003e\u003cstrong\u003eLearning and growth:\u003c/strong\u003e How does the use of AI impact my skill development and craftsmanship?\u003c/li\u003e\u003cli id=\"c173\"\u003e\u003cstrong\u003eInclusivity and bias\u003c/strong\u003e: Is AI helping to amplify diverse perspectives, or reinforcing harmful generalizations?\u003c/li\u003e\u003cli id=\"b0b4\"\u003e\u003cstrong\u003eAccountability\u003c/strong\u003e: Can I clearly articulate which parts of the work were AI-generated versus human-driven?\u003c/li\u003e\u003cli id=\"fc1a\"\u003e\u003cstrong\u003eHuman flourishing: \u003c/strong\u003eDoes the use of AI affect my personal sense of \u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/human-flourishing-in-the-age-of-ai-b456b1de31c7\"\u003epurpose, fulfillment, and meaning\u003c/a\u003e?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"dec2\"\u003e\u003cstrong\u003eThe goal of transparency\u003c/strong\u003e\u003c/h2\u003e\u003cp id=\"95c3\"\u003eAI-based tools are already shaping our present reality. The question is not \u003cem\u003ewhether\u003c/em\u003e we use AI, but \u003cem\u003ehow\u003c/em\u003e we disclose, govern, and apply it responsibly.\u003c/p\u003e\u003cp id=\"e066\"\u003eTransparency is not about restriction — it is about trust. By adopting AI transparency as a standard, we shape the ethical and philosophical foundation of how AI integrates into our work, our industries, and our daily lives. This is our opportunity to lead, before regulation forces its own outcome.\u003c/p\u003e\u003cp id=\"0f9c\"\u003eThis approach doesn’t aim to dictate a “correct” level of AI involvement but instead encourages openness about the choices made in the creative and decision-making process.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"60f0\"\u003eIf your reflection raises concerns, reconsider whether AI is being used responsibly and intentionally… and respond accordingly.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"f299\"\u003eAs we evolve with AI, our goal should always be to ensure it works for us, enhances human flourishing, and promotes purpose, creativity, and equity for all.\u003c/p\u003e\u003ch2 id=\"258f\"\u003eFull circle with full disclosure\u003c/h2\u003e\u003cp id=\"cbe6\"\u003eI believe this article represents \u003cstrong\u003eAI Transparency Level 3\u003c/strong\u003e. The framework is wholly mine, but I used ChatGPT to refine some wording and perform some background research to think through the implications and ensure I haven\u0026#39;t missed anything important. I also had feedback and help from my colleague Katie Trocin.\u003c/p\u003e\u003ch2 id=\"6f3a\"\u003eLearn more\u003c/h2\u003e\u003cp id=\"d461\"\u003eThis article doesn\u0026#39;t exist in isolation but is the natural outcome of two other recently published articles:\u003c/p\u003e\u003col\u003e\u003cli id=\"2755\"\u003e\u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/human-flourishing-in-the-age-of-ai-b456b1de31c7\"\u003eHuman flourishing in the age of AI\u003c/a\u003e — if you are looking for reference articles and sources cited, this is the place to start. With an extensive appendix and sources cited throughout, this article is a treasure trove of references and a synthesis of current thinking on human flourishing and AI.\u003c/li\u003e\u003cli id=\"5280\"\u003e\u003ca rel=\"noopener\" target=\"_blank\" href=\"https://uxdesign.cc/the-human-centered-ai-manifesto-21118d3dd4c0\"\u003eThe human-centered AI manifesto\u003c/a\u003e — the manifesto is based on the initial human flourishing article as a summary of principles of human-centered AI and commitments to action. If you are so moved, there\u0026#39;s a link to a \u003ca href=\"https://www.change.org/p/the-human-centered-ai-manifesto\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003echange.org petition\u003c/a\u003e you can sign to show your support and stand up for the responsible design and development of human-centered AI-based products and services.\u003c/li\u003e\u003c/ol\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": "2025-01-31T21:48:21.971Z",
  "modifiedTime": null
}
