{
  "id": "8d4ebbbb-57b6-4d6f-b9c7-0a720fb867be",
  "title": "Craft vs. Complacency: the ethics of laziness in AI-driven UX",
  "link": "https://uxdesign.cc/craft-vs-complacency-the-ethics-of-laziness-in-ai-driven-ux-38be675e5b8a?source=rss----138adf9c44c---4",
  "description": "",
  "author": "Dan Maccarone",
  "published": "Sun, 08 Jun 2025 16:03:17 GMT",
  "source": "https://uxdesign.cc/feed",
  "categories": [
    "user-experience",
    "information-architecture",
    "product-design",
    "design",
    "ai"
  ],
  "byline": "Dan Maccarone",
  "length": 10816,
  "excerpt": "Recently, a partner sent me an image to use on a client site. At first glance, it looked like another rough AI mockup. But then we looked closer. The image had started as a photo taken by a…",
  "siteName": "UX Collective",
  "favicon": "https://miro.medium.com/v2/resize:fill:256:256/1*dn6MbbIIlwobt0jnUcrt_Q.png",
  "text": "AI isn’t making UX worse. Sloppy designers are.Recently, a partner sent me an image to use on a client site. At first glance, it looked like another rough AI mockup. But then we looked closer. The image had started as a photo taken by a well-known photographer, someone with millions of followers on Instagram. Then it had been put through generative AI. And then it had been sloppily photoshopped.So it wasn’t just AI-generated, it was an IP violation layered with lazy design. It was poorly edited. And it was immediately recognizable as inauthentic. The lighting didn’t match. The proportions were off. There were clear AI giveaways: uncanny hands, distorted facial features, and subtle rendering issues that gave it away instantly.It wasn’t just rough, it was reckless. The kind of thing that says, “This was put through a machine, and no one cared enough to clean it up, or even check where it came from.”The problem wasn’t the tools used. The problem was the judgment. Someone thought this was good enough to send to a client and pass off as “original artwork” on their site.If we’d used it, people would’ve noticed, and not in a good way. Our client’s brand would’ve taken a hit, and not just in perception, but at a moment that actually mattered. They’re a startup. They’re bootstrapping. Every pixel, every decision, every asset counts. When someone sends them something phoned-in, it’s not just lazy, it’s disrespectful. They’re paying for design that reflects who they are and where they’re going. This would’ve undercut all of it before they even launched.And for us? We risk looking complicit. Like we didn’t catch it, or worse, like we didn’t care either.And this wasn’t a one-off.Lazy lowers the bar for everyone. It’s contagious.I’ve seen people submit conference talk proposals that were clearly ChatGPT-written: bad formatting, generic sentences, no personalization. I’ve seen client briefs so thin and AI-scraped they couldn’t hold their own weight.Sloppy isn’t harmless, it blocks everyone downstream from doing their job well. It doesn’t just waste time. It erodes trust.If you’ve ever watched an episode of Inspector Gadget, you know the drill: lots of noise, lots of tech, but at the end of the day, it was Penny and Brain doing the real work. That’s what AI is right now. The spectacle can be impressive, but the outcomes still depend on who’s guiding the machine.Recently, Patrick Neeman and I spoke at UXPA Boston, where we delivered a talk focused squarely on how the industry should think about AI as a tool, especially in a time when the industry is grappling with the speed and scale of change.This wasn’t an academic panel. It was a room full of seasoned pros, veteran UXers who understand that our field is in a moment of real crisis. That’s why we felt the need to give that talk.To drive the point home, we built our entire deck using AI-generated images. Every slide. And we told the audience upfront: we left the errors in on purpose. Spelling mistakes, weird fingers, inconsistent shadows, the whole parade of AI quirks.Here are a couple examples:Clearly, the AI generated image spelled “framework” incorrectly. right off the bat.The AI has this guitar player having 5 fingers on one hand and (assuming the thumb is behind the neck of the guitar) only four fingers on the other hand.The point wasn’t to dunk on the tech. It was to demonstrate that you can’t just let the machine drive and expect a perfect outcome. You still need a human behind the wheel.The day after UXPA Boston, Patrick and I were on the other side of the country speaking in Seattle at the University of Washington for the Women in UX conference. This audience was different. These were people just entering the industry, full of excitement, optimism, and thoughtful questions.Even in their early careers, they could sense the ethical tension. They weren’t asking how to avoid AI, they were asking how to use it well. The room was full of smart, thoughtful people, many of them early in their UX careers, asking exactly the right questions. They weren’t asking, “Can I use AI to replace my job?” They were asking, “How do I use AI without cutting corners?”They wanted to know where the line was.And here’s the truth: That line isn’t fixed. It’s contextual. But it exists. And the more we use AI in our work, the more we have to pay attention to when we’re using it to help and when we’re using it to hide.Tools don’t set standards. People do.We often hear the phrase “AI is just a tool.” And that’s true. But it’s an incomplete truth. A hammer is a tool, too. You can use it to build a house or to smash a window.The ethics don’t live in the object. They live in the intent and in the craft.Most of the articles out there focus on the big, theoretical stuff: privacy, surveillance, explainability.Darrell Estabrook and Gytis Markevicius have created an ethics-in-design primer that talks about fairness and user trust and it does a solid job of surfacing principles like fairness, user trust, and human-centeredness. That said, its guidance remains high-level. It talks about ‘human oversight’, but doesn’t define what that looks like when someone uses ChatGPT to write a case study and ships it without revision.Meanwhile, Nandkumar Bhujbal argues that AI systems must preserve user autonomy which is a fair point. But autonomy is just as compromised by poor design decisions as it is by surveillance. When we let AI write the error messages or confirmation modals without review, we’re not protecting autonomy, we’re delegating it.This leads us back to the human factor. Dennis Dickson raises a warning about ethical ambiguity as AI blends into our workflows. That’s the crux: AI isn’t visible to the end user anymore. So the ethics of how we use it get buried and designers stop asking who’s accountable.Jay Eckert underscores the need for designers to understand their tools’ boundaries. He warns that relying on AI without critical oversight will lead to “the erosion of design as a thoughtful, human practice.” That’s the kind of phrase we should pin above our monitors.It’s great to see people raising their voices here and, frankly, laying the groundwork.No one has gone far enough to say what needs to be said: that pushing unpolished work live because ‘the AI wrote it’ is a choice. And a bad one.We also need to talk about something more immediate: the ethics of effort.Because if you’re a UX designer using AI to generate something and then pushing it live without vetting it, refining it, questioning it, that’s not ethical. That’s lazy. And laziness at scale is just as damaging as malice. Sometimes more so.The ethics of effortCaiden Laubach writes about how ethical AI involves using tools built with integrity, ensuring outputs respect intellectual property rights, and safeguarding user data. He also underscores the necessity of obtaining proper permissions and maintaining transparency in AI-generated content to uphold brand trust. But here’s the thing:You don’t have to be trying to mislead to end up misleading someone. All you have to do is care less than you should.At the Women in UX event, the thing that struck me most wasn’t fear, it was optimism. People wanted to learn how to use AI well. They weren’t resisting the tool. They were resisting the temptation to let the tool lower their standards. They knew that AI could be brilliant at first drafts. They just didn’t want it to be their last.That’s the line.When you use AI, use it with disciplineThat’s why Patrick’s book, UXGPT, is so useful. It’s not a collection of hacks. It’s a method, a way to use AI to support clarity, not replace it. It gives structure to the chaos, and it centers the human. It helps people ask better questions, which is the entire point of good UX.We need more frameworks like that. Because as AI continues to shape our workflows, our challenge isn’t “How do we stay ahead of the robots?” It’s “How do we stay accountable to our users, our teams, and ourselves?”The People + AI Guidebook from Google reinforces this with its human-in-the-loop model: AI is there to assist, not decide. And yet, we’re seeing more and more tools automate decisions people care deeply about. Alan Cooper marked it as a red flag in his design philosophy when he said: “Don’t automate decisions people care about.” If we’re not applying that to our AI-infused workflows, we’re not doing UX, we’re doing automation theater.If we want to be trusted, we have to careThis matters not just because of quality, but because of trust. As Sharath Jegan puts it, “By prioritizing transparency and explainability, designers promote trust, empower users, and uphold ethical principles in AI-driven UX design.” If we want to be trusted, we need to care, not just about privacy, but about polish.So yes, keep talking about privacy. Keep demanding explainability. But also look at the work you’re shipping and ask:Did I do the hard part?Did I put this through a critical lens?Did I protect the user from my own shortcuts?The real riskAI can help us move faster. But it can also help us slide. That’s the ethical conversation we need to be having, not just in policy documents, but in pitch decks, design reviews, and production pushes.Because the real risk isn’t that AI will take our jobs. It’s that we’ll let it take our standards.And if that sounds like a Black Mirror episode, that’s because it is, Season 6, Episode 1, to be exact. But you could just as easily argue this is The Jetsons with fewer flying cars and more UX debt. Or HAL 9000 from 2001: A Space Odyssey, except instead of locking us out of an airlock, the algorithm just auto-publishes a homepage headline that makes no sense.We’re not building dystopia on purpose. But we are inching toward it with every unreviewed, unrefined, uncritical “good enough” that makes it into production.So let’s hold the lineWe still have a choice. We can decide where the line is. And we can decide to hold it.More importantly, we can model what it looks like to use AI the right way. We can show younger designers, skeptical stakeholders, and overwhelmed teams that AI doesn’t mean compromise, it means discipline. It means knowing when to hit “Generate” and when to say, “Not good enough yet.” It means raising the standard, not just because the user deserves it, but because we do.If we do this well, AI doesn’t replace UX. It reinforces it.When it comes down to it, design still matters. Judgment still matters. Craft still matters. And that is the hill I’ll die on, even if it was landscaped by Midjourney.About Dan MaccaroneDan Maccarone is a UX strategist, product designer, and co-founder of Charming Robot. He’s also the author of The Barstool MBA, an Audible Original on real-world product strategy. You can connect with Dan on LinkedIn and Twitter (he’s not calling it X).",
  "image": "https://miro.medium.com/v2/resize:fit:1200/1*lTTxKh3k8rdX3wvfkMx7ZQ.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"a590\"\u003eAI isn’t making UX worse. Sloppy designers are.\u003c/h2\u003e\u003cdiv tabindex=\"-1\" aria-hidden=\"false\"\u003e\u003ca href=\"https://medium.com/@danmaccarone?source=post_page---byline--38be675e5b8a---------------------------------------\" rel=\"noopener follow\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Dan Maccarone\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*ZVYnvgMYAeNcKz2YFXAelg.png\" width=\"32\" height=\"32\" loading=\"lazy\" data-testid=\"authorPhoto\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp id=\"3ada\"\u003eRecently, a partner sent me an image to use on a client site. At first glance, it looked like another rough AI mockup. But then we looked closer. The image had started as a photo taken by a well-known photographer, someone with millions of followers on Instagram. Then it had been put through generative AI. And then it had been sloppily photoshopped.\u003c/p\u003e\u003cp id=\"f46f\"\u003eSo it wasn’t just AI-generated, it was an IP violation layered with lazy design. It was poorly edited. And it was immediately recognizable as inauthentic. The lighting didn’t match. The proportions were off. There were clear AI giveaways: uncanny hands, distorted facial features, and subtle rendering issues that gave it away instantly.\u003c/p\u003e\u003cp id=\"be8b\"\u003eIt wasn’t just rough, it was reckless. The kind of thing that says, “This was put through a machine, and no one cared enough to clean it up, or even check where it came from.”\u003c/p\u003e\u003cp id=\"e4a1\"\u003eThe problem wasn’t the tools used. The problem was the judgment. Someone thought this was good enough to send to a client and pass off as “original artwork” on their site.\u003c/p\u003e\u003cp id=\"ffb4\"\u003eIf we’d used it, people would’ve noticed, and not in a good way. Our client’s brand would’ve taken a hit, and not just in perception, but at a moment that actually mattered. They’re a startup. They’re bootstrapping. Every pixel, every decision, every asset counts. When someone sends them something phoned-in, it’s not just lazy, it’s disrespectful. They’re paying for design that reflects who they are and where they’re going. This would’ve undercut all of it before they even launched.\u003c/p\u003e\u003cp id=\"8e95\"\u003eAnd for us? We risk looking complicit. Like we didn’t catch it, or worse, like we didn’t care either.\u003c/p\u003e\u003cp id=\"4b69\"\u003eAnd this wasn’t a one-off.\u003c/p\u003e\u003ch2 id=\"b6ed\"\u003eLazy lowers the bar for everyone. It’s contagious.\u003c/h2\u003e\u003cp id=\"fbcc\"\u003eI’ve seen people submit conference talk proposals that were clearly ChatGPT-written: bad formatting, generic sentences, no personalization. I’ve seen client briefs so thin and AI-scraped they couldn’t hold their own weight.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"2e43\"\u003eSloppy isn’t harmless, it blocks everyone downstream from doing their job well. It doesn’t just waste time. It erodes trust.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"ec27\"\u003eIf you’ve ever watched an episode of Inspector Gadget, you know the drill: lots of noise, lots of tech, but at the end of the day, it was Penny and Brain doing the real work. That’s what AI is right now. The spectacle can be impressive, but the outcomes still depend on who’s guiding the machine.\u003c/p\u003e\u003cp id=\"df1a\"\u003eRecently, \u003ca href=\"https://www.linkedin.com/in/patrick-neeman-ux/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003ePatrick Neeman\u003c/a\u003e and I spoke at UXPA Boston, where we delivered a talk focused squarely on how the industry should think about AI as a tool, especially in a time when the industry is grappling with the speed and scale of change.\u003c/p\u003e\u003cp id=\"d920\"\u003eThis wasn’t an academic panel. It was a room full of seasoned pros, veteran UXers who understand that our field is in a moment of real crisis. That’s why we felt the need to give that talk.\u003c/p\u003e\u003cp id=\"67e7\"\u003eTo drive the point home, we built our \u003ca href=\"https://www.slideshare.net/slideshow/we-trust-ai-until-we-don-t_-the-ux-of-comfort-zones-by-dan-maccarone-and-patrick-neeman/279008774\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eentire deck using AI-generated images\u003c/a\u003e. Every slide. And we told the audience upfront: we left the errors in on purpose. Spelling mistakes, weird fingers, inconsistent shadows, the whole parade of AI quirks.\u003c/p\u003e\u003cp id=\"6198\"\u003eHere are a couple examples:\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eClearly, the AI generated image spelled “framework” incorrectly. right off the bat.\u003c/figcaption\u003e\u003c/figure\u003e\u003cfigure\u003e\u003cfigcaption\u003eThe AI has this guitar player having 5 fingers on one hand and (assuming the thumb is behind the neck of the guitar) only four fingers on the other hand.\u003c/figcaption\u003e\u003c/figure\u003e\u003cp id=\"d525\"\u003eThe point wasn’t to dunk on the tech. It was to demonstrate that you can’t just let the machine drive and expect a perfect outcome. You still need a human behind the wheel.\u003c/p\u003e\u003cp id=\"f5d1\"\u003eThe day after UXPA Boston, Patrick and I were on the other side of the country speaking in Seattle at the University of Washington for the Women in UX conference. This audience was different. These were people just entering the industry, full of excitement, optimism, and thoughtful questions.\u003c/p\u003e\u003cp id=\"e24d\"\u003eEven in their early careers, they could sense the ethical tension. They weren’t asking how to avoid AI, they were asking how to use it \u003cem\u003ewell.\u003c/em\u003e The room was full of smart, thoughtful people, many of them early in their UX careers, asking exactly the right questions. They weren’t asking, “Can I use AI to replace my job?” They were asking, “How do I use AI without cutting corners?”\u003c/p\u003e\u003cp id=\"a9f8\"\u003eThey wanted to know where the line was.\u003c/p\u003e\u003cp id=\"61c3\"\u003eAnd here’s the truth: That line isn’t fixed. It’s contextual. But it exists. And the more we use AI in our work, the more we have to pay attention to when we’re using it to help and when we’re using it to hide.\u003c/p\u003e\u003ch2 id=\"7319\"\u003eTools don’t set standards. People do.\u003c/h2\u003e\u003cp id=\"4465\"\u003eWe often hear the phrase “AI is just a tool.” And that’s true. But it’s an incomplete truth. A hammer is a tool, too. You can use it to build a house or to smash a window.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"a5e6\"\u003eThe ethics don’t live in the object. They live in the intent and in the craft.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"8ae5\"\u003eMost of the articles out there focus on the big, theoretical stuff: privacy, surveillance, explainability.\u003c/p\u003e\u003cp id=\"d72f\"\u003eDarrell Estabrook and Gytis Markevicius have created an \u003ca href=\"https://www.toptal.com/designers/artificial-intelligence/ai-ethics-in-design\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eethics-in-design primer\u003c/a\u003e that talks about fairness and user trust and it does a solid job of surfacing principles like fairness, user trust, and human-centeredness. That said, its guidance remains high-level. It talks about ‘human oversight’, but doesn’t define what that looks like when someone uses ChatGPT to write a case study and ships it without revision.\u003c/p\u003e\u003cp id=\"4810\"\u003eMeanwhile, \u003ca href=\"https://indiaai.gov.in/article/ethical-considerations-in-ai-driven-ux-design\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eNandkumar Bhujbal\u003c/a\u003e argues that AI systems must preserve user autonomy which is a fair point. But autonomy is just as compromised by poor design decisions as it is by surveillance. When we let AI write the error messages or confirmation modals without review, we’re not protecting autonomy, we’re delegating it.\u003c/p\u003e\u003cp id=\"5e1e\"\u003eThis leads us back to the human factor. \u003ca href=\"https://www.linkedin.com/pulse/ethical-implications-ai-ux-design-particularly-how-maintain-dickson-ihdxf/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eDennis Dickson\u003c/a\u003e raises a warning about ethical ambiguity as AI blends into our workflows. That’s the crux: AI isn’t visible to the end user anymore. So the ethics of how we use it get buried and designers stop asking who’s accountable.\u003c/p\u003e\u003cp id=\"71af\"\u003e\u003ca href=\"https://parachutedesign.ca/blog/ethics-of-ai-in-design/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eJay Eckert\u003c/a\u003e underscores the need for designers to understand their tools’ boundaries. He warns that relying on AI without critical oversight will lead to “the erosion of design as a thoughtful, human practice.” That’s the kind of phrase we should pin above our monitors.\u003c/p\u003e\u003cp id=\"f674\"\u003eIt’s great to see people raising their voices here and, frankly, laying the groundwork.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"2f59\"\u003eNo one has gone far enough to say what needs to be said: that pushing unpolished work live because ‘the AI wrote it’ is a choice. And a bad one.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"7240\"\u003eWe also need to talk about something more immediate: the ethics of effort.\u003c/p\u003e\u003cp id=\"4c7c\"\u003eBecause if you’re a UX designer using AI to generate something and then pushing it live without vetting it, refining it, questioning it, that’s not ethical. That’s lazy. And laziness at scale is just as damaging as malice. Sometimes more so.\u003c/p\u003e\u003ch2 id=\"346e\"\u003eThe ethics of effort\u003c/h2\u003e\u003cp id=\"862b\"\u003e\u003ca href=\"https://designpickle.com/the-importance-of-ethical-ai-in-design-branding-and-marketing\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eCaiden Laubach\u003c/a\u003e writes about how ethical AI involves using tools built with integrity, ensuring outputs respect intellectual property rights, and safeguarding user data. He also underscores the necessity of obtaining proper permissions and maintaining transparency in AI-generated content to uphold brand trust. But here’s the thing:\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"257c\"\u003eYou don’t have to be trying to mislead to end up misleading someone. All you have to do is care less than you should.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"196b\"\u003eAt the Women in UX event, the thing that struck me most wasn’t fear, it was optimism. People wanted to learn how to use AI well. They weren’t resisting the tool. They were resisting the temptation to let the tool lower their standards. They knew that AI could be brilliant at first drafts. They just didn’t want it to be their last.\u003c/p\u003e\u003cp id=\"b13d\"\u003eThat’s the line.\u003c/p\u003e\u003ch2 id=\"a8ea\"\u003eWhen you use AI, use it with discipline\u003c/h2\u003e\u003cp id=\"f4c9\"\u003eThat’s why Patrick’s book, \u003ca href=\"https://www.gptpromptguides.com/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eUXGPT\u003c/a\u003e, is so useful. It’s not a collection of hacks. It’s a method, a way to use AI to support clarity, not replace it. It gives structure to the chaos, and it centers the human. It helps people ask better questions, which is the entire point of good UX.\u003c/p\u003e\u003cp id=\"0990\"\u003eWe need more frameworks like that. Because as AI continues to shape our workflows, our challenge isn’t “How do we stay ahead of the robots?” It’s “How do we stay accountable to our users, our teams, and ourselves?”\u003c/p\u003e\u003cp id=\"91f3\"\u003e\u003ca href=\"https://pair.withgoogle.com/guidebook/\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eThe People + AI Guidebook from Google\u003c/a\u003e reinforces this with its human-in-the-loop model: AI is there to assist, not decide. And yet, we’re seeing more and more tools automate decisions people care deeply about. Alan Cooper marked it as a red flag in his design philosophy when he said: “Don’t automate decisions people care about.” If we’re not applying that to our AI-infused workflows, we’re not doing UX, we’re doing automation theater.\u003c/p\u003e\u003ch2 id=\"cdcc\"\u003eIf we want to be trusted, we have to care\u003c/h2\u003e\u003cp id=\"964c\"\u003eThis matters not just because of quality, but because of trust. As \u003ca href=\"https://medium.com/@sjegann/five-ethical-principles-for-ai-in-ux-c1021a7fd806\" rel=\"noopener\"\u003eSharath Jegan\u003c/a\u003e puts it, “By prioritizing transparency and explainability, designers promote trust, empower users, and uphold ethical principles in AI-driven UX design.” If we want to be trusted, we need to care, not just about privacy, but about polish.\u003c/p\u003e\u003cp id=\"a357\"\u003eSo yes, keep talking about privacy. Keep demanding explainability. But also look at the work you’re shipping and ask:\u003c/p\u003e\u003cul\u003e\u003cli id=\"862c\"\u003eDid I do the hard part?\u003c/li\u003e\u003cli id=\"a92c\"\u003eDid I put this through a critical lens?\u003c/li\u003e\u003cli id=\"e93d\"\u003eDid I protect the user from my own shortcuts?\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"b801\"\u003eThe real risk\u003c/h2\u003e\u003cp id=\"8f64\"\u003eAI can help us move faster. But it can also help us slide. That’s the ethical conversation we need to be having, not just in policy documents, but in pitch decks, design reviews, and production pushes.\u003c/p\u003e\u003cp id=\"67c4\"\u003eBecause the real risk isn’t that AI will take our jobs. It’s that we’ll let it take our standards.\u003c/p\u003e\u003cp id=\"90e0\"\u003eAnd if that sounds like a Black Mirror episode, that’s because it is, \u003ca href=\"https://en.wikipedia.org/wiki/Joan_Is_Awful\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eSeason 6, Episode 1\u003c/a\u003e, to be exact. But you could just as easily argue this is The Jetsons with fewer flying cars and more UX debt. Or \u003ca href=\"https://en.wikipedia.org/wiki/HAL_9000\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eHAL 9000\u003c/a\u003e from 2001: A Space Odyssey, except instead of locking us out of an airlock, the algorithm just auto-publishes a homepage headline that makes no sense.\u003c/p\u003e\u003cp id=\"e207\"\u003eWe’re not building dystopia on purpose. But we are inching toward it with every unreviewed, unrefined, uncritical “good enough” that makes it into production.\u003c/p\u003e\u003ch2 id=\"6d18\"\u003eSo let’s hold the line\u003c/h2\u003e\u003cp id=\"036b\"\u003eWe still have a choice. We can decide where the line is. And we can decide to hold it.\u003c/p\u003e\u003cp id=\"9667\"\u003eMore importantly, we can model what it looks like to use AI the right way. We can show younger designers, skeptical stakeholders, and overwhelmed teams that AI doesn’t mean compromise, it means discipline. It means knowing when to hit “Generate” and when to say, “Not good enough yet.” It means raising the standard, not just because the user deserves it, but because we do.\u003c/p\u003e\u003cblockquote\u003e\u003cp id=\"b39d\"\u003eIf we do this well, AI doesn’t replace UX. It reinforces it.\u003c/p\u003e\u003c/blockquote\u003e\u003cp id=\"e3ae\"\u003eWhen it comes down to it, design still matters. Judgment still matters. Craft still matters. And that is the hill I’ll die on, even if it was landscaped by Midjourney.\u003c/p\u003e\u003ch2 id=\"7c54\"\u003eAbout Dan Maccarone\u003c/h2\u003e\u003cp id=\"effe\"\u003eDan Maccarone is a UX strategist, product designer, and co-founder of Charming Robot. He’s also the author of \u003ca href=\"https://www.audible.com/pd/The-Barstool-MBA-Audiobook/B07S2TJLHK\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003e\u003cem\u003eThe Barstool MBA\u003c/em\u003e\u003c/a\u003e, an Audible Original on real-world product strategy. You can connect with Dan on \u003ca href=\"https://www.linkedin.com/in/danmaccarone\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eLinkedIn\u003c/a\u003e and \u003ca href=\"https://twitter.com/danmaccarone\" rel=\"noopener ugc nofollow\" target=\"_blank\"\u003eTwitter\u003c/a\u003e (he’s not calling it X).\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2025-05-27T13:38:53.246Z",
  "modifiedTime": null
}
