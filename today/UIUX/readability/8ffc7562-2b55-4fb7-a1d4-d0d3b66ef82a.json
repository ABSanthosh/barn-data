{
  "id": "8ffc7562-2b55-4fb7-a1d4-d0d3b66ef82a",
  "title": "Adaptive Video Streaming With Dash.js In React",
  "link": "https://smashingmagazine.com/2025/03/adaptive-video-streaming-dashjs-react/",
  "description": "HTML `` is the de facto element we turn to for embedding video content, but it comes with constraints. For example, it downloads the video file linearly over HTTP, which leads to performance hiccups, especially for large videos consumed on slower connections. But with adaptive bitrate streaming, we can split the video into multiple segments at different bitrates and resolutions.",
  "author": "Teng Wei Herr",
  "published": "Thu, 27 Mar 2025 13:00:00 GMT",
  "source": "https://www.smashingmagazine.com/feed",
  "categories": null,
  "byline": "About The Author",
  "length": 14464,
  "excerpt": "HTML `` is the de facto element we turn to for embedding video content, but it comes with constraints. For example, it downloads the video file linearly over HTTP, which leads to performance hiccups, especially for large videos consumed on slower connections. But with adaptive bitrate streaming, we can split the video into multiple segments at different bitrates and resolutions.",
  "siteName": "Smashing Magazine",
  "favicon": "https://smashingmagazine.com/images/favicon/apple-touch-icon.png",
  "text": "9 min readVideo, Techniques, Tools, React, CodingHTML \u003cvideo\u003e is the de facto element we turn to for embedding video content, but it comes with constraints. For example, it downloads the video file linearly over HTTP, which leads to performance hiccups, especially for large videos consumed on slower connections. But with adaptive bitrate streaming, we can split the video into multiple segments at different bitrates and resolutions.I was recently tasked with creating video reels that needed to be played smoothly under a slow network or on low-end devices. I started with the native HTML5 \u003cvideo\u003e tag but quickly hit a wall — it just doesn’t cut it when connections are slow or devices are underpowered.After some research, I found that adaptive bitrate streaming was the solution I needed. But here’s the frustrating part: finding a comprehensive, beginner-friendly guide was so difficult. The resources on MDN and other websites were helpful but lacked the end-to-end tutorial I was looking for.That’s why I’m writing this article: to provide you with the step-by-step guide I wish I had found. I’ll bridge the gap between writing FFmpeg scripts, encoding video files, and implementing the DASH-compatible video player (Dash.js) with code examples you can follow.Going Beyond The Native HTML5 \u003cvideo\u003e TagYou might be wondering why you can’t simply rely on the HTML \u003cvideo\u003e element. There’s a good reason for that. Let’s compare the difference between a native \u003cvideo\u003e element and adaptive video streaming in browsers.Progressive DownloadWith progressive downloading, your browser downloads the video file linearly from the server over HTTP and starts playback as long as it has buffered enough data. This is the default behavior of the \u003cvideo\u003e element.\u003cvideo src=\"rabbit320.mp4\" /\u003e When you play the video, check your browser’s network tab, and you’ll see multiple requests with the 206 Partial Content status code.(Large preview)It uses HTTP 206 Range Requests to fetch the video file in chunks. The server sends specific byte ranges of the video to your browser. When you seek, the browser will make more range requests asking for new byte ranges (e.g., “Give me bytes 1,000,000–2,000,000”).In other words, it doesn’t fetch the entire file all at once. Instead, it delivers partial byte ranges from the single MP4 video file on demand. This is still considered a progressive download because only a single file is fetched over HTTP — there is no bandwidth or quality adaptation.If the server or browser doesn’t support range requests, the entire video file will be downloaded in a single request, returning a 200 OK status code. In that case, the video can only begin playing once the entire file has finished downloading.The problems? If you’re on a slow connection trying to watch high-resolution video, you’ll be waiting a long time before playback starts.Adaptive Bitrate StreamingInstead of serving one single video file, adaptive bitrate (ABR) streaming splits the video into multiple segments at different bitrates and resolutions. During playback, the ABR algorithm will automatically select the highest quality segment that can be downloaded in time for smooth playback based on your network connectivity, bandwidth, and other device capabilities. It continues adjusting throughout to adapt to changing conditions.This magic happens through two key browser technologies:Media Source Extension (MSE)It allows passing a MediaSource object to the src attribute in \u003cvideo\u003e, enabling sending multiple SourceBuffer objects that represent video segments.\u003cvideo src=\"blob:https://example.com/6e31fe2a-a0a8-43f9-b415-73dc02985892\" /\u003eMedia Capabilities APIIt provides information on your device’s video decoding and encoding abilities, enabling ABR to make informed decisions about which resolution to deliver.Together, they enable the core functionality of ABR, serving video chunks optimized for your specific device limitations in real time.Streaming Protocols: MPEG-DASH Vs. HLSAs mentioned above, to stream media adaptively, a video is split into chunks at different quality levels across various time points. We need to facilitate the process of switching between these segments adaptively in real time. To achieve this, ABR streaming relies on specific protocols. The two most common ABR protocols are:MPEG-DASH,HTTP Live Streaming (HLS).Both of these protocols utilize HTTP to send video files. Hence, they are compatible with HTTP web servers.This article focuses on MPEG-DASH. However, it’s worth noting that DASH isn’t supported by Apple devices or browsers, as mentioned in Mux’s article.MPEG-DASHMPEG-DASH enables adaptive streaming through:A Media Presentation Description (MPD) fileThis XML manifest file contains information on how to select and manage streams based on adaptive rules.Segmented Media FilesVideo and audio files are divided into segments at different resolutions and durations using MPEG-DASH-compliant codecs and formats.On the client side, a DASH-compliant video player reads the MPD file and continuously monitors network bandwidth. Based on available bandwidth, the player selects the appropriate bitrate and requests the corresponding video chunk. This process repeats throughout playback, ensuring smooth, optimal quality.Now that you understand the fundamentals, let’s build our adaptive video player!Steps To Build an Adaptive Bitrate Streaming Video PlayerHere’s the plan:Transcode the MP4 video into audio and video renditions at different resolutions and bitrates with FFmpeg.Generate an MPD file with FFmpeg.Serve the output files from the server.Build the DASH-compatible video player to play the video.Install FFmpegFor macOS users, install FFmpeg using Brew by running the following command in your terminal:brew install ffmpeg For other operating systems, please refer to FFmpeg’s documentation.Generate Audio RenditionNext, run the following script to extract the audio track and encode it in WebM format for DASH compatibility:ffmpeg -i \"input_video.mp4\" -vn -acodec libvorbis -ab 128k \"audio.webm\" -i \"input_video.mp4\": Specifies the input video file.-vn: Disables the video stream (audio-only output).-acodec libvorbis: Uses the libvorbis codec to encode audio.-ab 128k: Sets the audio bitrate to 128 kbps.\"audio.webm\": Specifies the output audio file in WebM format.Generate Video RenditionsRun this script to create three video renditions with varying resolutions and bitrates. The largest resolution should match the input file size. For example, if the input video is 576×1024 at 30 frames per second (fps), the script generates renditions optimized for vertical video playback.ffmpeg -i \"input_video.mp4\" -c:v libvpx-vp9 -keyint_min 150 -g 150 \\ -tile-columns 4 -frame-parallel 1 -f webm \\ -an -vf scale=576:1024 -b:v 1500k \"input_video_576x1024_1500k.webm\" \\ -an -vf scale=480:854 -b:v 1000k \"input_video_480x854_1000k.webm\" \\ -an -vf scale=360:640 -b:v 750k \"input_video_360x640_750k.webm\" -c:v libvpx-vp9: Uses the libvpx-vp9 as the VP9 video encoder for WebM.-keyint_min 150 and -g 150: Set a 150-frame keyframe interval (approximately every 5 seconds at 30 fps). This allows bitrate switching every 5 seconds.-tile-columns 4 and -frame-parallel 1: Optimize encoding performance through parallel processing.-f webm: Specifies the output format as WebM.In each rendition:-an: Excludes audio (video-only output).-vf scale=576:1024: Scales the video to a resolution of 576x1024 pixels.-b:v 1500k: Sets the video bitrate to 1500 kbps.WebM is chosen as the output format, as they are smaller in size and optimized yet widely compatible with most web browsers.Generate MPD Manifest FileCombine the video renditions and audio track into a DASH-compliant MPD manifest file by running the following script:ffmpeg \\ -f webm_dash_manifest -i \"input_video_576x1024_1500k.webm\" \\ -f webm_dash_manifest -i \"input_video_480x854_1000k.webm\" \\ -f webm_dash_manifest -i \"input_video_360x640_750k.webm\" \\ -f webm_dash_manifest -i \"audio.webm\" \\ -c copy \\ -map 0 -map 1 -map 2 -map 3 \\ -f webm_dash_manifest \\ -adaptation_sets \"id=0,streams=0,1,2 id=1,streams=3\" \\ \"input_video_manifest.mpd\" -f webm_dash_manifest -i \"…\": Specifies the inputs so that the ASH video player will switch between them dynamically based on network conditions.-map 0 -map 1 -map 2 -map 3: Includes all video (0, 1, 2) and audio (3) in the final manifest.-adaptation_sets: Groups streams into adaptation sets:id=0,streams=0,1,2: Groups the video renditions into a single adaptation set.id=1,streams=3: Assigns the audio track to a separate adaptation set.The resulting MPD file (input_video_manifest.mpd) describes the streams and enables adaptive bitrate streaming in MPEG-DASH.\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cMPD xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:mpeg:DASH:schema:MPD:2011\" xsi:schemaLocation=\"urn:mpeg:DASH:schema:MPD:2011\" type=\"static\" mediaPresentationDuration=\"PT81.166S\" minBufferTime=\"PT1S\" profiles=\"urn:mpeg:dash:profile:webm-on-demand:2012\"\u003e \u003cPeriod id=\"0\" start=\"PT0S\" duration=\"PT81.166S\"\u003e \u003cAdaptationSet id=\"0\" mimeType=\"video/webm\" codecs=\"vp9\" lang=\"eng\" bitstreamSwitching=\"true\" subsegmentAlignment=\"false\" subsegmentStartsWithSAP=\"1\"\u003e \u003cRepresentation id=\"0\" bandwidth=\"1647920\" width=\"576\" height=\"1024\"\u003e \u003cBaseURL\u003einput_video_576x1024_1500k.webm\u003c/BaseURL\u003e \u003cSegmentBase indexRange=\"16931581-16931910\"\u003e \u003cInitialization range=\"0-645\" /\u003e \u003c/SegmentBase\u003e \u003c/Representation\u003e \u003cRepresentation id=\"1\" bandwidth=\"1126977\" width=\"480\" height=\"854\"\u003e \u003cBaseURL\u003einput_video_480x854_1000k.webm\u003c/BaseURL\u003e \u003cSegmentBase indexRange=\"11583599-11583986\"\u003e \u003cInitialization range=\"0-645\" /\u003e \u003c/SegmentBase\u003e \u003c/Representation\u003e \u003cRepresentation id=\"2\" bandwidth=\"843267\" width=\"360\" height=\"640\"\u003e \u003cBaseURL\u003einput_video_360x640_750k.webm\u003c/BaseURL\u003e \u003cSegmentBase indexRange=\"8668326-8668713\"\u003e \u003cInitialization range=\"0-645\" /\u003e \u003c/SegmentBase\u003e \u003c/Representation\u003e \u003c/AdaptationSet\u003e \u003cAdaptationSet id=\"1\" mimeType=\"audio/webm\" codecs=\"vorbis\" lang=\"eng\" audioSamplingRate=\"44100\" bitstreamSwitching=\"true\" subsegmentAlignment=\"true\" subsegmentStartsWithSAP=\"1\"\u003e \u003cRepresentation id=\"3\" bandwidth=\"89219\"\u003e \u003cBaseURL\u003eaudio.webm\u003c/BaseURL\u003e \u003cSegmentBase indexRange=\"921727-922055\"\u003e \u003cInitialization range=\"0-4889\" /\u003e \u003c/SegmentBase\u003e \u003c/Representation\u003e \u003c/AdaptationSet\u003e \u003c/Period\u003e \u003c/MPD\u003e After completing these steps, you’ll have:Three video renditions (576x1024, 480x854, 360x640),One audio track, andAn MPD manifest file.input_video.mp4 audio.webm input_video_576x1024_1500k.webm input_video_480x854_1000k.webm input_video_360x640_750k.webm input_video_manifest.mpd The original video input_video.mp4 should also be kept to serve as a fallback video source later.Serve The Output FilesThese output files can now be uploaded to cloud storage (e.g., AWS S3 or Cloudflare R2) for playback. While they can be served directly from a local folder, I highly recommend storing them in cloud storage and leveraging a CDN to cache the assets for better performance. Both AWS and Cloudflare support HTTP range requests out of the box.Building The DASH-Compatible Video Player In ReactThere’s nothing like a real-world example to help understand how everything works. There are different ways we can implement a DASH-compatible video player, but I’ll focus on an approach using React.First, install the Dash.js npm package by running:npm i dashjs Next, create a component called \u003cDashVideoPlayer /\u003e and initialize the Dash MediaPlayer instance by pointing it to the MPD file when the component mounts.The ref callback function runs upon the component mounting, and within the callback function, playerRef will refer to the actual Dash MediaPlayer instance and be bound with event listeners. We also include the original MP4 URL in the \u003csource\u003e element as a fallback if the browser doesn’t support MPEG-DASH.If you’re using Next.js app router, remember to add the ‘use client’ directive to enable client-side hydration, as the video player is only initialized on the client side.Here is the full example:import dashjs from 'dashjs' import { useCallback, useRef } from 'react' export const DashVideoPlayer = () =\u003e { const playerRef = useRef() const callbackRef = useCallback((node) =\u003e { if (node !== null) { playerRef.current = dashjs.MediaPlayer().create() playerRef.current.initialize(node, \"https://example.com/uri/to/input_video_manifest.mpd\", false) playerRef.current.on('canPlay', () =\u003e { // upon video is playable }) playerRef.current.on('error', (e) =\u003e { // handle error }) playerRef.current.on('playbackStarted', () =\u003e { // handle playback started }) playerRef.current.on('playbackPaused', () =\u003e { // handle playback paused }) playerRef.current.on('playbackWaiting', () =\u003e { // handle playback buffering }) } },[]) return ( \u003cvideo ref={callbackRef} width={310} height={548} controls\u003e \u003csource src=\"https://example.com/uri/to/input_video.mp4\" type=\"video/mp4\" /\u003e Your browser does not support the video tag. \u003c/video\u003e ) }ResultObserve the changes in the video file when the network connectivity is adjusted from Fast 4G to 3G using Chrome DevTools. It switches from 480p to 360p, showing how the experience is optimized for more or less available bandwidth.ABR exampleConclusionThat’s it! We just implemented a working DASH-compatible video player in React to establish a video with adaptive bitrate streaming. Again, the benefits of this are rooted in performance. When we adopt ABR streaming, we’re requesting the video in smaller chunks, allowing for more immediate playback than we’d get if we needed to fully download the video file first. And we’ve done it in a way that supports multiple versions of the same video, allowing us to serve the best format for the user’s device.References“Http Range Request And MP4 Video Play In Browser,” Zeng XuSetting up adaptive streaming media sources (Mozilla Developer Network)DASH Adaptive Streaming for HTML video (Mozilla Developer Network) (gg, yk)",
  "image": "https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/adaptive-video-streaming-dashjs-react.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article__content\"\u003e\u003cul\u003e\u003cli\u003e9 min read\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://smashingmagazine.com/category/video\"\u003eVideo\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/techniques\"\u003eTechniques\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/tools\"\u003eTools\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/react\"\u003eReact\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/coding\"\u003eCoding\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003csection aria-label=\"Quick summary\"\u003eHTML \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e is the de facto element we turn to for embedding video content, but it comes with constraints. For example, it downloads the video file linearly over HTTP, which leads to performance hiccups, especially for large videos consumed on slower connections. But with adaptive bitrate streaming, we can split the video into multiple segments at different bitrates and resolutions.\u003c/section\u003e\u003c/p\u003e\u003cp\u003eI was recently tasked with creating video reels that needed to be played smoothly under a slow network or on low-end devices. I started with the native HTML5 \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e tag but quickly hit a wall — it just doesn’t cut it when connections are slow or devices are underpowered.\u003c/p\u003e\u003cp\u003eAfter some research, I found that \u003cstrong\u003eadaptive bitrate streaming\u003c/strong\u003e was the solution I needed. But here’s the frustrating part: finding a comprehensive, beginner-friendly guide was so difficult. The resources on MDN and other websites were helpful but lacked the end-to-end tutorial I was looking for.\u003c/p\u003e\u003cp\u003eThat’s why I’m writing this article: to provide you with the step-by-step guide I wish I had found. I’ll bridge the gap between writing FFmpeg scripts, encoding video files, and implementing the DASH-compatible video player (\u003ca href=\"https://dashjs.org/\"\u003eDash.js\u003c/a\u003e) with code examples you can follow.\u003c/p\u003e\u003ch2 id=\"going-beyond-the-native-html5-video-tag\"\u003eGoing Beyond The Native HTML5 \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e Tag\u003c/h2\u003e\u003cp\u003eYou might be wondering why you can’t simply rely on the HTML \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e element. There’s a good reason for that. Let’s compare the difference between a native \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e element and adaptive video streaming in browsers.\u003c/p\u003e\u003ch3 id=\"progressive-download\"\u003eProgressive Download\u003c/h3\u003e\u003cp\u003eWith progressive downloading, your browser downloads the video file linearly from the server over HTTP and starts playback as long as it has buffered enough data. This is the default behavior of the \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e element.\u003c/p\u003e\u003cpre\u003e\u003ccode\u003e\u0026lt;video src=\u0026#34;rabbit320.mp4\u0026#34; /\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen you play the video, check your browser’s network tab, and you’ll see multiple requests with the \u003ccode\u003e206 Partial Content\u003c/code\u003e status code.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"140\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png\" sizes=\"100vw\" alt=\"HTTP 206 Range Requests\"/\u003e\u003c/a\u003e\u003cfigcaption\u003e(\u003ca href=\"https://files.smashing.media/articles/adaptive-video-streaming-dashjs-react/http-206-range-requests.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eIt uses \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests\"\u003eHTTP 206 Range Requests\u003c/a\u003e to fetch the video file in chunks. The server sends specific byte ranges of the video to your browser. When you seek, the browser will make more range requests asking for new byte ranges (e.g., “Give me bytes 1,000,000–2,000,000”).\u003c/p\u003e\u003cp\u003eIn other words, it doesn’t fetch the entire file all at once. Instead, it delivers partial byte ranges from the single MP4 video file on demand. This is still considered a \u003cstrong\u003eprogressive download\u003c/strong\u003e because only a single file is fetched over HTTP — there is no bandwidth or quality adaptation.\u003c/p\u003e\u003cp\u003eIf the server or browser doesn’t support range requests, the entire video file will be downloaded in a single request, returning a \u003ccode\u003e200 OK\u003c/code\u003e status code. In that case, the video can only begin playing once the entire file has finished downloading.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe problems?\u003c/strong\u003e If you’re on a slow connection trying to watch high-resolution video, you’ll be waiting a long time before playback starts.\u003c/p\u003e\u003ch3 id=\"adaptive-bitrate-streaming\"\u003eAdaptive Bitrate Streaming\u003c/h3\u003e\u003cp\u003eInstead of serving one single video file, \u003cstrong\u003eadaptive bitrate (ABR) streaming\u003c/strong\u003e splits the video into multiple segments at different bitrates and resolutions. During playback, the ABR algorithm will automatically select the highest quality segment that can be downloaded in time for smooth playback based on your network connectivity, bandwidth, and other device capabilities. It continues adjusting throughout to adapt to changing conditions.\u003c/p\u003e\u003cp\u003eThis magic happens through two key browser technologies:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eMedia Source Extension (MSE)\u003c/strong\u003e\u003cbr/\u003eIt allows passing a \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/MediaSource\"\u003eMediaSource\u003c/a\u003e object to the \u003ccode\u003esrc\u003c/code\u003e attribute in \u003ccode\u003e\u0026lt;video\u0026gt;\u003c/code\u003e, enabling sending multiple \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/SourceBuffer\"\u003eSourceBuffer\u003c/a\u003e objects that represent video segments.\u003cbr/\u003e\u003c/li\u003e\u003c/ul\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode\u003e\u0026lt;video src=\u0026#34;blob:https://example.com/6e31fe2a-a0a8-43f9-b415-73dc02985892\u0026#34; /\u0026gt;\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eMedia Capabilities API\u003c/strong\u003e\u003cbr/\u003eIt provides information on your device’s video decoding and encoding abilities, enabling ABR to make informed decisions about which resolution to deliver.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTogether, they enable the core functionality of ABR, serving video chunks optimized for your specific device limitations in real time.\u003c/p\u003e\u003ch2 id=\"streaming-protocols-mpeg-dash-vs-hls\"\u003eStreaming Protocols: MPEG-DASH Vs. HLS\u003c/h2\u003e\u003cp\u003eAs mentioned above, to stream media adaptively, a video is split into chunks at different quality levels across various time points. We need to facilitate the process of switching between these segments adaptively in real time. To achieve this, ABR streaming relies on specific protocols. The two most common ABR protocols are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eMPEG-DASH,\u003c/li\u003e\u003cli\u003eHTTP Live Streaming (HLS).\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eBoth of these protocols utilize HTTP to send video files. Hence, they are compatible with HTTP web servers.\u003c/p\u003e\u003cp\u003eThis article focuses on MPEG-DASH. However, it’s worth noting that DASH isn’t supported by Apple devices or browsers, as mentioned in \u003ca href=\"https://www.mux.com/articles/hls-vs-dash-what-s-the-difference-between-the-video-streaming-protocols\"\u003eMux’s article\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"mpeg-dash\"\u003eMPEG-DASH\u003c/h3\u003e\u003cp\u003eMPEG-DASH enables adaptive streaming through:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eA Media Presentation Description (MPD) file\u003c/strong\u003e\u003cbr/\u003eThis XML manifest file contains information on how to select and manage streams based on adaptive rules.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eSegmented Media Files\u003c/strong\u003e\u003cbr/\u003eVideo and audio files are divided into segments at different resolutions and durations using MPEG-DASH-compliant codecs and formats.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eOn the client side, a DASH-compliant video player reads the MPD file and continuously monitors network bandwidth. Based on available bandwidth, the player selects the appropriate bitrate and requests the corresponding video chunk. This process repeats throughout playback, ensuring smooth, optimal quality.\u003c/p\u003e\u003cp\u003eNow that you understand the fundamentals, let’s build our adaptive video player!\u003c/p\u003e\u003ch2 id=\"steps-to-build-an-adaptive-bitrate-streaming-video-player\"\u003eSteps To Build an Adaptive Bitrate Streaming Video Player\u003c/h2\u003e\u003cp\u003eHere’s the plan:\u003c/p\u003e\u003col\u003e\u003cli\u003eTranscode the MP4 video into audio and video renditions at different resolutions and bitrates with FFmpeg.\u003c/li\u003e\u003cli\u003eGenerate an MPD file with FFmpeg.\u003c/li\u003e\u003cli\u003eServe the output files from the server.\u003c/li\u003e\u003cli\u003eBuild the DASH-compatible video player to play the video.\u003c/li\u003e\u003c/ol\u003e\u003ch3 id=\"install-ffmpeg\"\u003eInstall FFmpeg\u003c/h3\u003e\u003cp\u003eFor macOS users, install FFmpeg using Brew by running the following command in your terminal:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003ebrew install ffmpeg\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eFor other operating systems, please \u003ca href=\"https://www.ffmpeg.org/download.html\"\u003erefer to FFmpeg’s documentation\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"generate-audio-rendition\"\u003eGenerate Audio Rendition\u003c/h3\u003e\u003cp\u003eNext, run the following script to extract the audio track and encode it in WebM format for DASH compatibility:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode\u003effmpeg -i \u0026#34;input_video.mp4\u0026#34; -vn -acodec libvorbis -ab 128k \u0026#34;audio.webm\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003e-i \u0026#34;input_video.mp4\u0026#34;\u003c/code\u003e: Specifies the input video file.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-vn\u003c/code\u003e: Disables the video stream (audio-only output).\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-acodec libvorbis\u003c/code\u003e: Uses the \u003ca href=\"https://ffmpeg.org/ffmpeg-codecs.html#libvorbis\"\u003e\u003cstrong\u003elibvorbis\u003c/strong\u003e\u003c/a\u003e codec to encode audio.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-ab 128k\u003c/code\u003e: Sets the audio bitrate to \u003cstrong\u003e128 kbps\u003c/strong\u003e.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e\u0026#34;audio.webm\u0026#34;\u003c/code\u003e: Specifies the output audio file in WebM format.\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"generate-video-renditions\"\u003eGenerate Video Renditions\u003c/h3\u003e\u003cp\u003eRun this script to create three video renditions with varying resolutions and bitrates. The largest resolution should match the input file size. For example, if the input video is \u003cstrong\u003e576×1024\u003c/strong\u003e at 30 frames per second (fps), the script generates renditions optimized for vertical video playback.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode\u003effmpeg -i \u0026#34;input_video.mp4\u0026#34; -c:v libvpx-vp9 -keyint_min 150 -g 150 \\\n-tile-columns 4 -frame-parallel 1 -f webm \\\n-an -vf scale=576:1024 -b:v 1500k \u0026#34;input_video_576x1024_1500k.webm\u0026#34; \\\n-an -vf scale=480:854 -b:v 1000k \u0026#34;input_video_480x854_1000k.webm\u0026#34; \\\n-an -vf scale=360:640 -b:v 750k \u0026#34;input_video_360x640_750k.webm\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003e-c:v libvpx-vp9\u003c/code\u003e: Uses the \u003ca href=\"https://trac.ffmpeg.org/wiki/Encode/VP9\"\u003e\u003cstrong\u003elibvpx-vp9\u003c/strong\u003e\u003c/a\u003e as the VP9 video encoder for WebM.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-keyint_min 150\u003c/code\u003e and \u003ccode\u003e-g 150\u003c/code\u003e: Set a \u003cstrong\u003e150-frame keyframe interval\u003c/strong\u003e (approximately every 5 seconds at 30 fps). This allows bitrate switching every 5 seconds.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-tile-columns 4\u003c/code\u003e and \u003ccode\u003e-frame-parallel 1\u003c/code\u003e: Optimize encoding performance through parallel processing.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-f webm\u003c/code\u003e: Specifies the output format as WebM.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn each rendition:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003e-an\u003c/code\u003e: Excludes audio (video-only output).\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-vf scale=576:1024\u003c/code\u003e: Scales the video to a resolution of \u003cstrong\u003e576x1024\u003c/strong\u003e pixels.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-b:v 1500k\u003c/code\u003e: Sets the video bitrate to \u003cstrong\u003e1500 kbps\u003c/strong\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWebM is chosen as the output format, as they are smaller in size and optimized yet widely compatible with most web browsers.\u003c/p\u003e\u003ch3 id=\"generate-mpd-manifest-file\"\u003eGenerate MPD Manifest File\u003c/h3\u003e\u003cp\u003eCombine the video renditions and audio track into a DASH-compliant MPD manifest file by running the following script:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode\u003effmpeg \\\n  -f webm_dash_manifest -i \u0026#34;input_video_576x1024_1500k.webm\u0026#34; \\\n  -f webm_dash_manifest -i \u0026#34;input_video_480x854_1000k.webm\u0026#34; \\\n  -f webm_dash_manifest -i \u0026#34;input_video_360x640_750k.webm\u0026#34; \\\n  -f webm_dash_manifest -i \u0026#34;audio.webm\u0026#34; \\\n  -c copy \\\n  -map 0 -map 1 -map 2 -map 3 \\\n  -f webm_dash_manifest \\\n  -adaptation_sets \u0026#34;id=0,streams=0,1,2 id=1,streams=3\u0026#34; \\\n  \u0026#34;input_video_manifest.mpd\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003e-f webm_dash_manifest -i \u0026#34;…\u0026#34;\u003c/code\u003e: Specifies the inputs so that the ASH video player will switch between them dynamically based on network conditions.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-map 0 -map 1 -map 2 -map 3\u003c/code\u003e: Includes all video (0, 1, 2) and audio (3) in the final manifest.\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-adaptation_sets\u003c/code\u003e: Groups streams into adaptation sets:\u003cul\u003e\u003cli\u003e\u003ccode\u003eid=0,streams=0,1,2\u003c/code\u003e: Groups the video renditions into a single adaptation set.\u003c/li\u003e\u003cli\u003e\u003ccode\u003eid=1,streams=3\u003c/code\u003e: Assigns the audio track to a separate adaptation set.\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe resulting MPD file (\u003ccode\u003einput_video_manifest.mpd\u003c/code\u003e) describes the streams and enables adaptive bitrate streaming in MPEG-DASH.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode\u003e\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\n\u0026lt;MPD\n  xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\n  xmlns=\u0026#34;urn:mpeg:DASH:schema:MPD:2011\u0026#34;\n  xsi:schemaLocation=\u0026#34;urn:mpeg:DASH:schema:MPD:2011\u0026#34;\n  type=\u0026#34;static\u0026#34;\n  mediaPresentationDuration=\u0026#34;PT81.166S\u0026#34;\n  minBufferTime=\u0026#34;PT1S\u0026#34;\n  profiles=\u0026#34;urn:mpeg:dash:profile:webm-on-demand:2012\u0026#34;\u0026gt;\n\n  \u0026lt;Period id=\u0026#34;0\u0026#34; start=\u0026#34;PT0S\u0026#34; duration=\u0026#34;PT81.166S\u0026#34;\u0026gt;\n    \u0026lt;AdaptationSet\n      id=\u0026#34;0\u0026#34;\n      mimeType=\u0026#34;video/webm\u0026#34;\n      codecs=\u0026#34;vp9\u0026#34;\n      lang=\u0026#34;eng\u0026#34;\n      bitstreamSwitching=\u0026#34;true\u0026#34;\n      subsegmentAlignment=\u0026#34;false\u0026#34;\n      subsegmentStartsWithSAP=\u0026#34;1\u0026#34;\u0026gt;\n      \n      \u0026lt;Representation id=\u0026#34;0\u0026#34; bandwidth=\u0026#34;1647920\u0026#34; width=\u0026#34;576\u0026#34; height=\u0026#34;1024\u0026#34;\u0026gt;\n        \u0026lt;BaseURL\u0026gt;input_video_576x1024_1500k.webm\u0026lt;/BaseURL\u0026gt;\n        \u0026lt;SegmentBase indexRange=\u0026#34;16931581-16931910\u0026#34;\u0026gt;\n          \u0026lt;Initialization range=\u0026#34;0-645\u0026#34; /\u0026gt;\n        \u0026lt;/SegmentBase\u0026gt;\n      \u0026lt;/Representation\u0026gt;\n      \n      \u0026lt;Representation id=\u0026#34;1\u0026#34; bandwidth=\u0026#34;1126977\u0026#34; width=\u0026#34;480\u0026#34; height=\u0026#34;854\u0026#34;\u0026gt;\n        \u0026lt;BaseURL\u0026gt;input_video_480x854_1000k.webm\u0026lt;/BaseURL\u0026gt;\n        \u0026lt;SegmentBase indexRange=\u0026#34;11583599-11583986\u0026#34;\u0026gt;\n          \u0026lt;Initialization range=\u0026#34;0-645\u0026#34; /\u0026gt;\n        \u0026lt;/SegmentBase\u0026gt;\n      \u0026lt;/Representation\u0026gt;\n      \n      \u0026lt;Representation id=\u0026#34;2\u0026#34; bandwidth=\u0026#34;843267\u0026#34; width=\u0026#34;360\u0026#34; height=\u0026#34;640\u0026#34;\u0026gt;\n        \u0026lt;BaseURL\u0026gt;input_video_360x640_750k.webm\u0026lt;/BaseURL\u0026gt;\n        \u0026lt;SegmentBase indexRange=\u0026#34;8668326-8668713\u0026#34;\u0026gt;\n          \u0026lt;Initialization range=\u0026#34;0-645\u0026#34; /\u0026gt;\n        \u0026lt;/SegmentBase\u0026gt;\n      \u0026lt;/Representation\u0026gt;\n      \n    \u0026lt;/AdaptationSet\u0026gt;\n    \n    \u0026lt;AdaptationSet\n      id=\u0026#34;1\u0026#34;\n      mimeType=\u0026#34;audio/webm\u0026#34;\n      codecs=\u0026#34;vorbis\u0026#34;\n      lang=\u0026#34;eng\u0026#34;\n      audioSamplingRate=\u0026#34;44100\u0026#34;\n      bitstreamSwitching=\u0026#34;true\u0026#34;\n      subsegmentAlignment=\u0026#34;true\u0026#34;\n      subsegmentStartsWithSAP=\u0026#34;1\u0026#34;\u0026gt;\n      \n      \u0026lt;Representation id=\u0026#34;3\u0026#34; bandwidth=\u0026#34;89219\u0026#34;\u0026gt;\n        \u0026lt;BaseURL\u0026gt;audio.webm\u0026lt;/BaseURL\u0026gt;\n        \u0026lt;SegmentBase indexRange=\u0026#34;921727-922055\u0026#34;\u0026gt;\n          \u0026lt;Initialization range=\u0026#34;0-4889\u0026#34; /\u0026gt;\n        \u0026lt;/SegmentBase\u0026gt;\n      \u0026lt;/Representation\u0026gt;\n      \n    \u0026lt;/AdaptationSet\u0026gt;\n  \u0026lt;/Period\u0026gt;\n\u0026lt;/MPD\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAfter completing these steps, you’ll have:\u003c/p\u003e\u003col\u003e\u003cli\u003eThree video renditions (\u003ccode\u003e576x1024\u003c/code\u003e, \u003ccode\u003e480x854\u003c/code\u003e, \u003ccode\u003e360x640\u003c/code\u003e),\u003c/li\u003e\u003cli\u003eOne audio track, and\u003c/li\u003e\u003cli\u003eAn MPD manifest file.\u003c/li\u003e\u003c/ol\u003e\u003cpre\u003e\u003ccode\u003einput_video.mp4\naudio.webm\ninput_video_576x1024_1500k.webm\ninput_video_480x854_1000k.webm\ninput_video_360x640_750k.webm\ninput_video_manifest.mpd\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe original video \u003ccode\u003einput_video.mp4\u003c/code\u003e should also be kept to serve as a fallback video source later.\u003c/p\u003e\u003ch3 id=\"serve-the-output-files\"\u003eServe The Output Files\u003c/h3\u003e\u003cp\u003eThese output files can now be uploaded to cloud storage (e.g., AWS S3 or Cloudflare R2) for playback. While they can be served directly from a local folder, I highly recommend storing them in cloud storage and leveraging a CDN to cache the assets for better performance. Both AWS and Cloudflare support HTTP range requests out of the box.\u003c/p\u003e\u003ch3 id=\"building-the-dash-compatible-video-player-in-react\"\u003eBuilding The DASH-Compatible Video Player In React\u003c/h3\u003e\u003cp\u003eThere’s nothing like a real-world example to help understand how everything works. There are different ways we can implement a DASH-compatible video player, but I’ll focus on an approach using React.\u003c/p\u003e\u003cp\u003eFirst, install the \u003ca href=\"https://github.com/Dash-Industry-Forum/dash.js\"\u003eDash.js\u003c/a\u003e npm package by running:\u003c/p\u003e\u003cpre\u003e\u003ccode\u003enpm i dashjs\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNext, create a component called \u003ccode\u003e\u0026lt;DashVideoPlayer /\u0026gt;\u003c/code\u003e and initialize the Dash \u003ca href=\"https://cdn.dashjs.org/latest/jsdoc/module-MediaPlayer.html\"\u003eMediaPlayer\u003c/a\u003e instance by pointing it to the MPD file when the component mounts.\u003c/p\u003e\u003cp\u003eThe ref callback function runs upon the component mounting, and within the callback function, \u003ccode\u003eplayerRef\u003c/code\u003e will refer to the actual Dash \u003ca href=\"https://cdn.dashjs.org/latest/jsdoc/module-MediaPlayer.html\"\u003eMediaPlayer\u003c/a\u003e instance and be bound with event listeners. We also include the original MP4 URL in the \u003ccode\u003e\u0026lt;source\u0026gt;\u003c/code\u003e element as a fallback if the browser doesn’t support MPEG-DASH.\u003c/p\u003e\u003cp\u003eIf you’re using \u003cstrong\u003eNext.js app router\u003c/strong\u003e, remember to add the \u003ccode\u003e‘use client’\u003c/code\u003e directive to enable client-side hydration, as the video player is only initialized on the client side.\u003c/p\u003e\u003cp\u003eHere is the full example:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode\u003eimport dashjs from \u0026#39;dashjs\u0026#39;\nimport { useCallback, useRef } from \u0026#39;react\u0026#39;\n\nexport const DashVideoPlayer = () =\u0026gt; {\n  const playerRef = useRef()\n\n  const callbackRef = useCallback((node) =\u0026gt; {\n    if (node !== null) {  \n      playerRef.current = dashjs.MediaPlayer().create()\n\n      playerRef.current.initialize(node, \u0026#34;https://example.com/uri/to/input_video_manifest.mpd\u0026#34;, false)\n  \n      playerRef.current.on(\u0026#39;canPlay\u0026#39;, () =\u0026gt; {\n        // upon video is playable\n      })\n  \n      playerRef.current.on(\u0026#39;error\u0026#39;, (e) =\u0026gt; {\n        // handle error\n      })\n  \n      playerRef.current.on(\u0026#39;playbackStarted\u0026#39;, () =\u0026gt; {\n        // handle playback started\n      })\n  \n      playerRef.current.on(\u0026#39;playbackPaused\u0026#39;, () =\u0026gt; {\n        // handle playback paused\n      })\n  \n      playerRef.current.on(\u0026#39;playbackWaiting\u0026#39;, () =\u0026gt; {\n        // handle playback buffering\n      })\n    }\n  },[])\n\n  return (\n    \u0026lt;video ref={callbackRef} width={310} height={548} controls\u0026gt;\n      \u0026lt;source src=\u0026#34;https://example.com/uri/to/input_video.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34; /\u0026gt;\n      Your browser does not support the video tag.\n    \u0026lt;/video\u0026gt;\n  )\n}\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"result\"\u003eResult\u003c/h3\u003e\u003cp\u003eObserve the changes in the video file when the network connectivity is adjusted from Fast 4G to 3G using Chrome DevTools. It switches from 480p to 360p, showing how the experience is optimized for more or less available bandwidth.\u003c/p\u003e\u003cfigure\u003e\u003cfigcaption\u003eABR example\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\u003cp\u003eThat’s it! We just implemented a working DASH-compatible video player in React to establish a video with adaptive bitrate streaming. Again, the benefits of this are rooted in \u003cstrong\u003eperformance\u003c/strong\u003e. When we adopt ABR streaming, we’re requesting the video in smaller chunks, allowing for more immediate playback than we’d get if we needed to fully download the video file first. And we’ve done it in a way that supports multiple versions of the same video, allowing us to serve the best format for the user’s device.\u003c/p\u003e\u003ch3 id=\"references\"\u003eReferences\u003c/h3\u003e\u003cul\u003e\u003cli\u003e“\u003ca href=\"https://www.zeng.dev/post/2023-http-range-and-play-mp4-in-browser/\"\u003eHttp Range Request And MP4 Video Play In Browser\u003c/a\u003e,” Zeng Xu\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/Media/Audio_and_video_delivery/Setting_up_adaptive_streaming_media_sources\"\u003eSetting up adaptive streaming media sources\u003c/a\u003e (Mozilla Developer Network)\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/Media/DASH_Adaptive_Streaming_for_HTML_5_Video\"\u003eDASH Adaptive Streaming for HTML video\u003c/a\u003e (Mozilla Developer Network)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cimg src=\"https://www.smashingmagazine.com/images/logo/logo--red.png\" alt=\"Smashing Editorial\" width=\"35\" height=\"46\" loading=\"lazy\" decoding=\"async\"/\u003e\n\u003cspan\u003e(gg, yk)\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": "2025-03-27T13:00:00Z",
  "modifiedTime": "2025-03-27T13:00:00Z"
}
