{
  "id": "828df6a3-a822-46a5-a3de-bc56fbb50fd7",
  "title": "A Research Agenda for Generative AI in UX",
  "link": "https://www.nngroup.com/articles/genai-ux-research-agenda/?utm_source=rss\u0026utm_medium=feed\u0026utm_campaign=rss-syndication",
  "description": "To navigate this period of change, researchers must explore how generative AI changes what we study and how we study it.",
  "author": "Raluca Budiu",
  "published": "Fri, 20 Jun 2025 17:00:00 +0000",
  "source": "https://www.nngroup.com/feed/rss/",
  "categories": [
    "Article"
  ],
  "byline": "Raluca Budiu",
  "length": 13399,
  "excerpt": "To navigate this period of change, researchers must explore how generative AI changes what we study and how we study it.",
  "siteName": "Nielsen Norman Group",
  "favicon": "",
  "text": "Summary:  To navigate this period of change, researchers must explore how generative AI changes what we study and how we study it. Generative AI (genAI) is changing how we work, and UX research (UXR) is no exception. So far, most of the spotlight has been on content creation, but genAI has significant potential to reshape how we plan studies, understand users, and evaluate designs. This article lays out a roadmap for exploring that potential, by outlining four major research areas. Four Major Research Areas for GenAI in UXR 1. Researching Interfaces for GenAI 2. Studying New Types of UIs   3. Supporting Current UX-Research Practices and Methods 4. Replacing Current Practices with New Methods and Types of Data AI = Research on the Cheap? Who Should Answer These Questions Conclusion: Building the Research Agenda Four Major Research Areas for GenAI in UXR As an industry, we are facing a flood of critical new research questions introduced by AI. UX researchers must explore the open questions around how genAI changes what we study and how we study it. I suggest that the following four areas surface the big questions we need to ask as this technology takes hold in the UX field: What we study (interfaces and interactions) Researching interfaces for GenAI systems and tools Researching new types of UIs How we evaluate interfaces (process and methods): Supporting current UX practices and methods Replacing current practices with new methods for interface evaluation A Note on GenAI in Design Although this article focuses on UX research, many of the points raised also apply to design work. GenAI is already beginning to influence design tools and workflows, and the questions we're asking about research — like how AI supports or replaces current practices — are just as relevant to design. As new tools emerge, they may lead to new UX processes altogether. These changes, too, will benefit from research and exploration. 1. Researching Interfaces for GenAI Perhaps the most obvious area of research is building usable interfaces for genAI systems. As with any interactive tool, user adoption depends on ease of use. Fortunately, this domain is familiar ground for UX professionals, as many genAI systems currently employ standard UI elements and patterns (e.g., chatbot) that can be studied with standard UX methods. We can apply our existing knowledge of UX to improve the user experience of genAI. Still, there are many research questions that need clear answers. Key Research Questions How do interface features for genAI systems influence user trust in AI? How might interaction design mitigate the risks of overreliance on genAI or AI underutilization? What design patterns best support transparency and explainability in AI systems? 2. Studying New Types of UIs   It is possible that, in the future, that concept of user interface may morph into something else. For example, we may be able to design generative UIs that adapt on the fly to each user’s specific needs and characteristics. Or, we may need to design interfaces that cater to both humans and to agents that act on humans’ behalf. Key Research Questions What kinds of user data should be used to decide what the interface would look like for a particular user? How should we evaluate systems that change over time? What new UX patterns will emerge in agent-based environments? 3. Supporting Current UX-Research Practices and Methods A third area of investigation involves using genAI to enhance the efficiency and effectiveness of existing UX methods. It’s simply about taking any current UX activity and asking the question: Can we do it more efficiently with genAI? And if so, how? The focus here is not on how genAI changes UX research but on how it can help researchers do their jobs better. Common tasks that can be augmented by genAI include: Secondary (desk) research Brainstorming and ideation Writing various study plans and deliverables Facilitating research studies Doing a design review Extracting themes from qualitative data Analyzing quantitative data Creating graphs and visualizations This is also (mostly) an easy area of research. These applications are relatively low-risk and involve experimentation with AI. Researchers can compare genAI-assisted outputs with traditional ones to understand where and when AI adds value or introduces errors. Key Research Questions What are the limitations of genAI-generated content? When is human review essential? What kinds of errors are likely to be made by AI? And how does AI involvement influence the quality of UX work and how does AI output compare with that produced by humans? Does AI use lead to biased results and, if so, what kinds of biases should we look for? In some situations, evaluating and building on the genAI output will be easier than in others — for example, genAI may produce study-plan drafts that are imperfect but improvable, saving time even if editing is required. In others, such as with AI-moderated sessions, new concerns arise. Do followup questions generated by AI introduce bias? How do the insights from AI-led studies compare to those derived from human-moderated or unmoderated studies? 4. Replacing Current Practices with New Methods and Types of Data Ultimately, the goal of UX research is to support the creation of better products. It does so by evaluating interfaces against user needs and goals. GenAI has the potential to develop new methods for evaluating user interfaces. In particular, there are two avenues already emerging: Simulation of human behavior through synthetic users and digital twins Automated UI analysis against existing best practices Simulation of Human Behavior Historically, the field of human-computer interaction has relied on cognitive models to explain and predict user behavior. Cognitive models like GOMS (Goals, Operators, Methods, Selection rules) and cognitive architectures (like ACT-R) are grounded in cognitive psychology and simulate the steps a user goes through when interacting with an interface. Traditional cognitive models typically require an expert to carefully model the task and the user’s knowledge by hand, after which they can produce quantitative predictions (like how long a task will take, how many errors might occur, or how users’ learning curve might look). However, cognitive models are time-consuming and complex to build. Each new task or interface might need a new model. Cognitive models also tend to abstract the task and the environment, often simplifying real-world constraints and ignoring contextual distractions or other unpredictable user behaviors (such as boredom or stress). In the era of AI, however, the strength of cognitive modeling (predicting human behavior) is being revisited in two new forms: synthetic users and digital twins. These types of genAI-powered constructs do not claim to replicate internal human processes, but they do aim to predict human outputs —- whether verbal or behavioral. Synthetic Users Synthetic users are AI-generated profiles that attempt to mimic a user group.  A synthetic user does not represent a specific real individual — it is an amalgam simulation of many users’ behaviors and characteristics, tuned to represent a particular target demographic or user segment (almost like an interactive persona). While, as of now, synthetic users are not agentic (meaning that they do not aim to replicate human actions such as navigating the web or interacting with an interface), they do attempt to replicate the verbal output of humans in that group. If synthetic users gained agentic capabilities, they could hypothetically be utilized to “test” interfaces. For example, a synthetic user that could mimic how a person interacts with an interface may be used to test that interface and identify at least a subset of the usability issues associated with it. Digital Twins Unlike a synthetic user, which is a generic representation of a user group, a digital twin is a virtual replica of a real user. It is built by collecting extensive data from that specific user (e.g., responses to questionnaires, sequences of actions that the user has performed on a website) and using that data to predict that user's future behavior. For example, with a digital twin, one could carry out longitudinal studies that look at behaviors and attitudes over time without having the person come back to the lab. Or, researchers could use the digital twin to predict how that particular person would react to a new product or product feature. Or, they could ask them sensitive questions that they may not be able to ask in real life. Key Research Questions How accurately can synthetic users or digital twins represent human users? What are the biases in these systems, and how can they be detected or mitigated? How can we responsibly collect and use data to build digital twins, while protecting user privacy and ensuring ethical practices? What types of data are appropriate to gather, and how can we safeguard the data to maintain user trust? What types of UX research goals are well-suited for AI-generated participants? How can we help stakeholders and teammates understand the differences between data from AI-generated participants and research with human customers? Automated UI Analysis Another emerging application of genAI is in automated interface evaluations, such as AI-generated heuristic reviews. Traditionally, heuristic evaluations require expert reviewers to examine an interface against a set of usability heuristics. With genAI, these evaluations could be automated. For example, an AI system could be prompted to identify potential usability issues in a user interface using a list of principles such as the ten usability heuristics or another extensive list of guidelines. Research is needed to benchmark the accuracy and utility of AI-led evaluations. Key Research Questions What domains are they suited for? Would general-purpose tools that evaluate any product perform as well as domain-specific tools that focus on a single domain? What percentage of actual usability issues do these tools detect? How do the detected issues compare with those identified by human experts? How severe are the issues detected with these tools? Do they miss critical issues? Do they surface false positives? How can their outputs be refined or guided with better prompting or data? AI = Research on the Cheap? One of the most promising aspects of genAI for UX is its potential to reduce costs. Traditional UX research often requires significant time and resources — from participant recruitment and compensation to running studies to data collection and analysis. GenAI-driven approaches may be more viable for small teams, startups, or resource-constrained organizations that may not have the budget to conduct iterative research throughout a product's lifecycle. In many cases, the comparison will not be between genAI and traditional research but between genAI and no research at all. But, for us to be able to use genAI-augmented research practices as first steps or replacements for research with real users, we need to understand: What we can expect from them How the outcomes compare with those of traditional methods What risks or dangers are introduced when involving genAI in the research process How to interpret the results Even if the cost of evaluating an interface with AI may be low, poor results will lead to incorrect design decisions and high long-term costs. That is why it is imperative for the UX field to actively research these questions and create clear guidelines for using AI. Who Should Answer These Questions These are important questions that everyone in UX should consider as we start using AI tools in our work. That said, most organizations won’t have the resources to investigate these big-picture issues in depth. While valuable insights may come from teams in lower-UX-maturity organizations experimenting with genAI, the bulk of this foundational research is likely to come from academic institutions, leading UX organizations like NNGroup, and companies with advanced UX maturity that actively shape the direction of the field. If you’re not part of one of those organizations but are using genAI in your work, it’s especially important to stay informed. Take time to learn what’s already known about your specific use case and understand both the benefits and risks. At NNGroup, we’re already working on addressing some of these questions. We’re committed to helping the field develop solid foundations and best practices for the use of  genAI in UX. We’ll also be publishing regular updates to share findings from both academia and industry in the four key research areas outlined here. Conclusion: Building the Research Agenda The UX profession is in the midst of a major transformation. GenAI is a new paradigm for interacting with data, users, and design problems. This proposed research program outlines several promising directions, from enhancing existing methods to developing entirely new ones. To ensure that this transformation benefits both users and professionals, we must approach genAI with rigor, curiosity, and a commitment to ethics and equity. The future of UX in the genAI era will be shaped not just by what is possible, but by what we choose to investigate.",
  "image": "https://media.nngroup.com/media/articles/opengraph_images/Research-Agenda_Opengraph-30.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cp\u003e\u003cspan\u003e\n                  Summary: \n                \u003c/span\u003eTo navigate this period of change, researchers must explore how generative AI changes what we study and how we study it.\n              \u003c/p\u003e\u003cdiv\u003e\n              \u003cp\u003eGenerative AI (genAI) is changing how we work, and UX research (UXR) is no exception. So far, most of the spotlight has been on content creation, but genAI has significant potential to reshape how we plan studies, understand users, and evaluate designs. This article lays out a roadmap for exploring that potential, by outlining four major research areas.\u003c/p\u003e\n\u003cdiv\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-four-major-research-areas-for-genai-in-uxr-1\"\u003eFour Major Research Areas for GenAI in UXR\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-1-researching-interfaces-for-genai-2\"\u003e1. Researching Interfaces for GenAI\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-2-studying-new-types-of-uis-3\"\u003e2. Studying New Types of UIs  \u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-3-supporting-current-ux-research-practices-and-methods-4\"\u003e3. Supporting Current UX-Research Practices and Methods\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-4-replacing-current-practices-with-new-methods-and-types-of-data-5\"\u003e4. Replacing Current Practices with New Methods and Types of Data\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-ai-research-on-the-cheap-6\"\u003eAI = Research on the Cheap?\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-who-should-answer-these-questions-7\"\u003eWho Should Answer These Questions\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#toc-conclusion-building-the-research-agenda-8\"\u003eConclusion: Building the Research Agenda\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e\u003ch2 id=\"toc-four-major-research-areas-for-genai-in-uxr-1\"\u003eFour Major Research Areas for GenAI in UXR\u003c/h2\u003e\n\u003cp\u003eAs an industry, we are facing a flood of critical new research questions introduced by AI. UX researchers must explore the open questions around \u003cstrong\u003ehow genAI changes\u003cem\u003e what \u003c/em\u003ewe study and \u003cem\u003ehow \u003c/em\u003ewe study it.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eI suggest that the following four areas surface the big questions we need to ask as this technology takes hold in the UX field:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003cem\u003eWhat\u003c/em\u003e we study\u003c/strong\u003e (interfaces and interactions)\n\n\t\u003col\u003e\n\u003cli\u003eResearching interfaces for GenAI systems and tools\u003c/li\u003e\n\u003cli\u003eResearching new types of UIs\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003cem\u003eHow\u003c/em\u003e we evaluate interfaces\u003c/strong\u003e (process and methods):\n\t\u003col start=\"3\"\u003e\n\u003cli\u003eSupporting current UX practices and methods\u003c/li\u003e\n\u003cli\u003eReplacing current practices with new methods for interface evaluation\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eA Note on GenAI in Design\u003c/h3\u003e\n\u003cp\u003eAlthough \u003cstrong\u003ethis article focuses on UX research\u003c/strong\u003e, many of the points raised also apply to design work. \u003ca href=\"https://www.nngroup.com/articles/ai-design-tools-update-2/\"\u003eGenAI is already beginning to influence design tools and workflows\u003c/a\u003e, and the questions we\u0026#39;re asking about research — like how AI supports or replaces current practices — are just as relevant to design. As new tools emerge, they may lead to new UX processes altogether. These changes, too, will benefit from research and exploration.\u003c/p\u003e\n\u003ch2 id=\"toc-1-researching-interfaces-for-genai-2\"\u003e1. Researching Interfaces for GenAI\u003c/h2\u003e\n\u003cp\u003ePerhaps the most obvious area of research is building usable interfaces for genAI systems. As with any interactive tool, user adoption depends on ease of use. Fortunately, this domain is familiar ground for UX professionals, as many genAI systems currently employ standard UI elements and patterns (e.g., chatbot) that can be studied with standard UX methods. We can apply our existing knowledge of UX to improve the user experience of genAI.\u003c/p\u003e\n\u003cp\u003eStill, there are many research questions that need clear answers.\u003c/p\u003e\n\u003ch3\u003eKey Research Questions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHow do interface features for genAI systems influence user trust in AI?\u003c/li\u003e\n\u003cli\u003eHow might interaction design mitigate the risks of overreliance on genAI or AI underutilization?\u003c/li\u003e\n\u003cli\u003eWhat design patterns best support transparency and explainability in AI systems?\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"toc-2-studying-new-types-of-uis-3\"\u003e2. Studying New Types of UIs  \u003c/h2\u003e\n\u003cp\u003eIt is possible that, in the future, that concept of user interface may morph into something else. For example, we may be able to design \u003ca href=\"https://www.nngroup.com/articles/generative-ui/\"\u003egenerative UIs\u003c/a\u003e that adapt on the fly to each user’s specific needs and characteristics. Or, we may need to design interfaces that cater to both humans and to agents that act on humans’ behalf.\u003c/p\u003e\n\u003ch3\u003eKey Research Questions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhat kinds of user data should be used to decide what the interface would look like for a particular user?\u003c/li\u003e\n\u003cli\u003eHow should we evaluate systems that change over time?\u003c/li\u003e\n\u003cli\u003eWhat new UX patterns will emerge in agent-based environments?\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"toc-3-supporting-current-ux-research-practices-and-methods-4\"\u003e3. Supporting Current UX-Research Practices and Methods\u003c/h2\u003e\n\u003cp\u003eA third area of investigation involves using genAI to enhance the efficiency and effectiveness of existing UX methods. It’s simply about taking any current UX activity and asking the question: \u003cstrong\u003eCan we do it more efficiently with genAI?\u003c/strong\u003e And if so, how?\u003c/p\u003e\n\u003cp\u003eThe focus here is not on how genAI changes UX research but on how it can help researchers do their jobs better.\u003c/p\u003e\n\u003cp\u003eCommon tasks that can be augmented by genAI include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSecondary (desk) research\u003c/li\u003e\n\u003cli\u003eBrainstorming and ideation\u003c/li\u003e\n\u003cli\u003eWriting various study plans and deliverables\u003c/li\u003e\n\u003cli\u003eFacilitating research studies\u003c/li\u003e\n\u003cli\u003eDoing a design review\u003c/li\u003e\n\u003cli\u003eExtracting themes from qualitative data\u003c/li\u003e\n\u003cli\u003eAnalyzing quantitative data\u003c/li\u003e\n\u003cli\u003eCreating graphs and visualizations\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis is also (mostly) an easy area of research. These applications are relatively low-risk and involve experimentation with AI. Researchers can compare genAI-assisted outputs with traditional ones to understand where and when AI adds value or introduces errors.\u003c/p\u003e\n\u003ch3\u003eKey Research Questions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhat are the limitations of genAI-generated content?\u003c/li\u003e\n\u003cli\u003eWhen is human review essential?\u003c/li\u003e\n\u003cli\u003eWhat kinds of errors are likely to be made by AI?\u003c/li\u003e\n\u003cli\u003eAnd how does AI involvement influence the quality of UX work and how does AI output compare with that produced by humans?\u003c/li\u003e\n\u003cli\u003eDoes AI use lead to biased results and, if so, what kinds of biases should we look for?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn some situations, evaluating and building on the genAI output will be easier than in others — for example, genAI may produce study-plan drafts that are imperfect but improvable, saving time even if editing is required.\u003c/p\u003e\n\u003cp\u003eIn others, such as with AI-moderated sessions, new concerns arise. Do followup questions generated by AI introduce bias? How do the insights from AI-led studies compare to those derived from human-moderated or unmoderated studies?\u003c/p\u003e\n\u003ch2 id=\"toc-4-replacing-current-practices-with-new-methods-and-types-of-data-5\"\u003e4. Replacing Current Practices with New Methods and Types of Data\u003c/h2\u003e\n\u003cp\u003eUltimately, \u003cstrong\u003e\u003ca href=\"https://www.nngroup.com/articles/ux-job-with-ai/\"\u003ethe goal of UX research is to support the creation of better products\u003c/a\u003e\u003c/strong\u003e. It does so by evaluating interfaces against user needs and goals. GenAI has the potential to develop new methods for evaluating user interfaces.\u003c/p\u003e\n\u003cp\u003eIn particular, there are two avenues already emerging:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSimulation of human behavior \u003c/strong\u003ethrough synthetic users and digital twins\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAutomated UI analysis \u003c/strong\u003eagainst existing best practices\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eSimulation of Human Behavior\u003c/h3\u003e\n\u003cp\u003eHistorically, the field of human-computer interaction has relied on cognitive models to explain and predict user behavior. Cognitive models like \u003ca href=\"https://en.wikipedia.org/wiki/GOMS\"\u003eGOMS\u003c/a\u003e (Goals, Operators, Methods, Selection rules) and cognitive architectures (like \u003ca href=\"https://en.wikipedia.org/wiki/ACT-R\"\u003eACT-R\u003c/a\u003e) are grounded in cognitive psychology and simulate the steps a user goes through when interacting with an interface.\u003c/p\u003e\n\u003cp\u003eTraditional cognitive models typically require an expert to carefully model the task and the user’s knowledge by hand, after which they can produce quantitative predictions (like how long a task will take, how many errors might occur, or how users’ \u003ca href=\"https://www.nngroup.com/articles/measure-learnability/\"\u003elearning curve\u003c/a\u003e might look).\u003c/p\u003e\n\u003cp\u003eHowever, cognitive models are time-consuming and complex to build. Each new task or interface might need a new model. Cognitive models also tend to abstract the task and the environment, often simplifying real-world constraints and ignoring contextual distractions or other unpredictable user behaviors (such as boredom or stress).\u003c/p\u003e\n\u003cp\u003eIn the era of AI, however, the strength of cognitive modeling (predicting human behavior) is being revisited in two new forms: \u003cstrong\u003esynthetic users \u003c/strong\u003eand\u003cstrong\u003e digital twins.\u003c/strong\u003e These types of genAI-powered constructs do not claim to replicate internal human processes, but they do aim to predict human outputs —- whether verbal or behavioral.\u003c/p\u003e\n\u003ch4\u003eSynthetic Users\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://www.nngroup.com/articles/synthetic-users/\"\u003eSynthetic users \u003c/a\u003eare AI-generated profiles that attempt to mimic a user group.  A \u003cstrong\u003esynthetic user\u003c/strong\u003e does \u003cem\u003enot\u003c/em\u003e\u003cstrong\u003e \u003c/strong\u003erepresent a specific real individual — it is an amalgam simulation of many users’ behaviors and characteristics, tuned to represent a particular target demographic or user segment (almost like an interactive persona).\u003c/p\u003e\n\u003cp\u003eWhile, as of now, synthetic users are not agentic (meaning that they do not aim to replicate human actions such as navigating the web or interacting with an interface), they do attempt to replicate the verbal output of humans in that group.\u003c/p\u003e\n\u003cp\u003eIf synthetic users gained agentic capabilities, they could hypothetically be utilized to “test” interfaces. For example, a synthetic user that could mimic how a person interacts with an interface may be used to test that interface and identify at least a subset of the usability issues associated with it.\u003c/p\u003e\n\u003ch4\u003eDigital Twins\u003c/h4\u003e\n\u003cp\u003eUnlike a synthetic user, which is a generic representation of a user group, a \u003cstrong\u003edigital twin\u003c/strong\u003e is a virtual replica of a real user. It is built by collecting extensive data from that specific user (e.g., responses to questionnaires, sequences of actions that the user has performed on a website) and using that data to predict that user\u0026#39;s future behavior.\u003c/p\u003e\n\u003cp\u003eFor example, with a digital twin, one could carry out longitudinal studies that look at behaviors and attitudes over time without having the person come back to the lab. Or, researchers could use the digital twin to predict how that particular person would react to a new product or product feature. Or, they could ask them sensitive questions that they may not be able to ask in real life.\u003c/p\u003e\n\u003ch3\u003eKey Research Questions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHow accurately can synthetic users or digital twins represent human users?\u003c/li\u003e\n\u003cli\u003eWhat are the biases in these systems, and how can they be detected or mitigated?\u003c/li\u003e\n\u003cli\u003eHow can we responsibly collect and use data to build digital twins, while protecting user privacy and ensuring ethical practices? What types of data are appropriate to gather, and how can we safeguard the data to maintain user trust?\u003c/li\u003e\n\u003cli\u003eWhat types of UX research goals are well-suited for AI-generated participants?\u003c/li\u003e\n\u003cli\u003eHow can we help stakeholders and teammates understand the differences between data from AI-generated participants and research with human customers?\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eAutomated UI Analysis\u003c/h3\u003e\n\u003cp\u003eAnother emerging application of genAI is in automated interface evaluations, such as AI-generated heuristic reviews. Traditionally, \u003ca href=\"https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/\"\u003eheuristic evaluations\u003c/a\u003e require expert reviewers to examine an interface against a set of usability heuristics. With genAI, these evaluations could be automated. For example, an AI system could be prompted to identify potential usability issues in a user interface using a list of principles such as \u003ca href=\"https://www.nngroup.com/articles/ten-usability-heuristics/\"\u003ethe ten usability heuristics\u003c/a\u003e or another extensive list of guidelines.\u003c/p\u003e\n\u003cp\u003eResearch is needed to benchmark the accuracy and utility of AI-led evaluations.\u003c/p\u003e\n\u003ch3\u003eKey Research Questions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhat domains are they suited for?\n\t\u003cul\u003e\n\u003cli\u003eWould general-purpose tools that evaluate any product perform as well as domain-specific tools that focus on a single domain?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhat percentage of actual usability issues do these tools detect?\n\t\u003cul\u003e\n\u003cli\u003eHow do the detected issues compare with those identified by human experts?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eHow severe are the issues detected with these tools?\n\t\u003cul\u003e\n\u003cli\u003eDo they miss critical issues?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDo they surface false positives?\u003c/li\u003e\n\u003cli\u003eHow can their outputs be refined or guided with better prompting or data?\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"toc-ai-research-on-the-cheap-6\"\u003eAI = Research on the Cheap?\u003c/h2\u003e\n\u003cp\u003eOne of the most promising aspects of genAI for UX is its potential to reduce costs.\u003c/p\u003e\n\u003cp\u003eTraditional UX research often requires significant time and resources — from participant recruitment and compensation to running studies to data collection and analysis. GenAI-driven approaches may be more viable for small teams, startups, or resource-constrained organizations that may not have the budget to conduct iterative research throughout a product\u0026#39;s lifecycle.\u003c/p\u003e\n\u003cp\u003eIn many cases, the comparison will not be between genAI and traditional research but between genAI and no research at all. But, for us to be able to use genAI-augmented research practices as first steps or replacements for research with real users, we need to understand:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat we can expect from them\u003c/li\u003e\n\u003cli\u003eHow the outcomes compare with those of traditional methods\u003c/li\u003e\n\u003cli\u003eWhat risks or dangers are introduced when involving genAI in the research process\u003c/li\u003e\n\u003cli\u003eHow to interpret the results\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEven if the cost of evaluating an interface with AI may be low, \u003cstrong\u003epoor results will lead to incorrect design decisions and high long-term costs.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThat is why it is imperative for the UX field to actively research these questions and create clear guidelines for using AI.\u003c/p\u003e\n\u003ch2 id=\"toc-who-should-answer-these-questions-7\"\u003eWho Should Answer These Questions\u003c/h2\u003e\n\u003cp\u003eThese are important questions that everyone in UX should consider as we start using AI tools in our work.\u003c/p\u003e\n\u003cp\u003eThat said, most organizations won’t have the resources to investigate these big-picture issues in depth. While valuable insights may come from teams in lower-\u003ca href=\"https://www.nngroup.com/articles/ux-maturity-model/\"\u003eUX-maturity\u003c/a\u003e organizations experimenting with genAI, \u003cstrong\u003ethe bulk of this foundational research is likely to come from academic institutions, leading UX organizations like NNGroup, and companies with advanced UX maturity\u003c/strong\u003e that actively shape the direction of the field.\u003c/p\u003e\n\u003cp\u003eIf you’re not part of one of those organizations but are using genAI in your work, it’s especially important to stay informed. Take time to learn what’s already known about your specific use case and understand both the benefits and risks.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAt NNGroup, we’re already working on addressing some of these questions.\u003c/strong\u003e We’re committed to helping the field develop solid \u003ca href=\"https://www.nngroup.com/topic/ai/\"\u003efoundations and best practices for the use of  genAI in UX.\u003c/a\u003e We’ll also be publishing regular updates to share findings from both academia and industry in the four key research areas outlined here.\u003c/p\u003e\n\u003ch2 id=\"toc-conclusion-building-the-research-agenda-8\"\u003eConclusion: Building the Research Agenda\u003c/h2\u003e\n\u003cp\u003eThe UX profession is in the midst of a major transformation. GenAI is a new paradigm for interacting with data, users, and design problems. This proposed research program outlines several promising directions, from enhancing existing methods to developing entirely new ones.\u003c/p\u003e\n\u003cp\u003eTo ensure that this transformation benefits both users and professionals, we must approach genAI with rigor, curiosity, and a commitment to ethics and equity. The future of UX in the genAI era will be shaped not just by what is possible, but by what we choose to investigate.\u003c/p\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "15 min read",
  "publishedTime": "2025-06-20T17:00:00Z",
  "modifiedTime": null
}
