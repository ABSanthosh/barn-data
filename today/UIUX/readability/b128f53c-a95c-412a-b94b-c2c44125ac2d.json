{
  "id": "b128f53c-a95c-412a-b94b-c2c44125ac2d",
  "title": "Interview With Björn Ottosson, Creator Of The Oklab Color Space",
  "link": "https://smashingmagazine.com/2024/10/interview-bjorn-ottosson-creator-oklab-color-space/",
  "description": "Go behind the scenes with Björn Ottosson, the Swedish engineer who created Oklab color space, and discover how he developed a simple yet effective model with good hue uniformity while also handling lightness and saturation well — and is “okay” to use.",
  "author": "Philip Jägenstedt",
  "published": "Wed, 02 Oct 2024 10:00:00 GMT",
  "source": "https://www.smashingmagazine.com/feed",
  "categories": null,
  "byline": "About The Author",
  "length": 11291,
  "excerpt": "Go behind the scenes with Björn Ottosson, the Swedish engineer who created Oklab color space, and discover how he developed a simple yet effective model with good hue uniformity while also handling lightness and saturation well — and is “okay” to use.",
  "siteName": "Smashing Magazine",
  "favicon": "https://smashingmagazine.com/images/favicon/apple-touch-icon.png",
  "text": "10 min readColors, Interviews, DesignGo behind the scenes with Björn Ottosson, the Swedish engineer who created Oklab color space, and discover how he developed a simple yet effective model with good hue uniformity while also handling lightness and saturation well — and is “okay” to use.Oklab is a new perceptual color space supported in all major browsers created by the Swedish engineer Björn Ottosson. In this interview, Philip Jägenstedt explores how and why Björn created Oklab and how it spread across the ecosystem.Note: The original interview was conducted in Swedish and is available to watch.About BjörnPhilip Jägenstedt: Tell me a little about yourself, Björn.Björn Ottosson: I worked for many years in the game industry on game engines and games like FIFA, Battlefield, and Need for Speed. I’ve always been interested in technology and its interaction with the arts. I’m an engineer, but I’ve always held both of these interests.On Working With ColorPhilip: For someone who hasn’t dug into colors much, what’s so hard about working with them?Björn: Intuitively, colors can seem quite simple. A color can be lighter or darker, it can be more blue or more green, and so on. Everyone with typical color vision has a fairly similar experience of color, and this can be modeled.However, the way we manipulate colors in software usually doesn’t align with human perception of colors. The most common color space is sRGB. There’s also HSL, which is common for choosing colors, but it’s also based on sRGB.One problem with sRGB is that in a gradient between blue and white, it becomes a bit purple in the middle of the transition. That’s because sRGB really isn’t created to mimic how the eye sees colors; rather, it is based on how CRT monitors work. That means it works with certain frequencies of red, green, and blue, and also the non-linear coding called gamma. It’s a miracle it works as well as it does, but it’s not connected to color perception. When using those tools, you sometimes get surprising results, like purple in the gradient.Image source: How software gets color wrong. (Large preview)On Color PerceptionPhilip: How do humans perceive color?Björn: When light enters the eye and hits the retina, it’s processed in many layers of neurons and creates a mental impression. It’s unlikely that the process would be simple and linear, and it’s not. But incredibly enough, most people still perceive colors similarly.People have been trying to understand colors and have created color wheels and similar visualizations for hundreds of years. During the 20th century, a lot of research and modeling went into color vision. For example, the CIE XYZ model is based on how sensitive our photoreceptor cells are to different frequencies of light. CIE XYZ is still a foundational color space on which all other color spaces are based.There were also attempts to create simple models matching human perception based on XYZ, but as it turned out, it’s not possible to model all color vision that way. Perception of color is incredibly complex and depends, among other things, on whether it is dark or light in the room and the background color it is against. When you look at a photograph, it also depends on what you think the color of the light source is. The dress is a typical example of color vision being very context-dependent. It is almost impossible to model this perfectly.Models that try to take all of this complexity into account are called color appearance models. Although they have many applications, they’re not that useful if you don’t know if the viewer is in a light or bright room or other viewing conditions.The odd thing is that there’s a gap between the tools we typically use — such as sRGB and HSL — and the findings of this much older research. To an extent, this makes sense because when HSL was developed in the 1970s, we didn’t have much computing power, so it’s a fairly simple translation of RGB. However, not much has changed since then.We have a lot more processing power now, but we’ve settled for fairly simple tools for handling colors in software.Display technology has also improved. Many displays now have different RGB primaries, i.e., a redder red, greener green, or bluer blue. sRGB cannot reach all colors available on these displays. The new P3 color space can, but it’s very similar to sRGB, just a little wider.On Creating OklabPhilip: What, then, is Oklab, and how did you create it?Björn: When working in the game industry, sometimes I wanted to do simple color manipulations like making a color darker or changing the hue. I researched existing color spaces and how good they are at these simple tasks and concluded that all of them are problematic in some way.Many people know about CIE Lab. It’s quite close to human perception of color, but the handling of hue is not great. For example, a gradient between blue and white turns out purple in CIE Lab, similar to in sRGB. Some color spaces handle hue well but have other issues to consider.When I left my job in gaming to pursue education and consulting, I had a bit of time to tackle this problem. Oklab is my attempt to find a better balance, something Lab-like but “okay”.I based Oklab on two other color spaces, CIECAM16 and IPT. I used the lightness and saturation prediction from CIECAM16, which is a color appearance model, as a target. I actually wanted to use the datasets used to create CIECAM16, but I couldn’t find them.IPT was designed to have better hue uniformity. In experiments, they asked people to match light and dark colors, saturated and unsaturated colors, which resulted in a dataset for which colors, subjectively, have the same hue. IPT has a few other issues but is the basis for hue in Oklab.Using these three datasets, I set out to create a simple color space that would be “okay”. I used an approach quite similar to IPT but combined it with the lightness and saturation estimates from CIECAM16. The resulting Oklab still has good hue uniformity but also handles lightness and saturation well.Philip: How about the name Oklab? Why is it just okay?Björn: This is a bit tongue-in-cheek and some amount of humility.For the tasks I had in mind, existing color spaces weren’t okay, and my goal was to make one that is. At the same time, it is possible to delve deeper. If a university had worked on this, they could have run studies with many participants. For a color space intended mainly for use on computer and phone screens, you could run studies in typical environments where they are used. It’s possible to go deeper.Nevertheless, I took the datasets I could find and made the best of what I had. The objective was to make a very simple model that’s okay to use. And I think it is okay, and I couldn’t come up with anything better. I didn’t want to call it Björn Ottosson Lab or something like that, so I went with Oklab.Philip: Does the name follow a tradition of calling things okay? I know there’s also a Quite OK Image format.Björn: No, I didn’t follow any tradition here. Oklab was just the name I came up with.On Oklab AdoptionPhilip: I discovered Oklab when it suddenly appeared in all browsers. Things often move slowly on the web, but in this case, things moved very quickly. How did it happen?Björn: I was surprised, too! I wrote a blog post and shared it on Twitter.I have a lot of contacts in the gaming industry and some contacts in the Visual Effects (VFX) industry. I expected that people working with shaders or visual effects might try this out, and maybe it would be used in some games, perhaps as an effect for a smooth color transition.But the blog post was spread much more widely than I thought. It was on Hacker News, and many people read it.The code for Oklab is only 10 lines long, so many open-source libraries have adopted it. This all happened very quickly.Chris Lilley from the W3C got in touch and asked me some questions about Oklab. We discussed it a bit, and I explained how it works and why I created it. He gave a presentation at a conference about it, and then he pushed for it to be added to CSS.Photoshop also changed its gradients to use Oklab. All of this happened organically without me having to cheer it on.On OkhslPhilip: In another blog post, you introduced two other color spaces, Okhsv and Okhsl. You’ve already talked about HSL, so what is Okhsl?Björn: When picking colors, HSL has a big advantage, which is that the parameter space is simple. Any value 0-360 for hue (H) together with any values 0-1 for saturation (S) and lightness (L) are valid combinations and result in different colors on screen. The geometry of HSL is a cylinder, and there’s no way to end up outside that cylinder accidentally.Image source: Wikipedia. (Large preview)By contrast, Oklab contains all physically possible colors, but there are combinations of values that don’t work where you reach colors that don’t exist. For example, starting from light and saturated yellow in Oklab and rotating the hue to blue, that blue color does not exist in sRGB; there are only darker and less saturated blues. That’s because sRGB in Oklab has a strange shape, so it’s easy to end up going outside it. This makes it difficult to select and manipulate colors with Oklab or Oklch.sRGB shape in Oklab. (Image source: Chris Cameron demo) (Large preview)Okhsl was an attempt at compromise. It maintains Oklab’s behavior for colors that are not very saturated, close to gray, and beyond that, stretches out to a cylinder that contains all of sRGB. Another way to put it is that the strange shape of sRGB in Oklab has been stretched into a cylinder with reasonably smooth transitions.The result is similar to HSL, where all parameters can be changed independently without ending up outside sRGB. It also makes Okhsl more complicated than Oklab. There are unavoidable compromises to get something with the characteristics that HSL has.Everything with color is about compromises. Color vision is so complex that it's about making practical compromises.This is an area where I wish there were more research. If I have a white background and want to pick some nice colors to put on it, then you can make a lot of assumptions. Okhsl solves many things, but is it possible to do even better?On Color CompromisesPhilip: Some people who have tried Oklab say there are too many dark shades. You changed that in Okhsl with a new lightness estimate.Björn: This is because Oklab is exposure invariant and doesn’t account for viewing conditions, such as the background color. On the web, there’s usually a white background, which makes it harder to see the difference between black and other dark colors. But if you look at the same gradient on a black background, the difference is more apparent.CIE Lab handles this, and I tried to handle it in Okhsl, too. So, gradients in Okhsl look better on a white background, but there will be other issues on a black background. It’s always a compromise.And, Finally…Philip: Final question: What’s your favorite color?Björn: I would have to say Burgundy. Burgundy, dark greens, and navy blues are favorites.Philip: Thank you for your time, Björn. I hope our readers have learned something, and I’ll remind them of your excellent blog, where you go into more depth about Oklab and Okhsl.Björn: Thank you! (gg, yk)",
  "image": "https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/interview-bjorn-ottosson-creator-oklab-color-space.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article__content\"\u003e\u003cul\u003e\u003cli\u003e10 min read\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://smashingmagazine.com/category/colors\"\u003eColors\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/interviews\"\u003eInterviews\u003c/a\u003e,\n\u003ca href=\"https://smashingmagazine.com/category/design\"\u003eDesign\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003csection aria-label=\"Quick summary\"\u003eGo behind the scenes with Björn Ottosson, the Swedish engineer who created Oklab color space, and discover how he developed a simple yet effective model with good hue uniformity while also handling lightness and saturation well — and is “okay” to use.\u003c/section\u003e\u003c/p\u003e\u003cp\u003eOklab is a new perceptual color space supported in all major browsers created by the Swedish engineer Björn Ottosson. In this interview, Philip Jägenstedt explores how and why Björn created Oklab and how it spread across the ecosystem.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: \u003cem\u003eThe original interview was conducted in Swedish and is \u003ca href=\"https://www.youtube.com/watch?v=1LuF9eOXeBY\"\u003eavailable to watch\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\u003ch2 id=\"about-björn\"\u003eAbout Björn\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip Jägenstedt:\u003c/span\u003e Tell me a little about yourself, Björn.\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://files.smashing.media/authors/bjorn-ottosson.jpg\" width=\"200\" height=\"200\" alt=\"Photo of Björn Ottosson\"/\u003e\u003cspan\u003eBjörn Ottosson:\u003c/span\u003e I worked for many years in the game industry on game engines and games like FIFA, Battlefield, and Need for Speed. I’ve always been interested in technology and its interaction with the arts. I’m an engineer, but I’ve always held both of these interests.\u003c/p\u003e\u003ch2 id=\"on-working-with-color\"\u003eOn Working With Color\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e For someone who hasn’t dug into colors much, what’s so hard about working with them?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e Intuitively, colors can seem quite simple. A color can be lighter or darker, it can be more blue or more green, and so on. Everyone with typical color vision has a fairly similar experience of color, and this can be modeled.\u003c/p\u003e\u003cp\u003eHowever, the way we manipulate colors in software usually doesn’t align with human perception of colors. The most common color space is sRGB. There’s also HSL, which is common for choosing colors, but it’s also based on sRGB.\u003c/p\u003e\u003cp\u003eOne problem with sRGB is that in a gradient between blue and white, it becomes a bit purple in the middle of the transition. That’s because sRGB really isn’t created to mimic how the eye sees colors; rather, it is based on how \u003ca href=\"https://en.wikipedia.org/wiki/Cathode-ray_tube\"\u003eCRT monitors\u003c/a\u003e work. That means it works with certain frequencies of red, green, and blue, and also the \u003ca href=\"https://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/\"\u003enon-linear coding called gamma\u003c/a\u003e. It’s a miracle it works as well as it does, but it’s not connected to color perception. When using those tools, you sometimes get surprising results, like purple in the gradient.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"76\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png\" sizes=\"100vw\" alt=\"Purple in the gradient\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eImage source: \u003ca href=\"https://bottosson.github.io/posts/colorwrong/\"\u003eHow software gets color wrong\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/1-purple-in-gradient.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003ch2 id=\"on-color-perception\"\u003eOn Color Perception\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e How do humans perceive color?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e When light enters the eye and hits the retina, it’s processed in many layers of neurons and creates a mental impression. It’s unlikely that the process would be simple and linear, and it’s not. But incredibly enough, most people still perceive colors similarly.\u003c/p\u003e\u003cp\u003ePeople have been trying to understand colors and have created color wheels and similar visualizations for hundreds of years. During the 20th century, a lot of research and modeling went into color vision. For example, the \u003ca href=\"https://en.wikipedia.org/wiki/CIE_1931_color_space\"\u003eCIE XYZ\u003c/a\u003e model is based on how sensitive our photoreceptor cells are to different frequencies of light. CIE XYZ is still a foundational color space on which all other color spaces are based.\u003c/p\u003e\u003cp\u003eThere were also attempts to create simple models matching human perception based on XYZ, but as it turned out, it’s not possible to model all color vision that way. Perception of color is incredibly complex and depends, among other things, on whether it is dark or light in the room and the background color it is against. When you look at a photograph, it also depends on what you think the color of the light source is. \u003ca href=\"https://en.wikipedia.org/wiki/The_dress\"\u003eThe dress\u003c/a\u003e is a typical example of color vision being very context-dependent. It is almost impossible to model this perfectly.\u003c/p\u003e\u003cp\u003eModels that try to take all of this complexity into account are called \u003cstrong\u003ecolor appearance models\u003c/strong\u003e. Although they have many applications, they’re not that useful if you don’t know if the viewer is in a light or bright room or other viewing conditions.\u003c/p\u003e\u003cp\u003eThe odd thing is that there’s a gap between the tools we typically use — such as sRGB and HSL — and the findings of this much older research. To an extent, this makes sense because when HSL was developed in the 1970s, we didn’t have much computing power, so it’s a fairly simple translation of RGB. However, not much has changed since then.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003ca aria-label=\"Share on Twitter\" href=\"https://twitter.com/share?text=%0aWe%20have%20a%20lot%20more%20processing%20power%20now,%20but%20we%e2%80%99ve%20settled%20for%20fairly%20simple%20tools%20for%20handling%20colors%20in%20software.%0a\u0026amp;url=https://smashingmagazine.com%2f2024%2f10%2finterview-bjorn-ottosson-creator-oklab-color-space%2f\"\u003eWe have a lot more processing power now, but we’ve settled for fairly simple tools for handling colors in software.\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eDisplay technology has also improved. Many displays now have different RGB primaries, i.e., a redder red, greener green, or bluer blue. sRGB cannot reach all colors available on these displays. The new P3 color space can, but it’s very similar to sRGB, just a little wider.\u003c/p\u003e\u003ch2 id=\"on-creating-oklab\"\u003eOn Creating Oklab\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e What, then, is Oklab, and how did you create it?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e When working in the game industry, sometimes I wanted to do simple color manipulations like making a color darker or changing the hue. I researched existing color spaces and how good they are at these simple tasks and concluded that all of them are problematic in some way.\u003c/p\u003e\u003cp\u003eMany people know about \u003ca href=\"https://en.wikipedia.org/wiki/CIELAB_color_space\"\u003eCIE Lab\u003c/a\u003e. It’s quite close to human perception of color, but the handling of hue is not great. For example, a gradient between blue and white turns out purple in CIE Lab, similar to in sRGB. Some color spaces handle hue well but have other issues to consider.\u003c/p\u003e\u003cp\u003eWhen I left my job in gaming to pursue education and consulting, I had a bit of time to tackle this problem. Oklab is my attempt to find a better balance, something Lab-like but “okay”.\u003c/p\u003e\u003cp\u003eI based Oklab on two other color spaces, \u003ca href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/col.22131\"\u003eCIECAM16\u003c/a\u003e and \u003ca href=\"https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/cic/6/1/art00003\"\u003eIPT\u003c/a\u003e. I used the lightness and saturation prediction from CIECAM16, which is a color appearance model, as a target. I actually wanted to use the datasets used to create CIECAM16, but I couldn’t find them.\u003c/p\u003e\u003cp\u003eIPT was designed to have better hue uniformity. In experiments, they asked people to match light and dark colors, saturated and unsaturated colors, which resulted in a dataset for which colors, subjectively, have the same hue. IPT has a few other issues but is the basis for hue in Oklab.\u003c/p\u003e\u003cp\u003eUsing these three datasets, I set out to create a simple color space that would be “okay”. I used an approach quite similar to IPT but combined it with the lightness and saturation estimates from CIECAM16. The resulting Oklab still has good hue uniformity but also handles lightness and saturation well.\u003c/p\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e How about the name Oklab? Why is it just okay?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e This is a bit tongue-in-cheek and some amount of humility.\u003c/p\u003e\u003cp\u003eFor the tasks I had in mind, existing color spaces weren’t okay, and my goal was to make one that is. At the same time, it is possible to delve deeper. If a university had worked on this, they could have run studies with many participants. For a color space intended mainly for use on computer and phone screens, you could run studies in typical environments where they are used. It’s possible to go deeper.\u003c/p\u003e\u003cp\u003eNevertheless, I took the datasets I could find and made the best of what I had. The objective was to make a very simple model that’s okay to use. And I think it is okay, and I couldn’t come up with anything better. I didn’t want to call it Björn Ottosson Lab or something like that, so I went with Oklab.\u003c/p\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e Does the name follow a tradition of calling things okay? I know there’s also a \u003ca href=\"https://qoiformat.org/\"\u003eQuite OK Image\u003c/a\u003e format.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e No, I didn’t follow any tradition here. Oklab was just the name I came up with.\u003c/p\u003e\u003ch2 id=\"on-oklab-adoption\"\u003eOn Oklab Adoption\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e I discovered Oklab when it suddenly appeared in all browsers. Things often move slowly on the web, but in this case, things moved very quickly. How did it happen?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e I was surprised, too! I wrote \u003ca href=\"https://bottosson.github.io/posts/oklab/\"\u003ea blog post\u003c/a\u003e and shared it on Twitter.\u003c/p\u003e\u003cp\u003eI have a lot of contacts in the gaming industry and some contacts in the Visual Effects (VFX) industry. I expected that people working with shaders or visual effects might try this out, and maybe it would be used in some games, perhaps as an effect for a smooth color transition.\u003c/p\u003e\u003cp\u003eBut the blog post was spread much more widely than I thought. It was on Hacker News, and many people read it.\u003c/p\u003e\u003cp\u003eThe code for Oklab is only 10 lines long, so many open-source libraries have adopted it. This all happened very quickly.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://svgees.us\"\u003eChris Lilley\u003c/a\u003e from the W3C got in touch and asked me some questions about Oklab. We discussed it a bit, and I explained how it works and why I created it. He gave a \u003ca href=\"https://www.w3.org/Graphics/Color/Workshop/slides/talk/lilley\"\u003epresentation\u003c/a\u003e at a conference about it, and then he pushed for it to be added to CSS.\u003c/p\u003e\u003cp\u003ePhotoshop also changed its gradients to use Oklab. All of this happened organically without me having to cheer it on.\u003c/p\u003e\u003ch2 id=\"on-okhsl\"\u003eOn Okhsl\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e In \u003ca href=\"https://bottosson.github.io/posts/colorpicker/\"\u003eanother blog post\u003c/a\u003e, you introduced two other color spaces, Okhsv and Okhsl. You’ve already talked about HSL, so what is Okhsl?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e When picking colors, HSL has a big advantage, which is that the parameter space is simple. Any value 0-360 for hue (H) together with any values 0-1 for saturation (S) and lightness (L) are valid combinations and result in different colors on screen. The geometry of HSL is a cylinder, and there’s no way to end up outside that cylinder accidentally.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"349\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png\" sizes=\"100vw\" alt=\"Color solid cylinder\"/\u003e\u003c/a\u003e\u003cfigcaption\u003eImage source: \u003ca href=\"https://en.wikipedia.org/wiki/HSL_and_HSV\"\u003eWikipedia\u003c/a\u003e. (\u003ca href=\"https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/2-color-solid-cylinder.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eBy contrast, \u003ca href=\"https://en.wikipedia.org/wiki/Oklab_color_space\"\u003eOklab\u003c/a\u003e contains all physically possible colors, but there are combinations of values that don’t work where you reach colors that don’t exist. For example, starting from light and saturated yellow in Oklab and rotating the hue to blue, that blue color does not exist in sRGB; there are only darker and less saturated blues. That’s because sRGB in Oklab has a strange shape, so it’s easy to end up going outside it. This makes it difficult to select and manipulate colors with Oklab or Oklch.\u003c/p\u003e\u003cfigure\u003e\u003ca href=\"https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png\"\u003e\u003cimg loading=\"lazy\" decoding=\"async\" fetchpriority=\"low\" width=\"800\" height=\"641\" srcset=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png 400w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_800/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png 800w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1200/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png 1200w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_1600/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png 1600w,\nhttps://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_2000/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png 2000w\" src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png\" sizes=\"100vw\" alt=\"sRGB shape in Oklab.\"/\u003e\u003c/a\u003e\u003cfigcaption\u003esRGB shape in Oklab. (Image source: \u003ca href=\"https://ccameron-chromium.github.io/webgl-examples/gamut.html\"\u003eChris Cameron demo\u003c/a\u003e) (\u003ca href=\"https://files.smashing.media/articles/interview-bjorn-ottosson-creator-oklab-color-space/3-srgb-shape-oklab.png\"\u003eLarge preview\u003c/a\u003e)\u003c/figcaption\u003e\u003c/figure\u003e\u003cp\u003eOkhsl was an attempt at compromise. It maintains Oklab’s behavior for colors that are not very saturated, close to gray, and beyond that, stretches out to a cylinder that contains all of sRGB. Another way to put it is that the strange shape of sRGB in Oklab has been stretched into a cylinder with reasonably smooth transitions.\u003c/p\u003e\u003cp\u003eThe result is similar to HSL, where all parameters can be changed independently without ending up outside sRGB. It also makes Okhsl more complicated than Oklab. There are unavoidable compromises to get something with the characteristics that HSL has.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003ca aria-label=\"Share on Twitter\" href=\"https://twitter.com/share?text=%0aEverything%20with%20color%20is%20about%20compromises.%20Color%20vision%20is%20so%20complex%20that%20it%27s%20about%20making%20practical%20compromises.%0a\u0026amp;url=https://smashingmagazine.com%2f2024%2f10%2finterview-bjorn-ottosson-creator-oklab-color-space%2f\"\u003eEverything with color is about compromises. Color vision is so complex that it\u0026#39;s about making practical compromises.\u003c/a\u003e\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eThis is an area where I wish there were more research. If I have a white background and want to pick some nice colors to put on it, then you can make a lot of assumptions. Okhsl solves many things, but is it possible to do even better?\u003c/p\u003e\u003ch2 id=\"on-color-compromises\"\u003eOn Color Compromises\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e Some people who have tried Oklab say there are too many dark shades. You changed that in Okhsl with a new lightness estimate.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e This is because Oklab is exposure invariant and doesn’t account for viewing conditions, such as the background color. On the web, there’s usually a white background, which makes it harder to see the difference between black and other dark colors. But if you look at the same gradient on a black background, the difference is more apparent.\u003c/p\u003e\u003cp\u003eCIE Lab handles this, and I tried to handle it in Okhsl, too. So, gradients in Okhsl look better on a white background, but there will be other issues on a black background. It’s always a compromise.\u003c/p\u003e\u003ch2 id=\"and-finally\"\u003eAnd, Finally…\u003c/h2\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e Final question: What’s your favorite color?\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e I would have to say Burgundy. Burgundy, dark greens, and navy blues are favorites.\u003c/p\u003e\u003cp\u003e\u003cspan\u003ePhilip:\u003c/span\u003e Thank you for your time, Björn. I hope our readers have learned something, and I’ll remind them of \u003ca href=\"https://bottosson.github.io/\"\u003eyour excellent blog\u003c/a\u003e, where you go into more depth about Oklab and Okhsl.\u003c/p\u003e\u003cp\u003e\u003cspan\u003eBjörn:\u003c/span\u003e Thank you!\u003c/p\u003e\u003cp\u003e\u003cimg src=\"https://www.smashingmagazine.com/images/logo/logo--red.png\" alt=\"Smashing Editorial\" width=\"35\" height=\"46\" loading=\"lazy\" decoding=\"async\"/\u003e\n\u003cspan\u003e(gg, yk)\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2024-10-02T10:00:00Z",
  "modifiedTime": "2024-10-02T10:00:00Z"
}
