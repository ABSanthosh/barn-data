{
  "id": "890718ba-1bbd-4ee3-8fdc-65556895c5e5",
  "title": "CodeSOD: Feeling Free",
  "link": "https://thedailywtf.com/articles/feeling-free",
  "description": "Jason started work on a C++ application doing quantitative work. The nature of the program involves allocating all sorts of blocks of memory, doing loads of complicated math, and then freeing them. Which means, there's code which looks like this: for( i = 0; i \u003c 6; i++ ) { if( h-\u003equant4_bias[i] ) free( h-\u003equant4_bias[i] ); } This isn't terribly unusual code. I have quibbles- why the magic number 6, I'd prefer the comparison against nullptr to be explicit- but this isn't the kind of code that's going to leave anybody scratching their head. If h-\u003equant4_bias[i] is pointing to actual memory, free it. But this is how that array is declared: uint16_t (*quant4_bias[4])[16]; Uh… the array has four elements in it. We free six elements. And shockingly, this doesn't crash. Why not? Well… it's because we get lucky. Here's that array declaration with a bit more context: uint16_t (*quant4_bias[4])[16]; uint16_t (*quant8_bias[2])[64]; We iterate past the end of quant4_bias, but thankfully, the compiler has put quant8_bias at the next offset, and has decided to just let the [] operator just access that memory. There's no guarantee about this- this is peak undefined behavior. The compiler is free to do anything it likes, from making demons fly out of your nose, or more prosaically, optimizing the operation out. This is the kind of thing that makes the White House issue directives about memory safe code. The absence of memory safety is a gateway to all sorts of WTFs. This one, here, is a pretty mild one, as memory bugs go. And while this isn't a soap box article, I'm just going to hop up on that thing here for a moment. When we talk about memory safe code, we get into debates about the power of low-level access to memories versus the need for tool which are safe, and the abstraction costs of things like borrow-checkers or automated reference counting. This is a design challenge for any tool. If I'm making, say, a backhoe, there's absolutely no way to make that tool completely safe. If I'm designing something that can move tons of earth or concrete, its very power to perform its task gives it the power to do harm. We address this through multiple factors. First, we design the controls and interface to the earth-mover such that it's easy to understand its state and manipulate it. The backhoe responds to user inputs in clear, predictable, ways. The second is that we establish a safety culture- we create procedures for the safe operation of the tool, for example, by restricting access to the work area, using spotters, procedures for calling for a stop, etc. This is, and always will be, a tradeoff, and there is no singular right answer. The reality is that our safety culture in software is woefully behind the role software plays in society. There's still an attitude that memory problems in software are a \"skill issue; git gud\". But that runs counter to a safety culture. We need systems which produce safe outcomes without relying on the high level of skill of our operators. Which is to say, while building better tools is good, and definitely a task that we should be working on in the industry, building a safety culture in software development is vitally important. Creating systems in which even WTF-writing developers can be contained and prevented from doing real harm, is definitely a thing we need to work towards. [Advertisement] BuildMaster allows you to create a self-service release management platform that allows different teams to manage their applications. Explore how!",
  "author": "Remy Porter",
  "published": "Tue, 01 Oct 2024 06:30:00 GMT",
  "source": "http://syndication.thedailywtf.com/TheDailyWtf",
  "categories": [
    "CodeSOD"
  ],
  "byline": "Remy Porter",
  "length": 3813,
  "excerpt": "Jason started work on a C++ application doing quantitative work. The nature of the program involves allocating all sorts of blocks of memory, doing loads of complicated math, and then freeing them. Which means, there's code which looks like this: for( i = 0; i \u003c 6; i++ ) { if( h-\u003equant4_bias[i] ) free( h-\u003equant4_bias[i] ); }",
  "siteName": "The Daily WTF",
  "favicon": "",
  "text": "by in CodeSOD on 2024-10-01 Edit Remy PorterComputers were a mistake, which is why I'm trying to shoot them into space. Editor-in-Chief for TDWTF. Jason started work on a C++ application doing quantitative work. The nature of the program involves allocating all sorts of blocks of memory, doing loads of complicated math, and then freeing them. Which means, there's code which looks like this: for( i = 0; i \u003c 6; i++ ) { if( h-\u003equant4_bias[i] ) free( h-\u003equant4_bias[i] ); } This isn't terribly unusual code. I have quibbles- why the magic number 6, I'd prefer the comparison against nullptr to be explicit- but this isn't the kind of code that's going to leave anybody scratching their head. If h-\u003equant4_bias[i] is pointing to actual memory, free it. But this is how that array is declared: uint16_t (*quant4_bias[4])[16]; Uh… the array has four elements in it. We free six elements. And shockingly, this doesn't crash. Why not? Well… it's because we get lucky. Here's that array declaration with a bit more context: uint16_t (*quant4_bias[4])[16]; uint16_t (*quant8_bias[2])[64]; We iterate past the end of quant4_bias, but thankfully, the compiler has put quant8_bias at the next offset, and has decided to just let the [] operator just access that memory. There's no guarantee about this- this is peak undefined behavior. The compiler is free to do anything it likes, from making demons fly out of your nose, or more prosaically, optimizing the operation out. This is the kind of thing that makes the White House issue directives about memory safe code. The absence of memory safety is a gateway to all sorts of WTFs. This one, here, is a pretty mild one, as memory bugs go. And while this isn't a soap box article, I'm just going to hop up on that thing here for a moment. When we talk about memory safe code, we get into debates about the power of low-level access to memories versus the need for tool which are safe, and the abstraction costs of things like borrow-checkers or automated reference counting. This is a design challenge for any tool. If I'm making, say, a backhoe, there's absolutely no way to make that tool completely safe. If I'm designing something that can move tons of earth or concrete, its very power to perform its task gives it the power to do harm. We address this through multiple factors. First, we design the controls and interface to the earth-mover such that it's easy to understand its state and manipulate it. The backhoe responds to user inputs in clear, predictable, ways. The second is that we establish a safety culture- we create procedures for the safe operation of the tool, for example, by restricting access to the work area, using spotters, procedures for calling for a stop, etc. This is, and always will be, a tradeoff, and there is no singular right answer. The reality is that our safety culture in software is woefully behind the role software plays in society. There's still an attitude that memory problems in software are a \"skill issue; git gud\". But that runs counter to a safety culture. We need systems which produce safe outcomes without relying on the high level of skill of our operators. Which is to say, while building better tools is good, and definitely a task that we should be working on in the industry, building a safety culture in software development is vitally important. Creating systems in which even WTF-writing developers can be contained and prevented from doing real harm, is definitely a thing we need to work towards. [Advertisement] BuildMaster allows you to create a self-service release management platform that allows different teams to manage their applications. Explore how!",
  "image": "https://s3.amazonaws.com/remy.jetpackshark.com/remy-thumb.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv itemscope=\"\" itemtype=\"http://schema.org/Article\" id=\"article-page\"\u003e\n\n        \n        \u003cp\u003e\u003cspan\u003eby \n            in \u003ca itemprop=\"articleSection\" href=\"https://thedailywtf.com/series/code-sod\"\u003eCodeSOD\u003c/a\u003e\n            on \u003cspan itemprop=\"datePublished\" content=\"2024-10-01\"\u003e2024-10-01\u003c/span\u003e\n            \u003ca href=\"https://thedailywtf.com/admin/article/edit/10749\" rel=\"nofollow\"\u003eEdit\u003c/a\u003e\n        \u003c/span\u003e\u003c/p\u003e\n        \u003cdiv itemprop=\"author\" itemscope=\"\" itemtype=\"http://schema.org/Person\"\u003e\n            \u003cp\u003e\u003cimg itemprop=\"image\" src=\"https://s3.amazonaws.com/remy.jetpackshark.com/remy-thumb.jpg\"/\u003e\n            \u003ca itemprop=\"name\" href=\"https://thedailywtf.com/authors/remy-porter\"\u003eRemy Porter\u003c/a\u003e\u003c/p\u003e\u003cp itemprop=\"description\"\u003eComputers were a mistake, which is why I\u0026#39;m trying to shoot them into space. Editor-in-Chief for TDWTF.\u003c/p\u003e\n        \u003c/div\u003e\n        \u003cdiv itemprop=\"articleBody\"\u003e\n            \u003cp\u003e\u003cstrong\u003eJason\u003c/strong\u003e started work on a C++ application doing quantitative work. The nature of the program involves allocating all sorts of blocks of memory, doing loads of complicated math, and then freeing them. Which means, there\u0026#39;s code which looks like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cspan\u003efor\u003c/span\u003e( i = \u003cspan\u003e0\u003c/span\u003e; i \u0026lt; \u003cspan\u003e6\u003c/span\u003e; i++ )\n{\n    \u003cspan\u003eif\u003c/span\u003e( h-\u0026gt;quant4_bias[i] )\n        \u003cspan\u003efree\u003c/span\u003e( h-\u0026gt;quant4_bias[i] );\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis isn\u0026#39;t terribly unusual code. I have quibbles- why the magic number \u003ccode\u003e6\u003c/code\u003e, I\u0026#39;d prefer the comparison against \u003ccode\u003enullptr\u003c/code\u003e to be explicit- but this isn\u0026#39;t the kind of code that\u0026#39;s going to leave anybody scratching their head.  If \u003ccode\u003eh-\u0026gt;quant4_bias[i]\u003c/code\u003e is pointing to actual memory, \u003ccode\u003efree\u003c/code\u003e it.\u003c/p\u003e\n\u003cp\u003eBut this is how that array is declared:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cspan\u003euint16_t\u003c/span\u003e        (*quant4_bias[\u003cspan\u003e4\u003c/span\u003e])[\u003cspan\u003e16\u003c/span\u003e];\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUh… the array has four elements in it. We \u003cem\u003efree\u003c/em\u003e six elements. And shockingly, this doesn\u0026#39;t crash. Why not? Well… it\u0026#39;s because we get lucky. Here\u0026#39;s that array declaration with a bit more context:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cspan\u003euint16_t\u003c/span\u003e        (*quant4_bias[\u003cspan\u003e4\u003c/span\u003e])[\u003cspan\u003e16\u003c/span\u003e];\n\u003cspan\u003euint16_t\u003c/span\u003e        (*quant8_bias[\u003cspan\u003e2\u003c/span\u003e])[\u003cspan\u003e64\u003c/span\u003e];\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe iterate \u003cem\u003epast\u003c/em\u003e the end of \u003ccode\u003equant4_bias\u003c/code\u003e, but thankfully, the compiler has put \u003ccode\u003equant8_bias\u003c/code\u003e at the next offset, \u003cem\u003eand\u003c/em\u003e has decided to just let the \u003ccode\u003e[]\u003c/code\u003e operator just access that memory. There\u0026#39;s no guarantee about this- this is peak undefined behavior. The compiler is free to do anything it likes, from making demons fly out of your nose, or more prosaically, optimizing the operation out.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eThis\u003c/em\u003e is the kind of thing that \u003ca href=\"https://www.tomshardware.com/software/security-software/white-house-urges-developers-to-avoid-c-and-c-use-memory-safe-programming-languages\"\u003emakes the White House issue directives about memory safe code\u003c/a\u003e. The absence of memory safety is a gateway to all sorts of WTFs. This one, here, is a pretty mild one, as memory bugs go.\u003c/p\u003e\n\u003cp\u003eAnd while this isn\u0026#39;t a soap box article, I\u0026#39;m just going to hop up on that thing here for a moment. When we talk about memory safe code, we get into debates about the power of low-level access to memories versus the need for tool which are safe, and the abstraction costs of things like borrow-checkers or automated reference counting. This is a design challenge for any tool. If I\u0026#39;m making, say, a backhoe, there\u0026#39;s absolutely no way to make that tool completely safe. If I\u0026#39;m designing something that can move tons of earth or concrete, its very power to perform its task gives it the power to do harm. We address this through multiple factors. First, we design the controls and interface to the earth-mover such that it\u0026#39;s easy to understand its state and manipulate it. The backhoe responds to user inputs in clear, predictable, ways. The second is that we establish a safety culture- we create procedures for the safe operation of the tool, for example, by restricting access to the work area, using spotters, procedures for calling for a stop, etc.\u003c/p\u003e\n\u003cp\u003eThis is, and always will be, a tradeoff, and there is no singular right answer. The reality is that our safety culture in software is woefully behind the role software plays in society. There\u0026#39;s still an attitude that memory problems in software are a \u0026#34;skill issue; git gud\u0026#34;. But that runs counter to a safety culture. We need systems which \u003cem\u003eproduce safe outcomes\u003c/em\u003e without relying on the high level of skill of our operators.\u003c/p\u003e\n\u003cp\u003eWhich is to say, while building \u003cem\u003ebetter tools\u003c/em\u003e is good, and definitely a task that we should be working on in the industry, building a safety culture in software development is vitally important. Creating systems in which \u003cem\u003eeven WTF-writing developers\u003c/em\u003e can be contained and prevented from doing real harm, is definitely a thing we need to work towards.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://thedailywtf.com/images/inedo/buildmaster-icon.png\"/\u003e [Advertisement] \n\t\u003ca href=\"https://inedo.com/BuildMaster?utm_source=tdwtf\u0026amp;utm_medium=footerad\u0026amp;utm_term=2018\u0026amp;utm_content=Self_Service\u0026amp;utm_campaign=Buildmaster_Footer\"\u003eBuildMaster\u003c/a\u003e allows you to create a self-service release management platform that allows different teams to manage their applications. \u003ca href=\"https://inedo.com/BuildMaster/download?utm_source=tdwtf\u0026amp;utm_medium=footerad\u0026amp;utm_term=2018\u0026amp;utm_content=Self_Service\u0026amp;utm_campaign=Buildmaster_Footer\"\u003eExplore how!\u003c/a\u003e \n\u003c/p\u003e\n\n\n        \u003c/div\u003e\n\n        \n    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2024-10-01T06:30:00Z",
  "modifiedTime": null
}
