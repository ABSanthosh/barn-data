{
  "id": "a95df56e-3c45-4403-b401-19712e44544a",
  "title": "Why This AI Gazes into Goat Faces",
  "link": "https://www.scientificamerican.com/article/why-this-ai-gazes-into-goat-faces/",
  "description": "AI-based systems can help identify livestock’s early signs of distress",
  "author": "",
  "published": "Fri, 07 Feb 2025 13:00:00 +0000",
  "source": "http://rss.sciam.com/ScientificAmerican-Global",
  "categories": null,
  "byline": "Lucy Tu",
  "length": 3421,
  "excerpt": "AI-based systems can help identify livestock’s early signs of distress",
  "siteName": "Scientific American",
  "favicon": "",
  "text": "February 7, 20252 min readAI-based systems can help identify livestock’s early signs of distress Nitin Prabhudesai/Getty ImagesThe patient grumbled and grimaced, but he refused to speak to his doctor.The patient was a goat.Recognizing animal pain is notoriously difficult. To do so, humans must rely on subtle body language or behavioral changes. But a new artificial-intelligence model automates this process by identifying pain in goats—using only their facial expressions. The model, described in Scientific Reports, achieved 80 percent accuracy and offers a promising avenue for automatically monitoring livestock health.On supporting science journalismIf you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.Traditionally, detecting animal pain involves analyzing photos or videos by hand for specific cues—a raised lip, a flared nostril—and creating pain scales tailored to individual species. But as humans, we both detect and interpret animals’ pain through a biased lens, says University of Florida veterinary anesthesi­ologist Ludovica ­Chiavaccini, the new study’s lead author. When detection is automated, “the computer just picks up the patterns.”Chiavaccini and her team videotaped 40 goats of various breeds and ages with different medical conditions at a veterinary hospital, generating more than 5,000 fixed frames. Using a behavioral pain scale, clinical history and physical exams, they classified each goat as in pain or not. The team tried three approaches, training an algorithm on different groupings of images while reserving others to test that training. The most balanced model, similarly adept at detecting pained and not-pained goats, was trained on four fifths of the frames, fine-tuned using the remaining fifth and tested on videos of two additional goats. Repeating this process five times with varying groupings yielded an average accuracy of 80 percent. Such training “essentially builds 30 years of clinical experience in 30 minutes,” Chiavaccini says.Similar AI tools exist for cats, which have better-established expression-based pain scales, but the only such pain scale for goats had been validated solely in young, healthy males undergoing castration. Chiavaccini was inspired by the lack of goat pain scales, in addition to a graduate student’s enthusiasm for the animals after presenting them at an agricultural show.AI-powered tools built with similar methods could someday help veterinarians make quicker and more accurate diagnoses or alert farmers to early stages of livestock distress. “This study shows the potential for broader adoption of AI in animal care and highlights the need for further exploration across diverse species,” says University of Glasgow computer scientist Marwa Mahmoud, who specializes in human and animal behavioral AI.Expression-based pain-assessment tools already exist for nonverbal human patients, but these systems’ effectiveness can be limited by poor image quality or suboptimal camera angles. “Many of the engineering problems we solved, like adapting to messy, real-world conditions, could be helpful to human medicine,” Chiavaccini says. “Doctors worry about perfect lighting or head alignment. Meanwhile I’m out here racing after a goat with my camera.”",
  "image": "https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003eFebruary 7, 2025\u003c/p\u003e\u003cp\u003e2 min read\u003c/p\u003e\u003c/div\u003e\u003cp\u003eAI-based systems can help identify livestock’s early signs of distress\u003c/p\u003e\u003cfigure\u003e\u003cimg src=\"https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026amp;w=600\" alt=\"Goat staring\" srcset=\"https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026amp;w=600 600w, https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026amp;w=900 900w, https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026amp;w=1000 1000w, https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026amp;w=1200 1200w, https://static.scientificamerican.com/dam/m/65caa3b4cecc7b94/original/sa0325Adva07.jpg?m=1738855967.359\u0026amp;w=1350 1350w\" sizes=\"(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw\" fetchpriority=\"high\"/\u003e\u003cfigcaption\u003e \u003cp\u003eNitin Prabhudesai/Getty Images\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe patient grumbled and grimaced, but he refused to speak to his doctor.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eThe patient was a goat.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eRecognizing animal pain is notoriously difficult. To do so, \u003ca href=\"https://www.scientificamerican.com/blog/observations/yes-we-can-communicate-with-animals/\"\u003ehumans must rely on\u003c/a\u003e subtle body language or behavioral changes. But a new artificial-intelligence model automates this process by identifying pain in goats—using only their facial expressions. The model, described \u003ca href=\"https://www.nature.com/articles/s41598-024-78494-0\"\u003ein \u003ci\u003eScientific Reports\u003c/i\u003e\u003c/a\u003e, achieved 80 percent accuracy and offers a promising avenue for automatically monitoring livestock health.\u003c/p\u003e\u003chr/\u003e\u003ch2\u003eOn supporting science journalism\u003c/h2\u003e\u003cp\u003eIf you\u0026#39;re enjoying this article, consider supporting our award-winning journalism by \u003ca href=\"https://www.scientificamerican.com/getsciam/\"\u003esubscribing\u003c/a\u003e. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.\u003c/p\u003e\u003chr/\u003e\u003cp data-block=\"sciam/paragraph\"\u003eTraditionally, detecting animal pain involves analyzing photos or videos by hand for specific cues—a raised lip, a flared nostril—and creating pain scales tailored to individual species. But as humans, we both detect and interpret animals’ pain through a biased lens, says University of Florida veterinary anesthesi­ologist Ludovica ­Chiavaccini, the new study’s lead author. When detection is automated, “the computer just picks up the patterns.”\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eChiavaccini and her team videotaped 40 goats of various breeds and ages with different medical conditions at a veterinary hospital, generating more than 5,000 fixed frames. Using a behavioral pain scale, clinical history and physical exams, they classified each goat as in pain or not. The team tried three approaches, training an algorithm on different groupings of images while reserving others to test that training. The most balanced model, similarly adept at detecting pained and not-pained goats, was trained on four fifths of the frames, fine-tuned using the remaining fifth and tested on videos of two additional goats. Repeating this process five times with varying groupings yielded an average accuracy of 80 percent. Such training “essentially builds 30 years of clinical experience in 30 minutes,” Chiavaccini says.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eSimilar AI tools exist \u003ca href=\"https://www.scientificamerican.com/article/cats-can-hide-their-pain-but-not-from-ai/\"\u003efor cats\u003c/a\u003e, which have better-established expression-based pain scales, but the only such \u003ca href=\"https://www.mdpi.com/2076-2615/13/13/2136\"\u003epain scale for goats\u003c/a\u003e had been validated solely in young, healthy males undergoing castration. Chiavaccini was inspired by the lack of goat pain scales, in addition to a graduate student’s enthusiasm for the animals after presenting them at an agricultural show.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eAI-powered tools built with similar methods could someday help veterinarians make quicker and more accurate diagnoses or alert farmers to early stages of livestock distress. “This study shows the potential for broader adoption of AI in animal care and highlights the need for further exploration across diverse species,” says University of Glasgow computer scientist Marwa Mahmoud, who specializes in human and animal behavioral AI.\u003c/p\u003e\u003cp data-block=\"sciam/paragraph\"\u003eExpression-based pain-assessment tools already exist for nonverbal human patients, but these systems’ effectiveness \u003ca href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC11111436/\"\u003ecan be limited\u003c/a\u003e by poor image quality or suboptimal camera angles. “Many of the engineering problems we solved, like adapting to messy, real-world conditions, could be helpful to human medicine,” Chiavaccini says. “Doctors worry about perfect lighting or head alignment. Meanwhile I’m out here racing after a goat with my camera.”\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-02-07T08:00:00-05:00",
  "modifiedTime": null
}
