{
  "id": "582cd2d1-97f6-46df-89cd-0286154bd26c",
  "title": "Nvidia announces Blackwell Ultra and Rubin AI chips",
  "link": "https://www.cnbc.com/2025/03/18/nvidia-announces-blackwell-ultra-and-vera-rubin-ai-chips-.html",
  "description": "Nvidia’s sales are up more than sixfold since its business was transformed by the release of OpenAI’s ChatGPT in late 2022.",
  "author": "",
  "published": "Tue, 18 Mar 2025 19:30:21 GMT",
  "source": "https://www.cnbc.com/id/100003114/device/rss/rss.html",
  "categories": null,
  "byline": "Kif Leswing",
  "length": 6870,
  "excerpt": "Nvidia’s sales are up more than sixfold since its business was transformed by the release of OpenAI’s ChatGPT in late 2022.",
  "siteName": "CNBC",
  "favicon": "",
  "text": "Nvidia CEO Jensen Huang arrives to attend the opening ceremony of Siliconware Precision Industries Co. (SPIL)’s Tan Ke Plant site in Taichung, Taiwan Jan. 16, 2025. Ann Wang | ReutersNvidia announced new chips for building and deploying artificial intelligence models at its annual GTC conference on Tuesday. CEO Jensen Huang revealed Blackwell Ultra, a family of chips shipping in the second half of this year, as well as Vera Rubin, the company's next-generation graphics processing unit, or GPU, that is expected to ship in 2026.Nvidia's sales are up more than sixfold since its business was transformed by the release of OpenAI's ChatGPT in late 2022. That's because its \"big GPUs\" have most of the market for developing advanced AI, a process called training.Software developers and investors are closely watching the company's new chips to see if they offer enough additional performance and efficiency to convince the company's biggest end customers — cloud companies including Microsoft, Google and Amazon — to continue spending billions of dollars to build data centers based around Nvidia chips.\"This last year is where almost the entire world got involved. The computational requirement, the scaling law of AI, is more resilient, and in fact, is hyper-accelerated,\" Huang said.Tuesday's announcements are also a test of Nvidia's new annual release cadence. The company is striving to announce new chip families on an every-year basis. Before the AI boom, Nvidia released new chip architectures every other year. The GTC conference in San Jose, California, is also a show of strength for Nvidia. The event, Nvidia's second in-person conference since the pandemic, is expected to have 25,000 attendees and hundreds of companies discussing the ways they use the company's hardware for AI. That includes Waymo, Microsoft and Ford, among others. General Motors also announced that it will use Nvidia's service for its next-generation vehicles.The chip architecture after Rubin will be named after physicist Richard Feynman, Nvidia said on Tuesday, continuing its tradition of naming chip families after scientists. Nvidia's Feynman chips are expected to be available in 2028, according to a slide displayed by Huang.Nvidia will also showcase its other products and services at the event. For example, Nvidia announced new laptops and desktops using its chips, including two AI-focused PCs called DGX Spark and DGX Station that will be able to run large AI models such as Llama or DeepSeek. The company also announced updates to its networking parts for tying hundreds or thousands of GPUs together so they work as one, as well as a software package called Dynamo that helps users get the most out of their chips.Jensen Huang, co-founder and chief executive officer of Nvidia Corp., speaks during the Nvidia GPU Technology Conference (GTC) in San Jose, California, US, on Tuesday, March 18, 2025. David Paul Morris | Bloomberg | Getty ImagesVera RubinNvidia expects to start shipping systems on its next-generation GPU family in the second half of 2026. The system has two main components: a CPU, called Vera, and a new GPU design, called Rubin. It's named after astronomer Vera Rubin.Vera is Nvidia's first custom CPU design, the company said, and it's based on a core design they've named Olympus. Previously when it needed CPUs, Nvidia used an off-the-shelf design from Arm. Companies that have developed custom Arm core designs, such as Qualcomm and Apple, say that they can be more tailored and unlock better performance.The custom Vera design will be twice as fast as the CPU used in last year's Grace Blackwell chips, the company said. When paired with Vera, Rubin can manage 50 petaflops while doing inference, more than double the 20 petaflops for the company's current Blackwell chips. Rubin can also support as much as 288 gigabytes of fast memory, which is one of the core specs that AI developers watch.Nvidia is also making a change to what it calls a GPU. Rubin is actually two GPUs, Nvidia said. The Blackwell GPU, which is currently on the market, is actually two separate chips that were assembled together and made to work as one chip.Starting with Rubin, Nvidia will say that when it combines two or more dies to make a single chip, it will refer to them as separate GPUs. In the second half of 2027, Nvidia plans to release a \"Rubin Next\" chip that combines four dies to make a single chip, doubling the speed of Rubin, and it will refer to that as four GPUs.Nvidia said that will come in a rack called Vera Rubin NVL144. Previous versions of Nvidia's rack were called NVL72.Jensen Huang, co-founder and chief executive officer of Nvidia Corp., speaks during the Nvidia GPU Technology Conference (GTC) in San Jose, California, US, on Tuesday, March 18, 2025. David Paul Morris | Bloomberg | Getty ImagesBlackwell UltraNvidia also announced new versions of its Blackwell family of chips that it calls Blackwell Ultra.That chip will be able to produce more tokens per second, which means that the chip can generate more content in the same amount of time as its predecessor, the company said in a briefing.Nvidia says that means that cloud providers can use Blackwell Ultra to offer a premium AI service for time-sensitive applications, allowing them to make as much as 50 times the revenue from the new chips as the Hopper generation, which shipped in 2023.Blackwell Ultra will come in a version with two paired to an Nvidia Arm CPU, called GB300, and a version with just the GPU, called B300. It will also come in versions with eight GPUs in a single server blade and a rack version with 72 Blackwell chips.The top four cloud companies have deployed three times the number of Blackwell chips as Hopper chips, Nvidia said.DeepSeekChina's DeepSeek R1 model may have scared Nvidia investors when it was released in January, but Nvidia has embraced the software. The chipmaker will use the model to benchmark several of its new products.Many AI observers said that DeepSeek's model, which reportedly required fewer chips than models made in the U.S., threatened Nvidia's business.But Huang said earlier this year that DeepSeek was actually a good sign for Nvidia. That's because DeepSeek uses a process called \"reasoning,\" which requires more computing power to provide users better answers. The new Blackwell Ultra chips are better for reasoning models, Nvidia said. It's developed its chips to more efficiently do inference, so when new reasoning models require more computing power at the time of deployment, Nvidia's chips will be able to handle it.\"In the last 2 to 3 years, a major breakthrough happened, a fundamental advance in artificial intelligence happened. We call it agentic AI,\" Huang said. \"It can reason about how to answer or how to solve a problem.\"WATCH: Nvidia kicks off its GTC Conference: The Committee debate how to trade it",
  "image": "https://image.cnbcfm.com/api/v1/image/108117806-1742323196842-gettyimages-2205211176-NVIDIA_AI.jpeg?v=1742323247\u0026w=1920\u0026h=1080",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"SpecialReportArticle-ArticleBody-6\" data-module=\"ArticleBody\" data-test=\"articleBody-2\" data-analytics=\"SpecialReportArticle-articleBody-6-2\"\u003e\u003cdiv id=\"ArticleBody-InlineImage-108108036\" data-test=\"InlineImage\"\u003e\u003cp\u003eNvidia CEO Jensen Huang arrives to attend the opening ceremony of Siliconware Precision Industries Co. (SPIL)’s Tan Ke Plant site in Taichung, Taiwan Jan. 16, 2025. \u003c/p\u003e\u003cp\u003eAnn Wang | Reuters\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp\u003e\u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-1\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/NVDA/\"\u003eNvidia\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e announced new chips for building and deploying artificial intelligence models at its annual GTC conference on Tuesday. \u003c/p\u003e\u003cp\u003eCEO Jensen Huang revealed Blackwell Ultra, a family of chips shipping in the second half of this year, as well \u003ca href=\"https://www.cnbc.com/2025/03/13/nvidia-to-detail-vera-rubin-chips-at-gtc-conference.html\"\u003eas Vera Rubin\u003c/a\u003e, the company\u0026#39;s next-generation graphics processing unit, or GPU, that is expected to ship in 2026.\u003c/p\u003e\u003cp\u003eNvidia\u0026#39;s sales are up more than sixfold since its business was transformed by the release of OpenAI\u0026#39;s ChatGPT in late 2022. That\u0026#39;s because its \u0026#34;big GPUs\u0026#34; have most of the market for developing advanced AI, a process called training.\u003c/p\u003e\u003cp\u003eSoftware developers and investors are closely watching the company\u0026#39;s new chips to see if they offer enough additional performance and efficiency to convince the company\u0026#39;s biggest end customers — cloud companies including \u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-3\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/MSFT/\"\u003eMicrosoft\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e, \u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-4\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/GOOGL/\"\u003eGoogle\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e and \u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-5\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/AMZN/\"\u003eAmazon\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e — to continue spending billions of dollars to build data centers based around Nvidia chips.\u003c/p\u003e\u003cp\u003e\u0026#34;This last year is where almost the entire world got involved. The computational requirement, the scaling law of AI, is more resilient, and in fact, is hyper-accelerated,\u0026#34; Huang said.\u003c/p\u003e\u003cp\u003eTuesday\u0026#39;s announcements are also a test of Nvidia\u0026#39;s new annual release cadence. The company is striving to announce new chip families on an every-year basis. Before the AI boom, Nvidia released new chip architectures every other year. \u003c/p\u003e\u003cp\u003eThe GTC conference in San Jose, California, is also a show of strength for Nvidia. \u003c/p\u003e\u003cp\u003eThe event, Nvidia\u0026#39;s second in-person conference since the pandemic, is expected to have 25,000 attendees and hundreds of companies discussing the ways they use the company\u0026#39;s hardware for AI. That includes Waymo, Microsoft and \u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-6\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/F/\"\u003eFord\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e, among others. \u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-7\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/GM/\"\u003eGeneral Motors\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e also announced that it will use Nvidia\u0026#39;s service for its \u003ca href=\"https://www.cnbc.com/2025/03/18/nvidia-gm-deals-ai-factories-vehicles.html\"\u003enext-generation vehicles\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eThe chip architecture after Rubin will be named after physicist Richard Feynman, Nvidia said on Tuesday, continuing its tradition of naming chip families after scientists. Nvidia\u0026#39;s Feynman chips are expected to be available in 2028, according to a slide displayed by Huang.\u003c/p\u003e\u003cp\u003eNvidia will also showcase its other products and services at the event. \u003c/p\u003e\u003cp\u003eFor example, Nvidia announced new laptops and desktops using its chips, including two AI-focused PCs called \u003ca href=\"https://nvidianews.nvidia.com/news/nvidia-announces-dgx-spark-and-dgx-station-personal-ai-computers\" target=\"_blank\"\u003eDGX Spark and DGX Station\u003c/a\u003e that will be able to run large AI models such as Llama or DeepSeek. The company also announced updates to its networking parts for tying hundreds or thousands of GPUs together so they work as one, as well as a software package called Dynamo that helps users get the most out of their chips.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"ArticleBody-InlineImage-108117806\" data-test=\"InlineImage\"\u003e\u003cp\u003eJensen Huang, co-founder and chief executive officer of Nvidia Corp., speaks during the Nvidia GPU Technology Conference (GTC) in San Jose, California, US, on Tuesday, March 18, 2025. \u003c/p\u003e\u003cp\u003eDavid Paul Morris | Bloomberg | Getty Images\u003c/p\u003e\u003c/div\u003e\u003ch2\u003e\u003ca id=\"headline0\"\u003e\u003c/a\u003eVera Rubin\u003c/h2\u003e\u003cdiv\u003e\u003cp\u003eNvidia expects to start shipping systems on its next-generation GPU family in the second half of 2026. \u003c/p\u003e\u003cp\u003eThe system has two main components: a CPU, called Vera, and a new GPU design, called Rubin. It\u0026#39;s named after \u003ca href=\"https://www.cnbc.com/2025/03/13/nvidia-to-detail-vera-rubin-chips-at-gtc-conference.html\"\u003eastronomer Vera Rubin\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eVera is Nvidia\u0026#39;s first custom CPU design, the company said, and it\u0026#39;s based on a core design they\u0026#39;ve named Olympus. \u003c/p\u003e\u003cp\u003ePreviously when it needed CPUs, Nvidia used an off-the-shelf design from \u003cspan data-test=\"QuoteInBody\" id=\"SpecialReportArticle-QuoteInBody-11\"\u003e\u003ca href=\"https://www.cnbc.com/quotes/ARM/\"\u003eArm\u003c/a\u003e\u003cspan\u003e\u003cspan id=\"-WatchlistDropdown\" data-analytics-id=\"-WatchlistDropdown\"\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e. Companies that have developed custom Arm core designs, such as Qualcomm and Apple, say that they can be more tailored and unlock better performance.\u003c/p\u003e\u003cp\u003eThe custom Vera design will be twice as fast as the CPU used in last year\u0026#39;s Grace Blackwell chips, the company said. \u003c/p\u003e\u003cp\u003eWhen paired with Vera, Rubin can manage 50 petaflops while doing inference, more than double the 20 petaflops for the company\u0026#39;s current Blackwell chips. Rubin can also support as much as 288 gigabytes of fast memory, which is one of the core specs that AI developers watch.\u003c/p\u003e\u003cp\u003eNvidia is also making a change to what it calls a GPU. Rubin is actually two GPUs, Nvidia said. \u003c/p\u003e\u003cp\u003eThe Blackwell GPU, which is currently on the market, is actually two separate chips that were assembled together and made to work as one chip.\u003c/p\u003e\u003cp\u003eStarting with Rubin, Nvidia will say that when it combines two or more dies to make a single chip, it will refer to them as separate GPUs. In the second half of 2027, Nvidia plans to release a \u0026#34;Rubin Next\u0026#34; chip that combines four dies to make a single chip, doubling the speed of Rubin, and it will refer to that as four GPUs.\u003c/p\u003e\u003cp\u003eNvidia said that will come in a rack called Vera Rubin NVL144. Previous versions of Nvidia\u0026#39;s rack were called NVL72.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"ArticleBody-InlineImage-108117808\" data-test=\"InlineImage\"\u003e\u003cp\u003eJensen Huang, co-founder and chief executive officer of Nvidia Corp., speaks during the Nvidia GPU Technology Conference (GTC) in San Jose, California, US, on Tuesday, March 18, 2025. \u003c/p\u003e\u003cp\u003eDavid Paul Morris | Bloomberg | Getty Images\u003c/p\u003e\u003c/div\u003e\u003ch2\u003e\u003ca id=\"headline1\"\u003e\u003c/a\u003eBlackwell Ultra\u003c/h2\u003e\u003cdiv\u003e\u003cp\u003eNvidia also announced new versions of its Blackwell family of chips that it calls Blackwell Ultra.\u003c/p\u003e\u003cp\u003eThat chip will be able to produce more tokens per second, which means that the chip can generate more content in the same amount of time as its predecessor, the company said in a briefing.\u003c/p\u003e\u003cp\u003eNvidia says that means that cloud providers can use Blackwell Ultra to offer a premium AI service for time-sensitive applications, allowing them to make as much as 50 times the revenue from the new chips as the Hopper generation, which shipped in 2023.\u003c/p\u003e\u003cp\u003eBlackwell Ultra will come in a version with two paired to an Nvidia Arm CPU, called GB300, and a version with just the GPU, called B300. It will also come in versions with eight GPUs in a single server blade and a rack version with 72 Blackwell chips.\u003c/p\u003e\u003cp\u003eThe top four cloud companies have deployed three times the number of Blackwell chips as Hopper chips, Nvidia said.\u003c/p\u003e\u003c/div\u003e\u003ch2\u003e\u003ca id=\"headline2\"\u003e\u003c/a\u003eDeepSeek\u003c/h2\u003e\u003cdiv\u003e\u003cp\u003eChina\u0026#39;s DeepSeek R1 model may have scared Nvidia investors when it was released in January, but Nvidia has embraced the software. The chipmaker will use the model to benchmark several of its new products.\u003c/p\u003e\u003cp\u003eMany AI observers said that DeepSeek\u0026#39;s model, which reportedly required fewer chips than models made in the U.S., threatened Nvidia\u0026#39;s business.\u003c/p\u003e\u003cp\u003eBut Huang said earlier this year that DeepSeek was actually a good sign for Nvidia. That\u0026#39;s because DeepSeek uses a process called \u0026#34;reasoning,\u0026#34; which requires more computing power to provide users better answers. \u003c/p\u003e\u003cp\u003eThe new Blackwell Ultra chips are better for reasoning models, Nvidia said. \u003c/p\u003e\u003cp\u003eIt\u0026#39;s developed its chips to more efficiently do inference, so when new reasoning models require more computing power at the time of deployment, Nvidia\u0026#39;s chips will be able to handle it.\u003c/p\u003e\u003cp\u003e\u0026#34;In the last 2 to 3 years, a major breakthrough happened, a fundamental advance in artificial intelligence happened. We call it agentic AI,\u0026#34; Huang said. \u0026#34;It can reason about how to answer or how to solve a problem.\u0026#34;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWATCH: \u003c/strong\u003e\u003ca href=\"https://www.cnbc.com/video/2025/03/17/nvidia-kicks-off-its-gtc-conference-the-committee-debate-how-to-trade-it.html\"\u003eNvidia kicks off its GTC Conference: The Committee debate how to trade it\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"Placeholder-ArticleBody-Video-108116990\" data-test=\"VideoPlaceHolder\" role=\"region\" tabindex=\"0\" data-vilynx-id=\"7000369870\" aria-labelledby=\"Placeholder-ArticleBody-Video-108116990\"\u003e\u003cp\u003e\u003cimg src=\"https://image.cnbcfm.com/api/v1/image/108116991-17422284081742228404-38941539178-1080pnbcnews.jpg?v=1742228407\u0026amp;w=750\u0026amp;h=422\u0026amp;vtcrop=y\" alt=\"Nvidia kicks off its GTC Conference: The Committee debate how to trade it\"/\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-03-18T18:35:54Z",
  "modifiedTime": "2025-03-18T19:30:21Z"
}
