{
  "id": "5a3c3940-6c2f-465c-9a2a-f31dfd75db89",
  "title": "6 updates for Gemini on Pixel that make it better than ever",
  "link": "https://blog.google/products/pixel/six-months-gemini-pixel-six-updates/",
  "description": "Learn about major updates launched for Gemini on Pixel in recent months.",
  "author": "Molly McHugh-JohnsonContributorThe Keyword",
  "published": "Mon, 24 Feb 2025 17:00:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Gemini App",
    "Gemini Features"
  ],
  "byline": "Molly McHugh-Johnson",
  "length": 4817,
  "excerpt": "Learn about major updates launched for Gemini on Pixel in recent months.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20250219-1743",
  "text": "Feb 24, 2025 [[read-time]] min read Over the last six months, Gemini on Pixel received quite a few improvements. Here are six updates we’ve launched and how you can use them. Bullet points Six updates to Gemini on Pixel make it smarter, faster, and more useful. New AI models, including Flash, Flash Thinking, and Pro, improve Gemini's capabilities. Multimodal capabilities in Gemini Live let you add images, files, and videos to conversations. Deep Research uses Gemini models to search and write reports on complex topics. Gemini now answers questions even when your phone is locked and integrates with various apps. Summaries were generated by Google AI. Generative AI is experimental. Six months ago, we introduced our first Pixel phones with Gemini built in. Since then, we’ve been busy updating Gemini models and the Gemini app, along with developing new features that make it more useful. Here are six upgrades that launched over the past six months for Gemini:1. New AI models made Gemini a smarter, faster assistantIn December, we introduced experimental versions of our latest family of models, Gemini 2.0. This includes Flash, Flash Thinking and Pro — each of which is for specific use cases. 2.0 Flash can handle your everyday tasks, try 2.0 Flash Thinking when you have questions that require multiple steps and 2.0 Pro is great at coding, math and other complex queries. In January, an updated version of 2.0 Flash launched for all Gemini app users on desktop as well as mobile. All of this means that Gemini now answers your questions faster and is better at answering more complex questions, too.Plus, the Gemini app now uses our latest Imagen 3 model, delivering significantly brighter, better composed images and more accurate rendering of diverse art styles, from photorealism to anime.2. Multimodal capabilities gave Gemini Live more to talk aboutWe added multimodal capabilities to Gemini Live in January. Gemini Live (available for Android and iOS phones) lets you have free-flowing conversations with Gemini. Multimodal capabilities in Gemini Live allow you to add images, files and YouTube videos to your conversations to provide more context about what exactly you’re looking for or trying to understand — this means you can do things like take a photo of a plant and have a conversation with Gemini Live about whether it will survive in your yard and when you should plant it, or link to a cooking tutorial video on YouTube and ask Gemini to talk you through how to double the recipe.3. Gemini started researching — and writing reports — for youLaunched in December, Deep Research is our new agentic feature in Gemini Advanced: It uses Gemini models to search dozens of websites and explore complex topics for you and delivers its findings in easy-to-read reports. You can ask Deep Research to compare mortgage rates in different cities or help you decide what car you should buy. The reports include source links and you can always use the chat feature to add more information or edit the report. Recently, we also made Deep Research available on mobile (including Pixel users, of course) in the Gemini app, in addition to it being available for everyone via desktop.4. Gemini started answering more questions in more placesAn Assistant can’t be helpful if it isn’t able to answer your questions when you need it, so now Gemini responds to more of your questions in more places. Gemini now answers your queries, even when your phone is locked.5. Extensions gave Gemini all kinds of new usesOver the past six months, Gemini broadened its capabilities by integrating a number of new extensions. For example, Gemini’s Google Home extension lets you do things from your Pixel, like ask it to dim your lights or turn on your TV. You can also ask Gemini to call personal contacts or businesses, as well as draft and send messages with your default phone and messaging apps. And with the new Utilities extension, Gemini can even set alarms, control your device settings and open your camera to take a quick selfie. The list of available extensions includes apps like Google Calendar, Google Tasks, Spotify and more — and the list is growing!6. A redesign and simpler interface made it easier to tell Gemini what you needAt the beginning of this year, Gemini’s overlay on Pixel got a new look: The simple, intuitive layout makes it easy to prompt Gemini whenever you need it. Simply long press the power button or say “Hey Google” to activate it.",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SOCIAL_SHARE_-6_cool_things_Gemini_Assistant_.width-1300.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;6 updates for Gemini on Pixel that make it better than ever\u0026#34;\n  }\"\u003e\n  \n  \u003cdiv\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eFeb 24, 2025\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          Over the last six months, Gemini on Pixel received quite a few improvements. Here are six updates we’ve launched and how you can use them.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n  \n  \u003cdiv data-summary-id=\"ai_summary_2\" data-component=\"uni-ai-generated-summary\" data-analytics-module=\"{\n    \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n    \u0026#34;module_name\u0026#34;: \u0026#34;ai_summary\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;CTA\u0026#34;\n  }\"\u003e\n          \u003ch2\u003eBullet points\u003c/h2\u003e\n          \u003cul\u003e\n\u003cli\u003eSix updates to Gemini on Pixel make it smarter, faster, and more useful.\u003c/li\u003e\n\u003cli\u003eNew AI models, including Flash, Flash Thinking, and Pro, improve Gemini\u0026#39;s capabilities.\u003c/li\u003e\n\u003cli\u003eMultimodal capabilities in Gemini Live let you add images, files, and videos to conversations.\u003c/li\u003e\n\u003cli\u003eDeep Research uses Gemini models to search and write reports on complex topics.\u003c/li\u003e\n\u003cli\u003eGemini now answers questions even when your phone is locked and integrates with various apps.\u003c/li\u003e\n\u003c/ul\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n    \n\n    \n      \n\n\n\n\n\n\n\n\n\u003cdiv\u003e\n    \u003cfigure\u003e\n      \u003cdiv\u003e\n  \u003cp\u003e\u003cimg srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/6_cool_things_Gemini_Assistant_ca.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/6_cool_things_Gemini_Assistant_c.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/6_cool_things_Gemini_Assistant_c.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/6_cool_things_Gemini_Assistant_c.width-2200.format-webp.webp 2200w\" sizes=\"(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/6_cool_things_Gemini_Assistant_c.width-1200.format-webp.webp\" fetchpriority=\"high\" alt=\"The image is a collage showcasing Google Gemini\u0026#39;s interface on a smartphone, surrounded by diverse visuals including landscapes, a person using a laptop, and abstract shapes.  The central phone screen features Gemini Live with various media integrations.\"/\u003e\n  \u003c/p\u003e\n\u003c/div\u003e\n\n      \n    \u003c/figure\u003e\n  \u003c/div\u003e\n\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\n\n\u003cgoogle-read-aloud-player data-analytics-module=\"{\n        \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n        \u0026#34;module_name\u0026#34;: \u0026#34;ai_audio\u0026#34;,\n        \u0026#34;section_header\u0026#34;: \u0026#34;6 updates for Gemini on Pixel that make it better than ever\u0026#34;\n    }\" data-call-to-action-text=\"Listen to article\" data-date-modified=\"2025-02-24T17:00:07.733311+00:00\" data-progress-bar-style=\"half-wave\" data-api-key=\"AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac\" data-article-style=\"style9\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-layout-style=\"style1\" data-highlight-mode=\"word-over-paragraph\" data-highlight-text-color=\"#000000\" data-highlight-word-background=\"#8AB4F8\" data-highlight-paragraph-background=\"#D2E3FC\" data-background=\"linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)\" data-foreground-color=\"#202124\" data-font=\"600 16px Google Sans, sans-serif\" data-box-shadow=\"0px 1px 3px 1px rgba(60, 64, 67, 0.15)\"\u003e\n\u003c/google-read-aloud-player\u003e\n\n\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;6 updates for Gemini on Pixel that make it better than ever\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"xk08l\"\u003eSix months ago, we introduced our \u003ca href=\"https://blog.google/products/pixel/google-pixel-9-pro-xl/\"\u003efirst Pixel phones with Gemini built in\u003c/a\u003e. Since then, we’ve been busy updating Gemini models and the Gemini app, along with developing new features that make it more useful. Here are six upgrades that launched over the past six months for Gemini:\u003c/p\u003e\u003ch2 data-block-key=\"254hc\"\u003e1. New AI models made Gemini a smarter, faster assistant\u003c/h2\u003e\u003cp data-block-key=\"5bkk1\"\u003eIn December, we introduced experimental versions of our latest family of models, \u003ca href=\"https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#gemini-2-0\"\u003eGemini 2.0\u003c/a\u003e. This includes Flash, Flash Thinking and Pro — each of which is for specific use cases. 2.0 Flash can handle your everyday tasks, try 2.0 Flash Thinking when you have questions that require multiple steps and 2.0 Pro is great at coding, math and other complex queries. In January, an updated version of 2.0 Flash launched for all Gemini app users on desktop as well as mobile. All of this means that Gemini now answers your questions faster and is better at answering more complex questions, too.\u003c/p\u003e\u003cp data-block-key=\"8r2ej\"\u003ePlus, the Gemini app now uses our \u003ca href=\"https://blog.google/technology/google-labs/video-image-generation-update-december-2024/\"\u003elatest Imagen 3 model\u003c/a\u003e, delivering significantly brighter, better composed images and more accurate rendering of diverse art styles, from photorealism to anime.\u003c/p\u003e\u003ch2 data-block-key=\"1lbh8\"\u003e2. Multimodal capabilities gave Gemini Live more to talk about\u003c/h2\u003e\u003cp data-block-key=\"fsdon\"\u003eWe added \u003ca href=\"https://blog.google/products/android/google-ai-samsung-galaxy-s25/\"\u003emultimodal capabilities to Gemini Live in January\u003c/a\u003e. Gemini Live (available for \u003ca href=\"https://blog.google/products/gemini/made-by-google-gemini-ai-updates/\"\u003eAndroid\u003c/a\u003e and \u003ca href=\"https://blog.google/products/gemini/gemini-iphone-app/\"\u003eiOS\u003c/a\u003e phones) lets you have free-flowing conversations with Gemini. Multimodal capabilities in Gemini Live allow you to add images, files and YouTube videos to your conversations to provide more context about what exactly you’re looking for or trying to understand — this means you can do things like take a photo of a plant and have a conversation with Gemini Live about whether it will survive in your yard and when you should plant it, or link to a cooking tutorial video on YouTube and ask Gemini to talk you through how to double the recipe.\u003c/p\u003e\u003ch2 data-block-key=\"5ur9b\"\u003e3. Gemini started researching — and writing reports — for you\u003c/h2\u003e\u003cp data-block-key=\"9jl7u\"\u003eLaunched in December, \u003ca href=\"https://blog.google/products/gemini/google-gemini-deep-research/\"\u003eDeep Research\u003c/a\u003e is our new agentic feature in Gemini Advanced: It uses Gemini models to search dozens of websites and explore complex topics for you and delivers its findings in easy-to-read reports. You can ask Deep Research to compare mortgage rates in different cities or help you decide what car you should buy. The reports include source links and you can always use the chat feature to add more information or edit the report. Recently, we also made Deep Research available on mobile (including Pixel users, of course) in the Gemini app, in addition to it being available for everyone via desktop.\u003c/p\u003e\u003ch2 data-block-key=\"dd4mp\"\u003e4. Gemini started answering more questions in more places\u003c/h2\u003e\u003cp data-block-key=\"dfktb\"\u003eAn Assistant can’t be helpful if it isn’t able to answer your questions when you need it, so now Gemini responds to more of your questions in more places. Gemini now answers your queries, \u003ca href=\"https://support.google.com/gemini/answer/14576209?hl=en-GB#:~:text=On%20Android%20phones%20and%20tablets,torch%20and%20changing%20the%20volume\"\u003eeven when your phone is locked\u003c/a\u003e.\u003c/p\u003e\u003ch2 data-block-key=\"11s1f\"\u003e5. Extensions gave Gemini all kinds of new uses\u003c/h2\u003e\u003cp data-block-key=\"50hgt\"\u003eOver the past six months, Gemini broadened its capabilities by integrating a number of new \u003ca href=\"https://support.google.com/gemini/answer/13695044?hl=en\u0026amp;co=GENIE.Platform%3DDesktop\"\u003eextensions\u003c/a\u003e. For example, Gemini’s Google Home extension lets you do things from your Pixel, like ask it to dim your lights or turn on your TV. You can also ask Gemini to call personal contacts or businesses, as well as draft and send messages with your default phone and messaging apps. And with the new Utilities extension, Gemini can even set alarms, control your device settings and open your camera to take a quick selfie. The list of available extensions includes apps like Google Calendar, Google Tasks, Spotify and more — and the list is growing!\u003c/p\u003e\u003ch2 data-block-key=\"esarq\"\u003e6. A redesign and simpler interface made it easier to tell Gemini what you need\u003c/h2\u003e\u003cp data-block-key=\"anqaq\"\u003eAt the beginning of this year, Gemini’s overlay on Pixel got a new look: The simple, intuitive layout makes it easy to prompt Gemini whenever you need it. Simply long press the power button or say “Hey Google” to activate it.\u003c/p\u003e\u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-02-24T17:00:00Z",
  "modifiedTime": null
}
