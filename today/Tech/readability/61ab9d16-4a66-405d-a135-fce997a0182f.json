{
  "id": "61ab9d16-4a66-405d-a135-fce997a0182f",
  "title": "Cloudflare is luring web-scraping bots into an ‘AI Labyrinth’",
  "link": "https://www.theverge.com/news/634345/cloudflare-ai-labyrinth-web-scraping-bots-training-data",
  "description": "Cloudflare, one of the biggest network internet infrastructure companies in the world, has announced AI Labyrinth, a new tool to fight web-crawling bots that scrape sites for AI training data without permission. The company says in a blog post that when it detects “inappropriate bot behavior,” the free, opt-in tool lures crawlers down a path […]",
  "author": "Wes Davis",
  "published": "2025-03-22T14:17:38-04:00",
  "source": "https://www.theverge.com/rss/index.xml",
  "categories": [
    "AI",
    "News",
    "Tech"
  ],
  "byline": "Wes Davis",
  "length": 2705,
  "excerpt": "Cloudflare has a new AI-generated “honeypot.”",
  "siteName": "The Verge",
  "favicon": "https://www.theverge.com/static-assets/icons/android-chrome-512x512.png",
  "text": "Wes Davis is a weekend editor who covers the latest in tech and entertainment. He has written news, reviews, and more as a tech journalist since 2020.Cloudflare, one of the biggest network internet infrastructure companies in the world, has announced AI Labyrinth, a new tool to fight web-crawling bots that scrape sites for AI training data without permission. The company says in a blog post that when it detects “inappropriate bot behavior,” the free, opt-in tool lures crawlers down a path of links to AI-generated decoy pages that “slow down, confuse, and waste the resources” of those acting in bad faith.Websites have long used the honor system approach of robots.txt, a text file that gives or denies permission to scrapers, but which AI companies, even well-known ones like Anthropic and Perplexity AI, have been accused of ignoring. Cloudflare writes that it sees over 50 billion web crawler requests per day, and although it has tools for spotting and blocking the malicious ones, this often prompts attackers to switch tactics in “a never-ending arms race.”Cloudflare says rather than block bots, AI Labyrinth fights back by making them process data that has nothing to do with a given website’s actual data. The company says it also functions as “a next-generation honeypot,” drawing in AI crawlers that keep following links to fake pages deeper, whereas a regular human being wouldn’t. It says this makes it easier to fingerprint malicious bots for Cloudflare’s list of bad actors as well as identify “new bot patterns and signatures” it wouldn’t have detected otherwise. According to the post, these links shouldn’t be visible to human visitors.You can read more about how AI Labyrinth works on Cloudflare’s blog, but here’s a bit more detail from the post:We found that generating a diverse set of topics first, then creating content for each topic, produced more varied and convincing results. It is important to us that we don’t generate inaccurate content that contributes to the spread of misinformation on the Internet, so the content we generate is real and related to scientific facts, just not relevant or proprietary to the site being crawled.Website administrators can opt into using AI Labyrinth by navigating to the Bot Management section of their site’s Cloudflare dashboard’s settings and toggling it on. The company says that this “is only the first iteration of using generative AI to thwart bots.” It plans to create “whole networks of linked URLs” that bots that end up in will have a hard time clocking as fake. As Ars Technica notes, AI Labyrinth sounds similar to Nepenthes, a tool that’s designed to sideline crawlers for “months” in a hell of AI-generated junk data.",
  "image": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/STKB326_CLOUDFLARE_A.jpg?quality=90\u0026strip=all\u0026crop=0%2C10.732984293194%2C100%2C78.534031413613\u0026w=1200",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Wes Davis\" data-chromatic=\"ignore\" loading=\"lazy\" width=\"36\" height=\"36\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/196306/unnamed.0.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/196306/unnamed.0.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=96 2x\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/196306/unnamed.0.jpg?quality=90\u0026amp;strip=all\u0026amp;crop=0%2C0%2C100%2C100\u0026amp;w=96\"/\u003e\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.theverge.com/authors/wes-davis\"\u003eWes Davis\u003c/a\u003e \u003cspan\u003eis a weekend editor who covers the latest in tech and entertainment. He has written news, reviews, and more as a tech journalist since 2020.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"zephr-anchor\"\u003e\u003cp\u003eCloudflare, one of the biggest network internet infrastructure companies in the world, has announced AI Labyrinth, a new tool to fight web-crawling bots that scrape sites for AI training data without permission. The company says in \u003ca href=\"https://blog.cloudflare.com/ai-labyrinth/\"\u003ea blog post\u003c/a\u003e that when it detects “inappropriate bot behavior,” the free, opt-in tool lures crawlers down a path of links to AI-generated decoy pages that “slow down, confuse, and waste the resources” of those acting in bad faith.\u003c/p\u003e\u003cp\u003eWebsites have long used the \u003ca href=\"https://www.theverge.com/24067997/robots-txt-ai-text-file-web-crawlers-spiders\"\u003ehonor system approach of robots.txt\u003c/a\u003e, a text file that gives or denies permission to scrapers, but which AI companies, even well-known ones \u003ca href=\"https://www.theverge.com/2024/7/25/24205943/anthropic-ai-web-crawler-claudebot-ifixit-scraping-training-data\"\u003elike Anthropic\u003c/a\u003e and \u003ca href=\"https://www.theverge.com/2024/6/27/24187405/perplexity-ai-twitter-lie-plagiarism\"\u003ePerplexity AI\u003c/a\u003e, have been accused of ignoring. Cloudflare writes that it sees over 50 billion web crawler requests per day, and although it has tools for spotting and blocking the malicious ones, this often prompts attackers to switch tactics in “a never-ending arms race.”\u003c/p\u003e\u003cp\u003eCloudflare says rather than block bots, AI Labyrinth fights back by making them process data that has nothing to do with a given website’s actual data. The company says it also functions as “a next-generation honeypot,” drawing in AI crawlers that keep following links to fake pages deeper, whereas a regular human being wouldn’t. It says this makes it easier to fingerprint malicious bots for Cloudflare’s list of bad actors as well as identify “new bot patterns and signatures” it wouldn’t have detected otherwise. According to the post, these links shouldn’t be visible to human visitors.\u003c/p\u003e\u003cp\u003eYou can read more about how AI Labyrinth works on Cloudflare’s blog, but here’s a bit more detail from the post:\u003c/p\u003e\u003cdiv\u003e\u003cblockquote\u003e\u003cp\u003eWe found that generating a diverse set of topics first, then creating content for each topic, produced more varied and convincing results. It is important to us that we don’t generate inaccurate content that contributes to the spread of misinformation on the Internet, so the content we generate is real and related to scientific facts, just not relevant or proprietary to the site being crawled.\u003c/p\u003e\u003c/blockquote\u003e\u003c/div\u003e\u003cp\u003eWebsite administrators can opt into using AI Labyrinth by navigating to the Bot Management section of their site’s Cloudflare dashboard’s settings and toggling it on. The company says that this “is only the first iteration of using generative AI to thwart bots.” It plans to create “whole networks of linked URLs” that bots that end up in will have a hard time clocking as fake. As \u003ca href=\"https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/\"\u003e\u003cem\u003eArs Technica\u003c/em\u003e notes\u003c/a\u003e, AI Labyrinth sounds similar to Nepenthes, a tool that’s designed to sideline crawlers for “months” in a hell of AI-generated junk data.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-03-22T18:17:38Z",
  "modifiedTime": "2025-03-22T18:17:38Z"
}
