{
  "id": "3799ec14-fe2b-44de-8d8f-3d6619e71326",
  "title": "Cloudflare turns AI against itself with endless maze of irrelevant facts",
  "link": "https://arstechnica.com/ai/2025/03/cloudflare-turns-ai-against-itself-with-endless-maze-of-irrelevant-facts/",
  "description": "New approach punishes AI companies that ignore \"no crawl\" directives.",
  "author": "Benj Edwards",
  "published": "Fri, 21 Mar 2025 21:14:35 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Biz \u0026 IT",
    "AI security",
    "cloudflare",
    "large language models",
    "machine learning"
  ],
  "byline": "Benj Edwards",
  "length": 2453,
  "excerpt": "New approach punishes AI companies that ignore “no crawl” directives.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "On Wednesday, web infrastructure provider Cloudflare announced a new feature called \"AI Labyrinth\" that aims to combat unauthorized AI data scraping by serving fake AI-generated content to bots. The tool will attempt to thwart AI companies that crawl websites without permission to collect training data for large language models that power AI assistants like ChatGPT. Cloudflare, founded in 2009, is probably best known as a company that provides infrastructure and security services for websites, particularly protection against distributed denial-of-service (DDoS) attacks and other malicious traffic. Instead of simply blocking bots, Cloudflare's new system lures them into a \"maze\" of realistic-looking but irrelevant pages, wasting the crawler's computing resources. The approach is a notable shift from the standard block-and-defend strategy used by most website protection services. Cloudflare says blocking bots sometimes backfires because it alerts the crawler's operators that they've been detected. \"When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them,\" writes Cloudflare. \"But while real looking, this content is not actually the content of the site we are protecting, so the crawler wastes time and resources.\" The company says the content served to bots is deliberately irrelevant to the website being crawled, but it is carefully sourced or generated using real scientific facts—such as neutral information about biology, physics, or mathematics—to avoid spreading misinformation (whether this approach effectively prevents misinformation, however, remains unproven). Cloudflare creates this content using its Workers AI service, a commercial platform that runs AI tasks. Cloudflare designed the trap pages and links to remain invisible and inaccessible to regular visitors, so people browsing the web don't run into them by accident. A smarter honeypot AI Labyrinth functions as what Cloudflare calls a \"next-generation honeypot.\" Traditional honeypots are invisible links that human visitors can't see but bots parsing HTML code might follow. But Cloudflare says modern bots have become adept at spotting these simple traps, necessitating more sophisticated deception. The false links contain appropriate meta directives to prevent search engine indexing while remaining attractive to data-scraping bots.",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/robot_maze_1-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                      \n                      \n          \u003cp\u003eOn Wednesday, web infrastructure provider Cloudflare announced a new feature called \u0026#34;\u003ca href=\"https://blog.cloudflare.com/ai-labyrinth/\"\u003eAI Labyrinth\u003c/a\u003e\u0026#34; that aims to combat unauthorized AI data scraping by serving fake AI-generated content to bots. The tool will attempt to thwart AI companies that crawl websites without permission to collect training data for large language models that power AI assistants like \u003ca href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\"\u003eChatGPT\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCloudflare, founded in 2009, is probably best known as a company that \u003ca href=\"https://en.wikipedia.org/wiki/Cloudflare\"\u003eprovides\u003c/a\u003e infrastructure and security services for websites, particularly protection against \u003ca href=\"https://en.wikipedia.org/wiki/DDoS_mitigation\"\u003edistributed denial-of-service\u003c/a\u003e (DDoS) attacks and other malicious traffic.\u003c/p\u003e\n\u003cp\u003eInstead of simply blocking bots, Cloudflare\u0026#39;s new system lures them into a \u0026#34;maze\u0026#34; of realistic-looking but irrelevant pages, wasting the crawler\u0026#39;s computing resources. The approach is a notable shift from the standard block-and-defend strategy used by most website protection services. Cloudflare says blocking bots sometimes backfires because it alerts the crawler\u0026#39;s operators that they\u0026#39;ve been detected.\u003c/p\u003e\n\u003cp\u003e\u0026#34;When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them,\u0026#34; writes Cloudflare. \u0026#34;But while real looking, this content is not actually the content of the site we are protecting, so the crawler wastes time and resources.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThe company says the content served to bots is deliberately irrelevant to the website being crawled, but it is carefully sourced or generated using real scientific facts—such as neutral information about biology, physics, or mathematics—to avoid spreading misinformation (whether this approach effectively prevents misinformation, however, remains unproven). Cloudflare creates this content using its \u003ca href=\"https://developers.cloudflare.com/workers-ai/\"\u003eWorkers AI\u003c/a\u003e service, a commercial platform that runs AI tasks.\u003c/p\u003e\n\u003cp\u003eCloudflare designed the trap pages and links to remain invisible and inaccessible to regular visitors, so people browsing the web don\u0026#39;t run into them by accident.\u003c/p\u003e\n\u003ch2\u003eA smarter honeypot\u003c/h2\u003e\n\u003cp\u003eAI Labyrinth functions as what Cloudflare calls a \u0026#34;next-generation honeypot.\u0026#34; Traditional honeypots are invisible links that human visitors can\u0026#39;t see but bots parsing HTML code might follow. But Cloudflare says modern bots have become adept at spotting these simple traps, necessitating more sophisticated deception. The false links contain appropriate meta directives to prevent search engine indexing while remaining attractive to data-scraping bots.\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-03-21T21:14:35Z",
  "modifiedTime": "2025-03-21T21:14:35Z"
}
