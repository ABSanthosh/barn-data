{
  "id": "731271ff-8f4a-4fb3-a36b-e69fa6b3a03e",
  "title": "Everything you need to know from Google I/O 2025",
  "link": "https://mashable.com/article/google-io-2025-everything-you-need-to-know",
  "description": "Here's everything we learned from the Google I/O 2025 keynote address, from the latest Gemini updates to a new AI video generation too called Flow.",
  "author": "",
  "published": "Tue, 20 May 2025 22:37:43 +0000",
  "source": "http://feeds.mashable.com/Mashable",
  "categories": null,
  "byline": "Matt Binder",
  "length": 12478,
  "excerpt": "Google announced a lot. Here's what you can't miss.",
  "siteName": "Mashable",
  "favicon": "https://mashable.com/favicons/android-chrome-512x512.png",
  "text": "Google imagines a world powered by artificial intelligence. Credit: Google From the opening AI-influenced intro video set to \"You Get What You Give\" by New Radicals to CEO Sundar Pichai's sign-off, Google I/O 2025 was packed with news and updates for the tech giant and its products. And when we say packed, we mean it, as this year's Google I/O clocked in at nearly two hours long. During that time, Google shared some big wins for its AI products, such as Gemini topping various categories on the LMArena leaderboard. Another example that Google seemed really proud of was the fact that Gemini completed Pokémon Blue a few weeks ago.But, we know what you're really here for: Product updates and new product announcements. Aside from a few braggadocious moments, Google spent most of those 117 minutes talking about what's coming out next. Google I/O mixes consumer-facing product announcements with more developer-oriented ones, from the latest Gmail updates to Google's powerful new chip, Ironwood, coming to Google Cloud customers later this year. We're going to break down what product updates and announcements you need to know from the full two-hour event, so you can walk away with all the takeaways without spending the same time it takes to watch a major motion picture to learn about them.Before we dive in though, here's the most shocking news out of Google I/O: The subscription pricing that Google has for its Google AI Ultra plan. While Google provides a base subscription at $19.99 per month, the Ultra plan comes in at a whopping $249.99 per month for its entire suite of products with the highest rate limits available.Google Search AI ModeGoogle tucked away what will easily be its most visible feature way too far back into the event, but we'll surface it to the top.At Google I/O, Google announced that the new AI Mode feature for Google Search is launching today to everyone in the United States. Basically, it will allow users to use Google's search feature but with longer, more complex queries. Using a \"query fan-out technique,\" AI Mode will be able to break a search into multiple parts in order to process each part of the query, then pull all the information together to present to the user. Google says AI Mode \"checks its work\" too, but its unclear at this time exactly what that means. Google announces AI Mode in Google Search Credit: Google AI Mode is available now. Later in the summer, Google will launch Personal Context in AI Mode, which will make suggestions based on a user's past searches and other contextual information about the user from other Google products like Gmail. In addition, other new features will soon come to AI Mode, such as Deep Search, which can dive deeper into queries by searching through multiple websites, and data visualization features, which can take the search results and present them in a visual graph when applicable.According to Google, its AI overviews in search are viewed by 1.5 billion users every month, so AI Mode clearly has the largest potential user base out of all of Google's announcements today.AI ShoppingOut of all the announcements at the event, these AI shopping features seemed to spark the biggest reaction from Google I/O live attendees.Connected to AI Mode, Google showed off its Shopping Graph, which includes more than 50 billion products globally. Users can just describe the type of product they are looking for – say a specific type of couch, and Google will present options that match that description. Google AI Shopping Credit: Google Google also had a significant presentation that showed its presenter upload a photo of themselves so that AI could create a visual of what she'd look like in a dress. This virtual try-on feature will be available in Google Labs, and it's the IRL version of Cher's Clueless closet.The presenter was then able to use an AI shopping agent to keep tabs on the item's availability and track its price. When the price dropped, the user received a notification of the pricing change.Google said users will be able to try on different looks via AI in Google Labs starting today.Android XRGoogle's long-awaited post-Google Glass AR/VR plans were finally presented at Google I/O. The company also unveiled a number of wearable products utilizing its AR/VR operating system, Android XR.One important part of the Android XR announcement is that Google seems to understand the different use cases for an immersive headset and an on-the-go pair of smartglasses and have built Android XR to accommodate that.While Samsung has previously teased its Project Moohan XR headset, Google I/O marked the first time that Google revealed the product, which is being built in partnership with the mobile giant and chipmaker Qualcomm. Google shared that the Project Moohan headset should be available later this year. Mashable Light Speed Project Moohan Credit: Google In addition to the XR headset, Google announced Glasses with Android XR, smartglasses that incorporate a camera, speakers, and in-lens display that connect with a user's smartphone. Unlike Google Glass, these smart glasses will incorporate more fashionable looks thanks to partnerships with Gentle Monster and Warby Parker.Google shared that developers will be able to start developing for Glasses starting next year, so it's likely that a release date for the smartglasses will follow after that.GeminiEasily the star of Google I/O 2025 was the company's AI model, Gemini. Google announced a new updated Gemini 2.5 Pro, which it says is its most powerful model yet. The company showed Gemini 2.5 Pro being used to turn sketches into full applications in a demo. Along with that, Google introduced Gemini 2.5 Flash, which is a more affordable version of the powerful Pro model. The latter will be released in early June with the former coming out soon after. Google also revealed Gemini 2.5 Pro Deep Think for complex math and coding, which will only be available to \"trusted testers\" at first.Speaking of coding, Google shared its asynchronous coding agent Jules, which is currently in public beta. Developers will be able to utilize Jules in order to tackle codebase tasks and modify files. Jules coding agent Credit: Google Developers will also have access to a new Native Audio Output text-to-speech model which can replicate the same voice in different languages.The Gemini app will soon see a new Agent Mode, bringing users an AI agent who can research and complete tasks based on a user's prompts.Gemini will also be deeply integrated into Google products like Workspace with Personalized Smart Replies. Gemini will use personal context via documents, emails, and more from across a user's Google apps in order to match their tone, voice, and style in order to generate automatic replies. Workspace users will find the feature available in Gmail this summer.Other features announced for Gemini include Deep Research, which lets users upload their own files to guide the AI agent when asking questions, and Gemini in Chrome, an AI Assistant that answers queries using the context on the web page that a user is on. The latter feature is rolling out this week for Gemini subscribers in the U.S.Google intends to bring Gemini to all of its devices, including smartwatches, smart cars, and smart TVs.Generative AI updatesGemini's AI assistant capabilities and language model updates were only a small piece of Google's broader AI puzzle. The company had a slew of generative AI announcements to make too.Google announced Imagen 4, its latest image generation model. According to Google, Imagen 4 provides richer details and better visuals. In addition, Imagen 4 is apparently much better at generating text and typography in its graphics. This is an area which AI models are notoriously bad at, so Imagen 4 appears to be a big step forward. Flow AI video tool Credit: Google A new video generation model, Veo 3, was also unveiled with a video generation tool called Flow. Google claims Veo 3 has a stronger understanding of physics when generating scenes and can also create accompanying sound effects, background noise, and dialogue.  Both Veo 3 and Flow are available today alongside a new generative music model called Lyria 2.Google I/O also saw the debut of Gemini Canvas, which Google describes as a co-creation platform.Project Starline aka Google BeamAnother big announcement out of Google I/O: Project Starline is no more.Google's immersive communication project will now be known as Google Beam, an AI-first communication platform.As part of Google Beam, Google announced Google Meet translations, which basically provides real-time speech translation during meetings on the platform. AI will be able to match a speaker's voice and tone, so it sounds like the translation is coming directly from them. Google Meet translations are available in English and Spanish starting today with more language on the way in the coming weeks. Google Meet translations Credit: Google Google also had another work-in-progress project to tease under Google Beam: A 3-D conferencing platform that uses multiple cameras to capture a user from different angles in order to render the individual on a 3-D light-field display.Project AstraWhile Project Starline may have undergone a name change, it appears Project Astra is still kicking it at Google, at least for now.Project Astra is Google's real-world universal AI assistant and Google had plenty to announce as part of it.Gemini Live is a new AI assistant feature that can interact with a user's surroundings via their mobile device's camera and audio input. Users can ask Gemini Live questions about what they're capturing on camera and the AI assistant will be able to answer queries based on those visuals. According to Google, Gemini Live is rolling out today to Gemini users. Gemini Live Credit: Google It appears Google has plans to implement Project Astra's live AI capabilities into Google Search's AI mode as a Google Lens visual search enhancement.Google also highlighted some of its hopes for Gemini Live, such as being able to help as an accessibility tool for those with disabilities.Project MarinerAnother one of Google's AI projects is an AI agent that can interact with the web in order to complete tasks for the user known as Project Mariner. While Project Mariner was previously announced late last year, Google had some updates such as a multi-tasking feature which would allow an AI agent to work on up to 10 different tasks simultaneously. Another new feature is Teach and Repeat, which would provide the AI agent with the ability to learn from previously completed tasks in order to complete similar ones without the need for the same detailed direction in the future.Google announced plans to bring these agentic AI capabilities to Chrome, Google Search via AI Mode, and the Gemini app. These newsletters may contain advertising, deals, or affiliate links. By clicking Subscribe, you confirm you are 16+ and agree to our Terms of Use and Privacy Policy.",
  "image": "https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/hero-image.fill.size_1200x675.v1747777294.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003csection data-ga-module=\"content_body\"\u003e\n                        \u003cdiv\u003e\n                \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/hero-image.fill.size_1248x702.v1747777294.png\" alt=\"Google I/O\" width=\"1248\" height=\"702\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/hero-image.fill.size_400x225.v1747777294.png 400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/hero-image.fill.size_800x450.v1747777294.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/hero-image.fill.size_1248x702.v1747777294.png 1600w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eGoogle imagines a world powered by artificial intelligence.\u003c/span\u003e\n                \n                                    \u003cspan\u003eCredit: Google\u003c/span\u003e\n                            \u003c/p\u003e\n                        \u003c/div\u003e\n\n    \n    \n    \n            \u003carticle id=\"article\" data-autopogo=\"\"\u003e\n                                    \u003cp\u003eFrom the opening AI-influenced intro video set to \u0026#34;You Get What You Give\u0026#34; by New Radicals to CEO Sundar Pichai\u0026#39;s sign-off, \u003ca href=\"https://www.youtube.com/watch?v=o8NiE3XMPrM\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\" title=\"(opens in a new window)\"\u003eGoogle I/O 2025\u003c/a\u003e was packed with news and updates for the tech giant and its products. And when we say packed, we mean it, as this year\u0026#39;s Google I/O clocked in at nearly \u003cem\u003etwo hours long\u003c/em\u003e. \u003c/p\u003e\u003cp\u003eDuring that time, Google shared some big wins for its AI products, such as Gemini topping various categories on the \u003ca href=\"https://lmarena.ai/\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\" title=\"(opens in a new window)\"\u003eLMArena leaderboard\u003c/a\u003e. Another example that Google seemed really proud of was the fact that Gemini completed Pokémon Blue a few weeks ago.\u003c/p\u003e\u003cp\u003eBut, we know what you\u0026#39;re really here for: Product updates and new product announcements.\u003c/p\u003e\n\u003cp\u003eAside from a few braggadocious moments, Google spent most of those 117 minutes talking about what\u0026#39;s coming out next. Google I/O mixes consumer-facing product announcements with more developer-oriented ones, from the latest Gmail updates to Google\u0026#39;s powerful new chip, Ironwood, coming to Google Cloud customers later this year.\u003c/p\u003e\n\n\n\u003cp\u003eWe\u0026#39;re going to break down what product updates and announcements you need to know from the full two-hour event, so you can walk away with all the takeaways without spending the same time it takes to watch a major motion picture to learn about them.\u003c/p\u003e\u003cp\u003eBefore we dive in though, here\u0026#39;s the most shocking news out of Google I/O: The subscription pricing that Google has for its \u003ca href=\"https://mashable.com/article/google-io-ai-ultra-subscription-plan\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003eGoogle AI Ultra plan\u003c/a\u003e. While Google provides a base subscription at $19.99 per month, the Ultra plan comes in at a whopping $249.99 per month for its entire suite of products with the highest rate limits available.\u003c/p\u003e\u003ch2\u003eGoogle Search AI Mode\u003c/h2\u003e\u003cp\u003eGoogle tucked away what will easily be its most visible feature way too far back into the event, but we\u0026#39;ll surface it to the top.\u003c/p\u003e\u003cp\u003eAt Google I/O, Google announced that the \u003ca href=\"https://mashable.com/article/google-ai-mode-launch\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003enew AI Mode feature for Google Search\u003c/a\u003e is launching today to everyone in the United States. Basically, it will allow users to use Google\u0026#39;s search feature but with longer, more complex queries. Using a \u0026#34;query fan-out technique,\u0026#34; AI Mode will be able to break a search into multiple parts in order to process each part of the query, then pull all the information together to present to the user. Google says AI Mode \u0026#34;checks its work\u0026#34; too, but its unclear at this time exactly what that means.\u003c/p\u003e\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-4.fill.size_2000x1123.v1747777295.png\" alt=\"Google announces AI Mode in Google Search\" width=\"2000\" height=\"1123\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-4.fill.size_800x449.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-4.fill.size_1400x786.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-4.fill.size_2000x1123.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003eGoogle announces AI Mode in Google Search\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eAI Mode is available now. Later in the summer, Google will launch Personal Context in AI Mode, which will make suggestions based on a user\u0026#39;s past searches and other contextual information about the user from other Google products like Gmail. \u003c/p\u003e\u003cp\u003eIn addition, other new features will soon come to AI Mode, such as Deep Search, which can dive deeper into queries by searching through multiple websites, and data visualization features, which can take the search results and present them in a visual graph when applicable.\u003c/p\u003e\u003cp\u003eAccording to Google, its AI overviews in search are viewed by 1.5 billion users every month, so AI Mode clearly has the largest potential user base out of all of Google\u0026#39;s announcements today.\u003c/p\u003e\u003ch2\u003eAI Shopping\u003c/h2\u003e\u003cp\u003eOut of all the announcements at the event, these AI shopping features seemed to spark the biggest reaction from Google I/O live attendees.\u003c/p\u003e\u003cp\u003eConnected to AI Mode, Google \u003ca href=\"https://mashable.com/article/google-io-2025-try-it-on-ai-mode-shopping-tool\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003eshowed off its Shopping Graph\u003c/a\u003e, which includes more than 50 billion products globally. Users can just describe the type of product they are looking for – say a specific type of couch, and Google will present options that match that description.\u003c/p\u003e\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-3.fill.size_2000x1071.v1747777295.png\" alt=\"Google AI Shopping\" width=\"2000\" height=\"1071\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-3.fill.size_800x429.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-3.fill.size_1400x750.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-3.fill.size_2000x1071.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003eGoogle AI Shopping\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eGoogle also had a significant presentation that showed its presenter upload a photo of themselves so that AI could create a visual of what she\u0026#39;d look like in a dress. This virtual try-on feature will be available in Google Labs, and it\u0026#39;s the IRL version of Cher\u0026#39;s \u003cem\u003eClueless \u003c/em\u003ecloset.\u003c/p\u003e\u003cp\u003eThe presenter was then able to use an AI shopping agent to keep tabs on the item\u0026#39;s availability and track its price. When the price dropped, the user received a notification of the pricing change.\u003c/p\u003e\u003cp\u003eGoogle said users will be able to try on different looks via AI in Google Labs starting today.\u003c/p\u003e\u003ch2\u003eAndroid XR\u003c/h2\u003e\u003cp\u003eGoogle\u0026#39;s long-awaited post-Google Glass AR/VR plans were finally presented at Google I/O. The company also unveiled a number of wearable products utilizing its AR/VR operating system, Android XR.\u003c/p\u003e\u003cp\u003eOne important part of the Android XR announcement is that Google seems to understand the different use cases for an immersive headset and an on-the-go pair of smartglasses and have built Android XR to accommodate that.\u003c/p\u003e\u003cp\u003eWhile Samsung has previously teased its \u003ca href=\"https://mashable.com/article/samsung-unpacked-xr-headset-project-moohan-teased\" target=\"_blank\" data-ga-click=\"1\" data-ga-label=\"$text\" data-ga-item=\"text-link\" data-ga-module=\"content_body\"\u003e\u003cu\u003eProject Moohan\u003c/u\u003e\u003c/a\u003e XR headset, Google I/O marked the first time that Google revealed the product, which is being built in partnership with the mobile giant and chipmaker Qualcomm. Google shared that the Project Moohan headset should be available later this year.\u003c/p\u003e\u003csection x-data=\"window.newsletter()\" x-init=\"init()\" data-ga-impression=\"\" data-ga-category=\"newsletters\" data-ga-module=\"incontent_nl_signup\" data-ga-label=\"mashablelightspeed\"\u003e\n        \u003cp\u003e\n            Mashable Light Speed\n        \u003c/p\u003e\n        \n        \n    \u003c/section\u003e\n\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-1.fill.size_2000x1127.v1747777295.png\" alt=\"Project Moohan\" width=\"2000\" height=\"1127\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-1.fill.size_800x451.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-1.fill.size_1400x789.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-1.fill.size_2000x1127.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003e Project Moohan\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eIn addition to the XR headset, Google announced Glasses with Android XR, smartglasses that incorporate a camera, speakers, and in-lens display that connect with a user\u0026#39;s smartphone. Unlike Google Glass, these smart glasses will incorporate more fashionable looks thanks to partnerships with Gentle Monster and Warby Parker.\u003c/p\u003e\u003cp\u003eGoogle shared that developers will be able to start developing for Glasses starting next year, so it\u0026#39;s likely that a release date for the smartglasses will follow after that.\u003c/p\u003e\u003ch2\u003eGemini\u003c/h2\u003e\u003cp\u003eEasily the star of Google I/O 2025 was the company\u0026#39;s AI model, Gemini. Google announced a new updated \u003cstrong\u003eGemini 2.5 Pro\u003c/strong\u003e, which it says is its most powerful model yet. The company showed Gemini 2.5 Pro being used to turn sketches into full applications in a demo. Along with that, Google introduced \u003cstrong\u003eGemini 2.5 Flash\u003c/strong\u003e, which is a more affordable version of the powerful Pro model. The latter will be released in early June with the former coming out soon after. Google also revealed \u003cstrong\u003eGemini 2.5 Pro Deep Think\u003c/strong\u003e for complex math and coding, which will only be available to \u0026#34;trusted testers\u0026#34; at first.\u003c/p\u003e\u003cp\u003eSpeaking of coding, Google shared its asynchronous coding agent \u003cstrong\u003eJules\u003c/strong\u003e, which is currently in public beta. Developers will be able to utilize Jules in order to tackle codebase tasks and modify files.\u003c/p\u003e\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-7.fill.size_2000x1126.v1747777295.png\" alt=\"Jules coding agent\" width=\"2000\" height=\"1126\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-7.fill.size_800x450.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-7.fill.size_1400x788.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-7.fill.size_2000x1126.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003eJules coding agent\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eDevelopers will also have access to a new Native Audio Output text-to-speech model which can replicate the same voice in different languages.\u003c/p\u003e\u003cp\u003eThe Gemini app will soon see a new Agent Mode, bringing users an AI agent who can research and complete tasks based on a user\u0026#39;s prompts.\u003c/p\u003e\u003cp\u003eGemini will also be deeply integrated into Google products like Workspace with \u003cstrong\u003ePersonalized Smart Replies\u003c/strong\u003e. Gemini will use personal context via documents, emails, and more from across a user\u0026#39;s Google apps in order to match their tone, voice, and style in order to generate automatic replies. Workspace users will find the feature available in Gmail this summer.\u003c/p\u003e\u003cp\u003eOther features announced for Gemini include \u003cstrong\u003eDeep Research\u003c/strong\u003e, which lets users upload their own files to guide the AI agent when asking questions, and \u003cstrong\u003eGemini in Chrome\u003c/strong\u003e, an AI Assistant that answers queries using the context on the web page that a user is on. The latter feature is rolling out this week for Gemini subscribers in the U.S.\u003c/p\u003e\u003cp\u003eGoogle intends to bring Gemini to all of its devices, including smartwatches, smart cars, and smart TVs.\u003c/p\u003e\u003ch2\u003eGenerative AI updates\u003c/h2\u003e\u003cp\u003eGemini\u0026#39;s AI assistant capabilities and language model updates were only a small piece of Google\u0026#39;s broader AI puzzle. The company had a slew of generative AI announcements to make too.\u003c/p\u003e\u003cp\u003eGoogle announced \u003cstrong\u003eImagen 4\u003c/strong\u003e, its latest image generation model. According to Google, Imagen 4 provides richer details and better visuals. In addition, Imagen 4 is apparently much better at generating text and typography in its graphics. This is an area which AI models are notoriously bad at, so Imagen 4 appears to be a big step forward.\u003c/p\u003e\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-2.fill.size_2000x1013.v1747777295.png\" alt=\"Flow AI video tool\" width=\"2000\" height=\"1013\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-2.fill.size_800x405.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-2.fill.size_1400x709.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-2.fill.size_2000x1013.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003eFlow AI video tool\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eA new video generation model, \u003cstrong\u003eVeo 3\u003c/strong\u003e, was also unveiled with a video generation tool called \u003cstrong\u003eFlow\u003c/strong\u003e. Google claims Veo 3 has a stronger understanding of physics when generating scenes and can also create accompanying sound effects, background noise, and dialogue. \u003c/p\u003e\n\u003cp\u003eBoth Veo 3 and Flow are available today alongside a new generative music model called \u003cstrong\u003eLyria 2\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eGoogle I/O also saw the debut of \u003cstrong\u003eGemini Canvas\u003c/strong\u003e, which Google describes as a co-creation platform.\u003c/p\u003e\u003ch2\u003eProject Starline aka Google Beam\u003c/h2\u003e\u003cp\u003eAnother big announcement out of Google I/O: Project Starline is no more.\u003c/p\u003e\u003cp\u003eGoogle\u0026#39;s immersive communication project will now be known as Google Beam, an AI-first communication platform.\u003c/p\u003e\u003cp\u003eAs part of Google Beam, Google announced Google Meet translations, which basically provides real-time speech translation during meetings on the platform. AI will be able to match a speaker\u0026#39;s voice and tone, so it sounds like the translation is coming directly from them. Google Meet translations are available in English and Spanish starting today with more language on the way in the coming weeks.\u003c/p\u003e\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-6.fill.size_2000x1120.v1747777295.png\" alt=\"Google Meet translations\" width=\"2000\" height=\"1120\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-6.fill.size_800x448.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-6.fill.size_1400x784.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-6.fill.size_2000x1120.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003eGoogle Meet translations\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eGoogle also had another work-in-progress project to tease under Google Beam: A 3-D conferencing platform that uses multiple cameras to capture a user from different angles in order to render the individual on a 3-D light-field display.\u003c/p\u003e\u003ch2\u003eProject Astra\u003c/h2\u003e\u003cp\u003eWhile Project Starline may have undergone a name change, it appears Project Astra is still kicking it at Google, at least for now.\u003c/p\u003e\u003cp\u003eProject Astra is Google\u0026#39;s real-world universal AI assistant and Google had plenty to announce as part of it.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGemini Live\u003c/strong\u003e is a new AI assistant feature that can interact with a user\u0026#39;s surroundings via their mobile device\u0026#39;s camera and audio input. Users can ask Gemini Live questions about what they\u0026#39;re capturing on camera and the AI assistant will be able to answer queries based on those visuals. According to Google, Gemini Live is rolling out today to Gemini users.\u003c/p\u003e\u003cdiv\u003e\n    \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-5.fill.size_2000x1123.v1747777295.png\" alt=\"Gemini Live\" width=\"2000\" height=\"1123\" loading=\"lazy\" srcset=\"https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-5.fill.size_800x449.v1747777295.png 800w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-5.fill.size_1400x786.v1747777295.png 1400w, https://helios-i.mashable.com/imagery/articles/05Z3MBAskYfvvcvg0b34Ecn/images-5.fill.size_2000x1123.v1747777295.png 2000w\" sizes=\"(max-width: 1408px) 100vw, 1408px\"/\u003e\n\n\n            \u003c/p\u003e\n            \u003cp\u003e\u003cspan\u003eGemini Live\u003c/span\u003e\n            \u003cspan\u003eCredit: Google\u003c/span\u003e\n        \u003c/p\u003e\n    \u003c/div\u003e\n\u003cp\u003eIt appears Google has plans to implement Project Astra\u0026#39;s live AI capabilities into Google Search\u0026#39;s AI mode as a Google Lens visual search enhancement.\u003c/p\u003e\u003cp\u003eGoogle also highlighted some of its hopes for Gemini Live, such as being able to help as an accessibility tool for those with disabilities.\u003c/p\u003e\u003ch2\u003eProject Mariner\u003c/h2\u003e\u003cp\u003eAnother one of Google\u0026#39;s AI projects is an AI agent that can interact with the web in order to complete tasks for the user known as Project Mariner. \u003c/p\u003e\u003cp\u003eWhile Project Mariner was previously announced late last year, Google had some updates such as a multi-tasking feature which would allow an AI agent to work on up to 10 different tasks simultaneously. Another new feature is Teach and Repeat, which would provide the AI agent with the ability to learn from previously completed tasks in order to complete similar ones without the need for the same detailed direction in the future.\u003c/p\u003e\u003cp\u003eGoogle announced plans to bring these agentic AI capabilities to Chrome, Google Search via AI Mode, and the Gemini app.\u003c/p\u003e\n\n                                        \n                    \u003c/article\u003e\n    \n    \n    \n        \n        \n                    \u003c/section\u003e\u003csection data-ga-module=\"content_body\"\u003e\n        \n\n    \n    \u003csection\u003e\n                                    \u003chr/\u003e\n            \n                            \n                                    \u003cdiv data-module=\"content-list\" data-ga-module=\"chartbeat-recirc\" data-ga-element=\"content-stripe\" data-ga-action=\"content-stripe\"\u003e\n                            \n                                                    \u003chr/\u003e\n                                            \u003cdiv data-ga-position=\"2\"\u003e\n    \n    \u003ca data-ga-click=\"\" data-ga-item=\"image\" data-ga-label=\"NYT Connections hints today: Clues, answers for May 20, 2025\" href=\"https://mashable.com/article/nyt-connections-hint-answer-today-may-20-2025\"\u003e\n        \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/03tZsCZhBDFN9WP14qzKIPi/hero-image.fill.size_220x133.v1747667095.jpg\" alt=\"Connections game on a smartphone\" width=\"220\" height=\"133\" loading=\"lazy\"/\u003e\n\n\n        \u003c/p\u003e\n        \u003cp\u003e\u003cimg src=\"https://helios-i.mashable.com/imagery/articles/03tZsCZhBDFN9WP14qzKIPi/hero-image.fill.size_220x220.v1747667095.jpg\" alt=\"Connections game on a smartphone\" width=\"220\" height=\"220\" loading=\"lazy\"/\u003e\n\n\n        \u003c/p\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n                                                    \u003chr/\u003e\n                                            \n                                                    \u003chr/\u003e\n                                            \n                                                    \u003chr/\u003e\n                                            \n                                                    \u003c/div\u003e\n                                \u003c/section\u003e\n    \u003c/section\u003e\u003cdiv x-data=\"window.newsletter()\" x-init=\"init()\" data-ga-impression=\"\" data-ga-category=\"newsletters\" data-ga-module=\"footer_nl_signup\" data-ga-label=\"Top Stories\"\u003e\n    \n\n    \u003cp\u003e\n        These newsletters may contain advertising, deals, or affiliate links. By clicking Subscribe, you confirm you are 16+ and agree to our \u003ca href=\"https://www.ziffdavis.com/terms-of-use\" target=\"_blank\" rel=\"noopener\" title=\"(opens in a new window)\"\u003eTerms of Use\u003c/a\u003e and \u003ca href=\"https://www.ziffdavis.com/ztg-privacy-policy\" target=\"_blank\" rel=\"noopener\" title=\"(opens in a new window)\"\u003ePrivacy Policy\u003c/a\u003e.\n    \u003c/p\u003e\n    \n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "14 min read",
  "publishedTime": "2025-05-20T22:37:43Z",
  "modifiedTime": null
}
