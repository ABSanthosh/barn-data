{
  "id": "e0d050a8-4ebe-4de6-85d6-7524592dc20a",
  "title": "Open Source devs say AI crawlers dominate traffic, forcing blocks on entire countries",
  "link": "https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/",
  "description": "AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back.",
  "author": "Benj Edwards",
  "published": "Tue, 25 Mar 2025 21:36:58 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Biz \u0026 IT",
    "DDoS",
    "machine learning"
  ],
  "byline": "Benj Edwards",
  "length": 11613,
  "excerpt": "AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back. Software developer Xe Iaso reached a breaking point earlier this year when aggressive AI crawler traffic from Amazon overwhelmed their Git repository service, repeatedly causing instability and downtime. Despite configuring standard defensive measures—adjusting robots.txt, blocking known crawler user-agents, and filtering suspicious traffic—Iaso found that AI crawlers continued evading all attempts to stop them, spoofing user-agents and cycling through residential IP addresses as proxies. Desperate for a solution, Iaso eventually resorted to moving their server behind a VPN and creating \"Anubis,\" a custom-built proof-of-work challenge system that forces web browsers to solve computational puzzles before accessing the site. \"It's futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more,\" Iaso wrote in a blog post titled \"a desperate cry for help.\" \"I don't want to have to close off my Gitea server to the public, but I will if I have to.\" Iaso's story highlights a broader crisis rapidly spreading across the open source community, as what appear to be aggressive AI crawlers increasingly overload community-maintained infrastructure, causing what amounts to persistent distributed denial-of-service (DDoS) attacks on vital public resources. According to a comprehensive recent report from LibreNews, some open source projects now see as much as 97 percent of their traffic originating from AI companies' bots, dramatically increasing bandwidth costs, service instability, and burdening already stretched-thin maintainers. Kevin Fenzi, a member of the Fedora Pagure project's sysadmin team, reported on his blog that the project had to block all traffic from Brazil after repeated attempts to mitigate bot traffic failed. GNOME GitLab implemented Iaso's \"Anubis\" system, requiring browsers to solve computational puzzles before accessing content. GNOME sysadmin Bart Piotrowski shared on Mastodon that only about 3.2 percent of requests (2,690 out of 84,056) passed their challenge system, suggesting the vast majority of traffic was automated. KDE's GitLab infrastructure was temporarily knocked offline by crawler traffic originating from Alibaba IP ranges, according to LibreNews, citing a KDE Development chat. While Anubis has proven effective at filtering out bot traffic, it comes with drawbacks for legitimate users. When many people access the same link simultaneously—such as when a GitLab link is shared in a chat room—site visitors can face significant delays. Some mobile users have reported waiting up to two minutes for the proof-of-work challenge to complete, according to the news outlet. The situation isn't exactly new. In December, Dennis Schubert, who maintains infrastructure for the Diaspora social network, described the situation as \"literally a DDoS on the entire internet\" after discovering that AI companies accounted for 70 percent of all web requests to their services. The costs are both technical and financial. The Read the Docs project reported that blocking AI crawlers immediately decreased their traffic by 75 percent, going from 800GB per day to 200GB per day. This change saved the project approximately $1,500 per month in bandwidth costs, according to their blog post \"AI crawlers need to be more respectful.\" A disproportionate burden on open source The situation has created a tough challenge for open source projects, which rely on public collaboration and typically operate with limited resources compared to commercial entities. Many maintainers have reported that AI crawlers deliberately circumvent standard blocking measures, ignoring robots.txt directives, spoofing user agents, and rotating IP addresses to avoid detection. As LibreNews reported, Martin Owens from the Inkscape project noted on Mastodon that their problems weren't just from \"the usual Chinese DDoS from last year, but from a pile of companies that started ignoring our spider conf and started spoofing their browser info.\" Owens added, \"I now have a prodigious block list. If you happen to work for a big company doing AI, you may not get our website anymore.\" On Hacker News, commenters in threads about the LibreNews post last week and a post on Iaso's battles in January expressed deep frustration with what they view as AI companies' predatory behavior toward open source infrastructure. While these comments come from forum posts rather than official statements, they represent a common sentiment among developers. As one Hacker News user put it, AI firms are operating from a position that \"goodwill is irrelevant\" with their \"$100bn pile of capital.\" The discussions depict a battle between smaller AI startups that have worked collaboratively with affected projects and larger corporations that have been unresponsive despite allegedly forcing thousands of dollars in bandwidth costs on open source project maintainers. Beyond consuming bandwidth, the crawlers often hit expensive endpoints, like git blame and log pages, placing additional strain on already limited resources. Drew DeVault, founder of SourceHut, reported on his blog that the crawlers access \"every page of every git log, and every commit in your repository,\" making the attacks particularly burdensome for code repositories. The problem extends beyond infrastructure strain. As LibreNews points out, some open source projects began receiving AI-generated bug reports as early as December 2023, first reported by Daniel Stenberg of the Curl project on his blog in a post from January 2024. These reports appear legitimate at first glance but contain fabricated vulnerabilities, wasting valuable developer time. Who is responsible, and why are they doing this? AI companies have a history of taking without asking. Before the mainstream breakout of AI image generators and ChatGPT attracted attention to the practice in 2022, the machine learning field regularly compiled datasets with little regard to ownership. While many AI companies engage in web crawling, the sources suggest varying levels of responsibility and impact. Dennis Schubert's analysis of Diaspora's traffic logs showed that approximately one-fourth of its web traffic came from bots with an OpenAI user agent, while Amazon accounted for 15 percent and Anthropic for 4.3 percent. The crawlers' behavior suggests different possible motivations. Some may be collecting training data to build or refine large language models, while others could be executing real-time searches when users ask AI assistants for information. The frequency of these crawls is particularly telling. Schubert observed that AI crawlers \"don't just crawl a page once and then move on. Oh, no, they come back every 6 hours because lol why not.\" This pattern suggests ongoing data collection rather than one-time training exercises, potentially indicating that companies are using these crawls to keep their models' knowledge current. Some companies appear more aggressive than others. KDE's sysadmin team reported that crawlers from Alibaba IP ranges were responsible for temporarily knocking their GitLab offline. Meanwhile, Iaso's troubles came from Amazon's crawler. A member of KDE's sysadmin team told LibreNews that Western LLM operators like OpenAI and Anthropic were at least setting proper user agent strings (which theoretically allows websites to block them), while some Chinese AI companies were reportedly more deceptive in their approaches. It remains unclear why these companies don't adopt more collaborative approaches and, at a minimum, rate-limit their data harvesting runs so they don't overwhelm source websites. Amazon, OpenAI, Anthropic, and Meta did not immediately respond to requests for comment, but we will update this piece if they reply. Tarpits and labyrinths: The growing resistance In response to these attacks, new defensive tools have emerged to protect websites from unwanted AI crawlers. As Ars reported in January, an anonymous creator identified only as \"Aaron\" designed a tool called \"Nepenthes\" to trap crawlers in endless mazes of fake content. Aaron explicitly describes it as \"aggressive malware\" intended to waste AI companies' resources and potentially poison their training data. \"Any time one of these crawlers pulls from my tarpit, it's resources they've consumed and will have to pay hard cash for,\" Aaron explained to Ars. \"It effectively raises their costs. And seeing how none of them have turned a profit yet, that's a big problem for them.\" On Friday, Cloudflare announced \"AI Labyrinth,\" a similar but more commercially polished approach. Unlike Nepenthes, which is designed as an offensive weapon against AI companies, Cloudflare positions its tool as a legitimate security feature to protect website owners from unauthorized scraping, as we reported at the time. \"When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them,\" Cloudflare explained in its announcement. The company reported that AI crawlers generate over 50 billion requests to their network daily, accounting for nearly 1 percent of all web traffic they process. The community is also developing collaborative tools to help protect against these crawlers. The \"ai.robots.txt\" project offers an open list of web crawlers associated with AI companies and provides premade robots.txt files that implement the Robots Exclusion Protocol, as well as .htaccess files that return error pages when detecting AI crawler requests. As it currently stands, both the rapid growth of AI-generated content overwhelming online spaces and aggressive web-crawling practices by AI firms threaten the sustainability of essential online resources. The current approach taken by some large AI companies—extracting vast amounts of data from open-source projects without clear consent or compensation—risks severely damaging the very digital ecosystem on which these AI models depend. Responsible data collection may be achievable if AI firms collaborate directly with the affected communities. However, prominent industry players have shown little incentive to adopt more cooperative practices. Without meaningful regulation or self-restraint by AI firms, the arms race between data-hungry bots and those attempting to defend open source infrastructure seems likely to escalate further, potentially deepening the crisis for the digital ecosystem that underpins the modern Internet. Benj Edwards is Ars Technica's Senior AI Reporter and founder of the site's dedicated AI beat in 2022. He's also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC. 49 Comments",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/flood_header-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n            \u003carticle data-id=\"2084217\"\u003e\n  \n  \u003cheader\u003e\n  \u003cdiv\u003e\n      \n\n      \n\n      \u003cp\u003e\n        AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back.\n      \u003c/p\u003e\n\n      \n    \u003c/div\u003e\n\u003c/header\u003e\n\n\n  \n\n  \n      \n    \n    \u003cdiv\u003e\n                      \n                      \n          \n\u003cp\u003eSoftware developer Xe Iaso \u003ca href=\"https://xeiaso.net/notes/2025/amazon-crawler/\"\u003ereached a breaking point\u003c/a\u003e earlier this year when aggressive AI crawler traffic from Amazon overwhelmed their Git repository service, repeatedly causing instability and downtime. Despite configuring standard defensive measures—adjusting robots.txt, blocking known crawler user-agents, and filtering suspicious traffic—Iaso found that AI crawlers continued evading all attempts to stop them, spoofing user-agents and cycling through residential IP addresses as proxies.\u003c/p\u003e\n\u003cp\u003eDesperate for a solution, Iaso eventually resorted to moving their server behind a VPN and creating \u0026#34;Anubis,\u0026#34; a custom-built proof-of-work challenge system that forces web browsers to solve computational puzzles before accessing the site. \u0026#34;It\u0026#39;s futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more,\u0026#34; Iaso wrote in a \u003ca href=\"https://xeiaso.net/notes/2025/amazon-crawler/\"\u003eblog post\u003c/a\u003e titled \u0026#34;a desperate cry for help.\u0026#34; \u0026#34;I don\u0026#39;t want to have to close off my Gitea server to the public, but I will if I have to.\u0026#34;\u003c/p\u003e\n\u003cp\u003eIaso\u0026#39;s story highlights a broader crisis rapidly spreading across the open source community, as what appear to be aggressive AI crawlers increasingly overload community-maintained infrastructure, causing what amounts to persistent distributed denial-of-service (DDoS) attacks on vital public resources. According to a \u003ca href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\"\u003ecomprehensive recent report\u003c/a\u003e from LibreNews, some open source projects now see as much as 97 percent of their traffic originating from AI companies\u0026#39; bots, dramatically increasing bandwidth costs, service instability, and burdening already stretched-thin maintainers.\u003c/p\u003e\n\u003cp\u003eKevin Fenzi, a member of the Fedora Pagure project\u0026#39;s sysadmin team, \u003ca href=\"https://www.scrye.com/blogs/nirik/posts/2025/03/15/mid-march-infra-bits-2025/\"\u003ereported on his blog\u003c/a\u003e that the project had to block all traffic from Brazil after repeated attempts to mitigate bot traffic failed. GNOME GitLab implemented Iaso\u0026#39;s \u0026#34;Anubis\u0026#34; system, requiring browsers to solve computational puzzles before accessing content. GNOME sysadmin Bart Piotrowski \u003ca href=\"https://social.treehouse.systems/@barthalion/114190930216801561\"\u003eshared\u003c/a\u003e on Mastodon that only about 3.2 percent of requests (2,690 out of 84,056) passed their challenge system, suggesting the vast majority of traffic was automated. KDE\u0026#39;s GitLab infrastructure was temporarily knocked offline by crawler traffic originating from Alibaba IP ranges, according to LibreNews, citing a KDE Development chat.\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eWhile Anubis has proven effective at filtering out bot traffic, it comes with drawbacks for legitimate users. When many people access the same link simultaneously—such as when a GitLab link is shared in a chat room—site visitors can face significant delays. Some mobile users have reported waiting up to two minutes for the proof-of-work challenge to complete, according to the news outlet.\u003c/p\u003e\n\u003cp\u003eThe situation isn\u0026#39;t exactly new. In December, Dennis Schubert, who maintains infrastructure for the Diaspora social network, \u003ca href=\"https://pod.geraspora.de/posts/17342163\"\u003edescribed\u003c/a\u003e the situation as \u0026#34;literally a DDoS on the entire internet\u0026#34; after discovering that AI companies accounted for 70 percent of all web requests to their services.\u003c/p\u003e\n\u003cp\u003eThe costs are both technical and financial. The Read the Docs project reported that blocking AI crawlers immediately decreased their traffic by 75 percent, going from 800GB per day to 200GB per day. This change saved the project approximately $1,500 per month in bandwidth costs, according to their blog post \u0026#34;AI crawlers need to be more respectful.\u0026#34;\u003c/p\u003e\n\u003ch2\u003eA disproportionate burden on open source\u003c/h2\u003e\n\u003cp\u003eThe situation has created a tough challenge for open source projects, which rely on public collaboration and typically operate with limited resources compared to commercial entities. Many maintainers have reported that AI crawlers deliberately circumvent standard blocking measures, ignoring robots.txt directives, spoofing user agents, and rotating IP addresses to avoid detection.\u003c/p\u003e\n\u003cp\u003eAs LibreNews reported, Martin Owens from the Inkscape project \u003ca href=\"https://floss.social/@doctormo/114191332274003577\"\u003enoted\u003c/a\u003e on Mastodon that their problems weren\u0026#39;t just from \u0026#34;the usual Chinese DDoS from last year, but from a pile of companies that started ignoring our spider conf and started spoofing their browser info.\u0026#34; Owens added, \u0026#34;I now have a prodigious block list. If you happen to work for a big company doing AI, you may not get our website anymore.\u0026#34;\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eOn Hacker News, commenters in threads \u003ca href=\"https://news.ycombinator.com/item?id=43422413\"\u003eabout the LibreNews\u003c/a\u003e post last week and a \u003ca href=\"https://news.ycombinator.com/item?id=42750420\"\u003epost on Iaso\u0026#39;s battles\u003c/a\u003e in January expressed deep frustration with what they view as AI companies\u0026#39; predatory behavior toward open source infrastructure. While these comments come from forum posts rather than official statements, they represent a common sentiment among developers.\u003c/p\u003e\n\u003cp\u003eAs one Hacker News user \u003ca href=\"https://news.ycombinator.com/item?id=43422792\"\u003eput it\u003c/a\u003e, AI firms are operating from a position that \u0026#34;goodwill is irrelevant\u0026#34; with their \u0026#34;$100bn pile of capital.\u0026#34; The discussions depict a battle between smaller AI startups that have worked collaboratively with affected projects and larger corporations that have been unresponsive despite allegedly forcing thousands of dollars in bandwidth costs on open source project maintainers.\u003c/p\u003e\n\u003cp\u003eBeyond consuming bandwidth, the crawlers often hit expensive endpoints, like git blame and log pages, placing additional strain on already limited resources. Drew DeVault, founder of SourceHut, \u003ca href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\"\u003ereported on his blog\u003c/a\u003e that the crawlers access \u0026#34;every page of every git log, and every commit in your repository,\u0026#34; making the attacks particularly burdensome for code repositories.\u003c/p\u003e\n\u003cp\u003eThe problem extends beyond infrastructure strain. As LibreNews points out, some open source projects began receiving AI-generated bug reports as early as December 2023, first \u003ca href=\"https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-for-intelligence/\"\u003ereported\u003c/a\u003e by Daniel Stenberg of the Curl project on his blog in a post from January 2024. These reports appear legitimate at first glance but contain fabricated vulnerabilities, wasting valuable developer time.\u003c/p\u003e\n\n\u003ch2\u003eWho is responsible, and why are they doing this?\u003c/h2\u003e\n\u003cp\u003eAI companies have a history of taking without asking. Before the mainstream breakout of AI image generators and ChatGPT attracted attention to the practice in 2022, the machine learning field regularly compiled datasets with little regard to ownership.\u003c/p\u003e\n\u003cp\u003eWhile many AI companies engage in web crawling, the sources suggest varying levels of responsibility and impact. Dennis Schubert\u0026#39;s \u003ca href=\"https://pod.geraspora.de/posts/17342163\"\u003eanalysis\u003c/a\u003e of Diaspora\u0026#39;s traffic logs showed that approximately one-fourth of its web traffic came from bots with an OpenAI user agent, while Amazon accounted for 15 percent and Anthropic for 4.3 percent.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eThe crawlers\u0026#39; behavior suggests different possible motivations. Some may be collecting training data to build or refine large language models, while others could be executing real-time searches when users ask AI assistants for information.\u003c/p\u003e\n\u003cp\u003eThe frequency of these crawls is particularly telling. Schubert observed that AI crawlers \u0026#34;don\u0026#39;t just crawl a page once and then move on. Oh, no, they come back every 6 hours because lol why not.\u0026#34; This pattern suggests ongoing data collection rather than one-time training exercises, potentially indicating that companies are using these crawls to keep their models\u0026#39; knowledge current.\u003c/p\u003e\n\u003cp\u003eSome companies appear more aggressive than others. KDE\u0026#39;s sysadmin team reported that crawlers from Alibaba IP ranges were responsible for temporarily knocking their GitLab offline. Meanwhile, Iaso\u0026#39;s troubles came from Amazon\u0026#39;s crawler. A member of KDE\u0026#39;s sysadmin team told LibreNews that Western LLM operators like OpenAI and Anthropic were at least setting proper user agent strings (which theoretically allows websites to \u003ca href=\"https://arstechnica.com/information-technology/2023/08/openai-details-how-to-keep-chatgpt-from-gobbling-up-website-data/\"\u003eblock them\u003c/a\u003e), while some Chinese AI companies were reportedly more deceptive in their approaches.\u003c/p\u003e\n\u003cp\u003eIt remains unclear why these companies don\u0026#39;t adopt more collaborative approaches and, at a minimum, rate-limit their data harvesting runs so they don\u0026#39;t overwhelm source websites. Amazon, OpenAI, Anthropic, and Meta did not immediately respond to requests for comment, but we will update this piece if they reply.\u003c/p\u003e\n\u003ch2\u003eTarpits and labyrinths: The growing resistance\u003c/h2\u003e\n\u003cp\u003eIn response to these attacks, new defensive tools have emerged to protect websites from unwanted AI crawlers. As Ars \u003ca href=\"https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/\"\u003ereported in January\u003c/a\u003e, an anonymous creator identified only as \u0026#34;Aaron\u0026#34; designed a tool called \u0026#34;Nepenthes\u0026#34; to trap crawlers in endless mazes of fake content. Aaron explicitly describes it as \u0026#34;aggressive malware\u0026#34; intended to waste AI companies\u0026#39; resources and potentially poison their training data.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n\n        \n        \u003cdiv\u003e\n          \n          \n\u003cp\u003e\u0026#34;Any time one of these crawlers pulls from my tarpit, it\u0026#39;s resources they\u0026#39;ve consumed and will have to pay hard cash for,\u0026#34; Aaron explained to Ars. \u0026#34;It effectively raises their costs. And seeing how none of them have turned a profit yet, that\u0026#39;s a big problem for them.\u0026#34;\u003c/p\u003e\n\u003cp\u003eOn Friday, Cloudflare \u003ca href=\"https://arstechnica.com/ai/2025/03/cloudflare-turns-ai-against-itself-with-endless-maze-of-irrelevant-facts/\"\u003eannounced\u003c/a\u003e \u0026#34;AI Labyrinth,\u0026#34; a similar but more commercially polished approach. Unlike Nepenthes, which is designed as an offensive weapon against AI companies, Cloudflare positions its tool as a legitimate security feature to protect website owners from unauthorized scraping, as we reported at the time.\u003c/p\u003e\n\u003cp\u003e\u0026#34;When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them,\u0026#34; Cloudflare explained in its announcement. The company reported that AI crawlers generate over 50 billion requests to their network daily, accounting for nearly 1 percent of all web traffic they process.\u003c/p\u003e\n\u003cp\u003eThe community is also developing collaborative tools to help protect against these crawlers. The \u0026#34;\u003ca href=\"https://github.com/ai-robots-txt/ai.robots.txt\"\u003eai.robots.txt\u003c/a\u003e\u0026#34; project offers an open list of web crawlers associated with AI companies and provides premade robots.txt files that implement the Robots Exclusion Protocol, as well as .htaccess files that return error pages when detecting AI crawler requests.\u003c/p\u003e\n\u003cp\u003eAs it currently stands, both the rapid growth of AI-generated content \u003ca href=\"https://www.404media.co/ai-slop-is-a-brute-force-attack-on-the-algorithms-that-control-reality/\"\u003eoverwhelming\u003c/a\u003e online spaces and aggressive web-crawling practices by AI firms threaten the sustainability of essential online resources. The current approach taken by some large AI companies—\u003ca href=\"https://www.vintagecomputing.com/index.php/archives/3292/the-pc-is-dead-its-time-to-make-computing-personal-again\"\u003eextracting\u003c/a\u003e vast amounts of data from open-source projects without clear consent or compensation—risks severely damaging the very digital ecosystem on which these AI models depend.\u003c/p\u003e\n\u003cp\u003eResponsible data collection may be achievable if AI firms collaborate directly with the affected communities. However, prominent industry players have shown little incentive to adopt more cooperative practices. Without meaningful regulation or self-restraint by AI firms, the arms race between data-hungry bots and those attempting to defend open source infrastructure seems likely to escalate further, potentially deepening the crisis for the digital ecosystem that underpins the modern Internet.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\n\n                  \n          \n\n\n\n\n\n\n  \u003cdiv\u003e\n  \u003cdiv\u003e\n          \u003cp\u003e\u003ca href=\"https://arstechnica.com/author/benjedwards/\"\u003e\u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2022/08/benj_ega.png\" alt=\"Photo of Benj Edwards\"/\u003e\u003c/a\u003e\u003c/p\u003e\n  \u003c/div\u003e\n\n  \u003cdiv\u003e\n    \n\n    \u003cp\u003e\n      Benj Edwards is Ars Technica\u0026#39;s Senior AI Reporter and founder of the site\u0026#39;s dedicated AI beat in 2022. He\u0026#39;s also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.\n    \u003c/p\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\n  \u003cp\u003e\n    \u003ca href=\"https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/#comments\" title=\"49 comments\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 80 80\"\u003e\u003cdefs\u003e\u003cclipPath id=\"bubble-zero_svg__a\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"bubble-zero_svg__b\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#bubble-zero_svg__a)\"\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#bubble-zero_svg__b)\"\u003e\u003cpath d=\"M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40\"\u003e\u003c/path\u003e\u003cpath d=\"M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n    49 Comments\n  \u003c/a\u003e\n      \u003c/p\u003e\n              \u003c/div\u003e\n  \u003c/article\u003e\n\n\n  \n\n\n  \n\n\n  \u003cdiv\u003e\n    \u003cheader\u003e\n      \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 26\"\u003e\u003cdefs\u003e\u003cclipPath id=\"most-read_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"most-read_svg__b\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#most-read_svg__a)\"\u003e\u003cg fill=\"none\" clip-path=\"url(#most-read_svg__b)\"\u003e\u003cpath fill=\"currentColor\" d=\"M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1\"\u003e\u003c/path\u003e\u003cpath fill=\"#ff4e00\" d=\"M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n      \n    \u003c/header\u003e\n    \u003col\u003e\n              \u003cli\u003e\n                      \u003ca href=\"https://arstechnica.com/space/2025/03/as-preps-continue-its-looking-more-likely-nasa-will-fly-the-artemis-ii-mission/\"\u003e\n              \u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/KSC-20250323-PH-FMX01_0159orig-copy-768x432.jpg\" alt=\"Listing image for first story in Most Read: As preps continue, it’s looking more likely that NASA will fly the Artemis II mission\" decoding=\"async\" loading=\"lazy\"/\u003e\n            \u003c/a\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                  \u003c/ol\u003e\n\u003c/div\u003e\n\n\n  \n\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "13 min read",
  "publishedTime": "2025-03-25T21:36:58Z",
  "modifiedTime": "2025-03-26T00:20:16Z"
}
