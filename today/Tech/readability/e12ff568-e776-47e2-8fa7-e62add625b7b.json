{
  "id": "e12ff568-e776-47e2-8fa7-e62add625b7b",
  "title": "Under new law, cops bust famous cartoonist for AI-generated child sex abuse images",
  "link": "https://arstechnica.com/tech-policy/2025/01/under-new-law-cops-bust-famous-cartoonist-for-ai-generated-child-sex-abuse-images/",
  "description": "Darrin Bell won a major cartooning award in 2019.",
  "author": "Nate Anderson",
  "published": "Fri, 17 Jan 2025 21:08:47 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "Policy",
    "AI",
    "csam",
    "Darrin Bell",
    "sacramento"
  ],
  "byline": "Nate Anderson",
  "length": 1310,
  "excerpt": "Darrin Bell won a major cartooning award in 2019.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "Late last year, California passed a law against the possession or distribution of child sex abuse material (CSAM) that has been generated by AI. The law went into effect on January 1, and Sacramento police announced yesterday that they have already arrested their first suspect—a 49-year-old Pulitzer-prize-winning cartoonist named Darrin Bell. The new law, which you can read here, declares that AI-generated CSAM is harmful, even without an actual victim. In part, says the law, this is because all kinds of CSAM can be used to groom children into thinking sexual activity with adults is normal. But the law singles out AI-generated CSAM for special criticism due to the way that generative AI systems work. \"The creation of CSAM using AI is inherently harmful to children because the machine-learning models utilized by AI have been trained on datasets containing thousands of depictions of known CSAM victims,\" it says, \"revictimizing these real children by using their likeness to generate AI CSAM images into perpetuity.\" The law defines \"artificial intelligence\" as \"an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments.\"",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-1258473947-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                      \n                      \n          \u003cp\u003eLate last year, California passed a law against the possession or distribution of child sex abuse material (CSAM) that has been generated by AI. The law went into effect on January 1, and Sacramento police announced yesterday that they have already arrested their first suspect—a 49-year-old Pulitzer-prize-winning cartoonist named Darrin Bell.\u003c/p\u003e\n\u003cp\u003eThe new law, which \u003ca href=\"https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB1831\"\u003eyou can read here\u003c/a\u003e, declares that AI-generated CSAM is harmful, even without an actual victim. In part, says the law, this is because all kinds of CSAM can be used to groom children into thinking sexual activity with adults is normal. But the law singles out AI-generated CSAM for special criticism due to the way that generative AI systems work.\u003c/p\u003e\n\u003cp\u003e\u0026#34;The creation of CSAM using AI is inherently harmful to children because the machine-learning models utilized by AI have been trained on datasets containing thousands of depictions of known CSAM victims,\u0026#34; it says, \u0026#34;revictimizing these real children by using their likeness to generate AI CSAM images into perpetuity.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThe law defines \u0026#34;artificial intelligence\u0026#34; as \u0026#34;an engineered or machine-based system that varies in its level of autonomy and that can, for explicit or implicit objectives, infer from the input it receives how to generate outputs that can influence physical or virtual environments.\u0026#34;\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": "2025-01-17T21:08:47Z",
  "modifiedTime": "2025-01-17T21:15:51Z"
}
