{
  "id": "237c0370-ecbf-412c-9d3a-0635c3d282ab",
  "title": "How to use Google Lens to ask questions out loud about what you see",
  "link": "https://blog.google/products/search/google-lens-voice-search/",
  "description": "Voice input in Google Lens lets you make your voice heard as you search. Here’s how to use this new feature.",
  "author": "Zahra ThompsonContributorThe Keyword",
  "published": "Thu, 03 Oct 2024 16:00:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Search",
    "Google Lens",
    "AI"
  ],
  "byline": "Zahra Thompson",
  "length": 2587,
  "excerpt": "Voice input in Google Lens lets you make your voice heard as you search. Here’s how to use this new feature.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png",
  "text": "Oct 03, 2024 [[read-time]] min read The new voice input feature makes it easier to point your camera and ask a question. You can now use voice input in Google Lens to ask questions about the things you see — the same way you’d point at something and ask your friend about it. This feature is one of the latest Google Search updates that make it easier to ask questions and find helpful information from across the web.Asking your questions out loud with Lens can be useful in all kinds of situations, especially if you’re on the go. Maybe you’re visiting a museum and want to know the history behind one of the paintings. Or perhaps you want to find out the name of a colorful bird you see while you’re out walking your dog (and using one hand to hold their leash!).Previously, you’d have to take a picture and then type in your question manually. But now with voice input in Lens, you can search what you see and ask a question about it all in one go, so it’s more natural and intuitive to explore the world around you. Here’s how to get started.How to use voice input in LensOpen the Google app (Android \u0026 iOS) and tap the camera icon in the Search bar to open Lens.Point your camera at whatever you want to ask about.Hold down the shutter button and ask your question out loud, like “why did the artist paint this?” or “what kind of clouds are these?”If you’re a Search Labs user enrolled in the “AI Overviews and more” experiment, holding the shutter button will capture a video to provide Lens with even more visual context for your search.Scroll through the results, which may include an AI Overview, as well as links to relevant sites across the web.To ask another question out loud about the photo you took, simply tap the microphone icon at the top of the results page. Video format not supported Search with your voice in Lens to find the information you need, plus links to learn more. Voice input for Lens is now available globally for English queries in the Google app for Android and iOS.To learn about other helpful search features — including new ways to identify songs you hear and shop what you see — read about our latest set of Google Search updates.",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Lens_Voice_Input.width-1300.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;How to use Google Lens to ask questions out loud about what you see\u0026#34;\n  }\"\u003e\n      \u003cdiv\u003e\n          \u003cp\u003eOct 03, 2024\u003c/p\u003e\n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          The new voice input feature makes it easier to point your camera and ask a question.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n      \n\n\n\n\n\n\n\n\u003cdiv\u003e\n    \u003cfigure\u003e\n      \u003cdiv\u003e\n  \u003cp\u003e\u003cimg srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Lens_Voice_Input.width-600.format-webp.webp 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Lens_Voice_Input.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Lens_Voice_Input.width-1600.format-webp.webp 1600w\" sizes=\"(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Lens_Voice_Input.width-1200.format-webp.webp\" fetchpriority=\"high\" alt=\"Illustration showing two people standing in front of color-block artwork. Between them are outlines of two phones — one with a Google Search results page, the other showing part of the user flow for voice input with Lens.\"/\u003e\n  \u003c/p\u003e\n\u003c/div\u003e\n\n      \n    \u003c/figure\u003e\n  \u003c/div\u003e\n\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-drop-cap|uni-tombstone\"\u003e\n\n            \n              \n\n\n\u003cgoogle-read-aloud-player data-analytics-module=\"{\n        \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n        \u0026#34;module_name\u0026#34;: \u0026#34;ai_audio\u0026#34;,\n        \u0026#34;section_header\u0026#34;: \u0026#34;How to use Google Lens to ask questions out loud about what you see\u0026#34;\n    }\" data-date-modified=\"2024-10-04T20:05:19.735386+00:00\" data-progress-bar-style=\"half-wave\" data-api-key=\"AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac\" data-article-style=\"style9\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-layout-style=\"style1\" data-highlight-mode=\"word-over-paragraph\" data-highlight-text-color=\"#000000\" data-highlight-word-background=\"#8AB4F8\" data-highlight-paragraph-background=\"#D2E3FC\" data-background=\"linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)\" data-foreground-color=\"#202124\" data-font=\"600 16px Google Sans, sans-serif\" data-box-shadow=\"0px 1px 3px 1px rgba(60, 64, 67, 0.15)\"\u003e\n\u003c/google-read-aloud-player\u003e\n\n\n\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How to use Google Lens to ask questions out loud about what you see\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"9zojq\"\u003eYou can now use voice input in \u003ca href=\"https://blog.google/products/google-lens/google-lens-features/\"\u003eGoogle Lens\u003c/a\u003e to ask questions about the things you see — the same way you’d point at something and ask your friend about it. This feature is one of the \u003ca href=\"https://blog.google/products/search/google-search-lens-october-2024-updates\"\u003elatest Google Search updates\u003c/a\u003e that make it easier to ask questions and find helpful information from across the web.\u003c/p\u003e\u003cp data-block-key=\"5c9i4\"\u003eAsking your questions out loud with Lens can be useful in all kinds of situations, especially if you’re on the go. Maybe you’re visiting a museum and want to know the history behind one of the paintings. Or perhaps you want to find out the name of a colorful bird you see while you’re out walking your dog (and using one hand to hold their leash!).\u003c/p\u003e\u003cp data-block-key=\"cbhq0\"\u003ePreviously, you’d have to take a picture and then type in your question manually. But now with voice input in Lens, you can search what you see and ask a question about it all in one go, so it’s more natural and intuitive to explore the world around you. Here’s how to get started.\u003c/p\u003e\u003ch2 data-block-key=\"6h2ul\"\u003eHow to use voice input in Lens\u003c/h2\u003e\u003col\u003e\u003cli data-block-key=\"ahn96\"\u003eOpen the Google app (\u003ca href=\"https://play.google.com/store/apps/details?id=com.google.android.googlequicksearchbox\u0026amp;hl=en_US\"\u003eAndroid\u003c/a\u003e \u0026amp; \u003ca href=\"https://apps.apple.com/us/app/google/id284815942\"\u003eiOS\u003c/a\u003e) and tap the camera icon in the Search bar to open Lens.\u003cbr/\u003e\u003c/li\u003e\u003cli data-block-key=\"dle44\"\u003ePoint your camera at whatever you want to ask about.\u003cbr/\u003e\u003c/li\u003e\u003cli data-block-key=\"2e73b\"\u003eHold down the shutter button and ask your question out loud, like “why did the artist paint this?” or “what kind of clouds are these?”\u003cp\u003eIf you’re a Search Labs user enrolled in the “AI Overviews and more” experiment, holding the shutter button will capture a video to provide Lens with even more visual context for your search.\u003c/p\u003e\u003c/li\u003e\u003cli data-block-key=\"dsib8\"\u003eScroll through the results, which may include an AI Overview, as well as links to relevant sites across the web.\u003cbr/\u003e\u003c/li\u003e\u003cli data-block-key=\"3brch\"\u003eTo ask another question out loud about the photo you took, simply tap the microphone icon at the top of the results page.\u003c/li\u003e\u003c/ol\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n  \n      \u003cdiv data-analytics-module=\"{\n          \u0026#34;module_name\u0026#34;: \u0026#34;Inline Images\u0026#34;,\n          \u0026#34;section_header\u0026#34;: \u0026#34;How to use Google Lens to ask questions out loud about what you see\u0026#34;\n        }\"\u003e\n  \n\n  \u003cp\u003e\n\n      \n      \n        \n          \u003cvideo tabindex=\"0\" autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/LENS-IMAGE_CLOUDS_SHELL.mp4\" type=\"video/mp4\" title=\"A video showing how to use voice input with Lens to identify the clouds in a photo. Over a photo of white clouds against a blue sky, text on the screen says speak now to ask about this image. Lens transcribes text that says “what clouds are these”, then populates a page about altocumulus clouds, starting with an AI Overview.\" alt=\"Lens Clouds Shell\"\u003e\n            Video format not supported\n          \u003c/video\u003e\n        \n      \n    \n    \u003c/p\u003e\n    \n      \u003cfigcaption\u003e\u003cp data-block-key=\"oin2a\"\u003eSearch with your voice in Lens to find the information you need, plus links to learn more.\u003c/p\u003e\u003c/figcaption\u003e\n    \n  \n    \u003c/div\u003e\n  \n\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How to use Google Lens to ask questions out loud about what you see\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"9zojq\"\u003eVoice input for Lens is now available globally for English queries in the Google app for \u003ca href=\"https://play.google.com/store/apps/details?id=com.google.android.googlequicksearchbox\u0026amp;hl=en_US\"\u003eAndroid\u003c/a\u003e and \u003ca href=\"https://apps.apple.com/us/app/google/id284815942\"\u003eiOS\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"a2pts\"\u003eTo learn about other helpful search features — including new ways to identify songs you hear and shop what you see — read about \u003ca href=\"https://blog.google/products/search/google-search-lens-october-2024-updates\"\u003eour latest set of Google Search updates\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2024-10-03T16:00:00Z",
  "modifiedTime": null
}
