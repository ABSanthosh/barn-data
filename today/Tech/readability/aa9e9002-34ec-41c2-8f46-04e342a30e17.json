{
  "id": "aa9e9002-34ec-41c2-8f46-04e342a30e17",
  "title": "A satellite just used AI to make its own decisions in space — and NASA’s stoked",
  "link": "https://thenextweb.com/news/ai-satellite-space-nasa-opencosmos-ubotica",
  "description": "For the first time, a satellite has used onboard AI to autonomously decide where and when to capture a scientific image — all in under 90 seconds, with no human input. The technology, called Dynamic Targeting, was tested by NASA’s Jet Propulsion Laboratory (JPL) earlier this month. It was installed aboard a briefcase-sized satellite built and operated by UK-based startup Open Cosmos, and carried a machine learning processor developed by Dublin-based firm Ubotica.   In the test, the satellite tilted forward to scan 500km ahead of its orbit and snapped a preview image. Ubotica’s AI quickly analysed the scene to check…This story continues at The Next WebOr just read more coverage about: NASA",
  "author": "Siôn Geschwindt",
  "published": "Fri, 25 Jul 2025 14:06:44 +0000",
  "source": "https://thenextweb.com/feed/",
  "categories": [
    "Deep tech",
    "Startups and technology",
    "Next Featured",
    "Government and policy",
    "Corporates and innovation"
  ],
  "byline": "Siôn Geschwindt",
  "length": 2485,
  "excerpt": "For the first time, a satellite has used onboard AI to autonomously decide where and when to capture a scientific image.",
  "siteName": "TNW | Deep-Tech",
  "favicon": "https://next.tnwcdn.com/assets/img/favicon/favicon-194x194.png",
  "text": "For the first time, a satellite has used onboard AI to autonomously decide where and when to capture a scientific image — all in under 90 seconds, with no human input. The technology, called Dynamic Targeting, was tested by NASA’s Jet Propulsion Laboratory (JPL) earlier this month. It was installed aboard a briefcase-sized satellite built and operated by UK-based startup Open Cosmos, and carried a machine learning processor developed by Dublin-based firm Ubotica.   In the test, the satellite tilted forward to scan 500km ahead of its orbit and snapped a preview image. Ubotica’s AI quickly analysed the scene to check for cloud cover. If the skies were clear, the satellite tilted back to take a detailed photo of the surface. If clouds obscured the view, it skipped the shot — saving time, storage, and bandwidth. “If you can be smart about what you’re taking pictures of, then you only image the ground and skip the clouds,”  said Ben Smith of JPL, which funds the Dynamic Targeting work. “This technology will help scientists get a much higher proportion of usable data.” Brian Quinn, chief strategy officer at Ubotica, said that until now, satellites have merely acted as passive data collectors. They image whatever happens to be beneath them and beam all that data — useful or not — back to Earth. Scientists then sort through the backlog. “It takes post-processing, which could be days later, to say, ‘Hey, there was a fire. Hey, there was a harmful algal bloom’,” said Quinn in an article published on NASA’s website earlier this year.  NASA, Ubotica, and OpenCosmos say the system could also be expanded to spot wildfires, volcanic eruptions, and severe storms faster than ever before from space.  The recent test builds on previous partnerships involving the three parties. In 2021, Ubotica demonstrated real-time AI cloud detection aboard the International Space Station (ISS) as part of a broader research collaboration with JPL. Then, in 2024, Open Cosmos launched HAMMER, an AI-powered satellite equipped with a hyperspectral camera and Ubotica’s machine learning processor. Get the TNW newsletter Get the most important tech news in your inbox each week. Also tagged with",
  "image": "https://img-cdn.tnwcdn.com/image/tnw-blurple?filter_last=1\u0026fit=1280%2C640\u0026url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026signature=4b8421cedc975b3103ac367714d67d3f",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n                \u003carticle id=\"articleOutput\"\u003e\n                                                                        \u003cdiv\u003e\n                                \u003cfigure\u003e\n                                    \u003cimg alt=\"A satellite just used AI to make its own decisions in space — and NASA’s stoked\" src=\"https://img-cdn.tnwcdn.com/image?fit=1280%2C720\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=58ca107253c7d83f016e70ce03a0718a\" sizes=\"(max-width: 1023px) 100vw\n                                                   868px\" srcset=\"https://img-cdn.tnwcdn.com/image?fit=576%2C324\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=69d06e9ea28e33c5e796adb1bf62758d 576w,\n                                                    https://img-cdn.tnwcdn.com/image?fit=1152%2C648\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=7c139c90af21cccd054694c8c4492c16 1152w,\n                                                    https://img-cdn.tnwcdn.com/image?fit=1280%2C720\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=58ca107253c7d83f016e70ce03a0718a 1280w\" data-src=\"https://img-cdn.tnwcdn.com/image?fit=1280%2C720\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=58ca107253c7d83f016e70ce03a0718a\" data-srcset=\"https://img-cdn.tnwcdn.com/image?fit=576%2C324\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=69d06e9ea28e33c5e796adb1bf62758d 576w,\n                                                     https://img-cdn.tnwcdn.com/image?fit=1152%2C648\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=7c139c90af21cccd054694c8c4492c16 1152w,\n                                                     https://img-cdn.tnwcdn.com/image?fit=1280%2C720\u0026amp;url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F12%2FUntitled-design-32.jpeg\u0026amp;signature=58ca107253c7d83f016e70ce03a0718a 1280w\"/\u003e\n\n                                    \n\n                                                                    \u003c/figure\u003e\n                            \u003c/div\u003e\n                        \n                                                    \n                            \n                                            \n                    \n                    \n\n                    \n                    \u003cdiv\u003e\n                        \u003cdiv id=\"article-main-content\"\u003e\n                            \u003cp\u003e\u003cspan\u003eFor the first time, a satellite has used onboard AI to autonomously decide where and when to capture a scientific image — all in under 90 seconds, with no human input.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThe technology, called Dynamic Targeting, was tested by NASA’s Jet Propulsion Laboratory (JPL) earlier this month. It was installed aboard a briefcase-sized satellite built and operated by UK-based startup Open Cosmos, and carried a \u003ca href=\"https://thenextweb.com/topic/machine-learning\" target=\"_blank\" rel=\"noopener\"\u003emachine learning\u003c/a\u003e processor developed by Dublin-based firm Ubotica.  \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eIn the test, the satellite tilted forward to scan 500km ahead of its orbit and snapped a preview image. Ubotica’s AI quickly analysed the scene to check for cloud cover. If the skies were clear, the satellite tilted back to take a detailed photo of the surface. If clouds obscured the view, it skipped the shot — saving time, storage, and bandwidth.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e“If you can be smart about what you’re taking pictures of, then you only image the ground and skip the clouds,”  said Ben Smith of JPL, which funds the Dynamic Targeting work. “This technology will help scientists get a much higher proportion of usable data.”\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eBrian Quinn, chief strategy officer at Ubotica, said that until now, satellites have merely acted as passive data collectors. They image whatever happens to be beneath them and beam all that data — useful or not — back to Earth. Scientists then sort through the backlog.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e“It takes post-processing, which could be days later, to say, ‘Hey, there was a fire. Hey, there was a harmful algal bloom’,”\u003c/span\u003e \u003cspan\u003esaid Quinn in an \u003c/span\u003e\u003ca href=\"https://spinoff.nasa.gov/Intelligent_Processing_at_the_Edge\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cspan\u003earticle\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e published on NASA’s website earlier this year. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eNASA, Ubotica, and OpenCosmos say the system could also be expanded to spot wildfires, volcanic eruptions, and severe storms faster than ever before from \u003ca href=\"https://thenextweb.com/topic/space\" target=\"_blank\" rel=\"noopener\"\u003espace\u003c/a\u003e. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThe recent test builds on previous partnerships involving the three parties. In 2021, Ubotica demonstrated real-time AI cloud detection aboard the International Space Station (ISS) as part of a broader research collaboration with JPL. Then, in 2024, \u003c/span\u003e\u003ca href=\"https://thenextweb.com/news/uk-startup-ai-satellite-real-time-images-of-earth-spacex\" target=\"_blank\" rel=\"noopener\"\u003e\u003cspan\u003eOpen Cosmos launched HAMMER\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, an AI-powered satellite equipped with a hyperspectral camera and Ubotica’s machine learning processor. \u003c/span\u003e\u003c/p\u003e\n                        \u003c/div\u003e\n\n                        \n\n                        \u003cdiv id=\"nl-container\"\u003e\n                                                        \u003ch2\u003eGet the TNW newsletter\u003c/h2\u003e\n                            \u003cp\u003eGet the most important tech news in your inbox each week.\u003c/p\u003e\n                            \n                        \u003c/div\u003e\n\n                        \n                                                    \u003ch2\u003eAlso tagged with\u003c/h2\u003e\n\n                            \u003cbr/\u003e\n\n                            \n                        \n                        \n\n                        \n                    \u003c/div\u003e\n                    \n\n                    \n                \u003c/article\u003e\n            \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-07-25T14:06:44Z",
  "modifiedTime": "2025-07-25T15:44:04Z"
}
