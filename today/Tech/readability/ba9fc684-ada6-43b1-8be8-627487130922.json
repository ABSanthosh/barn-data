{
  "id": "ba9fc684-ada6-43b1-8be8-627487130922",
  "title": "NeuralSVG: An Implicit Representation for Text-to-Vector Generation",
  "link": "https://sagipolaczek.github.io/NeuralSVG/",
  "description": "Comments",
  "author": "",
  "published": "Wed, 08 Jan 2025 18:16:37 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "Sagi Polaczek1,",
  "length": 5110,
  "excerpt": "1 - Tel Aviv University",
  "siteName": "",
  "favicon": "https://sagipolaczek.github.io/NeuralSVG/static/figures_nsvg/punk.png",
  "text": "1 - Tel Aviv University 2 - MIT CSAIL NeuralSVG generates vector graphics from text prompts with ordered and editable shapes. Our method supports dynamic conditioning, such as background color, which facilitating the generation of multiple color palettes for a single learned representation. Abstract Vector graphics are essential in design, providing artists with a versatile medium for creating resolution-independent and highly editable visual content. Recent advancements in vision-language and diffusion models have fueled interest in text-to-vector graphics generation. However, existing approaches often suffer from over-parameterized outputs or treat the layered structure --- a core feature of vector graphics --- as a secondary goal, diminishing their practical use. Recognizing the importance of layered SVG representations, we propose NeuralSVG, an implicit neural representation for generating vector graphics from text prompts. Inspired by Neural Radiance Fields (NeRFs), NeuralSVG encodes the entire scene into the weights of a small MLP network, optimized using Score Distillation Sampling (SDS). To encourage a layered structure in the generated SVG, we introduce a dropout-based regularization technique that strengthens the standalone meaning of each shape. We additionally demonstrate that utilizing a neural representation provides an added benefit of inference-time control, enabling users to dynamically adapt the generated SVG based on user-provided inputs, all with a single learned representation. Through extensive qualitative and quantitative evaluations, we demonstrate that NeuralSVG outperforms existing methods in generating structured and flexible SVG. Examples of Text-to-Vector Generation with NeuralSVG How Does it Work? We learn an implicit neural representation for generating vector graphics from text prompts. We encode the SVG into the weights of a small MLP network, optimized using an Score Distillation Sampling (SDS). To promote an ordered representation, we use a dropout-based technique to encourages each learned shape to have a meaningful and ordered role in the overall scene. Our neural representation enables inference-time control over the generated asset such as dynamically adjusting the color palette or aspect ratio of the generated SVG, all with a single learned representation. What Can it Do? Encouraging Ordered Representation with Nested Dropout We show results generated by our method when keeping a varying number of learned shapes in the final rendering. Even with a small number of shapes, our approach effectively captures the coarse structure of the scene. Color Palette Control Given a learned representation, we render the result using different background colors specified by the user, resulting in varying color palettes in the resulting SVGs. The upper row shows colors observed during training while the bottom row shows unobserved (generalized) colors. Aspect Ratio Control We present results from optimizing NeuralSVG with aspect ratios of 1:1 and 4:1. In each pair, the left image displays the generated SVG with a 1:1 aspect ratio (square format), while the right image shows the model's output with a 4:1 aspect ratio. Sketch Generation NeuralSVG generates sketches with varying numbers of strokes using a single network, without any modifications to the framework.",
  "image": "static/images/og_tag_header_image.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\n\n\n\n\n\u003cdiv\u003e\n                    \n\n                    \n                                        \n                    \u003cp\u003e\u003cspan\u003e1 - Tel Aviv University\u003c/span\u003e\n                    \u003c/p\u003e\n                    \u003cp\u003e\u003cspan\u003e2 - MIT CSAIL\u003c/span\u003e\n                    \u003c/p\u003e\n                                                    \n                    \n\n                \u003c/div\u003e\n\n\u003csection\u003e\n    \n    \u003cdiv\u003e\n                            \u003cp\u003e\u003cimg src=\"https://sagipolaczek.github.io/NeuralSVG/static/figures_nsvg/teaser-1.png\" alt=\"NeTI\"/\u003e\u003c/p\u003e\u003ch2\u003e\n                                NeuralSVG generates vector graphics from text prompts with ordered and editable shapes. \n                                Our method supports dynamic conditioning, such as background color, which facilitating the generation \n                                of multiple color palettes for a single learned representation.\n                            \u003c/h2\u003e\n                        \u003c/div\u003e\n\n    \u003cdiv\u003e\n                    \n                    \u003ch2\u003eAbstract\u003c/h2\u003e\n                    \u003cp\u003e\n                            Vector graphics are essential in design, providing artists with a versatile medium for creating resolution-independent\n                             and highly editable visual content. Recent advancements in vision-language and diffusion models have fueled interest \n                             in text-to-vector graphics generation. However, existing approaches often suffer from over-parameterized outputs or \n                             treat the layered structure --- a core feature of vector graphics --- as a secondary goal, diminishing their practical \n                             use. Recognizing the importance of layered SVG representations, we propose NeuralSVG, an implicit neural representation\n                              for generating vector graphics from text prompts. Inspired by Neural Radiance Fields (NeRFs), NeuralSVG encodes the \n                              entire scene into the weights of a small MLP network, optimized using Score Distillation Sampling (SDS). To encourage \n                              a layered structure in the generated SVG, we introduce a dropout-based regularization technique that strengthens the \n                              standalone meaning of each shape. We additionally demonstrate that utilizing a neural representation provides an added \n                              benefit of inference-time control, enabling users to dynamically adapt the generated SVG based on user-provided inputs, \n                              all with a single learned representation. Through extensive qualitative and quantitative evaluations, we demonstrate that \n                              NeuralSVG outperforms existing methods in generating structured and flexible SVG.\n                        \u003c/p\u003e\n                \u003c/div\u003e\n\n    \n\n    \u003cdiv\u003e\n                \u003ch2\u003eExamples of Text-to-Vector Generation \u003cbr/\u003e with NeuralSVG\n                \u003c/h2\u003e\n                \n            \u003c/div\u003e\n\n    \u003cdiv\u003e\n                    \u003ch2\u003eHow Does it Work?\u003c/h2\u003e\n                    \n                    \u003cp\u003e\u003cimg src=\"https://sagipolaczek.github.io/NeuralSVG/static/figures_nsvg/method.png\" alt=\"neuralsvg\"/\u003e\n                    \u003c/p\u003e\n                    \u003cul\u003e\n                      \u003cli\u003e We learn an implicit neural representation for generating vector graphics from text prompts. We encode the SVG into the weights of a small MLP network, optimized using an Score Distillation Sampling (SDS).\n                      \u003c/li\u003e\n                      \u003cbr/\u003e\n                      \u003cli\u003e To promote an ordered representation, we use a dropout-based technique to encourages each learned shape to have a meaningful and ordered role in the overall scene.\n                      \u003c/li\u003e\n                      \u003cbr/\u003e\n                      \u003cli\u003e Our neural representation enables inference-time control over the generated asset such as dynamically adjusting the color palette or aspect ratio of the generated SVG, all with a single learned representation.\n                      \u003c/li\u003e\n                      \u003cbr/\u003e\n                    \u003c/ul\u003e\n                \u003c/div\u003e\n\n    \u003cdiv\u003e\n            \u003cdiv\u003e\n                    \u003ch2\u003eWhat Can it Do?\u003c/h2\u003e\n                    \n                    \u003ch3\u003eEncouraging Ordered Representation with Nested Dropout\u003c/h3\u003e\n                    \u003cp\u003e\n                        We show results generated by our method when keeping a varying number of learned shapes in the final rendering. Even with a small number of shapes, our approach effectively captures the coarse structure of the scene.\n                    \u003c/p\u003e\n                \u003c/div\u003e\n            \n\n            \u003cdiv\u003e\n                  \n                  \u003ch3\u003eColor Palette Control\u003c/h3\u003e\n                  \u003cp\u003e \n                    Given a learned representation, we render the result using different background colors specified by the user, resulting in varying color palettes in the resulting SVGs. The upper row shows colors observed during training while the bottom row shows unobserved (generalized) colors.\n                  \u003c/p\u003e\n              \u003c/div\u003e\n          \n\n          \u003cdiv\u003e\n                \n                \u003ch3\u003eAspect Ratio Control\u003c/h3\u003e\n                \u003cp\u003e\n                    We present results from optimizing NeuralSVG with aspect ratios of 1:1 and 4:1. In each pair, the left image displays the generated SVG with a 1:1 aspect ratio (square format), while the right image shows the model\u0026#39;s output with a 4:1 aspect ratio.\n                \u003c/p\u003e\n            \u003c/div\u003e\n        \n\n          \u003cdiv\u003e\n                \n                \u003ch3\u003eSketch Generation\u003c/h3\u003e\n                \u003cp\u003e\n                    NeuralSVG generates sketches with varying numbers of strokes using a single network, without any modifications to the framework.\n                \u003c/p\u003e\n            \u003c/div\u003e\n        \n\n        \u003c/div\u003e\n\n\n    \n\n\n\n\u003c/section\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": null,
  "modifiedTime": null
}
