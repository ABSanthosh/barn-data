{
  "id": "8dee274d-e2e5-4800-a198-69d4d236bfa7",
  "title": "How to watch LlamaCon 2025, Meta's first generative AI developer conference",
  "link": "https://www.engadget.com/ai/how-to-watch-llamacon-2025-metas-first-generative-ai-developer-conference-215241289.html?src=rss",
  "description": "After a couple years of having its open-source Llama AI model be just a part of its Connect conferences, Meta is breaking things out and hosting an entirely generative AI-focused developer conference called LlamaCon on April 29. The event is entirely virtual, and you'll be able to watch along live on the Meta for Developers Facebook page. LlamaCon kicks off at 1PM ET / 10AM PT with a keynote address from Meta's Chief Product Officer Chris Cox, Vice President of AI Manohar Paluri and research scientist Angela Fan. The keynote is supposed to cover developments in the company's open-source AI community, \"the latest on the Llama collection of models and tools\" and offer a glimpse at yet-to-be released AI features. The keynote address will be followed by a conversation at 1:45PM ET / 10:45PM ET between Meta CEO Mark Zuckerberg and Databricks CEO Ali Ghodsi on \"building AI-powered applications,\" followed by a chat at 7PM ET / 4PM PT about \"the latest trends in AI\" between Zuckerberg and Microsoft CEO Satya Nadella. It doesn't seem like either conversation will be used to break news, but Microsoft and Meta have collaborated before, so anything is possible. Meta hasn't traditionally waited for a conference to launch updates to Meta AI or the Llama model. The company introduced its new Llama 4 family of models, which excel at image understanding and document parsing, on a Saturday in early April. It's not clear what new models or products the company could have saved for LlamaCon. LlamaCon will stream live on April 29th through the Meta for Developers Facebook page and we'll be live-blogging the event right here on Engadget so you can get all the details as they happen.This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-llamacon-2025-metas-first-generative-ai-developer-conference-215241289.html?src=rss",
  "author": "Ian Carlos Campbell",
  "published": "Fri, 25 Apr 2025 21:52:41 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Software",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Ian Carlos Campbell"
  ],
  "byline": "Ian Carlos Campbell",
  "length": 1685,
  "excerpt": "Meta's LlamaCon developer conference will stream live on Facebook and feature a chat between Meta CEO Mark Zuckerberg and Microsoft CEO Satya Nadella.",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "After a couple years of having its open-source Llama AI model be just a part of its Connect conferences, Meta is breaking things out and hosting an entirely generative AI-focused developer conference called LlamaCon on April 29. The event is entirely virtual, and you'll be able to watch along live on the Meta for Developers Facebook page.LlamaCon kicks off at 1PM ET / 10AM PT with a keynote address from Meta's Chief Product Officer Chris Cox, Vice President of AI Manohar Paluri and research scientist Angela Fan. The keynote is supposed to cover developments in the company's open-source AI community, \"the latest on the Llama collection of models and tools\" and offer a glimpse at yet-to-be released AI features.The keynote address will be followed by a conversation at 1:45PM ET / 10:45PM ET between Meta CEO Mark Zuckerberg and Databricks CEO Ali Ghodsi on \"building AI-powered applications,\" followed by a chat at 7PM ET / 4PM PT about \"the latest trends in AI\" between Zuckerberg and Microsoft CEO Satya Nadella. It doesn't seem like either conversation will be used to break news, but Microsoft and Meta have collaborated before, so anything is possible.Meta hasn't traditionally waited for a conference to launch updates to Meta AI or the Llama model. The company introduced its new Llama 4 family of models, which excel at image understanding and document parsing, on a Saturday in early April. It's not clear what new models or products the company could have saved for LlamaCon.LlamaCon will stream live on April 29th through the Meta for Developers Facebook page and we'll be live-blogging the event right here on Engadget so you can get all the details as they happen.",
  "image": "https://s.yimg.com/ny/api/res/1.2/prnlvtmWXhgV1abSv.CxdQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2025-04/6f0bf2f0-221f-11f0-b3f9-2942fc974a8d",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAfter a couple years of having its open-source Llama AI model be just a part of its Connect conferences, Meta is breaking things out and hosting an entirely generative AI-focused developer conference called \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1\" href=\"https://www.engadget.com/ai/meta-just-scheduled-a-generative-ai-conference-called-llamacon-for-april-29-181351134.html\" data-ylk=\"slk:LlamaCon;elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1;itc:0;sec:content-canvas\"\u003eLlamaCon\u003c/a\u003e on April 29. The event is entirely virtual, and you\u0026#39;ll be able to watch along live on the \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1\" href=\"https://www.facebook.com/MetaforDevelopers/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:Meta for Developers;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas\"\u003eMeta for Developers\u003c/a\u003e Facebook page.\u003c/p\u003e\u003cp\u003eLlamaCon kicks off at 1PM ET / 10AM PT with a keynote address from Meta\u0026#39;s Chief Product Officer Chris Cox, Vice President of AI Manohar Paluri and research scientist Angela Fan. The keynote is supposed to cover developments in the company\u0026#39;s open-source AI community, \u0026#34;the latest on the Llama collection of models and tools\u0026#34; and offer a glimpse at yet-to-be released AI features.\u003c/p\u003e\u003cp\u003eThe keynote address will be followed by a conversation at 1:45PM ET / 10:45PM ET between Meta CEO Mark Zuckerberg and Databricks CEO Ali Ghodsi on \u0026#34;building AI-powered applications,\u0026#34; followed by a chat at 7PM ET / 4PM PT about \u0026#34;the latest trends in AI\u0026#34; between Zuckerberg and Microsoft CEO Satya Nadella. It doesn\u0026#39;t seem like either conversation will be used to break news, but Microsoft and Meta \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1\" href=\"https://www.engadget.com/meta-and-microsoft-release-llama-2-an-ai-language-model-for-commercial-use-163615807.html\" data-ylk=\"slk:have collaborated before;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas\"\u003ehave collaborated before\u003c/a\u003e, so anything is possible.\u003c/p\u003e\u003cp\u003eMeta hasn\u0026#39;t traditionally waited for a conference to launch updates to Meta AI or the Llama model. The company introduced its new \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1\" href=\"https://www.engadget.com/meta-and-microsoft-release-llama-2-an-ai-language-model-for-commercial-use-163615807.html\" data-ylk=\"slk:Llama 4;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas\"\u003eLlama 4\u003c/a\u003e family of models, which excel at image understanding and document parsing, on a Saturday in early April. It\u0026#39;s not clear what new models or products the company could have saved for LlamaCon.\u003c/p\u003e\u003cp\u003eLlamaCon will stream live on April 29th through the \u003ca data-i13n=\"elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1\" href=\"https://www.facebook.com/MetaforDevelopers/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:Meta for Developers;elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1;itc:0;sec:content-canvas\"\u003eMeta for Developers\u003c/a\u003e Facebook page and we\u0026#39;ll be live-blogging the event right here on Engadget so you can get all the details as they happen.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": "2025-04-25T21:52:41Z",
  "modifiedTime": null
}
