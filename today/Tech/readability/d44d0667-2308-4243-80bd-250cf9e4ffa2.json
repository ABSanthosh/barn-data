{
  "id": "d44d0667-2308-4243-80bd-250cf9e4ffa2",
  "title": "Study finds AI-generated meme captions funnier than human ones on average",
  "link": "https://arstechnica.com/ai/2025/03/ai-beats-humans-at-meme-humor-but-the-best-joke-is-still-human-made/",
  "description": "Mollick proclaims \"the meme Turing Test has been passed,\" but a new study offers a key caveat.",
  "author": "Benj Edwards",
  "published": "Wed, 19 Mar 2025 22:12:47 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Biz \u0026 IT",
    "Culture",
    "AI study",
    "Ethan Mollick",
    "GPT-4o",
    "Humor",
    "Internet memes",
    "large language models",
    "machine learning",
    "openai"
  ],
  "byline": "Benj Edwards",
  "length": 7826,
  "excerpt": "Mollick proclaims “the meme Turing Test has been passed,” but a new study offers a key caveat.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "Skip to content Mollick proclaims \"the meme Turing Test has been passed,\" but a new study offers a key caveat. A new study examining meme creation found that AI-generated meme captions on existing famous meme images scored higher on average for humor, creativity, and \"shareability\" than those made by people. Even so, people still created the most exceptional individual examples. The research, which will be presented at the 2025 International Conference on Intelligent User Interfaces, reveals a nuanced picture of how AI and humans perform differently in humor creation tasks. Still, the results were surprising enough to have one expert declaring victory for the machines. \"I regret to announce that the meme Turing Test has been passed,\" wrote Wharton professor Ethan Mollick on Bluesky after reviewing the study results. Mollick studies AI academically, and he's referring to a famous test proposed by computing pioneer Alan Turing in 1950 that seeks to determine whether humans can distinguish between AI outputs and human-created content. But maybe it's too soon to crown the robots. As the paper states, \"While AI can boost productivity and create content that appeals to a broad audience, human creativity remains crucial for content that connects on a deeper level.\" The international research team from KTH Royal Institute of Technology in Sweden, LMU Munich in Germany, and TU Darmstadt in Germany set up three test scenarios comparing meme creation quality. They pitted humans working alone against humans collaborating with large language models (LLMs), specifically OpenAI's GPT-4o, and memes generated entirely by GPT-4o without human input. Some of the meme image templates used in the study, taken from the paper. Credit: Wu et al. The researchers tested meme captions across three relatable categories (work, food, and sports) to explore how well AI and humans handled humor in familiar contexts. They found notable differences in performance across these categories—for example, memes about work tended to be rated higher for humor and shareability than those about food or sports—highlighting how context can influence the effectiveness of meme humor, whether created by humans or AI. It's worth clarifying that AI models did not generate the images used in the study. Instead, researchers used popular, pre-existing meme templates, and GPT-4o or human participants generated captions for them. More memes, not better memes When crowdsourced participants rated the memes, those created entirely by AI models scored higher on average in humor, creativity, and shareability. The researchers defined shareability as a meme's potential to be widely circulated, influenced by humor, relatability, and relevance to current cultural topics. They note that this study is among the first to show AI-generated memes outperforming human-created ones across these metrics. However, the study comes with an important caveat. On average, fully AI-generated memes scored higher than those created by humans alone or humans collaborating with AI. But when researchers looked at the best individual memes, humans created the funniest examples, and human-AI collaborations produced the most creative and shareable memes. In other words, AI models consistently produced broadly appealing memes, but humans—with or without AI help—still made the most exceptional individual examples. Diagrams of meme creation and evaluation workflows taken from the paper. Credit: Wu et al. The study also found that participants using AI assistance generated significantly more meme ideas and described the process as easier and requiring less effort. Despite this productivity boost, human-AI collaborative memes did not rate higher on average than memes humans created alone. As the researchers put it, \"The increased productivity of human-AI teams does not lead to better results—just to more results.\" Participants who used AI assistance reported feeling slightly less ownership over their creations compared to solo creators. Given that a sense of ownership influenced creative motivation and satisfaction in the study, the researchers suggest that people interested in using AI should carefully consider how to balance AI assistance in creative tasks. From the paper: \"Top 4 Memes Generated by AI, Humans, and Human-AI Collaboration Across Humor, Creativity, and Shareability Metric.\" Credit: Wu et al. So, how can an AI model make reportedly funny things that humans appreciate? The researchers attribute the AI model's strong average performance to its training on vast amounts of Internet data, allowing it to identify broadly appealing humor patterns. Human-created memes, meanwhile, often reflected more personal experiences that occasionally produced particularly funny content but somehow resulted in lower average scores. The researches included a few examples of the meme captions from the study, seen in the images above. When a Bluesky user recently pointed out that the AI-generated memes in the study are \"not great,\" Mollick offered an observation that might partially explain the study results: \"One lesson is many people find bad memes funny and interesting.\" His comment raises a key question about the findings: does AI's success reflect statistical proficiency in reproducing common humor patterns, or simply its ability to target the lowest common denominator of Internet comedy? Limitations The study had several limitations worth noting. The meme caption creation sessions were relatively short, and participants didn't always fully utilize the collaborative capabilities of the AI tools. Future research could investigate whether extended use of AI tools and better prompting might further enhance human-AI creative collaborations. Additionally, the use of crowdsourced evaluators introduces subjectivity and potential biases toward mainstream or conventional humor, possibly favoring AI-generated memes optimized for broad appeal. Future studies might alternately incorporate expert panels or targeted demographics to better capture nuanced and culturally specific aspects of humor and creativity. The research team suggests future work should explore scenarios where an AI model rapidly generates multiple ideas, allowing humans to act as curators who select and refine the best content. But for now, humans remain the champions of meme captions. Benj Edwards is Ars Technica's Senior AI Reporter and founder of the site's dedicated AI beat in 2022. He's also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC. 39 Comments",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/woman_dropped_phone_on_face-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"app\"\u003e\n    \u003cp\u003e\u003ca href=\"#main\"\u003e\n  Skip to content\n\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003cmain id=\"main\"\u003e\n            \u003carticle data-id=\"2083308\"\u003e\n  \n  \u003cheader\u003e\n  \u003cdiv\u003e\n      \n\n      \n\n      \u003cp\u003e\n        Mollick proclaims \u0026#34;the meme Turing Test has been passed,\u0026#34; but a new study offers a key caveat.\n      \u003c/p\u003e\n\n      \n    \u003c/div\u003e\n\u003c/header\u003e\n\n\n  \n\n  \n      \n    \n    \u003cdiv\u003e\n                      \n                      \n          \u003cp\u003eA \u003ca href=\"https://arxiv.org/abs/2501.11433\"\u003enew study\u003c/a\u003e examining meme creation found that AI-generated meme captions on existing famous meme images scored higher on average for humor, creativity, and \u0026#34;shareability\u0026#34; than those made by people. Even so, people still created the most exceptional individual examples.\u003c/p\u003e\n\u003cp\u003eThe research, which will be presented at the \u003ca href=\"https://iui.acm.org/2025/\"\u003e2025 International Conference on Intelligent User Interfaces\u003c/a\u003e, reveals a nuanced picture of how AI and humans perform differently in humor creation tasks. Still, the results were surprising enough to have one expert declaring victory for the machines.\u003c/p\u003e\n\u003cp\u003e\u0026#34;I regret to announce that the meme Turing Test has been passed,\u0026#34; \u003ca href=\"https://bsky.app/profile/emollick.bsky.social/post/3lkjvtg6wmk2i\"\u003ewrote\u003c/a\u003e Wharton professor Ethan Mollick on Bluesky after reviewing the study results. Mollick studies AI academically, and he\u0026#39;s referring to a \u003ca href=\"https://en.wikipedia.org/wiki/Turing_test\"\u003efamous test\u003c/a\u003e proposed by computing pioneer Alan Turing in 1950 that seeks to determine whether humans can distinguish between AI outputs and human-created content.\u003c/p\u003e\n\u003cp\u003eBut maybe it\u0026#39;s too soon to crown the robots. As the paper states, \u0026#34;While AI can boost productivity and create content that appeals to a broad audience, human creativity remains crucial for content that connects on a deeper level.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThe international research team from KTH Royal Institute of Technology in Sweden, LMU Munich in Germany, and TU Darmstadt in Germany set up three test scenarios comparing meme creation quality. They pitted humans working alone against humans collaborating with large language models (LLMs), specifically OpenAI\u0026#39;s \u003ca href=\"https://arstechnica.com/information-technology/2024/05/chatgpt-4o-lets-you-have-real-time-audio-video-conversations-with-emotional-chatbot/\"\u003eGPT-4o\u003c/a\u003e, and memes generated entirely by GPT-4o without human input.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"1024\" height=\"436\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/example_meme_templates-1024x436.jpg\" alt=\"Some of the meme image templates used in the study, taken from the paper.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/example_meme_templates-1024x436.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/example_meme_templates-640x272.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/example_meme_templates-768x327.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/example_meme_templates-980x417.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/example_meme_templates.jpg 1285w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      Some of the meme image templates used in the study, taken from the paper.\n\n              \u003cspan\u003e\n          Credit:\n\n                      \u003ca href=\"https://arxiv.org/abs/2501.11433\" target=\"_blank\"\u003e\n          \n          Wu et al.\n\n                      \u003c/a\u003e\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eThe researchers tested meme captions across three relatable categories (work, food, and sports) to explore how well AI and humans handled humor in familiar contexts. They found notable differences in performance across these categories—for example, memes about work tended to be rated higher for humor and shareability than those about food or sports—highlighting how context can influence the effectiveness of meme humor, whether created by humans or AI.\u003c/p\u003e\n\n          \n                      \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n          \n          \n\u003cp\u003eIt\u0026#39;s worth clarifying that AI models did not generate the images used in the study. Instead, researchers used popular, pre-existing meme templates, and GPT-4o or human participants generated captions for them.\u003c/p\u003e\n\u003ch2\u003eMore memes, not better memes\u003c/h2\u003e\n\u003cp\u003eWhen crowdsourced participants rated the memes, those created entirely by AI models scored higher on average in humor, creativity, and shareability. The researchers defined shareability as a meme\u0026#39;s potential to be widely circulated, influenced by humor, relatability, and relevance to current cultural topics. They note that this study is among the first to show AI-generated memes outperforming human-created ones across these metrics.\u003c/p\u003e\n\u003cp\u003eHowever, the study comes with an important caveat. On average, fully AI-generated memes scored higher than those created by humans alone or humans collaborating with AI. But when researchers looked at the best individual memes, humans created the funniest examples, and human-AI collaborations produced the most creative and shareable memes. In other words, AI models consistently produced broadly appealing memes, but humans—with or without AI help—still made the most exceptional individual examples.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"1024\" height=\"792\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/meme_workflow-1024x792.jpg\" alt=\"Diagrams of meme creation and evaluation workflows taken from the paper.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/meme_workflow-1024x792.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/meme_workflow-640x495.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/meme_workflow-768x594.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/meme_workflow-980x758.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/meme_workflow.jpg 1396w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      Diagrams of meme creation and evaluation workflows taken from the paper.\n\n              \u003cspan\u003e\n          Credit:\n\n                      \u003ca href=\"https://arxiv.org/abs/2501.11433\" target=\"_blank\"\u003e\n          \n          Wu et al.\n\n                      \u003c/a\u003e\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eThe study also found that participants using AI assistance generated significantly more meme ideas and described the process as easier and requiring less effort. Despite this productivity boost, human-AI collaborative memes did not rate higher on average than memes humans created alone. As the researchers put it, \u0026#34;The increased productivity of human-AI teams does not lead to better results—just to more results.\u0026#34;\u003c/p\u003e\n\u003cp\u003eParticipants who used AI assistance reported feeling slightly less ownership over their creations compared to solo creators. Given that a sense of ownership influenced creative motivation and satisfaction in the study, the researchers suggest that people interested in using AI should carefully consider how to balance AI assistance in creative tasks.\u003c/p\u003e\n\n          \n                  \u003c/div\u003e\n                    \n        \n          \n    \n    \u003cdiv\u003e\n\n        \n        \u003cdiv\u003e\n          \n          \n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"1024\" height=\"368\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-1024x368.jpg\" alt=\"From the paper: \u0026#34;Top 4 Memes Generated by AI, Humans, and Human-AI Collaboration Across Humor, Creativity, and Shareability Metric.\u0026#34;\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-1024x368.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-640x230.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-768x276.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-1536x552.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-980x352.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes-1440x517.jpg 1440w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/top_memes.jpg 1742w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      From the paper: \u0026#34;Top 4 Memes Generated by AI, Humans, and Human-AI Collaboration Across Humor, Creativity, and Shareability Metric.\u0026#34;\n\n              \u003cspan\u003e\n          Credit:\n\n                      \u003ca href=\"https://arxiv.org/abs/2501.11433\" target=\"_blank\"\u003e\n          \n          Wu et al.\n\n                      \u003c/a\u003e\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eSo, how can an AI model make reportedly funny things that humans appreciate? The researchers attribute the AI model\u0026#39;s strong average performance to its training on vast amounts of Internet data, allowing it to identify broadly appealing humor patterns. Human-created memes, meanwhile, often reflected more personal experiences that occasionally produced particularly funny content but somehow resulted in lower average scores.\u003c/p\u003e\n\u003cp\u003eThe researches included a few examples of the meme captions from the study, seen in the images above. When a Bluesky user recently \u003ca href=\"https://bsky.app/profile/alexyzt.bsky.social/post/3lkjyoypbfc2i\"\u003epointed out\u003c/a\u003e that the AI-generated memes in the study are \u0026#34;not great,\u0026#34; Mollick \u003ca href=\"https://bsky.app/profile/emollick.bsky.social/post/3lkkchsji3c2i\"\u003eoffered\u003c/a\u003e an observation that might partially explain the study results: \u0026#34;One lesson is many people find bad memes funny and interesting.\u0026#34; His comment raises a key question about the findings: does AI\u0026#39;s success reflect statistical proficiency in reproducing common humor patterns, or simply its ability to target the lowest common denominator of Internet comedy?\u003c/p\u003e\n\u003ch2\u003eLimitations\u003c/h2\u003e\n\u003cp\u003eThe study had several limitations worth noting. The meme caption creation sessions were relatively short, and participants didn\u0026#39;t always fully utilize the collaborative capabilities of the AI tools. Future research could investigate whether extended use of AI tools and better prompting might further enhance human-AI creative collaborations.\u003c/p\u003e\n\u003cp\u003eAdditionally, the use of crowdsourced evaluators introduces subjectivity and potential biases toward mainstream or conventional humor, possibly favoring AI-generated memes optimized for broad appeal. Future studies might alternately incorporate expert panels or targeted demographics to better capture nuanced and culturally specific aspects of humor and creativity.\u003c/p\u003e\n\u003cp\u003eThe research team suggests future work should explore scenarios where an AI model rapidly generates multiple ideas, allowing humans to act as curators who select and refine the best content. But for now, humans remain the champions of meme captions.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\n\n                  \n          \n\n\n\n\n\n\n  \u003cdiv\u003e\n  \u003cdiv\u003e\n          \u003cp\u003e\u003ca href=\"https://arstechnica.com/author/benjedwards/\"\u003e\u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2022/08/benj_ega.png\" alt=\"Photo of Benj Edwards\"/\u003e\u003c/a\u003e\u003c/p\u003e\n  \u003c/div\u003e\n\n  \u003cdiv\u003e\n    \n\n    \u003cp\u003e\n      Benj Edwards is Ars Technica\u0026#39;s Senior AI Reporter and founder of the site\u0026#39;s dedicated AI beat in 2022. He\u0026#39;s also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.\n    \u003c/p\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\n  \u003cp\u003e\n    \u003ca href=\"https://arstechnica.com/ai/2025/03/ai-beats-humans-at-meme-humor-but-the-best-joke-is-still-human-made/#comments\" title=\"39 comments\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 80 80\"\u003e\u003cdefs\u003e\u003cclipPath id=\"bubble-zero_svg__a\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"bubble-zero_svg__b\"\u003e\u003cpath fill=\"none\" stroke-width=\"0\" d=\"M0 0h80v80H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#bubble-zero_svg__a)\"\u003e\u003cg fill=\"currentColor\" clip-path=\"url(#bubble-zero_svg__b)\"\u003e\u003cpath d=\"M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40\"\u003e\u003c/path\u003e\u003cpath d=\"M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n    39 Comments\n  \u003c/a\u003e\n      \u003c/p\u003e\n              \u003c/div\u003e\n  \u003c/article\u003e\n\n\n  \n\n\n  \n\n\n  \u003cdiv\u003e\n    \u003cheader\u003e\n      \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 40 26\"\u003e\u003cdefs\u003e\u003cclipPath id=\"most-read_svg__a\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003cclipPath id=\"most-read_svg__b\"\u003e\u003cpath fill=\"none\" d=\"M0 0h40v26H0z\"\u003e\u003c/path\u003e\u003c/clipPath\u003e\u003c/defs\u003e\u003cg clip-path=\"url(#most-read_svg__a)\"\u003e\u003cg fill=\"none\" clip-path=\"url(#most-read_svg__b)\"\u003e\u003cpath fill=\"currentColor\" d=\"M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1\"\u003e\u003c/path\u003e\u003cpath fill=\"#ff4e00\" d=\"M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/g\u003e\u003c/svg\u003e\n      \n    \u003c/header\u003e\n    \u003col\u003e\n              \u003cli\u003e\n                      \u003ca href=\"https://arstechnica.com/space/2025/03/can-nasa-remain-nonpartisan-when-basic-spaceflight-truths-are-shredded/\"\u003e\n              \u003cimg src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/splashdown-nasa-768x432.jpg\" alt=\"Listing image for first story in Most Read: Can NASA remain nonpartisan when basic spaceflight truths are shredded?\" decoding=\"async\" loading=\"lazy\"/\u003e\n            \u003c/a\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                    \u003cli\u003e\n                    \n        \u003c/li\u003e\n                  \u003c/ol\u003e\n\u003c/div\u003e\n\n\n  \n\n  \u003c/main\u003e\n\n\n\n\n\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-03-19T22:12:47Z",
  "modifiedTime": "2025-03-19T22:23:31Z"
}
