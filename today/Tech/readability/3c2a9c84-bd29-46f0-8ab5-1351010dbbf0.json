{
  "id": "3c2a9c84-bd29-46f0-8ab5-1351010dbbf0",
  "title": "Google now thinks it's OK to use AI for weapons and surveillance",
  "link": "https://www.engadget.com/ai/google-now-thinks-its-ok-to-use-ai-for-weapons-and-surveillance-224824373.html?src=rss",
  "description": "Google has made one of the most substantive changes to its AI principles since first publishing them in 2018. In a change spotted by The Washington Post, the search giant edited the document to remove pledges it had made promising it would not \"design or deploy\" AI tools for use in weapons or surveillance technology. Previously, those guidelines included a section titled \"applications we will not pursue,\" which is not present in the current version of the document. Instead, there's now a section titled \"responsible development and deployment.\" There, Google says it will implement \"appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.\" That's a far broader commitment than the specific ones the company made as recently as the end of last month when the prior version of its AI principles was still live on its website. For instance, as it relates to weapons, the company previously said it would not design AI for use in \"weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.” As for AI surveillance tools, the company said it would not develop tech that violates \"internationally accepted norms.\" Google When asked for comment, a Google spokesperson pointed Engadget to a blog post the company published on Thursday. In it, DeepMind CEO Demis Hassabis and James Manyika, senior vice president of research, labs, technology and society at Google, say AI's emergence as a \"general-purpose technology\" necessitated a policy change.  \"We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights. And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,\" the two wrote. \"… Guided by our AI Principles, we will continue to focus on AI research and applications that align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights — always evaluating specific work by carefully assessing whether the benefits substantially outweigh potential risks.\" When Google first published its AI principles in 2018, it did so in the aftermath of Project Maven. It was a controversial government contract that, had Google decided to renew it, would have seen the company provide AI software to the Department of Defense for analyzing drone footage. Dozens of Google employees quit the company in protest of the contract, with thousands more signing a petition in opposition. When Google eventually published its new guidelines, CEO Sundar Pichai reportedly told staff his hope was they would stand \"the test of time.\" By 2021, however, Google began pursuing military contracts again, with what was reportedly an \"aggressive\" bid for the Pentagon's Joint Warfighting Cloud Capability cloud contract. At the start of this year, The Washington Post reported that Google employees had repeatedly worked with Israel's Defense Ministry to expand the government's use of AI tools.This article originally appeared on Engadget at https://www.engadget.com/ai/google-now-thinks-its-ok-to-use-ai-for-weapons-and-surveillance-224824373.html?src=rss",
  "author": "Igor Bonifacic",
  "published": "Tue, 04 Feb 2025 22:48:24 +0000",
  "source": "https://www.engadget.com/rss.xml",
  "categories": [
    "Internet \u0026 Networking Technology",
    "Information Technology",
    "site|engadget",
    "provider_name|Engadget",
    "region|US",
    "language|en-US",
    "author_name|Igor Bonifacic"
  ],
  "byline": "Igor Bonifacic",
  "length": 3267,
  "excerpt": "Google has edited its AI Principles to remove commitments the company made to not use the technology in weapons or surveillance.",
  "siteName": "Engadget",
  "favicon": "https://s.yimg.com/kw/assets/favicon-160x160.png",
  "text": "Google has made one of the most substantive changes to its AI principles since first publishing them in 2018. In a change spotted by The Washington Post, the search giant edited the document to remove pledges it had made promising it would not \"design or deploy\" AI tools for use in weapons or surveillance technology. Previously, those guidelines included a section titled \"applications we will not pursue,\" which is not present in the current version of the document.Instead, there's now a section titled \"responsible development and deployment.\" There, Google says it will implement \"appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.\"That's a far broader commitment than the specific ones the company made as recently as the end of last month when the prior version of its AI principles was still live on its website. For instance, as it relates to weapons, the company previously said it would not design AI for use in \"weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.” As for AI surveillance tools, the company said it would not develop tech that violates \"internationally accepted norms.\" GoogleWhen asked for comment, a Google spokesperson pointed Engadget to a blog post the company published on Thursday. In it, DeepMind CEO Demis Hassabis and James Manyika, senior vice president of research, labs, technology and society at Google, say AI's emergence as a \"general-purpose technology\" necessitated a policy change.\"We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights. And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,\" the two wrote. \"… Guided by our AI Principles, we will continue to focus on AI research and applications that align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights — always evaluating specific work by carefully assessing whether the benefits substantially outweigh potential risks.\"When Google first published its AI principles in 2018, it did so in the aftermath of Project Maven. It was a controversial government contract that, had Google decided to renew it, would have seen the company provide AI software to the Department of Defense for analyzing drone footage. Dozens of Google employees quit the company in protest of the contract, with thousands more signing a petition in opposition. When Google eventually published its new guidelines, CEO Sundar Pichai reportedly told staff his hope was they would stand \"the test of time.\"By 2021, however, Google began pursuing military contracts again, with what was reportedly an \"aggressive\" bid for the Pentagon's Joint Warfighting Cloud Capability cloud contract. At the start of this year, The Washington Post reported that Google employees had repeatedly worked with Israel's Defense Ministry to expand the government's use of AI tools.",
  "image": "https://s.yimg.com/ny/api/res/1.2/w_6FY6VoBVkb4zy3XiZfOQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2025-02/198e7990-e2cf-11ef-bf7f-53030ad472f1",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eGoogle has made one of the most substantive changes to its \u003ca data-i13n=\"cpos:1;pos:1\" href=\"https://ai.google/responsibility/principles/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:AI principles;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003eAI principles\u003c/a\u003e since first publishing them in 2018. In a change spotted by \u003ca data-i13n=\"cpos:2;pos:1\" href=\"https://www.washingtonpost.com/technology/2025/02/04/google-ai-policies-weapons-harm\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:The Washington Post;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003e\u003cem\u003eThe Washington Post\u003c/em\u003e\u003c/a\u003e, the search giant edited the document to remove pledges it had made promising it would not \u0026#34;design or deploy\u0026#34; AI tools for use in weapons or surveillance technology. Previously, those guidelines included a section titled \u0026#34;applications we will not pursue,\u0026#34; which is not present in the current version of the document.\u003c/p\u003e\u003cp\u003eInstead, there\u0026#39;s now a section titled \u0026#34;responsible development and deployment.\u0026#34; There, Google says it will implement \u0026#34;appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.\u0026#34;\u003c/p\u003e\u003cp\u003eThat\u0026#39;s a far broader commitment than the specific ones the company made as recently as the end of last month when the prior version of its AI principles was still live on its website. For instance, as it relates to weapons, the company previously said it would not design AI for use in \u0026#34;weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.” As for AI surveillance tools, the company said it would not develop tech that violates \u0026#34;internationally accepted norms.\u0026#34;\u003c/p\u003e\u003cfigure\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"A screenshot showing the previous version of Google\u0026#39;s AI Principles. \" src=\"https://s.yimg.com/ny/api/res/1.2/nArYLalr_LRQ9VyTvnf2Ag--/YXBwaWQ9aGlnaGxhbmRlcjt3PTk2MDtoPTU0MDtjZj13ZWJw/https://s.yimg.com/os/creatr-uploaded-images/2025-02/90d29370-e346-11ef-bffb-8cc725a6e98c\" height=\"540\" width=\"960\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cfigcaption\u003e\u003cspan\u003e Google\u003c/span\u003e\u003c/figcaption\u003e\u003c/p\u003e\u003c/figure\u003e\u003cp\u003eWhen asked for comment, a Google spokesperson pointed Engadget to a \u003ca data-i13n=\"cpos:3;pos:1\" href=\"https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:blog post;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003eblog post\u003c/a\u003e the company published on Thursday. In it, DeepMind CEO Demis Hassabis and James Manyika, senior vice president of research, labs, technology and society at Google, say AI\u0026#39;s emergence as a \u0026#34;general-purpose technology\u0026#34; necessitated a policy change.\u003c/p\u003e\u003cp\u003e\u0026#34;We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights. And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,\u0026#34; the two wrote. \u0026#34;… Guided by our AI Principles, we will continue to focus on AI research and applications that align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights — always evaluating specific work by carefully assessing whether the benefits substantially outweigh potential risks.\u0026#34;\u003c/p\u003e\u003cp\u003eWhen Google first published its AI principles in 2018, it did so in the aftermath of \u003ca data-i13n=\"cpos:4;pos:1\" href=\"https://www.engadget.com/2018-06-01-google-will-not-renew-military-ai-contract-project-maven.html\" data-ylk=\"slk:Project Maven;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003eProject Maven\u003c/a\u003e. It was a controversial government contract that, had Google decided to renew it, would have seen the company provide AI software to the Department of Defense for analyzing drone footage. Dozens of Google employees \u003ca data-i13n=\"cpos:5;pos:1\" href=\"https://www.engadget.com/2018-05-14-google-project-maven-employee-protest.html\" data-ylk=\"slk:quit the company;cpos:5;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003equit the company\u003c/a\u003e in protest of the contract, with thousands more \u003ca data-i13n=\"cpos:6;pos:1\" href=\"https://www.engadget.com/2018-04-04-google-employees-petition-ceo-to-drop-out-of-pentagon-ai-project.html\" data-ylk=\"slk:signing a petition in opposition;cpos:6;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003esigning a petition in opposition\u003c/a\u003e. When Google eventually published its new guidelines, CEO Sundar Pichai reportedly told staff his hope was they would stand \u0026#34;the test of time.\u0026#34;\u003c/p\u003e\u003cp\u003eBy 2021, however, Google began pursuing military contracts again, with what was reportedly an \u003ca data-i13n=\"cpos:7;pos:1\" href=\"https://www.engadget.com/google-jwcc-contract-214046745.html\" data-ylk=\"slk:\u0026#34;aggressive\u0026#34; bid;cpos:7;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003e\u0026#34;aggressive\u0026#34; bid\u003c/a\u003e for the Pentagon\u0026#39;s Joint Warfighting Cloud Capability cloud contract. At the start of this year, \u003cem\u003eThe Washington Post\u003c/em\u003e reported that Google employees had repeatedly worked with Israel\u0026#39;s Defense Ministry to \u003ca data-i13n=\"cpos:8;pos:1\" href=\"https://www.engadget.com/google-reportedly-made-sure-israels-military-had-access-to-its-ai-tools-142130574.html\" data-ylk=\"slk:expand the government\u0026#39;s use of AI tools;cpos:8;pos:1;elm:context_link;itc:0;sec:content-canvas\"\u003eexpand the government\u0026#39;s use of AI tools\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": "2025-02-04T22:48:24Z",
  "modifiedTime": null
}
