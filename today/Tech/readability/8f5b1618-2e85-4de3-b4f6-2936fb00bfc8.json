{
  "id": "8f5b1618-2e85-4de3-b4f6-2936fb00bfc8",
  "title": "AI search engines give incorrect answers at an alarming 60% rate, study says",
  "link": "https://arstechnica.com/ai/2025/03/ai-search-engines-give-incorrect-answers-at-an-alarming-60-rate-study-says/",
  "description": "CJR study shows AI search services misinform users and ignore publisher exclusion requests.",
  "author": "Benj Edwards",
  "published": "Thu, 13 Mar 2025 21:16:05 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "Biz \u0026 IT",
    "AI confabulations",
    "ai hallucinations",
    "ai search",
    "ChatGPT",
    "confabulations",
    "deepseek",
    "DeepSeek Search",
    "google",
    "Google Gemini",
    "grok",
    "Grok 3",
    "machine learning",
    "microsoft",
    "Microsoft Copilot",
    "openai",
    "Perplexity",
    "xAI"
  ],
  "byline": "Benj Edwards",
  "length": 2386,
  "excerpt": "CJR study shows AI search services misinform users and ignore publisher exclusion requests.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "Even when these AI search tools cited sources, they often directed users to syndicated versions of content on platforms like Yahoo News rather than original publisher sites. This occurred even in cases where publishers had formal licensing agreements with AI companies. URL fabrication emerged as another significant problem. More than half of citations from Google's Gemini and Grok 3 led users to fabricated or broken URLs resulting in error pages. Of 200 citations tested from Grok 3, 154 resulted in broken links. These issues create significant tension for publishers, which face difficult choices. Blocking AI crawlers might lead to loss of attribution entirely, while permitting them allows widespread reuse without driving traffic back to publishers' own websites. A graph from CJR showing that blocking crawlers doesn't mean that AI search providers honor the request. Credit: CJR Mark Howard, chief operating officer at Time magazine, expressed concern to CJR about ensuring transparency and control over how Time's content appears via AI-generated searches. Despite these issues, Howard sees room for improvement in future iterations, stating, \"Today is the worst that the product will ever be,\" citing substantial investments and engineering efforts aimed at improving these tools. However, Howard also did some user shaming, suggesting it's the user's fault if they aren't skeptical of free AI tools’ accuracy: \"If anybody as a consumer is right now believing that any of these free products are going to be 100 percent accurate, then shame on them.\" OpenAI and Microsoft provided statements to CJR acknowledging receipt of the findings but did not directly address the specific issues. OpenAI noted its promise to support publishers by driving traffic through summaries, quotes, clear links, and attribution. Microsoft stated it adheres to Robot Exclusion Protocols and publisher directives. The latest report builds on previous findings published by the Tow Center in November 2024, which identified similar accuracy problems in how ChatGPT handled news-related content. For more detail on the fairly exhaustive report, check out Columbia Journalism Review's website.",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/dartboard_missed-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n          \n          \n\u003cp\u003eEven when these AI search tools cited sources, they often directed users to syndicated versions of content on platforms like Yahoo News rather than original publisher sites. This occurred even in cases where publishers had formal licensing agreements with AI companies.\u003c/p\u003e\n\u003cp\u003eURL fabrication emerged as another significant problem. More than half of citations from Google\u0026#39;s Gemini and Grok 3 led users to fabricated or broken URLs resulting in error pages. Of 200 citations tested from Grok 3, 154 resulted in broken links.\u003c/p\u003e\n\u003cp\u003eThese issues create significant tension for publishers, which face difficult choices. Blocking AI crawlers might lead to loss of attribution entirely, while permitting them allows widespread reuse without driving traffic back to publishers\u0026#39; own websites.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"1024\" height=\"599\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-1024x599.jpg\" alt=\"A graph from CJR showing that blocking crawlers doesn\u0026#39;t mean that AI search providers honor the request.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-1024x599.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-640x374.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-768x449.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-1536x899.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-2048x1198.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-980x573.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/03/Screenshot-2025-03-06-at-9.22.03-AM-1440x842.jpg 1440w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      A graph from CJR showing that blocking crawlers doesn\u0026#39;t mean that AI search providers honor the request.\n\n              \u003cspan\u003e\n          Credit:\n\n                      \u003ca href=\"https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php\" target=\"_blank\"\u003e\n          \n          CJR\n\n                      \u003c/a\u003e\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eMark Howard, chief operating officer at Time magazine, expressed concern to CJR about ensuring transparency and control over how Time\u0026#39;s content appears via AI-generated searches. Despite these issues, Howard sees room for improvement in future iterations, stating, \u0026#34;Today is the worst that the product will ever be,\u0026#34; citing substantial investments and engineering efforts aimed at improving these tools.\u003c/p\u003e\n\u003cp\u003eHowever, Howard also did some user shaming, suggesting it\u0026#39;s the user\u0026#39;s fault if they aren\u0026#39;t skeptical of free AI tools’ accuracy: \u0026#34;If anybody as a consumer is right now believing that any of these free products are going to be 100 percent accurate, then shame on them.\u0026#34;\u003c/p\u003e\n\u003cp\u003eOpenAI and Microsoft provided statements to CJR acknowledging receipt of the findings but did not directly address the specific issues. OpenAI noted its promise to support publishers by driving traffic through summaries, quotes, clear links, and attribution. Microsoft stated it adheres to Robot Exclusion Protocols and publisher directives.\u003c/p\u003e\n\u003cp\u003eThe latest report builds on \u003ca href=\"https://www.cjr.org/tow_center/how-chatgpt-misrepresents-publisher-content.php\"\u003eprevious findings\u003c/a\u003e published by the Tow Center in November 2024, which identified similar accuracy problems in how ChatGPT handled news-related content. For more detail on the fairly exhaustive report, check out \u003ca href=\"https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php\"\u003eColumbia Journalism Review\u0026#39;s website\u003c/a\u003e.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-03-13T21:16:05Z",
  "modifiedTime": "2025-03-13T21:16:05Z"
}
