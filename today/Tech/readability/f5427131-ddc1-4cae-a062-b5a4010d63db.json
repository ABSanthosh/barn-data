{
  "id": "f5427131-ddc1-4cae-a062-b5a4010d63db",
  "title": "How we're using AI to drive scientific research with greater real-world benefit",
  "link": "https://blog.google/technology/research/google-research-scientific-discovery/",
  "description": "Google Research teams are using AI to address fundamental scientific questions and advance research across disciplines from quantum computing to genomics and neuroscienc…",
  "author": "Yossi MatiasVice President \u0026 Head of Google Research",
  "published": "Thu, 08 May 2025 17:30:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Research",
    "AI"
  ],
  "byline": "Yossi Matias",
  "length": 7466,
  "excerpt": "Google Research teams are using AI to address fundamental scientific questions and advance research across disciplines from quantum computing to genomics and neuroscience.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20250424-1642",
  "text": "May 08, 2025 [[read-time]] min read Google Research teams are using AI to address fundamental scientific questions and advance research across disciplines from biomedical science and neuroscience to geospatial science and quantum computing. AI has long driven scientific advances at Google, and the velocity at which breakthroughs are happening today is unprecedented. AI’s increasing capabilities have made the “magic cycle” of research from breakthrough to real-world impact broader and quicker than ever.AI is an amplifier of human ingenuity. At Google, our teams are using AI to address fundamental scientific questions and push the boundaries of what’s possible, leading to new understanding of life and novel solutions to humanity’s greatest challenges. As we accelerate scientific discovery, we collaborate closely with the scientific community and ecosystem, across both industry and academia, and make our tech and tools available to our partners for their own research.Here are four areas where Google Research has shared recent breakthroughs with meaningful scientific and societal impact.Advancing biomedical science to better treat diseaseWe’re excited about the potential of AI to personalize medicine, democratize science and open up new avenues for biological and medical discovery. Our AI co-scientist aims to help expedite the process of making new biomedical discoveries. This multi-agent system uses AI’s ability to synthesize information and perform complex reasoning tasks to aid scientists in creating novel hypotheses and research proposals using natural language. We recently introduced a multimodal version of AMIE, a research AI agent for medical diagnostic conversations published in Nature. It can intelligently interpret and reason about visual medical information, working towards more accurate diagnosis. AMIE builds upon our earlier work on MedPaLM and subsequent language models fine-tuned for the medical domain. We continue to add assets to Health AI Developer Foundations to help developers build medical AI applications and we released TxGemma, a collection of open models designed to improve the efficiency of therapeutic development, building on our embeddings models for chest x-rays, digital pathology and dermatology.We keep advancing research into genomics, too, to better understand individuals' genetic predispositions to illnesses and to diagnose rare diseases. REGLE is an unsupervised deep learning model that helps researchers discover associations with genetic variants. And we open sourced new DeepVariant models as part of a collaboration on Personalized Pangenome References, which can reduce errors by 30% when analyzing genomes of diverse ancestries.Advancing neuroscience research to demystify the brainOver the past decade, we’ve made fundamental contributions to the field of connectomics and furthered scientific understanding of the workings of the brain. Just yesterday in Nature, a team from Google Research and ISTA published on LICONN, the first-ever method for using commonly available light microscopes to comprehensively map neurons and their connections in brain tissue. LICONN will enable more labs around the world to pursue connectomics studies. Building beyond neural connections, in collaboration with HHMI Janelia and Harvard, we introduced the Zebrafish Activity Prediction Benchmark (ZAPBench) with recordings of more than 70,000 neurons from the entire brain of the larval zebrafish. This allows researchers to investigate the relationship between the structural wiring and dynamic neural activity across an entire vertebrate brain for the first time. We’ve open-sourced the dataset and benchmark to help neuroscientists develop more accurate brain activity models.We’ve also explored the similarities and differences in how the human brain and deep language models process natural language through a series of studies in collaboration with Princeton University, NYU and HUJI. Our findings indicate that deep learning models could offer a new computational framework for understanding the brain's neural code.Advancing geospatial science to tackle planet-scale challengesGoogle Research is also accelerating geospatial problem solving by making critical information more accessible. We recently launched the first FireSat satellite to help address wildfires. As we expand the constellation to more than 50 satellites, the high-resolution imagery, updated globally every 20 minutes, will help emergency responders detect wildfires at an earlier stage and help scientists understand how wildfires spread. We’ve also driven climate resilience and crisis response with our advanced AI models for Flood Forecasting and WeatherNext models. Geospatial Reasoning is a new research effort that seeks to combine the power of our geospatial foundation models with generative AI to uncover powerful and actionable information — all through a simple conversational interface. It builds on prior models including those for floods, wildfires and weather, as well as Open Buildings and SKAI models and expands our previous Population Dynamics and trajectory-based mobility foundational models. Geospatial Reasoning can be a critical tool for advancing public health, urban planning, integrated business planning, climate science and more.Advancing quantum computing towards real-world applicationsFor more than a decade, we’ve been making progress toward building large-scale quantum computers that can solve otherwise impossible problems. Our new Willow chip is a major milestone, demonstrating error correction and state-of-the-art performance. On World Quantum Day, we highlighted how it’s bringing us closer to real-world applications. For example, in collaboration with Sandia National Laboratories, we demonstrated that a quantum algorithm could more efficiently simulate the mechanisms needed for sustained fusion reactions. This could help make fusion energy a reality, with its potential for clean energy at scale. We continue to advance our quantum research, and recently shared a novel hybrid approach to quantum simulation that paves the way for further scientific discoveries. The promise of AI is now becoming a reality across scientific disciplines. We’ll continue to ask the biggest questions and address challenges that were previously unsolvable in pursuit of scientific breakthroughs that can benefit billions. Related stories",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ScientificDiscovery_SS_1920x1080.width-1300.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"jump-content\" tabindex=\"-1\"\u003e\n            \n\n    \n    \n\n    \u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\u0026#34;\n  }\"\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eMay 08, 2025\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          Google Research teams are using AI to address fundamental scientific questions and advance research across disciplines from biomedical science and neuroscience to geospatial science and quantum computing.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n      \n\n\n\n\n\n\n\n\n\n\n\u003cdiv\u003e\n    \u003cfigure\u003e\n      \u003cdiv\u003e\n        \u003cp\u003e\u003cimg alt=\"Collage on a black background showing scientific images including a gloved hand on a microscope and a quantum computer\" data-component=\"uni-progressive-image\" fetchpriority=\"high\" height=\"150px\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ScientificDiscovery_Hero_2097x118.width-200.format-webp.webp\" width=\"360px\" data-sizes=\"(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px\" data-srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ScientificDiscovery_Hero_2097x118.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ScientificDiscovery_Hero_2097x11.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ScientificDiscovery_Hero_2097x11.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ScientificDiscovery_Hero_2097x11.width-2200.format-webp.webp 2200w\"/\u003e\n        \u003c/p\u003e\n      \u003c/div\u003e\n      \n    \u003c/figure\u003e\n  \u003c/div\u003e\n\n\n\n\n\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\n\n\n\u003cuni-article-speakable page-title=\"How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\" listen-to-article=\"Listen to article\" data-date-modified=\"2025-05-08T17:25:07.552680+00:00\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-script-src=\"https://www.gstatic.com/readaloud/player/web/api/js/api.js\"\u003e\u003c/uni-article-speakable\u003e\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"k8q3h\"\u003eAI has long driven scientific advances at Google, and the velocity at which breakthroughs are happening today is unprecedented. AI’s increasing capabilities have made the “\u003ca href=\"https://blog.google/technology/research/what-is-google-research/\"\u003emagic cycle\u003c/a\u003e” of research from breakthrough to real-world impact broader and quicker than ever.\u003c/p\u003e\u003cp data-block-key=\"3oer9\"\u003eAI is an amplifier of human ingenuity. At Google, our teams are using AI to address fundamental scientific questions and push the boundaries of what’s possible, leading to new understanding of life and novel solutions to humanity’s greatest challenges. As we accelerate scientific discovery, we collaborate closely with the scientific community and ecosystem, across both industry and academia, and make our tech and tools available to our partners for their own research.\u003c/p\u003e\u003cp data-block-key=\"1oa9q\"\u003eHere are four areas where Google Research has shared recent breakthroughs with meaningful scientific and societal impact.\u003c/p\u003e\u003ch2 data-block-key=\"1q0bq\"\u003eAdvancing biomedical science to better treat disease\u003c/h2\u003e\u003cp data-block-key=\"cp9ju\"\u003eWe’re excited about the potential of AI to personalize medicine, democratize science and open up new avenues for biological and medical discovery. Our \u003ca href=\"https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/\"\u003eAI co-scientist\u003c/a\u003e aims to help expedite the process of \u003ca href=\"https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/\"\u003emaking new biomedical discoveries\u003c/a\u003e. This multi-agent system uses AI’s ability to synthesize information and perform complex reasoning tasks to aid scientists in creating novel hypotheses and research proposals using natural language.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n\u003cuni-related-content-tout title=\"We’re launching a new AI system for scientists.\" cta=\"See more\" summary=\"AI co-scientist is a new AI system built on Gemini 2.0 and designed to aid scientists in creating novel hypotheses and research plans.\" hideimage=\"False\" eyebrow=\"\" image-alt-text=\"A chart showing how AI co-scientist works to create a research plan after a scientist specifies a research goal\" role=\"none\" externalurl=\"https://blog.google/feed/google-research-ai-co-scientist/\" fullurl=\"\" pagetype=\"\" isarticlepage=\"\"\u003e\n  \n    \u003cdiv slot=\"rct-image-slot\"\u003e\n      \n    \u003cfigure\u003e\n        \u003cpicture\u003e\n            \n\n\n    \n\n    \n        \u003csource media=\"(max-resolution: 1.5dppx)\" sizes=\"300px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Coscientist_SocialShare.max-1440x.width-300.format-webp.webp 300w\"/\u003e\n    \n        \u003csource media=\"(min-resolution: 1.5dppx)\" sizes=\"600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Coscientist_SocialShare.max-1440x.width-600.format-webp.webp 600w\"/\u003e\n    \n\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Coscientist_SocialShare.max-1440x.width-600.format-webp.webp\" alt=\"A chart showing how AI co-scientist works to create a research plan after a scientist specifies a research goal\" sizes=\" 300px,  600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Coscientist_SocialShare.max-1440x.width-300.format-webp.webp 300w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Coscientist_SocialShare.max-1440x.width-600.format-webp.webp 600w\" data-target=\"image\" loading=\"lazy\"/\u003e\n    \n\n\n        \u003c/picture\u003e\n    \u003c/figure\u003e\n\n\n    \u003c/div\u003e\n  \n\u003c/uni-related-content-tout\u003e\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"k8q3h\"\u003eWe recently introduced a \u003ca href=\"https://research.google/blog/amie-gains-vision-a-research-ai-agent-for-multi-modal-diagnostic-dialogue/\"\u003emultimodal version\u003c/a\u003e of \u003ca href=\"https://research.google/blog/amie-a-research-ai-system-for-diagnostic-medical-reasoning-and-conversations/\"\u003eAMIE\u003c/a\u003e, a research AI agent for medical diagnostic conversations \u003ca href=\"https://www.nature.com/articles/s41586-025-08866-7\"\u003epublished\u003c/a\u003e in \u003ca href=\"https://www.nature.com/articles/s41586-025-08869-4\"\u003e\u003ci\u003eNature\u003c/i\u003e\u003c/a\u003e. It can intelligently interpret and reason about visual medical information, working towards more accurate diagnosis. AMIE builds upon our earlier work on \u003ca href=\"https://www.nature.com/articles/s41586-023-06291-2\"\u003eMedPaLM\u003c/a\u003e and subsequent language models fine-tuned for the \u003ca href=\"https://sites.research.google/med-palm/\"\u003emedical domain\u003c/a\u003e. We continue to add assets to \u003ca href=\"https://developers.google.com/health-ai-developer-foundations\"\u003eHealth AI Developer Foundations\u003c/a\u003e to help developers build medical AI applications and we released \u003ca href=\"https://developers.googleblog.com/en/introducing-txgemma-open-models-improving-therapeutics-development/\"\u003eTxGemma\u003c/a\u003e, a collection of open models designed to improve the efficiency of therapeutic development, building on our embeddings models for chest x-rays, digital pathology and dermatology.\u003c/p\u003e\u003cp data-block-key=\"debtg\"\u003eWe keep advancing research into genomics, too, to better understand individuals\u0026#39; genetic predispositions to illnesses and to diagnose rare diseases. \u003ca href=\"https://www.nature.com/articles/s41588-024-01831-6\"\u003eREGLE\u003c/a\u003e is an unsupervised deep learning model that helps researchers discover associations with genetic variants. And we open sourced new \u003ca href=\"https://github.com/google/deepvariant/blob/r1.8/docs/pangenome-aware-wgs-vg-case-study.md\"\u003eDeepVariant models\u003c/a\u003e as part of a collaboration on \u003ca href=\"https://www.nature.com/articles/s41592-024-02407-2\"\u003ePersonalized Pangenome References\u003c/a\u003e, which can reduce errors by 30% when analyzing genomes of diverse ancestries.\u003c/p\u003e\u003ch2 data-block-key=\"5t1ss\"\u003eAdvancing neuroscience research to demystify the brain\u003c/h2\u003e\u003cp data-block-key=\"5m8vv\"\u003eOver the past decade, we’ve made fundamental contributions to the field of \u003ca href=\"https://sites.research.google/neural-mapping/\"\u003econnectomics\u003c/a\u003e and furthered scientific understanding of the workings of the brain. Just yesterday in \u003ci\u003eNature\u003c/i\u003e, a team from Google Research and ISTA \u003ca href=\"https://www.nature.com/articles/s41586-025-08985-1\"\u003epublished\u003c/a\u003e on \u003ca href=\"https://research.google/blog/a-new-light-on-neural-connections/\"\u003eLICONN\u003c/a\u003e, the first-ever method for using commonly available light microscopes to comprehensively map neurons and their connections in brain tissue. LICONN will enable more labs around the world to pursue connectomics studies.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n\u003cuni-related-content-tout title=\"Google Research and ISTA are using light microscopes to “map” the brain.\" cta=\"See more\" summary=\"In collaboration with ISTA, we’ve helped develop a new method for brain mapping, called LICONN, that could make connectomics significantly more accessible.\" hideimage=\"False\" eyebrow=\"\" image-alt-text=\"Collage illustration of the human brain in blue, yellow, orange, pink and purple, with a black square in the middle. In the black square are colorful neurons.\" role=\"none\" externalurl=\"https://blog.google/technology/research/liconn-connectomics\" fullurl=\"\" pagetype=\"\" isarticlepage=\"\"\u003e\n  \n    \u003cdiv slot=\"rct-image-slot\"\u003e\n      \n    \u003cfigure\u003e\n        \u003cpicture\u003e\n            \n\n\n    \n\n    \n        \u003csource media=\"(max-resolution: 1.5dppx)\" sizes=\"300px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LICONN_hero_2096x1182.width-300.format-webp.webp 300w\"/\u003e\n    \n        \u003csource media=\"(min-resolution: 1.5dppx)\" sizes=\"600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LICONN_hero_2096x1182.width-600.format-webp.webp 600w\"/\u003e\n    \n\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LICONN_hero_2096x1182.width-600.format-webp.webp\" alt=\"Collage illustration of the human brain in blue, yellow, orange, pink and purple, with a black square in the middle. In the black square are colorful neurons.\" sizes=\" 300px,  600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LICONN_hero_2096x1182.width-300.format-webp.webp 300w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LICONN_hero_2096x1182.width-600.format-webp.webp 600w\" data-target=\"image\" loading=\"lazy\"/\u003e\n    \n\n\n        \u003c/picture\u003e\n    \u003c/figure\u003e\n\n\n    \u003c/div\u003e\n  \n\u003c/uni-related-content-tout\u003e\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"k8q3h\"\u003eBuilding beyond neural connections, in collaboration with HHMI Janelia and Harvard, we introduced the \u003ca href=\"https://research.google/blog/improving-brain-models-with-zapbench/\"\u003eZebrafish Activity Prediction Benchmark\u003c/a\u003e (ZAPBench) with recordings of more than 70,000 neurons from the entire brain of the larval zebrafish. This allows researchers to \u003ca href=\"https://arxiv.org/abs/2503.02618\"\u003einvestigate the relationship\u003c/a\u003e between the structural wiring and dynamic neural activity across an entire vertebrate brain for the first time. We’ve \u003ca href=\"https://zapbench-release.storage.googleapis.com/landing.html\"\u003eopen-sourced the dataset and benchmark\u003c/a\u003e to help neuroscientists develop more accurate brain activity models.\u003c/p\u003e\u003cp data-block-key=\"d1002\"\u003eWe’ve also explored the similarities and differences in how the human brain and deep language models \u003ca href=\"https://research.google/blog/deciphering-language-processing-in-the-human-brain-through-llm-representations/\"\u003eprocess natural language\u003c/a\u003e through a \u003ca href=\"https://www.nature.com/articles/s41593-022-01026-4\"\u003eseries\u003c/a\u003e \u003ca href=\"https://www.nature.com/articles/s41467-024-46631-y\"\u003eof\u003c/a\u003e \u003ca href=\"https://www.nature.com/articles/s41562-025-02105-9\"\u003estudies\u003c/a\u003e in collaboration with \u003ca href=\"https://hassonlab.princeton.edu/\"\u003ePrinceton University\u003c/a\u003e, \u003ca href=\"https://nyulangone.org/locations/comprehensive-epilepsy-center\"\u003eNYU\u003c/a\u003e and \u003ca href=\"https://www.deepcognitionlab.com/\"\u003eHUJI\u003c/a\u003e. Our findings indicate that deep learning models could offer a new computational framework for understanding the brain\u0026#39;s neural code.\u003c/p\u003e\u003ch2 data-block-key=\"449hr\"\u003eAdvancing geospatial science to tackle planet-scale challenges\u003c/h2\u003e\u003cp data-block-key=\"cn4n4\"\u003eGoogle Research is also accelerating geospatial problem solving by making critical information more accessible. We recently launched the \u003ca href=\"https://blog.google/feed/firesat-first-satellite-launch/\"\u003efirst FireSat satellite\u003c/a\u003e to help \u003ca href=\"https://sites.research.google/gr/wildfires/\"\u003eaddress wildfires\u003c/a\u003e. As we expand the constellation to more than 50 satellites, the high-resolution imagery, updated globally every 20 minutes, will help emergency responders detect wildfires at an earlier stage and help scientists understand how wildfires spread. We’ve also driven climate resilience and crisis response with our advanced \u003ca href=\"https://www.nature.com/articles/s41586-024-07145-1\"\u003eAI models\u003c/a\u003e for \u003ca href=\"https://blog.google/technology/ai/google-ai-global-flood-forecasting/\"\u003eFlood Forecasting\u003c/a\u003e and \u003ca href=\"https://blog.google/products/google-cloud/scientific-research-tools-ai/\"\u003eWeatherNext\u003c/a\u003e models.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n\u003cuni-related-content-tout title=\"Inside the launch of FireSat\" cta=\"See more\" summary=\"Learn more about Google Research’s FireSat project, built to detect small wildfires.\" hideimage=\"False\" eyebrow=\"Related Article\" image-alt-text=\"A digital collage on a black background featuring a purple globe with white lines, a small satellite with gold panels, a bright yellow circle, and two small images, one with red and blue colors and the other showing a landscape with a dark patch.\" role=\"none\" fullurl=\"https://blog.google/technology/ai/inside-firesat-launch-muon-space/\" pagetype=\"articlepage\" isarticlepage=\"\" data-ga4-related-article=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;article_lead_click\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;Inside the launch of FireSat, a system to find wildfires earlier\u0026#34;,\n  \u0026#34;link_type\u0026#34;: \u0026#34;internal\u0026#34;,\n  \u0026#34;full_url\u0026#34;: \u0026#34;https://blog.google/technology/ai/inside-firesat-launch-muon-space/\u0026#34;,\n  \u0026#34;title\u0026#34;: \u0026#34;Inside the launch of FireSat, a system to find wildfires earlier\u0026#34;,\n  \u0026#34;author\u0026#34; : \u0026#34;Molly McHugh-Johnson\u0026#34;,\n  \u0026#34;slug\u0026#34;: \u0026#34;inside-firesat-launch-muon-space\u0026#34;,\n  \u0026#34;position\u0026#34;: \u0026#34;1 of 1\u0026#34;,\n  \u0026#34;click_location\u0026#34;: \u0026#34;undefined\u0026#34;,\n  \u0026#34;primary_tag\u0026#34;: \u0026#34;Topics - AI\u0026#34;,\n  \u0026#34;secondary_tags\u0026#34;: \u0026#34;Research,Sustainability\u0026#34;,\n  \u0026#34;published_date\u0026#34;: \u0026#34;2025-03-17|12:00\u0026#34;,\n  \u0026#34;hero_media_type\u0026#34;: \u0026#34;image\u0026#34;,\n  \u0026#34;days_since_published\u0026#34;: \u0026#34;52\u0026#34;,\n  \u0026#34;content_category\u0026#34;: \u0026#34;Editorial feature\u0026#34;,\n  \u0026#34;word_count\u0026#34;: \u0026#34;995\u0026#34;,\n  \u0026#34;has_audio\u0026#34;: \u0026#34;no\u0026#34;,\n  \u0026#34;has_video\u0026#34;: \u0026#34;yes\u0026#34;,\n  \u0026#34;has_image\u0026#34;: \u0026#34;yes\u0026#34;,\n  \u0026#34;has_carousel\u0026#34;: \u0026#34;no\u0026#34;\n}\"\u003e\n  \n    \u003cdiv slot=\"rct-image-slot\"\u003e\n      \n    \u003cfigure\u003e\n        \u003cpicture\u003e\n            \n\n\n    \n\n    \n        \u003csource media=\"(max-resolution: 1.5dppx)\" sizes=\"300px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FireSat_v2_1_Hero.width-300.format-webp.webp 300w\"/\u003e\n    \n        \u003csource media=\"(min-resolution: 1.5dppx)\" sizes=\"600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FireSat_v2_1_Hero.width-600.format-webp.webp 600w\"/\u003e\n    \n\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FireSat_v2_1_Hero.width-600.format-webp.webp\" alt=\"A digital collage on a black background featuring a purple globe with white lines, a small satellite with gold panels, a bright yellow circle, and two small images, one with red and blue colors and the other showing a landscape with a dark patch.\" sizes=\" 300px,  600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FireSat_v2_1_Hero.width-300.format-webp.webp 300w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FireSat_v2_1_Hero.width-600.format-webp.webp 600w\" data-target=\"image\" loading=\"lazy\"/\u003e\n    \n\n\n        \u003c/picture\u003e\n    \u003c/figure\u003e\n\n\n    \u003c/div\u003e\n  \n\u003c/uni-related-content-tout\u003e\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"k8q3h\"\u003e\u003ca href=\"https://research.google/blog/geospatial-reasoning-unlocking-insights-with-generative-ai-and-multiple-foundation-models/\"\u003eGeospatial Reasoning\u003c/a\u003e is a new research effort that seeks to combine the power of our geospatial foundation models with generative AI to uncover powerful and actionable information — all through a simple conversational interface. It builds on prior models including those for floods, wildfires and weather, as well as \u003ca href=\"https://sites.research.google/gr/open-buildings/\"\u003eOpen Buildings\u003c/a\u003e and \u003ca href=\"https://disha.unglobalpulse.org/ai-from-google-research-and-un-boosts-humanitarian-disaster-response-wider-coverage-faster-damage-assessments/\"\u003eSKAI\u003c/a\u003e models and expands our previous \u003ca href=\"https://research.google/blog/insights-into-population-dynamics-a-foundation-model-for-geospatial-inference/\"\u003ePopulation Dynamics\u003c/a\u003e and \u003ca href=\"https://dl.acm.org/doi/10.1145/3681766.3699610\"\u003etrajectory-based mobility\u003c/a\u003e foundational models. Geospatial Reasoning can be a critical tool for advancing public health, urban planning, integrated business planning, climate science and more.\u003c/p\u003e\u003ch2 data-block-key=\"p58r\"\u003eAdvancing quantum computing towards real-world applications\u003c/h2\u003e\u003cp data-block-key=\"68usd\"\u003eFor more than a decade, we’ve been making progress toward building large-scale quantum computers that can solve otherwise impossible problems. Our new \u003ca href=\"https://blog.google/technology/research/google-willow-quantum-chip/\"\u003eWillow\u003c/a\u003e chip is a major milestone, demonstrating error correction and state-of-the-art performance. On World Quantum Day, we highlighted how it’s bringing us closer to \u003ca href=\"https://blog.google/technology/research/google-quantum-computer-real-world-applications/\"\u003ereal-world applications\u003c/a\u003e. For example, in collaboration with \u003ca href=\"https://www.sandia.gov/research/news/sandia-and-google-unleash-new-possibilities-in-quantum-computing/\"\u003eSandia\u003c/a\u003e National Laboratories, we \u003ca href=\"https://www.pnas.org/doi/epdf/10.1073/pnas.2317772121\"\u003edemonstrated\u003c/a\u003e that a quantum algorithm could more efficiently simulate the mechanisms needed for sustained fusion reactions. This could help make fusion energy a reality, with its potential for clean energy at scale. We continue to advance our quantum research, and recently \u003ca href=\"https://www.nature.com/articles/s41586-024-08460-3\"\u003eshared\u003c/a\u003e a novel \u003ca href=\"https://research.google/blog/a-new-hybrid-platform-for-quantum-simulation-of-magnetism/\"\u003ehybrid approach to quantum simulation\u003c/a\u003e that paves the way for further scientific discoveries.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n\u003cuni-related-content-tout title=\"Go inside the Google Quantum AI lab\" cta=\"See more\" summary=\"Get a behind-the-scenes look at Google\u0026#39;s Quantum AI lab in Santa Barbara, CA.\" hideimage=\"False\" eyebrow=\"Related Article\" image-alt-text=\"\" role=\"none\" fullurl=\"https://blog.google/technology/research/behind-the-scenes-google-quantum-ai-lab/\" pagetype=\"articlepage\" isarticlepage=\"\" data-ga4-related-article=\"{\n  \u0026#34;event\u0026#34;: \u0026#34;article_lead_click\u0026#34;,\n  \u0026#34;link_text\u0026#34;: \u0026#34;Go inside the Google Quantum AI lab to learn about how quantum computing works\u0026#34;,\n  \u0026#34;link_type\u0026#34;: \u0026#34;internal\u0026#34;,\n  \u0026#34;full_url\u0026#34;: \u0026#34;https://blog.google/technology/research/behind-the-scenes-google-quantum-ai-lab/\u0026#34;,\n  \u0026#34;title\u0026#34;: \u0026#34;Go inside the Google Quantum AI lab to learn about how quantum computing works\u0026#34;,\n  \u0026#34;author\u0026#34; : \u0026#34;Anthony Megrant, Yu Chen\u0026#34;,\n  \u0026#34;slug\u0026#34;: \u0026#34;behind-the-scenes-google-quantum-ai-lab\u0026#34;,\n  \u0026#34;position\u0026#34;: \u0026#34;1 of 1\u0026#34;,\n  \u0026#34;click_location\u0026#34;: \u0026#34;undefined\u0026#34;,\n  \u0026#34;primary_tag\u0026#34;: \u0026#34;Topics - Research\u0026#34;,\n  \u0026#34;secondary_tags\u0026#34;: \u0026#34;AI\u0026#34;,\n  \u0026#34;published_date\u0026#34;: \u0026#34;2024-12-09|18:30\u0026#34;,\n  \u0026#34;hero_media_type\u0026#34;: \u0026#34;video\u0026#34;,\n  \u0026#34;days_since_published\u0026#34;: \u0026#34;150\u0026#34;,\n  \u0026#34;content_category\u0026#34;: \u0026#34;Announcement\u0026#34;,\n  \u0026#34;word_count\u0026#34;: \u0026#34;801\u0026#34;,\n  \u0026#34;has_audio\u0026#34;: \u0026#34;no\u0026#34;,\n  \u0026#34;has_video\u0026#34;: \u0026#34;yes\u0026#34;,\n  \u0026#34;has_image\u0026#34;: \u0026#34;no\u0026#34;,\n  \u0026#34;has_carousel\u0026#34;: \u0026#34;no\u0026#34;\n}\"\u003e\n  \n    \u003cdiv slot=\"rct-image-slot\"\u003e\n      \n    \u003cfigure\u003e\n        \u003cpicture\u003e\n            \n\n\n    \n\n    \n        \u003csource media=\"(max-resolution: 1.5dppx)\" sizes=\"300px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Q_Lab_tour_Still006_1.width-300.format-webp.webp 300w\"/\u003e\n    \n        \u003csource media=\"(min-resolution: 1.5dppx)\" sizes=\"600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Q_Lab_tour_Still006_1.width-600.format-webp.webp 600w\"/\u003e\n    \n\n    \u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Q_Lab_tour_Still006_1.width-600.format-webp.webp\" alt=\"Q Lab tour Still006 (1)\" sizes=\" 300px,  600px\" srcset=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Q_Lab_tour_Still006_1.width-300.format-webp.webp 300w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Q_Lab_tour_Still006_1.width-600.format-webp.webp 600w\" data-target=\"image\" loading=\"lazy\"/\u003e\n    \n\n\n        \u003c/picture\u003e\n    \u003c/figure\u003e\n\n\n    \u003c/div\u003e\n  \n\u003c/uni-related-content-tout\u003e\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" role=\"presentation\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we\\u0027re using AI to drive scientific research with greater real\\u002Dworld benefit\u0026#34;\n         }\"\u003e\n        \u003cp data-block-key=\"k8q3h\"\u003eThe promise of AI is now becoming a reality across scientific disciplines. We’ll continue to ask the biggest questions and address challenges that were previously unsolvable in pursuit of scientific breakthroughs that can benefit billions.\u003c/p\u003e\n      \u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\n  \n\n\n\n\n\n  \n\n  \n\n\n\u003cdiv data-component=\"uni-related-articles\" data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Article Footer Related Stories\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;Related stories\u0026#34;\n  }\"\u003e\n        \u003ch3\u003e\n          \u003cp\u003e\n            Related stories\n          \u003c/p\u003e\n        \u003c/h3\u003e\n      \u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-05-08T17:30:00Z",
  "modifiedTime": null
}
