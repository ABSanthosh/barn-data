{
  "id": "3f21c728-40e3-44aa-ab3a-1688959c6226",
  "title": "Google Rolls Out New Gemini Model That Can Run On Robots Locally",
  "link": "https://hardware.slashdot.org/story/25/06/24/2150256/google-rolls-out-new-gemini-model-that-can-run-on-robots-locally?utm_source=rss1.0mainlinkanon\u0026utm_medium=feed",
  "description": "Google DeepMind has launched Gemini Robotics On-Device, a new language model that enables robots to perform complex tasks locally without internet connectivity. TechCrunch reports: Building on the company's previous Gemini Robotics model that was released in March, Gemini Robotics On-Device can control a robot's movements. Developers can control and fine-tune the model to suit various needs using natural language prompts. In benchmarks, Google claims the model performs at a level close to the cloud-based Gemini Robotics model. The company says it outperforms other on-device models in general benchmarks, though it didn't name those models. In a demo, the company showed robots running this local model doing things like unzipping bags and folding clothes. Google says that while the model was trained for ALOHA robots, it later adapted it to work on a bi-arm Franka FR3 robot and the Apollo humanoid robot by Apptronik. Google claims the bi-arm Franka FR3 was successful in tackling scenarios and objects it hadn't \"seen\" before, like doing assembly on an industrial belt. Google DeepMind is also releasing a Gemini Robotics SDK. The company said developers can show robots 50 to 100 demonstrations of tasks to train them on new tasks using these models on the MuJoCo physics simulator. Read more of this story at Slashdot.",
  "author": "BeauHD",
  "published": "2025-06-25T00:10:00+00:00",
  "source": "http://rss.slashdot.org/Slashdot/slashdotMain",
  "categories": [
    "robot"
  ],
  "byline": "",
  "length": 1296,
  "excerpt": "Google DeepMind has launched Gemini Robotics On-Device, a new language model that enables robots to perform complex tasks locally without internet connectivity. TechCrunch reports: Building on the company's previous Gemini Robotics model that was released in March, Gemini Robotics On-Device can con...",
  "siteName": "",
  "favicon": "",
  "text": "Google DeepMind has launched Gemini Robotics On-Device, a new language model that enables robots to perform complex tasks locally without internet connectivity. TechCrunch reports: Building on the company's previous Gemini Robotics model that was released in March, Gemini Robotics On-Device can control a robot's movements. Developers can control and fine-tune the model to suit various needs using natural language prompts. In benchmarks, Google claims the model performs at a level close to the cloud-based Gemini Robotics model. The company says it outperforms other on-device models in general benchmarks, though it didn't name those models. In a demo, the company showed robots running this local model doing things like unzipping bags and folding clothes. Google says that while the model was trained for ALOHA robots, it later adapted it to work on a bi-arm Franka FR3 robot and the Apollo humanoid robot by Apptronik. Google claims the bi-arm Franka FR3 was successful in tackling scenarios and objects it hadn't \"seen\" before, like doing assembly on an industrial belt. Google DeepMind is also releasing a Gemini Robotics SDK. The company said developers can show robots 50 to 100 demonstrations of tasks to train them on new tasks using these models on the MuJoCo physics simulator.",
  "image": "https://a.fsdn.com/sd/topics/robot_64.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"fhbody-178165831\"\u003e\n\t\n\t\t\n\t\n\n\t\n\t\t\n\t\t\u003cp\u003e\n\t\t\t\n\t\t \t\n\t\t\t\tGoogle DeepMind has \u003ca href=\"https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/\"\u003elaunched\u003c/a\u003e Gemini Robotics On-Device, a new language model that \u003ca href=\"https://techcrunch.com/2025/06/24/google-rolls-out-new-gemini-model-that-can-run-on-robots-locally/\"\u003eenables robots to perform complex tasks locally without internet connectivity\u003c/a\u003e. TechCrunch reports: \u003ci\u003e Building on the company\u0026#39;s previous Gemini Robotics model that was released in March, Gemini Robotics On-Device can control a robot\u0026#39;s movements. Developers can control and fine-tune the model to suit various needs using natural language prompts. In benchmarks, Google claims the model performs at a level close to the cloud-based Gemini Robotics model. The company says it outperforms other on-device models in general benchmarks, though it didn\u0026#39;t name those models.\n\u003cp\u003e \nIn a demo, the company showed robots running this local model doing things like unzipping bags and folding clothes. Google says that while the model was trained for ALOHA robots, it later adapted it to work on a bi-arm Franka FR3 robot and the Apollo humanoid robot by Apptronik. Google claims the bi-arm Franka FR3 was successful in tackling scenarios and objects it hadn\u0026#39;t \u0026#34;seen\u0026#34; before, like doing assembly on an industrial belt. Google DeepMind is also releasing a \u003ca href=\"https://github.com/google-deepmind/gemini-robotics-sdk\"\u003eGemini Robotics SDK\u003c/a\u003e. The company said developers can show robots 50 to 100 demonstrations of tasks to train them on new tasks using these models on the MuJoCo physics simulator.\u003c/p\u003e\u003c/i\u003e\n\t\t \t\n\t\t\u003c/p\u003e\n\n\t\t\n\n\t\t\n\n\t\t\n\t\t\t\n\t\t\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "2 min read",
  "publishedTime": null,
  "modifiedTime": null
}
