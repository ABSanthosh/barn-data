{
  "id": "9bc451f4-b44c-40d7-8a74-b939f27b4fd2",
  "title": "Functional ultrasound through the skull",
  "link": "https://brainhack.vercel.app/fus",
  "description": "Comments",
  "author": "",
  "published": "Fri, 01 Nov 2024 20:52:45 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "By: Raffi Hotter, Vincent Huang, Brian Machado, Thomas Ribeiro, and Anson Yu",
  "length": 15717,
  "excerpt": "We show new results for making functional ultrasound work through the skull.",
  "siteName": "",
  "favicon": "",
  "text": "Functional ultrasound imaging (fUSI) is an awesome new technology for imaging brain activity. Its spatial resolution can be even better than fMRI. The hardware to run ultrasound can be made compact and cheap. Could we possibly use it to make a brain-computer interface? Similar to the acousto-electric effect, fUSI could have 10,000x more channels than state-of-the-art EEG. Your browser does not support the video tag.Functional ultrasound in a rat brain (from Macé et al., 2011) So far, all fUSI experiments involve opening up the skull or replacing it with an acoustically-transparent window. Not the greatest if you want a non-invasive brain-computer interface. Could we do functional ultrasound with the skull intact? When we asked around about doing functional ultrasound with the skull intact, we were told it was impossible. There are two big challenges in it ultrasound work through the skull: High frequency ultrasound waves get distorted when they pass through the skull. If you use traditional ultrasound beamforming and don't account for this distortion, you're bound to fail. Your browser does not support the video tag.A 1 MHz ultrasound wave propagating through a skull model, obtained via CT. A 2D solver with no absorption was used for simplicity. (Jupyter notebook) The skull attenuates ultrasound, so there might not even be enough signal once the ultrasound has passed through the skull and back. People often quote 22 dB/cm/MHz attenuation of ultrasound. Decibels are a logarithmic scale, so with 1.4 cm of roundtrip skull distance, and typical fUSI frequencies of 10 MHz, this would be 14 orders of magnitude of attenuation! In physics, there's a word for 14 orders of magnitude of attenuation. It's called zero, i.e., you will measure nothing. But where did the 22 dB/cm/MHz attenuation number come from? We were skeptical of the methods used to measure this. We ran a 10-day hacksprint to try to answer if functional ultrasound through the skull was possible. Two main results: Attenuation through the skull is actually not as high as currently reported! We can de-abberrate the signal after it interfaces with the skull. Code and algorithm shared! What is functional ultrasound? Before anything else, a quick primer on functional ultrasound. Functional ultrasound measures changes in blood flow or volume in the brain. Blood changes are correlated with neural activity — more neurons firing means more energy consumed, which means more blood that will flow to deliver more energy. Functional ultrasound measures blood volume by sending short pulses of ultrasound into the brain. Because blood cells have a different acoustic impedance than the background, the blood cells scatter the sound waves. Ultrasound transducers then read the scattered sound waves and form an image of the scattering. What frequency to use? The first design question for an ultrasound imager is what frequency to use. Higher frequencies attenuate ultrasound more — the typical 10 MHz ultrasound would attenuate the signal to well below the noise levels of ultrasound transducers. You might then think to use as low of a frequency as you can. But there's a problem with that, too: as you lower the frequency, the amount of scattering from red blood cells decreases and you get less signal back. The physical reason for this is that the scattering is in the Rayleigh regime (the red blood cells are a lot smaller than the wavelength of ultrasound), and the scattering in this regime scales with the fourth power of frequency. So what's the optimal frequency? We modeled the ultrasound attenuation through the skull and the Rayleigh scattering from the blood and asked what frequency gives the most signal back. Ultrasound signal drop through bone for blood cells. This combines both reduced Rayleigh scattering and bone attenuation effects. This uses an attenuation of 10 dB/cm/MHz through 0.7 cm of skull each way. The attenuation is given relative to 5 MHz functional ultrasound without the skull, which is the lowest frequency we've seen people do functional ultrasound (Jupyter notebook) It turns out that 1.25 MHz gives the least signal drop for an attenuation of 10 dB/cm/MHz. So we use 1-2 MHz as a first guess.** The signal drop isn't the only metric that matters. Another relevant metric is contrast: higher frequencies will give higher contrast between the Rayleigh scattering blood cells and the background. Skull CT Scan The thing that nobody tells you is that you can buy a real human skull online (shoutout to skullsunlimited.com). We did that, and then CT scanned it. Here's what the CT scan looks like. We thought this was really cool! You can access the scan here. Your browser does not support the video tag. De-aberration To correct for the distortion of ultrasound through the skull, we developed our own skull de-aberration algorithm. Aberrations in the body come from changes in the speed of sound** Changes in density and even the stiffness of the material can also affect wave propagation, but those are less pronounced than changes in speed of sound in tissue., similar to how light bends in Snell's law. There are two problems here Bone has a much higher speed of sound (~2800 m/s) than the brain (~1540 m/s) Part of the skull is actually porous, filled with marrow. There's a big change in the speed of sound of the bone (~2800 m/s) and the marrow (~1540 m/s). Different parts of bone (source: Anatomy and Physiology) The problem is that traditional ultrasound imaging assumes that the medium's speed of sound is the same everywhere. The engine of our algorithm is a wave propagation simulator. It takes in a speed of sound map and source waves, and it simulates waves propagating through the medium. Your browser does not support the video tag. We use a CT scan of the skull to estimate the skull's speed of sound map. Then, our algorithm considers virtual sensors below the skull.** To go from the CT scan to a speed of sound map, we binarize the CT skull into tissue/marrow and bone. We set bone voxels to 2,800 m/s and the rest to 1,540 m/s. We use the wave solver to find a transformation between the data recorded at the actual sensors that are above the skull and the data that would have been recorded if they were at the virtual positions below the skull. Then, we use this transformation to act as if the sensors were below the skull, and apply standard delay-and-sum beamforming. The code for reproducing our results can be found in recon_skull.ipynb in our GitHub repository. How do we find the transformation?To find the transformation, we play a trick with time-reversing waves. If the sensors retransmit a time-reversed version of what they measured, you can, in some sense, “rewind” the waves.There's two parts to the transformation: on transmit and on receive.On transmit, we simulate the virtual sensors sending a plane wave, and we measure the signal at the real sensors. Then, in real life, we get the sensors to send a time-reversed version of what they measured in simulation. This should produce a plane wave at the virtual sensor location.On receive, we take the data measured by our real transducers in reality, and propagate the time-reversed version through the wave simulator, while recording at the virtual sensors. We use the virtual sensor data for the subsequent beamforming. We tested our algorithm in a 2D simulation, with a cross-section of our CT-scanned skull. We placed a small scatterer below the skull, and the goal was to reconstruct it. Regular beamforming completely fails, but our algorithm can correctly capture the location of the spot.* We also started to test our approach on real data. We have some preliminary results that show that we can de-abberate through a 3d printed squiggly material (meant to emulate the skull), but we need to do some more testing. In translating this approach to humans, we won't have access to a CT scan. But, perhaps an MRI would suffice. Or, maybe you could use machine learning to bypass de-aberration altogether. Attenuation measurements Now that we have a potential way to de-aberrate through the skull, we wanted to know if there would even be enough signal after the ultrasound passes through the skull and back. Ultrasound transducers have noise that's about 1 mPa/Hz1 \\text{ mPa}/\\sqrt{\\text{Hz}}, which is ~1 Pa for a ~1 MHz bandwidth (ref). So we need to make sure the signal we receive is above that. Why not just shoot more ultrasound?Unfortunately, there's a safety limit. Since the head absorbs ultrasound, it heats up a little bit. The safety limit imposed by the International Electrotechnical Commission (IEC) is 2ºC, so we need to make sure not to surpass that. To estimate how much signal we'd get back, we needed to know how much the skull attenuates ultrasound. You'd think the literature would have an answer to this, but different sources report widely different answers, from 8.3 dB/cm/MHz to 22 dB/cm/MHz. For some reason, 22 dB/cm/MHz is the number people will tell you in conversation. We decided to measure it ourselves. We built a little mechanical jig to hold an ultrasound probe on one side of the skull to transmit and a small hydrophone on the other to receive. More technical detailsWe had the probe send a plane wave through the skull and we measured the pressure levels at the hydrophone. Our jig allowed us to place the hydrophone in 9 different spots, so that we can be sure to capture as much of the wave as possible. We took 9 measurements at two different locations on the head (occipital and temporal), and also had a control without the skull. We used continuous wave transmission at multiple frequencies: 1 MHz, 2 MHz, and 3 MHz.We used a Phillips P4-1 probe that we found on Ebay. We chose it because it was the transducer that operated at the lowest frequencies we could find (1-4 MHz bandwidth). We measured the signal using an Onda HNR 500 connected directly to a standard oscilloscope. We drove the transducer using a Verasonics Vantage 64 system. The skull was degassed to remove air bubbles (which would otherwise cause lots of scattering) and it was placed in distilled water. Your browser does not support the video tag. A few hours before the hacksprint ended, we rushed to get some measurements in. We only had time to take measurements at two jig locations on the head (with 9 hydrophone spots at each location). This is the attenuation we measured: The attenuation we measured was 11.18 dB/cm/MHz, which was on the lower side of what we saw in the literature. How did we compute attenuation?First, the data was preprocessed by bandpass filtering the data around the reference frequency. Then, for each jig location, we computed the total power as the squared measurements summed over all 9 locations. Then we divided the total power at each jig location by the total power with no skull. We measured the thickness of the skull at each jig location with a digital caliper. See this Jupyter notebook for our data analysis. Why are our results different? Since we only had time to measure two jig locations (+ we sketchily removed a nonsensical outlier measurement), you should take our measurements with a grain of salt. But upon digging into the literature, we found big problems with using the Fry 1978 paper that measures 22 db/cm/MHz attenuation. Firstly, there is no mention in the paper of degassing the skull. Without degassing, there could be many air bubbles formed in the pores, which will scatter ultrasound heavily (since there is a huge mechanical impedance mismatch between air and water). Secondly, they use focused transmission, instead of sending plane waves. The skull will spread out the focus, so if you don't sample enough, you'll mistake spreading for attenuation. The only good reference we could find for attenuation across frequencies was a 2006 paper by White. They degas the skull and use plane waves. They claim to measure 8.53 dB/cm/MHz, but when we tried reproducing their analysis using their data, we got 11.9 dB/cm/MHz. This is very close to what we measured! An important point is that we measured attenuation, which is different from absorption. Attenuation also includes things like scattering and reflections. But it's absorption that really limits us, not attenuation, since absorption is what contributes to heating in the head. Our attenuation measurements serve as an upper bound on absorption. It could be that the absorption is a lot lower than the attenuation. Pinton et al find that with a 1 MHz pulsed source, only 2.7 dB/cm of the measured 13.3 dB/cm was due to absorption. Could fUSI through the skull work? So back to the key question: does fUSI through the skull get a high enough signal-to-noise ratio (SNR)? If we use 11 dB/cm/MHz as the attenuation value, we'd expect a signal drop of about 40 dB, or equivalently, 100x in pressure, relative to below-skull functional ultrasound (see the earlier plot). If we use 2.7 dB/cm/MHz, we get a signal drop of 22 dB, or 10x in pressure. Is that too low? We're not sure yet. It depends on the pressure changes that are typically seen in regular functional ultrasound. Unfortunately, we couldn't find that in the literature (if you know this number, please let us know). If the changes in regular functional ultrasound are 100 Pa, then we'd expect to see changes of about 1-10 Pa in functional ultrasound through the skull. This is 1-10 times larger than the noise floor of a transducer (~1 Pa). And we can use a functional ultrasound trick, called coherent compounding, to increase the SNR further. Note, this is the SNR in the sensor domain, but what we really care about is the SNR in the image domain. Doppler testbed We also built a testbed to test fUSI outside of simulation. We wanted it to have properties similar to those of the brain. Previous work showed that tofu is desirable as a phantom material, both because it is fast to get and because it has similar physical properties (density, speed of sound) as soft tissue. Because functional ultrasound works by detecting the movement of blood cells in blood vessels, we also needed a way to emulate blood vessels in the phantom. We accomplished this by building our own pump system. Syringe Pump We built our own syringe pump. Blood travels at around ~10 mm/s in small vessels in the brain, so we wanted our pump to have similar speeds. Initially we planned on using a peristaltic pump, however we could not source one that had a small enough volumetric flow rate, and at slow speeds peristaltic pumps flow rate is not consistent. Technical detailsWe purchased a premade stepper motor driven linear actuator, and mounted it to a base plate. Normal sterile syringes of different sizes were used and custom mounts for each one could be swapped in; this along with adjusting the actuator speed in our Arduino code allows us to vary the volumetric flow rate. We also had various sizes of PTFE and silicone tubing to simulate different sized veins. We used Ultrasound Refill Fluid, which has similar acoustic properties to blood.The stepper motor was controlled by a TB6600 controller, and step signals were sent by a Teensy4.1 running this program we wrote to easily adjust flow rate, typically 1-10mm/sec, analogous to the rate at which blood cells in smaller blood vessels and capillaries move. We have AE at home Check out our other post, We have AE at home! Acknowledgements A big thank you to: Protocol Labs for sponsoring the hacksprint Hunter Davis, David Garrett, Sumner Norman, David Maresca, and Hari Kumar for technical advice Leo Zaroff for lending us his hydrophone and for advice Code The whole project is open source. You can find the code on our GitHub repository.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n\n\n\n\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Functional_ultrasound_imaging\"\u003eFunctional ultrasound imaging\u003c/a\u003e (fUSI) is an awesome new technology for imaging brain activity. Its spatial resolution can be even better than fMRI. The hardware to run ultrasound can be made \u003ca href=\"https://www.butterflynetwork.com/\"\u003ecompact and cheap\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCould we possibly use it to make a brain-computer interface? Similar to the \u003ca href=\"https://brainhack.vercel.app/ae\"\u003eacousto-electric effect\u003c/a\u003e, fUSI could have \u003cstrong\u003e10,000x\u003c/strong\u003e more channels than state-of-the-art EEG.\u003c/p\u003e\n\u003cfigure\u003e\u003cvideo loop=\"\" playsinline=\"\" muted=\"\" autoplay=\"\"\u003e\u003csource src=\"https://pub-9ded51b796ab46ffb6c70940cf4b6be4.r2.dev/fus.mp4\" type=\"video/mp4\"/\u003eYour browser does not support the video tag.\u003c/video\u003e\u003cfigcaption\u003e\u003cp\u003eFunctional ultrasound in a rat brain (from \u003ca href=\"https://www.nature.com/articles/nmeth.1641\"\u003eMacé et al., 2011\u003c/a\u003e)\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003eSo far, all fUSI experiments involve opening up the skull or replacing it with an \u003ca href=\"https://www.science.org/doi/10.1126/scitranslmed.adj3143\"\u003eacoustically-transparent window\u003c/a\u003e. Not the greatest if you want a non-invasive brain-computer interface. Could we do functional ultrasound with the skull intact?\u003c/p\u003e\n\u003cp\u003eWhen we asked around about doing functional ultrasound with the skull intact, we were told it was impossible. There are two big challenges in it ultrasound work through the skull:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eHigh frequency ultrasound waves get distorted when they pass through the skull. If you use traditional ultrasound beamforming and don\u0026#39;t account for this distortion, you\u0026#39;re bound to fail.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cfigure\u003e\u003cvideo loop=\"\" playsinline=\"\" muted=\"\" autoplay=\"\"\u003e\u003csource src=\"https://pub-9ded51b796ab46ffb6c70940cf4b6be4.r2.dev/pressure_animation_1.0MHz.mp4\" type=\"video/mp4\"/\u003eYour browser does not support the video tag.\u003c/video\u003e\u003cfigcaption\u003e\u003cp\u003eA 1 MHz ultrasound wave propagating through a skull model, obtained via CT. A 2D solver with no absorption was used for simplicity. (\u003ca href=\"https://github.com/Brain-Hack-2024/transcranial-ultrasound/blob/main/skull-propagation/skull_propagation.ipynb\"\u003eJupyter notebook\u003c/a\u003e)\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eThe skull attenuates ultrasound, so there might not even be enough signal once the ultrasound has passed through the skull and back.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003ca href=\"https://www.cambridge.org/core/books/diagnostic-ultrasound/E49EEE09C4081D1EFE1DC457C7D7973C\"\u003ePeople\u003c/a\u003e \u003ca href=\"https://www.sciencedirect.com/book/9780122228001/physical-properties-of-tissues\"\u003eoften\u003c/a\u003e \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/690336/\"\u003equote\u003c/a\u003e 22 dB/cm/MHz attenuation of ultrasound. Decibels are a logarithmic scale, so with 1.4 cm of roundtrip skull distance, and typical fUSI frequencies of 10 MHz, this would be 14 orders of magnitude of attenuation! In physics, there\u0026#39;s a word for 14 orders of magnitude of attenuation. It\u0026#39;s called zero, i.e., you will measure nothing.\u003c/p\u003e\n\u003cp\u003eBut where did the 22 dB/cm/MHz attenuation number come from? We were skeptical of the methods used to measure this.\u003c/p\u003e\n\u003cp\u003eWe ran a 10-day hacksprint to try to answer if functional ultrasound through the skull was possible.\u003c/p\u003e\n\u003cp\u003eTwo main results:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eAttenuation through the skull is actually not as high as currently reported!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe can de-abberrate the signal after it interfaces with the skull. Code and algorithm shared!\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg alt=\"Banner image showing functional ultrasound through the skull\" loading=\"lazy\" width=\"10492\" height=\"2081\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner.49d0b6ef.png\u0026amp;w=3840\u0026amp;q=75 1x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner.49d0b6ef.png\u0026amp;w=3840\u0026amp;q=75\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Banner image showing functional ultrasound through the skull\" loading=\"lazy\" width=\"7969\" height=\"2081\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner-mobile.fa2255b1.png\u0026amp;w=3840\u0026amp;q=75 1x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner-mobile.fa2255b1.png\u0026amp;w=3840\u0026amp;q=75\"/\u003e\u003c/p\u003e\n\u003ch3\u003eWhat is functional ultrasound?\u003c/h3\u003e\n\u003cp\u003eBefore anything else, a quick primer on functional ultrasound. Functional ultrasound measures changes in blood flow or volume in the brain. Blood changes are correlated with neural activity — more neurons firing means more energy consumed, which means more blood that will flow to deliver more energy.\u003c/p\u003e\n\u003cp\u003eFunctional ultrasound measures blood volume by sending short pulses of ultrasound into the brain. Because blood cells have a different acoustic impedance than the background, the blood cells scatter the sound waves. Ultrasound transducers then read the scattered sound waves and form an image of the scattering.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Diagram illustrating functional ultrasound imaging process\" loading=\"lazy\" width=\"840\" height=\"1208\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffus_pic.af47d7df.png\u0026amp;w=1080\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffus_pic.af47d7df.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ffus_pic.af47d7df.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003c/figure\u003e\n\u003ch3\u003eWhat frequency to use?\u003c/h3\u003e\n\u003cp\u003eThe first design question for an ultrasound imager is what frequency to use. Higher frequencies attenuate ultrasound more — the typical 10 MHz ultrasound would attenuate the signal to well below the noise levels of ultrasound transducers.\u003c/p\u003e\n\u003cp\u003eYou might then think to use as low of a frequency as you can. But there\u0026#39;s a problem with that, too: as you lower the frequency, the amount of scattering from red blood cells decreases and you get less signal back. The physical reason for this is that the scattering is in the \u003ca href=\"https://en.wikipedia.org/wiki/Rayleigh_scattering\"\u003eRayleigh regime\u003c/a\u003e (the red blood cells are a lot smaller than the wavelength of ultrasound), and the scattering in this regime scales with the fourth power of frequency.\u003c/p\u003e\n\u003cp\u003eSo what\u0026#39;s the optimal frequency? We modeled the ultrasound attenuation through the skull and the Rayleigh scattering from the blood and asked what frequency gives the most signal back.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Graph showing ultrasound signal drop through bone for blood cells\" loading=\"lazy\" width=\"689\" height=\"470\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fattenuation.32d23ef6.png\u0026amp;w=750\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fattenuation.32d23ef6.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fattenuation.32d23ef6.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003cfigcaption\u003e\u003cp\u003eUltrasound signal drop through bone for blood cells. This combines both reduced Rayleigh scattering and bone attenuation effects. This uses an attenuation of 10 dB/cm/MHz through 0.7 cm of skull each way. The attenuation is given relative to 5 MHz functional ultrasound without the skull, which is the lowest frequency we\u0026#39;ve seen people do functional ultrasound (\u003ca href=\"https://github.com/Brain-Hack-2024/transcranial-ultrasound/blob/main/frequency-selection/main.ipynb\"\u003eJupyter notebook\u003c/a\u003e)\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003eIt turns out that 1.25 MHz gives the least signal drop for an attenuation of 10 dB/cm/MHz. So we use 1-2 MHz as a first guess.\u003cspan\u003e\u003csup\u003e*\u003c/sup\u003e\u003c/span\u003e\u003c/p\u003e\u003cp\u003e* The signal drop isn\u0026#39;t the only metric that matters. Another relevant metric is contrast: higher frequencies will give higher contrast between the Rayleigh scattering blood cells and the background.\u003c/p\u003e\n\u003ch3\u003eSkull CT Scan\u003c/h3\u003e\n\u003cp\u003eThe thing that nobody tells you is that you can buy a real human skull online (shoutout to \u003ca href=\"https://skullsunlimited.com\"\u003eskullsunlimited.com\u003c/a\u003e). We did that, and then CT scanned it.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Photo of a human skull used for CT scanning\" loading=\"lazy\" width=\"803\" height=\"803\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fskull.cfc98049.png\u0026amp;w=828\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fskull.cfc98049.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fskull.cfc98049.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003c/figure\u003e\n\u003cp\u003eHere\u0026#39;s what the CT scan looks like. We thought this was really cool! You can access the scan \u003ca href=\"https://drive.google.com/file/d/1_DwyJauas5qvFQ3T0cpL_5P-mgHvKkRE/view?usp=sharing\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cfigure\u003e\u003cvideo loop=\"\" playsinline=\"\" muted=\"\" autoplay=\"\"\u003e\u003csource src=\"https://pub-9ded51b796ab46ffb6c70940cf4b6be4.r2.dev/ct.mp4\" type=\"video/mp4\"/\u003eYour browser does not support the video tag.\u003c/video\u003e\u003c/figure\u003e\n\u003ch3\u003eDe-aberration\u003c/h3\u003e\n\u003cp\u003eTo correct for the distortion of ultrasound through the skull, we developed our own skull de-aberration algorithm.\u003c/p\u003e\n\u003cp\u003eAberrations in the body come from changes in the speed of sound\u003cspan\u003e\u003csup\u003e*\u003c/sup\u003e\u003c/span\u003e\u003c/p\u003e\u003cp\u003e* Changes in density and even the stiffness of the material can also affect wave propagation, but those are less pronounced than changes in speed of sound in tissue.\u003c/p\u003e\u003cp\u003e, similar to how light bends in Snell\u0026#39;s law. There are two problems here\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eBone has a much higher speed of sound (~2800 m/s) than the brain (~1540 m/s)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePart of the skull is actually porous, filled with marrow. There\u0026#39;s a big change in the speed of sound of the bone (~2800 m/s) and the marrow (~1540 m/s).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cfigure\u003e\u003cimg alt=\"Diagram showing different parts of bone structure\" loading=\"lazy\" width=\"800\" height=\"405\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fskull-regions.f3339dd9.png\u0026amp;w=828\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fskull-regions.f3339dd9.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fskull-regions.f3339dd9.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003cfigcaption\u003e\u003cp\u003eDifferent parts of bone (source: \u003ca href=\"https://openstax.org/books/anatomy-and-physiology/pages/6-3-bone-structure\"\u003eAnatomy and Physiology\u003c/a\u003e)\u003c/p\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\u003cp\u003eThe problem is that traditional ultrasound imaging assumes that the medium\u0026#39;s speed of sound is the same everywhere.\u003c/p\u003e\n\u003cp\u003eThe engine of our algorithm is a wave propagation simulator. It takes in a speed of sound map and source waves, and it simulates waves propagating through the medium.\u003c/p\u003e\n\u003cfigure\u003e\u003cvideo loop=\"\" playsinline=\"\" muted=\"\" autoplay=\"\"\u003e\u003csource src=\"https://pub-9ded51b796ab46ffb6c70940cf4b6be4.r2.dev/waves.mp4\" type=\"video/mp4\"/\u003eYour browser does not support the video tag.\u003c/video\u003e\u003c/figure\u003e\n\u003cp\u003eWe use a CT scan of the skull to estimate the skull\u0026#39;s speed of sound map. Then, our algorithm considers virtual sensors below the skull.\u003cspan\u003e\u003csup\u003e*\u003c/sup\u003e\u003c/span\u003e\u003c/p\u003e\u003cp\u003e* To go from the CT scan to a speed of sound map, we binarize the CT skull into tissue/marrow and bone. We set bone voxels to 2,800 m/s and the rest to 1,540 m/s.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Diagram illustrating virtual sensors below the skull\" loading=\"lazy\" width=\"1314\" height=\"1032\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fvirtual-sensors.68347ad2.png\u0026amp;w=1920\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fvirtual-sensors.68347ad2.png\u0026amp;w=3840\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fvirtual-sensors.68347ad2.png\u0026amp;w=3840\u0026amp;q=75\"/\u003e\u003c/figure\u003e\n\u003cp\u003eWe use the wave solver to find a transformation between the data recorded at the actual sensors that are above the skull and the data that would have been recorded if they were at the virtual positions below the skull. Then, we use this transformation to act as if the sensors were below the skull, and apply standard delay-and-sum beamforming. The code for reproducing our results can be found in \u003ca href=\"https://github.com/Brain-Hack-2024/transcranial-ultrasound/blob/main/notebooks/recon_skull.ipynb\"\u003e\u003ccode\u003erecon_skull.ipynb\u003c/code\u003e\u003c/a\u003e in our GitHub repository.\u003c/p\u003e\n\u003cdetails\u003e\u003csummary\u003eHow do we find the transformation?\u003c/summary\u003e\u003cdiv\u003e\u003cp\u003eTo find the transformation, we play a trick with time-reversing waves. If the sensors retransmit a time-reversed version of what they measured, you can, in some sense, “rewind” the waves.\u003c/p\u003e\u003cp\u003eThere\u0026#39;s two parts to the transformation: on transmit and on receive.\u003c/p\u003e\u003cp\u003eOn transmit, we simulate the virtual sensors sending a plane wave, and we measure the signal at the real sensors. Then, in real life, we get the sensors to send a time-reversed version of what they measured in simulation. This should produce a plane wave at the virtual sensor location.\u003c/p\u003e\u003cfigure\u003e\u003cimg alt=\"Diagram showing plane wave propagation through the skull\" loading=\"lazy\" width=\"836\" height=\"594\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fplane_wave.35f9d889.png\u0026amp;w=1080\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fplane_wave.35f9d889.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fplane_wave.35f9d889.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003c/figure\u003e\u003cp\u003eOn receive, we take the data measured by our real transducers in reality, and propagate the time-reversed version through the wave simulator, while recording at the virtual sensors. We use the virtual sensor data for the subsequent beamforming.\u003c/p\u003e\u003c/div\u003e\u003c/details\u003e\n\u003cp\u003eWe tested our algorithm in a 2D simulation, with a cross-section of our CT-scanned skull. We placed a small scatterer below the skull, and the goal was to reconstruct it.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Comparison of regular beamforming and de-aberration algorithm results\" loading=\"lazy\" width=\"1970\" height=\"668\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faberration-correction.3f9db8a9.png\u0026amp;w=2048\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faberration-correction.3f9db8a9.png\u0026amp;w=3840\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Faberration-correction.3f9db8a9.png\u0026amp;w=3840\u0026amp;q=75\"/\u003e\u003c/figure\u003e\n\u003cp\u003eRegular beamforming completely fails, but our algorithm can correctly capture the location of the spot.\u003cspan\u003e\u003csup\u003e*\u003c/sup\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eWe also started to test our approach on real data. We have some preliminary results that show that we can de-abberate through a 3d printed squiggly material (meant to emulate the skull), but we need to do some more testing.\u003c/p\u003e\n\u003cp\u003eIn translating this approach to humans, we won\u0026#39;t have access to a CT scan. But, perhaps an MRI would suffice. Or, maybe you could use machine learning to bypass de-aberration altogether.\u003c/p\u003e\n\u003ch3\u003eAttenuation measurements\u003c/h3\u003e\n\u003cp\u003eNow that we have a potential way to de-aberrate through the skull, we wanted to know if there would even be enough signal after the ultrasound passes through the skull and back. Ultrasound transducers have noise that\u0026#39;s about \u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmn\u003e1\u003c/mn\u003e\u003cmtext\u003e mPa\u003c/mtext\u003e\u003cmi mathvariant=\"normal\"\u003e/\u003c/mi\u003e\u003cmsqrt\u003e\u003cmtext\u003eHz\u003c/mtext\u003e\u003c/msqrt\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e1 \\text{ mPa}/\\sqrt{\\text{Hz}}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e, which is ~1 Pa for a ~1 MHz bandwidth (\u003ca href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7407969/\"\u003eref\u003c/a\u003e). So we need to make sure the signal we receive is above that.\u003c/p\u003e\n\u003cdetails\u003e\u003csummary\u003eWhy not just shoot more ultrasound?\u003c/summary\u003e\u003cp\u003eUnfortunately, there\u0026#39;s a safety limit. Since the head absorbs ultrasound, it heats up a little bit. The safety limit imposed by the International Electrotechnical Commission (IEC) is 2ºC, so we need to make sure not to surpass that.\u003c/p\u003e\u003c/details\u003e\n\u003cp\u003eTo estimate how much signal we\u0026#39;d get back, we needed to know how much the skull attenuates ultrasound. You\u0026#39;d think the literature would have an answer to this, but different sources report widely different answers, from \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/16829322/\"\u003e8.3 dB/cm/MHz\u003c/a\u003e to \u003ca href=\"https://www.cambridge.org/core/books/diagnostic-ultrasound/E49EEE09C4081D1EFE1DC457C7D7973C\"\u003e22 dB/cm/MHz\u003c/a\u003e. For some reason, 22 dB/cm/MHz is the number people will tell you in conversation.\u003c/p\u003e\n\u003cp\u003eWe decided to measure it ourselves. We built a little mechanical jig to hold an ultrasound probe on one side of the skull to transmit and a small hydrophone on the other to receive.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg alt=\"Photo of the mechanical jig used for attenuation measurements\" loading=\"lazy\" width=\"1380\" height=\"946\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fattenuation-jig.2de833ea.jpg\u0026amp;w=1920\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fattenuation-jig.2de833ea.jpg\u0026amp;w=3840\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fattenuation-jig.2de833ea.jpg\u0026amp;w=3840\u0026amp;q=75\"/\u003e\u003c/figure\u003e\n\u003cdetails\u003e\u003csummary\u003eMore technical details\u003c/summary\u003e\u003cdiv\u003e\u003cp\u003eWe had the probe send a plane wave through the skull and we measured the pressure levels at the hydrophone. Our jig allowed us to place the hydrophone in 9 different spots, so that we can be sure to capture as much of the wave as possible. We took 9 measurements at two different locations on the head (occipital and temporal), and also had a control without the skull. We used continuous wave transmission at multiple frequencies: 1 MHz, 2 MHz, and 3 MHz.\u003c/p\u003e\u003cp\u003eWe used a \u003ca href=\"https://www.ebay.com/itm/115853090479\"\u003ePhillips P4-1\u003c/a\u003e probe that we found on Ebay. We chose it because it was the transducer that operated at the lowest frequencies we could find (1-4 MHz bandwidth). We measured the signal using an \u003ca href=\"https://www.ondacorp.com/hnr-needle-hydrophone/\"\u003eOnda HNR 500\u003c/a\u003e connected directly to a standard oscilloscope. We drove the transducer using a Verasonics Vantage 64 system. The skull was degassed to remove air bubbles (which would otherwise cause lots of scattering) and it was placed in distilled water.\u003c/p\u003e\u003c/div\u003e\u003c/details\u003e\n\u003cfigure\u003e\u003cvideo loop=\"\" playsinline=\"\" controls=\"\"\u003e\u003csource src=\"https://pub-9ded51b796ab46ffb6c70940cf4b6be4.r2.dev/skull_jig.mp4\" type=\"video/mp4\"/\u003eYour browser does not support the video tag.\u003c/video\u003e\u003c/figure\u003e\n\u003cp\u003eA few hours before the hacksprint ended, we rushed to get some measurements in. We only had time to take measurements at two jig locations on the head (with 9 hydrophone spots at each location). This is the attenuation we measured:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXdVQLRpMruD3GcXcEV3uhr9TDBUm4pfSxRCaotLB4aeJOQxQzLSdjncSBE_Y8oAvq2MTdw82_AttdTbsXttVqCWUd12lq35LiqsRF9MbNmwu7UX5X8ogQie4sRnegasRVfocWH9yQKw22syljPWx4MkUt5f?key=pBPggEzLFBh2YWTQGQnEtw\" alt=\"\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe attenuation we measured was 11.18 dB/cm/MHz, which was on the lower side of what we saw in the literature.\u003c/p\u003e\n\u003cdetails\u003e\u003csummary\u003e How did we compute attenuation?\u003c/summary\u003e\u003cp\u003eFirst, the data was preprocessed by bandpass filtering the data around the reference frequency. Then, for each jig location, we computed the total power as the squared measurements summed over all 9 locations. Then we divided the total power at each jig location by the total power with no skull. We measured the thickness of the skull at each jig location with a digital caliper. See this \u003ca href=\"https://github.com/Brain-Hack-2024/transcranial-ultrasound/blob/main/skull-attenuation-analysis/main.ipynb\"\u003eJupyter notebook\u003c/a\u003e for our data analysis.\u003c/p\u003e\u003c/details\u003e\n\u003ch3\u003eWhy are our results different?\u003c/h3\u003e\n\u003cp\u003eSince we only had time to measure two jig locations (+ we sketchily removed a nonsensical outlier measurement), you should take our measurements with a grain of salt. But upon digging into the literature, we found big problems with using the \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/690336/\"\u003eFry 1978\u003c/a\u003e paper that measures 22 db/cm/MHz attenuation.\u003c/p\u003e\n\u003cp\u003eFirstly, there is no mention in the paper of degassing the skull. Without degassing, there could be many air bubbles formed in the pores, which will scatter ultrasound heavily (since there is a huge mechanical impedance mismatch between air and water).\u003c/p\u003e\n\u003cp\u003eSecondly, they use focused transmission, instead of sending plane waves. The skull will spread out the focus, so if you don\u0026#39;t sample enough, you\u0026#39;ll mistake spreading for attenuation.\u003c/p\u003e\n\u003cp\u003eThe only good reference we could find for attenuation across frequencies was a 2006 paper by White. They degas the skull and use plane waves. They claim to measure 8.53 dB/cm/MHz, but when we tried \u003ca href=\"https://docs.google.com/spreadsheets/d/1A63-Qzqo9rgjiS1kin3i3dF24EzdTXvK-ylPrlOjii8/edit?gid=0#gid=0\"\u003ereproducing their analysis\u003c/a\u003e using their data, we got 11.9 dB/cm/MHz. This is very close to what we measured!\u003c/p\u003e\n\u003cp\u003eAn important point is that we measured attenuation, which is different from absorption. Attenuation also includes things like scattering and reflections. But it\u0026#39;s absorption that really limits us, not attenuation, since absorption is what contributes to heating in the head. Our attenuation measurements serve as an upper bound on absorption.\u003c/p\u003e\n\u003cp\u003eIt could be that the absorption is a lot lower than the attenuation. \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22225300/\"\u003ePinton et al\u003c/a\u003e find that with a 1 MHz pulsed source, only 2.7 dB/cm of the measured 13.3 dB/cm was due to absorption.\u003c/p\u003e\n\u003ch3\u003eCould fUSI through the skull work?\u003c/h3\u003e\n\u003cp\u003eSo back to the key question: does fUSI through the skull get a high enough signal-to-noise ratio (SNR)?\u003c/p\u003e\n\u003cp\u003eIf we use 11 dB/cm/MHz as the attenuation value, we\u0026#39;d expect a signal drop of about 40 dB, or equivalently, 100x in pressure, relative to below-skull functional ultrasound (see the earlier plot). If we use 2.7 dB/cm/MHz, we get a signal drop of 22 dB, or 10x in pressure.\u003c/p\u003e\n\u003cp\u003eIs that too low? We\u0026#39;re not sure yet. It depends on the pressure changes that are typically seen in regular functional ultrasound. Unfortunately, we couldn\u0026#39;t find that in the literature (if you know this number, please let us know). If the changes in regular functional ultrasound are 100 Pa, then we\u0026#39;d expect to see changes of about 1-10 Pa in functional ultrasound through the skull. This is 1-10 times larger than the noise floor of a transducer (~1 Pa). And we can use a functional ultrasound trick, called \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/19411209/\"\u003ecoherent compounding\u003c/a\u003e, to increase the SNR further. Note, this is the SNR in the sensor domain, but what we really care about is the SNR in the image domain.\u003c/p\u003e\n\u003ch3\u003eDoppler testbed\u003c/h3\u003e\n\u003cp\u003eWe also built a testbed to test fUSI outside of simulation. We wanted it to have properties similar to those of the brain. Previous \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/19101073/\"\u003ework\u003c/a\u003e showed that tofu is desirable as a phantom material, both because it is fast to get and because it has similar physical properties (density, speed of sound) as soft tissue.\u003c/p\u003e\n\u003cp\u003eBecause functional ultrasound works by detecting the movement of blood cells in blood vessels, we also needed a way to emulate blood vessels in the phantom. We accomplished this by building our own pump system.\u003c/p\u003e\n\u003ch4\u003eSyringe Pump\u003c/h4\u003e\n\u003cp\u003eWe built our own syringe pump. Blood travels at around \u003ca href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6610068/\"\u003e~10 mm/s\u003c/a\u003e in small vessels in the brain, so we wanted our pump to have similar speeds. Initially we planned on using a peristaltic pump, however we could not source one that had a small enough volumetric flow rate, and at slow speeds peristaltic pumps flow rate is not consistent.\u003c/p\u003e\n\u003cdetails\u003e\u003csummary\u003eTechnical details\u003c/summary\u003e\u003cdiv\u003e\u003cp\u003eWe purchased a premade stepper motor driven linear actuator, and mounted it to a base plate. Normal sterile syringes of different sizes were used and custom mounts for each one could be swapped in; this along with adjusting the actuator speed in our Arduino code allows us to vary the volumetric flow rate. We also had various sizes of PTFE and silicone tubing to simulate different sized veins. We used \u003ca href=\"https://anatomywarehouse.com/ultrasound-refill-fluid-a-108447?srsltid=AfmBOopmF2Y_8Zg8SybmpeO0B7QzFVYJSc8CizoTEapDtcQYBL2WcSgQ\"\u003eUltrasound Refill Fluid\u003c/a\u003e, which has similar acoustic properties to blood.\u003c/p\u003e\u003cp\u003eThe stepper motor was controlled by a TB6600 controller, and step signals were sent by a Teensy4.1 running this \u003ca href=\"https://github.com/Brain-Hack-2024/transcranial-ultrasound/blob/main/syringepump/teensycontrol.ino\"\u003eprogram\u003c/a\u003e we wrote to easily adjust flow rate, typically 1-10mm/sec, analogous to the rate at which blood cells in smaller blood vessels and capillaries move.\u003c/p\u003e\u003c/div\u003e\u003c/details\u003e\n\u003cfigure\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg alt=\"Photo of the tofu phantom used for testing\" loading=\"lazy\" width=\"716\" height=\"1074\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fphantom.e8f642c2.png\u0026amp;w=750\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fphantom.e8f642c2.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fphantom.e8f642c2.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cimg alt=\"Photo of the custom-built syringe pump\" loading=\"lazy\" width=\"817\" height=\"1228\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fpump.a931f727.png\u0026amp;w=828\u0026amp;q=75 1x, https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fpump.a931f727.png\u0026amp;w=1920\u0026amp;q=75 2x\" src=\"https://brainhack.vercel.app/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fpump.a931f727.png\u0026amp;w=1920\u0026amp;q=75\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/figure\u003e\n\u003ch3\u003eWe have AE at home\u003c/h3\u003e\n\u003cp\u003eCheck out our other post, \u003ca href=\"https://brainhack.vercel.app/ae\"\u003eWe have AE at home\u003c/a\u003e!\u003c/p\u003e\n\u003ch3\u003eAcknowledgements\u003c/h3\u003e\n\u003cp\u003eA big thank you to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProtocol Labs for sponsoring the hacksprint\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://twitter.com/huntercoledavis\"\u003eHunter Davis\u003c/a\u003e, \u003ca href=\"https://twitter.com/david_c_garrett\"\u003eDavid Garrett\u003c/a\u003e, \u003ca href=\"https://twitter.com/SumnerLN\"\u003eSumner Norman\u003c/a\u003e, \u003ca href=\"https://twitter.com/DMarescalab\"\u003eDavid Maresca\u003c/a\u003e, and \u003ca href=\"https://twitter.com/Harie1897\"\u003eHari Kumar\u003c/a\u003e for technical advice\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://twitter.com/leozaroff\"\u003eLeo Zaroff\u003c/a\u003e for lending us his hydrophone and for advice\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eCode\u003c/h3\u003e\n\u003cp\u003eThe whole project is open source. You can find the code on our \u003ca href=\"https://github.com/brain-hack-2024/transcranial-ultrasound/\"\u003eGitHub repository\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "17 min read",
  "publishedTime": null,
  "modifiedTime": null
}
