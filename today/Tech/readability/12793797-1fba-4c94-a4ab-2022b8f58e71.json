{
  "id": "12793797-1fba-4c94-a4ab-2022b8f58e71",
  "title": "How we built Google Meet’s adaptive audio feature",
  "link": "https://blog.google/products/meet/adaptive-audio-google-meet/",
  "description": "Here's how we built adaptive audio in Meet, which transforms multiple laptops in close proximity into a unified audio system so you can create ad-hoc meeting spaces IRL.",
  "author": "Ari MariniKeyword contributor",
  "published": "Fri, 01 Nov 2024 16:00:00 +0000",
  "source": "https://www.blog.google/rss/",
  "categories": [
    "Meet"
  ],
  "byline": "Ari Marini",
  "length": 6135,
  "excerpt": "Here's how we built adaptive audio in Meet, which transforms multiple laptops in close proximity into a unified audio system so you can create ad-hoc meeting spaces IRL.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20241029-1641",
  "text": "Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! At this year’s Cloud Next, the Google Meet team set up a demo room with several laptops lined up next to each other. Then the team brought customers into the space, and asked what they thought would happen if the laptops joined the same meeting at the same time.“One of those customers was like, ‘Oh, it’s going to be the screams of a thousand dying souls,’” says Meet Product Manager Huib Kleinhout, referring to the howling echoes and audio feedback that comes from two nearby devices on the same call. “Then he tried it — and silence. He was like, ‘How does this work? What kind of hardware do I need?’ We picked up a $200 Chromebook and showed him it could work on any machine.”The demo was for adaptive audio in Meet, a feature that transforms multiple laptops in close proximity into a unified audio system, eliminating the ear-splitting screeches that have plagued virtual meeting attendees for years. Adaptive audio is available to Google Workspace customers with a Gemini for Workspace add-on. Try it out with our no-cost 60-day Gemini trial, available until December 3, 2024. The Meet team tests new features like adaptive audio in their audio lab. The team started working on adaptive audio after the world switched to video conferencing and eventually, hybrid work due to the pandemic. At the time, it was challenging to get new meeting room hardware due to supply chain shortages. “Plus, many organizations didn’t have enough video conferencing rooms to begin with, or they didn’t have the resources for dedicated meeting room equipment,” Huib says.Teams needed to be able to create ad-hoc meeting spaces and without the inconvenience of crowding around a single laptop. But enabling everyone to join from their own devices while silencing the “screams” is much harder than it sounds.“Imagine a movie theater audio setup. You have multiple speakers around you, and it's a nice audio experience because they’re all cabled to the same sound source, so they play out in an intended synchronicity,” Meet Software Engineer Manager Henrik Lundin says. “Now, if you have several devices in the room playing the same audio without synchronization, it would sound horrible. You’re getting multiple copies of the same audio — like you’re standing in a large cathedral. And likewise, when you speak in a room with multiple microphones on different devices, they pick up sound at the same time, but they're not on the same clock.”Then there’s the echo problem. You’ve probably noticed that you’ll sometimes get an echo of your own voice back when using video conferencing tools. “The reason that you don't get that all the time is because the devices that run meetings have an echo canceller inside,” Henrik says. “It's a signal processing algorithm that tries to figure out which part of the audio from the microphone signal is actually just coming from the speakers in the same device and which part of it is your voice. This gets 10x harder when you have multiple laptops in the same room playing the audio and feeding into each other’s microphones.”To solve this audio puzzle, the team spent a lot of time getting in the same room and figuring out how to get their laptops to know they were next to each other. At first, they tested having people join specific preset groups within the meeting. “This was obviously error prone, but it helped us test out the experience of synchronizing all the laptops’ microphones and speakers,” Henrik says.Then they tried using ultrasound. By emitting high-frequency sounds undetectable to the human ear, the laptops can identify the presence of other laptops in close proximity and begin acting together as a group. This eliminated the need for users to manually configure their devices or select the room they were in. “But it was really tricky because the ultrasound needed to work reliably on any device, and be precise — if audio leaks from the room next door, it shouldn’t think you’re in the same room,” Henrik says. The team adopted a new type of ultrasound to increase accuracy, and tuned the frequency and volume to optimize reach without being audible.Once Meet detects multiple laptops are present, adaptive audio activates automatically, synchronizing all the laptops’ microphones and speakers without turning any speakers off. It switches between microphones depending on who’s talking to prevent feedback and echo. Additionally, Meet uses backend processing and a cloud denoiser to enhance audio quality and remove background noise before transmitting audio to other participants.All across Google, meetings every day already use adaptive audio — many without participants even realizing it. “It’s one of those technologies that removes the cognitive load from the user. They don’t have to wonder if they’re in the right setup before they join a meeting,” Meet Interaction Design Lead Ahmed Aly says. “Regardless of how complex and marvelous the engineering behind it is, from the end user perspective, whenever they open their laptop and join a meeting, it just works.” Looking ahead, the team continues to explore how they can help people connect more easily, especially when conferencing hardware or meeting rooms are unavailable. “We hope it provides more flexibility and improves meeting equity and participation,” Huib says. “You can be effective and represented — the camera and microphone are right in front of you, so you can be fully seen and heard, no matter where you’re seated.”",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Meet_SocialShare.width-1300.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n      \u003cp\u003e\n        \u003cvideo autoplay=\"\" muted=\"\" loop=\"\" playsinline=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Meet_Hero.mp4\" title=\"A gif shows people on their laptops meeting together. Blue design elements including the Meet logo appear. A notification appears over their faces that says: To avoid audio feedback, your audio is merged with other devices nearby.\" poster=\"\n            \n              https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Meet_Thumbnail.jpg\n            \"\u003e\n          Sorry, your browser doesn\u0026#39;t support embedded videos, but don\u0026#39;t worry, you can\n            \u003ca href=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Meet_Hero.mp4\"\u003edownload it\u003c/a\u003e\n            and watch it with your favorite video player!\n        \u003c/video\u003e\n      \u003c/p\u003e\n      \n    \u003c/div\u003e\u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\u003cgoogle-read-aloud-player data-analytics-module=\"{\n        \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n        \u0026#34;module_name\u0026#34;: \u0026#34;ai_audio\u0026#34;,\n        \u0026#34;section_header\u0026#34;: \u0026#34;How we built Google Meet’s adaptive audio feature\u0026#34;\n    }\" data-date-modified=\"2024-11-01T16:00:01.042439+00:00\" data-progress-bar-style=\"half-wave\" data-api-key=\"AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac\" data-article-style=\"style9\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-layout-style=\"style1\" data-highlight-mode=\"word-over-paragraph\" data-highlight-text-color=\"#000000\" data-highlight-word-background=\"#8AB4F8\" data-highlight-paragraph-background=\"#D2E3FC\" data-background=\"linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)\" data-foreground-color=\"#202124\" data-font=\"600 16px Google Sans, sans-serif\" data-box-shadow=\"0px 1px 3px 1px rgba(60, 64, 67, 0.15)\"\u003e\n\u003c/google-read-aloud-player\u003e\n\n\n\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Google Meet’s adaptive audio feature\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"kc89q\"\u003eAt this year’s \u003ca href=\"https://blog.google/products/google-cloud/google-cloud-next-2024/\"\u003eCloud Next\u003c/a\u003e, the Google Meet team set up a demo room with several laptops lined up next to each other. Then the team brought customers into the space, and asked what they thought would happen if the laptops joined the same meeting at the same time.\u003c/p\u003e\u003cp data-block-key=\"1l22o\"\u003e“One of those customers was like, ‘Oh, it’s going to be the screams of a thousand dying souls,’” says Meet Product Manager Huib Kleinhout, referring to the howling echoes and audio feedback that comes from two nearby devices on the same call. “Then he tried it — and silence. He was like, ‘How does this work? What kind of hardware do I need?’ We picked up a $200 Chromebook and showed him it could work on any machine.”\u003c/p\u003e\u003cp data-block-key=\"71hgs\"\u003eThe demo was for \u003ca href=\"https://workspaceupdates.googleblog.com/2024/05/google-meet-adaptive-audio.html\"\u003eadaptive audio in Meet\u003c/a\u003e, a feature that transforms multiple laptops in close proximity into a unified audio system, eliminating the ear-splitting screeches that have plagued virtual meeting attendees for years. Adaptive audio is available to Google Workspace customers with a Gemini for Workspace add-on. Try it out with our no-cost \u003ca href=\"https://workspace.google.com/solutions/ai/signup?source=gemini-lto\u0026amp;e=48754805\"\u003e60-day Gemini trial\u003c/a\u003e, available until December 3, 2024.\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n  \n      \u003cdiv data-analytics-module=\"{\n          \u0026#34;module_name\u0026#34;: \u0026#34;Inline Images\u0026#34;,\n          \u0026#34;section_header\u0026#34;: \u0026#34;How we built Google Meet’s adaptive audio feature\u0026#34;\n        }\"\u003e\n  \n\n  \u003cp\u003e\u003cimg alt=\"Several laptops on a table with microphones pointed at the speakers.\" src=\" https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Adaptive_Audio_in_Meet_developmen.width-100.format-webp.webp \" loading=\"lazy\" data-loading=\"{\n                \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Adaptive_Audio_in_Meet_developmen.width-500.format-webp.webp\u0026#34;,\n                \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Adaptive_Audio_in_Meet_developme.width-1000.format-webp.webp\u0026#34;\n              }\"/\u003e\n        \n      \n    \n    \u003c/p\u003e\n    \n      \u003cfigcaption\u003e\u003cp data-block-key=\"at8dc\"\u003eThe Meet team tests new features like adaptive audio in their audio lab.\u003c/p\u003e\u003c/figcaption\u003e\n    \n  \n    \u003c/div\u003e\n  \n\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Google Meet’s adaptive audio feature\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"kc89q\"\u003eThe team started working on adaptive audio after the world switched to video conferencing and eventually, hybrid work due to the pandemic. At the time, it was challenging to get new meeting room hardware due to supply chain shortages. “Plus, many organizations didn’t have enough video conferencing rooms to begin with, or they didn’t have the resources for dedicated meeting room equipment,” Huib says.\u003c/p\u003e\u003cp data-block-key=\"3l0en\"\u003eTeams needed to be able to create ad-hoc meeting spaces and without the inconvenience of crowding around a single laptop. But enabling everyone to join from their own devices while silencing the “screams” is much harder than it sounds.\u003c/p\u003e\u003cp data-block-key=\"afeqa\"\u003e“Imagine a movie theater audio setup. You have multiple speakers around you, and it\u0026#39;s a nice audio experience because they’re all cabled to the same sound source, so they play out in an intended synchronicity,” Meet Software Engineer Manager Henrik Lundin says. “Now, if you have several devices in the room playing the same audio without synchronization, it would sound horrible. You’re getting multiple copies of the same audio — like you’re standing in a large cathedral. And likewise, when you speak in a room with multiple microphones on different devices, they pick up sound at the same time, but they\u0026#39;re not on the same clock.”\u003c/p\u003e\u003cp data-block-key=\"3b0et\"\u003eThen there’s the echo problem. You’ve probably noticed that you’ll sometimes get an echo of your own voice back when using video conferencing tools. “The reason that you don\u0026#39;t get that all the time is because the devices that run meetings have an \u003ca href=\"https://workspace.google.com/resources/echo-cancellation\"\u003eecho canceller\u003c/a\u003e inside,” Henrik says. “It\u0026#39;s a signal processing algorithm that tries to figure out which part of the audio from the microphone signal is actually just coming from the speakers in the same device and which part of it is your voice. This gets 10x harder when you have multiple laptops in the same room playing the audio and feeding into each other’s microphones.”\u003c/p\u003e\u003cp data-block-key=\"3dn09\"\u003eTo solve this audio puzzle, the team spent a lot of time getting in the same room and figuring out how to get their laptops to know they were next to each other. At first, they tested having people join specific preset groups within the meeting. “This was obviously error prone, but it helped us test out the experience of synchronizing all the laptops’ microphones and speakers,” Henrik says.\u003c/p\u003e\u003cp data-block-key=\"84u33\"\u003eThen they tried using ultrasound. By emitting high-frequency sounds undetectable to the human ear, the laptops can identify the presence of other laptops in close proximity and begin acting together as a group. This eliminated the need for users to manually configure their devices or select the room they were in. “But it was really tricky because the ultrasound needed to work reliably on any device, and be precise — if audio leaks from the room next door, it shouldn’t think you’re in the same room,” Henrik says. The team adopted a new type of ultrasound to increase accuracy, and tuned the frequency and volume to optimize reach without being audible.\u003c/p\u003e\u003cp data-block-key=\"52r4j\"\u003eOnce Meet detects multiple laptops are present, adaptive audio activates automatically, synchronizing all the laptops’ microphones and speakers without turning any speakers off. It switches between microphones depending on who’s talking to prevent feedback and echo. Additionally, Meet uses backend processing and a cloud denoiser to enhance audio quality and remove background noise before transmitting audio to other participants.\u003c/p\u003e\u003cp data-block-key=\"1gocb\"\u003eAll across Google, meetings every day already use adaptive audio — many without participants even realizing it. “It’s one of those technologies that removes the cognitive load from the user. They don’t have to wonder if they’re in the right setup before they join a meeting,” Meet Interaction Design Lead Ahmed Aly says. “Regardless of how complex and marvelous the engineering behind it is, from the end user perspective, whenever they open their laptop and join a meeting, it just works.”\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n  \n    \n\n\u003cdiv data-component=\"uni-article-yt-player\" data-page-title=\"How we built Google Meet’s adaptive audio feature\" data-video-id=\"vuIQhZNMRdU\" data-index-id=\"4\" data-type=\"video\" data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Youtube Video\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;undefined\u0026#34;\n  }\" data-yt-video=\"module\"\u003e\n\n    \n\n    \u003ca role=\"video\" tabindex=\"0\"\u003e\n      \u003cdiv\u003e\n        \n          \n          \n          \n          \u003cp\u003e\u003cimg alt=\"A YouTube video still showing two people sitting at a table while on their laptops. A Google Meet menu in the middle of the image shows a list of four contributors with an indicator showing that merged audio is active.\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Adaptive_Audio_YouTube_Still.width-100.format-webp.webp\" loading=\"lazy\" data-loading=\"{\n                \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Adaptive_Audio_YouTube_Still.width-500.format-webp.webp\u0026#34;,\n                \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Adaptive_Audio_YouTube_Still.width-1000.format-webp.webp\u0026#34;\n              }\"/\u003e\u003c/p\u003e\n\n        \n        \u003csvg role=\"presentation\"\u003e\n  \u003cuse xmlns:xlink=\"http://www.w3.org/1999/xlink\" href=\"/static/blogv2/images/icons.svg?version=pr20241029-1641#mi-keyboard-arrow-right\"\u003e\u003c/use\u003e\n\u003c/svg\u003e\n\n\n        \u003csvg role=\"presentation\"\u003e\n          \n          \u003cuse href=\"/static/blogv2/images/icons.svg?version=pr20241029-1641#yt_video_play_button_no_hole\"\u003e\u003c/use\u003e\n          \n        \u003c/svg\u003e\n        \u003csvg role=\"img\"\u003e\n          \n          \u003cuse href=\"/static/blogv2/images/icons.svg?version=pr20241029-1641#yt_video_play_button\"\u003e\u003c/use\u003e\n          \n        \u003c/svg\u003e\n\n        \n        \n        \n        \n      \u003c/div\u003e\n    \u003c/a\u003e\n\n    \n\n    \n  \u003c/div\u003e\n\n  \n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;How we built Google Meet’s adaptive audio feature\u0026#34;\n         }\"\u003e\n        \u003cp data-block-key=\"kc89q\"\u003eLooking ahead, the team continues to explore how they can help people connect more easily, especially when conferencing hardware or meeting rooms are unavailable. “We hope it provides more flexibility and improves meeting equity and participation,” Huib says. “You can be effective and represented — the camera and microphone are right in front of you, so you can be fully seen and heard, no matter where you’re seated.”\u003c/p\u003e\n      \u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2024-11-01T16:00:00Z",
  "modifiedTime": null
}
