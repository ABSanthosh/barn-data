{
  "id": "c2e9ac4a-cbee-42cd-ae4c-e36cb1abf3b9",
  "title": "The new skill in AI is not prompting, it's context engineering",
  "link": "https://www.philschmid.de/context-engineering",
  "description": "Comments",
  "author": "",
  "published": "Mon, 30 Jun 2025 20:53:55 +0000",
  "source": "https://news.ycombinator.com/rss",
  "categories": null,
  "byline": "Philipp Schmid",
  "length": 5444,
  "excerpt": "Context Engineering is the new skill in AI. It is about providing the right information and tools, in the right format, at the right time.",
  "siteName": "Philipp Schmid",
  "favicon": "",
  "text": "Context Engineering is new term gaining traction in the AI world. The conversation is shifting from \"prompt engineering\" to a broader, more powerful concept: Context Engineering. Tobi Lutke describes it as \"the art of providing all the context for the task to be plausibly solvable by the LLM.” and he is right. With the rise of Agents it becomes more important what information we load into the “limited working memory”. We are seeing that the main thing that determines whether an Agents succeeds or fails is the quality of the context you give it. Most agent failures are not model failures anyemore, they are context failures. What is the Context? To understand context engineering, we must first expand our definition of \"context.\" It isn't just the single prompt you send to an LLM. Think of it as everything the model sees before it generates a response. Instructions / System Prompt: An initial set of instructions that define the behavior of the model during a conversation, can/should include examples, rules …. User Prompt: Immediate task or question from the user. State / History (short-term Memory): The current conversation, including user and model responses that have led to this moment. Long-Term Memory: Persistent knowledge base, gathered across many prior conversations, containing learned user preferences, summaries of past projects, or facts it has been told to remember for future use. Retrieved Information (RAG): External, up-to-date knowledge, relevant information from documents, databases, or APIs to answer specific questions. Available Tools: Definitions of all the functions or built-in tools it can call (e.g., check_inventory, send_email). Structured Output: Definitions on the format of the model's response, e.g. a JSON object. Why It Matters: From Cheap Demo to Magical Product The secret to building truly effective AI agents has less to do with the complexity of the code you write, and everything to do with the quality of the context you provide. Building Agents is less about the code you write or framework you use. The difference between a cheap demo and a “magical” agent is about the quality of the context you provide. Imagine an AI assistant is asked to schedule a meeting based on a simple email: Hey, just checking if you’re around for a quick sync tomorrow. The \"Cheap Demo\" Agent has poor context. It sees only the user's request and nothing else. Its code might be perfectly functional—it calls an LLM and gets a response—but the output is unhelpful and robotic: Thank you for your message. Tomorrow works for me. May I ask what time you had in mind? The \"Magical\" Agent is powered by rich context. The code's primary job isn't to figure out how to respond, but to gather the information the LLM needs to full fill its goal. Before calling the LLM, you would extend the context to include Your calendar information (which shows you're fully booked). Your past emails with this person (to determine the appropriate informal tone). Your contact list (to identify them as a key partner). Tools for send_invite or send_email. Then you can generate a response. Hey Jim! Tomorrow’s packed on my end, back-to-back all day. Thursday AM free if that works for you? Sent an invite, lmk if it works. The magic isn't in a smarter model or a more clever algorithm. It’s in about providing the right context for the right task. This is why context engineering will matter. Agent failures aren't only model failures; they are context failures. From Prompt to Context Engineering What is context engineering? While \"prompt engineering\" focuses on crafting the perfect set of instructions in a single text string, context engineering is a far broader. Let's put it simply: Context Engineering is the discipline of designing and building dynamic systems that provides the right information and tools, in the right format, at the right time, to give a LLM everything it needs to accomplish a task. Context Engineering is A System, Not a String: Context isn't just a static prompt template. It’s the output of a system that runs before the main LLM call. Dynamic: Created on the fly, tailored to the immediate task. For one request this could be the calendar data for another the emails or a web search. About the right information, tools at the right time: The core job is to ensure the model isn’t missing crucial details (\"Garbage In, Garbage Out\"). This means providing both knowledge (information) and capabilities (tools) only when required and helpful. where the format matters: How you present information matters. A concise summary is better than a raw data dump. A clear tool schema is better than a vague instruction. Conclusion Building powerful and reliable AI Agents is becoming less about finding a magic prompt or model updates. It is about the engineering of context and providing the right information and tools, in the right format, at the right time. It’s a cross-functional challenge that involves understanding your business use case, defining your outputs, and structuring all the necessary information so that an LLM can “accomplish the task.\" Acknowledgements This overview was created with the help of deep and manual research, drawing inspiration and information from several excellent resources, including: Tobi Lutke tweet Karpathy tweet The rise of \"context engineering\" Own your context window context engineering by Simon Willison Context Engineering for Agents",
  "image": "https://www.philschmid.de/static/blog/context-engineering/thumbnail.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eContext Engineering is new term gaining traction in the AI world. The conversation is shifting from \u0026#34;prompt engineering\u0026#34; to a broader, more powerful concept: \u003cstrong\u003eContext Engineering\u003c/strong\u003e. \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://x.com/tobi/status/1935533422589399127\"\u003eTobi Lutke\u003c/a\u003e describes it as \u0026#34;the art of providing all the context for the task to be plausibly solvable by the LLM.” and he is right.\u003c/p\u003e\n\u003cp\u003eWith the rise of Agents it becomes more important what information we load into the “limited working memory”. We are seeing that the main thing that determines whether an Agents succeeds or fails is the quality of the context you give it. Most agent failures are not model failures anyemore, they are context failures.\u003c/p\u003e\n\u003ch2 id=\"what-is-the-context\"\u003eWhat is the Context?\u003c/h2\u003e\n\u003cp\u003eTo understand context engineering, we must first expand our definition of \u0026#34;context.\u0026#34; It isn\u0026#39;t just the single prompt you send to an LLM. Think of it as everything the model sees before it generates a response.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://www.philschmid.de/static/blog/context-engineering/context.png\" alt=\"Context\"/\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInstructions / System Prompt:\u003c/strong\u003e An initial set of instructions that define the behavior of the model during a conversation, can/should include examples, rules ….\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUser Prompt:\u003c/strong\u003e Immediate task or question from the user.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eState / History (short-term Memory):\u003c/strong\u003e The current conversation, including user and model responses that have led to this moment.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLong-Term Memory:\u003c/strong\u003e Persistent knowledge base, gathered across many prior conversations, containing learned user preferences, summaries of past projects, or facts it has been told to remember for future use.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRetrieved Information (RAG):\u003c/strong\u003e External, up-to-date knowledge, relevant information from documents, databases, or APIs to answer specific questions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAvailable Tools:\u003c/strong\u003e Definitions of all the functions or built-in tools it can call (e.g., check_inventory, send_email).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStructured Output:\u003c/strong\u003e Definitions on the format of the model\u0026#39;s response, e.g. a JSON object.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"why-it-matters-from-cheap-demo-to-magical-product\"\u003eWhy It Matters: From Cheap Demo to Magical Product\u003c/h2\u003e\n\u003cp\u003eThe secret to building truly effective AI agents has less to do with the complexity of the code you write, and everything to do with the quality of the context you provide.\u003c/p\u003e\n\u003cp\u003eBuilding Agents is less about the code you write or framework you use. The difference between a cheap demo and a “magical” agent is about the quality of the context you provide. Imagine an AI assistant is asked to schedule a meeting based on a simple email:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eHey, just checking if you’re around for a quick sync tomorrow.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eThe \u0026#34;Cheap Demo\u0026#34; Agent\u003c/strong\u003e has poor context. It sees only the user\u0026#39;s request and nothing else. Its code might be perfectly functional—it calls an LLM and gets a response—but the output is unhelpful and robotic:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThank you for your message. Tomorrow works for me. May I ask what time you had in mind?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eThe \u0026#34;Magical\u0026#34; Agent\u003c/strong\u003e is powered by rich context. The code\u0026#39;s primary job isn\u0026#39;t to figure out \u003cem\u003ehow\u003c/em\u003e to respond, but to \u003cem\u003egather the information\u003c/em\u003e the LLM needs to full fill its goal. Before calling the LLM, you would extend the context to include\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYour calendar information (which shows you\u0026#39;re fully booked).\u003c/li\u003e\n\u003cli\u003eYour past emails with this person (to determine the appropriate informal tone).\u003c/li\u003e\n\u003cli\u003eYour contact list (to identify them as a key partner).\u003c/li\u003e\n\u003cli\u003eTools for send_invite or send_email.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThen you can generate a response.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eHey Jim! Tomorrow’s packed on my end, back-to-back all day. Thursday AM free if that works for you? Sent an invite, lmk if it works.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe magic isn\u0026#39;t in a smarter model or a more clever algorithm. It’s in about providing the right context for the right task. This is why context engineering will matter. Agent failures aren\u0026#39;t only model failures; they are context failures.\u003c/p\u003e\n\u003ch2 id=\"from-prompt-to-context-engineering\"\u003eFrom Prompt to Context Engineering\u003c/h2\u003e\n\u003cp\u003eWhat is context engineering? While \u0026#34;prompt engineering\u0026#34; focuses on crafting the perfect set of instructions in a single text string, context engineering is a far broader. Let\u0026#39;s put it simply:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eContext Engineering is the discipline of designing and building dynamic systems that provides the right information and tools, in the right format, at the right time, to give a LLM everything it needs to accomplish a task.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eContext Engineering is\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eA System, Not a String:\u003c/strong\u003e Context isn\u0026#39;t just a static prompt template. It’s the output of a \u003cstrong\u003esystem\u003c/strong\u003e that runs \u003cem\u003ebefore\u003c/em\u003e the main LLM call.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDynamic:\u003c/strong\u003e Created on the fly, tailored to the immediate task. For one request this could be the calendar data for another the emails or a web search.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAbout the right information, tools at the right time:\u003c/strong\u003e The core job is to ensure the model isn’t missing crucial details (\u0026#34;Garbage In, Garbage Out\u0026#34;). This means providing both knowledge (information) and capabilities (tools) only when required and helpful.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewhere the format matters:\u003c/strong\u003e How you present information matters. A concise summary is better than a raw data dump. A clear tool schema is better than a vague instruction.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eBuilding powerful and reliable AI Agents is becoming less about finding a magic prompt or model updates. It is about the engineering of context and providing the right information and tools, in the right format, at the right time. It’s a cross-functional challenge that involves understanding your business use case, defining your  outputs, and structuring all the necessary information so that an LLM can “accomplish the task.\u0026#34;\u003c/p\u003e\n\u003ch2 id=\"acknowledgements\"\u003eAcknowledgements\u003c/h2\u003e\n\u003cp\u003eThis overview was created with the help of deep and manual research, drawing inspiration and information from several excellent resources, including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://x.com/tobi/status/1935533422589399127\"\u003eTobi Lutke tweet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://x.com/karpathy/status/1937902205765607626\"\u003eKarpathy tweet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://blog.langchain.com/the-rise-of-context-engineering/\"\u003eThe rise of \u0026#34;context engineering\u0026#34;\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md\"\u003eOwn your context window\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://simonwillison.net/2025/Jun/27/context-engineering/\"\u003econtext engineering by Simon Willison\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://rlancemartin.github.io/2025/06/23/context_engineering/\"\u003eContext Engineering for Agents\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-06-30T00:00:00Z",
  "modifiedTime": null
}
