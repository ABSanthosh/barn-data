{
  "id": "b04bf172-1081-4664-a3b6-f07a8691cdf7",
  "title": "AI isn’t ready to replace human coders for debugging, researchers say",
  "link": "https://arstechnica.com/ai/2025/04/researchers-find-ai-is-pretty-bad-at-debugging-but-theyre-working-on-it/",
  "description": "Even when given access to tools, AI agents can't reliably debug software.",
  "author": "Samuel Axon",
  "published": "Fri, 11 Apr 2025 22:26:58 +0000",
  "source": "http://feeds.arstechnica.com/arstechnica/index",
  "categories": [
    "AI",
    "coding",
    "debugging",
    "LLM",
    "microsoft",
    "Programming",
    "software development"
  ],
  "byline": "Samuel Axon",
  "length": 1989,
  "excerpt": "Even when given access to tools, AI agents can’t reliably debug software.",
  "siteName": "Ars Technica",
  "favicon": "https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png",
  "text": "Agents using debugging tools drastically outperformed those that didn't, but their success rate still wasn't high enough. Credit: Microsoft Research This approach is much more successful than relying on the models as they're usually used, but when your best case is a 48.4 percent success rate, you're not ready for primetime. The limitations are likely because the models don't fully understand how to best use the tools, and because their current training data is not tailored to this use case. \"We believe this is due to the scarcity of data representing sequential decision-making behavior (e.g., debugging traces) in the current LLM training corpus,\" the blog post says. \"However, the significant performance improvement... validates that this is a promising research direction.\" This initial report is just the start of the efforts, the post claims.  The next step is to \"fine-tune an info-seeking model specialized in gathering the necessary information to resolve bugs.\" If the model is large, the best move to save inference costs may be to \"build a smaller info-seeking model that can provide relevant information to the larger one.\" This isn't the first time we've seen outcomes that suggest some of the ambitious ideas about AI agents directly replacing developers are pretty far from reality. There have been numerous studies already showing that even though an AI tool can sometimes create an application that seems acceptable to the user for a narrow task, the models tend to produce code laden with bugs and security vulnerabilities, and they aren't generally capable of fixing those problems. This is an early step on the path to AI coding agents, but most researchers agree it remains likely that the best outcome is an agent that saves a human developer a substantial amount of time, not one that can do everything they can do.",
  "image": "https://cdn.arstechnica.net/wp-content/uploads/2024/10/linux-scripts-1152x648.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n          \n          \n\u003cfigure\u003e\n    \u003cp\u003e\u003cimg width=\"1024\" height=\"516\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-1024x516.png\" alt=\"A graph showing agents with tools nearly doubling the success rates of those without, but still achieving a success score under 50 percent\" decoding=\"async\" loading=\"lazy\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-1024x516.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-640x322.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-768x387.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-1536x774.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-980x494.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart-1440x725.png 1440w, https://cdn.arstechnica.net/wp-content/uploads/2025/04/DeBug_froggy_bar_chart.png 1934w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\"/\u003e\n                  \u003c/p\u003e\n          \u003cfigcaption\u003e\n        \u003cdiv\u003e\n    \n    \u003cp\u003e\n      Agents using debugging tools drastically outperformed those that didn\u0026#39;t, but their success rate still wasn\u0026#39;t high enough.\n\n              \u003cspan\u003e\n          Credit:\n\n                      \u003ca href=\"https://www.microsoft.com/en-us/research/blog/debug-gym-an-environment-for-ai-coding-tools-to-learn-how-to-debug-code-like-programmers/\" target=\"_blank\"\u003e\n          \n          Microsoft Research\n\n                      \u003c/a\u003e\n                  \u003c/span\u003e\n          \u003c/p\u003e\n  \u003c/div\u003e\n      \u003c/figcaption\u003e\n      \u003c/figure\u003e\n\n\u003cp\u003eThis approach is much more successful than relying on the models as they\u0026#39;re usually used, but when your best case is a 48.4 percent success rate, you\u0026#39;re not ready for primetime. The limitations are likely because the models don\u0026#39;t fully understand how to best use the tools, and because their current training data is not tailored to this use case.\u003c/p\u003e\n\u003cp\u003e\u0026#34;We believe this is due to the scarcity of data representing sequential decision-making behavior (e.g., debugging traces) in the current LLM training corpus,\u0026#34; the blog post says. \u0026#34;However, the significant performance improvement... validates that this is a promising research direction.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThis initial report is just the start of the efforts, the post claims.  The next step is to \u0026#34;fine-tune an info-seeking model specialized in gathering the necessary information to resolve bugs.\u0026#34; If the model is large, the best move to save inference costs may be to \u0026#34;build a smaller info-seeking model that can provide relevant information to the larger one.\u0026#34;\u003c/p\u003e\n\u003cp\u003eThis isn\u0026#39;t the first time we\u0026#39;ve seen outcomes that suggest some of the ambitious ideas about AI agents directly replacing developers are pretty far from reality. There have been numerous studies already showing that even though an AI tool can sometimes create an application that seems acceptable to the user for a narrow task, the models tend to produce code laden with bugs and security vulnerabilities, and they aren\u0026#39;t generally capable of fixing those problems.\u003c/p\u003e\n\u003cp\u003eThis is an early step on the path to AI coding agents, but most researchers agree it remains likely that the best outcome is an agent that saves a human developer a substantial amount of time, not one that can do everything they can do.\u003c/p\u003e\n\n\n          \n                  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": "2025-04-11T22:26:58Z",
  "modifiedTime": "2025-04-11T22:37:31Z"
}
