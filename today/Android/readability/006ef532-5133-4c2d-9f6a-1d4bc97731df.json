{
  "id": "006ef532-5133-4c2d-9f6a-1d4bc97731df",
  "title": "4 reasons I host my own LLM, and you should too",
  "link": "https://www.xda-developers.com/4-reasons-i-host-my-own-llm/",
  "description": "Between Deepseek and Llama on my laptop, I rarely need to head to ChatGPT anymore.",
  "author": "Dhruv Bhutani",
  "published": "Mon, 10 Feb 2025 00:00:18 GMT",
  "source": "https://www.xda-developers.com/feed/",
  "categories": [
    "AI \u0026 Machine Learning"
  ],
  "byline": "Dhruv Bhutani",
  "length": 15937,
  "excerpt": "Between Deepseek and Llama on my laptop, I rarely need to head to ChatGPT anymore.",
  "siteName": "XDA",
  "favicon": "https://www.xda-developers.com/public/build/images/favicon-240x240.43161a66.png",
  "text": "Love them or hate them, Large Language Models are increasingly woven into the fabric of technology across the internet, smartphones, and personal computers. Your office suite now comes integrated with CoPilot, and Adobe's creative suite has its own AI assistant built in. But working with cloud-hosted LLMs comes with some tradeoffs -- privacy. If you’re privacy-conscious, self-hosting your own LLM might be the move. I’ve been hosting my own instance of the Llama 3 model and, lately, Deepseek, and it has provided me with unparalleled control, customization, and usability. Here are four reasons why hosting my own LLM model has been a game-changer for me—and might be for you. AI wants to help you: 5 creative ways to use LLMs Don't miss these great opportunities where AI could be saving you time, money, and hassle 4 Enhanced privacy and security I wouldn't trust ChatGPT with sensitive information, and neither should you One of the most compelling reasons for hosting my own LLM is privacy. While you can’t change the fact that practically every LLM has scooped up data from the internet and has been trained on publicly available information, I’m not in favor of feeding it even more personal data. When I’m working with confidential documents or analyzing my own health records, uploading them to ChatGPT is an absolute no-go. It’s not just about the data that’s collected; it’s about control. The more I can keep my personal information off the cloud, the better. Running my own locally hosted LLM means I can perform much of the same functions without giving these models access to my private information for training data. Yes, you can even switch off the internet, and the self-hosted LLM will work without a hitch. That level of privacy control is invaluable, especially for those of us who handle sensitive material regularly. Furthermore, hosting a model locally helps reduce the likelihood of any unintended data sharing. 3 On-the-go access I bet ChatGPT can't do this Which brings me to my next point — portability. As good as ChatGPT and Claude are, they can only be used as long as you’re near a Wi-Fi connection. What if you’re working on a flight, or perhaps a train with a spotty connection? What if you’re in a cafe with poor internet connectivity? That’s a no-go. That’s where self-hosting truly shines. For instance, just last week, I spun up the Deepseek 7B model on my MacBook Air while on a flight to brainstorm ideas for a presentation. Sure, it’s not as fast as accessing an LLM in the cloud, but I don’t really mind the few extra seconds it takes to brainstorm ideas, do a grammar check, or help me brush up on a language. The beauty of local hosting is that I’m not reliant on an external connection to get the job done. It’s been a game-changer. 2 Cost Subscription fatigue is real Let’s face it, nobody wants to pay for yet another subscription service. As good as ChatGPT’s premium tier is, almost anything I personally need from an LLM doesn’t really require the added cost. Hosting my own model has been incredibly cost-effective, and if your use case isn’t too complex, it might be the right choice for you as well — especially considering how easy it is with tools like LM Studio. While the premium tiers of services like ChatGPT might offer better performance, they’re often not necessary for most day-to-day tasks. Running my own model cuts out those subscription fees entirely, which, for me, is a huge win. More so, the availability of resource-efficient models like Llama 3 and Deepseek makes it an even more appealing choice. To be sure, you’re not going to be running the full-fledged models on your home computers. However, in my experience, the quantized models pack just enough utility for day-to-day purposes. 1 Learning and customization Fine tune the AI model to match your preferences Here’s where it gets more fun. As a tech enthusiast, getting into the nitty-gritty of things comes naturally to me. I enjoy understanding how things work under the hood, and self-hosting an LLM has given me that opportunity. Hosting my own LLM lets me experiment with it and optimize for my specific use cases—be it data analysis, conversations, or content generation. I’m not always successful with every tweak I make, but it’s a great way to learn how these models work and to shape them for my needs. Self-hosting offers an unmatched level of customization. Instead of being confined to preset options provided by cloud services, I can adjust my LLM’s behavior to better align with my requirements. This could mean altering its conversational tone, optimizing it for specific tasks, or integrating it with tools I use in my daily life. The flexibility to experiment and evolve the model is something I’ve really enjoyed. Admittedly, this doesn't work on-device unless you have extremely powerful hardware. But I've been experimenting with fine-tuning models using Amazon's Sagemaker. Additionally, I’ve been spending time building tools that plug into Deepseek’s API to analyze my personal investments and health data. While I wouldn’t be comfortable sending this data to a cloud server, having local access allows me to poke and prod the LLM model to better suit my use case. This hands-on approach has been both educational and incredibly rewarding. I’ve built custom scripts, explored new functionalities, and fine-tuned the model to give me exactly what I need. That sense of control is invaluable. Why self-hosting an LLM has been a game-changer for me In the end, hosting my own LLM has been a game-changer for me, offering a level of control, privacy, and customization that cloud-based models just can’t match. It’s not perfect — there are very notable tradeoffs when it comes to speed and convenience and, often, accuracy, especially when doing deep research. But the ability to experiment, protect my data, and have an AI that truly works on my terms has made it all worth it. If you’re someone who values privacy, enjoys tinkering with tech, or just wants a more personal AI experience, self-hosting might be the perfect fit for you, too.",
  "image": "https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/01/deepseek_r1_example_en.gif",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"article-body\" itemprop=\"articleBody\"\u003e\n\u003cp\u003eLove them or hate them, \u003ca href=\"https://www.xda-developers.com/what-large-language-models-can-do-next/\" target=\"_blank\"\u003eLarge Language Models\u003c/a\u003e are increasingly woven into the fabric of technology across the internet, \u003ca href=\"https://www.xda-developers.com/run-local-llms-smartphone/\" target=\"_blank\"\u003esmartphones\u003c/a\u003e, and personal computers. Your office suite now comes integrated with CoPilot, and Adobe\u0026#39;s creative suite has its own AI assistant built in. But working with cloud-hosted LLMs comes with some tradeoffs -- privacy.\u003c/p\u003e    \n\u003cp\u003eIf you’re privacy-conscious, self-hosting your own LLM might be the move. I’ve been hosting my own instance of the Llama 3 model and, lately, Deepseek, and it has provided me with unparalleled control, customization, and usability. Here are four reasons why hosting my own LLM model has been a game-changer for me—and might be for you.\u003c/p\u003e            \n    \n                    \n                        \n                \n    \n                                        \n    \n        \n    \n        \n                \n        \n    \u003cdiv data-include-community-rating=\"false\" id=\"fccf-4481-a262b3d8e77c\" data-nosnippet=\"\"\u003e\n        \n        \n                        \t                \n\t\t\u003ca href=\"https://www.xda-developers.com/five-creative-ways-to-use-an-llm/\"\u003e\n\t\n\t\u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=422\u0026amp;h=268\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=310\u0026amp;h=220\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=720\u0026amp;h=400\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png?q=49\u0026amp;fit=crop\u0026amp;w=432\u0026amp;h=260\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"1920\" height=\"1280\" loading=\"lazy\" decoding=\"async\" alt=\"The ChatGPT logo inside of an ouroboros, on a slate background\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/wm/2024/03/chatgpt-ouroboros-feature-image.png\"/\u003e\n    \u003c/picture\u003e\n                \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\t\t\u003c/a\u003e\n\t\n\n        \n        \n                            \u003cdiv\u003e\n\n                \n                 \n                \t\n\u003ch5\u003e\n\t\t\t\t\t        \t\t\t\t\n\t\t\u003ca href=\"https://www.xda-developers.com/five-creative-ways-to-use-an-llm/\" title=\"AI wants to help you: 5 creative ways to use LLMs\" target=\"_blank\"\u003e\n\t\t\tAI wants to help you: 5 creative ways to use LLMs\n\t\t\u003c/a\u003e\n\t\u003c/h5\u003e\n\n                                                    \n                \t\t\t\u003cp\u003eDon\u0026#39;t miss these great opportunities where AI could be saving you time, money, and hassle\u003c/p\u003e\n\t\n\n                    \n\n\n                \n                \n                \n                \n\n                \n                \n                \n                \t\n\n\n                \n\n                \n                \n                \n            \u003c/div\u003e\n                \n        \n        \n        \n            \u003c/div\u003e\n\u003ch2 id=\"enhanced-privacy-and-security\"\u003e\n            \u003cspan\u003e4 \u003c/span\u003e\n        \u003cspan\u003e\n                            Enhanced privacy and security\n                    \u003c/span\u003e\n       \u003c/h2\u003e\u003ch3 id=\"i-wouldn-39-t-trust-chatgpt-with-sensitive-information-and-neither-should-you\"\u003e\n            I wouldn\u0026#39;t trust ChatGPT with sensitive information, and neither should you\n    \u003c/h3\u003e\n\n\n\n\n    \n\n\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n    \n\n\u003cp\u003eOne of the most compelling reasons for hosting my own LLM is privacy. While you can’t change the fact that practically every LLM has scooped up data from the internet and has been trained on publicly available information, I’m not in favor of feeding it even more personal data. When I’m working with confidential documents or analyzing my own health records, uploading them to ChatGPT is an absolute no-go. It’s not just about the data that’s collected; it’s about control. The more I can keep my personal information off the cloud, the better.\u003c/p\u003e    \n\u003cp\u003eRunning my own locally hosted LLM means I can perform much of the same functions without giving these models access to my private information for training data. Yes, you can even switch off the internet, and the self-hosted LLM will work without a hitch. That level of privacy control is invaluable, especially for those of us who handle sensitive material regularly.\u003c/p\u003e    \n\u003cp\u003eFurthermore, hosting a model locally helps reduce the likelihood of any unintended data sharing.\u003c/p\u003e    \u003ch2 id=\"on-the-go-access\"\u003e\n            \u003cspan\u003e3 \u003c/span\u003e\n        \u003cspan\u003e\n                            On-the-go access\n                    \u003c/span\u003e\n       \u003c/h2\u003e\u003ch3 id=\"i-bet-chatgpt-can-39-t-do-this\"\u003e\n            I bet ChatGPT can\u0026#39;t do this\n    \u003c/h3\u003e\n\n                \n    \n    \n    \n                \n    \n                \n        \n                                                            \n                                                                                                                        \n                                                                        \n    \n    \n    \u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=800\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=800\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=500\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png?q=49\u0026amp;fit=crop\u0026amp;w=500\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"2606\" height=\"1808\" loading=\"lazy\" decoding=\"async\" alt=\"LM Studio Practice French results\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/lm-studio-practice-french-results.png\"/\u003e\n    \u003c/picture\u003e\n                                    \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\u003cp\u003e Which brings me to my next point — portability. As good as ChatGPT and Claude are, they can only be used as long as you’re near a Wi-Fi connection. What if you’re working on a flight, or perhaps a train with a spotty connection? What if you’re in a cafe with poor internet connectivity? That’s a no-go.\u003c/p\u003e    \n\u003cp\u003eThat’s where self-hosting truly shines. For instance, just last week, I spun up the Deepseek 7B model on my MacBook Air while on a flight to brainstorm ideas for a presentation. Sure, it’s not as fast as accessing an LLM in the cloud, but I don’t really mind the few extra seconds it takes to brainstorm ideas, do a grammar check, or help me brush up on a language.\u003c/p\u003e    \n\u003cp\u003eThe beauty of local hosting is that I’m not reliant on an external connection to get the job done. It’s been a game-changer.\u003c/p\u003e    \u003ch2 id=\"cost\"\u003e\n            \u003cspan\u003e2 \u003c/span\u003e\n        \u003cspan\u003e\n                            Cost\n                    \u003c/span\u003e\n       \u003c/h2\u003e\u003ch3 id=\"subscription-fatigue-is-real\"\u003e\n            Subscription fatigue is real\n    \u003c/h3\u003e\n\n                \n    \n    \n    \n                \n    \n                \n        \n                                                            \n                                                                                                                        \n                                                                        \n    \n    \n    \u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=800\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=800\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=500\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png?q=49\u0026amp;fit=crop\u0026amp;w=500\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"2398\" height=\"1552\" loading=\"lazy\" decoding=\"async\" alt=\"LLM cost\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/llm-cost.png\"/\u003e\n    \u003c/picture\u003e\n                                    \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\u003cp\u003e Let’s face it, nobody wants to pay for yet another subscription service. As good as ChatGPT’s premium tier is, almost anything I personally need from an LLM doesn’t really require the added cost. Hosting my own model has been incredibly cost-effective, and if your use case isn’t too complex, it might be the right choice for you as well — especially considering how easy it is with tools like LM Studio.\u003c/p\u003e    \n\u003cp\u003eWhile the premium tiers of services like ChatGPT might offer better performance, they’re often not necessary for most day-to-day tasks. Running my own model cuts out those subscription fees entirely, which, for me, is a huge win. More so, the availability of resource-efficient models like Llama 3 and Deepseek makes it an even more appealing choice.\u003c/p\u003e    \n\u003cp\u003eTo be sure, you’re not going to be running the full-fledged models on your home computers. However, in my experience, the quantized models pack just enough utility for day-to-day purposes.\u003c/p\u003e    \u003ch2 id=\"learning-and-customization\"\u003e\n            \u003cspan\u003e1 \u003c/span\u003e\n        \u003cspan\u003e\n                            Learning and customization\n                    \u003c/span\u003e\n       \u003c/h2\u003e\u003ch3 id=\"fine-tune-the-ai-model-to-match-your-preferences\"\u003e\n            Fine tune the AI model to match your preferences\n    \u003c/h3\u003e\n\n                \n    \n    \n    \n                \n    \n                \n        \n                                                            \n                                                                                                                        \n                                                                        \n    \n    \n    \u003cdiv data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png\" data-modal-id=\"single-image-modal\" data-modal-container-id=\"single-image-modal-container\" data-img-caption=\"\u0026#34;\u0026#34;\"\u003e\n\n            \n\n\n\n\n\u003cfigure\u003e\n        \u003cpicture\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 1024px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 768px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=825\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 481px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=800\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=800\u0026amp;dpr=2\"/\u003e\n        \n                                        \n                                    \n                                                                                                                                                                            \n            \n                                                            \n            \n            \n                                        \n            \u003csource media=\"(min-width: 0px)\" data-srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=500\u0026amp;dpr=2\" srcset=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png?q=49\u0026amp;fit=crop\u0026amp;w=500\u0026amp;dpr=2\"/\u003e\n                \u003cimg width=\"2052\" height=\"1390\" loading=\"lazy\" decoding=\"async\" alt=\"loading Llama 3 in LM Studio\" data-img-url=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png\" src=\"https://static1.xdaimages.com/wordpress/wp-content/uploads/2025/02/loading-llama-3-in-lm-studio.png\"/\u003e\n    \u003c/picture\u003e\n                                    \n    \u003c/figure\u003e\n\n\n        \u003c/div\u003e\n\n\u003cp\u003e Here’s where it gets more fun. As a tech enthusiast, getting into the nitty-gritty of things comes naturally to me. I enjoy understanding how things work under the hood, and self-hosting an LLM has given me that opportunity. Hosting my own LLM lets me experiment with it and optimize for my specific use cases—be it data analysis, conversations, or content generation. I’m not always successful with every tweak I make, but it’s a great way to learn how these models work and to shape them for my needs.\u003c/p\u003e    \n\u003cp\u003eSelf-hosting offers an unmatched level of customization. Instead of being confined to preset options provided by cloud services, I can adjust my LLM’s behavior to better align with my requirements. This could mean altering its conversational tone, optimizing it for specific tasks, or integrating it with tools I use in my daily life. The flexibility to experiment and evolve the model is something I’ve really enjoyed. Admittedly, this doesn\u0026#39;t work on-device unless you have extremely powerful hardware. But I\u0026#39;ve been experimenting with fine-tuning models using Amazon\u0026#39;s Sagemaker.\u003c/p\u003e    \n\u003cp\u003eAdditionally, I’ve been spending time building tools that plug into Deepseek’s API to analyze my personal investments and health data. While I wouldn’t be comfortable sending this data to a cloud server, having local access allows me to poke and prod the LLM model to better suit my use case. This hands-on approach has been both educational and incredibly rewarding. I’ve built custom scripts, explored new functionalities, and fine-tuned the model to give me exactly what I need. That sense of control is invaluable.\u003c/p\u003e    \u003ch3 id=\"why-self-hosting-an-llm-has-been-a-game-changer-for-me\"\u003e\n            Why self-hosting an LLM has been a game-changer for me\n    \u003c/h3\u003e\n\n\u003cp\u003eIn the end, hosting my own LLM has been a game-changer for me, offering a level of control, privacy, and customization that cloud-based models just can’t match. It’s not perfect — there are very notable tradeoffs when it comes to speed and convenience and, often, accuracy, especially when doing deep research. But the ability to experiment, protect my data, and have an AI that truly works on my terms has made it all worth it. If you’re someone who values privacy, enjoys tinkering with tech, or just wants a more personal AI experience, self-hosting might be the perfect fit for you, too.\u003c/p\u003e    \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "17 min read",
  "publishedTime": "2025-02-10T00:00:18Z",
  "modifiedTime": "2025-02-10T00:00:18Z"
}
