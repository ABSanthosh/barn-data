{
  "id": "8bf49f8d-ed02-490e-876d-076b070e04c4",
  "title": "Android’s Expressive Captions uses AI to bring emotion to captions",
  "link": "https://blog.google/products/android/google-android-expressive-captions/",
  "description": "The new Live Caption feature gives you the full picture of emotion in what’s being said on your device.",
  "author": "Angana GhoshDirector, Product ManagementAndroid",
  "published": "Thu, 05 Dec 2024 17:00:00 +0000",
  "source": "https://blog.google/products/android/rss",
  "categories": [
    "Accessibility",
    "Android"
  ],
  "byline": "Angana Ghosh",
  "length": 5377,
  "excerpt": "The new Live Caption feature gives you the full picture of emotion in what’s being said on your device.",
  "siteName": "Google",
  "favicon": "https://blog.google/static/blogv2/images/apple-touch-icon.png?version=pr20241210-1809",
  "text": "Dec 05, 2024 [[read-time]] min read This new feature builds on Live Caption so that you don’t just read what someone is saying — you get a sense of the emotion, too. General summary Android's new Expressive Captions feature uses AI to bring emotion to captions, making them more expressive and engaging. This feature, available on Android 14 and above, uses AI to capture not only spoken words but also tone, volume, and environmental cues. This means you can now experience the full emotional context of videos and livestreams, even without sound. Summaries were generated by Google AI. Generative AI is experimental. Basic explainer Android phones now have a cool new feature called Expressive Captions. It uses AI to make captions more like real conversations. It shows how people are talking, like if they're excited or sad. It also tells you about sounds in the background, like applause or cheering. You can use it on most videos, even when you're offline! Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: Sorry, your browser doesn't support embedded videos, but don't worry, you can download it and watch it with your favorite video player! Captions were originally popularized in the 1970s for the millions of people who are d/Deaf and hard of hearing to consume TV content. Now, 70% of Gen Z uses captions most of the time — whether they're watching videos on the subway, in a loud public space or just want to better understand what's being said. In some cases, the lack of pre-loaded captions for livestreams, social content or videos from friends or family can make them inaccessible. But in general, the way captions are presented hasn’t changed much in the past 50 years. And this means that nuances of language and sound, including emphasis, tone and personality, are often lost.Today, we want to change that with the introduction of Expressive Captions on Android, a new feature within Live Caption that will not only tell you what someone says, but how they say it. This is a meaningful update for advancing our Google Captions product suite that includes Live Transcribe, Sound Notifications, and more. Because even if you can’t hear it, you should still be able to feel it.Bringing feelings to captions Video format not supported Expressive Captions bring more intensity and emotion to your captions Expressive Captions uses AI on your Android device to communicate things like tone, volume, environmental cues and human noises. These small things make a huge difference in conveying what goes beyond words, especially for live and social content that doesn’t have pre-loaded or high-quality captions.All CAPs: Captions will now reflect the intensity of speech with capitalization, so you’ll know when a friend excitedly wishes you a “HAPPY BIRTHDAY!”Vocal bursts: You'll see even more sounds identified, like sighing, grunting and gasping, giving you essential expressions of tone.Ambient sound: We’ll label additional noises in the foreground and background, like applause and cheers, to give you a fuller picture of what’s happening in the environment. Expressive Captions uses three features to give you the context often missing from captions Expressive Captions are part of Live Caption, so they’re built into the operating system and available across apps on your phone.1 This means you can use Expressive Captions with most things you watch, like livestreams on social platforms, memories in your Google Photos reel and video messages from friends and family. When enabled, captions will occur in real time and on device, so you can use them even while you’re on airplane mode.Bringing Expressive Captions to lifeTo build Expressive Captions, our Android and Google DeepMind teams worked to understand how we engage with content on our devices without sound. Using multiple AI models, Expressive Captions not only captures spoken words but also translates them into stylized captions, while providing labels for an even wider range of background sounds. This makes captions just as vibrant as listening to audio. It’s just one way we’re building for the real lived experiences of people with disabilities and using AI to build for everyone.Starting today, Expressive Captions will be available in the U.S. in English on any Android device running Android 14 and above that has Live Caption. This is part of our work to find even more ways to bring emotional expression and context to captions.",
  "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ExpressiveCaptions_Hero-Thumbnail.width-1300.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle\u003e\n\n    \n    \n\n\n\n\n\n    \n\n    \n      \n\n\u003cdiv data-analytics-module=\"{\n    \u0026#34;module_name\u0026#34;: \u0026#34;Hero Menu\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n  }\"\u003e\n  \n  \u003cdiv\u003e\n      \u003cdiv\u003e\n          \n            \u003cp\u003eDec 05, 2024\u003c/p\u003e\n          \n          \n            \u003cp data-reading-time-render=\"\"\u003e[[read-time]] min read\u003c/p\u003e\n          \n        \u003c/div\u003e\n      \n        \u003cp\u003e\n          This new feature builds on Live Caption so that you don’t just read what someone is saying — you get a sense of the emotion, too.\n        \u003c/p\u003e\n      \n    \u003c/div\u003e\n  \n  \u003cdiv data-component=\"uni-ai-generated-summary\" data-analytics-module=\"{\n    \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n    \u0026#34;module_name\u0026#34;: \u0026#34;ai_summary\u0026#34;,\n    \u0026#34;section_header\u0026#34;: \u0026#34;CTA\u0026#34;\n  }\"\u003e\n      \n        \u003cdiv data-summary-id=\"ai_summary_1\"\u003e\n          \u003ch2\u003eGeneral summary\u003c/h2\u003e\n          \u003cp\u003eAndroid\u0026#39;s new Expressive Captions feature uses AI to bring emotion to captions, making them more expressive and engaging. This feature, available on Android 14 and above, uses AI to capture not only spoken words but also tone, volume, and environmental cues. This means you can now experience the full emotional context of videos and livestreams, even without sound.\u003c/p\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n      \n        \u003cdiv data-summary-id=\"ai_summary_3\"\u003e\n          \u003ch2\u003eBasic explainer\u003c/h2\u003e\n          \u003cp\u003eAndroid phones now have a cool new feature called Expressive Captions. It uses AI to make captions more like real conversations.  It shows how people are talking, like if they\u0026#39;re excited or sad. It also tells you about sounds in the background, like applause or cheering. You can use it on most videos, even when you\u0026#39;re offline!\u003c/p\u003e\n          \n          \u003cp\u003e\u003csmall\u003e\n            Summaries were generated by Google AI. Generative AI is experimental.\n          \u003c/small\u003e\n        \u003c/p\u003e\u003c/div\u003e\n      \n\n      \n      \u003cdiv\u003e\n        \u003ch4\u003e\n          Explore other styles:\n        \u003c/h4\u003e\n        \n      \u003c/div\u003e\n      \n\n      \u003c/div\u003e\n\u003c/div\u003e\n\n    \n\n    \n      \u003cdiv\u003e\n      \u003cp\u003e\n        \u003cvideo autoplay=\"\" muted=\"\" loop=\"\" playsinline=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/ExpressiveCaptions_Hero.mp4\" title=\"Two hands holding a Pixel Fold phone, unfolded to show a football game in progress. The phone displays captions that read, \u0026#34;To the three. THEY\u0026#39;RE GOING TO STOP HIM SHORT!\u0026#34;.\" poster=\"\n            \n              https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/ExpressiveCaptions_Hero-Thumbnail.jpg\n            \"\u003e\n          Sorry, your browser doesn\u0026#39;t support embedded videos, but don\u0026#39;t worry, you can\n            \u003ca href=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/ExpressiveCaptions_Hero.mp4\"\u003edownload it\u003c/a\u003e\n            and watch it with your favorite video player!\n        \u003c/video\u003e\n      \u003c/p\u003e\n      \n    \u003c/div\u003e\n\n    \n\n    \n    \u003cdiv data-reading-time=\"true\" data-component=\"uni-article-body\"\u003e\n\n            \n              \n\n\n\u003cgoogle-read-aloud-player data-analytics-module=\"{\n        \u0026#34;event\u0026#34;: \u0026#34;module_impression\u0026#34;,\n        \u0026#34;module_name\u0026#34;: \u0026#34;ai_audio\u0026#34;,\n        \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n    }\" data-date-modified=\"2024-12-05T18:35:54.569651+00:00\" data-progress-bar-style=\"half-wave\" data-api-key=\"AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac\" data-article-style=\"style9\" data-tracking-ids=\"G-HGNBTNCHCQ,G-6NKTLKV14N\" data-voice-list=\"en.ioh-pngnat:Cyan,en.usb-pngnat:Lime\" data-layout-style=\"style1\" data-highlight-mode=\"word-over-paragraph\" data-highlight-text-color=\"#000000\" data-highlight-word-background=\"#8AB4F8\" data-highlight-paragraph-background=\"#D2E3FC\" data-background=\"linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)\" data-foreground-color=\"#202124\" data-font=\"600 16px Google Sans, sans-serif\" data-box-shadow=\"0px 1px 3px 1px rgba(60, 64, 67, 0.15)\"\u003e\n\u003c/google-read-aloud-player\u003e\n\n\n\n\n            \n\n            \n            \n\n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"vauqm\"\u003eCaptions were originally popularized in the 1970s for the millions of people who are d/Deaf and hard of hearing to consume TV content. Now, \u003ca href=\"https://preply.com/en/blog/americas-subtitles-use/\"\u003e70% of Gen Z\u003c/a\u003e uses captions most of the time — whether they\u0026#39;re watching videos on the subway, in a loud public space or just want to better understand what\u0026#39;s being said. In some cases, the lack of pre-loaded captions for livestreams, social content or videos from friends or family can make them inaccessible. But in general, the way captions are presented hasn’t changed much in the past 50 years. And this means that nuances of language and sound, including emphasis, tone and personality, are often lost.\u003c/p\u003e\u003cp data-block-key=\"d1ug0\"\u003eToday, we want to change that with the introduction of Expressive Captions on Android, a new feature within \u003ca href=\"https://blog.google/products/android/live-caption/\"\u003eLive Caption\u003c/a\u003e that will not only tell you what someone says, but how they say it. This is a meaningful update for advancing our Google Captions product suite that includes Live Transcribe, Sound Notifications, and more. Because even if you can’t hear it, you should still be able to \u003ci\u003efeel\u003c/i\u003e it.\u003c/p\u003e\u003cp data-block-key=\"23o48\"\u003e\u003cb\u003eBringing feelings to captions\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n  \n    \n        \u003cdiv data-analytics-module=\"{\n            \u0026#34;module_name\u0026#34;: \u0026#34;Inline Images\u0026#34;,\n            \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n          }\"\u003e\n    \n\n    \u003cp\u003e\n\n        \n        \n          \n            \u003cvideo tabindex=\"0\" autoplay=\"\" loop=\"\" muted=\"\" playsinline=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Update_Intensity_ECvsLC_Football_Marketing_Final_1.mp4\" type=\"video/mp4\" title=\"Two phones side by side show a football game. On the left Expressive captions are off so the captions are plainly written. On the right, Expressive Captions is on and captioning the gasps, cheers and applause, and all caps of speech.\" alt=\"Expressive Captions High Intensity\"\u003e\n              Video format not supported\n            \u003c/video\u003e\n          \n        \n      \n      \u003c/p\u003e\n      \n        \u003cfigcaption\u003e\u003cp data-block-key=\"bxi5n\"\u003eExpressive Captions bring more intensity and emotion to your captions\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \n      \u003c/div\u003e\n    \n  \n\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"vauqm\"\u003eExpressive Captions uses AI on your Android device to communicate things like tone, volume, environmental cues and human noises. These small things make a huge difference in conveying what goes beyond words, especially for live and social content that doesn’t have pre-loaded or high-quality captions.\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"5mn3h\"\u003e\u003cb\u003eAll CAPs\u003c/b\u003e: Captions will now reflect the intensity of speech with capitalization, so you’ll know when a friend excitedly wishes you a “HAPPY BIRTHDAY!”\u003c/li\u003e\u003cli data-block-key=\"f6hj2\"\u003e\u003cb\u003eVocal bursts\u003c/b\u003e: You\u0026#39;ll see even more sounds identified, like sighing, grunting and gasping, giving you essential expressions of tone.\u003c/li\u003e\u003cli data-block-key=\"7u8n5\"\u003e\u003cb\u003eAmbient sound\u003c/b\u003e: We’ll label additional noises in the foreground and background, like applause and cheers, to give you a fuller picture of what’s happening in the environment.\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\n  \n\n  \n    \n\n\n\n\n\n\n\n  \n    \n        \u003cdiv data-analytics-module=\"{\n            \u0026#34;module_name\u0026#34;: \u0026#34;Inline Images\u0026#34;,\n            \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n          }\"\u003e\n    \n\n    \u003cp\u003e\u003cimg alt=\"A side by side of three phones showcasing the features of Expressive Captions with descriptions of them, including high intensity in CAPs, vocal bursts, and ambient sound.\" src=\" https://storage.googleapis.com/gweb-uniblog-publish-prod/images/EC_Keyword_Banner_Update.width-100.format-webp.webp \" loading=\"lazy\" data-loading=\"{\n                  \u0026#34;mobile\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/EC_Keyword_Banner_Update.width-500.format-webp.webp\u0026#34;,\n                  \u0026#34;desktop\u0026#34;: \u0026#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/EC_Keyword_Banner_Update.width-1000.format-webp.webp\u0026#34;\n                }\"/\u003e\n          \n        \n      \n      \u003c/p\u003e\n      \n        \u003cfigcaption\u003e\u003cp data-block-key=\"bxi5n\"\u003eExpressive Captions uses three features to give you the context often missing from captions\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \n      \u003c/div\u003e\n    \n  \n\n\n\n  \n\n  \n    \u003cdiv data-component=\"uni-article-paragraph\" data-analytics-module=\"{\n           \u0026#34;module_name\u0026#34;: \u0026#34;Paragraph\u0026#34;,\n           \u0026#34;section_header\u0026#34;: \u0026#34;Android’s Expressive Captions uses AI to bring emotion to captions\u0026#34;\n         }\"\u003e\u003cp data-block-key=\"vauqm\"\u003eExpressive Captions are part of Live Caption, so they’re built into the operating system and available across apps on your phone.\u003ca data-ga4-analytics-superscript-click=\"\" data-target=\"inline text\" href=\"#footnote-1\" id=\"footnote-source-1\"\u003e\u003csup\u003e1\u003c/sup\u003e\u003c/a\u003e This means you can use Expressive Captions with most things you watch, like livestreams on social platforms, memories in your Google Photos reel and video messages from friends and family. When enabled, captions will occur in real time and \u003ca href=\"https://blog.google/technology/ai/on-device-processing/\"\u003eon device\u003c/a\u003e, so you can use them even while you’re on airplane mode.\u003c/p\u003e\u003cp data-block-key=\"1ntdk\"\u003e\u003cb\u003eBringing Expressive Captions to life\u003c/b\u003e\u003c/p\u003e\u003cp data-block-key=\"12bsb\"\u003eTo build Expressive Captions, our Android and Google DeepMind teams worked to understand how we engage with content on our devices without sound. Using multiple AI models, Expressive Captions not only captures spoken words but also translates them into stylized captions, while providing labels for an even wider range of background sounds. This makes captions just as vibrant as listening to audio. It’s just one way we’re building for the real lived experiences of people with disabilities and using AI to build for everyone.\u003c/p\u003e\u003cp data-block-key=\"642jc\"\u003eStarting today, Expressive Captions will be available in the U.S. in English on any Android device running Android 14 and above that has Live Caption. This is part of our work to find even more ways to bring emotional expression and context to captions.\u003c/p\u003e\u003c/div\u003e\n  \n\n\n            \n            \n\n            \n              \n\n\n\n\n            \n          \u003c/div\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-12-05T17:00:00Z",
  "modifiedTime": null
}
