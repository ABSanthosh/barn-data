{
  "id": "9f6cc395-5fa7-4418-aac4-b1a1f48310b8",
  "title": "IBM sees enterprise customers are using ‘everything’ when it comes to AI, the challenge is matching the LLM to the right use case",
  "link": "https://venturebeat.com/ai/ibm-sees-enterprise-customers-are-using-everything-when-it-comes-to-ai-the-challenge-is-matching-the-llm-to-the-right-use-case/",
  "description": "Real-world deployment patterns show customers using multiple AI models simultaneously, forcing a fundamental shift in enterprise AI architecture.",
  "author": "Sean Michael Kerner",
  "published": "Wed, 25 Jun 2025 20:42:36 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Agent2Agent",
    "API",
    "AWS Bedrock",
    "Gemini",
    "Google Cloud",
    "IBM",
    "IBM Granite",
    "large language models (LLMs)",
    "LLaMA",
    "LLM router",
    "LLMs",
    "mistral",
    "model router",
    "Model routing",
    "multi-LLM",
    "o3",
    "VB Transform",
    "VB Transform 2025"
  ],
  "byline": "Sean Michael Kerner",
  "length": 6877,
  "excerpt": "Real-world deployment patterns show customers using multiple AI models simultaneously, forcing a fundamental shift in enterprise AI architecture.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. Learn more Over the last 100 years, IBM has seen many different tech trends rise and fall. What tends to win out are technologies where there is choice. At VB Transform 2025 today, Armand Ruiz, VP of AI Platform at IBM detailed how Big Blue is thinking about generative AI and how its enterprise users are actually deploying the technology. A key theme that Ruiz emphasized is that at this point, it’s not about choosing a single large language model (LLM) provider or technology. Increasingly, enterprise customers are systematically rejecting single-vendor AI strategies in favor of multi-model approaches that match specific LLMs to targeted use cases. IBM has its own open-source AI models with the Granite family, but it is not positioning that technology as the only choice, or even the right choice for all workloads. This enterprise behavior is driving IBM to position itself not as a foundation model competitor, but as what Ruiz referred to as a control tower for AI workloads. “When I sit in front of a customer, they’re using everything they have access to, everything,” Ruiz explained. “For coding, they love Anthropic and for some other use cases like  for reasoning, they like o3 and then for LLM customization, with their own data and fine tuning, they like either our Granite series or Mistral with their small models, or even Llama…it’s just matching the LLM to the right use case. And then we help them as well to make recommendations.” The Multi-LLM gateway strategy IBM’s response to this market reality is a newly released model gateway that provides enterprises with a single API to switch between different LLMs while maintaining observability and governance across all deployments.  The technical architecture allows customers to run open-source models on their own inference stack for sensitive use cases while simultaneously accessing public APIs like AWS Bedrock or Google Cloud’s Gemini for less critical applications. “That gateway is providing our customers a single layer with a single API to switch from one LLM to another LLM and add observability and governance all throughout,” Ruiz said. The approach directly contradicts the common vendor strategy of locking customers into proprietary ecosystems. IBM is not alone in taking a multi-vendor approach to model selection. Multiple tools have emerged in recent months for model routing, which aim to direct workloads to the appropriate model. Agent orchestration protocols emerge as critical infrastructure Beyond multi-model management, IBM is tackling the emerging challenge of agent-to-agent communication through open protocols.  The company has developed ACP (Agent Communication Protocol) and contributed it to the Linux Foundation. ACP is a competitive effort to Google’s Agent2Agent (A2A) protocol which just this week was contributed by Google to the Linux Foundation. Ruiz noted that both protocols aim to facilitate communication between agents and reduce custom development work. He expects that eventually, the different approaches will converge, and currently, the differences between A2A and ACP are mostly technical. The agent orchestration protocols provide standardized ways for AI systems to interact across different platforms and vendors. The technical significance becomes clear when considering enterprise scale: some IBM customers already have over 100 agents in pilot programs. Without standardized communication protocols, each agent-to-agent interaction requires custom development, creating an unsustainable integration burden. AI is about transforming workflows and the way work is done In terms of how Ruiz sees AI impacting enterprises today, he suggests it really needs to be more than just chatbots. “If you are just doing chatbots, or you’re only trying to do cost savings with AI, you are not doing AI,” Ruiz said. “I think AI is really about completely transforming the workflow and the way work is done.” The distinction between AI implementation and AI transformation centers on how deeply the technology integrates into existing business processes. IBM’s internal HR example illustrates this shift: instead of employees asking chatbots for HR information, specialized agents now handle routine queries about compensation, hiring, and promotions, automatically routing to appropriate systems and escalating to humans only when necessary. “I used to spend a lot of time talking to my HR partners for a lot of things. I handle most of it now with an HR agent,” Ruiz explained. “Depending on the question, if it’s something about compensation or it’s something about just handling separation, or hiring someone, or doing a promotion, all these things will connect with different HR internal systems, and those will be like separate agents.” This represents a fundamental architectural shift from human-computer interaction patterns to computer-mediated workflow automation. Rather than employees learning to interact with AI tools, the AI learns to execute complete business processes end-to-end. The technical implication: enterprises need to move beyond API integrations and prompt engineering toward deep process instrumentation that allows AI agents to execute multi-step workflows autonomously. Strategic implications for enterprise AI investment IBM’s real-world deployment data suggests several critical shifts for enterprise AI strategy: Abandon chatbot-first thinking: Organizations should identify complete workflows for transformation rather than adding conversational interfaces to existing systems. The goal is to eliminate human steps, not improve human-computer interaction. Architect for multi-model flexibility: Rather than committing to single AI providers, enterprises need integration platforms that enable switching between models based on use case requirements while maintaining governance standards. Invest in communication standards: Organizations should prioritize AI tools that support emerging protocols like MCP, ACP, and A2A rather than proprietary integration approaches that create vendor lock-in. “There is so much to build, and I keep saying everyone needs to learn AI and especially business leaders need to be AI first leaders and understand the concepts,” Ruiz said. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/06/IBM-TRANSFORM-2025-SMK.jpg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. \u003ca href=\"http://vbtransform.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLearn more\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eOver the last 100 years\u003cspan\u003e, \u003c/span\u003e\u003ca href=\"https://www.ibm.com/us-en\"\u003e\u003cspan\u003eI\u003c/span\u003eBM\u003c/a\u003e has seen many different tech trends rise and fall. What tends to win out are technologies where there is choice.\u003c/p\u003e\n\n\n\n\u003cp\u003eAt \u003ca href=\"https://www.vbtransform.com/\"\u003eVB Transform 2025\u003c/a\u003e today, Armand Ruiz, VP of AI Platform at IBM detailed how Big Blue is thinking about generative AI and how its enterprise users are actually deploying the technology. A key theme that Ruiz emphasized is that at this point, it’s not about choosing a single large language model (LLM) provider or technology. Increasingly, enterprise customers are systematically rejecting single-vendor AI strategies in favor of multi-model approaches that match specific LLMs to targeted use cases.\u003c/p\u003e\n\n\n\n\u003cp\u003eIBM has its own open-source AI models with the\u003ca href=\"https://venturebeat.com/ai/ibm-granite-3-2-uses-conditional-reasoning-time-series-forecasting-and-document-vision-to-tackle-challenging-enterprise-use-cases/\"\u003e Granite family\u003c/a\u003e, but it is not positioning that technology as the only choice, or even the right choice for all workloads. This enterprise behavior is driving IBM to position itself not as a foundation model competitor, but as what Ruiz referred to as a control tower for AI workloads.\u003c/p\u003e\n\n\n\n\u003cp\u003e“When I sit in front of a customer, they’re using everything they have access to, everything,” Ruiz explained. “For coding, they love Anthropic and for some other use cases like  for reasoning, they like o3 and then for LLM customization, with their own data and fine tuning, they like either our Granite series or\u003ca href=\"https://venturebeat.com/ai/mistral-just-updated-its-open-source-small-model-from-3-1-to-3-2-heres-why/\"\u003e Mistral\u003c/a\u003e with their small models, or even\u003ca href=\"https://venturebeat.com/ai/metas-answer-to-deepseek-is-here-llama-4-launches-with-long-context-scout-and-maverick-models-and-2t-parameter-behemoth-on-the-way/\"\u003e Llama\u003c/a\u003e…it’s just matching the LLM to the right use case. And then we help them as well to make recommendations.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-multi-llm-gateway-strategy\"\u003eThe Multi-LLM gateway strategy\u003c/h2\u003e\n\n\n\n\u003cp\u003eIBM’s response to this market reality is a newly released model gateway that provides enterprises with a single API to switch between different LLMs while maintaining observability and governance across all deployments. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe technical architecture allows customers to run open-source models on their own inference stack for sensitive use cases while simultaneously accessing public APIs like AWS Bedrock or Google Cloud’s Gemini for less critical applications.\u003c/p\u003e\n\n\n\n\u003cp\u003e“That gateway is providing our customers a single layer with a single API to switch from one LLM to another LLM and add observability and governance all throughout,” Ruiz said. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe approach directly contradicts the common vendor strategy of locking customers into proprietary ecosystems. IBM is not alone in taking a multi-vendor approach to model selection. Multiple tools have emerged in recent months for\u003ca href=\"https://venturebeat.com/ai/why-accenture-and-martian-see-model-routing-as-key-to-enterprise-ai-success/\"\u003e model routing\u003c/a\u003e, which aim to direct workloads to the appropriate model.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-agent-orchestration-protocols-emerge-as-critical-infrastructure\"\u003eAgent orchestration protocols emerge as critical infrastructure\u003c/h2\u003e\n\n\n\n\u003cp\u003eBeyond multi-model management, IBM is tackling the emerging challenge of agent-to-agent communication through open protocols.\u003c/p\u003e\n\n\n\n\u003cp\u003e The company has developed ACP (Agent Communication Protocol) and contributed it to the Linux Foundation. ACP is a competitive effort to\u003ca href=\"https://venturebeat.com/ai/googles-agent2agent-interoperability-protocol-aims-to-standardize-agentic-communication/\"\u003e Google’s Agent2Agent\u003c/a\u003e (A2A) protocol which just this week was contributed by Google to the Linux Foundation.\u003c/p\u003e\n\n\n\n\u003cp\u003eRuiz noted that both protocols aim to facilitate communication between agents and reduce custom development work. He expects that eventually, the different approaches will converge, and currently, the differences between A2A and ACP are mostly technical.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe agent orchestration protocols provide standardized ways for AI systems to interact across different platforms and vendors.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe technical significance becomes clear when considering enterprise scale: some IBM customers already have over 100 agents in pilot programs. Without standardized communication protocols, each agent-to-agent interaction requires custom development, creating an unsustainable integration burden.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-ai-is-about-transforming-workflows-and-the-way-work-is-done\"\u003eAI is about transforming workflows and the way work is done\u003c/h2\u003e\n\n\n\n\u003cp\u003eIn terms of how Ruiz sees AI impacting enterprises today, he suggests it really needs to be more than just chatbots.\u003c/p\u003e\n\n\n\n\u003cp\u003e“If you are just doing chatbots, or you’re only trying to do cost savings with AI, you are not doing AI,” Ruiz said. “I think AI is really about completely transforming the workflow and the way work is done.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThe distinction between AI implementation and AI transformation centers on how deeply the technology integrates into existing business processes. IBM’s internal HR example illustrates this shift: instead of employees asking chatbots for HR information, specialized agents now handle routine queries about compensation, hiring, and promotions, automatically routing to appropriate systems and escalating to humans only when necessary.\u003c/p\u003e\n\n\n\n\u003cp\u003e“I used to spend a lot of time talking to my HR partners for a lot of things. I handle most of it now with an HR agent,” Ruiz explained. “Depending on the question, if it’s something about compensation or it’s something about just handling separation, or hiring someone, or doing a promotion, all these things will connect with different HR internal systems, and those will be like separate agents.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThis represents a fundamental architectural shift from human-computer interaction patterns to computer-mediated workflow automation. Rather than employees learning to interact with AI tools, the AI learns to execute complete business processes end-to-end.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe technical implication: enterprises need to move beyond API integrations and prompt engineering toward deep process instrumentation that allows AI agents to execute multi-step workflows autonomously.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-strategic-implications-for-enterprise-ai-investment\"\u003eStrategic implications for enterprise AI investment\u003c/h2\u003e\n\n\n\n\u003cp\u003eIBM’s real-world deployment data suggests several critical shifts for enterprise AI strategy:\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eAbandon chatbot-first thinking\u003c/strong\u003e: Organizations should identify complete workflows for transformation rather than adding conversational interfaces to existing systems. The goal is to eliminate human steps, not improve human-computer interaction.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eArchitect for multi-model flexibility\u003c/strong\u003e: Rather than committing to single AI providers, enterprises need integration platforms that enable switching between models based on use case requirements while maintaining governance standards.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eInvest in communication standards\u003c/strong\u003e: Organizations should prioritize AI tools that support emerging protocols like MCP, ACP, and A2A rather than proprietary integration approaches that create vendor lock-in.\u003c/p\u003e\n\n\n\n\u003cp\u003e“There is so much to build, and I keep saying everyone needs to learn AI and especially business leaders need to be AI first leaders and understand the concepts,” Ruiz said.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-06-25T20:42:36Z",
  "modifiedTime": "2025-06-25T20:42:45Z"
}
