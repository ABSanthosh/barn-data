{
  "id": "c21428ce-225c-489e-b0cf-3f0392d4ed6d",
  "title": "Beyond static AI: MIT’s new framework lets models teach themselves",
  "link": "https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves/",
  "description": "MIT researchers developed SEAL, a framework that lets language models continuously learn new knowledge and tasks.",
  "author": "Ben Dickson",
  "published": "Mon, 23 Jun 2025 21:58:44 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI research",
    "AI, ML and Deep Learning",
    "Fine-tuning large language models",
    "in-context learning (ICL)",
    "large language models",
    "large language models (LLMs)",
    "LLMs",
    "MIT",
    "reinforcement learning",
    "research",
    "Self-Adapting Language Models (SEAL)",
    "test-time training (TTT)",
    "two-loop system"
  ],
  "byline": "Ben Dickson",
  "length": 8949,
  "excerpt": "MIT researchers developed SEAL, a framework that lets language models continuously learn new knowledge and tasks.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "June 23, 2025 2:58 PM Image credit: VentureBeat with ChatGPT Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. Learn more Researchers at MIT have developed a framework called Self-Adapting Language Models (SEAL) that enables large language models (LLMs) to continuously learn and adapt by updating their own internal parameters. SEAL teaches an LLM to generate its own training data and update instructions, allowing it to permanently absorb new knowledge and learn new tasks. This framework could be useful for enterprise applications, particularly for AI agents that operate in dynamic environments, where they must constantly process new information and adapt their behavior. The challenge of adapting LLMs While large language models have shown remarkable abilities, adapting them to specific tasks, integrating new information, or mastering novel reasoning skills remains a significant hurdle. Currently, when faced with a new task, LLMs typically learn from data “as-is” through methods like finetuning or in-context learning. However, the provided data is not always in an optimal format for the model to learn efficiently. Existing approaches don’t allow the model to develop its own strategies for best transforming and learning from new information. “Many enterprise use cases demand more than just factual recall—they require deeper, persistent adaptation,” Jyo Pari, PhD student at MIT and co-author of the paper, told VentureBeat. “For example, a coding assistant might need to internalize a company’s specific software framework, or a customer-facing model might need to learn a user’s unique behavior or preferences over time.”  In such cases, temporary retrieval falls short, and the knowledge needs to be “baked into” the model’s weights so that it influences all future responses.  Creating self-adapting language models “As a step towards scalable and efficient adaptation of language models, we propose equipping LLMs with the ability to generate their own training data and finetuning directives for using such data,” the MIT researchers state in their paper. Overview of SEAL framework Source: arXiv The researchers’ solution is SEAL, short for Self-Adapting Language Models. It uses a reinforcement learning (RL) algorithm to train an LLM to generate “self-edits”—natural-language instructions that specify how the model should update its own weights. These self-edits can restructure new information, create synthetic training examples, or even define the technical parameters for the learning process itself. Intuitively, SEAL teaches a model how to create its own personalized study guide. Instead of just reading a new document (the raw data), the model learns to rewrite and reformat that information into a style it can more easily absorb and internalize. This process brings together several key areas of AI research, including synthetic data generation, reinforcement learning and test-time training (TTT). The framework operates on a two-loop system. In an “inner loop,” the model uses a self-edit to perform a small, temporary update to its weights. In an “outer loop,” the system evaluates whether that update improved the model’s performance on a target task. If it did, the model receives a positive reward, reinforcing its ability to generate that kind of effective self-edit in the future. Over time, the LLM becomes an expert at teaching itself. In their study, the researchers used a single model for the entire SEAL framework. However, they also note that this process can be decoupled into a “teacher-student” model. A specialized teacher model could be trained to generate effective self-edits for a separate student model, which would then be updated. This approach could allow for more specialized and efficient adaptation pipelines in enterprise settings. SEAL in action The researchers tested SEAL in two key domains: knowledge incorporation (the ability to permanently integrate new facts) and few-shot learning (the ability to generalize from a handful of examples). SEAL in knowledge incorporation Source: arXiv For knowledge incorporation, the goal was to see if the model could answer questions about a text passage without having access to the passage during questioning. Finetuning Llama-3.2-1B on the raw text provided only a marginal improvement over the base model.  However, when the SEAL model created “self-edits” by generating several “implications” from a passage and was trained on this synthetic data, its accuracy jumped to 47%. Notably, this outperformed results from using synthetic data generated by the much larger GPT-4.1, suggesting the model learned to create superior training material for itself. SEAL in few-shot learning Source: arXiv For few-shot learning, the researchers tested SEAL on examples from the Abstract Reasoning Corpus (ARC), where the model must solve visual puzzles. In the self-edit phase, the model had to generate the entire adaptation strategy, including which data augmentations and tools to use and what learning rate to apply.  SEAL achieved a 72.5% success rate, a dramatic improvement over the 20% rate achieved without RL training and the 0% rate of standard in-context learning. SEAL (red line) continues to improve across RL cycles Source: arXiv Implications for the enterprise Some experts project that the supply of high-quality, human-generated training data could be exhausted in the coming years. Progress may soon depend on “a model’s capacity to generate its own high-utility training signal,” as the researchers put it. They add, “A natural next step is to meta-train a dedicated SEAL synthetic-data generator model that produces fresh pretraining corpora, allowing future models to scale and achieve greater data efficiency without relying on additional human text.” For example, the researchers propose that an LLM could ingest complex documents like academic papers or financial reports and autonomously generate thousands of explanations and implications to deepen its understanding.  “This iterative loop of self-expression and self-refinement could allow models to keep improving on rare or underrepresented topics even in the absence of additional external supervision,” the researchers explain. This capability is especially promising for building AI agents. Agentic systems must incrementally acquire and retain knowledge as they interact with their environment. SEAL provides a mechanism for this. After an interaction, an agent could synthesize a self-edit to trigger a weight update, allowing it to internalize the lessons learned. This enables the agent to evolve over time, improve its performance based on experience, and reduce its reliance on static programming or repeated human guidance. “SEAL demonstrates that large language models need not remain static after pretraining,” the researchers write. “By learning to generate their own synthetic self-edit data and to apply it through lightweight weight updates, they can autonomously incorporate new knowledge and adapt to novel tasks.” Limitations of SEAL That said, SEAL is not a universal solution. For example, it can suffer from “catastrophic forgetting,” where constant retraining cycles can result in the model learning its earlier knowledge. “In our current implementation, we encourage a hybrid approach,” Pari said. “Enterprises should be selective about what knowledge is important enough to integrate permanently.”  Factual and evolving data can remain in external memory through RAG, while long-lasting, behavior-shaping knowledge is better suited for weight-level updates via SEAL.  “This kind of hybrid memory strategy ensures the right information is persistent without overwhelming the model or introducing unnecessary forgetting,” he said. It is also worth noting that SEAL takes a non-trivial amount of time to tune the self-edit examples and train the model. This makes continuous, real-time editing infeasible in most production settings. “We envision a more practical deployment model where the system collects data over a period—say, a few hours or a day—and then performs targeted self-edits during scheduled update intervals,” Pari said. “This approach allows enterprises to control the cost of adaptation while still benefiting from SEAL’s ability to internalize new knowledge.” Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/06/self-adapting-language-models.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-06-23T21:58:44+00:00\" datetime=\"2025-06-23T21:58:44+00:00\"\u003eJune 23, 2025 2:58 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"500\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/self-adapting-language-models.png?w=750\" alt=\"Image credit: VentureBeat with ChatGPT\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eImage credit: VentureBeat with ChatGPT\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. \u003ca href=\"http://vbtransform.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLearn more\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eResearchers at \u003ca href=\"https://www.mit.edu/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMIT\u003c/a\u003e have developed a framework called \u003ca href=\"https://arxiv.org/abs/2506.10943\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSelf-Adapting Language Models\u003c/a\u003e (SEAL) that enables large language models (LLMs) to continuously learn and adapt by updating their own internal parameters. SEAL teaches an LLM to generate its own training data and update instructions, allowing it to permanently absorb new knowledge and learn new tasks.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis framework could be useful for enterprise applications, particularly for AI agents that operate in dynamic environments, where they must constantly process new information and adapt their behavior.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-challenge-of-adapting-llms\"\u003eThe challenge of adapting LLMs\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhile large language models have shown remarkable abilities, adapting them to specific tasks, integrating new information, or mastering novel reasoning skills remains a significant hurdle.\u003c/p\u003e\n\n\n\n\u003cp\u003eCurrently, when faced with a new task, LLMs typically learn from data “as-is” through methods like \u003ca href=\"https://venturebeat.com/ai/fine-tuning-vs-in-context-learning-new-research-guides-better-llm-customization-for-real-world-tasks/\"\u003efinetuning or in-context learning\u003c/a\u003e. However, the provided data is not always in an optimal format for the model to learn efficiently. Existing approaches don’t allow the model to develop its own strategies for best transforming and learning from new information.\u003c/p\u003e\n\n\n\n\u003cp\u003e“Many enterprise use cases demand more than just factual recall—they require deeper, persistent adaptation,” Jyo Pari, PhD student at MIT and co-author of the paper, told VentureBeat. “For example, a coding assistant might need to internalize a company’s specific software framework, or a customer-facing model might need to learn a user’s unique behavior or preferences over time.” \u003c/p\u003e\n\n\n\n\u003cp\u003eIn such cases, temporary retrieval falls short, and the knowledge needs to be “baked into” the model’s weights so that it influences all future responses. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-creating-self-adapting-language-models\"\u003eCreating self-adapting language models\u003c/h2\u003e\n\n\n\n\u003cp\u003e“As a step towards scalable and efficient adaptation of language models, we propose equipping LLMs with the ability to generate their own training data and finetuning directives for using such data,” the MIT researchers state in their paper.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" height=\"214\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?w=800\" alt=\"Overview of SEAL framework (source: arXiv)\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png 1202w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=300,80 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=768,206 768w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=800,214 800w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=400,107 400w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=750,201 750w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=578,155 578w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=930,249 930w, https://venturebeat.com/wp-content/uploads/2025/06/image_b1ee4c.png?resize=1200,322 1200w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eOverview of SEAL framework Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe researchers’ solution is SEAL, short for Self-Adapting Language Models. It uses a reinforcement learning (RL) algorithm to train an LLM to generate “self-edits”—natural-language instructions that specify how the model should update its own weights. These self-edits can restructure new information, create synthetic training examples, or even define the technical parameters for the learning process itself.\u003c/p\u003e\n\n\n\n\u003cp\u003eIntuitively, SEAL teaches a model how to create its own personalized study guide. Instead of just reading a new document (the raw data), the model learns to rewrite and reformat that information into a style it can more easily absorb and internalize. This process brings together several key areas of AI research, including synthetic data generation, \u003ca href=\"https://venturebeat.com/ai/deepseek-r1s-bold-bet-on-reinforcement-learning-how-it-outpaced-openai-at-3-of-the-cost/\"\u003ereinforcement learning\u003c/a\u003e and \u003ca href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms/\"\u003etest-time training\u003c/a\u003e (TTT).\u003c/p\u003e\n\n\n\n\u003cp\u003eThe framework operates on a two-loop system. In an “inner loop,” the model uses a self-edit to perform a small, temporary update to its weights. In an “outer loop,” the system evaluates whether that update improved the model’s performance on a target task. If it did, the model receives a positive reward, reinforcing its ability to generate that kind of effective self-edit in the future. Over time, the LLM becomes an expert at teaching itself.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn their study, the researchers used a single model for the entire SEAL framework. However, they also note that this process can be decoupled into a “teacher-student” model. A specialized teacher model could be trained to generate effective self-edits for a separate student model, which would then be updated. This approach could allow for more specialized and efficient adaptation pipelines in enterprise settings.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-seal-in-action\"\u003eSEAL in action\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe researchers tested SEAL in two key domains: knowledge incorporation (the ability to permanently integrate new facts) and \u003ca href=\"https://venturebeat.com/ai/deepmind-researchers-discover-impressive-learning-capabilities-in-long-context-llms/\"\u003efew-shot learning\u003c/a\u003e (the ability to generalize from a handful of examples).\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" height=\"152\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?w=800\" alt=\"SEAL in knowledge incorporation (source: arXiv)\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png 1220w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=300,57 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=768,146 768w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=800,152 800w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=400,76 400w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=750,143 750w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=578,110 578w, https://venturebeat.com/wp-content/uploads/2025/06/image_d93126.png?resize=930,177 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSEAL in knowledge incorporation Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFor knowledge incorporation, the goal was to see if the model could answer questions about a text passage without having access to the passage during questioning. Finetuning Llama-3.2-1B on the raw text provided only a marginal improvement over the base model. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, when the SEAL model created “self-edits” by generating several “implications” from a passage and was trained on this synthetic data, its accuracy jumped to 47%. Notably, this outperformed results from using synthetic data generated by the much larger \u003ca href=\"https://venturebeat.com/security/openais-new-gpt-4-1-models-can-process-a-million-tokens-and-solve-coding-problems-better-than-ever/\"\u003eGPT-4.1\u003c/a\u003e, suggesting the model learned to create superior training material for itself.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" height=\"218\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?w=800\" alt=\"SEAL in few-shot learning (source: arXiv)\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png 1226w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=300,82 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=768,209 768w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=800,218 800w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=400,109 400w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=750,204 750w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=578,157 578w, https://venturebeat.com/wp-content/uploads/2025/06/image_1e87a7.png?resize=930,253 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSEAL in few-shot learning Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFor few-shot learning, the researchers tested SEAL on examples from the \u003ca href=\"https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning/\"\u003eAbstract Reasoning Corpus\u003c/a\u003e (ARC), where the model must solve visual puzzles. In the self-edit phase, the model had to generate the entire adaptation strategy, including which data augmentations and tools to use and what learning rate to apply. \u003c/p\u003e\n\n\n\n\u003cp\u003eSEAL achieved a 72.5% success rate, a dramatic improvement over the 20% rate achieved without RL training and the 0% rate of standard in-context learning.\u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg loading=\"lazy\" decoding=\"async\" width=\"508\" height=\"510\" src=\"https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png\" alt=\"SEAL (red line) continues to improve across RL cycles (source: arXiv)\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png 508w, https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png?resize=300,301 300w, https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png?resize=52,52 52w, https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png?resize=160,160 160w, https://venturebeat.com/wp-content/uploads/2025/06/image_969ef3.png?resize=400,402 400w\" sizes=\"auto, (max-width: 508px) 100vw, 508px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eSEAL (red line) continues to improve across RL cycles Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003ch2 id=\"h-implications-for-the-enterprise\"\u003eImplications for the enterprise\u003c/h2\u003e\n\n\n\n\u003cp\u003eSome experts project that the supply of high-quality, human-generated training data could be exhausted in the coming years. Progress may soon depend on “a model’s capacity to generate its own high-utility training signal,” as the researchers put it. They add, “A natural next step is to meta-train a dedicated SEAL synthetic-data generator model that produces fresh pretraining corpora, allowing future models to scale and achieve greater data efficiency without relying on additional human text.”\u003c/p\u003e\n\n\n\n\u003cp\u003eFor example, the researchers propose that an LLM could ingest complex documents like academic papers or financial reports and autonomously generate thousands of explanations and implications to deepen its understanding. \u003c/p\u003e\n\n\n\n\u003cp\u003e“This iterative loop of self-expression and self-refinement could allow models to keep improving on rare or underrepresented topics even in the absence of additional external supervision,” the researchers explain.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis capability is especially promising for building \u003ca href=\"https://venturebeat.com/ai/why-agentic-ai-is-the-next-wave-of-innovation/\"\u003eAI agents\u003c/a\u003e. Agentic systems must incrementally acquire and retain knowledge as they interact with their environment. SEAL provides a mechanism for this. After an interaction, an agent could synthesize a self-edit to trigger a weight update, allowing it to internalize the lessons learned. This enables the agent to evolve over time, improve its performance based on experience, and reduce its reliance on static programming or repeated human guidance.\u003c/p\u003e\n\n\n\n\u003cp\u003e“SEAL demonstrates that large language models need not remain static after pretraining,” the researchers write. “By learning to generate their own synthetic self-edit data and to apply it through lightweight weight updates, they can autonomously incorporate new knowledge and adapt to novel tasks.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-limitations-of-seal\"\u003eLimitations of SEAL\u003c/h2\u003e\n\n\n\n\u003cp\u003eThat said, SEAL is not a universal solution. For example, it can suffer from “catastrophic forgetting,” where constant retraining cycles can result in the model learning its earlier knowledge.\u003c/p\u003e\n\n\n\n\u003cp\u003e“In our current implementation, we encourage a hybrid approach,” Pari said. “Enterprises should be selective about what knowledge is important enough to integrate permanently.” \u003c/p\u003e\n\n\n\n\u003cp\u003eFactual and evolving data can remain in external memory through RAG, while long-lasting, behavior-shaping knowledge is better suited for weight-level updates via SEAL. \u003c/p\u003e\n\n\n\n\u003cp\u003e“This kind of hybrid memory strategy ensures the right information is persistent without overwhelming the model or introducing unnecessary forgetting,” he said.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt is also worth noting that SEAL takes a non-trivial amount of time to tune the self-edit examples and train the model. This makes continuous, real-time editing infeasible in most production settings.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We envision a more practical deployment model where the system collects data over a period—say, a few hours or a day—and then performs targeted self-edits during scheduled update intervals,” Pari said. “This approach allows enterprises to control the cost of adaptation while still benefiting from SEAL’s ability to internalize new knowledge.”\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "10 min read",
  "publishedTime": "2025-06-23T21:58:44Z",
  "modifiedTime": "2025-06-23T21:58:56Z"
}
