{
  "id": "7958c610-12fc-4f92-a291-9af72a1df7b6",
  "title": "New AI architecture delivers 100x faster reasoning than LLMs with just 1,000 training examples",
  "link": "https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/",
  "description": "Hierarchical Reasoning Models (HRM) tackle complex reasoning tasks while being smaller, faster, and more data-efficient than large AI models.",
  "author": "Ben Dickson",
  "published": "Fri, 25 Jul 2025 23:27:42 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI Reasoning",
    "AI research",
    "AI, ML and Deep Learning",
    "chain of thought reasoning",
    "data",
    "large language models",
    "large language models (LLMs)",
    "LLMs",
    "reasoning models",
    "research",
    "sapient intelligence",
    "The Hierarchical Reasoning Model (HRM)"
  ],
  "byline": "Ben Dickson",
  "length": 9905,
  "excerpt": "Hierarchical Reasoning Models (HRM) tackle complex reasoning tasks while being smaller, faster, and more data-efficient than large AI models.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "July 25, 2025 4:27 PM Credit: VentureBeat made with Midjourney Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now Singapore-based AI startup Sapient Intelligence has developed a new AI architecture that can match, and in some cases vastly outperform, large language models (LLMs) on complex reasoning tasks, all while being significantly smaller and more data-efficient. The architecture, known as the Hierarchical Reasoning Model (HRM), is inspired by how the human brain utilizes distinct systems for slow, deliberate planning and fast, intuitive computation. The model achieves impressive results with a fraction of the data and memory required by today’s LLMs. This efficiency could have important implications for real-world enterprise AI applications where data is scarce and computational resources are limited. The limits of chain-of-thought reasoning When faced with a complex problem, current LLMs largely rely on chain-of-thought (CoT) prompting, breaking down problems into intermediate text-based steps, essentially forcing the model to “think out loud” as it works toward a solution. While CoT has improved the reasoning abilities of LLMs, it has fundamental limitations. In their paper, researchers at Sapient Intelligence argue that “CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely.” The AI Impact Series Returns to San Francisco - August 5 The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation. Secure your spot now - space is limited: https://bit.ly/3GuuPLF This dependency on generating explicit language tethers the model’s reasoning to the token level, often requiring massive amounts of training data and producing long, slow responses. This approach also overlooks the type of “latent reasoning” that occurs internally, without being explicitly articulated in language. As the researchers note, “A more efficient approach is needed to minimize these data requirements.” A hierarchical approach inspired by the brain To move beyond CoT, the researchers explored “latent reasoning,” where instead of generating “thinking tokens,” the model reasons in its internal, abstract representation of the problem. This is more aligned with how humans think; as the paper states, “the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language.” However, achieving this level of deep, internal reasoning in AI is challenging. Simply stacking more layers in a deep learning model often leads to a “vanishing gradient” problem, where learning signals weaken across layers, making training ineffective. An alternative, recurrent architectures that loop over computations can suffer from “early convergence,” where the model settles on a solution too quickly without fully exploring the problem. The Hierarchical Reasoning Model (HRM) is inspired by the structure of the brain Source: arXiv Seeking a better approach, the Sapient team turned to neuroscience for a solution. “The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack,” the researchers write. “It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning.” Inspired by this, they designed HRM with two coupled, recurrent modules: a high-level (H) module for slow, abstract planning, and a low-level (L) module for fast, detailed computations. This structure enables a process the team calls “hierarchical convergence.” Intuitively, the fast L-module addresses a portion of the problem, executing multiple steps until it reaches a stable, local solution. At that point, the slow H-module takes this result, updates its overall strategy, and gives the L-module a new, refined sub-problem to work on. This effectively resets the L-module, preventing it from getting stuck (early convergence) and allowing the entire system to perform a long sequence of reasoning steps with a lean model architecture that doesn’t suffer from vanishing gradients. HRM (left) smoothly converges on the solution across computation cycles and avoids early convergence (center, RNNs) and vanishing gradients (right, classic deep neural networks) Source: arXiv According to the paper, “This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step.” This nested-loop design allows the model to reason deeply in its latent space without needing long CoT prompts or huge amounts of data. A natural question is whether this “latent reasoning” comes at the cost of interpretability. Guan Wang, Founder and CEO of Sapient Intelligence, pushes back on this idea, explaining that the model’s internal processes can be decoded and visualized, similar to how CoT provides a window into a model’s thinking. He also points out that CoT itself can be misleading. “CoT does not genuinely reflect a model’s internal reasoning,” Wang told VentureBeat, referencing studies showing that models can sometimes yield correct answers with incorrect reasoning steps, and vice versa. “It remains essentially a black box.” Example of how HRM reasons over a maze problem across different compute cycles Source: arXiv HRM in action To test their model, the researchers pitted HRM against benchmarks that require extensive search and backtracking, such as the Abstraction and Reasoning Corpus (ARC-AGI), extremely difficult Sudoku puzzles and complex maze-solving tasks. The results show that HRM learns to solve problems that are intractable for even advanced LLMs. For instance, on the “Sudoku-Extreme” and “Maze-Hard” benchmarks, state-of-the-art CoT models failed completely, scoring 0% accuracy. In contrast, HRM achieved near-perfect accuracy after being trained on just 1,000 examples for each task. On the ARC-AGI benchmark, a test of abstract reasoning and generalization, the 27M-parameter HRM scored 40.3%. This surpasses leading CoT-based models like the much larger o3-mini-high (34.5%) and Claude 3.7 Sonnet (21.2%). This performance, achieved without a large pre-training corpus and with very limited data, highlights the power and efficiency of its architecture. HRM outperforms large models on complex reasoning tasks Source: arXiv While solving puzzles demonstrates the model’s power, the real-world implications lie in a different class of problems. According to Wang, developers should continue using LLMs for language-based or creative tasks, but for “complex or deterministic tasks,” an HRM-like architecture offers superior performance with fewer hallucinations. He points to “sequential problems requiring complex decision-making or long-term planning,” especially in latency-sensitive fields like embodied AI and robotics, or data-scarce domains like scientific exploration.  In these scenarios, HRM doesn’t just solve problems; it learns to solve them better. “In our Sudoku experiments at the master level… HRM needs progressively fewer steps as training advances—akin to a novice becoming an expert,” Wang explained. For the enterprise, this is where the architecture’s efficiency translates directly to the bottom line. Instead of the serial, token-by-token generation of CoT, HRM’s parallel processing allows for what Wang estimates could be a “100x speedup in task completion time.” This means lower inference latency and the ability to run powerful reasoning on edge devices.  The cost savings are also substantial. “Specialized reasoning engines such as HRM offer a more promising alternative for specific complex reasoning tasks compared to large, costly, and latency-intensive API-based models,” Wang said. To put the efficiency into perspective, he noted that training the model for professional-level Sudoku takes roughly two GPU hours, and for the complex ARC-AGI benchmark, between 50 and 200 GPU hours—a fraction of the resources needed for massive foundation models. This opens a path to solving specialized business problems, from logistics optimization to complex system diagnostics, where both data and budget are finite. Looking ahead, Sapient Intelligence is already working to evolve HRM from a specialized problem-solver into a more general-purpose reasoning module. “We are actively developing brain-inspired models built upon HRM,” Wang said, highlighting promising initial results in healthcare, climate forecasting, and robotics. He teased that these next-generation models will differ significantly from today’s text-based systems, notably through the inclusion of self-correcting capabilities.  The work suggests that for a class of problems that have stumped today’s AI giants, the path forward may not be bigger models, but smarter, more structured architectures inspired by the ultimate reasoning engine: the human brain. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_a_human_brain_rendered_in_a_semi-transp_907d536c-6a14-4c28-8c81-3d144ea0de3e.webp?w=986?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-07-25T23:27:42+00:00\" datetime=\"2025-07-25T23:27:42+00:00\"\u003eJuly 25, 2025 4:27 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"421\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Vector_art_of_a_human_brain_rendered_in_a_semi-transp_907d536c-6a14-4c28-8c81-3d144ea0de3e.webp?w=750\" alt=\"Credit: VentureBeat made with Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\u003c/em\u003e \u003cem\u003e\u003ca href=\"https://venturebeat.com/newsletters/\"\u003eSubscribe Now\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eSingapore-based AI startup \u003ca href=\"https://www.sapient.inc/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSapient Intelligence\u003c/a\u003e has developed a new AI architecture that can match, and in some cases vastly outperform, large language models (LLMs) on complex reasoning tasks, all while being significantly smaller and more data-efficient.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe architecture, \u003cspan\u003eknown as the \u003ca href=\"http://github.com/sapientinc/HRM\" target=\"_blank\"\u003eHierarchical Reasoning Model\u003c/a\u003e (HRM), is inspired by how the human brain utilizes distinct\u003c/span\u003e systems for slow, deliberate planning and fast, intuitive computation. The model achieves impressive results with a fraction of the data and memory required by today’s LLMs. This efficiency could have important implications for real-world enterprise AI applications where data is scarce and computational resources are limited.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-limits-of-chain-of-thought-reasoning\"\u003eThe limits of chain-of-thought reasoning\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhen faced with a complex problem, current LLMs largely rely on \u003ca href=\"https://venturebeat.com/ai/dont-believe-reasoning-models-chains-of-thought-says-anthropic/\"\u003echain-of-thought\u003c/a\u003e (CoT) prompting, breaking down problems into intermediate text-based steps, essentially forcing the model to “think out loud” as it works toward a solution.\u003c/p\u003e\n\n\n\n\u003cp\u003eWhile CoT has improved the reasoning abilities of LLMs, it has fundamental limitations. In their \u003ca href=\"https://arxiv.org/abs/2506.21734\" target=\"_blank\" rel=\"noreferrer noopener\"\u003epaper\u003c/a\u003e, researchers at Sapient Intelligence argue that “CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely.”\u003c/p\u003e\n\n\n\n\u003cdiv id=\"boilerplate_2803147\"\u003e\n\u003chr/\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003eThe AI Impact Series Returns to San Francisco - August 5\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.\u003c/p\u003e\n\n\n\n\u003cp\u003eSecure your spot now - space is limited: \u003ca href=\"https://bit.ly/3GuuPLF\"\u003ehttps://bit.ly/3GuuPLF\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThis dependency on generating explicit language tethers the model’s reasoning to the token level, often requiring massive amounts of training data and producing long, slow responses. This approach also overlooks the type of “latent reasoning” that occurs internally, without being explicitly articulated in language.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs the researchers note, “A more efficient approach is needed to minimize these data requirements.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-hierarchical-approach-inspired-by-the-brain\"\u003eA hierarchical approach inspired by the brain\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo move beyond CoT, the researchers explored “latent reasoning,” where instead of generating “thinking tokens,” the model reasons in its internal, abstract representation of the problem. This is more aligned with how humans think; as the paper states, “the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language.”\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, achieving this level of deep, internal reasoning in AI is challenging. Simply stacking more layers in a deep learning model often leads to a “vanishing gradient” problem, where learning signals weaken across layers, making training ineffective. An alternative, recurrent architectures that loop over computations can suffer from “early convergence,” where the model settles on a solution too quickly without fully exploring the problem.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"778\" height=\"508\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png\" alt=\"hierarchical reasoning model\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png 778w, https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png?resize=300,196 300w, https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png?resize=768,501 768w, https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png?resize=400,261 400w, https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png?resize=750,490 750w, https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png?resize=578,377 578w\" sizes=\"(max-width: 778px) 100vw, 778px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eThe Hierarchical Reasoning Model (HRM) is inspired by the structure of the brain Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eSeeking a better approach, the Sapient team turned to neuroscience for a solution. “The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack,” the researchers write. “It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning.”\u003c/p\u003e\n\n\n\n\u003cp\u003eInspired by this, they designed HRM with two coupled, recurrent modules: a high-level (H) module for slow, abstract planning, and a low-level (L) module for fast, detailed computations. This structure enables a process the team calls “hierarchical convergence.” Intuitively, the fast L-module addresses a portion of the problem, executing multiple steps until it reaches a stable, local solution. At that point, the slow H-module takes this result, updates its overall strategy, and gives the L-module a new, refined sub-problem to work on. This effectively resets the L-module, preventing it from getting stuck (early convergence) and allowing the entire system to perform a long sequence of reasoning steps with a lean model architecture that doesn’t suffer from vanishing gradients.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" height=\"202\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png 1444w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=300,76 300w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=768,194 768w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=800,202 800w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=400,101 400w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=750,189 750w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=578,146 578w, https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?resize=930,234 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eHRM (left) smoothly converges on the solution across computation cycles and avoids early convergence (center, RNNs) and vanishing gradients (right, classic deep neural networks) Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eAccording to the paper, “This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step.” This nested-loop design allows the model to reason deeply in its latent space without needing long CoT prompts or huge amounts of data.\u003c/p\u003e\n\n\n\n\u003cp\u003eA natural question is whether this “latent reasoning” comes at the cost of interpretability. Guan Wang, Founder and CEO of Sapient Intelligence, pushes back on this idea, explaining that the model’s internal processes can be decoded and visualized, similar to how CoT provides a window into a model’s thinking. He also points out that CoT itself can be misleading. “CoT does not genuinely reflect a model’s internal reasoning,” Wang told VentureBeat, referencing studies showing that models can sometimes \u003ca href=\"https://venturebeat.com/ai/dont-believe-reasoning-models-chains-of-thought-says-anthropic/\"\u003eyield correct answers with incorrect reasoning steps\u003c/a\u003e, and vice versa. “It remains essentially a black box.”\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" height=\"130\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png 1596w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=300,49 300w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=768,125 768w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=800,130 800w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=1536,250 1536w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=400,65 400w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=750,122 750w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=578,94 578w, https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?resize=930,152 930w\" sizes=\"(max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eExample of how HRM reasons over a maze problem across different compute cycles Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-hrm-in-action\"\u003eHRM in action\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo test their model, the researchers pitted HRM against benchmarks that require extensive search and backtracking, such as the \u003ca href=\"https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning/\"\u003eAbstraction and Reasoning Corpus\u003c/a\u003e (ARC-AGI), extremely difficult Sudoku puzzles and complex maze-solving tasks.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe results show that HRM learns to solve problems that are intractable for even advanced LLMs. For instance, on the “Sudoku-Extreme” and “Maze-Hard” benchmarks, state-of-the-art CoT models failed completely, scoring 0% accuracy. In contrast, HRM achieved near-perfect accuracy after being trained on just 1,000 examples for each task.\u003c/p\u003e\n\n\n\n\u003cp\u003eOn the ARC-AGI benchmark, a test of abstract reasoning and generalization, the 27M-parameter HRM scored 40.3%. This surpasses leading CoT-based models like the much larger \u003ca href=\"https://venturebeat.com/ai/its-here-openais-o3-mini-advanced-reasoning-model-arrives-to-counter-deepseeks-rise/\"\u003eo3-mini-high\u003c/a\u003e (34.5%) and \u003ca href=\"https://venturebeat.com/ai/anthropics-claude-3-7-sonnet-takes-aim-at-openai-and-deepseek-in-ais-next-big-battle/\"\u003eClaude 3.7 Sonnet\u003c/a\u003e (21.2%). This performance, achieved without a large pre-training corpus and with very limited data, highlights the power and efficiency of its architecture.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg loading=\"lazy\" decoding=\"async\" height=\"310\" width=\"800\" src=\"https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png 1328w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=300,116 300w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=768,297 768w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=800,310 800w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=400,155 400w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=750,290 750w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=578,224 578w, https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?resize=930,360 930w\" sizes=\"auto, (max-width: 800px) 100vw, 800px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eHRM outperforms large models on complex reasoning tasks Source: arXiv\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eWhile solving puzzles demonstrates the model’s power, the real-world implications lie in a different class of problems. According to Wang, developers should continue using LLMs for language-based or creative tasks, but for “complex or deterministic tasks,” an HRM-like architecture offers superior performance with fewer hallucinations. He points to “sequential problems requiring complex decision-making or long-term planning,” especially in latency-sensitive fields like embodied AI and robotics, or data-scarce domains like scientific exploration. \u003c/p\u003e\n\n\n\n\u003cp\u003eIn these scenarios, HRM doesn’t just solve problems; it learns to solve them better. “In our Sudoku experiments at the master level… HRM needs progressively fewer steps as training advances—akin to a novice becoming an expert,” Wang explained.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor the enterprise, this is where the architecture’s efficiency translates directly to the bottom line. Instead of the serial, token-by-token generation of CoT, HRM’s parallel processing allows for what Wang estimates could be a “100x speedup in task completion time.” This means lower inference latency and the ability to run powerful reasoning on edge devices. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe cost savings are also substantial. “Specialized reasoning engines such as HRM offer a more promising alternative for specific complex reasoning tasks compared to large, costly, and latency-intensive API-based models,” Wang said. To put the efficiency into perspective, he noted that training the model for professional-level Sudoku takes roughly two GPU hours, and for the complex ARC-AGI benchmark, between 50 and 200 GPU hours—a fraction of the resources needed for massive foundation models. This opens a path to solving specialized business problems, from logistics optimization to complex system diagnostics, where both data and budget are finite.\u003c/p\u003e\n\n\n\n\u003cp\u003eLooking ahead, Sapient Intelligence is already working to evolve HRM from a specialized problem-solver into a more general-purpose reasoning module. “We are actively developing brain-inspired models built upon HRM,” Wang said, highlighting promising initial results in healthcare, climate forecasting, and robotics. He teased that these next-generation models will differ significantly from today’s text-based systems, notably through the inclusion of self-correcting capabilities. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe work suggests that for a class of problems that have stumped today’s AI giants, the path forward may not be bigger models, but smarter, more structured architectures inspired by the ultimate reasoning engine: the human brain.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-07-25T23:27:42Z",
  "modifiedTime": "2025-07-25T23:27:49Z"
}
