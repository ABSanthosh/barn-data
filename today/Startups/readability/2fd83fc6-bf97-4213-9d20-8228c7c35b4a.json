{
  "id": "2fd83fc6-bf97-4213-9d20-8228c7c35b4a",
  "title": "Why agents are bad pair programmers",
  "link": "https://justin.searls.co/posts/why-agents-are-bad-pair-programmers/",
  "description": "Article URL: https://justin.searls.co/posts/why-agents-are-bad-pair-programmers/ Comments URL: https://news.ycombinator.com/item?id=44230838 Points: 16 # Comments: 5",
  "author": "sh_tomer",
  "published": "Mon, 09 Jun 2025 23:36:23 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "Justin Searls",
  "length": 4961,
  "excerpt": "LLM agents make bad pairs because they code faster than humans think. I'll admit, I've had a lot of fun using GitHub Copilot's agent mode in VS Code this month.…",
  "siteName": "justin․searls․co",
  "favicon": "https://justin.searls.co/img/logo.png",
  "text": "Friday, May 30, 2025 LLM agents make bad pairs because they code faster than humans think. I'll admit, I've had a lot of fun using GitHub Copilot's agent mode in VS Code this month. It's invigorating to watch it effortlessly write a working method on the first try. It's a relief when the agent unblocks me by reaching for a framework API I didn't even know existed. It's motivating to pair with someone even more tirelessly committed to my goal than I am. In fact, pairing with top LLMs evokes many memories of pairing with top human programmers. The worst memories. Memories of my pair grabbing the keyboard and—in total and unhelpful silence—hammering out code faster than I could ever hope to read it. Memories of slowly, inevitably becoming disengaged after expending all my mental energy in a futile attempt to keep up. Memories of my pair hitting a roadblock and finally looking to me for help, only to catch me off guard and without a clue as to what had been going on in the preceding minutes, hours, or days. Memories of gradually realizing my pair had been building the wrong thing all along and then suddenly realizing the task now fell to me to remediate a boatload of incidental complexity in order to hit a deadline. So yes, pairing with an AI agent can be uncannily similar to pairing with an expert programmer. The path forward What should we do instead? Two things: The same thing I did with human pair programmers who wanted to take the ball and run with it: I let them have it. In a perfect world, pairing might lead to a better solution, but there's no point in forcing it when both parties aren't bought in. Instead, I'd break the work down into discrete sub-components for my colleague to build independently. I would then review those pieces as pull requests. Translating that advice to LLM-based tools: give up on editor-based agentic pairing in favor of asynchronous workflows like GitHub's new Coding Agent, whose work you can also review via pull request Continue to practice pair-programming with your editor, but throttle down from the semi-autonomous \"Agent\" mode to the turn-based \"Edit\" or \"Ask\" modes. You'll go slower, and that's the point. Also, just like pairing with humans, try to establish a rigorously consistent workflow as opposed to only reaching for AI to troubleshoot. I've found that ping-pong pairing with an AI in Edit mode (where the LLM can propose individual edits but you must manually accept them) strikes the best balance between accelerated productivity and continuous quality control Give people a few more months with agents and I think (hope) others will arrive at similar conclusions about their suitability as pair programmers. My advice to the AI tool-makers would be to introduce features to make pairing with an AI agent more qualitatively similar to pairing with a human. Agentic pair programmers are not inherently bad, but their lightning-fast speed has the unintended consequence of undercutting any opportunity for collaborating with us mere mortals. If an agent were designed to type at a slower pace, pause and discuss periodically, and frankly expect more of us as equal partners, that could make for a hell of a product offering. Just imagining it now, any of these features would make agent-based pairing much more effective: Let users set how many lines-per-minute of code—or words-per-minute of prose—the agent outputs Allow users to pause the agent to ask a clarifying question or push back on its direction without derailing the entire activity or train of thought Expand beyond the chat metaphor by adding UI primitives that mirror the work to be done. Enable users to pin the current working session to a particular GitHub issue. Integrate a built-in to-do list to tick off before the feature is complete. That sort of thing Design agents to act with less self-confidence and more self-doubt. They should frequently stop to converse: validate why we're building this, solicit advice on the best approach, and express concern when we're going in the wrong direction Introduce advanced voice chat to better emulate human-to-human pairing, which would allow the user both to keep their eyes on the code (instead of darting back and forth between an editor and a chat sidebar) and to light up the parts of the brain that find mouth-words more engaging than text Anyway, that's how I see it from where I'm sitting the morning of Friday, May 30th, 2025. Who knows where these tools will be in a week or month or year, but I'm fairly confident you could find worse advice on meeting this moment. As always, if you have thoughts, e-mail 'em. Got a taste for hot, fresh takes? Then you're in luck, because you can subscribe to this site via RSS or Mastodon! And if that ain't enough, then sign up for my newsletter and I'll send you a usually-pretty-good essay once a month. I also have a solo podcast, because of course I do.",
  "image": "https://justin.searls.co/img/social/posts/why-agents-are-bad-pair-programmers.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"main\"\u003e\n  \u003carticle data-pagefind-body=\"\"\u003e\n    \u003ctime pubdate=\"\" datetime=\"2025-05-30\" data-pagefind-meta=\"date:2025-05-30\" data-pagefind-sort=\"date:2025-05-30\"\u003e\n      Friday, May 30, 2025\n    \u003c/time\u003e\n    \u003ca href=\"https://justin.searls.co/posts/why-agents-are-bad-pair-programmers/\"\u003e\n      \n    \u003c/a\u003e\n\n    \u003cp\u003eLLM agents make bad pairs because \u003cstrong\u003ethey code faster than humans think\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eI\u0026#39;ll admit, I\u0026#39;ve had a lot of fun \u003ca href=\"https://justin.searls.co/tubes/2025-04-19-17h46m37s/\"\u003eusing GitHub Copilot\u0026#39;s agent mode in VS Code\u003c/a\u003e this month. It\u0026#39;s invigorating to watch it effortlessly write a working method on the first try. It\u0026#39;s a relief when the agent unblocks me by reaching for a framework API I didn\u0026#39;t even know existed. It\u0026#39;s motivating to pair with someone even more tirelessly committed to my goal than I am.\u003c/p\u003e\n\u003cp\u003eIn fact, pairing with top LLMs evokes many memories of pairing with top human programmers.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eThe worst memories.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eMemories of my pair grabbing the keyboard and—in total and unhelpful silence—hammering out code faster than I could ever hope to read it. Memories of slowly, inevitably becoming disengaged after expending all my mental energy in a futile attempt to keep up. Memories of my pair hitting a roadblock and finally looking to me for help, only to catch me off guard and without a clue as to what had been going on in the preceding minutes, hours, or days. Memories of gradually realizing my pair had been building the \u003cem\u003ewrong thing all along\u003c/em\u003e and then suddenly realizing the task now fell to me to remediate a boatload of incidental complexity in order to hit a deadline.\u003c/p\u003e\n\u003cp\u003eSo yes, pairing with an AI agent can be uncannily similar to pairing with an expert programmer.\u003c/p\u003e\n\n\u003ch2 id=\"the-path-forward\"\u003e\n    \u003ca href=\"#the-path-forward\"\u003eThe path forward\u003c/a\u003e\n\u003c/h2\u003e\n\u003cp\u003eWhat should we do instead? Two things:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe same thing I did with human pair programmers who wanted to take the ball and run with it: I let them have it. In a perfect world, pairing might lead to a better solution, but there\u0026#39;s no point in forcing it when both parties aren\u0026#39;t bought in. Instead, I\u0026#39;d break the work down into discrete sub-components for my colleague to build independently. I would then review those pieces as pull requests. Translating that advice to LLM-based tools: \u003cstrong\u003egive up on editor-based agentic pairing in favor of asynchronous workflows like GitHub\u0026#39;s new \u003ca href=\"https://github.blog/news-insights/product-news/github-copilot-meet-the-new-coding-agent/\"\u003eCoding Agent\u003c/a\u003e\u003c/strong\u003e, whose work you can \u003cem\u003ealso\u003c/em\u003e review via pull request\u003c/li\u003e\n\u003cli\u003eContinue to practice pair-programming with your editor, but \u003cstrong\u003ethrottle down from the semi-autonomous \u0026#34;Agent\u0026#34; mode to the turn-based \u0026#34;Edit\u0026#34; or \u0026#34;Ask\u0026#34; modes\u003c/strong\u003e. You\u0026#39;ll go slower, and \u003cem\u003ethat\u0026#39;s the point\u003c/em\u003e. Also, just like pairing with humans, try to establish a rigorously consistent workflow as opposed to only reaching for AI to troubleshoot. I\u0026#39;ve found that \u003ca href=\"https://martinfowler.com/articles/on-pair-programming.html#PingPong\"\u003eping-pong pairing\u003c/a\u003e with an AI in Edit mode (where the LLM can propose individual edits but you must manually accept them) strikes the best balance between accelerated productivity and continuous quality control\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eGive people a few more months with agents and I think (hope) others will arrive at similar conclusions about their suitability as pair programmers. My advice to the AI tool-makers would be to introduce features to make pairing with an AI agent more qualitatively similar to pairing with a human. Agentic pair programmers are not inherently bad, but their lightning-fast speed has the unintended consequence of undercutting any opportunity for collaborating with us mere mortals. If an agent were designed to type at a slower pace, pause and discuss periodically, and frankly expect more of us as equal partners, that could make for a hell of a product offering.\u003c/p\u003e\n\u003cp\u003eJust imagining it now, any of these features would make agent-based pairing much more effective:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLet users set how many lines-per-minute of code—or words-per-minute of prose—the agent outputs\u003c/li\u003e\n\u003cli\u003eAllow users to pause the agent to ask a clarifying question or push back on its direction without derailing the entire activity or train of thought\u003c/li\u003e\n\u003cli\u003eExpand beyond the chat metaphor by adding UI primitives that mirror the work to be done. Enable users to pin the current working session to a particular GitHub issue. Integrate a built-in to-do list to tick off before the feature is complete. That sort of thing\u003c/li\u003e\n\u003cli\u003eDesign agents to act with less self-confidence and more self-doubt. They should frequently stop to converse: validate \u003cem\u003ewhy\u003c/em\u003e we\u0026#39;re building this, solicit advice on the best approach, and express concern when we\u0026#39;re going in the wrong direction\u003c/li\u003e\n\u003cli\u003eIntroduce advanced voice chat to better emulate human-to-human pairing, which would allow the user both to keep their eyes on the code (instead of darting back and forth between an editor and a chat sidebar) and to light up the parts of the brain that find mouth-words more engaging than text\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnyway, that\u0026#39;s how I see it from where I\u0026#39;m sitting the morning of Friday, May 30th, 2025. Who knows where these tools will be in a week or month or year, but I\u0026#39;m fairly confident you could find worse advice on meeting this moment.\u003c/p\u003e\n\u003cp\u003eAs always, if you have thoughts, \u003ca href=\"mailto:justin@searls.co\"\u003ee-mail \u0026#39;em\u003c/a\u003e.\u003c/p\u003e\n  \u003c/article\u003e\n  \u003cdiv\u003e\n  \u003chr/\u003e\n  \u003ch2\u003eGot a taste for hot, fresh takes?\u003c/h2\u003e\n  \u003cp\u003e\n    Then you\u0026#39;re in luck, because you can subscribe to this site via \u003ca href=\"https://justin.searls.co/rss\"\u003eRSS\u003c/a\u003e or \u003ca href=\"https://mastodon.social/@searls\"\u003eMastodon\u003c/a\u003e!\n    And if that ain\u0026#39;t enough, then sign up for my \u003ca href=\"https://justin.searls.co/newsletter\"\u003enewsletter\u003c/a\u003e and I\u0026#39;ll send you a usually-pretty-good essay once a month.\n    I also have a solo \u003ca href=\"https://justin.searls.co/casts\"\u003epodcast\u003c/a\u003e, because of course I do.\n  \u003c/p\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": null,
  "modifiedTime": null
}
