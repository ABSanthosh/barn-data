{
  "id": "00bd6138-7d7c-4ac2-b9bc-8d56f2988e28",
  "title": "From hallucinations to hardware: Lessons from a real-world computer vision project gone sideways",
  "link": "https://venturebeat.com/ai/from-hallucinations-to-hardware-lessons-from-a-real-world-computer-vision-project-gone-sideways/",
  "description": "What we tried, what didn't work and how a combination of approaches eventually helped us build a reliable computer vision model.",
  "author": "Shruti Tiwari, Dell Technologies",
  "published": "Sat, 28 Jun 2025 19:05:00 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "DataDecisionMakers",
    "AI, ML and Deep Learning",
    "computer vision",
    "Data Labelling",
    "Generative AI",
    "large language models",
    "NLP"
  ],
  "byline": "Shruti Tiwari, Dell Technologies",
  "length": 8519,
  "excerpt": "What we tried, what didn't work and how a combination of approaches eventually helped us build a reliable computer vision model.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. Learn more Computer vision projects rarely go exactly as planned, and this one was no exception. The idea was simple: Build a model that could look at a photo of a laptop and identify any physical damage — things like cracked screens, missing keys or broken hinges. It seemed like a straightforward use case for image models and large language models (LLMs), but it quickly turned into something more complicated. Along the way, we ran into issues with hallucinations, unreliable outputs and images that were not even laptops. To solve these, we ended up applying an agentic framework in an atypical way — not for task automation, but to improve the model’s performance. In this post, we will walk through what we tried, what didn’t work and how a combination of approaches eventually helped us build something reliable. Where we started: Monolithic prompting Our initial approach was fairly standard for a multimodal model. We used a single, large prompt to pass an image into an image-capable LLM and asked it to identify visible damage. This monolithic prompting strategy is simple to implement and works decently for clean, well-defined tasks. But real-world data rarely plays along. We ran into three major issues early on: Hallucinations: The model would sometimes invent damage that did not exist or mislabel what it was seeing. Junk image detection: It had no reliable way to flag images that were not even laptops, like pictures of desks, walls or people occasionally slipped through and received nonsensical damage reports. Inconsistent accuracy: The combination of these problems made the model too unreliable for operational use. This was the point when it became clear we would need to iterate. First fix: Mixing image resolutions One thing we noticed was how much image quality affected the model’s output. Users uploaded all kinds of images ranging from sharp and high-resolution to blurry. This led us to refer to research highlighting how image resolution impacts deep learning models. We trained and tested the model using a mix of high-and low-resolution images. The idea was to make the model more resilient to the wide range of image qualities it would encounter in practice. This helped improve consistency, but the core issues of hallucination and junk image handling persisted. The multimodal detour: Text-only LLM goes multimodal Encouraged by recent experiments in combining image captioning with text-only LLMs — like the technique covered in The Batch, where captions are generated from images and then interpreted by a language model, we decided to give it a try. Here’s how it works: The LLM begins by generating multiple possible captions for an image.  Another model, called a multimodal embedding model, checks how well each caption fits the image. In this case, we used SigLIP to score the similarity between the image and the text. The system keeps the top few captions based on these scores. The LLM uses those top captions to write new ones, trying to get closer to what the image actually shows. It repeats this process until the captions stop improving, or it hits a set limit. While clever in theory, this approach introduced new problems for our use case: Persistent hallucinations: The captions themselves sometimes included imaginary damage, which the LLM then confidently reported. Incomplete coverage: Even with multiple captions, some issues were missed entirely. Increased complexity, little benefit: The added steps made the system more complicated without reliably outperforming the previous setup. It was an interesting experiment, but ultimately not a solution. A creative use of agentic frameworks This was the turning point. While agentic frameworks are usually used for orchestrating task flows (think agents coordinating calendar invites or customer service actions), we wondered if breaking down the image interpretation task into smaller, specialized agents might help. We built an agentic framework structured like this: Orchestrator agent: It checked the image and identified which laptop components were visible (screen, keyboard, chassis, ports). Component agents: Dedicated agents inspected each component for specific damage types; for example, one for cracked screens, another for missing keys. Junk detection agent: A separate agent flagged whether the image was even a laptop in the first place. This modular, task-driven approach produced much more precise and explainable results. Hallucinations dropped dramatically, junk images were reliably flagged and each agent’s task was simple and focused enough to control quality well. The blind spots: Trade-offs of an agentic approach As effective as this was, it was not perfect. Two main limitations showed up: Increased latency: Running multiple sequential agents added to the total inference time. Coverage gaps: Agents could only detect issues they were explicitly programmed to look for. If an image showed something unexpected that no agent was tasked with identifying, it would go unnoticed. We needed a way to balance precision with coverage. The hybrid solution: Combining agentic and monolithic approaches To bridge the gaps, we created a hybrid system: The agentic framework ran first, handling precise detection of known damage types and junk images. We limited the number of agents to the most essential ones to improve latency. Then, a monolithic image LLM prompt scanned the image for anything else the agents might have missed. Finally, we fine-tuned the model using a curated set of images for high-priority use cases, like frequently reported damage scenarios, to further improve accuracy and reliability. This combination gave us the precision and explainability of the agentic setup, the broad coverage of monolithic prompting and the confidence boost of targeted fine-tuning. What we learned A few things became clear by the time we wrapped up this project: Agentic frameworks are more versatile than they get credit for: While they are usually associated with workflow management, we found they could meaningfully boost model performance when applied in a structured, modular way. Blending different approaches beats relying on just one: The combination of precise, agent-based detection alongside the broad coverage of LLMs, plus a bit of fine-tuning where it mattered most, gave us far more reliable outcomes than any single method on its own. Visual models are prone to hallucinations: Even the more advanced setups can jump to conclusions or see things that are not there. It takes a thoughtful system design to keep those mistakes in check. Image quality variety makes a difference: Training and testing with both clear, high-resolution images and everyday, lower-quality ones helped the model stay resilient when faced with unpredictable, real-world photos. You need a way to catch junk images: A dedicated check for junk or unrelated pictures was one of the simplest changes we made, and it had an outsized impact on overall system reliability. Final thoughts What started as a simple idea, using an LLM prompt to detect physical damage in laptop images, quickly turned into a much deeper experiment in combining different AI techniques to tackle unpredictable, real-world problems. Along the way, we realized that some of the most useful tools were ones not originally designed for this type of work. Agentic frameworks, often seen as workflow utilities, proved surprisingly effective when repurposed for tasks like structured damage detection and image filtering. With a bit of creativity, they helped us build a system that was not just more accurate, but easier to understand and manage in practice. Shruti Tiwari is an AI product manager at Dell Technologies. Vadiraj Kulkarni is a data scientist at Dell Technologies. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/06/Computer.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy. \u003ca href=\"http://vbtransform.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLearn more\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eComputer vision projects rarely go exactly as planned, and this one was no exception. The idea was simple: Build a model that could look at a photo of a laptop and identify any physical damage — things like cracked screens, missing keys or broken hinges. It seemed like a straightforward use case for image models and \u003ca href=\"https://venturebeat.com/ai/from-fear-to-fluency-why-empathy-is-the-missing-ingredient-in-ai-rollouts/\"\u003elarge language model\u003c/a\u003es (LLMs), but it quickly turned into something more complicated.\u003c/p\u003e\n\n\n\n\u003cp\u003eAlong the way, we ran into issues with hallucinations, unreliable outputs and images that were not even laptops. To solve these, we ended up applying an agentic framework in an atypical way — not for task automation, but to improve the model’s performance.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn this post, we will walk through what we tried, what didn’t work and how a combination of approaches eventually helped us build something reliable.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-where-we-started-monolithic-prompting\"\u003eWhere we started: Monolithic prompting\u003c/h2\u003e\n\n\n\n\u003cp\u003eOur initial approach was fairly standard for a multimodal model. We used a single, large prompt to pass an image into an \u003ca href=\"https://venturebeat.com/ai/rethinking-ai-deepseeks-playbook-shakes-up-the-high-spend-high-compute-paradigm/\"\u003eimage-capable LLM\u003c/a\u003e and asked it to identify visible damage. This monolithic prompting strategy is simple to implement and works decently for clean, well-defined tasks. But real-world data rarely plays along.\u003c/p\u003e\n\n\n\n\u003cp\u003eWe ran into three major issues early on:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHallucinations\u003c/strong\u003e: The model would sometimes invent damage that did not exist or mislabel what it was seeing.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eJunk image detection\u003c/strong\u003e: It had no reliable way to flag images that were not even laptops, like pictures of desks, walls or people occasionally slipped through and received nonsensical damage reports.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eInconsistent accuracy\u003c/strong\u003e: The combination of these problems made the model too unreliable for operational use.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThis was the point when it became clear we would need to iterate.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-first-fix-mixing-image-resolutions\"\u003eFirst fix: Mixing image resolutions\u003c/h2\u003e\n\n\n\n\u003cp\u003eOne thing we noticed was how much image quality affected the model’s output. Users uploaded all kinds of images ranging from sharp and high-resolution to blurry. This led us to refer to \u003ca href=\"https://arxiv.org/abs/1604.04004\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eresearch\u003c/a\u003e highlighting how image resolution impacts deep learning models.\u003c/p\u003e\n\n\n\n\u003cp\u003eWe trained and tested the model using a mix of high-and low-resolution images. The idea was to make the model more resilient to the wide range of image qualities it would encounter in practice. This helped improve consistency, but the core issues of hallucination and junk image handling persisted.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-multimodal-detour-text-only-llm-goes-multimodal\"\u003eThe multimodal detour: Text-only LLM goes multimodal\u003c/h2\u003e\n\n\n\n\u003cp\u003eEncouraged by recent experiments in combining image captioning with text-only LLMs — like the technique covered in \u003cem\u003e\u003ca href=\"https://www.deeplearning.ai/the-batch/issue-298/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eThe Batch\u003c/a\u003e\u003c/em\u003e, where captions are generated from images and then interpreted by a language model, we decided to give it a try.\u003c/p\u003e\n\n\n\n\u003cp\u003eHere’s how it works:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eThe LLM begins by generating multiple possible captions for an image. \u003c/li\u003e\n\n\n\n\u003cli\u003eAnother model, called a multimodal embedding model, checks how well each caption fits the image. In this case, we used SigLIP to score the similarity between the image and the text.\u003c/li\u003e\n\n\n\n\u003cli\u003eThe system keeps the top few captions based on these scores.\u003c/li\u003e\n\n\n\n\u003cli\u003eThe LLM uses those top captions to write new ones, trying to get closer to what the image actually shows.\u003c/li\u003e\n\n\n\n\u003cli\u003eIt repeats this process until the captions stop improving, or it hits a set limit.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eWhile clever in theory, this approach introduced new problems for our use case:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePersistent hallucinations\u003c/strong\u003e: The captions themselves sometimes included imaginary damage, which the LLM then confidently reported.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eIncomplete coverage\u003c/strong\u003e: Even with multiple captions, some issues were missed entirely.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eIncreased complexity, little benefit\u003c/strong\u003e: The added steps made the system more complicated without reliably outperforming the previous setup.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eIt was an interesting experiment, but ultimately not a solution.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-creative-use-of-agentic-frameworks\"\u003eA creative use of agentic frameworks\u003c/h2\u003e\n\n\n\n\u003cp\u003eThis was the turning point. While agentic frameworks are usually used for orchestrating task flows (think agents coordinating calendar invites or customer service actions), we wondered if breaking down the image interpretation task into smaller, \u003ca href=\"https://venturebeat.com/ai/agent-based-computing-is-outgrowing-the-web-as-we-know-it/\"\u003especialized agents\u003c/a\u003e might help.\u003c/p\u003e\n\n\n\n\u003cp\u003eWe built an agentic framework structured like this:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOrchestrator agent\u003c/strong\u003e: It checked the image and identified which laptop components were visible (screen, keyboard, chassis, ports).\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eComponent agents\u003c/strong\u003e: Dedicated agents inspected each component for specific damage types; for example, one for cracked screens, another for missing keys.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eJunk detection agent\u003c/strong\u003e: A separate agent flagged whether the image was even a laptop in the first place.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThis modular, task-driven approach produced much more precise and explainable results. Hallucinations dropped dramatically, junk images were reliably flagged and each agent’s task was simple and focused enough to control quality well.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-blind-spots-trade-offs-of-an-agentic-approach\"\u003eThe blind spots: Trade-offs of an agentic approach\u003c/h2\u003e\n\n\n\n\u003cp\u003eAs effective as this was, it was not perfect. Two main limitations showed up:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eIncreased latency\u003c/strong\u003e: Running multiple sequential agents added to the total inference time.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eCoverage gaps\u003c/strong\u003e: Agents could only detect issues they were explicitly programmed to look for. If an image showed something unexpected that no agent was tasked with identifying, it would go unnoticed.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eWe needed a way to balance precision with coverage.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-hybrid-solution-combining-agentic-and-monolithic-approaches\"\u003eThe hybrid solution: Combining agentic and monolithic approaches\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo bridge the gaps, we created a hybrid system:\u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003eThe \u003cstrong\u003eagentic framework\u003c/strong\u003e ran first, handling precise detection of known damage types and junk images. We limited the number of agents to the most essential ones to improve latency.\u003c/li\u003e\n\n\n\n\u003cli\u003eThen, a \u003cstrong\u003emonolithic image LLM prompt\u003c/strong\u003e scanned the image for anything else the agents might have missed.\u003c/li\u003e\n\n\n\n\u003cli\u003eFinally, we \u003cstrong\u003efine-tuned the model\u003c/strong\u003e using a curated set of images for high-priority use cases, like frequently reported damage scenarios, to further improve accuracy and reliability.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eThis combination gave us the precision and explainability of the agentic setup, the broad coverage of monolithic prompting and the confidence boost of targeted fine-tuning.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-we-learned\"\u003eWhat we learned\u003c/h2\u003e\n\n\n\n\u003cp\u003eA few things became clear by the time we wrapped up this project:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAgentic frameworks are more versatile than they get credit for\u003c/strong\u003e: While they are usually associated with workflow management, we found they could meaningfully boost model performance when applied in a structured, modular way.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eBlending different approaches beats relying on just one\u003c/strong\u003e: The combination of precise, agent-based detection alongside the broad coverage of LLMs, plus a bit of fine-tuning where it mattered most, gave us far more reliable outcomes than any single method on its own.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eVisual models are prone to hallucinations\u003c/strong\u003e: Even the more advanced setups can jump to conclusions or see things that are not there. It takes a thoughtful system design to keep those mistakes in check.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eImage quality variety makes a difference\u003c/strong\u003e: Training and testing with both clear, high-resolution images and everyday, lower-quality ones helped the model stay resilient when faced with unpredictable, real-world photos.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eYou need a way to catch junk images\u003c/strong\u003e: A dedicated check for junk or unrelated pictures was one of the simplest changes we made, and it had an outsized impact on overall system reliability.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2 id=\"h-final-thoughts\"\u003eFinal thoughts\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhat started as a simple idea, using an LLM prompt to detect physical damage in laptop images, quickly turned into a much deeper experiment in combining different AI techniques to tackle unpredictable, real-world problems. Along the way, we realized that some of the most useful tools were ones not originally designed for this type of work.\u003c/p\u003e\n\n\n\n\u003cp\u003eAgentic frameworks, often seen as workflow utilities, proved surprisingly effective when repurposed for tasks like structured damage detection and image filtering. With a bit of creativity, they helped us build a system that was not just more accurate, but easier to understand and manage in practice.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eShruti Tiwari is an AI product manager at Dell Technologies.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eVadiraj Kulkarni is a data scientist at Dell Technologies.\u003c/em\u003e\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "9 min read",
  "publishedTime": "2025-06-28T19:05:00Z",
  "modifiedTime": "2025-06-28T18:28:47Z"
}
