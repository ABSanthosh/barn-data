{
  "id": "5716e718-1c13-45be-80e8-4a94589862ef",
  "title": "Luma AI releases Ray2 generative video model with ‘fast, natural’ motion and better physics",
  "link": "https://venturebeat.com/ai/luma-ai-releases-ray2-generative-video-model-with-fast-natural-motion-and-better-physics/",
  "description": "Impressively, all the motions in the example videos appear lifelike and fluid — with subjects moving much faster and more naturally.",
  "author": "Carl Franzen",
  "published": "Thu, 16 Jan 2025 00:22:39 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI video",
    "ai video generation",
    "ai video generator",
    "AI, ML and Deep Learning",
    "Conversational AI",
    "Luma AI",
    "NLP",
    "ray2",
    "video AI"
  ],
  "byline": "Carl Franzen",
  "length": 4673,
  "excerpt": "Impressively, all the motions in the example videos appear lifelike and fluid — with subjects moving much faster and more naturally.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "January 15, 2025 4:22 PM Credit: @JeffSynthesized/X Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Luma AI made waves with the launch of its Dream Machine generative AI video creation platform last summer. Of course, while that was only seven short months ago, the AI video space has advanced rapidly with the release of many new AI video creation models from rival startups in the U.S. and China, including Runway, Kling, Pika 2.0, OpenAI’s Sora, Google’s Veo 2, MiniMax’s Hailuo and open source alternatives such as Hotshot and Genmo’s Mochi 1, to name but a few. Even Luma itself recently updated its Dream Machine platform to include new still image generation and brainstorming boards, and also debuted an iOS app. But the updates continue: Today, the San Francisco-based startup released Ray2, its newest video AI generation model, available now through its Dream Machine website and mobile apps for paying subscribers (to start). The model offers “fast, natural coherent motion and physics,” according co-founder and CEO Amit Jain says on his X account, and was trained with 10 times more compute than the original Luma AI video model, Ray1. “This skyrockets the success rate of usable production-ready generations and makes video storytelling accessible to a lot more people,” he added. Luma’s Dream Machine web platform offers a free tier with 720 pixel generations capped at a variable number each month: Paid plans begin at $6.99 per month: From “Lite,” which offers 1080p visuals, to Plus ($20.99/month), to Unlimited ($66.49/month) and Enterprise ($1,672.92/year). A leap forward in video gen Right now, Ray2 is limited to tex-to-video, allowing users to type in descriptions that are transformed into 5 or 10 second video clips. The model can generate new videos in a matter of seconds, although right now it can take minutes at a time due to a crush of demand from new users. Examples shared by Luma and early testers in its Creators program showcase the model’s versatility, including a man running through an Antarctic snowstorm surrounded by explosions, and a ballerina performing on an ice floe in the Arctic. Impressively, all the motions in the example videos appear lifelike and fluid — and often, with subjects moving much faster and more naturally than videos from rival AI generators, which often appear to generate in slow motion. The model can even create realistic versions of surreal ideas such as a giraffe surfing, as X user @JeffSynthesized demonstrated. “Ray 2 is the real deal,” he wrote on X. Other AI video creators who have tried the new model seem to largely agree, with Jerrod Lew posting on X: “Improved cinematography, lighting and realism has arrived and it’s awesome.” “…it’s so good!” AI video artist Heather Cooper chimed in. My own tests were a mixed bag, with some more complex prompts creating unnatural and glitchy results. But when it did produce clips that resembled more of what I had in mind in my prompts — such as fencers crossing swords aboard a space station orbiting Jupiter — it was undeniably impressive. Jain said Luma will also add image-to-video, video-to-video and editing capabilities to Ray2 in the future, further expanding the tool’s creative possibilities. To celebrate the launch of Ray2, Luma Labs is hosting the Ray2 Awards, offering creators the chance to win up to $7,000 in prizes. These include: A large scale award: The creator whose Ray2 content garners the most views on a single platform during the first week of launch will win $5,000. Submissions are due by January 22, 2025. A raffle for $3,000: Creators can enter by sharing Ray2 content on social media and engaging with Luma AI’s launch video. The deadline for participation is also January 22. Winners of both awards will be announced on January 27. Submissions can be uploaded via forms provided by Luma Labs, and creators are encouraged to use hashtags #Ray2 and #DreamMachine when sharing their work. Additionally, Luma Labs has launched an affiliate program, allowing participants to earn commissions by promoting its tools. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/01/giraffe-surfing.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-01-16T00:22:39+00:00\" datetime=\"2025-01-16T00:22:39+00:00\"\u003eJanuary 15, 2025 4:22 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"225\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/giraffe-surfing.png?w=400\" alt=\"Screenshot of AI video of surfing giraffe\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: @JeffSynthesized/X\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eLuma AI made waves with the launch of its \u003ca href=\"https://venturebeat.com/ai/luma-ai-debuts-dream-machine-for-realistic-video-generation-heating-up-ai-media-race/\"\u003eDream Machine\u003c/a\u003e generative AI video creation platform last summer.\u003c/p\u003e\n\n\n\n\u003cp\u003eOf course, while that was only seven short months ago, the AI video space has advanced rapidly with the release of many new AI video creation models from rival startups in the U.S. and China, including \u003ca href=\"https://venturebeat.com/ai/this-is-a-game-changer-runway-releases-new-ai-facial-expression-motion-capture-feature-act-one/\"\u003eRunway\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/what-you-need-to-know-about-kling-the-ai-video-generator-rival-to-sora-thats-wowing-creators/\"\u003eKling\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/pika-2-0-launches-in-wake-of-sora-integrating-your-own-characters-objects-scenes-in-new-ai-videos/\"\u003ePika 2.0\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/open-ai-sora-launches/\"\u003eOpenAI’s Sora\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/google-debuts-new-ai-video-generator-veo-2-claiming-better-audience-scores-than-sora/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGoogle’s Veo 2\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/hailuo-gets-feature-competitive-launching-image-to-video-ai-generation-capability/\"\u003eMiniMax’s Hailuo\u003c/a\u003e and open source alternatives such as \u003ca href=\"https://venturebeat.com/ai/hotshot-launches-new-text-to-video-ai-generator/\"\u003eHotshot\u003c/a\u003e and \u003ca href=\"https://venturebeat.com/ai/video-ai-startup-genmo-launches-mochi-1-an-open-source-model-to-rival-runway-kling-and-others/\"\u003eGenmo’s Mochi 1\u003c/a\u003e, to name but a few. Even Luma itself recently updated its \u003ca href=\"https://venturebeat.com/ai/luma-expands-dream-machine-ai-video-model-into-full-creative-platform-mobile-app/\"\u003eDream Machine platform\u003c/a\u003e to include new still image generation and brainstorming boards, and also debuted an iOS app.\u003c/p\u003e\n\n\n\n\u003cp\u003eBut the updates continue: Today, the San Francisco-based startup released \u003ca href=\"https://lumalabs.ai/ray\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRay2,\u003c/a\u003e its newest video AI generation model, available now through its Dream Machine website and mobile apps for paying subscribers (to start).\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model offers “fast, natural coherent motion and physics,” according co-founder and CEO \u003ca href=\"https://x.com/gravicle/status/1879599488018571394\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAmit Jain says on his X account\u003c/a\u003e, and was trained with 10 times more compute than the original Luma AI video model, Ray1.\u003c/p\u003e\n\n\n\n\u003cp\u003e“This skyrockets the success rate of usable production-ready generations and makes video storytelling accessible to a lot more people,” he added.\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://lumalabs.ai/learning-hub/dream-machine-support-pricing-information\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLuma’s Dream Machine web platform\u003c/a\u003e offers a free tier with 720 pixel generations capped at a variable number each month: Paid plans begin at $6.99 per month: From “Lite,” which offers 1080p visuals, to Plus ($20.99/month), to Unlimited ($66.49/month) and Enterprise ($1,672.92/year).\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-leap-forward-in-video-gen\"\u003eA leap forward in video gen\u003c/h2\u003e\n\n\n\n\u003cp\u003eRight now, Ray2 is limited to tex-to-video, allowing users to type in descriptions that are transformed into 5 or 10 second video clips. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe model can generate new videos in a matter of seconds, although right now it can take minutes at a time due to a crush of demand from new users.\u003c/p\u003e\n\n\n\n\u003cp\u003eExamples shared by Luma and early testers in its Creators program showcase the model’s versatility, including a man running through an Antarctic snowstorm surrounded by explosions, and a ballerina performing on an ice floe in the Arctic.\u003c/p\u003e\n\n\n\n\u003cp\u003eImpressively, all the motions in the example videos appear lifelike and fluid — and often, with subjects moving much faster and more naturally than videos from rival AI generators, which often appear to generate in slow motion.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model can even create realistic versions of surreal ideas such as a \u003ca href=\"https://x.com/JeffSynthesized/status/1879598540760269211\" target=\"_blank\" rel=\"noreferrer noopener\"\u003egiraffe surfing\u003c/a\u003e, as X user \u003ca href=\"https://x.com/JeffSynthesized/status/1879598540760269211\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e@JeffSynthesized\u003c/a\u003e demonstrated. “Ray 2 is the real deal,” he \u003ca href=\"https://x.com/JeffSynthesized/status/1879598540760269211\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewrote on X\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eOther AI video creators who have tried the new model seem to largely agree, with \u003ca href=\"https://x.com/jerrod_lew/status/1879596643030618333\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eJerrod Lew posting on X\u003c/a\u003e: “Improved cinematography, lighting and realism has arrived and it’s awesome.”\u003c/p\u003e\n\n\n\n\u003cp\u003e“…it’s so good!” \u003ca href=\"https://x.com/HBCoop_/status/1879648313521119577\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAI video artist Heather Cooper\u003c/a\u003e chimed in. \u003c/p\u003e\n\n\n\n\u003cp\u003eMy own tests were a mixed bag, with some more complex prompts creating unnatural and glitchy results. But when it did produce clips that resembled more of what I had in mind in my prompts — such as \u003ca href=\"https://x.com/carlfranzen/status/1879614042148663702/video/1\" target=\"_blank\" rel=\"noreferrer noopener\"\u003efencers crossing swords aboard a space station orbiting Jupiter\u003c/a\u003e — it was undeniably impressive.\u003c/p\u003e\n\n\n\n\u003cp\u003eJain said Luma will also add image-to-video, video-to-video and editing capabilities to Ray2 in the future, further expanding the tool’s creative possibilities.\u003c/p\u003e\n\n\n\n\n\n\n\n\u003cp\u003eTo celebrate the launch of Ray2, Luma Labs is hosting the Ray2 Awards, offering creators the chance to win up to $7,000 in prizes. These include: \u003c/p\u003e\n\n\n\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eA large scale award\u003c/strong\u003e: The creator whose Ray2 content garners the most views on a single platform during the first week of launch will win $5,000. Submissions are due by January 22, 2025.\u003c/li\u003e\n\n\n\n\u003cli\u003e\u003cstrong\u003eA raffle for $3,000\u003c/strong\u003e: Creators can enter by sharing Ray2 content on social media and engaging with Luma AI’s launch video. The deadline for participation is also January 22.\u003c/li\u003e\n\u003c/ol\u003e\n\n\n\n\u003cp\u003eWinners of both awards will be announced on January 27. Submissions can be uploaded via forms provided by Luma Labs, and creators are encouraged to use hashtags #Ray2 and #DreamMachine when sharing their work.\u003c/p\u003e\n\n\n\n\u003cp\u003eAdditionally, Luma Labs has launched an affiliate program, allowing participants to earn commissions by promoting its tools.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-01-16T00:22:39Z",
  "modifiedTime": "2025-01-16T00:54:40Z"
}
