{
  "id": "73eb60c7-5cd3-463d-82d2-50c886a2a550",
  "title": "How the A-MEM framework supports powerful long-context memory so LLMs can take on more complicated tasks",
  "link": "https://venturebeat.com/ai/how-the-a-mem-framework-supports-powerful-long-context-memory-so-llms-can-take-on-more-complicated-tasks/",
  "description": "A-MEM uses embeddings and LLMs to create dynamic memory notes that automatically link to create complex knowledge structures.",
  "author": "Ben Dickson",
  "published": "Wed, 05 Mar 2025 22:21:46 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Agentic AI",
    "AI agents",
    "AI research",
    "AI, ML and Deep Learning",
    "category-/Computers \u0026 Electronics/Software",
    "category-/Science/Computer Science",
    "Generative AI",
    "large language models",
    "large language models (LLMs)",
    "LLMs",
    "research"
  ],
  "byline": "Ben Dickson",
  "length": 5718,
  "excerpt": "A-MEM uses embeddings and LLMs to create dynamic memory notes that automatically link to create complex knowledge structures.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Researchers at Rutgers University, Ant Group and Salesforce Research have proposed a new framework that enables AI agents to take on more complicated tasks by integrating information from their environment and creating automatically linked memories to develop complex structures.  Called A-MEM, the framework uses large language models (LLMs) and vector embeddings to extract useful information from the agent’s interactions and create memory representations that can be retrieved and used efficiently. With enterprises looking to integrate AI agents into their workflows and applications, having a reliable memory management system can make a big difference. Why LLM memory is important Memory is critical in LLM and agentic applications because it enables long-term interactions between tools and users. Current memory systems, however, are either inefficient or based on predefined schemas that might not fit the changing nature of applications and the interactions they face. “Such rigid structures, coupled with fixed agent workflows, severely restrict these systems’ ability to generalize across new environments and maintain effectiveness in long-term interactions,” the researchers write. “The challenge becomes increasingly critical as LLM agents tackle more complex, open-ended tasks, where flexible knowledge organization and continuous adaptation are essential.” A-MEM explained A-MEM introduces an agentic memory architecture that enables autonomous and flexible memory management for LLM agents, according to the researchers. Every time an LLM agent interacts with its environment— whether by accessing tools or exchanging messages with users — A-MEM generates “structured memory notes” that capture both explicit information and metadata such as time, contextual description, relevant keywords and linked memories. Some details are generated by the LLM as it examines the interaction and creates semantic components. Once a memory is created, an encoder model is used to calculate the embedding value of all its components. The combination of LLM-generated semantic components and embeddings provides both human-interpretable context and a tool for efficient retrieval through similarity search. Building up memory over time One of the interesting components of the A-MEM framework is a mechanism for linking different memory notes without the need for predefined rules. For each new memory note, A-MEM identifies the nearest memories based on the similarity of their embedding values. The LLM then analyzes the full content of the retrieved candidates to choose the ones that are most suitable to link to the new memory.  “By using embedding-based retrieval as an initial filter, we enable efficient scalability while maintaining semantic relevance,” the researchers write. “A-MEM can quickly identify potential connections even in large memory collections without exhaustive comparison. More importantly, the LLM-driven analysis allows for nuanced understanding of relationships that goes beyond simple similarity metrics.” After creating links for the new memory, A-MEM updates the retrieved memories based on their textual information and relationships with the new memory. As more memories are added over time, this process refines the system’s knowledge structures, enabling the discovery of higher-order patterns and concepts across memories. In each interaction, A-MEM uses context-aware memory retrieval to provide the agent with relevant historical information. Given a new prompt, A-MEM first computes its embedding value with the same mechanism used for memory notes. The system uses this embedding to retrieve the most relevant memories from the memory store and augment the original prompt with contextual information that helps the agent better understand and respond to the current interaction.  “The retrieved context enriches the agent’s reasoning process by connecting the current interaction with related past experiences and knowledge stored in the memory system,” the researchers write. A-MEM in action The researchers tested A-MEM on LoCoMo, a dataset of very long conversations spanning multiple sessions. LoCoMo contains challenging tasks such as multi-hop questions that require synthesizing information across multiple chat sessions and reasoning questions that require understanding time-related information. The dataset also contains knowledge questions that require integrating contextual information from the conversation with external knowledge. The experiments show that A-MEM outperforms other baseline agentic memory techniques on most task categories, especially when using open source models. Notably, researchers say that A-MEM achieves superior performance while lowering inference costs, requiring up to 10X fewer tokens when answering questions. Effective memory management is becoming a core requirement as LLM agents become integrated into complex enterprise workflows across different domains and subsystems. A-MEM — whose code is available on GitHub — is one of several frameworks that enable enterprises to build memory-enhanced LLM agents. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/03/0fDPi8NORiSvt1W7X6U3nQ.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eResearchers at Rutgers University, Ant Group and Salesforce Research have proposed a new framework that enables AI agents to take on more complicated tasks by integrating information from their environment and creating automatically linked memories to develop complex structures. \u003c/p\u003e\n\n\n\n\u003cp\u003eCalled \u003ca href=\"https://arxiv.org/abs/2502.12110\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eA-MEM\u003c/a\u003e, the framework uses large language models (LLMs) and vector embeddings to extract useful information from the agent’s interactions and create memory representations that can be retrieved and used efficiently. With enterprises looking to integrate \u003ca href=\"https://venturebeat.com/ai/salesforce-launches-agentforce-2dx-pushing-autonomous-ai-deep-into-enterprise-workflows/\"\u003eAI agents\u003c/a\u003e into their workflows and applications, having a reliable memory management system can make a big difference.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-why-llm-memory-is-important\"\u003eWhy LLM memory is important\u003c/h2\u003e\n\n\n\n\u003cp\u003eMemory is critical in \u003ca href=\"https://venturebeat.com/ai/enhancing-ai-agents-with-long-term-memory-insights-into-langmem-sdk-memobase-and-the-a-mem-framework/\"\u003eLLM and agentic applications\u003c/a\u003e because it enables long-term interactions between tools and users. Current memory systems, however, are either inefficient or based on predefined schemas that might not fit the changing nature of applications and the interactions they face.\u003c/p\u003e\n\n\n\n\u003cp\u003e“Such rigid structures, coupled with fixed agent workflows, severely restrict these systems’ ability to generalize across new environments and maintain effectiveness in long-term interactions,” the researchers write. “The challenge becomes increasingly critical as LLM agents tackle more complex, open-ended tasks, where flexible knowledge organization and continuous adaptation are essential.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-mem-explained\"\u003eA-MEM explained\u003c/h2\u003e\n\n\n\n\u003cp\u003eA-MEM introduces an \u003ca href=\"https://venturebeat.com/ai/coheres-first-vision-model-aya-vision-is-here-with-broad-multilingual-understanding-and-open-weights-but-theres-a-catch/\"\u003eagentic memory\u003c/a\u003e architecture that enables autonomous and flexible memory management for LLM agents, according to the researchers.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"706\" height=\"432\" src=\"https://venturebeat.com/wp-content/uploads/2025/03/image.png\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/03/image.png 706w, https://venturebeat.com/wp-content/uploads/2025/03/image.png?resize=300,184 300w, https://venturebeat.com/wp-content/uploads/2025/03/image.png?resize=400,245 400w, https://venturebeat.com/wp-content/uploads/2025/03/image.png?resize=578,354 578w\" sizes=\"(max-width: 706px) 100vw, 706px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eEvery time an LLM agent interacts with its environment— whether by accessing tools or exchanging messages with users — A-MEM generates “structured memory notes” that capture both explicit information and metadata such as time, contextual description, relevant keywords and linked memories. Some details are generated by the LLM as it examines the interaction and creates semantic components.\u003c/p\u003e\n\n\n\n\u003cp\u003eOnce a memory is created, an encoder model is used to calculate the embedding value of all its components. The combination of LLM-generated semantic components and embeddings provides both human-interpretable context and a tool for efficient retrieval through similarity search.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-building-up-memory-over-time\"\u003eBuilding up memory over time\u003c/h2\u003e\n\n\n\n\u003cp\u003eOne of the interesting components of the A-MEM framework is a mechanism for linking different memory notes without the need for predefined rules. For each new memory note, A-MEM identifies the nearest memories based on the similarity of their embedding values. The LLM then analyzes the full content of the retrieved candidates to choose the ones that are most suitable to link to the new memory. \u003c/p\u003e\n\n\n\n\u003cp\u003e“By using embedding-based retrieval as an initial filter, we enable efficient scalability while maintaining semantic relevance,” the researchers write. “A-MEM can quickly identify potential connections even in large memory collections without exhaustive comparison. More importantly, the LLM-driven analysis allows for nuanced understanding of relationships that goes beyond simple similarity metrics.”\u003c/p\u003e\n\n\n\n\u003cp\u003eAfter creating links for the new memory, A-MEM updates the retrieved memories based on their textual information and relationships with the new memory. As more memories are added over time, this process refines the system’s knowledge structures, enabling the discovery of higher-order patterns and concepts across memories.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"4028\" height=\"1847\" src=\"https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png 4028w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=300,138 300w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=768,352 768w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=800,367 800w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=1536,704 1536w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=2048,939 2048w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=400,183 400w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=750,344 750w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=578,265 578w, https://venturebeat.com/wp-content/uploads/2025/03/image_d4ca4b.png?resize=930,426 930w\" sizes=\"(max-width: 4028px) 100vw, 4028px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIn each interaction, A-MEM uses context-aware memory retrieval to provide the agent with relevant historical information. Given a new prompt, A-MEM first computes its embedding value with the same mechanism used for memory notes. The system uses this embedding to retrieve the most relevant memories from the memory store and augment the original prompt with contextual information that helps the agent better understand and respond to the current interaction. \u003c/p\u003e\n\n\n\n\u003cp\u003e“The retrieved context enriches the agent’s reasoning process by connecting the current interaction with related past experiences and knowledge stored in the memory system,” the researchers write.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-a-mem-in-action\"\u003eA-MEM in action\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe researchers tested A-MEM on \u003ca href=\"https://snap-research.github.io/locomo/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLoCoMo\u003c/a\u003e, a dataset of very long conversations spanning multiple sessions. LoCoMo contains challenging tasks such as multi-hop questions that require synthesizing information across multiple chat sessions and reasoning questions that require understanding time-related information. The dataset also contains knowledge questions that require integrating contextual information from the conversation with external knowledge.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1416\" height=\"934\" src=\"https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png 1416w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=300,198 300w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=768,507 768w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=800,528 800w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=400,264 400w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=750,495 750w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=578,381 578w, https://venturebeat.com/wp-content/uploads/2025/03/image_1157c8.png?resize=930,613 930w\" sizes=\"(max-width: 1416px) 100vw, 1416px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe experiments show that A-MEM outperforms other baseline agentic memory techniques on most task categories, especially when using open source models. Notably, researchers say that A-MEM achieves superior performance while lowering inference costs, requiring up to 10X fewer tokens when answering questions.\u003c/p\u003e\n\n\n\n\u003cp\u003eEffective memory management is becoming a core requirement as LLM agents become integrated into complex enterprise workflows across different domains and subsystems. A-MEM — whose code is \u003ca href=\"https://github.com/agiresearch/A-mem\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eavailable on GitHub\u003c/a\u003e — is one of several frameworks that enable enterprises to build memory-enhanced LLM agents. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-03-05T22:21:46Z",
  "modifiedTime": "2025-03-05T22:21:52Z"
}
