{
  "id": "7a807e23-b8c6-4092-991f-f8c200a3f719",
  "title": "OpenAI begins 2025 with massive hype for AGI, superintelligence",
  "link": "https://venturebeat.com/ai/openai-begins-2025-with-massive-hype-for-agi-superintelligence/",
  "description": "The AGI and superintelligence hype has hit a fever pitch unlike any I've seen in my 15 years writing about technology.",
  "author": "Carl Franzen",
  "published": "Mon, 06 Jan 2025 22:59:51 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI, ML and Deep Learning",
    "Conversational AI",
    "LLM reasoning",
    "LLMs",
    "multimodal ai",
    "NLP",
    "o3",
    "o3-mini",
    "OpenAI",
    "openai o1",
    "OpenAI o3",
    "reasoning"
  ],
  "byline": "Carl Franzen",
  "length": 6548,
  "excerpt": "The AGI and superintelligence hype has hit a fever pitch unlike any I've seen in my 15 years writing about technology.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "January 6, 2025 2:59 PM Credit: VentureBeat made with OpenAI ChatGPT Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Much like how 2024 ended in New York City, the 2025 AI news cycle has started off with a thunderclap. OpenAI co-founder and CEO Sam Altman took to his personal blog yesterday (January 5) to belatedly commemorate the second anniversary of ChatGPT (which launched in November 2022) and offer a series of “Reflections” on progress toward OpenAI’s stated goal of developing artificial general intelligence (AGI) — the company defines this as “AI systems that are generally smarter than humans” — and later, superintellignence, AI systems even smarter than that. Among the eye-popping statements Altman writes in his post are: “We are now confident we know how to build AGI as we have traditionally understood it.” Altman didn’t put a timeline on this particular development in his blog post, but in an interview published by Bloomberg yesterday (but conducted ahead of last month’s announcement of OpenAI’s o3 model last month) Altman said: “I think AGI will probably get developed during this president’s term, and getting that right seems really important.” Before we have AGI, AI agents will join the workforce this year, Altman says Back to Altman’s blog, the CEO wrote: “We believe that, in 2025, we may see the first AI agents ‘join the workforce’ and materially change the output of companies.” If I may read between the lines here, the idea is that companies could soon augment or even replace human members of their staff with AI agents — that is, autonomous or semi-autonomous AI-powered assistants that can complete multiple tasks with minimal human back-and-forth. Superintelligence incoming? But it is Altman’s concluding statements in his blog post that are perhaps the most bold and provocative. He writes: “We are beginning to turn our aim beyond that, to superintelligence in the true sense of the word. We love our current products, but we are here for the glorious future. With superintelligence, we can do anything else. Superintelligent tools could massively accelerate scientific discovery and innovation well beyond what we are capable of doing on our own, and in turn massively increase abundance and prosperity. This sounds like science fiction right now, and somewhat crazy to even talk about it. That’s alright — we’ve been there before and we’re OK with being there again. We’re pretty confident that in the next few years, everyone will see what we see, and that the need to act with great care, while still maximizing broad benefit and empowerment, is so important. Given the possibilities of our work, OpenAI cannot be a normal company.” That very same day, OpenAI’s head of mission alignment Joshua Achiam posted on X: “The world isn’t grappling enough with the seriousness of AI and how it will upend or negate a lot of the assumptions many seemingly-robust equilibria are based upon.” Achiam expounded further in a lengthy thread on X, suggesting the rapid pace of AI advancement will significantly alter “Domestic politics. International politics. Market efficiency. The rate of change of technological progress. Social graphs. The emotional dependency of people on other people,” and in another post, added that this “will force changes in strategy in businesses, institutions of all kinds, and countries.” Prior to all these posts, on January 3rd, Stephen McAleer, a self-described researching safety agent at OpenAI, also posted on X: “I kinda miss doing AI research back when we didn’t know how to create superintelligence.” Reactions across the board The reaction around the web has been a fairly predictable mix of positive and negative, and appears to me to be mostly evenly split between those who embrace OpenAI’s optimistic and seemingly aggressive timeline for the advance of AI in society and those who believe the company is full of it. As McKay Wrigley, founder of skills development platform Takeoff AI, wrote in a post on X: “AGI timelines are out. ASI timelines are in.” Another X user, @gfodor, wrote an extremely optimistic prediction in a post: “By the end of Trump’s term we’ll have AGI if not ASI, we will be on Mars, we will have at least a million humanoid robots, we’ll know we are alone if aliens don’t show up, we’ll know if Yud was right, and we will have to have UBI. Fun” UBI, of course, refers to “universal basic income,” an idea floated back in the late 1700s to offer minimum wages to all of the population. This has in recent years received backing from Silicon Valley figures, including Altman, as a means of leveraging AI’s productivity gains and ensuring that they don’t cause society to undergo economic depression or devastation if most jobs are replaced by AI. Perennial OpenAI skeptic Gary Marcus took to X to post a thread of links to areas where he believes OpenAI’s o1 reasoning model is falling well short of what could be considered AGI or even close to it, stating: “Many leading figures in the field have acknowledged that we may have reached a period of diminishing returns of pure LLM scaling, much as I anticipated in 2022. It’s anybody’s guess what happens next.” ‪Benjamin Riley, a former JP Morgan associate who said he worked at the firm when infamous failed energy company Enron was a client, compared that firm to OpenAI on the social network BlueSky. In a series of posts he wrote, in part: “I mostly steer clear of OpenAI palace intrigue but man, all the signs are there.” Seizing upon Altman’s prediction of AI agents joining the workforce this year, public relations manager and outspoken AI critic Ed Zitron also wrote on BlueSky: “Stop fucking printing everything Sam Altman says like it’s truth!” We’ll soon find out if it is indeed the truth or not, as 2025 has scarcely just begun — and already, the AGI and superintelligence hype has hit a fever pitch unlike any I’ve seen in my 15 years writing about technology. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/01/this-way-agi.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-01-06T22:59:51+00:00\" datetime=\"2025-01-06T22:59:51+00:00\"\u003eJanuary 6, 2025 2:59 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"229\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/this-way-agi.png?w=400\" alt=\"Vintage comic sepia toned AI image showing a man and woman staring up at a sign reading This Way to AGI!\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with OpenAI ChatGPT\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eMuch like how \u003ca href=\"https://nypost.com/2025/01/01/us-news/nyc-new-years-eve-revelers-unfazed-by-rain-to-welcome-2025-in-times-square/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e2024 ended in New York City\u003c/a\u003e, the 2025 AI news cycle has started off with a thunderclap.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI co-founder and CEO Sam Altman took to \u003ca href=\"https://blog.samaltman.com/reflections\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ehis personal blog\u003c/a\u003e yesterday (January 5) to belatedly commemorate the second anniversary of ChatGPT (which launched in November 2022) and offer a series of “Reflections” on progress toward OpenAI’s stated goal of developing \u003ca href=\"https://openai.com/index/planning-for-agi-and-beyond/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eartificial general intelligence (AGI) \u003c/a\u003e— the company defines this as “AI systems that are generally smarter than humans” — and later, superintellignence, AI systems even smarter than that.\u003c/p\u003e\n\n\n\n\u003cp\u003eAmong the eye-popping statements Altman writes in his post are: “We are now confident we know how to build AGI as we have traditionally understood it.”\u003c/p\u003e\n\n\n\n\u003cp\u003eAltman didn’t put a timeline on this particular development in his blog post, but in an interview published by \u003ca href=\"https://www.bloomberg.com/features/2025-sam-altman-interview/?embedded-checkout=true\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eBloomberg\u003c/a\u003e yesterday (but conducted ahead of last month’s announcement of \u003ca href=\"https://venturebeat.com/ai/five-breakthroughs-that-make-openais-o3-a-turning-point-for-ai-and-one-big-challenge/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenAI’s o3 model last month\u003c/a\u003e) Altman said:\u003c/p\u003e\n\n\n\n\u003cp\u003e“I think AGI will probably get developed during this president’s term, and getting that right seems really important.” \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-before-we-have-agi-ai-agents-will-join-the-workforce-this-year-altman-says\"\u003eBefore we have AGI, AI agents will join the workforce this year, Altman says\u003c/h2\u003e\n\n\n\n\u003cp\u003eBack to Altman’s blog, the CEO wrote: “We believe that, in 2025, we may see the first AI agents ‘join the workforce’ and materially change the output of companies.”\u003c/p\u003e\n\n\n\n\u003cp\u003eIf I may read between the lines here, the idea is that companies could soon augment or even replace human members of their staff with AI agents — that is, autonomous or semi-autonomous AI-powered assistants that can complete multiple tasks with minimal human back-and-forth.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-superintelligence-incoming\"\u003eSuperintelligence incoming?\u003c/h2\u003e\n\n\n\n\u003cp\u003eBut it is Altman’s concluding statements in his blog post that are perhaps the most bold and provocative. He writes:\u003c/p\u003e\n\n\n\n\u003cp\u003e“We are beginning to turn our aim beyond that, to superintelligence in the true sense of the word. We love our current products, but we are here for the glorious future. With superintelligence, we can do anything else. Superintelligent tools could massively accelerate scientific discovery and innovation well beyond what we are capable of doing on our own, and in turn massively increase abundance and prosperity.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis sounds like science fiction right now, and somewhat crazy to even talk about it. That’s alright — we’ve been there before and we’re OK with being there again. We’re pretty confident that in the next few years, everyone will see what we see, and that the need to act with great care, while still maximizing broad benefit and empowerment, is so important. Given the possibilities of our work, OpenAI cannot be a normal company.”\u003c/p\u003e\n\n\n\n\u003cp\u003eThat very same day, OpenAI’s head of mission alignment \u003ca href=\"https://x.com/jachiam0/status/1875790261722477025\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eJoshua Achiam posted on X\u003c/a\u003e: “The world isn’t grappling enough with the seriousness of AI and how it will upend or negate a lot of the assumptions many seemingly-robust equilibria are based upon.” \u003c/p\u003e\n\n\n\n\u003cp\u003eAchiam expounded further in a lengthy thread on X, suggesting the rapid pace of AI advancement will significantly alter “Domestic politics. International politics. Market efficiency. The rate of change of technological progress. Social graphs. The emotional dependency of people on other people,” and in another post, added that this “will force changes in strategy in businesses, institutions of all kinds, and countries.” \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"830\" height=\"1142\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48%E2%80%AFPM.png?w=436\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png 830w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png?resize=291,400 291w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png?resize=768,1057 768w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png?resize=436,600 436w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png?resize=400,550 400w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png?resize=750,1032 750w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.48 PM.png?resize=578,795 578w\" sizes=\"(max-width: 830px) 100vw, 830px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"790\" height=\"572\" src=\"https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54%E2%80%AFPM.png\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54 PM.png 790w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54 PM.png?resize=300,217 300w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54 PM.png?resize=768,556 768w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54 PM.png?resize=400,290 400w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54 PM.png?resize=750,543 750w, https://venturebeat.com/wp-content/uploads/2025/01/Screenshot-2025-01-06-at-5.21.54 PM.png?resize=578,419 578w\" sizes=\"(max-width: 790px) 100vw, 790px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003ePrior to all these posts, on January 3rd, Stephen McAleer, a self-described researching safety agent at OpenAI, also \u003ca href=\"https://x.com/McaleerStephen/status/1875380842157178994\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eposted on X\u003c/a\u003e: “I kinda miss doing AI research back when we didn’t know how to create superintelligence.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-reactions-across-the-board\"\u003eReactions across the board\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe reaction around the web has been a fairly predictable mix of positive and negative, and appears to me to be mostly evenly split between those who embrace OpenAI’s optimistic and seemingly aggressive timeline for the advance of AI in society and those who believe the company is full of it.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs McKay Wrigley, founder of skills development platform Takeoff AI, \u003ca href=\"https://x.com/mckaywrigley/status/1876100617556689119\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewrote in a post on X\u003c/a\u003e: “AGI timelines are out. ASI timelines are in.”\u003c/p\u003e\n\n\n\n\u003cp\u003eAnother X user, @gfodor, wrote an extremely optimistic \u003ca href=\"https://x.com/gfodor/status/1876131102764781829\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eprediction in a post\u003c/a\u003e: “By the end of Trump’s term we’ll have AGI if not ASI, we will be on Mars, we will have at least a million humanoid robots, we’ll know we are alone if aliens don’t show up, we’ll know if Yud was right, and we will have to have UBI. Fun”\u003c/p\u003e\n\n\n\n\u003cp\u003eUBI, of course, refers to “universal basic income,” an idea \u003ca href=\"https://thereader.mitpress.mit.edu/the-deep-and-enduring-history-of-universal-basic-income/#:~:text=If%20anyone%20can%20be%20said,before%20it%20became%20widely%20known.\" target=\"_blank\" rel=\"noreferrer noopener\"\u003efloated back in the late 1700s\u003c/a\u003e to offer minimum wages to all of the population. This has in recent years received backing from Silicon Valley figures, including Altman, as a means of leveraging AI’s productivity gains and ensuring that they don’t cause society to undergo economic depression or devastation if most jobs are replaced by AI.\u003c/p\u003e\n\n\n\n\u003cp\u003ePerennial OpenAI skeptic \u003ca href=\"https://x.com/GaryMarcus/status/1876127737108119781\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGary Marcus \u003c/a\u003etook to X to post a thread of links to areas where he believes \u003ca href=\"https://venturebeat.com/ai/openai-launches-full-o1-model-with-34-reduced-error-rate-debuts-chatgpt-pro/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenAI’s o1 reasoning model\u003c/a\u003e is falling well short of what could be considered AGI or even close to it, stating: “Many leading figures in the field have acknowledged that we may have reached a period of diminishing returns of pure LLM scaling, much as I anticipated in 2022. It’s anybody’s guess what happens next.”\u003c/p\u003e\n\n\n\n\u003cp\u003e‪Benjamin Riley, a former JP Morgan associate who said he worked at the firm when infamous failed energy company Enron was a client, compared that firm to OpenAI on the \u003ca href=\"https://bsky.app/profile/benjaminjriley.bsky.social/post/3lf3povwouk2h\" target=\"_blank\" rel=\"noreferrer noopener\"\u003esocial network BlueSky\u003c/a\u003e. In a series of posts he wrote, in part: “I mostly steer clear of OpenAI palace intrigue but man, all the signs are there.”\u003c/p\u003e\n\n\n\n\u003cp\u003eSeizing upon Altman’s prediction of AI agents joining the workforce this year, public relations manager and outspoken AI critic Ed Zitron also wrote on \u003ca href=\"https://bsky.app/profile/edzitron.com/post/3lf3m6nfnws22\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eBlueSky\u003c/a\u003e: “Stop fucking printing everything Sam Altman says like it’s truth!” \u003c/p\u003e\n\n\n\n\u003cp\u003eWe’ll soon find out if it is indeed the truth or not, as 2025 has scarcely just begun — and already, the AGI and superintelligence hype has hit a fever pitch unlike any I’ve seen in my 15 years writing about technology.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-01-06T22:59:51Z",
  "modifiedTime": "2025-01-07T00:21:45Z"
}
