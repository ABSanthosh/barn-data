{
  "id": "a4d2f948-28cd-4043-8ba3-1a2389a65f1b",
  "title": "Mistral’s Voxtral goes beyond transcription with summarization, speech-triggered functions",
  "link": "https://venturebeat.com/ai/mistrals-voxtral-goes-beyond-transcription-with-summarization-speech-triggered-functions/",
  "description": "Mistral's open-source speech model Voxtral can recognize multiple languages, understand spoken instructions and also offer enterprise security.",
  "author": "Emilia David",
  "published": "Tue, 15 Jul 2025 23:34:49 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI speech",
    "ai speech recognition",
    "AI, ML and Deep Learning",
    "ElevenLabs",
    "Mistral AI",
    "speech",
    "speech recognition",
    "whisper"
  ],
  "byline": "Emilia David",
  "length": 5570,
  "excerpt": "Mistral's open-source speech model Voxtral can recognize multiple languages, understand spoken instructions and also offer enterprise security.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "July 15, 2025 4:34 PM Credit: VentureBeat made with Midjourney Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now Mistral released an open-sourced voice model today that could rival paid voice AI, such as those from ElevenLabs and Hume AI, which the company said bridges the gap between proprietary speech recognition models and the more open, yet error-prone versions.  Voxtral, which Mistral will release under an Apache 2.0 license, is available in a 24B parameter version and a 3B variant. The larger model is intended for applications at scale, while the smaller version would work for local and edge use cases.  “Voice was humanity’s first interface—long before writing or typing, it let us share ideas, coordinate work, and build relationships. As digital systems become more capable, voice is returning as our most natural form of human-computer interaction,” Mistral said in a blog post. “Yet today’s systems remain limited—unreliable, proprietary, and too brittle for real-world use. Closing this gap demands tools with exceptional transcription, deep understanding, multilingual fluency, and open, flexible deployment.” Voxtral is available on Mistral’s API and a transcription-only endpoint on its website. The models are also accessible through Le Chat, Mistral’s chat platform.  The AI Impact Series Returns to San Francisco â August 5 The next phase of AI is here â are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows â from real-time decision-making to end-to-end automation. Secure your spot now â space is limited: https://bit.ly/3GuuPLF Mistral said that speech AI “meant choosing between two trade-offs,” pointing out that some open-source automated speech recognition models often had limited semantic understanding. Still, closed models with strong language understanding come at a high cost.  Bridging the gap The company said Voxtral “offers state-of-the-art accuracy and native semantic understanding in the open, at less than half the price of comparable APIs.”  Voxtral, at a 32K token context, can listen to and transcribe up to 30 minutes of audio or 40 minutes of audio understanding. It offers summarization, meaning the model can answer questions based on the audio content and generate summaries without switching to a separate mode. Users can trigger functions and API calls based on spoken instructions. The model is based on Mistral’s Mistral Small 3.1. It supports multiple languages and can automatically detect languages such as English, Spanish, French, Portuguese, Hindi, German, Italian, and Dutch.  Mistral added enterprise features to Voxtral, including private deployment, so that organizations can integrate the model into their own ecosystems. These features also include domain-specific fine-tuning and advanced context and priority access to engineering resources for customers who need help integrating Voxtral into their workflows.  Performance  Speech recognition AI is now available on many platforms today. Users can speak to ChatGPT, and the platform will process spoken instructions similarly to written prompts. Fast food chains like White Castle have deployed SoundHound to their drive-thru services, and ElevenLabs has steadily been improving its multimodal platform. The open-source space also offers powerful options. Nari Labs, a startup, released the open-source speech model Dia in April. However, some of these services can be quite expensive. Transcription services like Otter and Read.ai can now embed themselves into Zoom meetings, recording, summarizing and even alerting users to actionable items. Many online video meeting platforms offer not just transcription, but also speech AI and agentic AI, with Google Meetings providing the option to take notes for users using Gemini. As a regular user of voice transcription services, I can say firsthand that speech recognition AI is not perfect, but it is improving. Mistral stated that Voxtral outperformed existing voice models, including OpenAI’s Whisper, Gemini 2.5 Flash and Scribe from ElevenLabs. Voxtral presented fewer word errors compared to Whisper, which is currently considered the best automatic speech recognition model available.  In terms of audio understanding, Voxtral Small is “competitive with GPT-4o-mini and Gemini 2.5 Flash across all tasks, achieving state-of-the-art performance in Speech Translation.” Since announcing Voxtral, social media users said they have been waiting for an open-source speech model that can match the performance of Whisper.  Yes! We needed this. A week ago, I was lamenting over a closed-source AI universe and cyberpunk dystopian future, but today, with this addition, my outlook is much improved – go open-source. https://t.co/QsKAfTOxou— David Hendrickson (@TeksEdge) July 15, 2025 Mistral said Voxtral will be available through its API at $0.001 per minute.  Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/02/nuneybits_Abstract_art_of_a_robot_voice_actor_recording_in_the__f9117954-b033-4730-a521-b507eb2ee48a-transformed.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-07-15T23:34:49+00:00\" datetime=\"2025-07-15T23:34:49+00:00\"\u003eJuly 15, 2025 4:34 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"224\" src=\"https://venturebeat.com/wp-content/uploads/2024/02/nuneybits_Abstract_art_of_a_robot_voice_actor_recording_in_the__f9117954-b033-4730-a521-b507eb2ee48a-transformed.webp?w=400\" alt=\"Credit: VentureBeat made with Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\u003c/em\u003e \u003cem\u003e\u003ca href=\"https://venturebeat.com/newsletters/\"\u003eSubscribe Now\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://mistral.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMistral\u003c/a\u003e released an open-sourced voice model today that could rival paid voice AI, such as those from \u003ca href=\"https://elevenlabs.io/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eElevenLabs\u003c/a\u003e and \u003ca href=\"https://www.hume.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHume AI\u003c/a\u003e, which the company said bridges the gap between proprietary speech recognition models and the more open, yet error-prone versions. \u003c/p\u003e\n\n\n\n\u003cp\u003eVoxtral, which Mistral will release under an Apache 2.0 license, is available in a 24B parameter version and a 3B variant. The larger model is intended for applications at scale, while the smaller version would work for local and edge use cases. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e“Voice was humanity’s first interface—long before writing or typing, it let us share ideas, coordinate work, and build relationships. As digital systems become more capable, voice is returning as our most natural form of human-computer interaction,” Mistral said in a \u003ca href=\"https://mistral.ai/news/voxtral\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eblog post\u003c/a\u003e. “Yet today’s systems remain limited—unreliable, proprietary, and too brittle for real-world use. Closing this gap demands tools with exceptional transcription, deep understanding, multilingual fluency, and open, flexible deployment.”\u003c/p\u003e\n\n\n\n\u003cp\u003eVoxtral is available on Mistral’s API and a transcription-only endpoint on its website. The models are also accessible through Le Chat, Mistral’s chat platform. \u003c/p\u003e\n\n\n\n\u003cdiv id=\"boilerplate_2803147\"\u003e\n\u003chr/\u003e\n\n\n\n\u003cp\u003e\u003cstrong\u003e\u003c/strong\u003e\u003cstrong\u003eThe AI Impact Series Returns to San Francisco â August 5\u003c/strong\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe next phase of AI is here â are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows â from real-time decision-making to end-to-end automation. \u003c/p\u003e\n\n\n\n\u003cp\u003eSecure your spot now â space is limited: \u003ca href=\"https://bit.ly/3GuuPLF\"\u003ehttps://bit.ly/3GuuPLF\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eMistral said that speech AI “meant choosing between two trade-offs,” pointing out that some open-source automated speech recognition models often had limited semantic understanding. Still, closed models with strong language understanding come at a high cost. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-bridging-the-gap\"\u003eBridging the gap\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe company said Voxtral “offers state-of-the-art accuracy and native semantic understanding in the open, at less than half the price of comparable APIs.” \u003c/p\u003e\n\n\n\n\u003cp\u003eVoxtral, at a 32K token context, can listen to and transcribe up to 30 minutes of audio or 40 minutes of audio understanding. It offers summarization, meaning the model can answer questions based on the audio content and generate summaries without switching to a separate mode. Users can trigger functions and API calls based on spoken instructions.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model is based on Mistral’s Mistral Small 3.1. It supports multiple languages and can automatically detect languages such as English, Spanish, French, Portuguese, Hindi, German, Italian, and Dutch. \u003c/p\u003e\n\n\n\n\u003cp\u003eMistral added enterprise features to Voxtral, including private deployment, so that organizations can integrate the model into their own ecosystems. These features also include domain-specific fine-tuning and advanced context and priority access to engineering resources for customers who need help integrating Voxtral into their workflows. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-performance-nbsp\"\u003ePerformance \u003c/h2\u003e\n\n\n\n\u003cp\u003eSpeech recognition AI is now available on many platforms today. Users can speak to ChatGPT, and the platform will process spoken instructions similarly to written prompts. Fast food chains like \u003ca href=\"https://venturebeat.com/ai/soundhound-buys-allset-to-bring-ai-voice-ordering-to-more-drive-throughs/\"\u003eWhite Castle have deployed\u003c/a\u003e \u003ca href=\"https://www.soundhound.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSoundHound\u003c/a\u003e to their drive-thru services, and ElevenLabs has steadily been \u003ca href=\"https://venturebeat.com/ai/elevenlabs-debuts-conversational-ai-2-0-voice-assistants-that-understand-when-to-pause-speak-and-take-turns-talking/\"\u003eimproving its multimodal platform\u003c/a\u003e. The open-source space also offers powerful options. \u003ca href=\"https://narilabs.org/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eNari Labs\u003c/a\u003e, a startup, released the open-source speech \u003ca href=\"https://venturebeat.com/ai/a-new-open-source-text-to-speech-model-called-dia-has-arrived-to-challenge-elevenlabs-openai-and-more/\"\u003emodel Dia in April.\u003c/a\u003e However, some of these services can be quite expensive.\u003c/p\u003e\n\n\n\n\u003cp\u003eTranscription services like \u003ca href=\"https://otter.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOtter\u003c/a\u003e and \u003ca href=\"http://read.ai\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eRead.ai\u003c/a\u003e can now embed themselves into Zoom meetings, recording, summarizing and even alerting users to actionable items. Many online video meeting platforms offer not just transcription, \u003ca href=\"https://venturebeat.com/ai/beyond-transcription-how-agentic-ai-is-set-to-change-enterprise-meetings/\"\u003ebut also speech AI and agentic AI\u003c/a\u003e, with \u003ca href=\"https://www.google.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGoogle\u003c/a\u003e Meetings providing the option to take notes for users using Gemini. As a regular user of voice transcription services, I can say firsthand that speech recognition AI is not perfect, but it is improving.\u003c/p\u003e\n\n\n\n\u003cp\u003eMistral stated that Voxtral outperformed existing voice models, including \u003ca href=\"https://openai.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenAI\u003c/a\u003e’s Whisper, Gemini 2.5 Flash and Scribe from ElevenLabs. Voxtral presented fewer word errors compared to Whisper, which is currently considered the best automatic speech recognition model available. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXd9RVhqCY4Ll5dqfnoFovIh3I1MbLXEk0TkpwHSuLsDZCaZYiQzgXJoD8GrJoC7bxLv3TDOUC3vk4rE3KmyViGZ6IYJLW7gK7KGHpWcxJxpeitfvUy4OOXtCef7ZbdFe7GqhohT?key=JFD1wgm0yPl09uGFvdwjmQ\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eIn terms of audio understanding, Voxtral Small is “competitive with GPT-4o-mini and Gemini 2.5 Flash across all tasks, achieving state-of-the-art performance in Speech Translation.”\u003c/p\u003e\n\n\n\n\u003cp\u003eSince announcing Voxtral, social media users said they have been waiting for an open-source speech model that can match the performance of Whisper. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cdiv\u003e\n\u003cblockquote data-width=\"500\" data-dnt=\"true\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003eYes! We needed this. A week ago, I was lamenting over a closed-source AI universe and cyberpunk dystopian future, but today, with this addition, my outlook is much improved – go open-source.  \u003ca href=\"https://t.co/QsKAfTOxou\"\u003ehttps://t.co/QsKAfTOxou\u003c/a\u003e\u003c/p\u003e— David Hendrickson (@TeksEdge) \u003ca href=\"https://twitter.com/TeksEdge/status/1945134312552100137?ref_src=twsrc%5Etfw\"\u003eJuly 15, 2025\u003c/a\u003e\u003c/blockquote\u003e\n\u003c/div\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eMistral said Voxtral will be available through its API at $0.001 per minute. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2025-07-15T23:34:49Z",
  "modifiedTime": "2025-07-15T23:34:55Z"
}
