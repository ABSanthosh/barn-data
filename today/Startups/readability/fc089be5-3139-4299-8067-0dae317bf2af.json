{
  "id": "fc089be5-3139-4299-8067-0dae317bf2af",
  "title": "Cohere’s smallest, fastest R-series model excels at RAG, reasoning in 23 languages",
  "link": "https://venturebeat.com/ai/coheres-smallest-fastest-r-series-model-excels-at-rag-reasoning-in-23-languages/",
  "description": "Cohere's Command R7B uses RAG, features a context length of 128K, supports 23 languages and outperforms Gemma, Llama and Ministral.",
  "author": "Taryn Plumb",
  "published": "Sat, 14 Dec 2024 00:27:49 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI, ML and Deep Learning",
    "category-/Business \u0026 Industrial",
    "Cohere",
    "Cohere AI",
    "Cohere Command",
    "Cohere Command R+",
    "Conversational AI",
    "Generative AI",
    "large language models",
    "NLP"
  ],
  "byline": "Taryn Plumb",
  "length": 4382,
  "excerpt": "Cohere's Command R7B uses RAG, features a context length of 128K, supports 23 languages and outperforms Gemma, Llama and Ministral.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "December 13, 2024 4:27 PM VentureBeat/Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Proving its intention to support a wide range of enterprise use cases — including those that don’t require expensive, resource-intensive large language models (LLMs) — AI startup Cohere has released Command R7B, the smallest and fastest in its R model series.  Command R7B is built to support fast prototyping and iteration and uses retrieval-augmented generation (RAG) to improve its accuracy. The model features a context length of 128K and supports 23 languages. It outperforms others in its class of open-weights models — Google’s Gemma, Meta’s Llama, Mistral’s Ministral — in tasks including math and coding, Cohere says. “The model is designed for developers and businesses that need to optimize for the speed, cost-performance and compute resources of their use cases,” Cohere co-founder and CEO Aidan Gomez writes in a blog post announcing the new model. Outperforming competitors in math, coding, RAG Cohere has been strategically focused on enterprises and their unique use cases. The company introduced Command-R in March and the powerful Command R+ in April, and has made upgrades throughout the year to support speed and efficiency. It teased Command R7B as the “final” model in its R series, and says it will release model weights to the AI research community. Cohere noted that a critical area of focus when developing Command R7B was to improve performance on math, reasoning, code and translation. The company appears to have succeeded in those areas, with the new smaller model topping the HuggingFace Open LLM Leaderboard against similarly-sized open-weight models including Gemma 2 9B, Ministral 8B and Llama 3.1 8B.  Further, the smallest model in the R series outperforms competing models in areas including AI agents, tool use and RAG, which helps improve accuracy by grounding model outputs in external data. Cohere says Command R7B excels at conversational tasks including tech workplace and enterprise risk management (ERM) assistance; technical facts; media workplace and customer service support; HR FAQs; and summarization. Cohere also notes that the model is “exceptionally good” at retrieving and manipulating numerical information in financial settings. All told, Command R7B ranked first, on average, in important benchmarks including instruction-following evaluation (IFeval); big bench hard (BBH); graduate-level Google-proof Q\u0026A (GPQA); multi-step soft reasoning (MuSR); and massive multitask language understanding (MMLU).  Removing unnecessary call functions Command R7B can use tools including search engines, APIs and vector databases to expand its functionality. Cohere reports that the model’s tool use performs strongly against competitors in the Berkeley Function-Calling Leaderboard, which evaluates a model’s accuracy in function calling (connecting to external data and systems).  Gomez points out that this proves its effectiveness in “real-world, diverse and dynamic environments” and removes the need for unnecessary call functions. This can make it a good choice for building “fast and capable” AI agents. For instance, Cohere points out, when functioning as an internet-augmented search agent, Command R7B can break complex questions down into subgoals, while also performing well with advanced reasoning and information retrieval. Because it is small, Command R7B can be deployed on lower-end and consumer CPUs, GPUs and MacBooks, allowing for on-device inference. The model is available now on the Cohere platform and HuggingFace. Pricing is $0.0375 per 1 million input tokens and $0.15 per 1 million output tokens. “It is an ideal choice for enterprises looking for a cost-efficient model grounded in their internal documents and data,” writes Gomez.  Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/12/nuneybits_A_marathon_race_track_with_various_AI_robots_lined_up_b13e43f0-e5e4-497d-bceb-1523c5bba44d-transformed.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-12-14T00:27:49+00:00\" datetime=\"2024-12-14T00:27:49+00:00\"\u003eDecember 13, 2024 4:27 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"224\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/nuneybits_A_marathon_race_track_with_various_AI_robots_lined_up_b13e43f0-e5e4-497d-bceb-1523c5bba44d-transformed.webp?w=400\" alt=\"VentureBeat/Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eProving its intention to support a wide range of enterprise use cases — including those that don’t require expensive, resource-intensive \u003ca href=\"https://venturebeat.com/ai/what-ai-vendor-should-you-choose-here-are-the-top-7-openai-still-leads/\"\u003elarge language models\u003c/a\u003e (LLMs) — AI startup \u003ca href=\"https://cohere.com/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eCohere\u003c/a\u003e has released Command R7B, the smallest and fastest in its R model series. \u003c/p\u003e\n\n\n\n\u003cp\u003eCommand R7B is built to support fast prototyping and iteration and uses retrieval-augmented generation (RAG) to improve its accuracy. The model features a context length of 128K and supports 23 languages. It outperforms others in its class of open-weights models — Google’s Gemma, Meta’s Llama, Mistral’s Ministral — in tasks including math and coding, Cohere says.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"816\" height=\"726\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?w=674\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png 816w, https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?resize=300,267 300w, https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?resize=768,683 768w, https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?resize=674,600 674w, https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?resize=400,356 400w, https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?resize=750,667 750w, https://venturebeat.com/wp-content/uploads/2024/12/Screenshot-117.png?resize=578,514 578w\" sizes=\"(max-width: 816px) 100vw, 816px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003e“The model is designed for developers and businesses that need to optimize for the speed, cost-performance and compute resources of their use cases,” Cohere co-founder and CEO Aidan Gomez \u003ca href=\"https://cohere.com/blog/command-r7b\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewrites in a blog post\u003c/a\u003e announcing the new model.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-outperforming-competitors-in-math-coding-rag\"\u003eOutperforming competitors in math, coding, RAG\u003c/h2\u003e\n\n\n\n\u003cp\u003eCohere has been strategically focused on enterprises and their unique use cases. The company introduced \u003ca href=\"https://docs.cohere.com/v2/docs/command-r\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eCommand-R in March\u003c/a\u003e and the powerful \u003ca href=\"https://venturebeat.com/ai/coheres-new-ai-command-r-is-available-on-sagemaker-and-azure/\"\u003eCommand R+\u003c/a\u003e in April, and has made upgrades \u003ca href=\"https://docs.cohere.com/v2/docs/command-r\"\u003ethroughout the year\u003c/a\u003e to support speed and efficiency. It teased Command R7B as the “final” model in its R series, and says it will release model weights to the AI research community.\u003c/p\u003e\n\n\n\n\u003cp\u003eCohere noted that a critical area of focus when developing Command R7B was to improve performance on math, reasoning, code and translation. The company appears to have succeeded in those areas, with the new smaller model topping the \u003ca href=\"https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard?ref=cohere-ai.ghost.io#/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eHuggingFace Open LLM Leaderboard\u003c/a\u003e against similarly-sized open-weight models including Gemma 2 9B, Ministral 8B and Llama 3.1 8B. \u003c/p\u003e\n\n\n\n\u003cp\u003eFurther, the smallest model in the R series outperforms competing models in areas including AI agents, tool use and RAG, which helps improve accuracy by grounding model outputs in external data. Cohere says Command R7B excels at conversational tasks including tech workplace and enterprise risk management (ERM) assistance; technical facts; media workplace and customer service support; HR FAQs; and summarization. Cohere also notes that the model is “exceptionally good” at retrieving and manipulating numerical information in financial settings.\u003c/p\u003e\n\n\n\n\u003cp\u003eAll told, Command R7B ranked first, on average, in important benchmarks including instruction-following evaluation (IFeval); big bench hard (BBH); graduate-level Google-proof Q\u0026amp;A (GPQA); \u003ca href=\"https://arxiv.org/abs/2310.16049\" target=\"_blank\" rel=\"noreferrer noopener\"\u003emulti-step soft reasoning\u003c/a\u003e (MuSR); and \u003ca href=\"https://arxiv.org/html/2406.01574v4\" target=\"_blank\" rel=\"noreferrer noopener\"\u003emassive multitask language understanding\u003c/a\u003e (MMLU). \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-removing-unnecessary-call-functions\"\u003eRemoving unnecessary call functions\u003c/h2\u003e\n\n\n\n\u003cp\u003eCommand R7B can use tools including search engines, APIs and vector databases to expand its functionality. Cohere reports that the model’s tool use performs strongly against competitors in the Berkeley Function-Calling Leaderboard, which evaluates a model’s accuracy in function calling (connecting to external data and systems). \u003c/p\u003e\n\n\n\n\u003cp\u003eGomez points out that this proves its effectiveness in “real-world, diverse and dynamic environments” and removes the need for unnecessary call functions. This can make it a good choice for building “fast and capable” AI agents. For instance, Cohere points out, when functioning as an internet-augmented search agent, Command R7B can break complex questions down into subgoals, while also performing well with advanced reasoning and information retrieval. \u003c/p\u003e\n\n\n\n\u003cp\u003eBecause it is small, Command R7B can be deployed on lower-end and consumer CPUs, GPUs and MacBooks, allowing for on-device inference. The model is available now on the Cohere platform and HuggingFace. Pricing is $0.0375 per 1 million input tokens and $0.15 per 1 million output tokens.\u003c/p\u003e\n\n\n\n\u003cp\u003e“It is an ideal choice for enterprises looking for a cost-efficient model grounded in their internal documents and data,” writes Gomez. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "5 min read",
  "publishedTime": "2024-12-14T00:27:49Z",
  "modifiedTime": "2024-12-14T00:37:48Z"
}
