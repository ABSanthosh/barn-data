{
  "id": "3ea6275b-172c-4ddc-8d40-098d6e5ec835",
  "title": "Now it’s TikTok parent ByteDance’s turn for a reasoning AI: enter Seed-Thinking-v1.5!",
  "link": "https://venturebeat.com/ai/now-its-tiktok-parent-bytedances-turn-for-a-reasoning-ai-enter-seed-thinking-v1-5/",
  "description": "It achieved an 8.0% higher win rate over DeepSeek R1, suggesting that its strengths generalize beyond just logic or math-heavy challenges.",
  "author": "Carl Franzen",
  "published": "Fri, 11 Apr 2025 19:08:24 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI infrastructure",
    "AI, ML and Deep Learning",
    "Bytedance",
    "Chain of Thought",
    "chain of thought reasoning",
    "China",
    "Conversational AI",
    "Deepseek R1",
    "Gemini 2.5 Pro",
    "Google",
    "GPU",
    "LLM reasoning",
    "LLMs",
    "mixture of experts",
    "NLP",
    "o3-mini",
    "OpenAI",
    "reasoning AI",
    "reasoning models",
    "reinforcement learning",
    "seed thinking",
    "seed-thinking-v1.5",
    "TikTok"
  ],
  "byline": "Carl Franzen",
  "length": 10149,
  "excerpt": "It achieved an 8.0% higher win rate over DeepSeek R1, suggesting that its strengths generalize beyond just logic or math-heavy challenges.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "April 11, 2025 12:08 PM Credit: VentureBeat made with ChatGPT Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More It started with the announcement of OpenAI’s o1 model in Sept. 2024, but really took off with the DeepSeek R1 release in Jan. 2025. Now, it seems that most major AI model providers and trainers are in a new race to deliver better, faster, and cheaper “reasoning” AI language models — that is, ones that maybe take a little longer to respond to a human user, but ideally do so with better, more comprehensive, more well “reasoned” answers, which these class of models get by performing “chain-of-thought,” reflecting on their own conclusions and interrogating them for veracity before responding. ByteDance, the Chinese web media giant parent of TikTok, is the latest to join the party with the announcement and publication of the technical paper behind Seed-Thinking-v1.5, an upcoming large language model (LLM) designed to advance reasoning performance across both science, tech, math, and engineering (STEM) fields and general-purpose domains. The model is not yet available for download or use, and it’s unclear what the licensing terms will be—whether it will be proprietary/closed source, open source/free for all to use and modify at will, or somewhere in between. However, the technical paper provides some noteworthy details that are worth going over now and in advance of whenever they are made available. Built atop the increasingly popular Mixture-of-Experts (MoE) architecture Like Meta’s new Llama 4 and Mistral’s Mixtral before it, Seed-Thinking-v1.5 is built using a Mixture-of-Experts (MoE) architecture. This architecture is designed to make models more efficient. It essentially combines the capabilities of multiple models into one, each specializing in a different domain. In this case, the MoE architecture means that Seed-Thinking-v1.5 uses only 20 billion of the 200 billion parameters at a time. ByteDance says in its technical paper published to GitHub that Seed-Thinking-v1.5 prioritizes structured reasoning and thoughtful response generation. The results nearly speak for themselves, with Seed-Thinking-v1.5 outperforming DeepSeek R1 and approaching Google’s newly released Gemini 2.5 Pro and OpenAI’s o3-mini-high reasoner on many third-party benchmark evaluations. It even exceeds those two in the case of the ARC-AGI benchmark, which measures progress towards artificial general intelligence, seen as the goal or “Holy Grail” of AI. This model outperforms humans on most economically valuable tasks, according to OpenAI’s definition. Positioned as a compact yet capable alternative to larger state-of-the-art models, Seed-Thinking-v1.5 achieves competitive benchmark results. It introduces reinforcement learning (RL) innovations, training data curation and AI infrastructure. Performance benchmarks and model focus Seed-Thinking-v1.5 shows strong performance on a suite of challenging tasks, scoring 86.7% on AIME 2024, 55.0% pass@8 on Codeforces and 77.3% on the GPQA science benchmark. These results place it close to or matching models like OpenAI’s o3-mini-high and Google’s Gemini 2.5 Pro on specific reasoning metrics. On non-reasoning tasks, the model was evaluated through human preference comparisons and achieved an 8.0% higher win rate over DeepSeek R1, suggesting that its strengths generalize beyond logic or math-heavy challenges. To address saturation in standard benchmarks like AIME, ByteDance introduced BeyondAIME, a new, harder math benchmark with curated problems designed to resist memorization and better discriminate model performance. This and the Codeforces evaluation set are expected to be publicly released to support future research. Data strategy Training data played a central role in the model’s development. For supervised fine-tuning (SFT), the team curated 400,000 samples, including 300,000 verifiable (STEM, logic and coding tasks) and 100,000 non-verifiable problems like creative writing and role-playing. For RL training, data was segmented into: Verifiable problems: 100,000 rigorously filtered STEM questions and logic puzzles with known answers, sourced from elite competitions and expert review. Non-verifiable tasks: Human-preference datasets focused on open-ended prompts, evaluated using pairwise reward models. The STEM data leaned heavily on advanced mathematics, accounting for over 80% of the problem set. Additional logic data included tasks like Sudoku and 24-point puzzles, with adjustable difficulty to match model progress. Reinforcement learning approach Reinforcement learning in Seed-Thinking-v1.5 is powered by custom actor-critic (VAPO) and policy-gradient (DAPO) frameworks, developed to address known instabilities in RL training. These techniques reduce reward signal sparsity and enhance training stability, especially in long chain-of-thought (CoT) settings. Reward models play a critical role in supervising RL outputs. ByteDance introduced two key tools: Seed-Verifier: A rule-based LLM that checks if generated and reference answers are mathematically equivalent. Seed-Thinking-Verifier: A step-by-step reasoning-based judge that improves judgment consistency and resists reward hacking. This two-tiered reward system enables nuanced evaluation for both straightforward and complex tasks. Infrastructure and scaling To support efficient large-scale training, ByteDance built a system atop its HybridFlow framework. Execution is handled by Ray clusters, and training and inference processes are co-located to reduce GPU idle time. The Streaming Rollout System (SRS) is a notable innovation that separates model evolution from runtime execution. It accelerates iteration speed by asynchronously managing partially completed generations across model versions. This architecture reportedly delivers up to 3× faster RL cycles. Additional infrastructure techniques include: Mixed precision (FP8) for memory savings Expert parallelism and kernel auto-tuning for MoE efficiency ByteCheckpoint for resilient and flexible checkpointing AutoTuner for optimizing parallelism and memory configurations Human evaluation and real-world impact To evaluate alignment with human-centric preferences, ByteDance conducted human testing across a range of domains, including creative writing, humanities knowledge and general conversation. Seed-Thinking-v1.5 consistently outperformed DeepSeek R1 across sessions, reinforcing its applicability to real-world user needs. The development team notes that reasoning models trained primarily on verifiable tasks demonstrated strong generalization to creative domains—an outcome attributed to the structure and rigor embedded in mathematical training workflows. What it means for technical leaders, data engineers and enterprise decision-makers For technical leads managing the lifecycle of large language models—from data curation to deployment—Seed-Thinking-v1.5 presents an opportunity to rethink how reasoning capabilities are integrated into enterprise AI stacks. Its modular training process, which includes verifiable reasoning datasets and multi-phase reinforcement learning, particularly appeals to teams looking to scale LLM development while retaining fine-grained control. ByteDance’s moves to introduce Seed-Verifier and Seed-Thinking-Verifier offer mechanisms for more trustworthy reward modeling, which can be critical when deploying models into customer-facing or regulated environments. For teams operating under tight deadlines and limited bandwidth, the model’s stability under reinforcement learning, enabled by innovations like VAPO and dynamic sampling, could reduce iteration cycles and streamline fine-tuning for specific tasks. From an orchestration and deployment perspective, the model’s hybrid infrastructure approach—including the Streaming Rollout System (SRS) and support for FP8 optimization—suggests significant gains in training throughput and hardware utilization. These features would be valuable for engineers responsible for scaling LLM operations across cloud and on-prem systems. The fact that Seed-Thinking-v1.5 was trained with mechanisms to adapt reward feedback based on runtime dynamics speaks directly to the challenges of managing heterogeneous data pipelines and maintaining consistency across domains. For teams tasked with ensuring reliability, reproducibility, and continuous integration of new tools, Seed-Thinking-v1.5’s system-level design could serve as a blueprint for building robust, multi-modal orchestration systems. For data engineering professionals, the structured approach to training data—including rigorous filtering, augmentation and expert verification—reinforces the importance of data quality as a multiplier of model performance. This could inspire more deliberate approaches to dataset development and validation pipelines. Future outlook Seed-Thinking-v1.5 results from collaboration within ByteDance’s Seed LLM Systems team, led by Yonghui Wu and with public representation by Haibin Lin, a long-time AI contributor. The project also draws on previous efforts, such as Doubao 1.5 Pro, and incorporates shared techniques in RLHF and data curation. The team plans to continue refining reinforcement learning techniques, focusing on training efficiency and reward modeling for non-verifiable tasks. The public release of internal benchmarks such as BeyondAIME is intended to foster broader advancement in reasoning-focused AI research. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/ChatGPT-Image-Apr-11-2025-03_04_50-PM.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-04-11T19:08:24+00:00\" datetime=\"2025-04-11T19:08:24+00:00\"\u003eApril 11, 2025 12:08 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"422\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/ChatGPT-Image-Apr-11-2025-03_04_50-PM.png?w=750\" alt=\"Hands planting seedling in cybernetic garden\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with ChatGPT\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eIt started with the announcement of\u003ca href=\"https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/\"\u003e OpenAI’s o1 model\u003c/a\u003e in Sept. 2024, but really took off with the \u003ca href=\"https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek/\"\u003eDeepSeek R1 release in Jan. 2025\u003c/a\u003e.\u003c/p\u003e\n\n\n\n\u003cp\u003eNow, it seems that most major AI model providers and trainers are in a new race to deliver better, faster, and cheaper “reasoning” AI language models — that is, ones that maybe take a little longer to respond to a human user, but ideally do so with better, more comprehensive, more well “reasoned” answers, which these class of models get by performing “chain-of-thought,” reflecting on their own conclusions and interrogating them for veracity before responding.\u003c/p\u003e\n\n\n\n\u003cp\u003eByteDance, the Chinese web media giant parent of TikTok, is the latest to join the party with the \u003ca href=\"https://x.com/eric_haibin_lin/status/1910433772782444904\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eannouncement\u003c/a\u003e and \u003ca href=\"https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf\" target=\"_blank\" rel=\"noreferrer noopener\"\u003epublication of the technical paper\u003c/a\u003e behind Seed-Thinking-v1.5, an upcoming large language model (LLM) designed to advance reasoning performance across both science, tech, math, and engineering (STEM) fields and general-purpose domains.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe model is not yet available for download or use, and it’s unclear what the licensing terms will be—whether it will be proprietary/closed source, open source/free for all to use and modify at will, or somewhere in between. However, the technical paper provides some noteworthy details that are worth going over now and in advance of whenever they are made available.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-built-atop-the-increasingly-popular-mixture-of-experts-moe-architecture\"\u003eBuilt atop the increasingly popular Mixture-of-Experts (MoE) architecture\u003c/h2\u003e\n\n\n\n\u003cp\u003eLike \u003ca href=\"https://venturebeat.com/ai/metas-answer-to-deepseek-is-here-llama-4-launches-with-long-context-scout-and-maverick-models-and-2t-parameter-behemoth-on-the-way/\"\u003eMeta’s new Llama 4\u003c/a\u003e and \u003ca href=\"https://venturebeat.com/ai/mistral-ai-drops-new-mixture-of-experts-model-with-a-torrent-link/\"\u003eMistral’s Mixtral\u003c/a\u003e before it, Seed-Thinking-v1.5 is built using a Mixture-of-Experts (MoE) architecture.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis architecture is designed to make models more efficient. It essentially combines the capabilities of multiple models into one, each specializing in a different domain.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn this case, the MoE architecture means that Seed-Thinking-v1.5 uses only 20 billion of the 200 billion parameters at a time.\u003c/p\u003e\n\n\n\n\u003cp\u003eByteDance says in its\u003ca href=\"https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e technical paper published to GitHub \u003c/a\u003ethat Seed-Thinking-v1.5 prioritizes structured reasoning and thoughtful response generation.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe results nearly speak for themselves, with Seed-Thinking-v1.5 outperforming DeepSeek R1 and approaching Google’s newly released Gemini 2.5 Pro and OpenAI’s o3-mini-high reasoner on many third-party benchmark evaluations. It even exceeds those two in the case of the \u003ca href=\"https://arcprize.org/arc-agi\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eARC-AGI benchmark\u003c/a\u003e, which measures progress towards artificial general intelligence, seen as the goal or “Holy Grail” of AI. This model outperforms humans on most economically valuable tasks, according to OpenAI’s definition.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"712\" height=\"432\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-11-at-2.39.32%E2%80%AFPM.png\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-11-at-2.39.32 PM.png 712w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-11-at-2.39.32 PM.png?resize=300,182 300w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-11-at-2.39.32 PM.png?resize=400,243 400w, https://venturebeat.com/wp-content/uploads/2025/04/Screenshot-2025-04-11-at-2.39.32 PM.png?resize=578,351 578w\" sizes=\"(max-width: 712px) 100vw, 712px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003ePositioned as a compact yet capable alternative to larger state-of-the-art models, Seed-Thinking-v1.5 achieves competitive benchmark results. It introduces reinforcement learning (RL) innovations, training data curation and AI infrastructure.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-performance-benchmarks-and-model-focus\"\u003ePerformance benchmarks and model focus\u003c/h2\u003e\n\n\n\n\u003cp\u003eSeed-Thinking-v1.5 shows strong performance on a suite of challenging tasks, scoring 86.7% on AIME 2024, 55.0% pass@8 on Codeforces and 77.3% on the GPQA science benchmark. These results place it close to or matching models like OpenAI’s o3-mini-high and Google’s Gemini 2.5 Pro on specific reasoning metrics.\u003c/p\u003e\n\n\n\n\u003cp\u003eOn non-reasoning tasks, the model was evaluated through human preference comparisons and achieved an 8.0% higher win rate over DeepSeek R1, suggesting that its strengths generalize beyond logic or math-heavy challenges.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo address saturation in standard benchmarks like AIME, ByteDance introduced BeyondAIME, a new, harder math benchmark with curated problems designed to resist memorization and better discriminate model performance. This and the Codeforces evaluation set are expected to be publicly released to support future research.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-data-strategy\"\u003eData strategy\u003c/h2\u003e\n\n\n\n\u003cp\u003eTraining data played a central role in the model’s development. For supervised fine-tuning (SFT), the team curated 400,000 samples, including 300,000 verifiable (STEM, logic and coding tasks) and 100,000 non-verifiable problems like creative writing and role-playing.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor RL training, data was segmented into:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eVerifiable problems: 100,000 rigorously filtered STEM questions and logic puzzles with known answers, sourced from elite competitions and expert review.\u003c/li\u003e\n\n\n\n\u003cli\u003eNon-verifiable tasks: Human-preference datasets focused on open-ended prompts, evaluated using pairwise reward models.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThe STEM data leaned heavily on advanced mathematics, accounting for over 80% of the problem set. Additional logic data included tasks like Sudoku and 24-point puzzles, with adjustable difficulty to match model progress.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-reinforcement-learning-approach\"\u003eReinforcement learning approach\u003c/h2\u003e\n\n\n\n\u003cp\u003eReinforcement learning in Seed-Thinking-v1.5 is powered by custom actor-critic (VAPO) and policy-gradient (DAPO) frameworks, developed to address known instabilities in RL training. These techniques reduce reward signal sparsity and enhance training stability, especially in long chain-of-thought (CoT) settings.\u003c/p\u003e\n\n\n\n\u003cp\u003eReward models play a critical role in supervising RL outputs. ByteDance introduced two key tools:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eSeed-Verifier: A rule-based LLM that checks if generated and reference answers are mathematically equivalent.\u003c/li\u003e\n\n\n\n\u003cli\u003eSeed-Thinking-Verifier: A step-by-step reasoning-based judge that improves judgment consistency and resists reward hacking.\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eThis two-tiered reward system enables nuanced evaluation for both straightforward and complex tasks.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-infrastructure-and-scaling\"\u003eInfrastructure and scaling\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo support efficient large-scale training, ByteDance built a system atop its HybridFlow framework. Execution is handled by Ray clusters, and training and inference processes are co-located to reduce GPU idle time.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe Streaming Rollout System (SRS) is a notable innovation that separates model evolution from runtime execution. It accelerates iteration speed by asynchronously managing partially completed generations across model versions. This architecture reportedly delivers up to 3× faster RL cycles.\u003c/p\u003e\n\n\n\n\u003cp\u003eAdditional infrastructure techniques include:\u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eMixed precision (FP8) for memory savings\u003c/li\u003e\n\n\n\n\u003cli\u003eExpert parallelism and kernel auto-tuning for MoE efficiency\u003c/li\u003e\n\n\n\n\u003cli\u003eByteCheckpoint for resilient and flexible checkpointing\u003c/li\u003e\n\n\n\n\u003cli\u003eAutoTuner for optimizing parallelism and memory configurations\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003ch2 id=\"h-human-evaluation-and-real-world-impact\"\u003eHuman evaluation and real-world impact\u003c/h2\u003e\n\n\n\n\u003cp\u003eTo evaluate alignment with human-centric preferences, ByteDance conducted human testing across a range of domains, including creative writing, humanities knowledge and general conversation.\u003c/p\u003e\n\n\n\n\u003cp\u003eSeed-Thinking-v1.5 consistently outperformed DeepSeek R1 across sessions, reinforcing its applicability to real-world user needs.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe development team notes that reasoning models trained primarily on verifiable tasks demonstrated strong generalization to creative domains—an outcome attributed to the structure and rigor embedded in mathematical training workflows.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-it-means-for-technical-leaders-data-engineers-and-enterprise-decision-makers\"\u003eWhat it means for technical leaders, data engineers and enterprise decision-makers\u003c/h2\u003e\n\n\n\n\u003cp\u003eFor technical leads managing the lifecycle of large language models—from data curation to deployment—Seed-Thinking-v1.5 presents an opportunity to rethink how reasoning capabilities are integrated into enterprise AI stacks. \u003c/p\u003e\n\n\n\n\u003cp\u003eIts modular training process, which includes verifiable reasoning datasets and multi-phase reinforcement learning, particularly appeals to teams looking to scale LLM development while retaining fine-grained control.\u003c/p\u003e\n\n\n\n\u003cp\u003eByteDance’s moves to introduce Seed-Verifier and Seed-Thinking-Verifier offer mechanisms for more trustworthy reward modeling, which can be critical when deploying models into customer-facing or regulated environments. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor teams operating under tight deadlines and limited bandwidth, the model’s stability under reinforcement learning, enabled by innovations like VAPO and dynamic sampling, could reduce iteration cycles and streamline fine-tuning for specific tasks.\u003c/p\u003e\n\n\n\n\u003cp\u003eFrom an orchestration and deployment perspective, the model’s hybrid infrastructure approach—including the Streaming Rollout System (SRS) and support for FP8 optimization—suggests significant gains in training throughput and hardware utilization. \u003c/p\u003e\n\n\n\n\u003cp\u003eThese features would be valuable for engineers responsible for scaling LLM operations across cloud and on-prem systems. The fact that Seed-Thinking-v1.5 was trained with mechanisms to adapt reward feedback based on runtime dynamics speaks directly to the challenges of managing heterogeneous data pipelines and maintaining consistency across domains. \u003c/p\u003e\n\n\n\n\u003cp\u003eFor teams tasked with ensuring reliability, reproducibility, and continuous integration of new tools, Seed-Thinking-v1.5’s system-level design could serve as a blueprint for building robust, multi-modal orchestration systems.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor data engineering professionals, the structured approach to training data—including rigorous filtering, augmentation and expert verification—reinforces the importance of data quality as a multiplier of model performance. This could inspire more deliberate approaches to dataset development and validation pipelines.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-future-outlook\"\u003eFuture outlook\u003c/h2\u003e\n\n\n\n\u003cp\u003eSeed-Thinking-v1.5 results from collaboration within ByteDance’s Seed LLM Systems team, led by Yonghui Wu and with public representation by Haibin Lin, a long-time AI contributor.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe project also draws on previous efforts, such as Doubao 1.5 Pro, and incorporates shared techniques in RLHF and data curation.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe team plans to continue refining reinforcement learning techniques, focusing on training efficiency and reward modeling for non-verifiable tasks. The public release of internal benchmarks such as BeyondAIME is intended to foster broader advancement in reasoning-focused AI research.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "11 min read",
  "publishedTime": "2025-04-11T19:08:24Z",
  "modifiedTime": "2025-04-12T01:06:20Z"
}
