{
  "id": "1b087e48-8b2e-4fc6-8833-1be9e5d43495",
  "title": "Hallucinations in AI: How GSK is addressing a critical problem in drug development",
  "link": "https://venturebeat.com/ai/hallucinations-in-ai-how-gsk-is-addressing-a-critical-problem-in-drug-development/",
  "description": "Hallucinations are a persistent problem in healthcare. Here's how GSK is using test-time compute scaling to improve its gen AI systems.",
  "author": "Bryson Masse",
  "published": "Tue, 14 Jan 2025 23:13:44 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI in healthcare",
    "AI, ML and Deep Learning",
    "category-/Business \u0026 Industrial/Pharmaceuticals \u0026 Biotech",
    "Generative AI",
    "hallucinations",
    "large language models",
    "NLP"
  ],
  "byline": "Bryson Masse",
  "length": 7216,
  "excerpt": "Hallucinations are a persistent problem in healthcare. Here's how GSK is using test-time compute scaling to improve its gen AI systems.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Generative AI has become a key piece of infrastructure in many industries, and healthcare is no exception. Yet, as organizations like GSK push the boundaries of what generative AI can achieve, they face significant challenges — particularly when it comes to reliability. Hallucinations, or when AI models generate incorrect or fabricated information, are a persistent problem in high-stakes applications like drug discovery and healthcare. For GSK, tackling these challenges requires leveraging test-time compute scaling to improve gen AI systems. Here’s how they’re doing it. The hallucination problem in generative health care Healthcare applications demand an exceptionally high level of accuracy and reliability. Errors are not merely inconvenient; they can have life-altering consequences. This makes hallucinations in large language models (LLMs) a critical issue for companies like GSK, where gen AI is applied to tasks such as scientific literature review, genomic analysis and drug discovery. To mitigate hallucinations, GSK employs advanced inference-time compute strategies, including self-reflection mechanisms, multi-model sampling and iterative output evaluation. According to Kim Branson, SvP of AI and machine learning (ML) at GSK, these techniques help ensure that agents are “robust and reliable,” while enabling scientists to generate actionable insights more quickly. Leveraging test-time compute scaling Test-time compute scaling refers to the ability to increase computational resources during the inference phase of AI systems. This allows for more complex operations, such as iterative output refinement or multi-model aggregation, which are critical for reducing hallucinations and improving model performance. Branson emphasized the transformative role of scaling in GSK’s AI efforts, noting that “we’re all about increasing the iteration cycles at GSK — how we think faster.” By using strategies like self-reflection and ensemble modeling, GSK can leverage these additional compute cycles to produce results that are both accurate and reliable. Branson also touched on the broader industry trend, saying, “You’re seeing this war happening with how much I can serve, my cost per token and time per token. That allows people to bring these different algorithmic strategies which were before not technically feasible, and that also will drive the kind of deployment and adoption of agents.” Strategies for reducing hallucinations GSK has identified hallucinations as a critical challenge in gen AI for healthcare. The company employs two main strategies that require additional computational resources during inference. Applying more thorough processing steps ensures that each answer is examined for accuracy and consistency before it is delivered in clinical or research settings, where reliability is paramount. Self-reflection and iterative output review One core technique is self-reflection, where LLMs critique or edit their own responses to improve quality. The model “thinks step by step,” analyzing its initial output, pinpointing weaknesses and revising answers as needed. GSK’s literature search tool exemplifies this: It collects data from internal repositories and an LLM’s memory, then re-evaluates its findings through self-criticism to uncover inconsistencies. This iterative process results in clearer, more detailed final answers. Branson underscored the value of self-criticism, saying: “If you can only afford to do one thing, do that.” Refining its own logic before delivering results allows the system to produce insights that align with healthcare’s strict standards. Multi-model sampling GSK’s second strategy relies on multiple LLMs or different configurations of a single model to cross-verify outputs. In practice, the system might run the same query at various temperature settings to generate diverse answers, employ fine-tuned versions of the same model specializing in particular domains or call on entirely separate models trained on distinct datasets. Comparing and contrasting these outputs helps confirm the most consistent or convergent conclusions. “You can get that effect of having different orthogonal ways to come to the same conclusion,” said Branson. Although this approach requires more computational power, it reduces hallucinations and boosts confidence in the final answer — an essential benefit in high-stakes healthcare environments. The inference wars GSK’s strategies depend on infrastructure that can handle significantly heavier computational loads. In what Branson calls “inference wars,” AI infrastructure companies — such as Cerebras, Groq and SambaNova — compete to deliver hardware breakthroughs that enhance token throughput, lower latency and reduce costs per token.  Specialized chips and architectures enable complex inferencing routines, including multi-model sampling and iterative self-reflection, at scale. Cerebras’ technology, for example, processes thousands of tokens per second, allowing advanced techniques to work in real-world scenarios. “You’re seeing the results of these innovations directly impacting how we can deploy generative models effectively in healthcare,” Branson noted.  When hardware keeps pace with software demands, solutions emerge to maintain accuracy and efficiency. Challenges remain Even with these advancements, scaling compute resources presents obstacles. Longer inference times can slow workflows, especially if clinicians or researchers need prompt results. Higher compute usage also drives up costs, requiring careful resource management. Nonetheless, GSK considers these trade-offs necessary for stronger reliability and richer functionality.  “As we enable more tools in the agent ecosystem, the system becomes more useful for people, and you end up with increased compute usage,” Branson noted. Balancing performance, costs and system capabilities allows GSK to maintain a practical yet forward-looking strategy. What’s next? GSK plans to keep refining its AI-driven healthcare solutions with test-time compute scaling as a top priority. The combination of self-reflection, multi-model sampling and robust infrastructure helps to ensure that generative models meet the rigorous demands of clinical environments.  This approach also serves as a road map for other organizations, illustrating how to reconcile accuracy, efficiency and scalability. Maintaining a leading edge in compute innovations and sophisticated inference techniques not only addresses current challenges, but also lays the groundwork for breakthroughs in drug discovery, patient care and beyond. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/01/a-stunning-sci-fi-illustration-of-a-futu_Ti_g4n2BRUmWlxEeqduNnw_cPuhW5SGRmq6qccxYtRY0Q-transformed.jpeg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eGenerative AI has become a key piece of infrastructure in many industries, and healthcare is no exception. Yet, as organizations like \u003ca href=\"https://www.gsk.com/en-gb/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGSK\u003c/a\u003e push the boundaries of what \u003ca href=\"https://venturebeat.com/ai/openais-agentic-era-begins-chatgpt-tasks-offers-job-scheduling-reminders-and-more/\"\u003egenerative AI\u003c/a\u003e can achieve, they face significant challenges — particularly when it comes to reliability. \u003ca href=\"https://venturebeat.com/ai/google-deepmind-researchers-introduce-new-benchmark-to-improve-llm-factuality-reduce-hallucinations/\"\u003eHallucinations\u003c/a\u003e, or when AI models generate incorrect or fabricated information, are a persistent problem in high-stakes applications like drug discovery and healthcare. For GSK, tackling these challenges requires leveraging test-time compute scaling to improve gen AI systems. Here’s how they’re doing it.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-hallucination-problem-in-generative-health-care\"\u003eThe hallucination problem in generative health care\u003c/h2\u003e\n\n\n\n\u003cp\u003eHealthcare applications demand an exceptionally high level of accuracy and reliability. Errors are not merely inconvenient; they can have life-altering consequences. This makes hallucinations in large language models (LLMs) a critical issue for companies like GSK, where gen AI is applied to tasks such as scientific literature review, genomic analysis and drug discovery.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo mitigate hallucinations, GSK employs advanced inference-time compute strategies, including self-reflection mechanisms, multi-model sampling and iterative output evaluation. According to Kim Branson, SvP of AI and machine learning (ML) at GSK, these techniques help ensure that agents are “robust and reliable,” while enabling scientists to generate actionable insights more quickly.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-leveraging-test-time-compute-scaling\"\u003eLeveraging test-time compute scaling\u003c/h2\u003e\n\n\n\n\u003cp\u003eTest-time compute scaling refers to the ability to \u003ca href=\"https://venturebeat.com/ai/hugging-face-shows-how-test-time-scaling-helps-small-language-models-punch-above-their-weight/\"\u003eincrease computational resources\u003c/a\u003e during the inference phase of AI systems. This allows for more complex operations, such as iterative output refinement or multi-model aggregation, which are critical for reducing hallucinations and improving model performance.\u003c/p\u003e\n\n\n\n\u003cp\u003eBranson emphasized the transformative role of scaling in GSK’s AI efforts, noting that “we’re all about increasing the iteration cycles at GSK — how we think faster.” By using strategies like self-reflection and ensemble modeling, GSK can leverage these additional compute cycles to produce results that are both accurate and reliable.\u003c/p\u003e\n\n\n\n\u003cp\u003eBranson also touched on the broader industry trend, saying, “You’re seeing this war happening with how much I can serve, my cost per token and time per token. That allows people to bring these different algorithmic strategies which were before not technically feasible, and that also will drive the kind of deployment and adoption of agents.”\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-strategies-for-reducing-hallucinations\"\u003eStrategies for reducing hallucinations\u003c/h2\u003e\n\n\n\n\u003cp\u003eGSK has identified hallucinations as a critical challenge in \u003ca href=\"https://venturebeat.com/ai/learn-how-ge-healthcare-used-aws-to-build-a-new-ai-model-that-interprets-mris/\"\u003egen AI for healthcare\u003c/a\u003e. The company employs two main strategies that require additional computational resources during inference. Applying more thorough processing steps ensures that each answer is examined for accuracy and consistency before it is delivered in clinical or research settings, where reliability is paramount.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-self-reflection-and-iterative-output-review\"\u003eSelf-reflection and iterative output review\u003c/h3\u003e\n\n\n\n\u003cdiv\u003e\u003cp\u003eOne core technique is self-reflection, where LLMs critique or edit their own responses to improve quality. The model “thinks step by step,” analyzing its initial output, pinpointing weaknesses and revising answers as needed. GSK’s literature search tool exemplifies this: It collects data from internal repositories and an LLM’s memory, then re-evaluates its findings through self-criticism to uncover inconsistencies. \u003c/p\u003e\u003cp\u003eThis iterative process results in clearer, more detailed final answers. Branson underscored the value of self-criticism, saying: “If you can only afford to do one thing, do that.” Refining its own logic before delivering results allows the system to produce insights that align with healthcare’s strict standards.\u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003ch3 id=\"h-multi-model-sampling\"\u003eMulti-model sampling\u003c/h3\u003e\n\n\n\n\u003cp\u003eGSK’s second strategy relies on multiple LLMs or different configurations of a single model to cross-verify outputs. In practice, the system might run the same query at various temperature settings to generate diverse answers, employ fine-tuned versions of the same model specializing in particular domains or call on entirely separate models trained on distinct datasets.\u003c/p\u003e\n\n\n\n\u003cp\u003eComparing and contrasting these outputs helps confirm the most consistent or convergent conclusions. “You can get that effect of having different orthogonal ways to come to the same conclusion,” said Branson. Although this approach requires more computational power, it reduces hallucinations and boosts confidence in the final answer — an essential benefit in high-stakes healthcare environments.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-inference-wars\"\u003eThe inference wars\u003c/h2\u003e\n\n\n\n\u003cp\u003eGSK’s strategies depend on infrastructure that can handle significantly heavier computational loads. In what Branson calls “inference wars,” AI infrastructure companies — such as \u003ca href=\"https://venturebeat.com/ai/cerebras-breaks-ground-on-condor-galaxy-3-an-ai-supercomputer-that-can-hit-8-exaflops/\"\u003eCerebras\u003c/a\u003e, Groq and SambaNova — compete to deliver hardware breakthroughs that enhance token throughput, lower latency and reduce costs per token. \u003c/p\u003e\n\n\n\n\u003cp\u003eSpecialized chips and architectures enable complex inferencing routines, including multi-model sampling and iterative self-reflection, at scale. Cerebras’ technology, for example, processes thousands of tokens per second, allowing advanced techniques to work in real-world scenarios. “You’re seeing the results of these innovations directly impacting how we can deploy generative models effectively in healthcare,” Branson noted. \u003c/p\u003e\n\n\n\n\u003cp\u003eWhen hardware keeps pace with software demands, solutions emerge to maintain accuracy and efficiency.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-challenges-remain\"\u003eChallenges remain\u003c/h2\u003e\n\n\n\n\u003cp\u003eEven with these advancements, scaling compute resources presents obstacles. Longer inference times can slow workflows, especially if clinicians or researchers need prompt results. Higher compute usage also drives up costs, requiring careful resource management. Nonetheless, GSK considers these trade-offs necessary for stronger reliability and richer functionality. \u003c/p\u003e\n\n\n\n\u003cp\u003e“As we enable more tools in the agent ecosystem, the system becomes more useful for people, and you end up with increased compute usage,” Branson noted. Balancing performance, costs and system capabilities allows GSK to maintain a practical yet forward-looking strategy.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-s-next\"\u003eWhat’s next?\u003c/h2\u003e\n\n\n\n\u003cp\u003eGSK plans to keep refining its AI-driven healthcare solutions with test-time compute scaling as a top priority. The combination of self-reflection, multi-model sampling and robust infrastructure helps to ensure that generative models meet the rigorous demands of clinical environments. \u003c/p\u003e\n\n\n\n\u003cp\u003eThis approach also serves as a road map for other organizations, illustrating how to reconcile accuracy, efficiency and scalability. Maintaining a leading edge in compute innovations and sophisticated inference techniques not only addresses current challenges, but also lays the groundwork for breakthroughs in drug discovery, patient care and beyond.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-01-14T23:13:44Z",
  "modifiedTime": "2025-01-14T23:13:51Z"
}
