{
  "id": "518ec9d2-9ba2-437e-b8e6-4821225488ce",
  "title": "FLUX.1 Kontext enables in-context image generation for enterprise AI pipelines",
  "link": "https://venturebeat.com/ai/flux-1-kontext-enables-in-context-image-generation-for-enterprise-ai-pipelines/",
  "description": "FLUX.1 Kontext from Black Forest Labs aims to let users edit images multiple times through both text and reference images without losing speed.",
  "author": "Emilia David",
  "published": "Thu, 29 May 2025 23:32:17 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "ai image generation",
    "AI, ML and Deep Learning",
    "API",
    "Black Forest Labs",
    "data",
    "Enterprise",
    "Flux.1",
    "image generation",
    "Image generation AI",
    "Midjourney",
    "Stable Diffusion"
  ],
  "byline": "Emilia David",
  "length": 5367,
  "excerpt": "FLUX.1 Kontext from Black Forest Labs aims to let users edit images multiple times through both text and reference images without losing speed.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "May 29, 2025 4:32 PM Credit: VentureBeat, generated with BFL Playground Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Black Forest Labs (BFL), the startup founded by the creators of the popular Stable Diffusion model, has launched a new image generation model called FLUX.1 Kontext. This model not only generates and edits photos, but also allows users to modify them with both text and other images.  The company also announced its new BFL Playground, where people can try out BFL’s models before letting them loose on enterprise applications.  BFL released two versions of the model: FLUX.1 Kontext [pro] and FLUX.1 Kontext [max]. A third version, FLUX.1 Kontext [dev] will be available on private beta. Both the Pro and Max versions are now available on platforms such as KreaAI, Freepik, Lightricks, OpenArt and LeonardoAI. These models allow enterprise creative teams and other developers to edit images with precision and at a faster pace. Today we're releasing FLUX.1 Kontext – a suite of generative flow matching models that allow you to generate and edit images.Unlike traditional text-to-image models, Kontext understands both text AND images as input, enabling true in-context generation and editing. pic.twitter.com/zleJGuXDge— Black Forest Labs (@bfl_ml) May 29, 2025 FLUX.1 Kontext can perform in-context generation. This means the model can be generated from a reference or situation presented to it; it doesn’t generate from scratch. The company said in a post on X that four things make Kontext “special”:  Character consistency and preserving elements across scenes Local editing that “targets specific parts without affecting the rest” Style reference that generates scenes in existing styles, and Minimal latency Developers can test use cases and play with the models on the BFL Playground before accessing the full BFL API.  The pro and max models  Enterprises can use the pro version for fast and iterative editing. Users can input both text and reference images and make local edits. The company said Kontext [pro] operates “up to an order of magnitude faster than previous state-of-the-art models” and is one of the first models that allows editing on multiple turns.  On the other hand, FLUX.1 Kontext [max] is the faster version with maximum performance. The company said it adheres more to prompts, makes typography readable and is consistent in edits without compromising speed. Of course, many other image generation models can also generate photos from uploaded files. MidJourney’s AI image editor can use a reference picture and then edit specific regions of it. So does Adobe’s Firefly, which many people who use Adobe’s popular image and video platforms have access to.  FLUX.1 Kontext [dev], the third version of the Kontext family of models, is an open-weight model at 12 billion parameters. Generative flow  BFL said FLUX.1 Kontext is a flow model, which gives it more flexibility to accomplish the tasks mentioned above.  Flow models learn from a continuous flow of data and define a path between noisy data and useful information. This differs from diffusion, the model architecture that underpins many image and video generation models from Stability AI, MidJourney and even OpenAI’s Sora, which “denoises” data.  BFL said in a blog post that the Kontext models represent an advancement to flow models. “FLUX.1 Kontext models go beyond text-to-image,” the company said. “Unlike previous flow models that only allow for pure text-based generation, FLUX.1 Kontext models also understand and can create from existing images. With FLUX.1 Kontext you can modify an input image via simple text instructions, enabling flexible and instant image editing – no need for finetuning or complex editing workflows.” In the text-to-image benchmark test, BFL claimed the FLUX.1 Kontext models can compete against other models in terms of aesthetics, following prompts, realism and typography.  Generating interest BFL released the text-to-image model Flux 1.1 Pro in October last year. It also included an API for third-party developers to integrate it into their apps.   Thanks to the BFL Playground, some users have already begun playing around with the Kontext models and report being impressed.  Can we talk about how mind-blowing it is that we can use a single image to generate headshots or edit images in less than 10 seconds with @bfl_ml FLUX.1 Kontext?I used the Professional Headshot model on @replicate and these aren't perfect, but my real images are on the left… pic.twitter.com/SZfyZsuvIM— Heather Cooper (@HBCoop_) May 29, 2025 Of course, it still has to compete with other image models available, especially those that have been around for a few years and have continued to improve.  Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/05/generation-ea8c698d-2cc4-4d75-bbb6-f06d2d95c369.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-05-29T23:32:17+00:00\" datetime=\"2025-05-29T23:32:17+00:00\"\u003eMay 29, 2025 4:32 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"405\" src=\"https://venturebeat.com/wp-content/uploads/2025/05/generation-ea8c698d-2cc4-4d75-bbb6-f06d2d95c369.png?w=750\" alt=\"Credit: VentureBeat, generated with BFL Playground\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat, generated with BFL Playground\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"http://blackforestlabs.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eBlack Forest Labs\u003c/a\u003e (BFL), the startup founded by the creators of the \u003ca href=\"https://venturebeat.com/ai/stability-ai-looks-to-grow-stable-diffusion-text-to-image-ai-usage-with-amazon-bedrock/\"\u003epopular Stable Diffusion model\u003c/a\u003e, has launched a new image generation model called \u003ca href=\"https://bfl.ai/announcements/flux-1-kontext\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eFLUX.1 Kontext\u003c/a\u003e. This model not only generates and edits photos, but also allows users to modify them with both text and other images. \u003c/p\u003e\n\n\n\n\u003cp\u003eThe company also announced its new BFL Playground, where people can try out BFL’s models before letting them loose on enterprise applications. \u003c/p\u003e\n\n\n\n\u003cp\u003eBFL released two versions of the model: FLUX.1 Kontext [pro] and FLUX.1 Kontext [max]. A third version, FLUX.1 Kontext [dev] will be available on private beta. Both the Pro and Max versions are now available on platforms such as \u003ca href=\"https://www.krea.ai/edit\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eKreaAI\u003c/a\u003e, \u003ca href=\"https://www.freepik.com/ai/image-generator\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eFreepik\u003c/a\u003e, \u003ca href=\"https://ltx.studio/blog/flux-kontext-in-ltx-studio\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLightricks\u003c/a\u003e, \u003ca href=\"https://openart.ai/create\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenArt\u003c/a\u003e and \u003ca href=\"https://www.canva.com/design/DAGog-jP6m4/ZvVMXL7cop_zqRc0gHnTMg/view?utm_content=DAGog-jP6m4\u0026amp;utm_campaign=designshare\u0026amp;utm_medium=link2\u0026amp;utm_source=uniquelinks\u0026amp;utlId=h68d63046d6\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eLeonardoAI\u003c/a\u003e. These models allow enterprise creative teams and other developers to edit images with precision and at a faster pace. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cdiv\u003e\n\u003cblockquote data-width=\"500\" data-dnt=\"true\"\u003e\u003cdiv lang=\"en\" dir=\"ltr\"\u003e\u003cp\u003eToday we\u0026#39;re releasing FLUX.1 Kontext – a suite of generative flow matching models that allow you to generate and edit images.\u003c/p\u003e\u003cp\u003eUnlike traditional text-to-image models, Kontext understands both text AND images as input, enabling true in-context generation and editing. \u003ca href=\"https://t.co/zleJGuXDge\"\u003epic.twitter.com/zleJGuXDge\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e— Black Forest Labs (@bfl_ml) \u003ca href=\"https://twitter.com/bfl_ml/status/1928143010811748863?ref_src=twsrc%5Etfw\"\u003eMay 29, 2025\u003c/a\u003e\u003c/blockquote\u003e\n\u003c/div\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eFLUX.1 Kontext can perform in-context generation. This means the model can be generated from a reference or situation presented to it; it doesn’t generate from scratch.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe company said in a post on \u003ca href=\"https://x.com/bfl_ml/status/1928143014364598280\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eX\u003c/a\u003e that four things make Kontext “special”: \u003c/p\u003e\n\n\n\n\u003cul\u003e\n\u003cli\u003eCharacter consistency and preserving elements across scenes\u003c/li\u003e\n\n\n\n\u003cli\u003eLocal editing that “targets specific parts without affecting the rest”\u003c/li\u003e\n\n\n\n\u003cli\u003eStyle reference that generates scenes in existing styles, and\u003c/li\u003e\n\n\n\n\u003cli\u003eMinimal latency\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\n\u003cp\u003eDevelopers can test use cases and play with the models on the BFL Playground before accessing the full BFL API. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-pro-and-max-models-nbsp\"\u003eThe pro and max models \u003c/h2\u003e\n\n\n\n\u003cp\u003eEnterprises can use the pro version for fast and iterative editing. Users can input both text and reference images and make local edits. The company said Kontext [pro] operates “up to an order of magnitude faster than previous state-of-the-art models” and is one of the first models that allows editing on multiple turns. \u003c/p\u003e\n\n\n\n\u003cp\u003eOn the other hand, FLUX.1 Kontext [max] is the faster version with maximum performance. The company said it adheres more to prompts, makes typography readable and is consistent in edits without compromising speed.\u003c/p\u003e\n\n\n\n\u003cp\u003eOf course, many other image generation models can also generate photos from uploaded files. \u003ca href=\"https://venturebeat.com/ai/midjourney-launches-ai-image-editor-how-to-use-it/\"\u003eMidJourney’s AI image editor\u003c/a\u003e can use a reference picture and then edit specific regions of it. So does \u003ca href=\"http://www.adobe.com\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eAdobe\u003c/a\u003e’s \u003ca href=\"https://venturebeat.com/ai/adobe-introduces-structure-reference-for-firefly-ai-and-genstudio-for-brands/\"\u003eFirefly\u003c/a\u003e, which many people who use Adobe’s popular image and video platforms have access to. \u003c/p\u003e\n\n\n\n\u003cp\u003eFLUX.1 Kontext [dev], the third version of the Kontext family of models, is an open-weight model at 12 billion parameters.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-generative-flow-nbsp\"\u003eGenerative flow \u003c/h2\u003e\n\n\n\n\u003cp\u003eBFL said FLUX.1 Kontext is a flow model, which gives it more flexibility to accomplish the tasks mentioned above. \u003c/p\u003e\n\n\n\n\u003cp\u003eFlow models learn from a continuous flow of data and define a path between noisy data and useful information. This differs from diffusion, the \u003ca href=\"https://venturebeat.com/ai/stable-diffusion-3-5-debuts-as-stability-ai-aims-to-improve-open-models-for-generating-images/\"\u003emodel architecture that underpins\u003c/a\u003e many image and video generation models from \u003ca href=\"https://stability.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eStability AI\u003c/a\u003e, \u003ca href=\"https://venturebeat.com/ai/midjourney-opens-website-to-all-users-with-25-free-ai-image-generations/\"\u003eMidJourney\u003c/a\u003e and even \u003ca href=\"https://openai.com/sora/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpenAI’s Sora\u003c/a\u003e, which “denoises” data. \u003c/p\u003e\n\n\n\n\u003cp\u003eBFL said in a blog post that the Kontext models represent an advancement to flow models.\u003c/p\u003e\n\n\n\n\u003cp\u003e“FLUX.1 Kontext models go beyond text-to-image,” the company said. “Unlike previous flow models that only allow for pure text-based generation, FLUX.1 Kontext models also understand and can create from existing images. With FLUX.1 Kontext you can modify an input image via simple text instructions, enabling flexible and instant image editing – no need for finetuning or complex editing workflows.”\u003c/p\u003e\n\n\n\n\u003cp\u003eIn the text-to-image benchmark test, BFL claimed the FLUX.1 Kontext models can compete against other models in terms of aesthetics, following prompts, realism and typography. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXfJt-sZkjkPv_UA5I1vJAKqhebsZv_qlyeefx2Wd6RorZNr2Vho1CiXNF6EpFZV-g-23EUhztTr4v_7iTni0kB_ijHieVg6Y8sYfImcsQQNqiKbh33vPPbN2miQmfihdcYBFZ0nog?key=tnY5drqW6H2UuHpGKvoC5A\" alt=\"\"/\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-generating-interest\"\u003eGenerating interest\u003c/h2\u003e\n\n\n\n\u003cp\u003eBFL \u003cspan\u003ereleased the \u003ca href=\"https://venturebeat.com/ai/black-forest-labs-releases-flux-1-1-pro-and-an-api/\" target=\"_blank\"\u003etext-to-image mod\u003c/a\u003e\u003c/span\u003e\u003ca href=\"https://venturebeat.com/ai/black-forest-labs-releases-flux-1-1-pro-and-an-api/\"\u003eel Flux 1.1 Pro in October last year. \u003c/a\u003eIt also included an API for third-party developers to integrate it into their apps.  \u003c/p\u003e\n\n\n\n\u003cp\u003eThanks to the BFL Playground, some users have already begun playing around with the Kontext models and report being impressed. \u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cdiv\u003e\n\u003cblockquote data-width=\"500\" data-dnt=\"true\"\u003e\u003cdiv lang=\"en\" dir=\"ltr\"\u003e\u003cp\u003eCan we talk about how mind-blowing it is that we can use a single image to generate headshots or edit images in less than 10 seconds with \u003ca href=\"https://twitter.com/bfl_ml?ref_src=twsrc%5Etfw\"\u003e@bfl_ml\u003c/a\u003e FLUX.1 Kontext?\u003c/p\u003e\u003cp\u003eI used the Professional Headshot model on \u003ca href=\"https://twitter.com/replicate?ref_src=twsrc%5Etfw\"\u003e@replicate\u003c/a\u003e and these aren\u0026#39;t perfect, but my real images are on the left… \u003ca href=\"https://t.co/SZfyZsuvIM\"\u003epic.twitter.com/SZfyZsuvIM\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e— Heather Cooper (@HBCoop_) \u003ca href=\"https://twitter.com/HBCoop_/status/1928164481873436760?ref_src=twsrc%5Etfw\"\u003eMay 29, 2025\u003c/a\u003e\u003c/blockquote\u003e\n\u003c/div\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003c/figure\u003e\n\n\n\n\u003cfigure\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eOf course, it still has to compete with other image models available, especially those that have been around for a few years and have continued to improve. \u003c/p\u003e\n\n\n\n\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-05-29T23:32:17Z",
  "modifiedTime": "2025-05-30T01:08:35Z"
}
