{
  "id": "07936c46-515d-47c5-a9e2-5f9085dee48d",
  "title": "How AI is Increasing Insider Threat Risk",
  "link": "https://www.inc.com/stu-sjouwerman/how-ai-is-increasing-insider-threat-risk/91187640",
  "description": "In the absence of IT governance, users may leak customer information, leading to non-compliance with data protection laws.",
  "author": "Stu Sjouwerman",
  "published": "Fri, 09 May 2025 16:45:04 -0400",
  "source": "https://www.inc.com/rss/",
  "categories": [
    "Inc. 5000"
  ],
  "byline": "Stu Sjouwerman",
  "length": 5213,
  "excerpt": "In the absence of IT governance, users may leak customer information, leading to non-compliance with data protection laws.",
  "siteName": "Inc",
  "favicon": "https://www.inc.com/_public/icons/apple-icon.png",
  "text": "The transformative power and rapid uptake of artificial intelligence have drawn users and businesses alike. By 2030, the AI market will surpass $826 billion. With the rising adoption of generative AI, Gartner reports that by next year, 30 percent of enterprises will automate at least half of their network traffic. But here comes the speed breaker. With AI tools so widely accessible, employees are bringing unsanctioned AI tools to work, such as AI chatbots, machine learning models for data analysis, and coding review assistants. According to a Microsoft study, 80 percent of employees last year were using unauthorized apps. Given that 38 percent of users exchange sensitive information with AI tools without company approval, a new threat known as shadow AI is hatching far-reaching security risks, including data exposure, inaccurate business decisions, and compliance issues. Shadow AI accelerates insider threats More employees are incorporating AI tools into their daily work routines. Marketing teams are finding the magic of ChatGPT good for automating email and social media campaigns and creating images. Finance teams are using AI data visualization tools to create patterns that provide deeper insight into company expenditures. Despite impressive outcomes, these tools are subject to shadow AI risk if organizations are unaware of their use.  Rather than pulling company-sanctioned material, a customer service team resorting to unauthorized AI chatbots to answer a customer query may betray inconsistent or misleading information, potentially sharing confidential or proprietary data.  Without altering the nature of work, shadow AI is substituting some form of human work and granting more autonomy to AI, introducing novel vulnerabilities. For example, under shadow IT, a Salesforce analyst is still performing the same underlying work. However, the same analyst using unauthorized AI tools to interpret customer behavior based on a proprietary data set can inadvertently reveal sensitive information in the process. Because of the abuse of shadow AI, most CISOs (75 percent) think insider threats are a greater risk than external attacks. In March 2024, more than a quarter (27 percent) of data employees used in AI tools was sensitive, an increase from 10.7 percent a year prior. The most prevalent type of sensitive data is customer support (16.3 percent), followed by source code (12.7 percent), R\u0026D content (10.8 percent), confidential internal communications (6.6 percent), and HR and employee records (3.9 percent). AI technology is a favorite among malicious actors, including insiders.  Secure organizations from shadow AI There is no need to compromise speed for security. Organizations can embrace innovation while reducing shadow AI risk and safeguarding valuable data. Here are four ways.   Develop an AI acceptable-use policy: ​Merely half of employees say their company’s policies concerning the use of AI are “clear,” while 57 percent admit to employing AI against company policies. Users must be informed on what kinds of information can and cannot be inputted into AI tools. Suggest grouping AI tools into categories: approved, limited use, and prohibited. Before deployment, all new AI projects should be vetted and approved by IT. The policy should be considered a living document that develops in response to new challenges and opportunities, remaining consistent with the security policies of the organization.  Set clear data handling requirements: By categorizing data and explicitly defining what types of information should not be processed by public or privately hosted AI offerings, you can minimize the risk of data exposure and implement governance. On-premises AI offerings might be used for highly sensitive data where data never crosses the company perimeter. Rather than shipping data to cloud-based AI services, capabilities can be deployed where the data is located.  Conduct ongoing awareness training: One of the best ways to mitigate shadow AI is by educating employees about AI risks and best practices. More than half (55 percent) of employees lack training on the risks of AI, and 65 percent are concerned about AI-powered cybercrime. Cybersecurity awareness training should be made a priority and supported with simulated phishing attacks to identify indicators of AI threats and help users react appropriately.  Create a secure AI culture: Shadow AI is more cultural than technological. Create a responsible AI usage culture by raising awareness of the consequences of using unauthorized AI tools. This awareness may prompt employees to seek approved alternatives or receive advice from IT before implementing new applications.  Organizations must integrate all AI systems and tools into official procedures to prevent cyber exposure and legal and compliance problems. By addressing the core risks of shadow AI with a formal AI-use policy, user training and awareness, setting clear expectations on the use of sensitive data, and establishing a clear AI culture, organizations can optimize AI and achieve a competitive advantage. The super early-rate deadline for the 2025 Inc. Power Partner Awards is Friday, May 30, at 11:59 p.m. PT. Apply now.",
  "image": "https://img-cdn.inc.com/image/upload/f_webp,q_auto,c_fit/vip/2025/05/INC-Masters-Fast-Company-publishing-2025-05-09T154324.460.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eThe transformative power and rapid uptake of artificial intelligence have drawn users and businesses alike. By 2030, the AI market will surpass \u003ca href=\"https://www.statista.com/forecasts/1474143/global-ai-market-size\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e$826 billion\u003c/a\u003e. With the rising adoption of generative AI,\u003ca href=\"https://www.gartner.com/en/newsroom/press-releases/2024-09-18-gartner-says-30-percent-of-enterprises-will-automate-more-than-half-of-their-network-activities-by-2026\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e \u003c/a\u003e\u003ca href=\"https://www.gartner.com/en/newsroom/press-releases/2024-09-18-gartner-says-30-percent-of-enterprises-will-automate-more-than-half-of-their-network-activities-by-2026\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eGartner\u003c/a\u003e reports that by next year, 30 percent of enterprises will automate at least half of their network traffic. \u003c/p\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003eBut here comes the speed breaker. With AI tools so widely accessible, employees are bringing unsanctioned AI tools to work, such as AI chatbots, machine learning models for data analysis, and coding review assistants. According to a Microsoft study,\u003ca href=\"https://learn.microsoft.com/en-us/defender-cloud-apps/tutorial-shadow-it\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e \u003c/a\u003e\u003ca href=\"https://learn.microsoft.com/en-us/defender-cloud-apps/tutorial-shadow-it\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e80 percent\u003c/a\u003e of employees last year were using unauthorized apps. Given that\u003ca href=\"https://www.infosecurity-magazine.com/news/third-employees-sharing-work-info/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e \u003c/a\u003e\u003ca href=\"https://www.infosecurity-magazine.com/news/third-employees-sharing-work-info/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e38 percent\u003c/a\u003e of users exchange sensitive information with AI tools without company approval, a new threat known as shadow AI is hatching far-reaching security risks, including data exposure, inaccurate business decisions, and compliance issues. \u003c/p\u003e\u003cp\u003e\u003cstrong\u003eShadow AI accelerates insider threats\u003c/strong\u003e \u003c/p\u003e\u003cp\u003eMore employees are incorporating AI tools into their daily work routines. Marketing teams are finding the magic of ChatGPT good for automating email and social media campaigns and creating images. Finance teams are using AI data visualization tools to create patterns that provide deeper insight into company expenditures. Despite impressive outcomes, these tools are subject to shadow AI risk if organizations are unaware of their use.  \u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003csvg width=\"28\" height=\"20\" aria-label=\"Video player icon\"\u003e\u003cuse href=\"/_public/sprite.svg?v=18#video-player\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003cp\u003e\u003cspan\u003e\u003c/span\u003e\u003cimg alt=\"Collapse icon\" loading=\"lazy\" width=\"15\" height=\"15\" decoding=\"async\" data-nimg=\"1\" srcset=\"https://www.inc.com/_next/image?url=%2F_public%2Fcollapse-icon_2x.webp\u0026amp;w=16\u0026amp;q=75 1x, https://www.inc.com/_next/image?url=%2F_public%2Fcollapse-icon_2x.webp\u0026amp;w=32\u0026amp;q=75 2x\" src=\"https://www.inc.com/_next/image?url=%2F_public%2Fcollapse-icon_2x.webp\u0026amp;w=32\u0026amp;q=75\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003eRather than pulling company-sanctioned material, a customer service team resorting to unauthorized AI chatbots to answer a customer query may betray inconsistent or misleading information, potentially sharing confidential or proprietary data.  \u003c/p\u003e\u003cp\u003eWithout altering the nature of work, shadow AI is substituting some form of human work and granting more autonomy to AI, introducing novel vulnerabilities. For example, under shadow IT, a Salesforce analyst is still performing the same underlying work. However, the same analyst using unauthorized AI tools to interpret customer behavior based on a proprietary data set can inadvertently reveal sensitive information in the process. \u003c/p\u003e\u003cp\u003eBecause of the abuse of shadow AI, most CISOs (\u003ca href=\"https://thecyberexpress.com/shadow-ai-in-2025-a-wake-up-call/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e75 percent\u003c/a\u003e) think insider threats are a greater risk than external attacks. \u003c/p\u003e\u003c/div\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003cp\u003eIn March 2024,\u003ca href=\"https://www.cyberhaven.com/blog/shadow-ai-how-employees-are-leading-the-charge-in-ai-adoption-and-putting-company-data-at-risk\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e \u003c/a\u003emore than a quarter (\u003ca href=\"https://www.cyberhaven.com/blog/shadow-ai-how-employees-are-leading-the-charge-in-ai-adoption-and-putting-company-data-at-risk\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e27 percent\u003c/a\u003e) of data employees used in AI tools was sensitive, an increase from 10.7 percent a year prior. The most prevalent type of sensitive data is customer support (16.3 percent), followed by source code (12.7 percent), R\u0026amp;D content (10.8 percent), confidential internal communications (6.6 percent), and HR and employee records (3.9 percent). AI technology is a favorite among malicious actors, including insiders.  \u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSecure organizations from shadow AI\u003c/strong\u003e \u003c/p\u003e\u003cp\u003eThere is no need to compromise speed for security. Organizations can embrace innovation while reducing shadow AI risk and safeguarding valuable data. Here are four ways.  \u003c/p\u003e\u003c/div\u003e\u003cdiv data-testid=\"content-chunk\"\u003e\u003col start=\"1\"\u003e\n\u003cli\u003e\u003cstrong\u003eDevelop an AI acceptable-use policy:\u003c/strong\u003e ​Merely half of employees say their company’s policies concerning the use of AI are “clear,” while \u003ca href=\"https://www.vktr.com/the-wire/57-concerned-about-violating-companys-ai-policies/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e57 percent\u003c/a\u003e admit to employing AI against company policies. Users must be informed on what kinds of information can and cannot be inputted into AI tools. Suggest grouping AI tools into categories: approved, limited use, and prohibited. Before deployment, all new AI projects should be vetted and approved by IT. The policy should be considered a living document that develops in response to new challenges and opportunities, remaining consistent with the security policies of the organization. \u003c/li\u003e\n\u003c/ol\u003e\u003col start=\"2\"\u003e\n\u003cli\u003e\u003cstrong\u003eSet clear data handling requirements:\u003c/strong\u003e By categorizing data and explicitly defining what types of information should not be processed by public or privately hosted AI offerings, you can minimize the risk of data exposure and implement governance. On-premises AI offerings might be used for highly sensitive data where data never crosses the company perimeter. Rather than shipping data to cloud-based AI services, capabilities can be deployed where the data is located. \u003c/li\u003e\n\u003c/ol\u003e\u003col start=\"3\"\u003e\n\u003cli\u003e\u003cstrong\u003eConduct ongoing awareness training:\u003c/strong\u003e One of the best ways to mitigate shadow AI is by educating employees about AI risks and best practices. More than half \u003ca href=\"https://www.forbes.com/sites/torconstantino/2024/10/21/55-of-employees-using-ai-at-work-have-no-training-on-its-risks/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e(\u003c/a\u003e\u003ca href=\"https://www.staysafeonline.org/press/study-less-than-half-of-ai-users-trained-on-security-and-privacy-risks\" target=\"_blank\" rel=\"noreferrer noopener\"\u003e55 percent\u003c/a\u003e) of employees lack training on the risks of AI, and 65 percent are concerned about AI-powered cybercrime. Cybersecurity awareness training should be made a priority and supported with simulated phishing attacks to identify indicators of AI threats and help users react appropriately. \u003c/li\u003e\n\u003c/ol\u003e\u003col start=\"4\"\u003e\n\u003cli\u003e\u003cstrong\u003eCreate a secure AI culture: \u003c/strong\u003eShadow AI is more cultural than technological. Create a responsible AI usage culture by raising awareness of the consequences of using unauthorized AI tools. This awareness may prompt employees to seek approved alternatives or receive advice from IT before implementing new applications. \u003c/li\u003e\n\u003c/ol\u003e\u003cp\u003eOrganizations must integrate all AI systems and tools into official procedures to prevent cyber exposure and legal and compliance problems. By addressing the core risks of shadow AI with a formal AI-use policy, user training and awareness, setting clear expectations on the use of sensitive data, and establishing a clear AI culture, organizations can optimize AI and achieve a competitive advantage. \u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003cp\u003e\u003cem\u003eThe super early-rate deadline for the 2025 \u003ca href=\"https://incpowerpartners.secure-platform.com/a\"\u003eInc. Power Partner Awards\u003c/a\u003e is Friday, May 30, at 11:59 p.m. PT. \u003ca href=\"https://incpowerpartners.secure-platform.com/a\"\u003eApply now\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2025-05-09T20:45:04Z",
  "modifiedTime": "2025-05-09T20:49:53Z"
}
