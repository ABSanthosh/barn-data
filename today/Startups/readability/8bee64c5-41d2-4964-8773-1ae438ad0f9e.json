{
  "id": "8bee64c5-41d2-4964-8773-1ae438ad0f9e",
  "title": "Alibaba researchers unveil Marco-o1, an LLM with advanced reasoning capabilities",
  "link": "https://venturebeat.com/ai/alibaba-researchers-unveil-marco-o1-an-llm-with-advanced-reasoning-capabilities/",
  "description": "The model uses more cycles during inference to generate more tokens and review responses, improving its performance on reasoning tasks.",
  "author": "Ben Dickson",
  "published": "Wed, 27 Nov 2024 23:26:11 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI research",
    "AI, ML and Deep Learning",
    "alibaba",
    "category-/Science",
    "chain of thought reasoning",
    "Conversational AI",
    "Deepseek",
    "Generative AI",
    "large language models",
    "NLP",
    "OpenAI"
  ],
  "byline": "Ben Dickson",
  "length": 6437,
  "excerpt": "The model uses more cycles during inference to generate more tokens and review responses, improving its performance on reasoning tasks.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "November 27, 2024 3:26 PM VentureBeat/Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More The recent release of OpenAI o1 has brought great attention to large reasoning models (LRMs), and is inspiring new models aimed at solving complex problems classic language models often struggle with. Building on the success of o1 and the concept of LRMs, researchers at Alibaba have introduced Marco-o1, which enhances reasoning capabilities and tackles problems with open-ended solutions where clear standards and quantifiable rewards are absent. OpenAI o1 uses “inference-time scaling” to improve the model’s reasoning ability by giving it “time to think.” Basically, the model uses more compute cycles during inference to generate more tokens and review its responses, which improves its performance on tasks that require reasoning. o1 is renowned for its impressive reasoning capabilities, especially in tasks with standard answers such as mathematics, physics and coding.  However, many applications involve open-ended problems that lack clear solutions and quantifiable rewards. “We aimed to push the boundaries of LLMs even further, enhancing their reasoning abilities to tackle complex, real-world challenges,” Alibaba researchers write. Marco-o1 is a fine-tuned version of Alibaba’s Qwen2-7B-Instruct that integrates advanced techniques such as chain-of-thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS) and reasoning action strategies. The researchers trained Marco-o1 on a combination of datasets, including the Open-O1 CoT dataset; the Marco-o1 CoT dataset, a synthetic dataset generated using MCTS; and the Marco-o1 Instruction dataset, a collection of custom instruction-following data for reasoning tasks. Marco-o1 uses CoT and MCTS to reason about tasks (source: arXiv) MCTS is a search algorithm that has proven to be effective in complex problem-solving scenarios. It intelligently explores different solution paths by repeatedly sampling possibilities, simulating outcomes and gradually building a decision tree. It has proven to be very effective in complex AI problems, such as beating the game Go. Marco-o1 leverages MCTS to explore multiple reasoning paths as it generates response tokens. The model uses the confidence scores of candidate response tokens to build its decision tree and explore different branches. This enables the model to consider a wider range of possibilities and arrive at more informed and nuanced conclusions, especially in scenarios with open-ended solutions. The researchers also introduced a flexible reasoning action strategy that allows them to adjust the granularity of MCTS steps by defining the number of tokens generated at each node in the tree. This provides a tradeoff between accuracy and computational cost, giving users the flexibility to balance performance and efficiency. Another key innovation in Marco-o1 is the introduction of a reflection mechanism. During the reasoning process, the model periodically prompts itself with the phrase, “Wait! Maybe I made some mistakes! I need to rethink from scratch.” This causes the model to re-evaluate its reasoning steps, identify potential errors and refine its thought process. “This approach allows the model to act as its own critic, identifying potential errors in its reasoning,” the researchers write. “By explicitly prompting the model to question its initial conclusions, we encourage it to re-express and refine its thought process.” To evaluate the performance of Marco-o1, the researchers conducted experiments on several tasks, including the MGSM benchmark, a dataset for multi-lingual grade school math problems. Marco-o1 significantly outperformed the base Qwen2-7B model, particularly when the MCTS component was adjusted for single-token granularity.  Different versions of Marco-o1 vs base model (source: arXiv) However, the primary objective of Marco-o1 was to address the challenges of reasoning in open-ended scenarios. To this end, the researchers tested the model on translating colloquial and slang expressions, a task that requires understanding subtle nuances of language, culture and context. The experiments showed that Marco-o1 was able to capture and translate these expressions more effectively than traditional translation tools. For instance, the model correctly translated a colloquial expression in Chinese, which literally means, “This shoe offers a stepping-on-poop sensation”, into the English equivalent, “This shoe has a comfortable sole.” The reasoning chain of the model shows how it evaluates different potential meanings and arrives at the correct translation. This paradigm can prove to be useful for tasks such as product design and strategy, which require deep and contextual understanding and do not have well-defined benchmarks and metrics. Example of reasoning chain for translation task (source: arXiv) A new wave of reasoning models Since the release of o1, AI labs are racing to release reasoning models. Last week, Chinese AI lab DeepSeek released R1-Lite-Preview, its o1 competitor, which is currently only available through the company’s online chat interface. R1-Lite-Preview reportedly beats o1 on several key benchmarks. The open source community is also catching up with the private model market, releasing models and datasets that take advantage of inference-time scaling laws. The Alibaba team released Marco-o1 on Hugging Face along with a partial reasoning dataset that researchers can use to train their own reasoning models. Another recently released model is LLaVA-o1, developed by researchers from multiple universities in China, which brings the inference-time reasoning paradigm to open-source vision language models (VLMs).  The release of these models comes amidst uncertainty about the future of model scaling laws. Various reports indicate that the returns on training larger models are diminishing and might be hitting a wall. But what’s for certain is that we are just beginning to explore the possibilities of inference-time scaling. VB Daily Stay in the know! Get the latest news in your inbox daily By subscribing, you agree to VentureBeat's Terms of Service. Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/11/nuneybits_Futuristic_brain-shaped_circuitry_intricate_network_o_19542b20-90ea-40fe-945a-71f5da4d8fdc-transformed.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-11-27T23:26:11+00:00\" datetime=\"2024-11-27T23:26:11+00:00\"\u003eNovember 27, 2024 3:26 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"420\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/nuneybits_Futuristic_brain-shaped_circuitry_intricate_network_o_19542b20-90ea-40fe-945a-71f5da4d8fdc-transformed.webp?w=750\" alt=\"VentureBeat/Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eVentureBeat/Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThe recent release of \u003ca href=\"https://venturebeat.com/ai/forget-gpt-5-openai-launches-new-ai-model-family-o1-claiming-phd-level-performance/\"\u003eOpenAI o1\u003c/a\u003e has brought great attention to large reasoning models (LRMs), and is inspiring new models aimed at solving complex problems classic language models often struggle with. Building on the success of o1 and the concept of LRMs, researchers at Alibaba have introduced \u003ca href=\"https://arxiv.org/abs/2411.14405\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMarco-o1\u003c/a\u003e, which enhances reasoning capabilities and tackles problems with open-ended solutions where clear standards and quantifiable rewards are absent.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI o1 uses “inference-time scaling” to improve the model’s reasoning ability by giving it “time to think.” Basically, the model uses more compute cycles during inference to generate more tokens and review its responses, which improves its performance on tasks that require reasoning. o1 is renowned for its impressive reasoning capabilities, especially in tasks with standard answers such as mathematics, physics and coding. \u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, many applications involve open-ended problems that lack clear solutions and quantifiable rewards. “We aimed to push the boundaries of LLMs even further, enhancing their reasoning abilities to tackle complex, real-world challenges,” Alibaba researchers write.\u003c/p\u003e\n\n\n\n\u003cp\u003eMarco-o1 is a fine-tuned version of Alibaba’s \u003ca href=\"https://venturebeat.com/ai/alibaba-claims-no-1-spot-in-ai-math-models-with-qwen2-math/\"\u003eQwen2-7B-Instruct\u003c/a\u003e that integrates advanced techniques such as \u003ca href=\"https://venturebeat.com/ai/improving-decision-making-in-llms-two-contemporary-approaches/\"\u003echain-of-thought \u003c/a\u003e(CoT) fine-tuning, \u003ca href=\"https://en.wikipedia.org/wiki/Monte_Carlo_tree_search\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMonte Carlo Tree Search\u003c/a\u003e (MCTS) and reasoning action strategies.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe researchers trained Marco-o1 on a combination of datasets, including the \u003ca href=\"https://opensource-o1.github.io/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eOpen-O1\u003c/a\u003e CoT dataset; the Marco-o1 CoT dataset, a synthetic dataset generated using MCTS; and the Marco-o1 Instruction dataset, a collection of custom instruction-following data for reasoning tasks.\u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1000\" height=\"807\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?w=743\" alt=\"Marco-o1\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg 1000w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=300,242 300w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=768,620 768w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=743,600 743w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=400,323 400w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=750,605 750w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=578,466 578w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1.jpg?resize=930,751 930w\" sizes=\"(max-width: 1000px) 100vw, 1000px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eMarco-o1 uses CoT and MCTS to reason about tasks (source: arXiv)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003eMCTS is a search algorithm that has proven to be effective in complex problem-solving scenarios. It intelligently explores different solution paths by repeatedly sampling possibilities, simulating outcomes and gradually building a decision tree. It has proven to be very effective in complex AI problems, such as beating the game Go.\u003c/p\u003e\n\n\n\n\u003cp\u003eMarco-o1 leverages MCTS to explore multiple reasoning paths as it generates response tokens. The model uses the confidence scores of candidate response tokens to build its decision tree and explore different branches. This enables the model to consider a wider range of possibilities and arrive at more informed and nuanced conclusions, especially in scenarios with open-ended solutions. The researchers also introduced a flexible reasoning action strategy that allows them to adjust the granularity of MCTS steps by defining the number of tokens generated at each node in the tree. This provides a tradeoff between accuracy and computational cost, giving users the flexibility to balance performance and efficiency.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnother key innovation in Marco-o1 is the introduction of a reflection mechanism. During the reasoning process, the model periodically prompts itself with the phrase, “Wait! Maybe I made some mistakes! I need to rethink from scratch.” This causes the model to re-evaluate its reasoning steps, identify potential errors and refine its thought process.\u003c/p\u003e\n\n\n\n\u003cp\u003e“This approach allows the model to act as its own critic, identifying potential errors in its reasoning,” the researchers write. “By explicitly prompting the model to question its initial conclusions, we encourage it to re-express and refine its thought process.”\u003c/p\u003e\n\n\n\n\u003cp\u003eTo evaluate the performance of Marco-o1, the researchers conducted experiments on several tasks, including the MGSM benchmark, a dataset for multi-lingual grade school math problems. Marco-o1 significantly outperformed the base Qwen2-7B model, particularly when the MCTS component was adjusted for single-token granularity. \u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1000\" height=\"478\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?w=800\" alt=\"Marco-o1 results\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg 1000w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=300,143 300w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=768,367 768w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=800,382 800w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=400,191 400w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=750,359 750w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=578,276 578w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-results.jpg?resize=930,445 930w\" sizes=\"(max-width: 1000px) 100vw, 1000px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eDifferent versions of Marco-o1 vs base model (source: arXiv)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003eHowever, the primary objective of Marco-o1 was to address the challenges of reasoning in open-ended scenarios. To this end, the researchers tested the model on translating colloquial and slang expressions, a task that requires understanding subtle nuances of language, culture and context. The experiments showed that Marco-o1 was able to capture and translate these expressions more effectively than traditional translation tools. For instance, the model correctly translated a colloquial expression in Chinese, which literally means, “This shoe offers a stepping-on-poop sensation”, into the English equivalent, “This shoe has a comfortable sole.” The reasoning chain of the model shows how it evaluates different potential meanings and arrives at the correct translation.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis paradigm can prove to be useful for tasks such as product design and strategy, which require deep and contextual understanding and do not have well-defined benchmarks and metrics.\u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1458\" height=\"1330\" src=\"https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?w=658\" alt=\"Marco-o1 translation\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg 1458w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=300,274 300w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=768,701 768w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=658,600 658w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=400,365 400w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=750,684 750w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=578,527 578w, https://venturebeat.com/wp-content/uploads/2024/11/Marco-o1-translation.jpg?resize=930,848 930w\" sizes=\"(max-width: 1458px) 100vw, 1458px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eExample of reasoning chain for translation task (source: arXiv)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003ch2 id=\"h-a-new-wave-of-reasoning-models\"\u003eA new wave of reasoning models\u003c/h2\u003e\n\n\n\n\u003cp\u003eSince the release of o1, AI labs are racing to release reasoning models. Last week, Chinese AI lab DeepSeek released \u003ca href=\"https://venturebeat.com/ai/deepseeks-first-reasoning-model-r1-lite-preview-turns-heads-beating-openai-o1-performance/\"\u003eR1-Lite-Preview\u003c/a\u003e, its o1 competitor, which is currently only available through the company’s online chat interface. R1-Lite-Preview reportedly beats o1 on several key benchmarks.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe open source community is also catching up with the private model market, releasing models and datasets that take advantage of inference-time scaling laws. The Alibaba team released \u003ca href=\"https://huggingface.co/AIDC-AI/Marco-o1\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMarco-o1\u003c/a\u003e on Hugging Face along with a \u003ca href=\"https://github.com/AIDC-AI/Marco-o1/blob/main/data/CoT_demo.json\" target=\"_blank\" rel=\"noreferrer noopener\"\u003epartial reasoning dataset\u003c/a\u003e that researchers can use to train their own reasoning models. Another recently released model is \u003ca href=\"https://venturebeat.com/ai/chinese-researchers-unveil-llava-o1-to-challenge-openais-o1-model/\"\u003eLLaVA-o1\u003c/a\u003e, developed by researchers from multiple universities in China, which brings the inference-time reasoning paradigm to open-source vision language models (VLMs). \u003c/p\u003e\n\n\n\n\u003cp\u003eThe release of these models comes amidst uncertainty about the future of model scaling laws. Various reports indicate that the returns on training larger models are diminishing and might be hitting a wall. But what’s for certain is that we are just beginning to explore the possibilities of inference-time scaling.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eVB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eStay in the know! Get the latest news in your inbox daily\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eBy subscribing, you agree to VentureBeat\u0026#39;s \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003eTerms of Service.\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2024-11-27T23:26:11Z",
  "modifiedTime": "2024-11-27T23:26:58Z"
}
