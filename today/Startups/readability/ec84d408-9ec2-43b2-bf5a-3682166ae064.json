{
  "id": "ec84d408-9ec2-43b2-bf5a-3682166ae064",
  "title": "Five breakthroughs that make OpenAI’s o3 a turning point for AI — and one big challenge",
  "link": "https://venturebeat.com/ai/five-breakthroughs-that-make-openais-o3-a-turning-point-for-ai-and-one-big-challenge/",
  "description": "OpenAI’s o3 tackles specific hurdles in reasoning and adaptability that have long stymied large language models. At the same time, it exposes challenges, including the high costs and efficiency bottlenecks inherent in pushing these systems to their limits. This article will explore five key innovations behind the o3 model, many of which are underpinned by advancements in reinforcement learning (RL), to unpack what this means for the future of AI as we move into 2025.",
  "author": "Matt Marshall",
  "published": "Sun, 29 Dec 2024 16:17:58 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Automation",
    "Business",
    "Data Infrastructure",
    "Enterprise Analytics",
    "Programming \u0026 Development",
    "category-/Computers \u0026 Electronics/Programming",
    "category-/Science/Computer Science",
    "francois chollet",
    "Nat McAleese",
    "o3",
    "OpenAI"
  ],
  "byline": "Matt Marshall",
  "length": 10841,
  "excerpt": "OpenAI’s o3 tackles specific hurdles in reasoning and adaptability that have long stymied large language models. At the same time, it exposes challenges, including the high costs and efficiency bottlenecks inherent in pushing these systems to their limits. This article will explore five key innovations behind the o3 model, many of which are underpinned by advancements in reinforcement learning (RL), to unpack what this means for the future of AI as we move into 2025.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "December 29, 2024 8:17 AM Image Credit: VentureBeat via ChatGPT Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More The end of the year 2024 has brought reckonings for artificial intelligence, as industry insiders feared progress toward even more intelligent AI is slowing down. But OpenAI’s o3 model, announced just last week, has sparked a fresh wave of excitement and debate, and suggests big improvements are still to come in 2025 and beyond. This model, announced for safety testing among researchers, but not yet released publicly, achieved an impressive score on the important ARC metric. The benchmark was created by François Chollet, a renowned AI researcher and creator of the Keras deep learning framework, and is specifically designed to measure a model’s ability to handle novel, intelligent tasks. As such, it provides a meaningful gauge of progress toward truly intelligent AI systems.Notably, o3 scored 75.7% on the ARC benchmark under standard compute conditions and 87.5% using high compute, significantly surpassing previous state-of-the-art results, such as the 53% scored by Claude 3.5. This achievement by o3 represents a surprising advancement, according to Chollet, who had been a critic of the ability of large language models (LLMs) to achieve this sort of intelligence. It highlights innovations that could accelerate progress toward superior intelligence, whether we call it artificial general intelligence (AGI) or not. AGI is a hyped term, and ill-defined, but it signals a goal: intelligence capable of adapting to novel challenges or questions in ways that surpass human abilities. OpenAI’s o3 tackles specific hurdles in reasoning and adaptability that have long stymied large language models. At the same time, it exposes challenges, including the high costs and efficiency bottlenecks inherent in pushing these systems to their limits. This article will explore five key innovations behind the o3 model, many of which are underpinned by advancements in reinforcement learning (RL). It will draw on insights from industry leaders, OpenAI’s claims, and above all Chollet’s important analysis, to unpack what this breakthrough means for the future of AI as we move into 2025. The five core innovations of o3 1. “Program synthesis” for task adaptation OpenAI’s o3 model introduces a new capability called “program synthesis,” which enables it to dynamically combine things that it learned during pre-training—specific patterns, algorithms, or methods—into new configurations. These things might include mathematical operations, code snippets, or logical procedures that the model has encountered and generalized during its extensive training on diverse datasets. Most significantly, program synthesis allows o3 to address tasks it has never directly seen in training, such as solving advanced coding challenges or tackling novel logic puzzles that require reasoning beyond rote application of learned information. François Chollet describes program synthesis as a system’s ability to recombine known tools in innovative ways—like a chef crafting a unique dish using familiar ingredients. This feature marks a departure from earlier models, which primarily retrieve and apply pre-learned knowledge without reconfiguration — and it’s also one that Chollet had advocated for months ago as the only viable way forward to better intelligence.  2. Natural language program search At the heart of o3’s adaptability is its use of Chains of Thought (CoTs) and a sophisticated search process that takes place during inference—when the model is actively generating answers in a real-world or deployed setting. These CoTs are step-by-step natural language instructions the model generates to explore solutions. Guided by an evaluator model, o3 actively generates multiple solution paths and evaluates them to determine the most promising option. This approach mirrors human problem-solving, where we brainstorm different methods before choosing the best fit. For example, in mathematical reasoning tasks, o3 generates and evaluates alternative strategies to arrive at accurate solutions. Competitors like Anthropic and Google have experimented with similar approaches, but OpenAI’s implementation sets a new standard. 3. Evaluator model: A new kind of reasoning O3 actively generates multiple solution paths during inference, evaluating each with the help of an integrated evaluator model to determine the most promising option. By training the evaluator on expert-labeled data, OpenAI ensures that o3 develops a strong capacity to reason through complex, multi-step problems. This feature enables the model to act as a judge of its own reasoning, moving large language models closer to being able to “think” rather than simply respond. 4. Executing Its own programs One of the most groundbreaking features of o3 is its ability to execute its own Chains of Thought (CoTs) as tools for adaptive problem-solving. Traditionally, CoTs have been used as step-by-step reasoning frameworks to solve specific problems. OpenAI’s o3 extends this concept by leveraging CoTs as reusable building blocks, allowing the model to approach novel challenges with greater adaptability. Over time, these CoTs become structured records of problem-solving strategies, akin to how humans document and refine their learning through experience. This ability demonstrates how o3 is pushing the frontier in adaptive reasoning. According to OpenAI engineer Nat McAleese, o3’s performance on unseen programming challenges, such as achieving a CodeForces rating above 2700, showcases its innovative use of CoTs to rival top competitive programmers. This 2700 rating places the model at “Grandmaster” level, among the top echelon of competitive programmers globally. 5. Deep learning-guided program search O3 leverages a deep learning-driven approach during inference to evaluate and refine potential solutions to complex problems. This process involves generating multiple solution paths and using patterns learned during training to assess their viability. François Chollet and other experts have noted that this reliance on ‘indirect evaluations’—where solutions are judged based on internal metrics rather than tested in real-world scenarios—can limit the model’s robustness when applied to unpredictable or enterprise-specific contexts. Additionally, o3’s dependence on expert-labeled datasets for training its evaluator model raises concerns about scalability. While these datasets enhance precision, they also require significant human oversight, which can restrict the system’s adaptability and cost-efficiency. Chollet highlights that these trade-offs illustrate the challenges of scaling reasoning systems beyond controlled benchmarks like ARC-AGI. Ultimately, this approach demonstrates both the potential and limitations of integrating deep learning techniques with programmatic problem-solving. While o3’s innovations showcase progress, they also underscore the complexities of building truly generalizable AI systems. The big challenge to o3 OpenAI’s o3 model achieves impressive results but at significant computational cost, consuming millions of tokens per task — and this costly approach is model’s biggest challenge. François Chollet, Nat McAleese, and others highlight concerns about the economic feasibility of such models, emphasizing the need for innovations that balance performance with affordability. The o3 release has sparked attention across the AI community. Competitors such as Google with Gemini 2 and Chinese firms like DeepSeek 3 are also advancing, making direct comparisons challenging until these models are more widely tested. Opinions on o3 are divided: some laud its technical strides, while others cite high costs and a lack of transparency, suggesting its real value will only become clear with broader testing. One of the biggest critiques came from Google DeepMind’s Denny Zhou, who implicitly attacked the model’s reliance on reinforcement learning (RL) scaling and search mechanisms as a potential “dead end,” arguing instead that a model should be able to learn to reason from simpler fine-tuning processes. What this means for enterprise AI Whether or not it represents the perfect direction for further innovation, for enterprises, o3’s new-found adaptability shows that AI will in one way or another continue to transform industries, from customer service and scientific research, in the future. Industry players will need some time to digest what o3 has delivered here. For enterprises concerned about o3’s high computational costs, OpenAI’s upcoming release of the scaled-down “o3-mini” version of the model provides a potential alternative. While it sacrifices some of the full model’s capabilities, o3-mini promises a more affordable option for businesses to experiment with — retaining much of the core innovation while significantly reducing test-time compute requirements. It may be some time before enterprise companies can get their hands on the o3 model. OpenAI says the o3-mini is expected to launch by the end of January. The full o3 release will follow after, though the timelines depend on feedback and insights gained during the current safety testing phase. Enterprise companies will be well advised to test it out. They’ll want to ground the model with their data and use cases and see how it really works. But in the mean time, they can already use the many other competent models that are already out and well tested, including the flagship o4 model and other competing models — many of which are already robust enough for building intelligent, tailored applications that deliver practical value. Indeed, next year, we’ll be operating on two gears. The first is in achieving practical value from AI applications, and fleshing out what models can do with AI agents, and other innovations already achieved. The second will be sitting back with the popcorn and seeing how the intelligence race plays out — and any progress will just be icing on the cake that has already been delivered. For more on o3’s innovations, watch the full YouTube discussion between myself and Sam Witteveen below, and follow VentureBeat for ongoing coverage of AI advancements. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/12/DALL·E-2024-12-29-07.53.04-A-clean-and-modern-vector-illustration-representing-artificial-intelligence-breakthroughs.-The-design-features-an-abstract-humanoid-AI-figure-with-int.webp?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-12-29T16:17:58+00:00\" datetime=\"2024-12-29T16:17:58+00:00\"\u003eDecember 29, 2024 8:17 AM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"750\" height=\"429\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/DALL·E-2024-12-29-07.53.04-A-clean-and-modern-vector-illustration-representing-artificial-intelligence-breakthroughs.-The-design-features-an-abstract-humanoid-AI-figure-with-int.webp?w=750\" alt=\"\"/\u003e\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u003cem\u003eImage Credit: VentureBeat via ChatGPT\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eThe end of the year 2024 has brought reckonings for artificial intelligence, as industry insiders feared progress toward even more intelligent AI is slowing down. But OpenAI’s o3 model, \u003ca href=\"https://venturebeat.com/ai/openai-confirms-new-frontier-models-o3-and-o3-mini/\"\u003eannounced just last week\u003c/a\u003e, has sparked a \u003ca href=\"https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning/\"\u003efresh wave of excitement and debate\u003c/a\u003e, and suggests big improvements are still to come in 2025 and beyond.\u003c/p\u003e\n\n\n\n\u003cdiv\u003e\u003cp\u003eThis model, announced for safety testing among researchers, but not yet released publicly, \u003ca href=\"https://arcprize.org/blog/oai-o3-pub-breakthrough\"\u003eachieved an impressive score on the important ARC metric\u003c/a\u003e. The benchmark was created by François Chollet, a renowned AI researcher and creator of the Keras deep learning framework, and is specifically designed to measure a model’s ability to handle novel, intelligent tasks. As such, it provides a meaningful gauge of progress toward truly intelligent AI systems.\u003c/p\u003e\u003cp\u003eNotably, o3 scored 75.7% on the ARC benchmark under standard compute conditions and 87.5% using high compute, significantly surpassing previous state-of-the-art results, such as \u003ca href=\"https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi\"\u003ethe 53% scored by Claude 3.5\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\n\n\n\u003cp\u003eThis achievement by o3 represents a surprising advancement, according to Chollet, who had \u003ca href=\"https://www.youtube.com/watch?v=UakqL6Pj9xo\"\u003ebeen a critic\u003c/a\u003e of the ability of large language models (LLMs) to achieve this sort of intelligence. It highlights innovations that could accelerate progress toward superior intelligence, whether we call it artificial general intelligence (AGI) or not.\u003c/p\u003e\n\n\n\n\u003cp\u003eAGI is a hyped term, and ill-defined, but it signals a goal: intelligence capable of adapting to novel challenges or questions in ways that surpass human abilities.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI’s o3 tackles specific hurdles in reasoning and adaptability that have long stymied large language models. At the same time, it exposes challenges, including the high costs and efficiency bottlenecks inherent in pushing these systems to their limits. This article will explore five key innovations behind the o3 model, many of which are underpinned by advancements in reinforcement learning (RL). It will draw on insights from industry leaders, \u003ca href=\"https://www.youtube.com/watch?v=SKBG1sqdyIU\"\u003eOpenAI’s claims\u003c/a\u003e, and above all \u003ca href=\"https://arcprize.org/blog/oai-o3-pub-breakthrough\"\u003eChollet’s important analysis\u003c/a\u003e, to unpack what this breakthrough means for the future of AI as we move into 2025.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-five-core-innovations-of-o3\"\u003eThe five core innovations of o3\u003c/h2\u003e\n\n\n\n\u003ch3 id=\"h-1-program-synthesis-for-task-adaptation\"\u003e1. “Program synthesis” for task adaptation\u003c/h3\u003e\n\n\n\n\u003cp\u003eOpenAI’s o3 model introduces a new capability called “program synthesis,” which enables it to dynamically combine things that it learned during pre-training—specific patterns, algorithms, or methods—into new configurations. These things might include mathematical operations, code snippets, or logical procedures that the model has encountered and generalized during its extensive training on diverse datasets. Most significantly, program synthesis allows o3 to address tasks it has never directly seen in training, such as solving advanced coding challenges or tackling novel logic puzzles that require reasoning beyond rote application of learned information. François Chollet describes program synthesis as a system’s ability to recombine known tools in innovative ways—like a chef crafting a unique dish using familiar ingredients. This feature marks a departure from earlier models, which primarily retrieve and apply pre-learned knowledge without reconfiguration — and it’s also one that Chollet had advocated for months ago as the only viable way forward to better intelligence. \u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-2-natural-language-program-search\"\u003e2. Natural language program search\u003c/h3\u003e\n\n\n\n\u003cp\u003eAt the heart of o3’s adaptability is its use of Chains of Thought (CoTs) and a sophisticated search process that takes place during inference—when the model is actively generating answers in a real-world or deployed setting. These CoTs are step-by-step natural language instructions the model generates to explore solutions. Guided by an evaluator model, o3 actively generates multiple solution paths and evaluates them to determine the most promising option. This approach mirrors human problem-solving, where we brainstorm different methods before choosing the best fit. For example, in mathematical reasoning tasks, o3 generates and evaluates alternative strategies to arrive at accurate solutions. Competitors like Anthropic and Google have experimented with similar approaches, but OpenAI’s implementation sets a new standard.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-3-evaluator-model-a-new-kind-of-reasoning\"\u003e3. Evaluator model: A new kind of reasoning\u003c/h3\u003e\n\n\n\n\u003cp\u003eO3 actively generates multiple solution paths during inference, evaluating each with the help of an integrated evaluator model to determine the most promising option. By training the evaluator on expert-labeled data, OpenAI ensures that o3 develops a strong capacity to reason through complex, multi-step problems. This feature enables the model to act as a judge of its own reasoning, moving large language models closer to being able to “think” rather than simply respond.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-4-executing-its-own-programs\"\u003e4. Executing Its own programs\u003c/h3\u003e\n\n\n\n\u003cp\u003eOne of the most groundbreaking features of o3 is its ability to execute its own Chains of Thought (CoTs) as tools for adaptive problem-solving. Traditionally, CoTs have been used as step-by-step reasoning frameworks to solve specific problems. OpenAI’s o3 extends this concept by leveraging CoTs as reusable building blocks, allowing the model to approach novel challenges with greater adaptability. Over time, these CoTs become structured records of problem-solving strategies, akin to how humans document and refine their learning through experience. This ability demonstrates how o3 is pushing the frontier in adaptive reasoning. According to \u003ca href=\"https://x.com/__nmca__/status/1870170101091008860\"\u003eOpenAI engineer Nat McAleese\u003c/a\u003e, o3’s performance on unseen programming challenges, such as achieving a CodeForces rating above 2700, showcases its innovative use of CoTs to rival top competitive programmers. This 2700 rating places the model at “Grandmaster” level, among the top echelon of competitive programmers globally.\u003c/p\u003e\n\n\n\n\u003ch3 id=\"h-5-deep-learning-guided-program-search\"\u003e5. Deep learning-guided program search\u003c/h3\u003e\n\n\n\n\u003cp\u003eO3 leverages a deep learning-driven approach during inference to evaluate and refine potential solutions to complex problems. This process involves generating multiple solution paths and using patterns learned during training to assess their viability. François Chollet and other experts have noted that this reliance on ‘indirect evaluations’—where solutions are judged based on internal metrics rather than tested in real-world scenarios—can limit the model’s robustness when applied to unpredictable or enterprise-specific contexts.\u003c/p\u003e\n\n\n\n\u003cp\u003eAdditionally, o3’s dependence on expert-labeled datasets for training its evaluator model raises concerns about scalability. While these datasets enhance precision, they also require significant human oversight, which can restrict the system’s adaptability and cost-efficiency. Chollet highlights that these trade-offs illustrate the challenges of scaling reasoning systems beyond controlled benchmarks like ARC-AGI.\u003c/p\u003e\n\n\n\n\u003cp\u003eUltimately, this approach demonstrates both the potential and limitations of integrating deep learning techniques with programmatic problem-solving. While o3’s innovations showcase progress, they also underscore the complexities of building truly generalizable AI systems.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-big-challenge-to-o3\"\u003eThe big\u003cstrong\u003e challenge to o3 \u003c/strong\u003e\u003c/h2\u003e\n\n\n\n\u003cp\u003eOpenAI’s o3 model achieves impressive results but at significant computational cost, consuming millions of tokens per task — and this costly approach is model’s biggest challenge. François Chollet, Nat McAleese, and others highlight concerns about the economic feasibility of such models, emphasizing the need for innovations that balance performance with affordability.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe o3 release has sparked attention across the AI community. Competitors such as \u003ca href=\"https://venturebeat.com/ai/gemini-2-0-flash-ushers-in-a-new-era-of-real-time-multimodal-ai/\"\u003eGoogle with Gemini 2\u003c/a\u003e and \u003ca href=\"https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/\"\u003eChinese firms like DeepSeek 3\u003c/a\u003e are also advancing, making direct comparisons challenging until these models are more widely tested.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpinions on o3 are divided: some laud its technical strides, while others cite high costs and a lack of transparency, suggesting its real value will only become clear with broader testing. One of the biggest critiques came from Google DeepMind’s Denny Zhou, who implicitly attacked the model’s reliance on reinforcement learning (RL) scaling and search mechanisms \u003ca href=\"https://x.com/denny_zhou/status/1870553370093830367\"\u003eas a potential “dead end\u003c/a\u003e,” arguing instead that a model should be able to learn to reason from \u003ca href=\"https://arxiv.org/abs/2203.14465\"\u003esimpler fine-tuning\u003c/a\u003e processes. \u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-what-this-means-for-enterprise-ai\"\u003eWhat this means for enterprise AI\u003c/h2\u003e\n\n\n\n\u003cp\u003eWhether or not it represents the perfect direction for further innovation, for enterprises, o3’s new-found adaptability shows that AI will in one way or another continue to transform industries, from customer service and scientific research, in the future. \u003c/p\u003e\n\n\n\n\u003cp\u003eIndustry players will need some time to digest what o3 has delivered here. For enterprises concerned about o3’s high computational costs, OpenAI’s upcoming release of the scaled-down “o3-mini” version of the model provides a potential alternative. While it sacrifices some of the full model’s capabilities, o3-mini promises a more affordable option for businesses to experiment with — retaining much of the core innovation while significantly reducing test-time compute requirements.\u003c/p\u003e\n\n\n\n\u003cp\u003eIt may be some time before enterprise companies can get their hands on the o3 model. OpenAI says the o3-mini is expected to launch by the end of January. The full o3 release will follow after, though the timelines depend on feedback and insights gained during the current safety testing phase. Enterprise companies will be well advised to test it out. They’ll want to ground the model with their data and use cases and see how it really works.  \u003c/p\u003e\n\n\n\n\u003cp\u003eBut in the mean time, they can already use the many other competent models that are already out and well tested, including the flagship o4 model and other competing models — many of which are already robust enough for building intelligent, tailored applications that deliver practical value.\u003c/p\u003e\n\n\n\n\u003cp\u003eIndeed, next year, we’ll be operating on two gears. The first is in achieving practical value from AI applications, and fleshing out what models can do with AI agents, and other innovations already achieved. The second will be sitting back with the popcorn and seeing how the intelligence race plays out — and any progress will just be icing on the cake that has already been delivered.\u003c/p\u003e\n\n\n\n\u003cp\u003eFor more on o3’s innovations, \u003ca href=\"https://www.youtube.com/watch?v=6t6zbNISyoc\"\u003ewatch the full YouTube discussion between myself and Sam Witteveen\u003c/a\u003e below, and follow VentureBeat for ongoing coverage of AI advancements.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cp\u003e\n\u003ciframe title=\"OpenAI o3: Five Game-Changing Innovations You Need to Know\" width=\"500\" height=\"281\" src=\"https://www.youtube.com/embed/6t6zbNISyoc?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\n\u003c/p\u003e\u003c/figure\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\u003cp\u003e\u003cimg src=\"https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png\" alt=\"\"/\u003e\n\t\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "12 min read",
  "publishedTime": "2024-12-29T16:17:58Z",
  "modifiedTime": "2024-12-29T16:28:55Z"
}
