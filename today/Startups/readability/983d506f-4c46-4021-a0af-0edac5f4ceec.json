{
  "id": "983d506f-4c46-4021-a0af-0edac5f4ceec",
  "title": "Meta defends Llama 4 release against ‘reports of mixed quality,’ blames bugs",
  "link": "https://venturebeat.com/ai/meta-defends-llama-4-release-against-reports-of-mixed-quality-blames-bugs/",
  "description": "Llama 4 continues to spread to other inference providers, but it's safe to say the initial release has not been a slam dunk.",
  "author": "Carl Franzen",
  "published": "Tue, 08 Apr 2025 00:11:14 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "AI, ML and Deep Learning",
    "controversy",
    "LLaMA",
    "llama 4",
    "llama 4 behemoth",
    "llama 4 maverick",
    "llama 4 scout",
    "Meta",
    "Meta Platforms",
    "NLP",
    "scandal"
  ],
  "byline": "Carl Franzen",
  "length": 6710,
  "excerpt": "Llama 4 continues to spread to other inference providers, but it's safe to say the initial release has not been a slam dunk.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "April 7, 2025 5:11 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Meta’s new flagship AI language model Llama 4 came suddenly over the weekend, with the parent company of Facebook, Instagram, WhatsApp and Quest VR (among other services and products) revealing not one, not two, but three versions — all upgraded to be more powerful and performant using the popular “Mixture-of-Experts” architecture and a new training method involving fixed hyperparameters, known as MetaP. Also, all three are equipped with massive context windows — the amount of information that an AI language model can handle in one input/output exchange with a user or tool. But following the surprise announcement and public release of two of those models for download and usage — the lower-parameter Llama 4 Scout and mid-tier Llama 4 Maverick — on Saturday, the response from the AI community on social media has been less than adoring. Llama 4 sparks confusion and criticism among AI users An unverified post on the North American Chinese language community forum 1point3acres made its way over to the r/LocalLlama subreddit on Reddit alleging to be from a researcher at Meta’s GenAI organization who claimed that the model performed poorly on third-party benchmarks internally and that company leadership “suggested blending test sets from various benchmarks during the post-training process, aiming to meet the targets across various metrics and produce a ‘presentable’ result.” The post was met with skepticism from the community in its authenticity, and a VentureBeat email to a Meta spokesperson has not yet received a reply. But other users found reasons to doubt the benchmarks regardless. “At this point, I highly suspect Meta bungled up something in the released weights … if not, they should lay off everyone who worked on this and then use money to acquire Nous,” commented @cto_junior on X, in reference to an independent user test showing Llama 4 Maverick’s poor performance (16%) on a benchmark known as aider polyglot, which runs a model through 225 coding tasks. That’s well below the performance of comparably sized, older models such as DeepSeek V3 and Claude 3.7 Sonnet. Referencing the 10 million-token context window Meta boasted for Llama 4 Scout, AI PhD and author Andriy Burkov wrote on X in part that: “The declared 10M context is virtual because no model was trained on prompts longer than 256k tokens. This means that if you send more than 256k tokens to it, you will get low-quality output most of the time.” Also on the r/LocalLlama subreddit, user Dr_Karminski wrote that “I’m incredibly disappointed with Llama-4,” and demonstrated its poor performance compared to DeepSeek’s non-reasoning V3 model on coding tasks such as simulating balls bouncing around a heptagon. Former Meta researcher and current AI2 (Allen Institute for Artificial Intelligence) Senior Research Scientist Nathan Lambert took to his Interconnects Substack blog on Monday to point out that a benchmark comparison posted by Meta to its own Llama download site of Llama 4 Maverick to other models, based on cost-to-performance on the third-party head-to-head comparison tool LMArena ELO aka Chatbot Arena, actually used a different version of Llama 4 Maverick than the company itself had made publicly available — one “optimized for conversationality.” As Lambert wrote: “Sneaky. The results below are fake, and it is a major slight to Meta’s community to not release the model they used to create their major marketing push. We’ve seen many open models that come around to maximize on ChatBotArena while destroying the model’s performance on important skills like math or code.” Lambert went on to note that while this particular model on the arena was “tanking the technical reputation of the release because its character is juvenile,” including lots of emojis and frivolous emotive dialog, “The actual model on other hosting providers is quite smart and has a reasonable tone!” In response to the torrent of criticism and accusations of benchmark cooking, Meta’s VP and Head of GenAI Ahmad Al-Dahle took to X to state: “We’re glad to start getting Llama 4 in all your hands. We’re already hearing lots of great results people are getting with these models. That said, we’re also hearing some reports of mixed quality across different services. Since we dropped the models as soon as they were ready, we expect it’ll take several days for all the public implementations to get dialed in. We’ll keep working through our bug fixes and onboarding partners. We’ve also heard claims that we trained on test sets — that’s simply not true and we would never do that. Our best understanding is that the variable quality people are seeing is due to needing to stabilize implementations. We believe the Llama 4 models are a significant advancement and we’re looking forward to working with the community to unlock their value.“ Yet even that response was met with many complaints of poor performance and calls for further information, such as more technical documentation outlining the Llama 4 models and their training processes, as well as additional questions about why this release compared to all prior Llama releases was particularly riddled with issues. It also comes on the heels of the number two at Meta’s VP of Research Joelle Pineau, who worked in the adjacent Meta Foundational Artificial Intelligence Research (FAIR) organization, announcing her departure from the company on LinkedIn last week with “nothing but admiration and deep gratitude for each of my managers.” Pineau, it should be noted also promoted the release of the Llama 4 model family this weekend. Llama 4 continues to spread to other inference providers with mixed results, but it’s safe to say the initial release of the model family has not been a slam dunk with the AI community. And the upcoming Meta LlamaCon on April 29, the first celebration and gathering for third-party developers of the model family, will likely have much fodder for discussion. We’ll be tracking it all, stay tuned. Daily insights on business use cases with VB Daily If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI. Read our Privacy Policy Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2025/04/cfr0z3n_vector_art_minimalist_acid_wash_flat_illustration_2D__4d1b2d49-d940-4a0c-86d3-beb181a36b7c_0.png?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2025-04-08T00:11:14+00:00\" datetime=\"2025-04-08T00:11:14+00:00\"\u003eApril 7, 2025 5:11 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"400\" height=\"224\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/cfr0z3n_vector_art_minimalist_acid_wash_flat_illustration_2D__4d1b2d49-d940-4a0c-86d3-beb181a36b7c_0.png?w=400\" alt=\"Three brown llamas and one green llama wearing sunglasses stand beside a bright pink painted low rise building with garage accordian door backdropped by palm trees\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://venturebeat.com/ai/metas-answer-to-deepseek-is-here-llama-4-launches-with-long-context-scout-and-maverick-models-and-2t-parameter-behemoth-on-the-way/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMeta’s new flagship AI language model Llama 4 came suddenly over the weekend\u003c/a\u003e, with the parent company of Facebook, Instagram, WhatsApp and \u003ca href=\"https://www.meta.com/quest/?srsltid=AfmBOorCz0FnXPtbB0qhb2Bh2XZ5hqv-CrAgalVDcl_eGG2CmGZE6g-C\"\u003eQuest VR\u003c/a\u003e (among other services and products) revealing not one, not two, but three versions — all upgraded to be more powerful and performant using the popular “Mixture-of-Experts” architecture and a new training method involving fixed hyperparameters, known as MetaP. \u003c/p\u003e\n\n\n\n\u003cp\u003eAlso, all three are equipped with massive context windows — the amount of information that an AI language model can handle in one input/output exchange with a user or tool. \u003c/p\u003e\n\n\n\n\u003cp\u003eBut following the surprise announcement and public release of two of those models for download and usage — the lower-parameter Llama 4 Scout and mid-tier Llama 4 Maverick — on Saturday, the response from the AI community on social media has been less than adoring.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-llama-4-sparks-confusion-and-criticism-among-ai-users\"\u003eLlama 4 sparks confusion and criticism among AI users\u003c/h2\u003e\n\n\n\n\u003cp\u003eAn unverified \u003ca href=\"https://www.1point3acres.com/bbs/thread-1122600-1-1.html\"\u003epost\u003c/a\u003e on the North American Chinese language community forum 1point3acres made its way over to the \u003ca href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jt8yug/serious_issues_in_llama_4_training_i_have/?utm_source=share\u0026amp;utm_medium=web3x\u0026amp;utm_name=web3xcss\u0026amp;utm_term=1\u0026amp;utm_content=share_button\"\u003er/LocalLlama subreddit\u003c/a\u003e on Reddit alleging to be from a researcher at Meta’s GenAI organization who claimed that the model performed poorly on third-party benchmarks internally and that company leadership \u003cem\u003e“suggested blending test sets from various benchmarks during the post-training process, aiming to meet the targets across various metrics and produce a ‘presentable’ result.”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eThe post was met with skepticism from the community in its authenticity, and a VentureBeat email to a Meta spokesperson has not yet received a reply. \u003c/p\u003e\n\n\n\n\u003cp\u003eBut other users found reasons to doubt the benchmarks regardless. \u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003e“At this point, I highly suspect Meta bungled up something in the released weights … if not, they should lay off everyone who worked on this and then use money to acquire Nous\u003c/em\u003e,” commented @cto_junior on X, in reference to an independent user test showing Llama 4 Maverick’s poor performance (16%) on a \u003ca href=\"https://aider.chat/docs/leaderboards/\"\u003ebenchmark known as aider polyglot\u003c/a\u003e, which runs a model through 225 coding tasks. That’s well below the performance of comparably sized, older models such as DeepSeek V3 and Claude 3.7 Sonnet.  \u003c/p\u003e\n\n\n\n\u003cp\u003eReferencing the 10 million-token context window Meta boasted for Llama 4 Scout, AI PhD and author \u003ca href=\"https://x.com/burkov/status/1908666701362978979\"\u003eAndriy Burkov wrote on X\u003c/a\u003e in part that: \u003cem\u003e“The declared 10M context is virtual because no model was trained on prompts longer than 256k tokens. This means that if you send more than 256k tokens to it, you will get low-quality output most of the time.”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eAlso on the r/LocalLlama subreddit, user Dr_Karminski wrote that “\u003ca href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jsl37d/im_incredibly_disappointed_with_llama4/\"\u003eI’m incredibly disappointed with Llama-4,\u003c/a\u003e” and demonstrated its poor performance compared to DeepSeek’s non-reasoning V3 model on coding tasks such as simulating balls bouncing around a heptagon. \u003c/p\u003e\n\n\n\n\u003cp\u003eFormer Meta researcher and current AI2 (Allen Institute for Artificial Intelligence) Senior Research Scientist Nathan Lambert took to \u003ca href=\"https://www.interconnects.ai/p/llama-4\"\u003ehis Interconnects Substack blog\u003c/a\u003e on Monday to point out that a benchmark comparison posted by Meta to its own Llama download site of Llama 4 Maverick to other models, based on cost-to-performance on the third-party head-to-head comparison tool \u003ca href=\"https://lmarena.ai/\"\u003eLMArena ELO\u003c/a\u003e aka Chatbot Arena, actually used a \u003cem\u003edifferent\u003c/em\u003e version of Llama 4 Maverick than the company itself had made publicly available — one “optimized for conversationality.”\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1920\" height=\"1284\" src=\"https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png 1920w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=300,200 300w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=768,514 768w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=800,535 800w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=1536,1027 1536w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=400,268 400w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=750,502 750w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=578,387 578w, https://venturebeat.com/wp-content/uploads/2025/04/d74ea148-e3bf-4700-a944-6e4155813eed_1920x1284.png?resize=930,622 930w\" sizes=\"(max-width: 1920px) 100vw, 1920px\"/\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eAs Lambert wrote: \u003cem\u003e“Sneaky. The results below are fake, and it is a major slight to Meta’s community to not release the model they used to create their major marketing push. We’ve seen many open models that come around to maximize on ChatBotArena while destroying the model’s performance on important skills like math or code.”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003eLambert went on to note that while this particular model on the arena was \u003cem\u003e“tanking the technical reputation of the release because its character is juvenile,”\u003c/em\u003e including lots of emojis and frivolous emotive dialog, \u003cem\u003e“The actual model on other hosting providers is quite smart and has a reasonable tone!”\u003c/em\u003e\u003c/p\u003e\n\n\n\n\n\n\n\n\u003cp\u003eIn response to the torrent of criticism and accusations of benchmark cooking, \u003ca href=\"https://x.com/Ahmad_Al_Dahle/status/1909302532306092107\"\u003eMeta’s VP and Head of GenAI Ahmad Al-Dahle took to X to state:\u003c/a\u003e\u003c/p\u003e\n\n\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e“We’re glad to start getting Llama 4 in all your hands. We’re already hearing lots of great results people are getting with these models.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eThat said, we’re also hearing some reports of mixed quality across different services. Since we dropped the models as soon as they were ready, we expect it’ll take several days for all the public implementations to get dialed in. We’ll keep working through our bug fixes and onboarding partners.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eWe’ve also heard claims that we trained on test sets — that’s simply not true and we would never do that. Our best understanding is that the variable quality people are seeing is due to needing to stabilize implementations.\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003cp\u003e\u003cem\u003eWe believe the Llama 4 models are a significant advancement and we’re looking forward to working with the community to unlock their value.\u003c/em\u003e“\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\n\n\u003cp\u003eYet even that response was met with many \u003ca href=\"https://x.com/RichardGibbonsX/status/1909319383950016647\"\u003ecomplaints of poor performance\u003c/a\u003e and calls for further information, such as \u003ca href=\"https://x.com/slow_developer/status/1909314771377369134\"\u003emore\u003c/a\u003e \u003ca href=\"https://x.com/omarsar0/status/1909305277511303389\"\u003etechnical documentation\u003c/a\u003e outlining the Llama 4 models and their training processes, as well as additional questions about why this release compared to all prior Llama releases was \u003ca href=\"https://x.com/M1ndPrison/status/1909334775497966052\"\u003eparticularly riddled with issues\u003c/a\u003e. \u003c/p\u003e\n\n\n\n\u003cp\u003eIt also comes on the heels of the number two at Meta’s VP of Research Joelle Pineau, who worked in the adjacent Meta Foundational Artificial Intelligence Research (FAIR) organization, announcing \u003ca href=\"https://www.linkedin.com/posts/joelle-pineau-371574141_a-personal-update-after-nearly-8-years-at-activity-7312871071928451072-QHng?utm_source=share\u0026amp;utm_medium=member_desktop\u0026amp;rcm=ACoAAAKTlTEBUrAfv-7hEwobIAwDLQPbtm2dljo\"\u003eher departure from the company\u003c/a\u003e on LinkedIn last week with “nothing but admiration and deep gratitude for each of my managers.” Pineau, it should be noted also\u003ca href=\"https://www.linkedin.com/posts/joelle-pineau-371574141_the-llama-4-herd-the-beginning-of-a-new-activity-7314363126085214209-S1FZ?utm_source=share\u0026amp;utm_medium=member_desktop\u0026amp;rcm=ACoAAAKTlTEBUrAfv-7hEwobIAwDLQPbtm2dljo\"\u003e promoted the release of the Llama 4 model family \u003c/a\u003ethis weekend.\u003c/p\u003e\n\n\n\n\u003cp\u003eLlama 4 continues to spread to other inference providers with mixed results, but it’s safe to say the initial release of the model family has not been a slam dunk with the AI community. \u003c/p\u003e\n\n\n\n\u003cp\u003eAnd the upcoming \u003ca href=\"https://www.llama.com/events/llamacon/signup/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eMeta LlamaCon on April 29\u003c/a\u003e, the first celebration and gathering for third-party developers of the model family, will likely have much fodder for discussion. We’ll be tracking it all, stay tuned. \u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eDaily insights on business use cases with VB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eRead our \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003ePrivacy Policy\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "8 min read",
  "publishedTime": "2025-04-08T00:11:14Z",
  "modifiedTime": "2025-04-08T00:11:21Z"
}
