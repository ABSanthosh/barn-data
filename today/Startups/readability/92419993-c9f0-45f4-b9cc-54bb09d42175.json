{
  "id": "92419993-c9f0-45f4-b9cc-54bb09d42175",
  "title": "Can AI really compete with human data scientists? OpenAI’s new benchmark puts it to the test",
  "link": "https://venturebeat.com/ai/can-ai-really-compete-with-human-data-scientists-openai-new-benchmark-puts-it-to-the-test/",
  "description": "OpenAI's new MLE-bench challenges AI systems with real-world data science tasks, revealing both the progress and limitations of AI in machine learning engineering compared to human experts.",
  "author": "Michael Nuñez",
  "published": "Thu, 10 Oct 2024 19:47:34 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Automation",
    "Data Infrastructure",
    "Enterprise Analytics",
    "Programming \u0026 Development",
    "AI Benchmark",
    "AI in data science",
    "AI performance",
    "AI research",
    "AI vs Human",
    "AI vs human data scientists",
    "AI, ML and Deep Learning",
    "artificial intelligence",
    "category-/Science/Computer Science",
    "Conversational AI",
    "Data Management",
    "Data Science",
    "kaggle",
    "machine learning",
    "Machine Learning Engineering",
    "MLE-Bench",
    "NLP",
    "OpenAI",
    "OpenAI benchmark",
    "tech innovation"
  ],
  "byline": "Michael Nuñez",
  "length": 4687,
  "excerpt": "OpenAI's new MLE-bench challenges AI systems with real-world data science tasks, revealing both the progress and limitations of AI in machine learning engineering compared to human experts.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "October 10, 2024 12:47 PM Credit: VentureBeat made with Midjourney Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More OpenAI has introduced a new tool to measure artificial intelligence capabilities in machine learning engineering. The benchmark, called MLE-bench, challenges AI systems with 75 real-world data science competitions from Kaggle, a popular platform for machine learning contests. This benchmark emerges as tech companies intensify efforts to develop more capable AI systems. MLE-bench goes beyond testing an AI’s computational or pattern recognition abilities; it assesses whether AI can plan, troubleshoot, and innovate in the complex field of machine learning engineering. A schematic representation of OpenAI’s MLE-bench, showing how AI agents interact with Kaggle-style competitions. The system challenges AI to perform complex machine learning tasks, from model training to submission creation, mimicking the workflow of human data scientists. The agent’s performance is then evaluated against human benchmarks. (Credit: arxiv.org) AI takes on Kaggle: Impressive wins and surprising setbacks The results reveal both the progress and limitations of current AI technology. OpenAI’s most advanced model, o1-preview, when paired with specialized scaffolding called AIDE, achieved medal-worthy performance in 16.9% of the competitions. This performance is notable, suggesting that in some cases, the AI system could compete at a level comparable to skilled human data scientists. However, the study also highlights significant gaps between AI and human expertise. The AI models often succeeded in applying standard techniques but struggled with tasks requiring adaptability or creative problem-solving. This limitation underscores the continued importance of human insight in the field of data science. Machine learning engineering involves designing and optimizing the systems that enable AI to learn from data. MLE-bench evaluates AI agents on various aspects of this process, including data preparation, model selection, and performance tuning. A comparison of three AI agent approaches to solving machine learning tasks in OpenAI’s MLE-bench. From left to right: MLAB ResearchAgent, OpenHands, and AIDE, each demonstrating different strategies and execution times in tackling complex data science challenges. The AIDE framework, with its 24-hour runtime, shows a more comprehensive problem-solving approach. (Credit: arxiv.org) From lab to industry: The far-reaching impact of AI in data science The implications of this research extend beyond academic interest. The development of AI systems capable of handling complex machine learning tasks independently could accelerate scientific research and product development across various industries. However, it also raises questions about the evolving role of human data scientists and the potential for rapid advancements in AI capabilities. OpenAI’s decision to make MLE-benc open-source allows for broader examination and use of the benchmark. This move may help establish common standards for evaluating AI progress in machine learning engineering, potentially shaping future development and safety considerations in the field. As AI systems approach human-level performance in specialized areas, benchmarks like MLE-bench provide crucial metrics for tracking progress. They offer a reality check against inflated claims of AI capabilities, providing clear, quantifiable measures of current AI strengths and weaknesses. The future of AI and human collaboration in machine learning The ongoing efforts to enhance AI capabilities are gaining momentum. MLE-bench offers a new perspective on this progress, particularly in the realm of data science and machine learning. As these AI systems improve, they may soon work in tandem with human experts, potentially expanding the horizons of machine learning applications. However, it’s important to note that while the benchmark shows promising results, it also reveals that AI still has a long way to go before it can fully replicate the nuanced decision-making and creativity of experienced data scientists. The challenge now lies in bridging this gap and determining how best to integrate AI capabilities with human expertise in the field of machine learning engineering. VB Daily Stay in the know! Get the latest news in your inbox daily By subscribing, you agree to VentureBeat's Terms of Service. Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Abstract_art_of_a_robot_scientist_working_side_by_sid_31432677-f62b-4ba8-8f7d-cb17f9ef1016.webp?w=550?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\t\t\n\t\t\u003csection\u003e\n\t\t\t\n\t\t\t\u003cp\u003e\u003ctime title=\"2024-10-10T19:47:34+00:00\" datetime=\"2024-10-10T19:47:34+00:00\"\u003eOctober 10, 2024 12:47 PM\u003c/time\u003e\n\t\t\t\u003c/p\u003e\n\t\t\t\n\t\t\u003c/section\u003e\n\t\t\u003cdiv\u003e\n\t\t\t\t\t\u003cp\u003e\u003cimg width=\"550\" height=\"308\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/nuneybits_Abstract_art_of_a_robot_scientist_working_side_by_sid_31432677-f62b-4ba8-8f7d-cb17f9ef1016.webp?w=550\" alt=\"Credit: VentureBeat made with Midjourney\"/\u003e\u003c/p\u003e\u003cp\u003e\u003cspan\u003eCredit: VentureBeat made with Midjourney\u003c/span\u003e\u003c/p\u003e\t\t\u003c/div\u003e\n\t\u003c/div\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://openai.com/\"\u003eOpenAI\u003c/a\u003e has introduced a new tool to measure artificial intelligence capabilities in machine learning engineering. The benchmark, called \u003ca href=\"https://openai.com/index/mle-bench/\"\u003eMLE-bench\u003c/a\u003e, challenges AI systems with 75 real-world data science competitions from \u003ca href=\"https://www.kaggle.com/datasets/kaggle/meta-kaggle\"\u003eKaggle\u003c/a\u003e, a popular platform for machine learning contests.\u003c/p\u003e\n\n\n\n\u003cp\u003eThis benchmark emerges as tech companies intensify efforts to develop more capable AI systems. MLE-bench goes beyond testing an AI’s computational or pattern recognition abilities; it assesses whether AI can plan, troubleshoot, and innovate in the complex field of machine learning engineering.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"958\" height=\"321\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png 958w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=300,101 300w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=768,257 768w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=800,268 800w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=400,134 400w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=750,251 750w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=578,194 578w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot_2024_10_10_at_12_22_00_PM.png?resize=930,312 930w\" sizes=\"(max-width: 958px) 100vw, 958px\"/\u003e\u003cfigcaption\u003eA schematic representation of OpenAI’s MLE-bench, showing how AI agents interact with Kaggle-style competitions. The system challenges AI to perform complex machine learning tasks, from model training to submission creation, mimicking the workflow of human data scientists. The agent’s performance is then evaluated against human benchmarks. (Credit: arxiv.org)\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-ai-takes-on-kaggle-impressive-wins-and-surprising-setbacks\"\u003eAI takes on Kaggle: Impressive wins and surprising setbacks\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe results reveal both the progress and limitations of current AI technology. OpenAI’s most advanced model, \u003ca href=\"https://openai.com/index/introducing-openai-o1-preview/\"\u003eo1-preview\u003c/a\u003e, when paired with specialized scaffolding called \u003ca href=\"https://www.weco.ai/blog/technical-report\"\u003eAIDE\u003c/a\u003e, achieved medal-worthy performance in 16.9% of the competitions. This performance is notable, suggesting that in some cases, the AI system could compete at a level comparable to skilled human data scientists.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, the study also highlights significant gaps between AI and human expertise. The AI models often succeeded in applying standard techniques but struggled with tasks requiring adaptability or creative problem-solving. This limitation underscores the continued importance of human insight in the field of data science.\u003c/p\u003e\n\n\n\n\u003cp\u003eMachine learning engineering involves designing and optimizing the systems that enable AI to learn from data. MLE-bench evaluates AI agents on various aspects of this process, including data preparation, model selection, and performance tuning.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"953\" height=\"691\" src=\"https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45%E2%80%AFPM.png?w=800\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png 953w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=300,218 300w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=768,557 768w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=800,580 800w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=400,290 400w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=750,544 750w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=578,419 578w, https://venturebeat.com/wp-content/uploads/2024/10/Screenshot-2024-10-10-at-12.45.45 PM.png?resize=930,674 930w\" sizes=\"(max-width: 953px) 100vw, 953px\"/\u003e\u003cfigcaption\u003eA comparison of three AI agent approaches to solving machine learning tasks in OpenAI’s MLE-bench. From left to right: MLAB ResearchAgent, OpenHands, and AIDE, each demonstrating different strategies and execution times in tackling complex data science challenges. The AIDE framework, with its 24-hour runtime, shows a more comprehensive problem-solving approach. (Credit: arxiv.org)\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003ch2 id=\"h-from-lab-to-industry-the-far-reaching-impact-of-ai-in-data-science\"\u003eFrom lab to industry: The far-reaching impact of AI in data science\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe implications of this research extend beyond academic interest. The development of AI systems capable of handling complex machine learning tasks independently could accelerate scientific research and product development across various industries. However, it also raises questions about the evolving role of human data scientists and the potential for rapid advancements in AI capabilities.\u003c/p\u003e\n\n\n\n\u003cp\u003eOpenAI’s decision to make MLE-benc \u003ca href=\"https://github.com/openai/mle-bench/\"\u003eopen-source\u003c/a\u003e allows for broader examination and use of the benchmark. This move may help establish common standards for evaluating AI progress in machine learning engineering, potentially shaping future development and safety considerations in the field.\u003c/p\u003e\n\n\n\n\u003cp\u003eAs AI systems approach human-level performance in specialized areas, benchmarks like MLE-bench provide crucial metrics for tracking progress. They offer a reality check against inflated claims of AI capabilities, providing clear, quantifiable measures of current AI strengths and weaknesses.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-the-future-of-ai-and-human-collaboration-in-machine-learning\"\u003eThe future of AI and human collaboration in machine learning\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe ongoing efforts to enhance AI capabilities are gaining momentum. MLE-bench offers a new perspective on this progress, particularly in the realm of data science and machine learning. As these AI systems improve, they may soon work in tandem with human experts, potentially expanding the horizons of machine learning applications.\u003c/p\u003e\n\n\n\n\u003cp\u003eHowever, it’s important to note that while the benchmark shows promising results, it also reveals that AI still has a long way to go before it can fully replicate the nuanced decision-making and creativity of experienced data scientists. The challenge now lies in bridging this gap and determining how best to integrate AI capabilities with human expertise in the field of machine learning engineering.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eVB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eStay in the know! Get the latest news in your inbox daily\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eBy subscribing, you agree to VentureBeat\u0026#39;s \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003eTerms of Service.\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "6 min read",
  "publishedTime": "2024-10-10T19:47:34Z",
  "modifiedTime": "2024-10-10T19:47:41Z"
}
