{
  "id": "b5406033-53f4-4b97-a6c3-046d81b9443a",
  "title": "Hertz-dev, the first open-source base model for conversational audio",
  "link": "https://si.inc/hertz-dev/",
  "description": "Article URL: https://si.inc/hertz-dev/ Comments URL: https://news.ycombinator.com/item?id=42036995 Points: 5 # Comments: 1",
  "author": "mnk47",
  "published": "Sun, 03 Nov 2024 23:30:48 +0000",
  "source": "https://hnrss.org/frontpage",
  "categories": null,
  "byline": "",
  "length": 3336,
  "excerpt": "For the last few months, we at Standard Intelligence have focused on fundamental research on the frontier of audio-only speech generation. We're excited to announce that we're open-sourcing current checkpoints of our full-duplex, audio-only transformer base model, hertz-dev, with a total of 8.5 billion parameters.",
  "siteName": "",
  "favicon": "",
  "text": "For the last few months, we at Standard Intelligence have focused on fundamental research on the frontier of audio-only speech generation. We're excited to announce that we're open-sourcing current checkpoints of our full-duplex, audio-only transformer base model, hertz-dev, with a total of 8.5 billion parameters. hertz-codec: a convolutional audio autoencoder that takes mono, 16kHz speech and transforms it into a 8 Hz latent representation at about 1kbps bitrate. Stage 1 at 1kbps outperforms Soundstream and Encodec at 6kbps and is on par with DAC at 8kbps in subjective evaluations, while having lower tokens per second than any popular tokenizer, critical for language modeling. Stage 1 has 5 million encoder parameters and 95 million decoder parameters. hertz-vae: a 1.8 billion parameter transformer decoder which acts as a learned prior for the audio VAE. The model takes in sampled latent representations and predicts the next encoded audio frame as a mixture of gaussians, with 15 bits of quantized information from the next token acting as semantic scaffolding to steer the generation in a streamable manner. hertz-dev: a 6.6 billion parameter transformer stack. The primary Stage 3 checkpoint is partially initialized from the weights of a pre-trained language model and then trained for a single epoch on 500B tokens. We're also publishing an ablation of the language model initialization which is similarly trained on 500B tokens. Hertz-dev is the first publicly released audio base model of its kind. Base models are uniquely valuable as a research product because they accurately model the distribution of the data that they were trained on, as opposed to models that have had substantial RL tuning done to collapse their generation distributions. This makes base models the best starting point to fine-tune for a large number of different tasks. Hertz-dev has a theoretical latency of 80ms and a real-world average latency of 120ms on a RTX 4090. This is about 2x lower latency than any public model in the world—a prerequisite for a model that can interact with you in human-like ways instead of what feels like a delayed, choppy phone call. We're currently training a larger, more advanced version of Hertz, which will use a scaled base model recipe and RL tuning to substantially improve the raw capabilities and final coherence of the model. Hertz-dev is a glimpse at the future of real-time voice interaction, and is the easiest conversational audio model in the world for researchers to fine-tune and build on top of. Sample Generations To demonstrate the audio modeling capabilities of hertz-dev, we sample both one-channel and two-channel generations as well as a live conversation between the model and a human. One-channel generation Your browser does not support the audio element. 2 seconds prompt. Two-channel generation Your browser does not support the audio element. 22 seconds prompt. Interactive generation Your browser does not support the audio element. 9 seconds prompt.",
  "image": "",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n    \n\n    \u003carticle\u003e\n      \u003cp\u003eFor the last few months, we at Standard Intelligence have focused on fundamental research on the frontier of audio-only speech generation. We\u0026#39;re excited to announce that we\u0026#39;re open-sourcing current checkpoints of our full-duplex, audio-only transformer base model, hertz-dev, with a total of 8.5 billion parameters.\u003c/p\u003e\n\n      \u003cul\u003e\n        \u003cli\u003e\u003cstrong\u003ehertz-codec:\u003c/strong\u003e a convolutional audio autoencoder that takes mono, 16kHz speech and transforms it into a 8 Hz latent representation at about 1kbps bitrate. Stage 1 at 1kbps outperforms Soundstream and Encodec at 6kbps and is on par with DAC at 8kbps in subjective evaluations, while having lower tokens per second than any popular tokenizer, critical for language modeling. Stage 1 has 5 million encoder parameters and 95 million decoder parameters.\u003c/li\u003e\n        \u003cli\u003e\u003cstrong\u003ehertz-vae:\u003c/strong\u003e a 1.8 billion parameter transformer decoder which acts as a learned prior for the audio VAE. The model takes in sampled latent representations and predicts the next encoded audio frame as a mixture of gaussians, with 15 bits of quantized information from the next token acting as semantic scaffolding to steer the generation in a streamable manner.\u003c/li\u003e\n        \u003cli\u003e\u003cstrong\u003ehertz-dev:\u003c/strong\u003e a 6.6 billion parameter transformer stack. The primary Stage 3 checkpoint is partially initialized from the weights of a pre-trained language model and then trained for a single epoch on 500B tokens. We\u0026#39;re also publishing an ablation of the language model initialization which is similarly trained on 500B tokens.\u003c/li\u003e\n      \u003c/ul\u003e\n\n      \u003cp\u003eHertz-dev is the first publicly released audio base model of its kind. Base models are uniquely valuable as a research product because they accurately model the distribution of the data that they were trained on, as opposed to models that have had substantial RL tuning done to collapse their generation distributions. This makes base models the best starting point to fine-tune for a large number of different tasks.\u003c/p\u003e\n\n      \u003cp\u003eHertz-dev has a theoretical latency of 80ms and a real-world average latency of 120ms on a RTX 4090. This is about 2x lower latency than any public model in the world—a prerequisite for a model that can interact with you in human-like ways instead of what feels like a delayed, choppy phone call. We\u0026#39;re currently training a larger, more advanced version of Hertz, which will use a scaled base model recipe and RL tuning to substantially improve the raw capabilities and final coherence of the model. Hertz-dev is a glimpse at the future of real-time voice interaction, and is the easiest conversational audio model in the world for researchers to fine-tune and build on top of.\u003c/p\u003e\n\n      \u003ch2\u003eSample Generations\u003c/h2\u003e\n      \u003cp\u003eTo demonstrate the audio modeling capabilities of hertz-dev, we sample both one-channel and two-channel generations as well as a live conversation between the model and a human.\u003c/p\u003e\n\n      \u003ch3\u003eOne-channel generation\u003c/h3\u003e\n      \u003cdiv\u003e\n          \u003cp\u003e\u003caudio controls=\"\"\u003e\n            \u003csource src=\"https://publicr2.si.inc/hertz-dev/generations/as_an_assistant.wav\" type=\"audio/wav\"/\u003e\n            Your browser does not support the audio element.\n          \u003c/audio\u003e\u003c/p\u003e\u003cp\u003e2 seconds prompt.\u003c/p\u003e\n        \u003c/div\u003e\n\n      \u003ch3\u003eTwo-channel generation\u003c/h3\u003e\n      \u003cdiv\u003e\n          \u003cdiv\u003e\n            \u003cp\u003e\u003caudio controls=\"\"\u003e\n                \u003csource src=\"https://publicr2.si.inc/hertz-dev/generations/counting.wav\" type=\"audio/wav\"/\u003e\n                Your browser does not support the audio element.\n              \u003c/audio\u003e\n            \u003c/p\u003e\n          \u003c/div\u003e\n          \u003cp\u003e22 seconds prompt. \u003c/p\u003e\n        \u003c/div\u003e\n\n      \u003ch3\u003eInteractive generation\u003c/h3\u003e\n      \u003cdiv\u003e\n          \u003cp\u003e\u003caudio controls=\"\"\u003e\n            \u003csource src=\"https://publicr2.si.inc/hertz-dev/generations/ai_talk.wav\" type=\"audio/wav\"/\u003e\n            Your browser does not support the audio element.\n          \u003c/audio\u003e\u003c/p\u003e\u003cp\u003e9 seconds prompt.\u003c/p\u003e\n        \u003c/div\u003e\n\n      \n    \u003c/article\u003e\n  \u003c/div\u003e\u003c/div\u003e",
  "readingTime": "4 min read",
  "publishedTime": null,
  "modifiedTime": null
}
