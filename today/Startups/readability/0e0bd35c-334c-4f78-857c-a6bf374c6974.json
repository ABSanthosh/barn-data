{
  "id": "0e0bd35c-334c-4f78-857c-a6bf374c6974",
  "title": "Sakana AI’s CycleQD outperforms traditional fine-tuning methods for multi-skill language models",
  "link": "https://venturebeat.com/ai/sakana-ais-cycleqd-outperforms-traditional-fine-tuning-methods-for-multi-skill-language-models/",
  "description": "CycleQD merges skills of experts models in clever ways to create many new models with multiple skills, no fine-tuning required.",
  "author": "Ben Dickson",
  "published": "Fri, 06 Dec 2024 21:08:35 +0000",
  "source": "https://feeds.feedburner.com/venturebeat/SZYF",
  "categories": [
    "AI",
    "Business",
    "AI research",
    "AI, ML and Deep Learning",
    "category-/Science",
    "Conversational AI",
    "Fine-tuning large language models",
    "large language models",
    "LLMs",
    "model fine-tuning",
    "NLP",
    "research",
    "sakana ai"
  ],
  "byline": "Ben Dickson",
  "length": 5844,
  "excerpt": "CycleQD merges skills of experts models in clever ways to create many new models with multiple skills, no fine-tuning required.",
  "siteName": "VentureBeat",
  "favicon": "",
  "text": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Researchers at Sakana AI have developed a resource-efficient framework that can create hundreds of language models specializing in different tasks. Called CycleQD, the technique uses evolutionary algorithms to combine the skills of different models without the need for expensive and slow training processes. CycleQD can create swarms of task-specific agents that offer a more sustainable alternative to the current paradigm of increasing model size. Rethinking model training Large language models (LLMs) have shown remarkable capabilities in various tasks. However, training LLMs to master multiple skills remains a challenge. When fine-tuning models, engineers must balance data from different skills and ensure that one skill doesn’t dominate the others. Current approaches often involve training ever-larger models, which leads to increasing computational demands and resource requirements. “We believe rather than aiming to develop a single large model to perform well on all tasks, population-based approaches to evolve a diverse swarm of niche models may offer an alternative, more sustainable path to scaling up the development of AI agents with advanced capabilities,” the Sakana researchers write in a blog post. To create populations of models, the researchers took inspiration from quality diversity (QD), an evolutionary computing paradigm that focuses on discovering a diverse set of solutions from an initial population sample. QD aims at creating specimens with various “behavior characteristics” (BCs), which represent different skill domains. It achieves this through evolutionary algorithms (EA) that select parent examples and use crossover and mutation operations to create new samples. Quality Diversity (source: Sakana AI) CycleQD CycleQD incorporates QD into the post-training pipeline of LLMs to help them learn new, complex skills. CycleQD is useful when you have multiple small models that have been fine-tuned for very specific skills, such as coding or performing database and operating system operations, and you want to create new variants that have different combinations of those skills. In the CycleQD framework, each of these skills is considered a behavior characteristic or a quality that the next generation of models is optimized for. In each generation, the algorithm focuses on one specific skill as its quality metric while using the other skills as BCs. “This ensures every skill gets its moment in the spotlight, allowing the LLMs to grow more balanced and capable overall,” the researchers explain. CycleQD (source: Sakana AI) CycleQD starts with a set of expert LLMs, each specialized in a single skill. The algorithm then applies “crossover” and “mutation” operations to add new higher-quality models to the population. Crossover combines the characteristics of two parent models to create a new model while mutation makes random changes to the model to explore new possibilities. The crossover operation is based on model merging, a technique that combines the parameters of two LLMs to create a new model with combined skills. This is a cost-effective and quick method for developing well-rounded models without the need to fine-tune them. The mutation operation uses singular value decomposition (SVD), a factorization method that breaks down any matrix into simpler components, making it easier to understand and manipulate its elements. CycleQD uses SVD to break down the model’s skills into fundamental components or sub-skills. By tweaking these sub-skills, the mutation process creates models that explore new capabilities beyond those of their parent models. This helps the models avoid getting stuck in predictable patterns and reduces the risk of overfitting. Evaluating CycleQD’s performance The researchers applied CycleQD to a set of Llama 3-8B expert models fine-tuned for coding, database operations and operating system operations. The goal was to see if the evolutionary method could combine the skills of the three models to create a superior model. The results showed that CycleQD outperformed traditional fine-tuning and model merging methods across the evaluated tasks. Notably, a model fine-tuned on all datasets combined performed only marginally better than the single-skill expert models, despite being trained on more data. Moreover, the traditional training process is much slower and more expensive. CycleQD was also able to create various models with different performance levels on the target tasks. “These results clearly show that CycleQD outperforms traditional methods, proving its effectiveness in training LLMs to excel across multiple skills,” the researchers write. CycleQD vs other fine-tuning methods (source: Sakana AI) The researchers believe that CycleQD has the potential to enable lifelong learning in AI systems, allowing them to continuously grow, adapt and accumulate knowledge over time. This can have direct implications for real-world applications. For example, CycleQD can be used to continuously merge the skills of expert models instead of training a large model from scratch. Another exciting direction is the development of multi-agent systems, where swarms of specialized agents evolved through CycleQD can collaborate, compete and learn from one another.  “From scientific discovery to real-world problem-solving, swarms of specialized agents could redefine the limits of AI,” the researchers write. VB Daily Stay in the know! Get the latest news in your inbox daily By subscribing, you agree to VentureBeat's Terms of Service. Thanks for subscribing. Check out more VB newsletters here. An error occured.",
  "image": "https://venturebeat.com/wp-content/uploads/2024/12/robotic-genes.jpg?w=1024?w=1200\u0026strip=all",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"primary\"\u003e\n\n\t\t\u003carticle id=\"content\"\u003e\n\t\t\t\u003cdiv\u003e\n\t\t\t\t\u003cdiv id=\"boilerplate_2682874\"\u003e\n\u003cp\u003e\u003cem\u003eJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. \u003ca href=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite\u0026amp;utm_medium=desktopNav\"\u003eLearn More\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\n\n\n\u003chr/\u003e\n\u003c/div\u003e\u003cp\u003eResearchers at \u003ca href=\"https://sakana.ai/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eSakana AI\u003c/a\u003e have developed a resource-efficient framework that can create hundreds of language models specializing in different tasks. Called \u003ca href=\"https://sakana.ai/cycleqd/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eCycleQD\u003c/a\u003e, the technique uses evolutionary algorithms to combine the skills of different models without the need for expensive and slow training processes.\u003c/p\u003e\n\n\n\n\u003cp\u003eCycleQD can create swarms of task-specific agents that offer a more sustainable alternative to the current paradigm of increasing model size.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-rethinking-model-training\"\u003eRethinking model training\u003c/h2\u003e\n\n\n\n\u003cp\u003e\u003ca href=\"https://venturebeat.com/ai/meta-launches-open-source-llama-3-3-shrinking-powerful-bigger-model-into-smaller-size/\"\u003eLarge language models\u003c/a\u003e (LLMs) have shown remarkable capabilities in various tasks. However, training LLMs to master multiple skills remains a challenge. When fine-tuning models, engineers must balance data from different skills and ensure that one skill doesn’t dominate the others. Current approaches often involve training ever-larger models, which leads to increasing computational demands and resource requirements.\u003c/p\u003e\n\n\n\n\u003cp\u003e“We believe rather than aiming to develop a single large model to perform well on all tasks, population-based approaches to evolve a diverse swarm of niche models may offer an alternative, more sustainable path to scaling up the development of AI agents with advanced capabilities,” the Sakana researchers write in a blog post.\u003c/p\u003e\n\n\n\n\u003cp\u003eTo create \u003ca href=\"https://venturebeat.com/ai/openai-launches-full-o1-model-with-34-reduced-error-rate-debuts-chatgpt-pro/\"\u003epopulations of models\u003c/a\u003e, the researchers took inspiration from quality diversity (QD), an evolutionary computing paradigm that focuses on discovering a diverse set of solutions from an initial population sample. QD aims at creating specimens with various “behavior characteristics” (BCs), which represent different skill domains. It achieves this through evolutionary algorithms (EA) that select parent examples and use crossover and mutation operations to create new samples.\u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg fetchpriority=\"high\" decoding=\"async\" width=\"1670\" height=\"1176\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?w=800\" alt=\"Quality Diversity\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png 1670w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=300,211 300w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=768,541 768w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=800,563 800w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=1536,1082 1536w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=400,282 400w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=750,528 750w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=578,407 578w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_schematic.png?resize=930,655 930w\" sizes=\"(max-width: 1670px) 100vw, 1670px\"/\u003e\u003cfigcaption\u003eQuality Diversity (source: Sakana AI)\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003ch2 id=\"h-cycleqd\"\u003eCycleQD\u003c/h2\u003e\n\n\n\n\u003cp\u003eCycleQD incorporates QD into the post-training pipeline of LLMs to help them learn new, complex skills. CycleQD is useful when you have multiple small models that have been fine-tuned for very specific skills, such as coding or performing \u003ca href=\"https://venturebeat.com/data-infrastructure/aws-cuts-database-prices-almost-50-and-adds-distributed-scaling-capabilities/\"\u003edatabase and operating system\u003c/a\u003e operations, and you want to create new variants that have different combinations of those skills.\u003c/p\u003e\n\n\n\n\u003cp\u003eIn the CycleQD framework, each of these skills is considered a behavior characteristic or a quality that the next generation of models is optimized for. In each generation, the algorithm focuses on one specific skill as its quality metric while using the other skills as BCs.\u003c/p\u003e\n\n\n\n\u003cp\u003e“This ensures every skill gets its moment in the spotlight, allowing the LLMs to grow more balanced and capable overall,” the researchers explain.\u003c/p\u003e\n\n\n\u003cdiv\u003e\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1654\" height=\"1344\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?w=738\" alt=\"CycleQD \" srcset=\"https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png 1654w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=300,244 300w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=768,624 768w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=738,600 738w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=1536,1248 1536w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=400,325 400w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=750,609 750w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=578,470 578w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_main.png?resize=930,756 930w\" sizes=\"(max-width: 1654px) 100vw, 1654px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eCycleQD (source: Sakana AI)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\n\n\n\u003cp\u003eCycleQD starts with a set of expert LLMs, each specialized in a single skill. The algorithm then applies “crossover” and “mutation” operations to add new higher-quality models to the population. Crossover combines the characteristics of two parent models to create a new model while mutation makes random changes to the model to explore new possibilities.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe crossover operation is based on \u003ca href=\"https://venturebeat.com/ai/sakana-ais-evolutionary-algorithm-discovers-new-architectures-for-generative-models/\"\u003emodel merging\u003c/a\u003e, a technique that combines the parameters of two LLMs to create a new model with combined skills. This is a cost-effective and quick method for developing well-rounded models without the need to fine-tune them.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe mutation operation uses \u003ca href=\"https://en.wikipedia.org/wiki/Singular_value_decomposition\" target=\"_blank\" rel=\"noreferrer noopener\"\u003esingular value decomposition\u003c/a\u003e (SVD), a factorization method that breaks down any matrix into simpler components, making it easier to understand and manipulate its elements. CycleQD uses SVD to break down the model’s skills into fundamental components or sub-skills. By tweaking these sub-skills, the mutation process creates models that explore new capabilities beyond those of their parent models. This helps the models avoid getting stuck in predictable patterns and reduces the risk of overfitting.\u003c/p\u003e\n\n\n\n\u003ch2 id=\"h-evaluating-cycleqd-s-performance\"\u003eEvaluating CycleQD’s performance\u003c/h2\u003e\n\n\n\n\u003cp\u003eThe researchers applied CycleQD to a set of \u003ca href=\"https://venturebeat.com/ai/llama-3-launches-alongside-new-stand-alone-meta-ai-chatbot/\"\u003eLlama 3-8B\u003c/a\u003e expert models fine-tuned for coding, database operations and operating system operations. The goal was to see if the evolutionary method could combine the skills of the three models to create a superior model.\u003c/p\u003e\n\n\n\n\u003cp\u003eThe results showed that CycleQD outperformed traditional fine-tuning and model merging methods across the evaluated tasks. Notably, a model fine-tuned on all datasets combined performed only marginally better than the single-skill expert models, despite being trained on more data. Moreover, the traditional training process is much slower and more expensive. CycleQD was also able to create various models with different performance levels on the target tasks.\u003c/p\u003e\n\n\n\n\u003cp\u003e“These results clearly show that CycleQD outperforms traditional methods, proving its effectiveness in training LLMs to excel across multiple skills,” the researchers write.\u003c/p\u003e\n\n\n\n\u003cfigure\u003e\u003cimg decoding=\"async\" width=\"1902\" height=\"1216\" src=\"https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?w=800\" alt=\"CycleQD vs other methods\" srcset=\"https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png 1902w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=300,192 300w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=768,491 768w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=800,511 800w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=1536,982 1536w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=400,256 400w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=750,479 750w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=578,370 578w, https://venturebeat.com/wp-content/uploads/2024/12/cycleqd_table.png?resize=930,595 930w\" sizes=\"(max-width: 1902px) 100vw, 1902px\"/\u003e\u003cfigcaption\u003e\u003cem\u003eCycleQD vs other fine-tuning methods (source: Sakana AI)\u003c/em\u003e\u003c/figcaption\u003e\u003c/figure\u003e\n\n\n\n\u003cp\u003eThe researchers believe that CycleQD has the potential to enable lifelong learning in AI systems, allowing them to continuously grow, adapt and accumulate knowledge over time. This can have direct implications for real-world applications. For example, CycleQD can be used to continuously merge the skills of expert models instead of training a large model from scratch.\u003c/p\u003e\n\n\n\n\u003cp\u003eAnother exciting direction is the development of multi-agent systems, where swarms of specialized agents evolved through CycleQD can collaborate, compete and learn from one another. \u003c/p\u003e\n\n\n\n\u003cp\u003e“From scientific discovery to real-world problem-solving, swarms of specialized agents could redefine the limits of AI,” the researchers write.\u003c/p\u003e\n\u003cdiv id=\"boilerplate_2660155\"\u003e\n\t\t\t\t\u003cp\u003e\u003cstrong\u003eVB Daily\u003c/strong\u003e\u003c/p\u003e\n\t\t\t\t\u003cp\u003eStay in the know! Get the latest news in your inbox daily\u003c/p\u003e\n\t\t\t\t\n\t\t\t\t\u003cp\u003eBy subscribing, you agree to VentureBeat\u0026#39;s \u003ca href=\"https://venturebeat.com/terms-of-service/\"\u003eTerms of Service.\u003c/a\u003e\u003c/p\u003e\n\t\t\t\t\u003cp id=\"boilerplateNewsletterConfirmation\"\u003e\n\t\t\t\t\tThanks for subscribing. Check out more \u003ca href=\"https://venturebeat.com/newsletters/\"\u003eVB newsletters here\u003c/a\u003e.\n\t\t\t\t\u003c/p\u003e\n\t\t\t\t\u003cp\u003eAn error occured.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\t\t\t\u003c/div\u003e\n\n\t\t\t\t\t\t\t\n\t\t\t\n\t\t\u003c/article\u003e\n\n\t\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "7 min read",
  "publishedTime": "2024-12-06T21:08:35Z",
  "modifiedTime": "2024-12-06T21:08:43Z"
}
