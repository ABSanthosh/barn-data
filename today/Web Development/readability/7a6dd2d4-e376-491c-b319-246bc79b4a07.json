{
  "id": "7a6dd2d4-e376-491c-b319-246bc79b4a07",
  "title": "Introducing llamafile",
  "link": "https://hacks.mozilla.org/2023/11/introducing-llamafile/",
  "description": "We're thrilled to announce the first release of llamafile, inviting the open source community to join this groundbreaking project. With llamafile, you can effortlessly convert large language model (LLM) weights into executables. Imagine transforming a 4GB file of LLM weights into a binary that runs smoothly on six different operating systems, without requiring installation. The post Introducing llamafile appeared first on Mozilla Hacks - the Web developer blog.",
  "author": "Stephen Hood",
  "published": "Wed, 29 Nov 2023 18:46:02 +0000",
  "source": "https://hacks.mozilla.org/feed/",
  "categories": [
    "Featured Article",
    "AI",
    "artificial intelligence",
    "language models",
    "llamafile",
    "MIECO",
    "mozilla",
    "open source"
  ],
  "byline": "By Stephen Hood",
  "length": 2462,
  "excerpt": "We're thrilled to announce the first release of llamafile, inviting the open source community to join this groundbreaking project.",
  "siteName": "Mozilla Hacks – the Web developer blog",
  "favicon": "",
  "text": "A special thanks to Justine Tunney of the Mozilla Internet Ecosystem (MIECO), who co-authored this blog post. Today we’re announcing the first release of llamafile and inviting the open source community to participate in this new project. llamafile lets you turn large language model (LLM) weights into executables. Say you have a set of LLM weights in the form of a 4GB file (in the commonly-used GGUF format). With llamafile you can transform that 4GB file into a binary that runs on six OSes without needing to be installed. This makes it dramatically easier to distribute and run LLMs. It also means that as models and their weights formats continue to evolve over time, llamafile gives you a way to ensure that a given set of weights will remain usable and perform consistently and reproducibly, forever. We achieved all this by combining two projects that we love: llama.cpp (a leading open source LLM chatbot framework) with Cosmopolitan Libc (an open source project that enables C programs to be compiled and run on a large number of platforms and architectures). It also required solving several interesting and juicy problems along the way, such as adding GPU and dlopen() support to Cosmopolitan; you can read more about it in the project’s README. This first release of llamafile is a product of Mozilla’s innovation group and developed by Justine Tunney, the creator of Cosmopolitan. Justine has recently been collaborating with Mozilla via MIECO, and through that program Mozilla funded her work on the 3.0 release  (Hacker News discussion) of Cosmopolitan. With llamafile, Justine is excited to be contributing more directly to Mozilla projects, and we’re happy to have her involved. llamafile is licensed Apache 2.0, and we encourage contributions. Our changes to llama.cpp itself are licensed MIT (the same license used by llama.cpp itself) so as to facilitate any potential future upstreaming. We’re all big fans of llama.cpp around here; llamafile wouldn’t have been possible without it and Cosmopolitan. We hope llamafile is useful to you and look forward to your feedback. Stephen leads open source AI projects (including llamafile) in Mozilla's Innovation group. He previously managed social bookmarking pioneer del.icio.us; co-founded Storium, Blockboard, and FairSpin; and worked on Yahoo Search and BEA WebLogic. More articles by Stephen Hood…",
  "image": "https://hacks.mozilla.org/wp-content/uploads/2023/11/image-3.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"content-main\"\u003e\n  \u003carticle role=\"article\"\u003e\n    \u003cp\u003e\u003cem\u003eA special thanks to Justine Tunney of the Mozilla Internet Ecosystem (MIECO), who co-authored this blog post.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eToday we’re announcing the first release of \u003c/span\u003e\u003ca href=\"https://github.com/Mozilla-Ocho/llamafile\"\u003e\u003cspan\u003ellamafile\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e and inviting the open source community to participate in this new project.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003ellamafile lets you turn large language model (LLM) weights into executables.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eSay you have a set of LLM weights in the form of a 4GB file (in the commonly-used GGUF format). With llamafile you can transform that 4GB file into a binary that runs on six OSes without needing to be installed.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThis makes it dramatically easier to distribute and run LLMs. It also means that as models and their weights formats continue to evolve over time, llamafile gives you a way to ensure that a given set of weights will remain usable and perform consistently and reproducibly, forever.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWe achieved all this by combining two projects that we love:\u003c/span\u003e\u003ca href=\"https://github.com/ggerganov/llama.cpp\"\u003e \u003cspan\u003ellama.cpp\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e (a leading open source LLM chatbot framework) with\u003c/span\u003e\u003ca href=\"https://github.com/jart/cosmopolitan\"\u003e \u003cspan\u003eCosmopolitan Libc\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e (an open source project that enables C programs to be compiled and run on a large number of platforms and architectures). It also required solving several interesting and juicy problems along the way, such as adding GPU and dlopen() support to Cosmopolitan; you can read more about it in \u003c/span\u003e\u003ca href=\"https://github.com/Mozilla-Ocho/llamafile#readme\"\u003e\u003cspan\u003ethe project’s README\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eThis first release of llamafile is a product of Mozilla’s innovation group and developed by \u003c/span\u003e\u003ca href=\"https://justine.lol\"\u003e\u003cspan\u003eJustine Tunney\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, the creator of Cosmopolitan. Justine has recently been collaborating with Mozilla via \u003c/span\u003e\u003ca href=\"https://future.mozilla.org/mieco/\"\u003e\u003cspan\u003eMIECO\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e, and through that program Mozilla funded her work on the \u003c/span\u003e\u003ca href=\"https://justine.lol/cosmo3/\"\u003e\u003cspan\u003e3.0 release\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e  (\u003c/span\u003e\u003ca href=\"https://news.ycombinator.com/item?id=38101613\"\u003e\u003cspan\u003eHacker News discussion\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e) of Cosmopolitan. With llamafile, Justine is excited to be contributing more directly to Mozilla projects, and we’re happy to have her involved.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003ellamafile is licensed Apache 2.0, and we encourage contributions. Our changes to llama.cpp itself are licensed MIT (the same license used by llama.cpp itself) so as to facilitate any potential future upstreaming. We’re all big fans of llama.cpp around here; llamafile wouldn’t have been possible without it and Cosmopolitan.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003eWe hope llamafile is useful to you and look \u003c/span\u003e\u003ca href=\"https://github.com/Mozilla-Ocho/llamafile\"\u003e\u003cspan\u003eforward to your feedback\u003c/span\u003e\u003c/a\u003e\u003cspan\u003e.\u003c/span\u003e\u003c/p\u003e\n\n\n    \u003csection\u003e\n                                \n                      \u003cp\u003eStephen leads open source AI projects (including llamafile) in Mozilla\u0026#39;s Innovation group. He previously managed social bookmarking pioneer del.icio.us; co-founded Storium, Blockboard, and FairSpin; and worked on Yahoo Search and BEA WebLogic.\u003c/p\u003e\n                                \u003cp\u003e\u003ca href=\"https://hacks.mozilla.org/author/slangtonhoodmozilla-com/\"\u003eMore articles by Stephen Hood…\u003c/a\u003e\u003c/p\u003e\n                  \u003c/section\u003e\n  \u003c/article\u003e\n  \n  \n\n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "3 min read",
  "publishedTime": null,
  "modifiedTime": null
}
