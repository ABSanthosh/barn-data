{
  "id": "1c50ecb6-2518-485c-9726-a4860451b614",
  "title": "How we introduced Gemini to Chrome DevTools",
  "link": "https://developer.chrome.com/blog/how-we-introduced-gemini-to-devtools?hl=en",
  "description": "Learn about fun and exciting use-cases of the new AI assistance panel in DevTools",
  "author": "",
  "published": "Tue, 14 Jan 2025 08:00:00 GMT",
  "source": "https://developer.chrome.com/static/blog/feed.xml",
  "categories": null,
  "byline": "X",
  "length": 15372,
  "excerpt": "Learn about fun and exciting use-cases of the new AI assistance panel in DevTools",
  "siteName": "Chrome for Developers",
  "favicon": "https://www.gstatic.com/devrel-devsite/prod/vda41147226ae308b24384f785d31d739107d2716272d99cd11c490ff3892954d/chrome/images/favicon.png",
  "text": "Published: January 14, 2025 At last year's Google I/O 2024 we launched console insights, the first AI feature in Chrome DevTools. Console insights helps understand errors and warnings logged to the console by sending network data, source code and stack traces related to the log message to Gemini, Google's Large Language Model (LLM). Console insights sends a single prompt to Gemini that returns a single response without the possibility for developers to ask follow-up questions. While this single interaction flow works relatively well for explaining error messages, it does not scale to more complex debugging use cases inside DevTools where it is not clear what data from the inspected page an AI would require to help. One such use case is debugging styling issues. A single web page can contain thousands of elements and CSS rules, with only a subset of them being relevant to debugging a specific scenario. Identifying the right code to debug can be challenging, even for humans. But with a prototype built during an AI hackathon at Google we learned that LLMs are actually pretty decent at it. So naturally, we wanted to bring that power to DevTools users, creating a tool that is able to investigate styling issues by interactively querying the page for additional context data. What we built launched as AI assistance for styling a few months later. In this post we want to shine some light on challenges we faced while introducing AI to a loved product such as Chrome DevTools - which at its core, is a web app - and what you can adapt for your own AI features. Collecting the right data Console insights is always using the same data points to respond to a predefined prompt. For AI assistance to be helpful with any user-defined prompt we need to dynamically determine what context data is important for the query at hand. Therefore we implemented the ReAct (Yao et al., 2022) strategy. This prompting strategy empowers LLMs to reason autonomously and determine the subsequent action based on its reasoning. This way AI assistance operates in a cycle of thought, action, and observation until it determines a suitable response to the user's query, at which point it concludes the cycle and provides an answer. This iterative process allows the LLM to gather the precise information needed to effectively debug styling issues. A visual representation of the ReAct pattern as implemented for AI assistance. The prompt is sent to Gemini which returns a response including actions to apply to the inspected page through DevTools commands. The cycle repeats until the LLM determines a suitable response to the user's query. To gather information, we have given only one tool to Gemini: running JavaScript on the inspected page. This allows Gemini through AI assistance to, for example: Access and analyze the DOM: traverse the DOM tree, inspect element attributes, and understand the relationships between elements. Retrieve computed styles: access computed styles for any element. Perform calculations and measurements: execute JavaScript code to calculate distances, sizes, and positions of elements. This makes AI assistance interactively act on only relevant code, improving response quality, response time and the use of computing resources, compared to sending the full HTML and CSS source code to Gemini. Running AI-generated code in user space It may seem unexpected that for debugging styling issues we used JavaScript. There are two reasons for this: Web APIs are very powerful and inherently cover many debugging use cases. While it might be tedious for a developer to use API calls manually to traverse the DOM or access computed styles for debugging, it is not a problem for an LLM to generate code calling them. While it is possible to invent new APIs for an agent to use, reusing existing, public APIs often is the better choice, because they are already known to LLMs. Educating an LLM about a new API requires a lot of resources for fine-tuning and specific training data. But running AI generated code in user space has risks. For AI assistance we needed to minimize the risk of destructive changes that the agent might do to the page. For that, we employed the side-effect checks that V8, Chrome's JavaScript engine, exposes through the Chrome DevTools Protocol. The same checks are used for the auto-complete functionality in the DevTools Console: it only runs JavaScript code as long as it does not modify any page state. The checks are performed while V8 executes the code and are based on an allow list of JavaScript built-ins that are known to have no side effects. If the checks detect that generated code is modifying the inspected page, execution is paused, and the user is asked to review the code and confirm that it is okay to run. Additionally, generated JavaScript is run in a so-called isolated \"world\". That's similar to how extensions run sandbox scripts: the generated code is able to access the DOM and Web APIs but not able to access JavaScript code or state defined by the inspected page. Tracking changes done by the agent In addition to investigating issues and answering debugging questions about the page, we also wanted to give the AI assistance agent the ability to fix styles on the page in a way that is traceable by developers. To accomplish this, we implemented a binding called setElementStyles that we expose to the agent's execution context in addition to the default Web APIs. To make Gemini aware of that new method, we instruct it to use it in the AI assistance preamble: If you need to set styles on an HTML element, always call the \\`async setElementStyles(el: Element, styles: object)\\` function. Despite being an API specifically designed for the agent, which comes with the previously mentioned challenges, even without fine-tuning Gemini quite reliably uses it when it needs to change styles on a given element. On the DevTools side, when setElementStyles is called from the agent, AI assistance uses inspector stylesheets to record the change for the elements selector. CSS nesting is used to name the change and raise the specificity of the element's selector. An exemplary CSS rule created by the agent, thus, looks as following: .ai-style-change-1 { /* the ID is incremented for each change*/ .element-selector { /* Element selector is computed based on the element setElementStyles was called on. */ color: blue; } } While this doesn't solve all possible style conflicts that can happen on the page, it works for the majority of the cases. The benefit of using inspector stylesheets compared to inline styles is that this way changes performed by the agent also show up in the Changes panel, which makes it easier to track what changes to element styles have been made and what a developer needs to transfer to the underlying source code. The integration with the Changes panel also allows rolling back the changes if the change isn't needed anymore. Making agent actions observable for users When adding agentic features to a product, it's important to make agent actions transparent for users, so that they have a chance to trace, understand and potentially intervene. For AI assistance we therefore instruct Gemini to structure responses in a specific format with an addition to the preamble: You are going to answer to the query in these steps: * THOUGHT * TITLE * ACTION * ANSWER * SUGGESTIONS Use THOUGHT to explain why you take the ACTION. Use TITLE to provide a short summary of the thought. This structure is then used to present Gemini's thought processes and actions as initially collapsed steps, preventing information overload while still allowing users to examine the underlying details or stop execution in case of unintended side effects. Collapsed and a paused thinking steps in Chrome DevTools AI assistance. This approach isn't just about observing the AI; it's about actively learning from it. By expanding these sections, users can analyze the data Gemini deemed relevant for debugging a specific issue and understand the process it followed. This transparency allows users to learn from the AI's debugging strategies, so they can apply similar techniques to future challenges, even when working without AI. To further enhance the user experience, AI assistance also provides contextually relevant suggestions following the AI's answer. These suggestions streamline the conversation, offering ideas for the next debugging step or even allowing users to directly execute recommended fixes with a single click. Exemplary suggested follow-up prompts in AI assistance, generated as part of the response. Initially, to generate step titles and suggestions in AI assistance, we considered using a smaller, separate model specifically for summarization. However, we realized that the ReAct pattern, which structures the Gemini's reasoning into a loop of \"Thoughts\" and \"Actions\" can be effectively extended. So instead of introducing a second model, which would also come with additional latency, we modified our prompt to instruct Gemini to generate not only its core \"Thoughts\" and \"Actions,\" but also concise titles and helpful suggestions within the same ReAct loop. Eval driven development The development of AI assistance for styling was driven by a rigorous evaluation process. To measure its performance and identify areas for improvement, we curated a comprehensive collection of real-world web debugging examples, touching on common overflow problems, web components, animations and more. This enabled us to map the breadth of the web debugging problem space and thoroughly understand the associated challenges. But that's a job never done: with new features being added to the web platform on a regular basis we need to keep those examples up to date in the future. Those examples are fed into an automated evaluation pipeline, recording Gemini's responses. Data from those automated test runs are then made available in a custom-built tool in which we manually evaluate Gemini's performance for AI assistance against predefined rubrics, which inform our subsequent development efforts. This evaluation-driven approach ensures that all changes, whether refining existing behaviors or introducing new capabilities, are carefully verified to both achieve their intended improvements and prevent regressions in existing functionality. To further enhance our evaluation process, we are exploring automated verification methods, including: Assertions to confirm correct application of fixes Code-based checks to prevent undesired outputs from Gemini Utilizing LLMs as judges, guided by specific rubrics, to semi-automate and accelerate our manual evaluations While automated verification helps to scale, human feedback is important. We are collecting human feedback with voting controls under every response in AI assistance to learn how satisfied users are. An additional Report button allows users to give more exact feedback for disputable responses. Prompt injections A well-known and documented limitation of LLMs is that they are prone to prompt injections. Prompt injection is the technique of finding a way to overwrite the original system instructions of an LLM, making it output content not intended by the developers. Most models by now have built-in mitigations for prompt injection, as does Gemini. For AI assistance in addition we also try to mitigate this in our preamble by including the following instruction: If the user asks a question about religion, race, politics, sexuality, gender, or other sensitive topics, answer with \"Sorry, I can't answer that. I'm best at questions about debugging web pages. While this works for some explicit off-topic questions, it is not perfect. One drawback we noticed is that short and ambiguous queries might get classified as off-topic. Building off a solid foundation When introducing AI to your product for the first time it's worthwhile to go step by step, rather than take a single big jump at once. That's also how we approached it for AI assistance. With everything we learned when building the styling agent we created a solid foundation to extend AI assistance into other areas of DevTools later on. Having already solved most of the bigger challenges when working on the styling agent only a few months later we were able to introduce AI assistance for network, performance and sources and could focus on their individual challenges. Security implications when working with network requests AI assistance for network allows users to discuss specific network requests with Gemini, using data from the request as context for the conversation. Specifically the following data is sent to Gemini: Request Headers: A subset of headers sent by the browser to the server. Response Headers: A subset of headers returned by the server. Response Status: The HTTP status code indicating the server's response (for example 200, 404). Timings: Detailed timing information covering various phases of the request, such as connection setup and data transfer. Request Initiator Chain: The sequence of actions and scripts that initiated the request. While headers are important to fully understand how a request comes together, they bear a security risk: they might contain credentials like API keys, session tokens or even plain passwords. To protect such sensitive information, we don't transmit all headers to Gemini. Instead, we maintain an allow list of permitted headers. Values of headers not on the allowlist are replaced with \u003credacted\u003e. This approach ensures that Gemini receives the necessary context while protecting user data. Adapting to various data formats AI assistance for sources lets developers ask questions about a source file in the Sources panel, for example, \"What is this file for?\". The data about the file, including the filename, file content and whether it is source-mapped is all sent in a single prompt. This works well because it's just plain text. But large text files or binary files pose a challenge for LLMs. For binary files, we decided to indicate that the content is binary in the prompt and not send any actual content. For large text files, we only send a smaller part of the content taken from the beginning of the file. For AI assistance for performance, which allows developers to ask questions about a particular task from a recorded performance profile, there is a similar challenge to create a representation that fits into Gemini's context window and also can be interpreted to provide additional insights. To create such a presentation from a performance profile, we created a dedicated serializer called AiCallTree which formats the call tree for a task in a way that an LLM can process. Going forward we are going to explore the ReAct strategy here too, to minimize the amount of data that needs to be sent to Gemini upfront. AI assistance in the future The result of all this work is now available starting with Chrome 132, which includes AI assistance for styling, network, sources and performance. We hope you enjoy using it as much as we did building it. To get an idea where to start, check the comprehensive AI assistance quickstart guide with plenty of demo prompts to try on your own pages and make sure to let us know what you think in our open discussion bug.",
  "image": "https://developer.chrome.com/static/blog/how-we-introduced-gemini-to-devtools/image/thumbnail.jpg",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\n\n  \n    \n\n\n\n\n\u003cdiv translate=\"no\"\u003e\n  \n    \n    \n      \u003cdiv\u003e\n        \n          \u003cp\u003e\u003cimg alt=\"Alex Rudenko\" src=\"https://web.dev/images/authors/orkon.jpg\" decoding=\"async\" height=\"64\" loading=\"lazy\" width=\"64\"/\u003e\u003c/p\u003e\n      \u003c/div\u003e\n    \n  \n    \n    \n      \u003cdiv\u003e\n        \n          \u003cp\u003e\u003cimg alt=\"Ergün Erdogmus\" src=\"https://web.dev/images/authors/ergunsh.jpg\" decoding=\"async\" height=\"64\" loading=\"lazy\" width=\"64\"/\u003e\u003c/p\u003e\n      \u003c/div\u003e\n    \n  \n\u003c/div\u003e\n\n\u003cp\u003e\n  Published: January 14, 2025\n\u003c/p\u003e\n\n\n\u003cp\u003eAt last year\u0026#39;s Google I/O 2024 we launched \u003ca href=\"https://developer.chrome.com/docs/devtools/console/understand-messages\"\u003econsole insights\u003c/a\u003e,\nthe first AI feature in Chrome DevTools. Console insights helps understand errors and warnings logged to\nthe console by sending network data, source code and stack traces related to the\nlog message to Gemini, Google\u0026#39;s Large Language Model (LLM). Console insights\nsends a single prompt to Gemini that returns a single response without the\npossibility for developers to ask follow-up questions. While this single\ninteraction flow works relatively well for explaining error messages, it does\nnot scale to more complex debugging use cases inside DevTools where it is not\nclear what data from the inspected page an AI would require to help.\u003c/p\u003e\n\n\u003cp\u003eOne such use case is debugging styling issues. A single web page can contain\nthousands of elements and CSS rules, with only a subset of them being relevant\nto debugging a specific scenario. Identifying the right code to debug can be\nchallenging, even for humans. But with a prototype built during an AI hackathon\nat Google we learned that LLMs are actually pretty decent at it. So naturally,\nwe wanted to bring that power to DevTools users, creating a tool that is able to\ninvestigate styling issues by interactively querying the page for additional\ncontext data. What we built launched as \u003ca href=\"https://developer.chrome.com/docs/devtools/ai-assistance/styling\"\u003eAI assistance for styling\u003c/a\u003e a few months later.\u003c/p\u003e\n\n\u003cp\u003eIn this post we want to shine some light on challenges we faced while\nintroducing AI to a loved product such as Chrome DevTools - which at its core,\nis a web app - and what you can adapt for your own AI features.\u003c/p\u003e\n\n\u003ch2 id=\"collecting_the_right_data\" data-text=\"Collecting the right data\" tabindex=\"-1\"\u003eCollecting the right data\u003c/h2\u003e\n\n\u003cp\u003eConsole insights is always using the same data points to respond to a predefined\nprompt. For AI assistance to be helpful with any user-defined prompt we need to\ndynamically determine what context data is important for the query at hand.\u003c/p\u003e\n\n\u003cp\u003eTherefore we implemented the ReAct (\u003ca href=\"https://arxiv.org/abs/2210.03629\"\u003eYao et al., 2022\u003c/a\u003e)\nstrategy. This prompting strategy empowers LLMs to reason autonomously and determine\nthe subsequent action based on its reasoning.\u003c/p\u003e\n\n\u003cp\u003eThis way AI assistance operates in a cycle of thought, action, and observation\nuntil it determines a suitable response to the user\u0026#39;s query, at which point it\nconcludes the cycle and provides an answer. This iterative process allows the\nLLM to gather the precise information needed to effectively debug styling issues.\u003c/p\u003e\n\n\u003cfigure\u003e\n  \u003cimg src=\"https://developer.chrome.com/blog/how-we-introduced-gemini-to-devtools/image/react-diagram.jpg\" width=\"2682\" height=\"504\" alt=\"A visual representation of the ReAct pattern as implemented for AI assistance. The prompt is sent to Gemini which returns a response which applies actions to the inspected page through DevTools commands. The cycle repeats until the LLM determines a suitable response to the user\u0026#39;s query.\"/\u003e\n  \u003cfigcaption\u003eA visual representation of the ReAct pattern as implemented for AI assistance. The prompt is sent to Gemini which returns a response including actions to apply to the inspected page through DevTools commands. The cycle repeats until the LLM determines a suitable response to the user\u0026#39;s query.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eTo gather information, we have given only one tool to Gemini: running JavaScript\non the inspected page. This allows Gemini through AI assistance to, for example:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAccess and analyze the DOM\u003c/strong\u003e: traverse the DOM tree, inspect element\nattributes, and understand the relationships between elements.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRetrieve computed styles\u003c/strong\u003e: access computed styles for any element.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePerform calculations and measurements\u003c/strong\u003e: execute JavaScript code to\ncalculate distances, sizes, and positions of elements.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis makes AI assistance interactively act on only relevant code, improving\nresponse quality, response time and the use of computing resources, compared to\nsending the full HTML and CSS source code to Gemini.\u003c/p\u003e\n\n\u003ch2 id=\"running_ai-generated_code_in_user_space\" data-text=\"Running AI-generated code in user space\" tabindex=\"-1\"\u003eRunning AI-generated code in user space\u003c/h2\u003e\n\n\u003cp\u003eIt may seem unexpected that for debugging styling issues we used JavaScript.\nThere are two reasons for this:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eWeb APIs are very powerful and inherently cover many debugging use cases.\nWhile it might be tedious for a developer to use API calls manually to\ntraverse the DOM or access computed styles for debugging, it is not a\nproblem for an LLM to generate code calling them.\u003c/li\u003e\n\u003cli\u003eWhile it is possible to invent new APIs for an agent to use, reusing\nexisting, public APIs often is the better choice, because they are already\nknown to LLMs. Educating an LLM about a new API requires a lot of resources\nfor fine-tuning and specific training data.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eBut running AI generated code in user space has risks. For AI assistance we\nneeded to minimize the risk of destructive changes that the agent might do to\nthe page. For that, we employed the side-effect checks that \u003ca href=\"https://chromedevtools.github.io/devtools-protocol/tot/Runtime/#method-callFunctionOn\"\u003eV8, Chrome\u0026#39;s JavaScript engine, exposes\u003c/a\u003e\nthrough the Chrome DevTools Protocol. The same checks are used for the\nauto-complete functionality in the DevTools Console: it only runs JavaScript\ncode as long as it does not modify any page state. The checks are performed\nwhile V8 executes the code and are based on an\n\u003ca href=\"https://source.chromium.org/chromium/chromium/src/+/main:v8/src/debug/debug-evaluate.cc;l=561;drc=c803f15380d8ce9f618aaf3f31a2adb527e9da68\"\u003eallow list\u003c/a\u003e\nof JavaScript built-ins that are known to have no side effects.\u003c/p\u003e\n\n\u003cp\u003eIf the checks detect that generated code is modifying the inspected page,\nexecution is paused, and the user is asked to review the code and confirm that it\nis okay to run.\u003c/p\u003e\n\n\u003cp\u003eAdditionally, generated JavaScript is run in a so-called isolated \u003ca href=\"https://source.chromium.org/chromium/chromium/src/+/main:third_party/blink/renderer/bindings/core/v8/V8BindingDesign.md;l=133;drc=eb90eb0f510ccf69c0ac8043e8cfe608fea8f41b\"\u003e\u0026#34;world\u0026#34;\u003c/a\u003e.\nThat\u0026#39;s similar to how extensions run sandbox scripts: the generated code is able\nto access the DOM and Web APIs but not able to access JavaScript code or state\ndefined by the inspected page.\u003c/p\u003e\n\n\u003ch2 id=\"tracking_changes_done_by_the_agent\" data-text=\"Tracking changes done by the agent\" tabindex=\"-1\"\u003eTracking changes done by the agent\u003c/h2\u003e\n\n\u003cp\u003eIn addition to investigating issues and answering debugging questions about the\npage, we also wanted to give the AI assistance agent the ability to fix styles\non the page in a way that is traceable by developers.\u003c/p\u003e\n\n\u003cp\u003eTo accomplish this, we implemented a binding called \u003ccode translate=\"no\" dir=\"ltr\"\u003esetElementStyles\u003c/code\u003e that we\nexpose to the agent\u0026#39;s execution context in addition to the default Web APIs.\u003c/p\u003e\n\n\u003cp\u003eTo make Gemini aware of that new method, we instruct it to use it in the AI\nassistance preamble:\u003c/p\u003e\n\u003cdevsite-code\u003e\u003cpre translate=\"no\" dir=\"ltr\" is-upgraded=\"\"\u003e\u003ccode translate=\"no\" dir=\"ltr\"\u003eIf you need to set styles on an HTML element, always call the \\`async setElementStyles(el: Element, styles: object)\\` function.\n\u003c/code\u003e\u003c/pre\u003e\u003c/devsite-code\u003e\n\u003cp\u003eDespite being an API specifically designed for the agent, which comes with the\npreviously mentioned challenges, even without fine-tuning Gemini quite reliably\nuses it when it needs to change styles on a given element.\u003c/p\u003e\n\n\u003cp\u003eOn the DevTools side, when \u003ccode translate=\"no\" dir=\"ltr\"\u003esetElementStyles\u003c/code\u003e is called from the agent, AI\nassistance uses inspector stylesheets to record the change for the elements\nselector. CSS nesting is used to name the change and raise the specificity of\nthe element\u0026#39;s selector. An exemplary CSS rule created by the agent, thus, looks\nas following:\u003c/p\u003e\n\u003cdevsite-code\u003e\u003cpre translate=\"no\" dir=\"ltr\" is-upgraded=\"\" syntax=\"CSS\"\u003e\u003ccode translate=\"no\" dir=\"ltr\"\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eai-style-change-1\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e{\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e/* the ID is incremented for each change*/\u003c/span\u003e\n\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003e.element-selector\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e{\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003e/* Element selector is computed based on the element setElementStyles was called on. */\u003c/span\u003e\n\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003ecolor\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003eblue\u003c/span\u003e\u003cspan\u003e;\u003c/span\u003e\n\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003e}\u003c/span\u003e\n\u003cspan\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/devsite-code\u003e\n\u003cp\u003eWhile this doesn\u0026#39;t solve all possible style conflicts that can happen on the\npage, it works for the majority of the cases.\u003c/p\u003e\n\n\u003cp\u003eThe benefit of using inspector stylesheets compared to inline styles is that\nthis way changes performed by the agent also show up in the \u003ca href=\"https://developer.chrome.com/docs/devtools/changes\"\u003e\u003cstrong\u003eChanges\u003c/strong\u003e panel\u003c/a\u003e, which\nmakes it easier to track what changes to element styles have been made and what\na developer needs to transfer to the underlying source code. The integration\nwith the Changes panel also allows rolling back the changes if the change isn\u0026#39;t\nneeded anymore.\u003c/p\u003e\n\n\u003ch2 id=\"making_agent_actions_observable_for_users\" data-text=\"Making agent actions observable for users\" tabindex=\"-1\"\u003eMaking agent actions observable for users\u003c/h2\u003e\n\n\u003cp\u003eWhen adding agentic features to a product, it\u0026#39;s important to make agent actions\ntransparent for users, so that they have a chance to trace, understand and\npotentially intervene.\u003c/p\u003e\n\n\u003cp\u003eFor AI assistance we therefore instruct Gemini to structure responses in a\nspecific format with an addition to the preamble:\u003c/p\u003e\n\u003cdevsite-code\u003e\u003cpre translate=\"no\" dir=\"ltr\" is-upgraded=\"\"\u003e\u003ccode translate=\"no\" dir=\"ltr\"\u003eYou are going to answer to the query in these steps:\n*   THOUGHT\n*   TITLE\n*   ACTION\n*   ANSWER\n*   SUGGESTIONS\nUse THOUGHT to explain why you take the ACTION. Use TITLE to provide a short summary of the thought.\n\u003c/code\u003e\u003c/pre\u003e\u003c/devsite-code\u003e\n\u003cp\u003eThis structure is then used to present Gemini\u0026#39;s thought processes and actions as\ninitially collapsed steps, preventing information overload while still allowing\nusers to examine the underlying details or stop execution in case of unintended\nside effects.\u003c/p\u003e\n\n\u003cfigure\u003e\n  \u003cimg src=\"https://developer.chrome.com/blog/how-we-introduced-gemini-to-devtools/image/thinking-steps.png\" width=\"847\" height=\"518\" alt=\"Collapsed and a paused thinking steps in Chrome DevTools AI assistance.\"/\u003e\n  \u003cfigcaption\u003eCollapsed and a paused thinking steps in Chrome DevTools AI assistance.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eThis approach isn\u0026#39;t just about observing the AI; it\u0026#39;s about actively learning\nfrom it. By expanding these sections, users can analyze the data Gemini deemed\nrelevant for debugging a specific issue and understand the process it followed.\nThis transparency allows users to learn from the AI\u0026#39;s debugging strategies, so\nthey can apply similar techniques to future challenges, even when working\nwithout AI.\u003c/p\u003e\n\n\u003cp\u003eTo further enhance the user experience, AI assistance also provides contextually\nrelevant suggestions following the AI\u0026#39;s answer. These suggestions streamline the\nconversation, offering ideas for the next debugging step or even allowing users\nto directly execute recommended fixes with a single click.\u003c/p\u003e\n\n\u003cfigure\u003e\n  \u003cimg src=\"https://developer.chrome.com/blog/how-we-introduced-gemini-to-devtools/image/suggested-prompts.png\" width=\"917\" height=\"142\" alt=\"Exemplary suggested follow-up prompts in AI assistance, generated as part of the response.\"/\u003e\n  \u003cfigcaption\u003eExemplary suggested follow-up prompts in AI assistance, generated as part of the response.\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eInitially, to generate step titles and suggestions in AI assistance, we\nconsidered using a smaller, separate model specifically for summarization.\nHowever, we realized that the ReAct pattern, which structures the Gemini\u0026#39;s\nreasoning into a loop of \u0026#34;Thoughts\u0026#34; and \u0026#34;Actions\u0026#34; can be effectively extended.\nSo instead of introducing a second model, which would also come with additional latency, we modified our\n\u003ca href=\"https://source.chromium.org/chromium/chromium/src/+/main:third_party/devtools-frontend/src/front_end/panels/ai_assistance/agents/StylingAgent.ts;l=50;drc=f63da124ddddc34f8b2595fbff342c633e0b21d2\"\u003eprompt\u003c/a\u003e\nto instruct Gemini to generate not only its core \u0026#34;Thoughts\u0026#34; and \u0026#34;Actions,\u0026#34; but\nalso concise titles and helpful suggestions within the same ReAct loop.\u003c/p\u003e\n\n\u003ch2 id=\"eval_driven_development\" data-text=\"Eval driven development\" tabindex=\"-1\"\u003eEval driven development\u003c/h2\u003e\n\n\u003cp\u003eThe development of AI assistance for styling was driven by a rigorous evaluation\nprocess. To measure its performance and identify areas for improvement, we\ncurated a comprehensive collection of real-world web debugging examples,\ntouching on common overflow problems, web components, animations and more. This\nenabled us to map the breadth of the web debugging problem space and thoroughly\nunderstand the associated challenges. But that\u0026#39;s a job never done: with new\nfeatures being added to the web platform on a regular basis we need to keep those\nexamples up to date in the future.\u003c/p\u003e\n\n\u003cp\u003eThose examples are fed into an automated evaluation pipeline, recording Gemini\u0026#39;s\nresponses. Data from those automated test runs are then made available in a\ncustom-built tool in which we manually evaluate Gemini\u0026#39;s performance for AI\nassistance against predefined rubrics, which inform our subsequent development\nefforts.\u003c/p\u003e\n\n\u003cp\u003eThis evaluation-driven approach ensures that all changes, whether refining\nexisting behaviors or introducing new capabilities, are carefully verified to\nboth achieve their intended improvements and prevent regressions in existing\nfunctionality.\u003c/p\u003e\n\n\u003cp\u003eTo further enhance our evaluation process, we are exploring automated\nverification methods, including:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAssertions to confirm correct application of fixes\u003c/li\u003e\n\u003cli\u003eCode-based checks to prevent undesired outputs from Gemini\u003c/li\u003e\n\u003cli\u003eUtilizing LLMs as judges, guided by specific rubrics, to semi-automate and accelerate our\nmanual evaluations\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhile automated verification helps to scale, human feedback is important. We are\ncollecting human feedback with voting controls under every response in AI\nassistance to learn how satisfied users are. An additional Report button allows\nusers to give more exact feedback for disputable responses.\u003c/p\u003e\n\n\u003ch2 id=\"prompt_injections\" data-text=\"Prompt injections\" tabindex=\"-1\"\u003ePrompt injections\u003c/h2\u003e\n\n\u003cp\u003eA well-known and documented limitation of LLMs is that they are prone to \u003ca href=\"https://developer.chrome.com/docs/devtools/ai-assistance#prompt-injection\"\u003eprompt injections\u003c/a\u003e.\nPrompt injection is the technique of finding a way to overwrite the original\nsystem instructions of an LLM, making it output content not intended by the\ndevelopers.\u003c/p\u003e\n\n\u003cp\u003eMost models by now have built-in mitigations for prompt injection, as does\nGemini. For AI assistance in addition we also try to mitigate this in our\npreamble by including the following instruction:\u003c/p\u003e\n\u003cdevsite-code\u003e\u003cpre translate=\"no\" dir=\"ltr\" is-upgraded=\"\"\u003e\u003ccode translate=\"no\" dir=\"ltr\"\u003eIf the user asks a question about religion, race, politics, sexuality, gender, or other sensitive topics, answer with \u0026#34;Sorry, I can\u0026#39;t answer that. I\u0026#39;m best at questions about debugging web pages.\n\u003c/code\u003e\u003c/pre\u003e\u003c/devsite-code\u003e\n\u003cp\u003eWhile this works for some explicit off-topic questions, it is not perfect. One\ndrawback we noticed is that short and ambiguous queries might get classified as\noff-topic.\u003c/p\u003e\n\n\u003ch2 id=\"building_off_a_solid_foundation\" data-text=\"Building off a solid foundation\" tabindex=\"-1\"\u003eBuilding off a solid foundation\u003c/h2\u003e\n\n\u003cp\u003eWhen introducing AI to your product for the first time it\u0026#39;s worthwhile to go\nstep by step, rather than take a single big jump at once. That\u0026#39;s also how we\napproached it for AI assistance. With everything we learned when building the\nstyling agent we created a solid foundation to extend AI assistance into other\nareas of DevTools later on.\u003c/p\u003e\n\n\u003cp\u003eHaving already solved most of the bigger challenges when working on the styling\nagent only a few months later we were able to introduce AI assistance for\nnetwork, performance and sources and could focus on their individual challenges.\u003c/p\u003e\n\n\u003ch3 id=\"security_implications_when_working_with_network_requests\" data-text=\"Security implications when working with network requests\" tabindex=\"-1\"\u003eSecurity implications when working with network requests\u003c/h3\u003e\n\n\u003cp\u003eAI assistance for network allows users to discuss specific network requests with\nGemini, using data from the request as context for the conversation.\nSpecifically the following data is sent to Gemini:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eRequest Headers\u003c/strong\u003e: A subset of headers sent by the browser to the server.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResponse Headers\u003c/strong\u003e: A subset of headers returned by the server.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResponse Status\u003c/strong\u003e: The HTTP status code indicating the server\u0026#39;s response\n(for example 200, 404).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTimings\u003c/strong\u003e: Detailed timing information covering various phases of the\nrequest, such as connection setup and data transfer.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRequest Initiator Chain\u003c/strong\u003e: The sequence of actions and scripts that\ninitiated the request.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhile headers are important to fully understand how a request comes together,\nthey bear a security risk: they might contain credentials like API keys, session\ntokens or even plain passwords. To protect such sensitive information, we don\u0026#39;t\ntransmit all headers to Gemini. Instead, we maintain an allow list of permitted\nheaders. Values of headers not on the allowlist are\nreplaced with \u003ccode translate=\"no\" dir=\"ltr\"\u003e\u0026lt;redacted\u0026gt;\u003c/code\u003e. This approach ensures that Gemini receives the\nnecessary context while protecting user data.\u003c/p\u003e\n\n\u003ch3 id=\"adapting_to_various_data_formats\" data-text=\"Adapting to various data formats\" tabindex=\"-1\"\u003eAdapting to various data formats\u003c/h3\u003e\n\n\u003cp\u003eAI assistance for sources lets developers ask questions about a source file in\nthe Sources panel, for example, \u0026#34;What is this file for?\u0026#34;.\u003c/p\u003e\n\n\u003cp\u003eThe data about the file, including the filename, file content and whether it is\nsource-mapped is all sent in a single prompt. This works well because it\u0026#39;s just\nplain text. But large text files or binary files pose a challenge for LLMs. For binary\nfiles, we decided to indicate that the content is binary in the prompt and not\nsend any actual content. For large text files, we only send a smaller part of the\ncontent taken from the beginning of the file.\u003c/p\u003e\n\n\u003cp\u003eFor AI assistance for performance, which allows developers to ask questions\nabout a particular task from a recorded performance profile, there is a similar\nchallenge to create a representation that fits into Gemini\u0026#39;s context window and\nalso can be interpreted to provide additional insights.\u003c/p\u003e\n\n\u003cp\u003eTo create such a presentation from a performance profile, we created a dedicated\nserializer called\n\u003ca href=\"https://source.chromium.org/chromium/chromium/src/+/main:third_party/devtools-frontend/src/front_end/panels/timeline/utils/AICallTree.ts;l=22;drc=1f1d642265eb4be3d20beca43b0bd259a8f33a9d\"\u003e\u003ccode translate=\"no\" dir=\"ltr\"\u003eAiCallTree\u003c/code\u003e\u003c/a\u003e\nwhich formats the call tree for a task in a way that an LLM can process. Going\nforward we are going to explore the ReAct strategy here too, to minimize the \namount of data that needs to be sent to Gemini upfront.\u003c/p\u003e\n\n\u003ch2 id=\"ai_assistance_in_the_future\" data-text=\"AI assistance in the future\" tabindex=\"-1\"\u003eAI assistance in the future\u003c/h2\u003e\n\n\u003cp\u003eThe result of all this work is now available starting with Chrome 132, which\nincludes AI assistance for styling, network, sources and performance. We hope\nyou enjoy using it as much as we did building it.\u003c/p\u003e\n\n\u003cp\u003eTo get an idea where to start, check the comprehensive \u003ca href=\"https://developer.chrome.com/docs/devtools/ai-assistance/quickstart\"\u003eAI assistance quickstart\nguide\u003c/a\u003e with plenty of demo prompts to\ntry on your own pages and make sure to let us know what you think in our open\n\u003ca href=\"https://crbug.com/364805393\"\u003ediscussion bug\u003c/a\u003e.\u003c/p\u003e\n\n  \n\n  \n\u003c/div\u003e\u003c/div\u003e",
  "readingTime": "16 min read",
  "publishedTime": null,
  "modifiedTime": null
}
