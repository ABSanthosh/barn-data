{
  "id": "d8625fbb-b9b7-4c6a-a86c-4ef02bf16fa9",
  "title": "Mozilla AI Guide Launch with Summarization Code Example",
  "link": "https://hacks.mozilla.org/2023/11/mozilla-ai-guide-launch-with-summarization-code-example/",
  "description": "Mozilla has just launched the AI Guide, a collaborative hub for developers to join forces, inspire each other, and lead the way in groundbreaking generative AI advancements. The AI Guide’s initial focus begins with language models and the aim is to become a collaborative community-driven resource covering other types of models. The post Mozilla AI Guide Launch with Summarization Code Example appeared first on Mozilla Hacks - the Web developer blog.",
  "author": "Melissa Thermidor",
  "published": "Thu, 16 Nov 2023 16:20:15 +0000",
  "source": "https://hacks.mozilla.org/feed/",
  "categories": [
    "Featured Article",
    "Firefox",
    "Mozilla",
    "AI",
    "firefox",
    "innovation",
    "language models",
    "mozilla"
  ],
  "byline": "By Melissa Thermidor",
  "length": 17645,
  "excerpt": "Mozilla has just launched the AI Guide, a collaborative hub for developers to join forces and lead the way in AI advancements.",
  "siteName": "Mozilla Hacks – the Web developer blog",
  "favicon": "",
  "text": "The Mozilla AI Guide has launched and we welcome you to read through and get acquainted with it. You can access it here Our vision is for the AI Guide to be the starting point for every new developer to the space and a place to revisit for clarity and inspiration, ensuring that AI innovations enrich everyday life. The AI Guide’s initial focus begins with language models and the aim is to become a collaborative community-driven resource covering other types of models. To start the first few sections in the Mozilla AI Guide go in-depth on the most asked questions about Large Language Models (LLMs). AI Basics covers the concepts of AI, ML, LLMs, what these concepts mean and how they are related. This section also breaks down the pros and cons of using an LLM. Language Models 101 continues to build on the shared knowledge of AI basics and dives deeper into the next level with language models. It will answer questions such as “What does ‘training’ an ML model mean” or “What is ‘human in the loop’ approach?” We will jump to the last section on Choosing ML Models and demonstrate in code below what can be done using open source models to summarize certain text. You can access the Colab Notebook here or continue reading: First Steps with Language Models Unlike other guides, this one is designed to help pick the right model for whatever it is you’re trying to do, by: teaching you how to always remain on the bleeding edge of published AI research broadening your perspective on current open options for any given task not be tied to a closed-source / closed-data large language model (ex OpenAI, Anthropic) creating a data-led system for always identifying and using the state-of-the-art (SOTA) model for any particular task. We’re going to hone in on “text summarization” as our first task. So… why are we not using one of the popular large language models? Great question. Most available LLMs worth their salt can do many tasks, including summarization, but not all of them may be good at what specifically you want them to do. We should figure out how to evaluate whether they actually can or not. Also, many of the current popular LLMs are not open, are trained on undisclosed data and exhibit biases. Responsible AI use requires careful choices, and we’re here to help you make them. Finally, most large LLMs require powerful GPU compute to use. While there are many models that you can use as a service, most of them cost money per API call. Unnecessary when some of the more common tasks can be done at good quality with already available open models and off-the-shelf hardware. Why do using open models matter? Over the last few decades, engineers have been blessed with being able to onboard by starting with open source projects, and eventually shipping open source to production. This default state is now at risk. Yes, there are many open models available that do a great job. However, most guides don’t discuss how to get started with them using simple steps and instead bias towards existing closed APIs. Funding is flowing to commercial AI projects, who have larger budgets than open source contributors to market their work, which inevitably leads to engineers starting with closed source projects and shipping expensive closed projects to production. Our First Project – Summarization We’re going to: Find text to summarize. Figure out how to summarize them using the current state-of-the-art open source models. Write some code to do so. Evaluate quality of results using relevant metrics For simplicity’s sake, let’s grab Mozilla’s Trustworthy AI Guidelines in string form Note that in the real world, you will likely have to use other libraries to extract content for any particular file type. import textwrap content = \"\"\"Mozilla's \"Trustworthy AI\" Thinking Points: PRIVACY: How is data collected, stored, and shared? Our personal data powers everything from traffic maps to targeted advertising. Trustworthy AI should enable people to decide how their data is used and what decisions are made with it. FAIRNESS: We’ve seen time and again how bias shows up in computational models, data, and frameworks behind automated decision making. The values and goals of a system should be power aware and seek to minimize harm. Further, AI systems that depend on human workers should protect people from exploitation and overwork. TRUST: People should have agency and control over their data and algorithmic outputs, especially considering the high stakes for individuals and societies. For instance, when online recommendation systems push people towards extreme, misleading content, potentially misinforming or radicalizing them. SAFETY: AI systems can carry high risk for exploitation by bad actors. Developers need to implement strong measures to protect our data and personal security. Further, excessive energy consumption and extraction of natural resources for computing and machine learning accelerates the climate crisis. TRANSPARENCY: Automated decisions can have huge personal impacts, yet the reasons for decisions are often opaque. We need to mandate transparency so that we can fully understand these systems and their potential for harm.\"\"\" Great. Now we’re ready to start summarizing. A brief pause for context The AI space is moving so fast that it requires a tremendous amount of catching up on scientific papers each week to understand the lay of the land and the state of the art. It’s some effort for an engineer who is brand new to AI to: discover which open models are even out there which models are appropriate for any particular task which benchmarks are used to evaluate those models which models are performing well based on evaluations which models can actually run on available hardware For the working engineer on a deadline, this is problematic. There’s not much centralized discourse on working with open source AI models. Instead there are fragmented X (formerly Twitter) threads, random private groups and lots of word-of-mouth transfer. However, once we have a workflow to address all of the above, you will have the means to forever be on the bleeding age of published AI research How do I get a list of available open summarization models? For now, we recommend Huggingface and their large directory of open models broken down by task. This is a great starting point. Note that larger LLMs are also included in these lists, so we will have to filter. In this huge list of summarization models, which ones do we choose? We don’t know what any of these models are trained on. For example, a summarizer trained on news articles vs Reddit posts will perform better on news articles. What we need is a set of metrics and benchmarks that we can use to do apples-to-apples comparisons of these models. How do I evaluate summarization models? The steps below can be used to evaluate any available model for any task. It requires hopping between a few sources of data for now, but we will be making this a lot easier moving forward. Steps: Find the most common datasets used to train models for summarization. Find the most common metrics used to evaluate models for summarization across those datasets. Do a quick audit on training data provenance, quality and any exhibited biases, to keep in line with Responsible AI usage. Finding datasets The easiest way to do this is using Papers With Code, an excellent resource for finding the latest scientific papers by task that also have code repositories attached. First, filter Papers With Code’s “Text Summarization” datasets by most cited text-based English datasets. Let’s pick (as of this writing) the most cited dataset — the “CNN/DailyMail” dataset. Usually most cited is one marker of popularity. Now, you don’t need to download this dataset. But we’re going to review the info Papers With Code have provided to learn more about it for the next step. This dataset is also available on Huggingface. You want to check 3 things: license recent papers whether the data is traceable and the methods are transparent First, check the license. In this case, it’s MIT licensed, which means it can be used for both commercial and personal projects. Next, see if the papers using this dataset are recent. You can do this by sorting Papers in descending order. This particular dataset has many papers from 2023 – great! Finally, let’s check whether the data is from a credible source. In this case, the dataset was generated by IBM in partnership with the University of Montréal. Great. Now, let’s dig into how we can evaluate models that use this dataset. Evaluating models Next, we look for measured metrics that are common across datasets for the summarization task. BUT, if you’re not familiar with the literature on summarization, you have no idea what those are. To find out, pick a “Subtask” that’s close to what you’d like to see. We’d like to summarize the CNN article we pulled down above, so let’s choose “Abstractive Text Summarization”. Now we’re in business! This page contains a significant amount of new information. There are mentions of three new terms: ROUGE-1, ROUGE-2 and ROUGE-L. These are the metrics that are used to measure summarization performance. There is also a list of models and their scores on these three metrics – this is exactly what we’re looking for. Assuming we’re looking at ROUGE-1 as our metric, we now have the top 3 models that we can evaluate in more detail. All 3 are close to 50, which is a promising ROUGE score (read up on ROUGE). Testing out a model OK, we have a few candidates, so let’s pick a model that will run on our local machines. Many models get their best performance when running on GPUs, but there are many that also generate summaries fast on CPUs. Let’s pick one of those to start – Google’s Pegasus. # first we install huggingface's transformers library %pip install transformers sentencepiece Then we find Pegasus on Huggingface. Note that part of the datasets Pegasus was trained on includes CNN/DailyMail which bodes well for our article summarization. Interestingly, there’s a variant of Pegasus from google that’s only trained on our dataset of choice, we should use that. from transformers import PegasusForConditionalGeneration, PegasusTokenizer import torch # Set the seed, this will help reproduce results. Changing the seed will # generate new results from transformers import set_seed set_seed(248602) # We're using the version of Pegasus specifically trained for summarization # using the CNN/DailyMail dataset model_name = \"google/pegasus-cnn_dailymail\" # If you're following along in Colab, switch your runtime to a # T4 GPU or other CUDA-compliant device for a speedup device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Load the tokenizer tokenizer = PegasusTokenizer.from_pretrained(model_name) # Load the model model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device) # Tokenize the entire content batch = tokenizer(content, padding=\"longest\", return_tensors=\"pt\").to(device) # Generate the summary as tokens summarized = model.generate(**batch) # Decode the tokens back into text summarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True) summarized_text = summarized_decoded[0] # Compare def compare(original, summarized_text): print(f\"Article text length: {len(original)}\\n\") print(textwrap.fill(summarized_text, 100)) print() print(f\"Summarized length: {len(summarized_text)}\") compare(content, summarized_text) Article text length: 1427 Trustworthy AI should enable people to decide how their data is used.\u003cn\u003evalues and goals of a system should be power aware and seek to minimize harm.\u003cn\u003ePeople should have agency and control over their data and algorithmic outputs.\u003cn\u003eDevelopers need to implement strong measures to protect our data and personal security. Summarized length: 320 Alright, we got something! Kind of short though. Let’s see if we can make the summary longer… set_seed(860912) # Generate the summary as tokens, with a max_new_tokens summarized = model.generate(**batch, max_new_tokens=800) summarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True) summarized_text = summarized_decoded[0] compare(content, summarized_text) Article text length: 1427 Trustworthy AI should enable people to decide how their data is used.\u003cn\u003evalues and goals of a system should be power aware and seek to minimize harm.\u003cn\u003ePeople should have agency and control over their data and algorithmic outputs.\u003cn\u003eDevelopers need to implement strong measures to protect our data and personal security. Summarized length: 320 Well, that didn’t really work. Let’s try a different approach called ‘sampling’. This allows the model to pick the next word according to its conditional probability distribution (specifically, the probability that said word follows the word before). We’ll also be setting the ‘temperature’. This variable works to control the levels of randomness and creativity in the generated output. set_seed(118511) summarized = model.generate(**batch, do_sample=True, temperature=0.8, top_k=0) summarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True) summarized_text = summarized_decoded[0] compare(content, summarized_text) Article text length: 1427 Mozilla's \"Trustworthy AI\" Thinking Points:.\u003cn\u003ePeople should have agency and control over their data and algorithmic outputs.\u003cn\u003eDevelopers need to implement strong measures to protect our data. Summarized length: 193 Shorter, but the quality is higher. Adjusting the temperature up will likely help. set_seed(108814) summarized = model.generate(**batch, do_sample=True, temperature=1.0, top_k=0) summarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True) summarized_text = summarized_decoded[0] compare(content, summarized_text) Article text length: 1427 Mozilla's \"Trustworthy AI\" Thinking Points:.\u003cn\u003ePeople should have agency and control over their data and algorithmic outputs.\u003cn\u003eDevelopers need to implement strong measures to protect our data and personal security.\u003cn\u003eWe need to mandate transparency so that we can fully understand these systems and their potential for harm. Summarized length: 325 Now let’s play with one other generation approach called top_k sampling — instead of considering all possible next words in the vocabulary, the model only considers the top ‘k’ most probable next words. This technique helps to focus the model on likely continuations and reduces the chances of generating irrelevant or nonsensical text. It strikes a balance between creativity and coherence by limiting the pool of next-word choices, but not so much that the output becomes deterministic. set_seed(226012) summarized = model.generate(**batch, do_sample=True, top_k=50) summarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True) summarized_text = summarized_decoded[0] compare(content, summarized_text) Article text length: 1427 Mozilla's \"Trustworthy AI\" Thinking Points look at ethical issues surrounding automated decision making.\u003cn\u003evalues and goals of a system should be power aware and seek to minimize harm.People should have agency and control over their data and algorithmic outputs.\u003cn\u003eDevelopers need to implement strong measures to protect our data and personal security. Summarized length: 355 Finally, let’s try top_p sampling — also known as nucleus sampling, is a strategy where the model considers only the smallest set of top words whose cumulative probability exceeds a threshold ‘p’. Unlike top_k which considers a fixed number of words, top_p adapts based on the distribution of probabilities for the next word. This makes it more dynamic and flexible. It helps create diverse and sensible text by allowing less probable words to be selected when the most probable ones don’t add up to ‘p’. set_seed(21420041) summarized = model.generate(**batch, do_sample=True, top_p=0.9, top_k=50) summarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True) summarized_text = summarized_decoded[0] compare(content, summarized_text) # saving this for later. pegasus_summarized_text = summarized_text Article text length: 1427 Mozilla's \"Trustworthy AI\" Thinking Points:.\u003cn\u003ePeople should have agency and control over their data and algorithmic outputs.\u003cn\u003eDevelopers need to implement strong measures to protect our data and personal security.\u003cn\u003eWe need to mandate transparency so that we can fully understand these systems and their potential for harm. Summarized length: 325 To continue with the code example and see a test with another model, and to learn how to evaluate ML model results (a whole another section), click here to view the Python Notebook and click “Open in Colab” to experiment with your own custom code. Note this guide will be constantly updated and new sections on Data Retrieval, Image Generation, and Fine Tuning will be coming next. Developer Contributions Are Vital Shortly after today’s launch of the Mozilla AI Guide, we will be publishing our community contribution guidelines. It will provide guidance on the type of content developers can contribute and how it can be shared. Get ready to share any great open source AI projects, implementations, video and audio models. Together, we can bring together a cohesive, collaborative and responsible AI community. A special thanks to Kevin Li and Pradeep Elankumaran who pulled this great blog post together. Melissa is a Senior Internet Advertising Specialist at Mozilla More articles by Melissa Thermidor…",
  "image": "https://hacks.mozilla.org/wp-content/uploads/2023/11/Social-post.png",
  "html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003carticle role=\"article\"\u003e\n    \u003cp\u003eThe Mozilla AI Guide has launched and we welcome you to read through and get acquainted with it. You can access it \u003ca href=\"https://ai-guide.future.mozilla.org/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur vision is for the AI Guide to be the starting point for every new developer to the space and a place to revisit for clarity and inspiration, ensuring that AI innovations enrich everyday life. The AI Guide’s initial focus begins with language models and the aim is to become a collaborative community-driven resource covering other types of models.\u003c/p\u003e\n\u003cp\u003eTo start the first few sections in the Mozilla AI Guide go in-depth on the most asked questions about Large Language Models (LLMs). \u003ca href=\"https://ai-guide.future.mozilla.org/content/ai-basics/\"\u003eAI Basics\u003c/a\u003e covers the concepts of AI, ML, LLMs, what these concepts mean and how they are related. This section also breaks down the pros and cons of using an LLM. \u003ca href=\"https://ai-guide.future.mozilla.org/content/llms-101/\"\u003eLanguage Models 101\u003c/a\u003e continues to build on the shared knowledge of AI basics and dives deeper into the next level with language models. It will answer questions such as “What does ‘training’ an ML model mean” or “What is ‘human in the loop’ approach?”\u003c/p\u003e\n\u003cp\u003eWe will jump to the last section on \u003ca href=\"https://ai-guide.future.mozilla.org/content/choosing-ml-models/\"\u003eChoosing ML Models\u003c/a\u003e and demonstrate in code below what can be done using open source models to summarize certain text. You can access the Colab Notebook \u003ca href=\"https://ai-guide.future.mozilla.org/content/choosing-ml-models/\"\u003ehere\u003c/a\u003e or continue reading:\u003c/p\u003e\n\u003ch2\u003eFirst Steps with Language Models\u003c/h2\u003e\n\u003cp\u003eUnlike other guides, this one is designed to help pick the right model for whatever it is you’re trying to do, by:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eteaching you how to always remain on the bleeding edge of published AI research\u003c/li\u003e\n\u003cli\u003ebroadening your perspective on current open options for any given task\u003c/li\u003e\n\u003cli\u003enot be tied to a closed-source / closed-data large language model (ex OpenAI, Anthropic)\u003c/li\u003e\n\u003cli\u003ecreating a data-led system for always identifying and using the state-of-the-art (SOTA) model for any particular task.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe’re going to hone in on “text summarization” as our first task.\u003c/p\u003e\n\u003ch2\u003eSo… why are we not using one of the popular large language models?\u003c/h2\u003e\n\u003cp\u003eGreat question. Most available LLMs worth their salt can do many tasks, including summarization, but not all of them may be good at what specifically you want them to do. We should figure out how to evaluate whether they actually can or not.\u003c/p\u003e\n\u003cp\u003eAlso, many of the current popular LLMs are not open, are trained on undisclosed data and exhibit biases. Responsible AI use requires careful choices, and we’re here to help you make them.\u003c/p\u003e\n\u003cp\u003eFinally, most large LLMs require powerful GPU compute to use. While there are many models that you can use as a service, most of them cost money per API call. Unnecessary when some of the more common tasks can be done at good quality with already available open models and off-the-shelf hardware.\u003c/p\u003e\n\u003ch2\u003eWhy do using open models matter?\u003c/h2\u003e\n\u003cp\u003eOver the last few decades, engineers have been blessed with being able to onboard by starting with open source projects, and eventually shipping open source to production. This default state is now at risk.\u003c/p\u003e\n\u003cp\u003eYes, there are many open models available that do a great job. However, most guides don’t discuss how to get started with them using simple steps and instead bias towards existing closed APIs.\u003c/p\u003e\n\u003cp\u003eFunding is flowing to commercial AI projects, who have larger budgets than open source contributors to market their work, which inevitably leads to engineers starting with closed source projects and shipping expensive closed projects to production.\u003c/p\u003e\n\u003ch2\u003eOur First Project – Summarization\u003c/h2\u003e\n\u003cp\u003eWe’re going to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFind text to summarize.\u003c/li\u003e\n\u003cli\u003eFigure out how to summarize them using the current state-of-the-art open source models.\u003c/li\u003e\n\u003cli\u003eWrite some code to do so.\u003c/li\u003e\n\u003cli\u003eEvaluate quality of results using relevant metrics\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor simplicity’s sake, let’s grab \u003cstrong\u003eMozilla’s Trustworthy AI Guidelines\u003c/strong\u003e in string form\u003c/p\u003e\n\u003cp\u003eNote that in the real world, you will likely have to use other libraries to extract content for any particular file type.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport textwrap\n\ncontent = \u0026#34;\u0026#34;\u0026#34;Mozilla\u0026#39;s \u0026#34;Trustworthy AI\u0026#34; Thinking Points:\n\nPRIVACY: How is data collected, stored, and shared? Our personal data powers everything from traffic maps to targeted advertising. Trustworthy AI should enable people to decide how their data is used and what decisions are made with it.\n\nFAIRNESS: We’ve seen time and again how bias shows up in computational models, data, and frameworks behind automated decision making. The values and goals of a system should be power aware and seek to minimize harm. Further, AI systems that depend on human workers should protect people from exploitation and overwork.\n\nTRUST: People should have agency and control over their data and algorithmic outputs, especially considering the high stakes for individuals and societies. For instance, when online recommendation systems push people towards extreme, misleading content, potentially misinforming or radicalizing them.\n\nSAFETY: AI systems can carry high risk for exploitation by bad actors. Developers need to implement strong measures to protect our data and personal security. Further, excessive energy consumption and extraction of natural resources for computing and machine learning accelerates the climate crisis.\n\nTRANSPARENCY: Automated decisions can have huge personal impacts, yet the reasons for decisions are often opaque. We need to mandate transparency so that we can fully understand these systems and their potential for harm.\u0026#34;\u0026#34;\u0026#34;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eGreat. Now we’re ready to start summarizing.\u003c/p\u003e\n\u003ch2\u003eA brief pause for context\u003c/h2\u003e\n\u003cp\u003eThe AI space is moving so fast that it requires a tremendous amount of catching up on scientific papers each week to understand the lay of the land and the state of the art.\u003c/p\u003e\n\u003cp\u003eIt’s some effort for an engineer who is brand new to AI to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ediscover which open models are even out there\u003c/li\u003e\n\u003cli\u003ewhich models are appropriate for any particular task\u003c/li\u003e\n\u003cli\u003ewhich benchmarks are used to evaluate those models\u003c/li\u003e\n\u003cli\u003ewhich models are performing well based on evaluations\u003c/li\u003e\n\u003cli\u003ewhich models can actually run on available hardware\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor the working engineer on a deadline, this is problematic. There’s not much centralized discourse on working with open source AI models. Instead there are fragmented X (formerly Twitter) threads, random private groups and lots of word-of-mouth transfer.\u003c/p\u003e\n\u003cp\u003eHowever, once we have a workflow to address all of the above, you will have the means to forever be on the bleeding age of published AI research\u003c/p\u003e\n\u003ch2\u003eHow do I get a list of available open summarization models?\u003c/h2\u003e\n\u003cp\u003eFor now, we recommend \u003ca href=\"https://huggingface.co/models?pipeline_tag=summarization\"\u003eHuggingface\u003c/a\u003e and their large directory of open models broken down by task. This is a great starting point. Note that larger LLMs are also included in these lists, so we will have to filter.\u003c/p\u003e\n\u003cp\u003eIn this huge list of summarization models, which ones do we choose?\u003c/p\u003e\n\u003cp\u003eWe don’t know what any of these models are trained on. For example, a summarizer trained on news articles vs Reddit posts will perform better on news articles.\u003c/p\u003e\n\u003cp\u003eWhat we need is a set of metrics and benchmarks that we can use to do apples-to-apples comparisons of these models.\u003c/p\u003e\n\u003ch2\u003eHow do I evaluate summarization models?\u003c/h2\u003e\n\u003cp\u003eThe steps below can be used to evaluate any available model for any task. It requires hopping between a few sources of data for now, but we will be making this a lot easier moving forward.\u003c/p\u003e\n\u003cp\u003eSteps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFind the most common datasets used to train models for summarization.\u003c/li\u003e\n\u003cli\u003eFind the most common metrics used to evaluate models for summarization across those datasets.\u003c/li\u003e\n\u003cli\u003eDo a quick audit on training data provenance, quality and any exhibited biases, to keep in line with Responsible AI usage.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eFinding datasets\u003c/h2\u003e\n\u003cp\u003eThe easiest way to do this is using \u003ca href=\"https://paperswithcode.com/methods\"\u003ePapers With Code\u003c/a\u003e, an excellent resource for finding the latest scientific papers by task that also have code repositories attached.\u003c/p\u003e\n\u003cp\u003eFirst, filter Papers With Code’s “Text Summarization” datasets by \u003ca href=\"https://paperswithcode.com/datasets?q=\u0026amp;v=lst\u0026amp;o=cited\u0026amp;lang=english\u0026amp;mod=texts\u0026amp;task=text-summarization\u0026amp;page=1\"\u003emost cited text-based English datasets.\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLet’s pick (as of this writing) the most cited dataset — the \u003ca href=\"https://paperswithcode.com/dataset/cnn-daily-mail-1\"\u003e“CNN/DailyMail”\u003c/a\u003e dataset. Usually most cited is one marker of popularity.\u003c/p\u003e\n\u003cp\u003eNow, you don’t need to download this dataset. But we’re going to review the info Papers With Code have provided to learn more about it for the next step. This dataset is also available on \u003ca href=\"https://huggingface.co/datasets/cnn_dailymail\"\u003eHuggingface\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou want to check 3 things:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003elicense\u003c/li\u003e\n\u003cli\u003erecent papers\u003c/li\u003e\n\u003cli\u003ewhether the data is traceable and the methods are transparent\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFirst, check the license. In this case, it’s MIT licensed, which means it can be used for both commercial and personal projects.\u003c/p\u003e\n\u003cp\u003eNext, see if the papers using this dataset are recent. You can do this by sorting Papers in descending order. This particular dataset has many papers from 2023 – great!\u003c/p\u003e\n\u003cp\u003eFinally, let’s check whether the data is from a credible source. In this case, the dataset was generated by IBM in partnership with the University of Montréal. Great.\u003c/p\u003e\n\u003cp\u003eNow, let’s dig into how we can evaluate models that use this dataset.\u003c/p\u003e\n\u003ch2\u003eEvaluating models\u003c/h2\u003e\n\u003cp\u003eNext, we look for measured metrics that are common across datasets for the summarization task. BUT, if you’re not familiar with the literature on summarization, you have no idea what those are.\u003c/p\u003e\n\u003cp\u003eTo find out, pick a “Subtask” that’s close to what you’d like to see. We’d like to summarize the CNN article we pulled down above, so let’s choose \u003ca href=\"https://paperswithcode.com/sota/abstractive-text-summarization-on-cnn-daily\"\u003e“Abstractive Text Summarization”.\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eNow we’re in business! This page contains a significant amount of new information.\u003c/p\u003e\n\u003cp\u003eThere are mentions of three new terms: ROUGE-1, ROUGE-2 and ROUGE-L. These are the metrics that are used to \u003ca href=\"https://en.wikipedia.org/wiki/ROUGE_(metric)\"\u003emeasure summarization performance\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere is also a list of models and their scores on these three metrics – this is exactly what we’re looking for.\u003c/p\u003e\n\u003cp\u003eAssuming we’re looking at ROUGE-1 as our metric, we now have the top 3 models that we can evaluate in more detail. All 3 are close to 50, which is a promising ROUGE score (read up on ROUGE).\u003c/p\u003e\n\u003ch2\u003eTesting out a model\u003c/h2\u003e\n\u003cp\u003eOK, we have a few candidates, so let’s pick a model that will run on our local machines. Many models get their best performance when running on GPUs, but there are many that also generate summaries fast on CPUs. Let’s pick one of those to start – \u003cstrong\u003eGoogle’s Pegasus.\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# first we install huggingface\u0026#39;s transformers library\n%pip install transformers sentencepiece\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen we \u003ca href=\"https://huggingface.co/google/pegasus-cnn_dailymail\"\u003efind Pegasus\u003c/a\u003e on Huggingface. Note that part of the datasets Pegasus was trained on includes CNN/DailyMail which bodes well for our article summarization. Interestingly, there’s a variant of Pegasus from google that’s only trained on our dataset of choice, we should use that.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom transformers import PegasusForConditionalGeneration, PegasusTokenizer \nimport torch \n\n# Set the seed, this will help reproduce results. Changing the seed will \n# generate new results \nfrom transformers import set_seed \nset_seed(248602) \n\n# We\u0026#39;re using the version of Pegasus specifically trained for summarization \n# using the CNN/DailyMail dataset \nmodel_name = \u0026#34;google/pegasus-cnn_dailymail\u0026#34;\n\n# If you\u0026#39;re following along in Colab, switch your runtime to a\n# T4 GPU or other CUDA-compliant device for a speedup\ndevice = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; \n\n# Load the tokenizer\ntokenizer = PegasusTokenizer.from_pretrained(model_name) \n\n# Load the model \nmodel = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n\n# Tokenize the entire content\nbatch = tokenizer(content, padding=\u0026#34;longest\u0026#34;, return_tensors=\u0026#34;pt\u0026#34;).to(device)\n\n# Generate the summary as tokens\nsummarized = model.generate(**batch)\n\n# Decode the tokens back into text\nsummarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True)\nsummarized_text = summarized_decoded[0]\n\n# Compare\ndef compare(original, summarized_text):\n  print(f\u0026#34;Article text length: {len(original)}\\n\u0026#34;)\n  print(textwrap.fill(summarized_text, 100))\n  print()\n  print(f\u0026#34;Summarized length: {len(summarized_text)}\u0026#34;)\n\ncompare(content, summarized_text)\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003eArticle text length: 1427\n\nTrustworthy AI should enable people to decide how their data is used.\u0026lt;n\u0026gt;values and goals of a system\nshould be power aware and seek to minimize harm.\u0026lt;n\u0026gt;People should have agency and control over their\ndata and algorithmic outputs.\u0026lt;n\u0026gt;Developers need to implement strong measures to protect our data and\npersonal security.\n\nSummarized length: 320\u003c/pre\u003e\n\u003cp\u003eAlright, we got something! Kind of short though. Let’s see if we can make the summary longer…\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\nset_seed(860912)\n\n# Generate the summary as tokens, with a max_new_tokens\nsummarized = model.generate(**batch, max_new_tokens=800)\nsummarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True)\nsummarized_text = summarized_decoded[0]\n\ncompare(content, summarized_text)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003eArticle text length: 1427\n\nTrustworthy AI should enable people to decide how their data is used.\u0026lt;n\u0026gt;values and goals of a system\nshould be power aware and seek to minimize harm.\u0026lt;n\u0026gt;People should have agency and control over their\ndata and algorithmic outputs.\u0026lt;n\u0026gt;Developers need to implement strong measures to protect our data and\npersonal security.\n\nSummarized length: 320\u003c/pre\u003e\n\u003cp\u003eWell, that didn’t really work. Let’s try a different approach called \u003cstrong\u003e‘sampling’\u003c/strong\u003e. This allows the model to pick the next word according to its conditional probability distribution (specifically, the probability that said word follows the word before).\u003c/p\u003e\n\u003cp\u003eWe’ll also be setting the\u003cstrong\u003e ‘temperature’\u003c/strong\u003e. This variable works to control the levels of randomness and creativity in the generated output.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eset_seed(118511)\nsummarized = model.generate(**batch, do_sample=True, temperature=0.8, top_k=0)\nsummarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True)\nsummarized_text = summarized_decoded[0]\ncompare(content, summarized_text)\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003eArticle text length: 1427\n\nMozilla\u0026#39;s \u0026#34;Trustworthy AI\u0026#34; Thinking Points:.\u0026lt;n\u0026gt;People should have agency and control over their data\nand algorithmic outputs.\u0026lt;n\u0026gt;Developers need to implement strong measures to protect our data.\n\nSummarized length: 193\u003c/pre\u003e\n\u003cp\u003eShorter, but the quality is higher. Adjusting the temperature up will likely help.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eset_seed(108814)\nsummarized = model.generate(**batch, do_sample=True, temperature=1.0, top_k=0)\nsummarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True)\nsummarized_text = summarized_decoded[0]\ncompare(content, summarized_text)\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003eArticle text length: 1427\n\nMozilla\u0026#39;s \u0026#34;Trustworthy AI\u0026#34; Thinking Points:.\u0026lt;n\u0026gt;People should have agency and control over their data\nand algorithmic outputs.\u0026lt;n\u0026gt;Developers need to implement strong measures to protect our data and\npersonal security.\u0026lt;n\u0026gt;We need to mandate transparency so that we can fully understand these systems\nand their potential for harm.\n\nSummarized length: 325\u003c/pre\u003e\n\u003cp\u003eNow let’s play with one other generation approach called \u003cstrong\u003etop_k\u003c/strong\u003e sampling — instead of considering all possible next words in the vocabulary, the model only considers the top ‘k’ most probable next words.\u003c/p\u003e\n\u003cp\u003eThis technique helps to focus the model on likely continuations and reduces the chances of generating irrelevant or nonsensical text.\u003c/p\u003e\n\u003cp\u003eIt strikes a balance between creativity and coherence by limiting the pool of next-word choices, but not so much that the output becomes deterministic.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eset_seed(226012)\nsummarized = model.generate(**batch, do_sample=True, top_k=50)\nsummarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True)\nsummarized_text = summarized_decoded[0]\ncompare(content, summarized_text)\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003eArticle text length: 1427\n\nMozilla\u0026#39;s \u0026#34;Trustworthy AI\u0026#34; Thinking Points look at ethical issues surrounding automated decision\nmaking.\u0026lt;n\u0026gt;values and goals of a system should be power aware and seek to minimize harm.People\nshould have agency and control over their data and algorithmic outputs.\u0026lt;n\u0026gt;Developers need to\nimplement strong measures to protect our data and personal security.\n\nSummarized length: 355\u003c/pre\u003e\n\u003cp\u003eFinally, let’s try \u003cstrong\u003etop_p\u003c/strong\u003e sampling — also known as nucleus sampling, is a strategy where the model considers only the smallest set of top words whose cumulative probability exceeds a threshold ‘p’.\u003c/p\u003e\n\u003cp\u003eUnlike \u003cstrong\u003etop_k\u003c/strong\u003e which considers a fixed number of words, \u003cstrong\u003etop_p\u003c/strong\u003e adapts based on the distribution of probabilities for the next word. This makes it more dynamic and flexible. It helps create diverse and sensible text by allowing less probable words to be selected when the most probable ones don’t add up to ‘p’.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eset_seed(21420041)\nsummarized = model.generate(**batch, do_sample=True, top_p=0.9, top_k=50)\nsummarized_decoded = tokenizer.batch_decode(summarized, skip_special_tokens=True)\nsummarized_text = summarized_decoded[0]\ncompare(content, summarized_text)\n\n# saving this for later.\npegasus_summarized_text = summarized_text\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003eArticle text length: 1427\n\nMozilla\u0026#39;s \u0026#34;Trustworthy AI\u0026#34; Thinking Points:.\u0026lt;n\u0026gt;People should have agency and control over their data\nand algorithmic outputs.\u0026lt;n\u0026gt;Developers need to implement strong measures to protect our data and\npersonal security.\u0026lt;n\u0026gt;We need to mandate transparency so that we can fully understand these systems\nand their potential for harm.\n\nSummarized length: 325\u003c/pre\u003e\n\u003cp\u003eTo continue with the code example and see a test with another model, and to learn how to \u003ca href=\"https://ai-guide.future.mozilla.org/content/choosing-ml-models/#evaluating-ml-model-results\"\u003eevaluate ML model results\u003c/a\u003e (a whole another section), click here to view the Python Notebook and click “Open in Colab” to experiment with your \u003ca href=\"https://ai-guide.future.mozilla.org/content/choosing-ml-models/\"\u003eown custom code\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNote this guide will be constantly updated and new sections on Data Retrieval, Image Generation, and Fine Tuning will be coming next.\u003c/p\u003e\n\u003ch2\u003eDeveloper Contributions Are Vital\u003c/h2\u003e\n\u003cp\u003eShortly after today’s launch of the Mozilla AI Guide, we will be publishing our community contribution guidelines. It will provide guidance on the type of content developers can contribute and how it can be shared. Get ready to share any great open source AI projects, implementations, video and audio models.\u003c/p\u003e\n\u003cp\u003eTogether, we can bring together a cohesive, collaborative and responsible AI community.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eA special thanks to Kevin Li and Pradeep Elankumaran who pulled this great blog post together.\u003c/em\u003e\u003c/p\u003e\n    \u003csection\u003e\n                                \n                      \u003cp\u003eMelissa is a Senior Internet Advertising Specialist at Mozilla\u003c/p\u003e\n                                \u003cp\u003e\u003ca href=\"https://hacks.mozilla.org/author/mthermidormozilla-com/\"\u003eMore articles by Melissa Thermidor…\u003c/a\u003e\u003c/p\u003e\n                  \u003c/section\u003e\n  \u003c/article\u003e\u003c/div\u003e",
  "readingTime": "19 min read",
  "publishedTime": null,
  "modifiedTime": null
}
